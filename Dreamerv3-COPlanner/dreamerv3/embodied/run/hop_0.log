Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {}
JAX devices (1): [gpu(id=0)]
Policy devices: gpu:0
Train devices:  gpu:0
Tracing train function.
Optimizer model_opt has 15,686,787 variables.
{'action': Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>, 'deter': Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>, 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>, 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>}
{'action': Traced<ShapedArray(float32[15,1024,4])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,4])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,4]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b8c3eea10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b8c3d7680; dead>, <weakref at 0x7f5b8c3d74f0; dead>, <weakref at 0x7f5b8c3d7770; dead>, <weakref at 0x7f5b8c3d7360; dead>, <weakref at 0x7f5b8c3d7400; to 'JaxprTracer' at 0x7f5b8c3d7d60>, <weakref at 0x7f5b8c3d7270; to 'JaxprTracer' at 0x7f5b8c3d79f0>, <weakref at 0x7f5b8c3d7040; to 'JaxprTracer' at 0x7f5b8c3d76d0>, <weakref at 0x7f5b8c3d7180; to 'JaxprTracer' at 0x7f5b8c3d7130>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f5b8c2c8470>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b8c3eea10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b8c3d7680; dead>, <weakref at 0x7f5b8c3d74f0; dead>, <weakref at 0x7f5b8c3d7770; dead>, <weakref at 0x7f5b8c3d7360; dead>, <weakref at 0x7f5b8c3d7400; to 'JaxprTracer' at 0x7f5b8c3d7d60>, <weakref at 0x7f5b8c3d7270; to 'JaxprTracer' at 0x7f5b8c3d79f0>, <weakref at 0x7f5b8c3d7040; to 'JaxprTracer' at 0x7f5b8c3d76d0>, <weakref at 0x7f5b8c3d7180; to 'JaxprTracer' at 0x7f5b8c3d7130>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f5b8c2c8470>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b8c3eea10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b8c3d7680; dead>, <weakref at 0x7f5b8c3d74f0; dead>, <weakref at 0x7f5b8c3d7770; dead>, <weakref at 0x7f5b8c3d7360; dead>, <weakref at 0x7f5b8c3d7400; to 'JaxprTracer' at 0x7f5b8c3d7d60>, <weakref at 0x7f5b8c3d7270; to 'JaxprTracer' at 0x7f5b8c3d79f0>, <weakref at 0x7f5b8c3d7040; to 'JaxprTracer' at 0x7f5b8c3d76d0>, <weakref at 0x7f5b8c3d7180; to 'JaxprTracer' at 0x7f5b8c3d7130>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f5b8c2c8470>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b8c3eea10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b8c3d7680; dead>, <weakref at 0x7f5b8c3d74f0; dead>, <weakref at 0x7f5b8c3d7770; dead>, <weakref at 0x7f5b8c3d7360; dead>, <weakref at 0x7f5b8c3d7400; to 'JaxprTracer' at 0x7f5b8c3d7d60>, <weakref at 0x7f5b8c3d7270; to 'JaxprTracer' at 0x7f5b8c3d79f0>, <weakref at 0x7f5b8c3d7040; to 'JaxprTracer' at 0x7f5b8c3d76d0>, <weakref at 0x7f5b8c3d7180; to 'JaxprTracer' at 0x7f5b8c3d7130>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f5b8c2c8470>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Optimizer actor_opt has 1,054,728 variables.
Optimizer critic_opt has 1,181,439 variables.
Logdir /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp
Observation space:
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  position         Space(dtype=float64, shape=(6,), low=-inf, high=inf)
  velocity         Space(dtype=float64, shape=(7,), low=-inf, high=inf)
  touch            Space(dtype=float64, shape=(2,), low=-inf, high=inf)
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
Action space:
  reset            Space(dtype=bool, shape=(), low=False, high=True)
  action           Space(dtype=float32, shape=(4,), low=-1.0, high=1.0)
Prefill train dataset.
train_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212753F455159-0hgjdAGXPj5f8NH1nlKqD7-4Clmm8jSKr0KEs5DZ7WNUm-1024.npz
Prefill eval dataset.
eval_Episode has 500 steps and return 0.0.
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212757F838074-6EhaWQqwY8EGyozTbpjZBP-09PdgeLAhXeUqDjWyUjNkf-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2200 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0
warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'


Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100 Counter(1100) 1037
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T212801F562614-09PdgeLAhXeUqDjWyUjNkf-0000000000000000000000-76.npz
Saved chunk: 20230921T212757F245335-4Clmm8jSKr0KEs5DZ7WNUm-0000000000000000000000-76.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Tracing policy function.
Tracing policy function.
eval_Episode has 500 steps and return 0.0.
Tracing policy function.
Tracing train function.
{'action': Traced<ShapedArray(float32[15,1024,4])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,4])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,4]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b9c7b0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b6c41d8b0; dead>, <weakref at 0x7f5b6c41d6d0; dead>, <weakref at 0x7f5b6c41d770; dead>, <weakref at 0x7f5b6c41dea0; dead>, <weakref at 0x7f5b6c41d900; to 'JaxprTracer' at 0x7f5b6c41dc70>, <weakref at 0x7f5b6c41df40; to 'JaxprTracer' at 0x7f5b6c41dd60>, <weakref at 0x7f5b6c41d040; to 'JaxprTracer' at 0x7f5b6c41d720>, <weakref at 0x7f5b6c41d220; to 'JaxprTracer' at 0x7f5b6c41d630>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f58f001e1b0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b9c7b0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b6c41d8b0; dead>, <weakref at 0x7f5b6c41d6d0; dead>, <weakref at 0x7f5b6c41d770; dead>, <weakref at 0x7f5b6c41dea0; dead>, <weakref at 0x7f5b6c41d900; to 'JaxprTracer' at 0x7f5b6c41dc70>, <weakref at 0x7f5b6c41df40; to 'JaxprTracer' at 0x7f5b6c41dd60>, <weakref at 0x7f5b6c41d040; to 'JaxprTracer' at 0x7f5b6c41d720>, <weakref at 0x7f5b6c41d220; to 'JaxprTracer' at 0x7f5b6c41d630>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f58f001e1b0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b9c7b0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b6c41d8b0; dead>, <weakref at 0x7f5b6c41d6d0; dead>, <weakref at 0x7f5b6c41d770; dead>, <weakref at 0x7f5b6c41dea0; dead>, <weakref at 0x7f5b6c41d900; to 'JaxprTracer' at 0x7f5b6c41dc70>, <weakref at 0x7f5b6c41df40; to 'JaxprTracer' at 0x7f5b6c41dd60>, <weakref at 0x7f5b6c41d040; to 'JaxprTracer' at 0x7f5b6c41d720>, <weakref at 0x7f5b6c41d220; to 'JaxprTracer' at 0x7f5b6c41d630>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f58f001e1b0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f5b9c7b0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f5b6c41d8b0; dead>, <weakref at 0x7f5b6c41d6d0; dead>, <weakref at 0x7f5b6c41d770; dead>, <weakref at 0x7f5b6c41dea0; dead>, <weakref at 0x7f5b6c41d900; to 'JaxprTracer' at 0x7f5b6c41dc70>, <weakref at 0x7f5b6c41df40; to 'JaxprTracer' at 0x7f5b6c41dd60>, <weakref at 0x7f5b6c41d040; to 'JaxprTracer' at 0x7f5b6c41d720>, <weakref at 0x7f5b6c41d220; to 'JaxprTracer' at 0x7f5b6c41d630>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f58f001e1b0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Tracing report function.
Tracing report function.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2202 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.25 / train/action_max 4.25 / train/action_mean 0.04 / train/action_min -4.1 / train/action_std 1.03 / train/actor_opt_actor_opt_grad_overflow 0 / 
train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.2e-4 / train/actor_opt_grad_steps 1 / train/actor_opt_loss -1.54 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 
0.98 / train/cont_loss_std 0.43 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 0.29 / train/cont_pos_loss 0.98 / train/cont_pred 0.41 / train/cont_rate 1 / train/dyn_loss_mean 7.21 / train/dyn_loss_std 0.31 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.56 / train/extr_critic_critic_opt_grad_steps 1 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 0 /
train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 0 / train/extr_return_normed_max -inf / train/extr_return_normed_mean 0 / train/extr_return_normed_min 0 / train/extr_return_normed_std
0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / 
train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2576.58 / train/image_loss_std 32.5 / train/model_loss_mean 2587.43 / train/model_loss_std 32.51 / train/model_opt_grad_norm nan / train/model_opt_grad_steps 0 / train/model_opt_loss 2.6e7 / 
train/model_opt_model_opt_grad_overflow 1 / train/model_opt_model_opt_grad_scale 5000 / train/policy_entropy_mag 5.58 / train/policy_entropy_max 5.58 / train/policy_entropy_mean 5.08 / train/policy_entropy_min 3.87 / train/policy_entropy_std 0.21 / 
train/policy_logprob_mag 15.92 / train/policy_logprob_max -2.32 / train/policy_logprob_mean -5.08 / train/policy_logprob_min -15.92 / train/policy_logprob_std 1.44 / train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.93 / 
train/policy_randomness_min 0.8 / train/policy_randomness_std 0.02 / train/post_ent_mag 107.72 / train/post_ent_max 107.72 / train/post_ent_mean 107.38 / train/post_ent_min 107.03 / train/post_ent_std 0.11 / train/prior_ent_mag 107.97 / train/prior_ent_max 107.97 / 
train/prior_ent_mean 107.4 / train/prior_ent_min 106.65 / train/prior_ent_std 0.22 / train/rep_loss_mean 7.21 / train/rep_loss_std 0.31 / train/reward_avg 0 / train/reward_loss_mean 5.54 / train/reward_loss_std 9.5e-7 / train/reward_max_data 0 / train/reward_max_pred 0 / 
train/reward_neg_acc 1 / train/reward_neg_loss 5.54 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train/params_agent/wm/model_opt 1.6e7 / train/params_agent/task_behavior/critic/critic_opt 1.2e6 / 
train/params_agent/task_behavior/ac/actor_opt 1.1e6 / report/cont_avg 1 / report/cont_loss_mean 0.97 / report/cont_loss_std 0.39 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 0.27 / report/cont_pos_loss 0.97 / report/cont_pred 0.41 / 
report/cont_rate 1 / report/dyn_loss_mean 7.24 / report/dyn_loss_std 0.33 / report/image_loss_mean 2576.93 / report/image_loss_std 31.14 / report/model_loss_mean 2587.78 / report/model_loss_std 31.15 / report/post_ent_mag 107.68 / report/post_ent_max 107.68 / 
report/post_ent_mean 107.38 / report/post_ent_min 107.08 / report/post_ent_std 0.11 / report/prior_ent_mag 107.94 / report/prior_ent_max 107.94 / report/prior_ent_mean 107.37 / report/prior_ent_min 106.32 / report/prior_ent_std 0.24 / report/rep_loss_mean 7.24 / 
report/rep_loss_std 0.33 / report/reward_avg 0 / report/reward_loss_mean 5.54 / report/reward_loss_std 9.5e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 5.54 / report/reward_pos_acc nan / report/reward_pos_loss
nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 0.96 / eval/cont_loss_std 0.42 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 0.29 / eval/cont_pos_loss 0.96 / eval/cont_pred 0.41 / eval/cont_rate 1 / 
eval/dyn_loss_mean 7.26 / eval/dyn_loss_std 0.31 / eval/image_loss_mean 2576.85 / eval/image_loss_std 32.1 / eval/model_loss_mean 2587.7 / eval/model_loss_std 32.11 / eval/post_ent_mag 107.71 / eval/post_ent_max 107.71 / eval/post_ent_mean 107.35 / eval/post_ent_min 
107.05 / eval/post_ent_std 0.11 / eval/prior_ent_mag 107.96 / eval/prior_ent_max 107.96 / eval/prior_ent_mean 107.38 / eval/prior_ent_min 106.57 / eval/prior_ent_std 0.24 / eval/rep_loss_mean 7.26 / eval/rep_loss_std 0.31 / eval/reward_avg 0 / eval/reward_loss_mean 5.54 /
eval/reward_loss_std 9.5e-7 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.54 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1038 / replay/inserts 1038 / 
replay/samples 112 / replay/insert_wait_avg 2.4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.5e-6 / replay/sample_wait_frac 1 / eval_replay/size 1538 / eval_replay/inserts 1538 / eval_replay/samples 112 / eval_replay/insert_wait_avg 2.6e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.9e-6 / eval_replay/sample_wait_frac 1 / timer/duration 94.42 / timer/env.step_count 1101 / timer/env.step_total 4.52 / timer/env.step_frac 0.05 / timer/env.step_avg 4.1e-3 / timer/env.step_min 3.3e-3 / 
timer/env.step_max 0.69 / timer/replay._sample_count 112 / timer/replay._sample_total 24.26 / timer/replay._sample_frac 0.26 / timer/replay._sample_avg 0.22 / timer/replay._sample_min 8.8e-4 / timer/replay._sample_max 1.62 / timer/agent.save_count 1 / 
timer/agent.save_total 0.28 / timer/agent.save_frac 2.9e-3 / timer/agent.save_avg 0.28 / timer/agent.save_min 0.28 / timer/agent.save_max 0.28 / timer/agent.policy_count 502 / timer/agent.policy_total 13.76 / timer/agent.policy_frac 0.15 / timer/agent.policy_avg 0.03 / 
timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 11.32 / timer/dataset_train_count 1 / timer/dataset_train_total 2.3e-5 / timer/dataset_train_frac 2.5e-7 / timer/dataset_train_avg 2.3e-5 / timer/dataset_train_min 2.3e-5 / timer/dataset_train_max 2.3e-5 / 
timer/agent.train_count 1 / timer/agent.train_total 59.05 / timer/agent.train_frac 0.63 / timer/agent.train_avg 59.05 / timer/agent.train_min 59.05 / timer/agent.train_max 59.05 / timer/agent.report_count 2 / timer/agent.report_total 9.26 / timer/agent.report_frac 0.1 / 
timer/agent.report_avg 4.63 / timer/agent.report_min 0.06 / timer/agent.report_max 9.19 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 3.6e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max
3.4e-5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 1500 Counter(1500) 1437
Saved chunk: 20230921T212801F562614-09PdgeLAhXeUqDjWyUjNkf-1YVWMkwYtp3WpWBrL16FsO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 2000 Counter(2000) 1937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212757F245335-4Clmm8jSKr0KEs5DZ7WNUm-3ngiZuIPdlyYTNlOEMOlX2-1024.npz
Starting evaluation at step 2500 Counter(2500) 2437
Saved chunk: 20230921T212958F797620-1YVWMkwYtp3WpWBrL16FsO-6iqhi00yXVFHqTKlNeCjgX-1024.npz
eval_Episode has 500 steps and return 1.2.
train_Episode has 500 steps and return 1.1.
Starting evaluation at step 3000 Counter(3000) 2937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213041F468770-3ngiZuIPdlyYTNlOEMOlX2-1LUB2tNiwy1b2y1yODdl9W-1024.npz
Starting evaluation at step 3500 Counter(3500) 3437
eval_Episode has 500 steps and return 0.5.
Saved chunk: 20230921T213116F859083-6iqhi00yXVFHqTKlNeCjgX-47RGxRqdBKXKXhRtDuQJEo-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 4000 Counter(4000) 3937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213201F378181-1LUB2tNiwy1b2y1yODdl9W-1GcqwRCmhbaTJsYMtUK9Ma-1024.npz
Starting evaluation at step 4500 Counter(4500) 4437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 9682 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.13 / train/action_max 5 / train/action_mean 0.21 / train/action_min -4.89 / train/action_std 1.24 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.1e-3 / train/actor_opt_grad_steps 940 / train/actor_opt_loss -24.76 / train/adv_mag 0.19 / train/adv_max 0.19 / train/adv_mean 8.5e-4 / train/adv_min -1.4e-4
/ train/adv_std 5.1e-3 / train/cont_avg 1 / train/cont_loss_mean 5.3e-3 / train/cont_loss_std 2.2e-3 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-3 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.85 /
train/dyn_loss_std 2.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.31 / train/extr_critic_critic_opt_grad_steps 940 / train/extr_critic_critic_opt_loss 1.3e4
/ train/extr_critic_mag 4.6e-3 / train/extr_critic_max -inf / train/extr_critic_mean 4.1e-3 / train/extr_critic_min 4e-3 / train/extr_critic_std 4.8e-5 / train/extr_return_normed_mag 0.19 / train/extr_return_normed_max 0.19 / train/extr_return_normed_mean 1.3e-3 / 
train/extr_return_normed_min 4.4e-4 / train/extr_return_normed_std 5.1e-3 / train/extr_return_rate 1.2e-4 / train/extr_return_raw_mag 0.2 / train/extr_return_raw_max 0.2 / train/extr_return_raw_mean 4.9e-3 / train/extr_return_raw_min 4.1e-3 / train/extr_return_raw_std 
5.1e-3 / train/extr_reward_mag 0.06 / train/extr_reward_max -inf / train/extr_reward_mean 1.6e-4 / train/extr_reward_min 8.5e-5 / train/extr_reward_std 1.3e-3 / train/image_loss_mean 38.91 / train/image_loss_std 7.26 / train/model_loss_mean 40.82 / train/model_loss_std 
7.91 / train/model_opt_grad_norm 108.3 / train/model_opt_grad_steps 931 / train/model_opt_loss 891.44 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 28.62 / train/policy_entropy_mag 5.66 / train/policy_entropy_max 5.66 / 
train/policy_entropy_mean 5.6 / train/policy_entropy_min 3.9 / train/policy_entropy_std 0.18 / train/policy_logprob_mag 16.4 / train/policy_logprob_max -2.2 / train/policy_logprob_mean -5.61 / train/policy_logprob_min -16.4 / train/policy_logprob_std 1.46 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.81 / train/policy_randomness_std 0.02 / train/post_ent_mag 60.34 / train/post_ent_max 60.34 / train/post_ent_mean 49.77 / train/post_ent_min 
44.03 / train/post_ent_std 2.59 / train/prior_ent_mag 66.47 / train/prior_ent_max 66.47 / train/prior_ent_mean 54.27 / train/prior_ent_min 49.34 / train/prior_ent_std 3.01 / train/rep_loss_mean 2.85 / train/rep_loss_std 2.33 / train/reward_avg 3.3e-4 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.07 / train/reward_max_data 0.1 / train/reward_max_pred 0.03 / train/reward_neg_acc 1 / train/reward_neg_loss 0.19 / train/reward_pos_acc 0.37 / train/reward_pos_loss 3.6 / train/reward_pred 2.3e-4 / train/reward_rate 
1.2e-3 / train_stats/mean_log_entropy 5.62 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-6 / report/cont_loss_std 2.4e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-6 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.31 / report/dyn_loss_std 3.8 / report/image_loss_mean 6.09 / report/image_loss_std 4.65 / report/model_loss_mean 8.08 / report/model_loss_std 5.89 / report/post_ent_mag 36.72 / report/post_ent_max 36.72 / 
report/post_ent_mean 24.32 / report/post_ent_min 17.69 / report/post_ent_std 3.2 / report/prior_ent_mag 51.05 / report/prior_ent_max 51.05 / report/prior_ent_mean 27.81 / report/prior_ent_min 20.14 / report/prior_ent_std 5.17 / report/rep_loss_mean 3.31 / 
report/rep_loss_std 3.8 / report/reward_avg 2.7e-6 / report/reward_loss_mean 1.4e-3 / report/reward_loss_std 4e-3 / report/reward_max_data 2.7e-3 / report/reward_max_pred 5.4e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 2.9e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-6 / eval/cont_loss_std 2.1e-6 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-6 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 7.2 / eval/dyn_loss_std 5.19 / eval/image_loss_mean 12.99 / eval/image_loss_std 6.65 / eval/model_loss_mean 17.32 / eval/model_loss_std 8.46 / eval/post_ent_mag 48.82 / eval/post_ent_max 48.82 / eval/post_ent_mean 28.58 / 
eval/post_ent_min 18.78 / eval/post_ent_std 4.25 / eval/prior_ent_mag 51.05 / eval/prior_ent_max 51.05 / eval/prior_ent_mean 32.38 / eval/prior_ent_min 23.26 / eval/prior_ent_std 4.38 / eval/rep_loss_mean 7.2 / eval/rep_loss_std 5.19 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.3e-3 / eval/reward_loss_std 2.1e-4 / eval/reward_max_data 0 / eval/reward_max_pred 4.6e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 2.4e-5 / eval/reward_rate 0 / 
replay/size 4778 / replay/inserts 3740 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5045 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 290.97 / timer/env.step_count 3740 / timer/env.step_total 19.61 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 430.3 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-4 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7247 / timer/agent.policy_total 16.4 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.09 / 
timer/dataset_train_count 1870 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1870 / timer/agent.train_total 236.03 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.71

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 5000 Counter(5000) 4937
Saved chunk: 20230921T213235F291300-47RGxRqdBKXKXhRtDuQJEo-051UeOn4znWkjPsAj0vj3R-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213321F308835-1GcqwRCmhbaTJsYMtUK9Ma-0NNPiOG7cvZFhO5LNMo7Jn-1024.npz
Starting evaluation at step 5500 Counter(5500) 5437
eval_Episode has 500 steps and return 0.8.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 6000 Counter(6000) 5937
Saved chunk: 20230921T213429F890777-051UeOn4znWkjPsAj0vj3R-2MqItgnECrkTwRRQ5mi0oq-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213442F021750-0NNPiOG7cvZFhO5LNMo7Jn-2tFo2sqg2VXQWaqdddUDz4-1024.npz
Starting evaluation at step 6500 Counter(6500) 6437
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.7.
Starting evaluation at step 7000 Counter(7000) 6937
Saved chunk: 20230921T213548F754450-2MqItgnECrkTwRRQ5mi0oq-0EaN9ujrFQXek9hPkpKqyB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213602F379367-2tFo2sqg2VXQWaqdddUDz4-27ggptY6yY90DSCzKL0C6d-1024.npz
Starting evaluation at step 7500 Counter(7500) 7437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 8000 Counter(8000) 7937
Saved chunk: 20230921T213707F363243-0EaN9ujrFQXek9hPkpKqyB-6IYqeXaRaVAlAGVNsfWwOV-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213722F483754-27ggptY6yY90DSCzKL0C6d-3yQjk62LI8c2izmvhdUqBC-1024.npz
Starting evaluation at step 8500 Counter(8500) 8437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 17286 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.17 / train/action_max 5.01 / train/action_mean 0.21 / train/action_min -4.96 / train/action_std 1.28 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.8e-3 / train/actor_opt_grad_steps 2825 / train/actor_opt_loss -21.86 / train/adv_mag 0.33 / train/adv_max 0.33 / train/adv_mean 5.7e-4 / train/adv_min 
-9.8e-3 / train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 2.2e-6 / train/cont_loss_std 1.2e-6 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-6 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.33 / train/dyn_loss_std 3.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.21 / train/extr_critic_critic_opt_grad_steps 2825 / 
train/extr_critic_critic_opt_loss 5308.75 / train/extr_critic_mag 0.03 / train/extr_critic_max 0.03 / train/extr_critic_mean 0.01 / train/extr_critic_min 0.01 / train/extr_critic_std 8e-4 / train/extr_return_normed_mag 0.34 / train/extr_return_normed_max 0.34 / 
train/extr_return_normed_mean 1.4e-3 / train/extr_return_normed_min 7.3e-5 / train/extr_return_normed_std 0.01 / train/extr_return_rate 4.5e-4 / train/extr_return_raw_mag 0.36 / train/extr_return_raw_max 0.36 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 
0.01 / train/extr_return_raw_std 0.01 / train/extr_reward_mag 0.12 / train/extr_reward_max 0.12 / train/extr_reward_mean 1.4e-4 / train/extr_reward_min 5.1e-6 / train/extr_reward_std 2.8e-3 / train/image_loss_mean 4.94 / train/image_loss_std 4.35 / train/model_loss_mean 
6.94 / train/model_loss_std 5.72 / train/model_opt_grad_norm 31.35 / train/model_opt_grad_steps 2816 / train/model_opt_loss 733.52 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 106.5 / train/policy_entropy_mag 5.67 / 
train/policy_entropy_max 5.67 / train/policy_entropy_mean 5.52 / train/policy_entropy_min -0.92 / train/policy_entropy_std 0.55 / train/policy_logprob_mag 16.37 / train/policy_logprob_max 2.15 / train/policy_logprob_mean -5.52 / train/policy_logprob_min -16.37 / 
train/policy_logprob_std 1.54 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.98 / train/policy_randomness_min 0.28 / train/policy_randomness_std 0.06 / train/post_ent_mag 35.89 / train/post_ent_max 35.89 / 
train/post_ent_mean 22 / train/post_ent_min 14.46 / train/post_ent_std 3.29 / train/prior_ent_mag 49.16 / train/prior_ent_max 49.16 / train/prior_ent_mean 26.02 / train/prior_ent_min 18.35 / train/prior_ent_std 5.08 / train/rep_loss_mean 3.33 / train/rep_loss_std 3.98 / 
train/reward_avg 2.4e-4 / train/reward_loss_mean 1.9e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.08 / train/reward_max_pred 0.06 / train/reward_neg_acc 1 / train/reward_neg_loss 1e-3 / train/reward_pos_acc 0.88 / train/reward_pos_loss 1.26 / 
train/reward_pred 2.3e-4 / train/reward_rate 8.4e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.49 / report/cont_avg 1 / report/cont_loss_mean 9.6e-7 / report/cont_loss_std 7.9e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 9.6e-7 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.03 / report/dyn_loss_std 4.04 / report/image_loss_mean 3.91 / report/image_loss_std 4.52 / report/model_loss_mean 5.73 / report/model_loss_std 5.96 / 
report/post_ent_mag 37.08 / report/post_ent_max 37.08 / report/post_ent_mean 20.92 / report/post_ent_min 14.76 / report/post_ent_std 3.25 / report/prior_ent_mag 51.41 / report/prior_ent_max 51.41 / report/prior_ent_mean 24.93 / report/prior_ent_min 17.58 / 
report/prior_ent_std 5.34 / report/rep_loss_mean 3.03 / report/rep_loss_std 4.04 / report/reward_avg 0 / report/reward_loss_mean 3.2e-4 / report/reward_loss_std 1.5e-3 / report/reward_max_data 0 / report/reward_max_pred 5e-3 / report/reward_neg_acc 1 / 
report/reward_neg_loss 3.2e-4 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 9.9e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.7e-7 / eval/cont_loss_std 6.7e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-7 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 8.17 / eval/dyn_loss_std 5.77 / eval/image_loss_mean 8.73 / eval/image_loss_std 4.72 / eval/model_loss_mean 13.63 / eval/model_loss_std 7.1 / eval/post_ent_mag 38.29
/ eval/post_ent_max 38.29 / eval/post_ent_mean 23.25 / eval/post_ent_min 14.89 / eval/post_ent_std 3.09 / eval/prior_ent_mag 51.41 / eval/prior_ent_max 51.41 / eval/prior_ent_mean 28.08 / eval/prior_ent_min 18.89 / eval/prior_ent_std 4.59 / eval/rep_loss_mean 8.17 / 
eval/rep_loss_std 5.77 / eval/reward_avg 0 / eval/reward_loss_mean 2.8e-4 / eval/reward_loss_std 8.6e-5 / eval/reward_max_data 0 / eval/reward_max_pred 1.9e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / 
eval/reward_pred 4.6e-6 / eval/reward_rate 0 / replay/size 8580 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9053 / eval_replay/inserts 
4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3802 / timer/env.step_total 19.95 / timer/env.step_frac 
0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 438.28 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / 
timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7810 / timer/agent.policy_total 17.64 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 8.4e-3 / timer/dataset_train_count 1901 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1901 / 
timer/agent.train_total 241.09 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 9000 Counter(9000) 8937
Saved chunk: 20230921T213825F778263-6IYqeXaRaVAlAGVNsfWwOV-6BCpi1a6uGdol872Tu5BWA-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213842F430564-3yQjk62LI8c2izmvhdUqBC-53SXQWRIVGSV4FbthWsX80-1024.npz
Starting evaluation at step 9500 Counter(9500) 9437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 10000 Counter(10000) 9937
Saved chunk: 20230921T213944F881968-6BCpi1a6uGdol872Tu5BWA-5FMyxGpG5N1BiqMJwr5PvQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214003F202289-53SXQWRIVGSV4FbthWsX80-4HWwT4Ku2960KlC5NO1ahe-1024.npz
Starting evaluation at step 10500 Counter(10500) 10437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 11000 Counter(11000) 10937
Saved chunk: 20230921T214103F812730-5FMyxGpG5N1BiqMJwr5PvQ-3mdCsRDGRpxERLZeIj8PZ6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214123F645060-4HWwT4Ku2960KlC5NO1ahe-33r7KJAP5O19WUt3zp8CjP-1024.npz
Starting evaluation at step 11500 Counter(11500) 11437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T214243F765126-33r7KJAP5O19WUt3zp8CjP-0000000000000000000000-336.npz
Saved chunk: 20230921T214222F457270-3mdCsRDGRpxERLZeIj8PZ6-0000000000000000000000-858.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 12000 Counter(12000) 11937
Saved chunk: 20230921T214222F457270-3mdCsRDGRpxERLZeIj8PZ6-2w8Rs5UlBwUUdWltTReq0o-1024.npz
eval_Episode has 500 steps and return 1.4.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214243F765126-33r7KJAP5O19WUt3zp8CjP-1saB7eY6I9jFfwMzV2xLn1-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 24970 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 1.42 / eval_episode/reward_rate 4e-3 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.16 / train/action_max 5.02 / train/action_mean 0.1 / train/action_min -4.95 / train/action_std 1.3 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-3 / train/actor_opt_grad_steps 4735 / train/actor_opt_loss -17.49 / train/adv_mag 0.2 / train/adv_max 0.18 / train/adv_mean 9.8e-5 / train/adv_min -0.04 /
train/adv_std 5.8e-3 / train/cont_avg 1 / train/cont_loss_mean 4.9e-7 / train/cont_loss_std 3e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.7 / 
train/dyn_loss_std 4.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 4735 / train/extr_critic_critic_opt_loss 
6165.7 / train/extr_critic_mag 0.08 / train/extr_critic_max 0.08 / train/extr_critic_mean 0.02 / train/extr_critic_min 0.01 / train/extr_critic_std 2.1e-3 / train/extr_return_normed_mag 0.22 / train/extr_return_normed_max 0.22 / train/extr_return_normed_mean 8.2e-4 / 
train/extr_return_normed_min -5.7e-4 / train/extr_return_normed_std 6.9e-3 / train/extr_return_rate 3.1e-4 / train/extr_return_raw_mag 0.23 / train/extr_return_raw_max 0.23 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.01 / train/extr_return_raw_std 
6.9e-3 / train/extr_reward_mag 0.09 / train/extr_reward_max 0.09 / train/extr_reward_mean 8e-5 / train/extr_reward_min 6.8e-7 / train/extr_reward_std 2e-3 / train/image_loss_mean 4.53 / train/image_loss_std 3.82 / train/model_loss_mean 6.75 / train/model_loss_std 5.62 / 
train/model_opt_grad_norm 26.45 / train/model_opt_grad_steps 4726 / train/model_opt_loss 2695.31 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 403.65 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.62 / train/policy_entropy_min 0.33 / train/policy_entropy_std 0.23 / train/policy_logprob_mag 16.47 / train/policy_logprob_max 0.7 / train/policy_logprob_mean -5.62 / train/policy_logprob_min -16.47 / train/policy_logprob_std 1.44 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.42 / train/policy_randomness_std 0.03 / train/post_ent_mag 33.25 / train/post_ent_max 33.25 / train/post_ent_mean 21.34 / train/post_ent_min 
13.4 / train/post_ent_std 3.19 / train/prior_ent_mag 51.57 / train/prior_ent_max 51.57 / train/prior_ent_mean 25.56 / train/prior_ent_min 16.54 / train/prior_ent_std 5.54 / train/rep_loss_mean 3.7 / train/rep_loss_std 4.51 / train/reward_avg 1.7e-4 / 
train/reward_loss_mean 7.1e-4 / train/reward_loss_std 8.8e-3 / train/reward_max_data 0.07 / train/reward_max_pred 0.06 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-4 / train/reward_pos_acc 0.94 / train/reward_pos_loss 0.52 / train/reward_pred 1.7e-4 / 
train/reward_rate 5.7e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.55 / report/cont_avg 1 / report/cont_loss_mean 2.2e-7 / report/cont_loss_std 1.2e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.2e-7 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.34 / report/dyn_loss_std 5.02 / report/image_loss_mean 5.33 / report/image_loss_std 3.89 / report/model_loss_mean 7.93 / report/model_loss_std 6 / report/post_ent_mag 36.62 / 
report/post_ent_max 36.62 / report/post_ent_mean 21.73 / report/post_ent_min 13.79 / report/post_ent_std 3.4 / report/prior_ent_mag 52.84 / report/prior_ent_max 52.84 / report/prior_ent_mean 26.58 / report/prior_ent_min 16.86 / report/prior_ent_std 5.77 / 
report/rep_loss_mean 4.34 / report/rep_loss_std 5.02 / report/reward_avg 2.7e-6 / report/reward_loss_mean 2.2e-4 / report/reward_loss_std 3e-3 / report/reward_max_data 2.7e-3 / report/reward_max_pred 2.1e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-4 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 8.8e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-7 / eval/cont_loss_std 9.7e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
1.9e-7 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 9.14 / eval/dyn_loss_std 5.77 / eval/image_loss_mean 7.62 / eval/image_loss_std 4.13 / eval/model_loss_mean 13.1 / eval/model_loss_std 6.71 / eval/post_ent_mag 37.37 / eval/post_ent_max 37.37 / 
eval/post_ent_mean 22.42 / eval/post_ent_min 14.25 / eval/post_ent_std 3.21 / eval/prior_ent_mag 52.84 / eval/prior_ent_max 52.84 / eval/prior_ent_mean 27.74 / eval/prior_ent_min 18.36 / eval/prior_ent_std 4.8 / eval/rep_loss_mean 9.14 / eval/rep_loss_std 5.77 / 
eval/reward_avg 0 / eval/reward_loss_mean 8.3e-5 / eval/reward_loss_std 2.4e-5 / eval/reward_max_data 0 / eval/reward_max_pred 3.3e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.3e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.2e-6 / 
eval/reward_rate 0 / replay/size 1.2e4 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.3e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3842 / timer/env.step_total 20.12 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 445.71 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-3 / 
timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7349 / timer/agent.policy_total 16.8 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / 
timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 3.6e-4 / timer/agent.train_count 1921 / timer/agent.train_total 244.09 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 12500 Counter(12500) 12437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 13000 Counter(13000) 12937
Saved chunk: 20230921T214341F119401-2w8Rs5UlBwUUdWltTReq0o-00mzmWqsxGq5GFL5a1hrQu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214403F979921-1saB7eY6I9jFfwMzV2xLn1-5deYeDoK7uez0ViA7C8acy-1024.npz
Starting evaluation at step 13500 Counter(13500) 13437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 14000 Counter(14000) 13937
Saved chunk: 20230921T214500F408543-00mzmWqsxGq5GFL5a1hrQu-43cX4SyrwVjEHQIfQZiE5H-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 2.1.
Saved chunk: 20230921T214524F845517-5deYeDoK7uez0ViA7C8acy-5GJuzXTWMv9jpp5hArJyn0-1024.npz
Starting evaluation at step 14500 Counter(14500) 14437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 15000 Counter(15000) 14937
Saved chunk: 20230921T214619F163095-43cX4SyrwVjEHQIfQZiE5H-0zCWj840ZL4dZSsdlfquRK-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214645F243871-5GJuzXTWMv9jpp5hArJyn0-6rPt9I6TbjuBDiqVG4KSKu-1024.npz
Starting evaluation at step 15500 Counter(15500) 15437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 16000 Counter(16000) 15937
Saved chunk: 20230921T214737F745689-0zCWj840ZL4dZSsdlfquRK-7GmsyubhI8u0QYVIifxMef-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 1.8.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 32562 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 1.8 / episode/reward_rate 4e-3 / train/action_mag 5.17 / train/action_max 5.05 / train/action_mean 0.13 / train/action_min -4.98 / train/action_std 1.3 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.5e-3 / train/actor_opt_grad_steps 6645 / train/actor_opt_loss -19.94 / train/adv_mag 0.39 / train/adv_max 0.35 / train/adv_mean 3.6e-4 / train/adv_min -0.14 
/ train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 1.2e-7 / train/cont_loss_std 7.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.05 / 
train/dyn_loss_std 4.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 6645 / train/extr_critic_critic_opt_loss 
5544.08 / train/extr_critic_mag 0.26 / train/extr_critic_max 0.26 / train/extr_critic_mean 0.01 / train/extr_critic_min 0.01 / train/extr_critic_std 8e-3 / train/extr_return_normed_mag 0.48 / train/extr_return_normed_max 0.48 / train/extr_return_normed_mean 1.6e-3 / 
train/extr_return_normed_min -5.2e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 6.8e-4 / train/extr_return_raw_mag 0.49 / train/extr_return_raw_max 0.49 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 0.01 / train/extr_return_raw_std 0.02 /
train/extr_reward_mag 0.17 / train/extr_reward_max 0.17 / train/extr_reward_mean 1.5e-4 / train/extr_reward_min 3e-7 / train/extr_reward_std 3.8e-3 / train/image_loss_mean 4.21 / train/image_loss_std 3.31 / train/model_loss_mean 6.64 / train/model_loss_std 5.42 / 
train/model_opt_grad_norm 20.94 / train/model_opt_grad_steps 6636 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1526.32 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.59 / train/policy_entropy_min -1.25 / train/policy_entropy_std 0.41 / train/policy_logprob_mag 16.39 / train/policy_logprob_max 2.37 / train/policy_logprob_mean -5.59 / train/policy_logprob_min -16.39 / train/policy_logprob_std 1.49 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.25 / train/policy_randomness_std 0.04 / train/post_ent_mag 33.02 / train/post_ent_max 33.02 / train/post_ent_mean 21.71 / train/post_ent_min 
13.16 / train/post_ent_std 3.25 / train/prior_ent_mag 53.53 / train/prior_ent_max 53.53 / train/prior_ent_mean 26.15 / train/prior_ent_min 15.98 / train/prior_ent_std 5.83 / train/rep_loss_mean 4.05 / train/rep_loss_std 4.81 / train/reward_avg 2.9e-4 / 
train/reward_loss_mean 1.3e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.1 / train/reward_max_pred 0.07 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-4 / train/reward_pos_acc 0.9 / train/reward_pos_loss 1.02 / train/reward_pred 2.3e-4 / 
train/reward_rate 8.2e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.45 / report/cont_avg 1 / report/cont_loss_mean 5.3e-8 / report/cont_loss_std 3.3e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.3e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.02 / report/dyn_loss_std 4.73 / report/image_loss_mean 4.23 / report/image_loss_std 3.45 / report/model_loss_mean 6.65 / report/model_loss_std 5.66 / report/post_ent_mag 39.71 /
report/post_ent_max 39.71 / report/post_ent_mean 21.67 / report/post_ent_min 13.46 / report/post_ent_std 3.23 / report/prior_ent_mag 55.18 / report/prior_ent_max 55.18 / report/prior_ent_mean 26.23 / report/prior_ent_min 16.8 / report/prior_ent_std 5.8 / 
report/rep_loss_mean 4.02 / report/rep_loss_std 4.73 / report/reward_avg 0 / report/reward_loss_mean 3.1e-5 / report/reward_loss_std 2e-5 / report/reward_max_data 0 / report/reward_max_pred 9.1e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-5 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.6e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-8 / eval/cont_loss_std 2.3e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
4.9e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 9.7 / eval/dyn_loss_std 5.95 / eval/image_loss_mean 6.18 / eval/image_loss_std 2.84 / eval/model_loss_mean 12 / eval/model_loss_std 5.55 / eval/post_ent_mag 31.66 / eval/post_ent_max 31.66 / 
eval/post_ent_mean 22.64 / eval/post_ent_min 14.14 / eval/post_ent_std 2.66 / eval/prior_ent_mag 55.18 / eval/prior_ent_max 55.18 / eval/prior_ent_mean 27.75 / eval/prior_ent_min 19.19 / eval/prior_ent_std 4.69 / eval/rep_loss_mean 9.7 / eval/rep_loss_std 5.95 / 
eval/reward_avg 0 / eval/reward_loss_mean 2.8e-5 / eval/reward_loss_std 2.7e-6 / eval/reward_max_data 0 / eval/reward_max_pred 3.5e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.3e-6 / 
eval/reward_rate 0 / replay/size 1.6e4 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.7e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3796 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 437.27 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 17.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.01 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1898 / 
timer/agent.train_total 241.32 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T214805F325298-6rPt9I6TbjuBDiqVG4KSKu-67O6EIT06voCnNGdMEyuha-1024.npz
Starting evaluation at step 16500 Counter(16500) 16437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 17000 Counter(17000) 16937
Saved chunk: 20230921T214856F309895-7GmsyubhI8u0QYVIifxMef-4eZYj144lpW4yqbcf5VLof-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214926F015338-67O6EIT06voCnNGdMEyuha-5nnj5TDz3fnnn7m3mQJSj4-1024.npz
Starting evaluation at step 17500 Counter(17500) 17437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 18000 Counter(18000) 17937
Saved chunk: 20230921T215015F882585-4eZYj144lpW4yqbcf5VLof-4E8d26X2lRyqtRe9TuNS12-1024.npz
eval_Episode has 500 steps and return 0.8.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215046F740574-5nnj5TDz3fnnn7m3mQJSj4-4dBjEmkCYWA3W3TrzwxYJQ-1024.npz
Starting evaluation at step 18500 Counter(18500) 18437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 19000 Counter(19000) 18937
Saved chunk: 20230921T215134F747135-4E8d26X2lRyqtRe9TuNS12-6KsFZcm0tNLMHaxjsoexv5-1024.npz
eval_Episode has 500 steps and return 2.1.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215207F017343-4dBjEmkCYWA3W3TrzwxYJQ-7tKhK1tGTKUgDAWn7n9jt5-1024.npz
Starting evaluation at step 19500 Counter(19500) 19437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 20000 Counter(20000) 19937
Saved chunk: 20230921T215253F387932-6KsFZcm0tNLMHaxjsoexv5-7eKMlxZCR8Fjt8krjcTTeW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 40146 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.21 / train/action_max 5.01 / train/action_mean -0.11 / train/action_min -5.03 / train/action_std 1.31 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5e-3 / train/actor_opt_grad_steps 8540 / train/actor_opt_loss -18.93 / train/adv_mag 0.41 / train/adv_max 0.33 / train/adv_mean 2.5e-4 / train/adv_min -0.19 / 
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 3.4e-8 / train/cont_loss_std 2.7e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.23 / 
train/dyn_loss_std 5.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 8540 / train/extr_critic_critic_opt_loss 
5993.22 / train/extr_critic_mag 0.33 / train/extr_critic_max 0.33 / train/extr_critic_mean 0.02 / train/extr_critic_min 0.01 / train/extr_critic_std 0.01 / train/extr_return_normed_mag 0.52 / train/extr_return_normed_max 0.52 / train/extr_return_normed_mean 1.6e-3 / 
train/extr_return_normed_min -8.2e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 7.3e-4 / train/extr_return_raw_mag 0.53 / train/extr_return_raw_max 0.53 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.01 / train/extr_return_raw_std 0.02 /
train/extr_reward_mag 0.21 / train/extr_reward_max 0.21 / train/extr_reward_mean 1.9e-4 / train/extr_reward_min 8.4e-7 / train/extr_reward_std 4.6e-3 / train/image_loss_mean 3.85 / train/image_loss_std 2.78 / train/model_loss_mean 6.38 / train/model_loss_std 5.16 / 
train/model_opt_grad_norm 18.13 / train/model_opt_grad_steps 8530.29 / train/model_opt_loss 2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3121.69 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.59 / train/policy_entropy_min -1.55 / train/policy_entropy_std 0.4 / train/policy_logprob_mag 16.45 / train/policy_logprob_max 2.56 / train/policy_logprob_mean -5.59 / train/policy_logprob_min -16.45 / train/policy_logprob_std 1.48 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.22 / train/policy_randomness_std 0.04 / train/post_ent_mag 34 / train/post_ent_max 34 / train/post_ent_mean 22.33 / train/post_ent_min 13.42 /
train/post_ent_std 3.32 / train/prior_ent_mag 55.58 / train/prior_ent_max 55.58 / train/prior_ent_mean 26.86 / train/prior_ent_min 16.02 / train/prior_ent_std 5.99 / train/rep_loss_mean 4.23 / train/rep_loss_std 5.08 / train/reward_avg 2.9e-4 / train/reward_loss_mean 
7.6e-4 / train/reward_loss_std 9.3e-3 / train/reward_max_data 0.11 / train/reward_max_pred 0.1 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-4 / train/reward_pos_acc 0.96 / train/reward_pos_loss 0.58 / train/reward_pred 2.8e-4 / train/reward_rate 7.2e-4 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.47 / report/cont_avg 1 / report/cont_loss_mean 1.8e-8 / report/cont_loss_std 9.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-8 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 4.88 / report/image_loss_mean 3.27 / report/image_loss_std 2.31 / report/model_loss_mean 5.57 / report/model_loss_std 4.75 / report/post_ent_mag 33.11 / report/post_ent_max 33.11 / 
report/post_ent_mean 22.9 / report/post_ent_min 13.64 / report/post_ent_std 3.26 / report/prior_ent_mag 55.87 / report/prior_ent_max 55.87 / report/prior_ent_mean 26.92 / report/prior_ent_min 16 / report/prior_ent_std 5.85 / report/rep_loss_mean 3.81 / report/rep_loss_std
4.88 / report/reward_avg 6.6e-4 / report/reward_loss_mean 8.4e-3 / report/reward_loss_std 0.19 / report/reward_max_data 0.44 / report/reward_max_pred 0.04 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-5 / report/reward_pos_acc 0 / report/reward_pos_loss 4.29 / 
report/reward_pred 4e-5 / report/reward_rate 2e-3 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-8 / eval/cont_loss_std 6.6e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-8 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 9.38 / eval/dyn_loss_std 5.74 / eval/image_loss_mean 5.31 / eval/image_loss_std 2.87 / eval/model_loss_mean 10.94 / eval/model_loss_std 5.44 / eval/post_ent_mag 34.33 / eval/post_ent_max 34.33 / eval/post_ent_mean 23.68 / eval/post_ent_min 15.49 / 
eval/post_ent_std 3.05 / eval/prior_ent_mag 55.87 / eval/prior_ent_max 55.87 / eval/prior_ent_mean 28.04 / eval/prior_ent_min 18.69 / eval/prior_ent_std 4.85 / eval/rep_loss_mean 9.38 / eval/rep_loss_std 5.74 / eval/reward_avg 0 / eval/reward_loss_mean 9.7e-6 / 
eval/reward_loss_std 6.4e-6 / eval/reward_max_data 0 / eval/reward_max_pred 2e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.7e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 7.3e-7 / eval/reward_rate 0 / replay/size 2e4 / replay/inserts 
3792 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3792 / timer/env.step_total 19.78 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / 
timer/env.step_max 7.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 438.16 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7800 / timer/agent.policy_total 17.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 
1896 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1896 / timer/agent.train_total 241.26 / timer/agent.train_frac 0.8 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T215327F218767-7tKhK1tGTKUgDAWn7n9jt5-2FYATXCEuQdA2E9jcLE0RX-1024.npz
Starting evaluation at step 20500 Counter(20500) 20437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21000 Counter(21000) 20937
Saved chunk: 20230921T215411F869289-7eKMlxZCR8Fjt8krjcTTeW-1gIUD1l5UFZctq0rrkWWUE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21500 Counter(21500) 21437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215448F003165-2FYATXCEuQdA2E9jcLE0RX-6ykbBA5uUEcpuDFXiNHDJh-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22000 Counter(22000) 21937
Saved chunk: 20230921T215531F493239-1gIUD1l5UFZctq0rrkWWUE-5Z2NnlNYytE4UpFRTpB2sa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22500 Counter(22500) 22437
eval_Episode has 500 steps and return 1.0.
Saved chunk: 20230921T215612F170562-6ykbBA5uUEcpuDFXiNHDJh-3JT3xMGiKmDLZnohp3wtBq-1024.npz
train_Episode has 500 steps and return 1.7.
Starting evaluation at step 23000 Counter(23000) 22937
Saved chunk: 20230921T215650F350409-5Z2NnlNYytE4UpFRTpB2sa-43S2L22xHFFDdWwxG1iBHE-1024.npz
eval_Episode has 500 steps and return 1.5.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T215809F423797-43S2L22xHFFDdWwxG1iBHE-0000000000000000000000-93.npz
Saved chunk: 20230921T215732F384629-3JT3xMGiKmDLZnohp3wtBq-0000000000000000000000-572.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 23500 Counter(23500) 23437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 1.0.
Saved chunk: 20230921T215732F384629-3JT3xMGiKmDLZnohp3wtBq-6ehGUadcJouq05X2lcVbAe-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 47806 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0.95 / episode/reward_rate 4e-3 / train/action_mag 5.18 / train/action_max 4.97 / train/action_mean -0.06 / train/action_min -5.05 / train/action_std 1.31 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.5e-3 / train/actor_opt_grad_steps 1e4 / train/actor_opt_loss -17.26 / train/adv_mag 0.38 / train/adv_max 0.31 / train/adv_mean 7.6e-5 / train/adv_min -0.23 /
train/adv_std 8.9e-3 / train/cont_avg 1 / train/cont_loss_mean 1.2e-8 / train/cont_loss_std 9.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.21 / 
train/dyn_loss_std 5.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.01 / train/extr_critic_critic_opt_grad_steps 1e4 / train/extr_critic_critic_opt_loss 
4635.05 / train/extr_critic_mag 0.46 / train/extr_critic_max 0.46 / train/extr_critic_mean 0.01 / train/extr_critic_min 8.9e-3 / train/extr_critic_std 0.01 / train/extr_return_normed_mag 0.57 / train/extr_return_normed_max 0.57 / train/extr_return_normed_mean 1.1e-3 / 
train/extr_return_normed_min -5.1e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 6.6e-4 / train/extr_return_raw_mag 0.58 / train/extr_return_raw_max 0.58 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 9.2e-3 / train/extr_return_raw_std 0.02
/ train/extr_reward_mag 0.23 / train/extr_reward_max 0.23 / train/extr_reward_mean 1.9e-4 / train/extr_reward_min 2.7e-7 / train/extr_reward_std 4.9e-3 / train/image_loss_mean 3.41 / train/image_loss_std 2.32 / train/model_loss_mean 5.94 / train/model_loss_std 4.83 / 
train/model_opt_grad_norm 15.89 / train/model_opt_grad_steps 1e4 / train/model_opt_loss 3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5130.21 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.62 / train/policy_entropy_min -1.68 / train/policy_entropy_std 0.39 / train/policy_logprob_mag 16.42 / train/policy_logprob_max 2.86 / train/policy_logprob_mean -5.62 / train/policy_logprob_min -16.42 / train/policy_logprob_std 1.48 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.2 / train/policy_randomness_std 0.04 / train/post_ent_mag 33.25 / train/post_ent_max 33.25 / train/post_ent_mean 23.07 / train/post_ent_min 
13.91 / train/post_ent_std 3.24 / train/prior_ent_mag 56.95 / train/prior_ent_max 56.95 / train/prior_ent_mean 27.54 / train/prior_ent_min 16.38 / train/prior_ent_std 5.81 / train/rep_loss_mean 4.21 / train/rep_loss_std 5.2 / train/reward_avg 3.1e-4 / 
train/reward_loss_mean 8.9e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.12 / train/reward_max_pred 0.11 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-4 / train/reward_pos_acc 0.96 / train/reward_pos_loss 0.65 / train/reward_pred 2.9e-4 / 
train/reward_rate 7.5e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.55 / report/cont_avg 1 / report/cont_loss_mean 8.1e-9 / report/cont_loss_std 6.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 8.1e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.45 / report/dyn_loss_std 5.08 / report/image_loss_mean 3.4 / report/image_loss_std 1.82 / report/model_loss_mean 6.08 / report/model_loss_std 4.31 / report/post_ent_mag 34.04 / 
report/post_ent_max 34.04 / report/post_ent_mean 24.47 / report/post_ent_min 16.05 / report/post_ent_std 3.14 / report/prior_ent_mag 57.63 / report/prior_ent_max 57.63 / report/prior_ent_mean 29.35 / report/prior_ent_min 18.03 / report/prior_ent_std 5.29 / 
report/rep_loss_mean 4.45 / report/rep_loss_std 5.08 / report/reward_avg 0 / report/reward_loss_mean 2.9e-5 / report/reward_loss_std 4.1e-4 / report/reward_max_data 0 / report/reward_max_pred 2.5e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-5 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 5.7e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-9 / eval/cont_loss_std 3.3e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
6.4e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 9.76 / eval/dyn_loss_std 6.18 / eval/image_loss_mean 4.69 / eval/image_loss_std 2.44 / eval/model_loss_mean 10.54 / eval/model_loss_std 5.43 / eval/post_ent_mag 34.45 / eval/post_ent_max 34.45 / 
eval/post_ent_mean 24.27 / eval/post_ent_min 14.6 / eval/post_ent_std 3.06 / eval/prior_ent_mag 57.63 / eval/prior_ent_max 57.63 / eval/prior_ent_mean 29.49 / eval/prior_ent_min 20.33 / eval/prior_ent_std 4.89 / eval/rep_loss_mean 9.76 / eval/rep_loss_std 6.18 / 
eval/reward_avg 0 / eval/reward_loss_mean 6e-6 / eval/reward_loss_std 3.5e-5 / eval/reward_max_data 0 / eval/reward_max_pred 1.6e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 7.4e-7 / 
eval/reward_rate 0 / replay/size 2.4e4 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.4e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3830 / timer/env.step_total 20.15 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 441.73 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / 
timer/replay._sample_max 0.09 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7337 / timer/agent.policy_total 17.22 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.45 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / 
timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 24000 Counter(24000) 23937
Saved chunk: 20230921T215809F423797-43S2L22xHFFDdWwxG1iBHE-34Aq7K42PSFwrUNpSGIEOE-1024.npz
eval_Episode has 500 steps and return 2.5.
train_Episode has 500 steps and return 3.1.
Starting evaluation at step 24500 Counter(24500) 24437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215853F210789-6ehGUadcJouq05X2lcVbAe-2joi3z4hUlWhHafBUiyvlu-1024.npz
Starting evaluation at step 25000 Counter(25000) 24937
Saved chunk: 20230921T215928F858776-34Aq7K42PSFwrUNpSGIEOE-3UwPoKAehFSl4BDR9Bzcfm-1024.npz
eval_Episode has 500 steps and return 3.2.
train_Episode has 500 steps and return 0.3.
Starting evaluation at step 25500 Counter(25500) 25437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220014F395138-2joi3z4hUlWhHafBUiyvlu-1jxDyX7fxPVMB87bvgnZcp-1024.npz
Starting evaluation at step 26000 Counter(26000) 25937
Saved chunk: 20230921T220048F067804-3UwPoKAehFSl4BDR9Bzcfm-5SFH5YaMgZ9wvomTWPAkYR-1024.npz
eval_Episode has 500 steps and return 0.3.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 26500 Counter(26500) 26437
eval_Episode has 500 steps and return 0.2.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220134F999887-1jxDyX7fxPVMB87bvgnZcp-2H6zIWHEu4CpKaZjfreMQz-1024.npz
Starting evaluation at step 27000 Counter(27000) 26937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220206F921437-5SFH5YaMgZ9wvomTWPAkYR-7BHVWuqUJxdnsHWYbRGIs5-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 27500 Counter(27500) 27437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220255F179842-2H6zIWHEu4CpKaZjfreMQz-4c1Rl6qrLyqp4KzhSkRUcY-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 55382 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.19 / train/action_max 5.04 / train/action_mean -0.01 / train/action_min -5.02 / train/action_std 1.32 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-3 / train/actor_opt_grad_steps 1.2e4 / train/actor_opt_loss -17.94 / train/adv_mag 0.39 / train/adv_max 0.31 / train/adv_mean 1.4e-4 / train/adv_min -0.22 /
train/adv_std 9.1e-3 / train/cont_avg 1 / train/cont_loss_mean 5.8e-9 / train/cont_loss_std 5.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.8e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.13 / 
train/dyn_loss_std 5.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 1.2e4 / train/extr_critic_critic_opt_loss 
3982.64 / train/extr_critic_mag 0.52 / train/extr_critic_max 0.52 / train/extr_critic_mean 9.1e-3 / train/extr_critic_min 6.9e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.62 / train/extr_return_normed_max 0.62 / train/extr_return_normed_mean 1.7e-3 / 
train/extr_return_normed_min -5.2e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 7.9e-4 / train/extr_return_raw_mag 0.63 / train/extr_return_raw_max 0.63 / train/extr_return_raw_mean 9.2e-3 / train/extr_return_raw_min 7e-3 / train/extr_return_raw_std 0.02
/ train/extr_reward_mag 0.21 / train/extr_reward_max 0.21 / train/extr_reward_mean 2.3e-4 / train/extr_reward_min 1.5e-7 / train/extr_reward_std 5e-3 / train/image_loss_mean 2.99 / train/image_loss_std 2.08 / train/model_loss_mean 5.47 / train/model_loss_std 4.69 / 
train/model_opt_grad_norm 14.04 / train/model_opt_grad_steps 1.2e4 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5052.91 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.63 / train/policy_entropy_min -1.63 / train/policy_entropy_std 0.35 / train/policy_logprob_mag 16.56 / train/policy_logprob_max 2.62 / train/policy_logprob_mean -5.63 / train/policy_logprob_min -16.56 / train/policy_logprob_std 1.47 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.21 / train/policy_randomness_std 0.04 / train/post_ent_mag 33.67 / train/post_ent_max 33.67 / train/post_ent_mean 24.01 / train/post_ent_min 
14.19 / train/post_ent_std 3.39 / train/prior_ent_mag 57.86 / train/prior_ent_max 57.86 / train/prior_ent_mean 28.31 / train/prior_ent_min 16.77 / train/prior_ent_std 5.73 / train/rep_loss_mean 4.13 / train/rep_loss_std 5.28 / train/reward_avg 3.5e-4 / 
train/reward_loss_mean 9.1e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.13 / train/reward_max_pred 0.13 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-4 / train/reward_pos_acc 0.95 / train/reward_pos_loss 0.63 / train/reward_pred 3.5e-4 / 
train/reward_rate 8.3e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.55 / report/cont_avg 1 / report/cont_loss_mean 4.6e-9 / report/cont_loss_std 3.8e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.6e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.37 / report/dyn_loss_std 5.54 / report/image_loss_mean 3.07 / report/image_loss_std 2 / report/model_loss_mean 5.69 / report/model_loss_std 4.7 / report/post_ent_mag 37.1 / 
report/post_ent_max 37.1 / report/post_ent_mean 25.56 / report/post_ent_min 13.95 / report/post_ent_std 3.45 / report/prior_ent_mag 58.31 / report/prior_ent_max 58.31 / report/prior_ent_mean 29.96 / report/prior_ent_min 18.84 / report/prior_ent_std 5.35 / 
report/rep_loss_mean 4.37 / report/rep_loss_std 5.54 / report/reward_avg 9.3e-4 / report/reward_loss_mean 1.9e-3 / report/reward_loss_std 0.03 / report/reward_max_data 0.53 / report/reward_max_pred 0.58 / report/reward_neg_acc 1 / report/reward_neg_loss 8.9e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 1e-3 / report/reward_rate 2e-3 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-9 / eval/cont_loss_std 1.9e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
4.5e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 8.28 / eval/dyn_loss_std 7.92 / eval/image_loss_mean 5.51 / eval/image_loss_std 5.88 / eval/model_loss_mean 10.51 / eval/model_loss_std 10.1 / eval/post_ent_mag 35.35 / eval/post_ent_max 35.35 / 
eval/post_ent_mean 23.73 / eval/post_ent_min 16 / eval/post_ent_std 3.72 / eval/prior_ent_mag 58.31 / eval/prior_ent_max 58.31 / eval/prior_ent_mean 26.19 / eval/prior_ent_min 19.66 / eval/prior_ent_std 5.7 / eval/rep_loss_mean 8.28 / eval/rep_loss_std 7.92 / 
eval/reward_avg 4.5e-4 / eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.41 / eval/reward_max_data 0.09 / eval/reward_max_pred 0.04 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 6.8e-5 / 
eval/reward_rate 0 / replay/size 2.8e4 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.8e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3788 / timer/env.step_total 19.91 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 440.72 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.2e-3 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 17.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 8.8e-3 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1894 / 
timer/agent.train_total 241.07 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 28000 Counter(28000) 27937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 28500 Counter(28500) 28437
Saved chunk: 20230921T220325F448630-7BHVWuqUJxdnsHWYbRGIs5-0lgBpUUu5KToqQAreIQhSb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220415F193716-4c1Rl6qrLyqp4KzhSkRUcY-3ZD1hRDIuBpCRLRxk8DiUU-1024.npz
Starting evaluation at step 29000 Counter(29000) 28937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 29500 Counter(29500) 29437
Saved chunk: 20230921T220520F677108-0lgBpUUu5KToqQAreIQhSb-0K41vXqHpMp9Nc1qADqmoR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220536F453434-3ZD1hRDIuBpCRLRxk8DiUU-1qzzgVlCqbNM5K598RFTD6-1024.npz
Starting evaluation at step 30000 Counter(30000) 29937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 30500 Counter(30500) 30437
Saved chunk: 20230921T220639F505036-0K41vXqHpMp9Nc1qADqmoR-6BxNFPsFb4fIa5CKPcCPMI-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220656F739878-1qzzgVlCqbNM5K598RFTD6-2DnRrrGDZqU6vjhjNgB3j7-1024.npz
Starting evaluation at step 31000 Counter(31000) 30937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 31500 Counter(31500) 31437
Saved chunk: 20230921T220758F043436-6BxNFPsFb4fIa5CKPcCPMI-68Vr7Ftp58ZWEOmhsKW12f-1024.npz
eval_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 63002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.2 / train/action_max 5.07 / train/action_mean 0.17 / train/action_min -4.97 / train/action_std 1.31 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.4e-3 / train/actor_opt_grad_steps 1.4e4 / train/actor_opt_loss -17.56 / train/adv_mag 0.35 / train/adv_max 0.3 / train/adv_mean 9.9e-5 / train/adv_min -0.22 
/ train/adv_std 8.1e-3 / train/cont_avg 1 / train/cont_loss_mean 3.5e-9 / train/cont_loss_std 3.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.11 /
train/dyn_loss_std 5.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.01 / train/extr_critic_critic_opt_grad_steps 1.4e4 / train/extr_critic_critic_opt_loss 
2865.49 / train/extr_critic_mag 0.61 / train/extr_critic_max 0.61 / train/extr_critic_mean 6.5e-3 / train/extr_critic_min 4.5e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.71 / train/extr_return_normed_max 0.71 / train/extr_return_normed_mean 1.7e-3 / 
train/extr_return_normed_min -3.8e-4 / train/extr_return_normed_std 0.03 / train/extr_return_rate 9.8e-4 / train/extr_return_raw_mag 0.72 / train/extr_return_raw_max 0.72 / train/extr_return_raw_mean 6.6e-3 / train/extr_return_raw_min 4.6e-3 / train/extr_return_raw_std 
0.03 / train/extr_reward_mag 0.23 / train/extr_reward_max 0.23 / train/extr_reward_mean 2.9e-4 / train/extr_reward_min 3.4e-8 / train/extr_reward_std 6.2e-3 / train/image_loss_mean 2.73 / train/image_loss_std 1.91 / train/model_loss_mean 5.19 / train/model_loss_std 4.59 /
train/model_opt_grad_norm 13.71 / train/model_opt_grad_steps 1.4e4 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5026.18 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.64 / train/policy_entropy_min -1.28 / train/policy_entropy_std 0.3 / train/policy_logprob_mag 16.44 / train/policy_logprob_max 2.35 / train/policy_logprob_mean -5.64 / train/policy_logprob_min -16.44 / train/policy_logprob_std 1.46 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.24 / train/policy_randomness_std 0.03 / train/post_ent_mag 34.42 / train/post_ent_max 34.42 / train/post_ent_mean 25.01 / train/post_ent_min 
15.08 / train/post_ent_std 3.41 / train/prior_ent_mag 58.55 / train/prior_ent_max 58.55 / train/prior_ent_mean 29.26 / train/prior_ent_min 17.75 / train/prior_ent_std 5.56 / train/rep_loss_mean 4.11 / train/rep_loss_std 5.32 / train/reward_avg 5e-4 / 
train/reward_loss_mean 1.2e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.18 / train/reward_max_pred 0.16 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-4 / train/reward_pos_acc 0.92 / train/reward_pos_loss 0.75 / train/reward_pred 4.7e-4 / 
train/reward_rate 1.3e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.63 / report/cont_avg 1 / report/cont_loss_mean 3.4e-9 / report/cont_loss_std 4.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.4e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.15 / report/dyn_loss_std 5.56 / report/image_loss_mean 2.65 / report/image_loss_std 1.88 / report/model_loss_mean 5.15 / report/model_loss_std 4.68 / report/post_ent_mag 34.75 /
report/post_ent_max 34.75 / report/post_ent_mean 25.77 / report/post_ent_min 16.05 / report/post_ent_std 3.55 / report/prior_ent_mag 58.99 / report/prior_ent_max 58.99 / report/prior_ent_mean 29.91 / report/prior_ent_min 19.22 / report/prior_ent_std 5.41 / 
report/rep_loss_mean 4.15 / report/rep_loss_std 5.56 / report/reward_avg 3e-3 / report/reward_loss_mean 6.8e-3 / report/reward_loss_std 0.07 / report/reward_max_data 0.52 / report/reward_max_pred 0.53 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-4 / 
report/reward_pos_acc 0.89 / report/reward_pos_loss 0.75 / report/reward_pred 2.8e-3 / report/reward_rate 8.8e-3 / eval/cont_avg 1 / eval/cont_loss_mean 2e-9 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.07 / eval/dyn_loss_std 7.94 / eval/image_loss_mean 3.29 / eval/image_loss_std 3.72 / eval/model_loss_mean 7.53 / eval/model_loss_std 7.99 / eval/post_ent_mag 31.43 / eval/post_ent_max 
31.43 / eval/post_ent_mean 23.8 / eval/post_ent_min 16.7 / eval/post_ent_std 2.71 / eval/prior_ent_mag 58.99 / eval/prior_ent_max 58.99 / eval/prior_ent_mean 27.22 / eval/prior_ent_min 20.18 / eval/prior_ent_std 6.04 / eval/rep_loss_mean 7.07 / eval/rep_loss_std 7.94 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.7e-6 / eval/reward_loss_std 1.6e-5 / eval/reward_max_data 0 / eval/reward_max_pred 1.6e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 3.3e-7 / 
eval/reward_rate 0 / replay/size 3.1e4 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.2e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.21 / timer/env.step_count 3810 / timer/env.step_total 19.97 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3e4 / timer/replay._sample_total 441.91 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max
0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7818 / timer/agent.policy_total 17.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 
8.2e-3 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1905 / timer/agent.train_total 242.24 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220816F782656-2DnRrrGDZqU6vjhjNgB3j7-49C3H8eeAmZh9rhyPJjpjR-1024.npz
Starting evaluation at step 32000 Counter(32000) 31937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 32500 Counter(32500) 32437
Saved chunk: 20230921T220916F456410-68Vr7Ftp58ZWEOmhsKW12f-4grFYcL2wgp1f3pkYmcJYm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220937F490100-49C3H8eeAmZh9rhyPJjpjR-09WSigResHMV75QzBT6c6B-1024.npz
Starting evaluation at step 33000 Counter(33000) 32937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 33500 Counter(33500) 33437
Saved chunk: 20230921T221036F096918-4grFYcL2wgp1f3pkYmcJYm-2AgLba1qMHChucCirkvlAR-1024.npz
eval_Episode has 500 steps and return 1.8.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221058F136052-09WSigResHMV75QzBT6c6B-7l7kMHGWHTD3SZWRTTUzql-1024.npz
Starting evaluation at step 34000 Counter(34000) 33937
eval_Episode has 500 steps and return 1.4.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 34500 Counter(34500) 34437
Saved chunk: 20230921T221154F936024-2AgLba1qMHChucCirkvlAR-5FK61d5gYF1b0fLtfRoKQo-1024.npz
eval_Episode has 500 steps and return 1.7.
train_Episode has 500 steps and return 1.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T221313F503477-5FK61d5gYF1b0fLtfRoKQo-0000000000000000000000-352.npz
Saved chunk: 20230921T221218F413790-7l7kMHGWHTD3SZWRTTUzql-0000000000000000000000-808.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T221218F413790-7l7kMHGWHTD3SZWRTTUzql-3XWhooXxAhK5jshGHqHcLb-1024.npz
Starting evaluation at step 35000 Counter(35000) 34937
eval_Episode has 500 steps and return 2.2.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 70678 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 2.24 / eval_episode/reward_rate 4e-3 / train/action_mag 5.19 / train/action_max 5.1 / train/action_mean 0.24 / train/action_min -4.93 / train/action_std 1.29 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.9e-3 / train/actor_opt_grad_steps 1.6e4 / train/actor_opt_loss -17 / train/adv_mag 0.27 / train/adv_max 0.22 / train/adv_mean 4.2e-5 / train/adv_min -0.16 / 
train/adv_std 5.6e-3 / train/cont_avg 1 / train/cont_loss_mean 1.9e-9 / train/cont_loss_std 1.9e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.08 / 
train/dyn_loss_std 5.38 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1e-2 / train/extr_critic_critic_opt_grad_steps 1.6e4 / train/extr_critic_critic_opt_loss 
2145.92 / train/extr_critic_mag 0.47 / train/extr_critic_max 0.47 / train/extr_critic_mean 4.4e-3 / train/extr_critic_min 3e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.53 / train/extr_return_normed_max 0.53 / train/extr_return_normed_mean 1.1e-3 / 
train/extr_return_normed_min -2.7e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 5.7e-4 / train/extr_return_raw_mag 0.53 / train/extr_return_raw_max 0.53 / train/extr_return_raw_mean 4.4e-3 / train/extr_return_raw_min 3.1e-3 / train/extr_return_raw_std 
0.02 / train/extr_reward_mag 0.2 / train/extr_reward_max 0.2 / train/extr_reward_mean 1.8e-4 / train/extr_reward_min 0 / train/extr_reward_std 4.4e-3 / train/image_loss_mean 2.5 / train/image_loss_std 1.77 / train/model_loss_mean 4.95 / train/model_loss_std 4.52 / 
train/model_opt_grad_norm 12.89 / train/model_opt_grad_steps 1.6e4 / train/model_opt_loss 3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6067.71 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.65 / train/policy_entropy_min -0.92 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 16.54 / train/policy_logprob_max 1.86 / train/policy_logprob_mean -5.65 / train/policy_logprob_min -16.54 / train/policy_logprob_std 1.45 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.28 / train/policy_randomness_std 0.03 / train/post_ent_mag 35.35 / train/post_ent_max 35.35 / train/post_ent_mean 25.92 / train/post_ent_min 
15.43 / train/post_ent_std 3.52 / train/prior_ent_mag 59.14 / train/prior_ent_max 59.14 / train/prior_ent_mean 30.07 / train/prior_ent_min 18.2 / train/prior_ent_std 5.51 / train/rep_loss_mean 4.08 / train/rep_loss_std 5.38 / train/reward_avg 3.3e-4 / 
train/reward_loss_mean 7.3e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.13 / train/reward_max_pred 0.13 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-4 / train/reward_pos_acc 0.96 / train/reward_pos_loss 0.58 / train/reward_pred 3.4e-4 / 
train/reward_rate 7.4e-4 / train_stats/mean_log_entropy 5.61 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.4e-9 / report/cont_loss_std 1.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.4e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 5.52 / report/image_loss_mean 2.16 / report/image_loss_std 1.68 / report/model_loss_mean 4.41 / report/model_loss_std 4.51 / report/post_ent_mag 35.1 / 
report/post_ent_max 35.1 / report/post_ent_mean 25.6 / report/post_ent_min 15.63 / report/post_ent_std 3.71 / report/prior_ent_mag 59.28 / report/prior_ent_max 59.28 / report/prior_ent_mean 29.65 / report/prior_ent_min 16.65 / report/prior_ent_std 5.87 / 
report/rep_loss_mean 3.76 / report/rep_loss_std 5.52 / report/reward_avg 0 / report/reward_loss_mean 2.2e-6 / report/reward_loss_std 1.9e-5 / report/reward_max_data 0 / report/reward_max_pred 7.3e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 3.8e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1e-9 / eval/cont_loss_std 6.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
1e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.52 / eval/dyn_loss_std 7.31 / eval/image_loss_mean 2.9 / eval/image_loss_std 3.43 / eval/model_loss_mean 6.81 / eval/model_loss_std 7.35 / eval/post_ent_mag 32.45 / eval/post_ent_max 32.45 / 
eval/post_ent_mean 23.68 / eval/post_ent_min 17.01 / eval/post_ent_std 2.74 / eval/prior_ent_mag 59.28 / eval/prior_ent_max 59.28 / eval/prior_ent_mean 26.2 / eval/prior_ent_min 21.01 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 6.52 / eval/rep_loss_std 7.31 / 
eval/reward_avg 0 / eval/reward_loss_mean 1e-6 / eval/reward_loss_std 1.4e-5 / eval/reward_max_data 0 / eval/reward_max_pred 9e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.8e-7 / 
eval/reward_rate 0 / replay/size 3.5e4 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.6e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3838 / timer/env.step_total 20.27 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 449.37 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / 
timer/replay._sample_max 0.11 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7345 / timer/agent.policy_total 16.84 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / 
timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 35500 Counter(35500) 35437
Saved chunk: 20230921T221313F503477-5FK61d5gYF1b0fLtfRoKQo-454qtRb6QW0ojaTbNoYKhU-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221338F734061-3XWhooXxAhK5jshGHqHcLb-4gBB2VtFQZpMYKuLFVRfAy-1024.npz
Starting evaluation at step 36000 Counter(36000) 35937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 36500 Counter(36500) 36437
Saved chunk: 20230921T221432F889068-454qtRb6QW0ojaTbNoYKhU-3z5SESGO248mEpCuakJcJO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.3.
Saved chunk: 20230921T221459F678723-4gBB2VtFQZpMYKuLFVRfAy-24JcNT4ojIZ4vRwFYztT3T-1024.npz
Starting evaluation at step 37000 Counter(37000) 36937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 37500 Counter(37500) 37437
Saved chunk: 20230921T221551F906164-3z5SESGO248mEpCuakJcJO-4QfAZDsJM2DwGB4ykfa9N3-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221620F161157-24JcNT4ojIZ4vRwFYztT3T-2GZFrugx4cmwN87Wh1myut-1024.npz
Starting evaluation at step 38000 Counter(38000) 37937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 38500 Counter(38500) 38437
Saved chunk: 20230921T221710F569197-4QfAZDsJM2DwGB4ykfa9N3-2elnw5JaA7jUm4V4MKC5Cu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221740F285465-2GZFrugx4cmwN87Wh1myut-74qsFpCX3Sj43v72NgwES0-1024.npz
Starting evaluation at step 39000 Counter(39000) 38937
eval_Episode has 500 steps and return 3.4.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 78270 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 3.38 / eval_episode/reward_rate 0.01 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.19 / train/action_max 5.1 / train/action_mean 0.32 / train/action_min -4.95 / train/action_std 1.29 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.3e-3 / train/actor_opt_grad_steps 1.8e4 / train/actor_opt_loss -16.88 / train/adv_mag 0.28 / train/adv_max 0.22 / train/adv_mean 2.9e-5 / train/adv_min -0.18
/ train/adv_std 5.8e-3 / train/cont_avg 1 / train/cont_loss_mean 1.1e-9 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.07 /
train/dyn_loss_std 5.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.6e-3 / train/extr_critic_critic_opt_grad_steps 1.8e4 / train/extr_critic_critic_opt_loss 
1537.45 / train/extr_critic_mag 0.52 / train/extr_critic_max 0.52 / train/extr_critic_mean 3.2e-3 / train/extr_critic_min 1.9e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.56 / train/extr_return_normed_max 0.56 / train/extr_return_normed_mean 1.1e-3 / 
train/extr_return_normed_min -1.9e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 6.4e-4 / train/extr_return_raw_mag 0.56 / train/extr_return_raw_max 0.56 / train/extr_return_raw_mean 3.3e-3 / train/extr_return_raw_min 2e-3 / train/extr_return_raw_std 0.02
/ train/extr_reward_mag 0.22 / train/extr_reward_max 0.22 / train/extr_reward_mean 1.8e-4 / train/extr_reward_min 0 / train/extr_reward_std 4.8e-3 / train/image_loss_mean 2.33 / train/image_loss_std 1.75 / train/model_loss_mean 4.77 / train/model_loss_std 4.57 / 
train/model_opt_grad_norm 12.26 / train/model_opt_grad_steps 1.8e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6798.94 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.65 / train/policy_entropy_min -0.97 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 16.47 / train/policy_logprob_max 1.97 / train/policy_logprob_mean -5.65 / train/policy_logprob_min -16.47 / train/policy_logprob_std 1.45 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.28 / train/policy_randomness_std 0.03 / train/post_ent_mag 36.18 / train/post_ent_max 36.18 / train/post_ent_mean 26.75 / train/post_ent_min 
15.66 / train/post_ent_std 3.69 / train/prior_ent_mag 59.75 / train/prior_ent_max 59.75 / train/prior_ent_mean 30.91 / train/prior_ent_min 18.77 / train/prior_ent_std 5.55 / train/rep_loss_mean 4.07 / train/rep_loss_std 5.47 / train/reward_avg 3e-4 / 
train/reward_loss_mean 6.6e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.13 / train/reward_max_pred 0.12 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.63 / train/reward_pred 2.9e-4 / 
train/reward_rate 7e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.58 / report/cont_avg 1 / report/cont_loss_mean 8.6e-10 / report/cont_loss_std 8.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 8.6e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.98 / report/dyn_loss_std 5.6 / report/image_loss_mean 2.3 / report/image_loss_std 1.63 / report/model_loss_mean 4.69 / report/model_loss_std 4.46 / report/post_ent_mag 36.72 / 
report/post_ent_max 36.72 / report/post_ent_mean 26.5 / report/post_ent_min 15.13 / report/post_ent_std 3.57 / report/prior_ent_mag 60.41 / report/prior_ent_max 60.41 / report/prior_ent_mean 30.52 / report/prior_ent_min 17.01 / report/prior_ent_std 5.84 / 
report/rep_loss_mean 3.98 / report/rep_loss_std 5.6 / report/reward_avg 2.1e-3 / report/reward_loss_mean 4.1e-3 / report/reward_loss_std 0.05 / report/reward_max_data 0.44 / report/reward_max_pred 0.46 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.62 / report/reward_pred 2.1e-3 / report/reward_rate 5.9e-3 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-10 / eval/cont_loss_std 3.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.6e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.06 / eval/dyn_loss_std 8.04 / eval/image_loss_mean 3.26 / eval/image_loss_std 3.69 / eval/model_loss_mean 7.5 / eval/model_loss_std 8 / eval/post_ent_mag 35.26 / eval/post_ent_max 
35.26 / eval/post_ent_mean 25.84 / eval/post_ent_min 16.3 / eval/post_ent_std 2.56 / eval/prior_ent_mag 60.41 / eval/prior_ent_max 60.41 / eval/prior_ent_mean 29.81 / eval/prior_ent_min 20.66 / eval/prior_ent_std 5.49 / eval/rep_loss_mean 7.06 / eval/rep_loss_std 8.04 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.8e-7 / eval/reward_loss_std 6.2e-7 / eval/reward_max_data 0 / eval/reward_max_pred 3e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 3.8e-8 / 
eval/reward_rate 0 / replay/size 3.9e4 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3796 / timer/env.step_total 19.87 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.02 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / 
timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 17.55 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.08 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1898 / 
timer/agent.train_total 241.18 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 39500 Counter(39500) 39437
Saved chunk: 20230921T221829F016678-2elnw5JaA7jUm4V4MKC5Cu-7j6K2QwVmOIr7s2Hh0ZwSV-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221900F261855-74qsFpCX3Sj43v72NgwES0-5FJYMlTWlQrOu7pvguDZpd-1024.npz
Starting evaluation at step 40000 Counter(40000) 39937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 40500 Counter(40500) 40437
Saved chunk: 20230921T221948F231385-7j6K2QwVmOIr7s2Hh0ZwSV-5np706whyqXxu4DBeHqqeS-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222021F249730-5FJYMlTWlQrOu7pvguDZpd-25hCzm3FHwphUKtUelugjO-1024.npz
Starting evaluation at step 41000 Counter(41000) 40937
eval_Episode has 500 steps and return 0.7.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 41500 Counter(41500) 41437
Saved chunk: 20230921T222107F191311-5np706whyqXxu4DBeHqqeS-5H8qJzCKCqlK4qWNNSAQmV-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222141F657106-25hCzm3FHwphUKtUelugjO-4MURZGpfXnls1IlD40WF2B-1024.npz
Starting evaluation at step 42000 Counter(42000) 41937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 42500 Counter(42500) 42437
Saved chunk: 20230921T222225F815784-5H8qJzCKCqlK4qWNNSAQmV-1pTxc8ELgsw9RSn3olVwia-1024.npz
eval_Episode has 500 steps and return 5.1.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 85958 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 5.13 / eval_episode/reward_rate 0.02 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.17 / train/action_max 5.1 / train/action_mean 0.27 / train/action_min -4.93 / train/action_std 1.3 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.1e-3 / train/actor_opt_grad_steps 2e4 / train/actor_opt_loss -17.5 / train/adv_mag 0.29 / train/adv_max 0.22 / train/adv_mean 9.1e-5 / train/adv_min -0.18 / 
train/adv_std 6.2e-3 / train/cont_avg 1 / train/cont_loss_mean 7.6e-10 / train/cont_loss_std 1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.12 / 
train/dyn_loss_std 5.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.3e-3 / train/extr_critic_critic_opt_grad_steps 2e4 / train/extr_critic_critic_opt_loss 
1057.61 / train/extr_critic_mag 0.53 / train/extr_critic_max 0.53 / train/extr_critic_mean 2.7e-3 / train/extr_critic_min 1.2e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.56 / train/extr_return_normed_max 0.56 / train/extr_return_normed_mean 1.4e-3 / 
train/extr_return_normed_min -1.2e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 7.8e-4 / train/extr_return_raw_mag 0.57 / train/extr_return_raw_max 0.57 / train/extr_return_raw_mean 2.7e-3 / train/extr_return_raw_min 1.3e-3 / train/extr_return_raw_std 
0.02 / train/extr_reward_mag 0.19 / train/extr_reward_max 0.19 / train/extr_reward_mean 2.3e-4 / train/extr_reward_min 0 / train/extr_reward_std 4.8e-3 / train/image_loss_mean 2.22 / train/image_loss_std 1.67 / train/model_loss_mean 4.7 / train/model_loss_std 4.51 / 
train/model_opt_grad_norm 11.58 / train/model_opt_grad_steps 2e4 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7616.58 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.65 / train/policy_entropy_min -0.8 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 16.45 / train/policy_logprob_max 1.79 / train/policy_logprob_mean -5.65 / train/policy_logprob_min -16.45 / train/policy_logprob_std 1.45 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.3 / train/policy_randomness_std 0.03 / train/post_ent_mag 37.28 / train/post_ent_max 37.28 / train/post_ent_mean 27.79 / train/post_ent_min 16.12
/ train/post_ent_std 3.81 / train/prior_ent_mag 60.2 / train/prior_ent_max 60.2 / train/prior_ent_mean 32 / train/prior_ent_min 19.44 / train/prior_ent_std 5.49 / train/rep_loss_mean 4.12 / train/rep_loss_std 5.48 / train/reward_avg 3.4e-4 / train/reward_loss_mean 7.9e-4 
/ train/reward_loss_std 0.01 / train/reward_max_data 0.13 / train/reward_max_pred 0.13 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-4 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.55 / train/reward_pred 3.5e-4 / train/reward_rate 8.4e-4 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.6 / report/cont_avg 1 / report/cont_loss_mean 6.3e-10 / report/cont_loss_std 6.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.13 / report/dyn_loss_std 5.85 / report/image_loss_mean 2.13 / report/image_loss_std 1.47 / report/model_loss_mean 4.61 / report/model_loss_std 4.54 / report/post_ent_mag 38.81 / report/post_ent_max 38.81 / 
report/post_ent_mean 28.22 / report/post_ent_min 14.59 / report/post_ent_std 4.02 / report/prior_ent_mag 60.83 / report/prior_ent_max 60.83 / report/prior_ent_mean 32.68 / report/prior_ent_min 17.02 / report/prior_ent_std 5.7 / report/rep_loss_mean 4.13 / 
report/rep_loss_std 5.85 / report/reward_avg 0 / report/reward_loss_mean 1.7e-7 / report/reward_loss_std 1.9e-6 / report/reward_max_data 0 / report/reward_max_pred 8.6e-6 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-7 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 4.8e-8 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-10 / eval/cont_loss_std 5.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.4e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.87 / eval/dyn_loss_std 6.23 / eval/image_loss_mean 2.84 / eval/image_loss_std 3.55 / eval/model_loss_mean 5.79 / eval/model_loss_std 6.76 / eval/post_ent_mag 38.51 / eval/post_ent_max 38.51 / eval/post_ent_mean 27.36 / 
eval/post_ent_min 16.67 / eval/post_ent_std 4.79 / eval/prior_ent_mag 60.83 / eval/prior_ent_max 60.83 / eval/prior_ent_mean 30.04 / eval/prior_ent_min 21.14 / eval/prior_ent_std 6.31 / eval/rep_loss_mean 4.87 / eval/rep_loss_std 6.23 / eval/reward_avg 2e-3 / 
eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.37 / eval/reward_max_data 0.84 / eval/reward_max_pred 0.52 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 4.92 / eval/reward_pred 1.9e-3 / eval/reward_rate 2.9e-3 / 
replay/size 4.3e4 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3844 / timer/env.step_total 20.09 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.96 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7351 / timer/agent.policy_total 16.68 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1922 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1922 / timer/agent.train_total 244.26 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 43000 Counter(43000) 42937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222301F744829-4MURZGpfXnls1IlD40WF2B-4hdUnxEGWw1OMXu3lUuru1-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 43500 Counter(43500) 43437
Saved chunk: 20230921T222344F278692-1pTxc8ELgsw9RSn3olVwia-0bLYLBuhuyiFWit8mJqydn-1024.npz
eval_Episode has 500 steps and return 0.2.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 44000 Counter(44000) 43937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222425F909301-4hdUnxEGWw1OMXu3lUuru1-51IqW67qVs6iqcoEzxm6pY-1024.npz
train_Episode has 500 steps and return 3.1.
Starting evaluation at step 44500 Counter(44500) 44437
Saved chunk: 20230921T222503F703823-0bLYLBuhuyiFWit8mJqydn-0QdxTms0LfMhQCsiEyZmgm-1024.npz
eval_Episode has 500 steps and return 12.3.
train_Episode has 500 steps and return 12.2.
Starting evaluation at step 45000 Counter(45000) 44937
eval_Episode has 500 steps and return 13.2.
Saved chunk: 20230921T222546F499922-51IqW67qVs6iqcoEzxm6pY-0GaKxutiC480hB1UD1rwyP-1024.npz
train_Episode has 500 steps and return 23.8.
Starting evaluation at step 45500 Counter(45500) 45437
Saved chunk: 20230921T222622F564665-0QdxTms0LfMhQCsiEyZmgm-26hka1a7iXP6JyvgmF7qQ8-1024.npz
eval_Episode has 500 steps and return 31.2.
train_Episode has 500 steps and return 16.1.
Starting evaluation at step 46000 Counter(46000) 45937
eval_Episode has 500 steps and return 22.2.
Saved chunk: 20230921T222706F738109-0GaKxutiC480hB1UD1rwyP-43FqJ7oGC8EuxoMMlpMBlO-1024.npz
train_Episode has 500 steps and return 36.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T222826F780680-43FqJ7oGC8EuxoMMlpMBlO-0000000000000000000000-20.npz
Saved chunk: 20230921T222741F164843-26hka1a7iXP6JyvgmF7qQ8-0000000000000000000000-611.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 46500 Counter(46500) 46437
Saved chunk: 20230921T222741F164843-26hka1a7iXP6JyvgmF7qQ8-7Hs4Nmr1gBQrV2FkYsz4hU-1024.npz
eval_Episode has 500 steps and return 27.5.
train_Episode has 500 steps and return 21.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 93542 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 27.45 / eval_episode/reward_rate 0.09 / episode/length 500 / episode/score 21.03 / episode/reward_rate 0.07 / train/action_mag 4.41 / train/action_max 4.34 / train/action_mean 0.17 / train/action_min -3.99 / train/action_std 
1.04 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 2.2e4 / train/actor_opt_loss -802.62 / train/adv_mag 1.09 / train/adv_max 1.08 / train/adv_mean 0.08 / train/adv_min 
-0.38 / train/adv_std 0.11 / train/cont_avg 1 / train/cont_loss_mean 5.7e-10 / train/cont_loss_std 8.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.12 / train/dyn_loss_std 5.54 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.77 / train/extr_critic_critic_opt_grad_steps 2.2e4 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 1.88 / train/extr_critic_max 1.88 / train/extr_critic_mean 1.1 / train/extr_critic_min 0.49 / train/extr_critic_std 0.31 / train/extr_return_normed_mag 1.68 / train/extr_return_normed_max 1.68 / 
train/extr_return_normed_mean 0.34 / train/extr_return_normed_min -1.3e-3 / train/extr_return_normed_std 0.23 / train/extr_return_rate 0.51 / train/extr_return_raw_mag 3.39 / train/extr_return_raw_max 3.39 / train/extr_return_raw_mean 1.25 / train/extr_return_raw_min 0.61
/ train/extr_return_raw_std 0.41 / train/extr_reward_mag 0.55 / train/extr_reward_max 0.55 / train/extr_reward_mean 7.1e-3 / train/extr_reward_min 6.3e-8 / train/extr_reward_std 0.05 / train/image_loss_mean 2.16 / train/image_loss_std 1.73 / train/model_loss_mean 4.63 / 
train/model_loss_std 4.6 / train/model_opt_grad_norm 11.28 / train/model_opt_grad_steps 2.2e4 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6798.94 / train/policy_entropy_mag 5.53 / train/policy_entropy_max
5.53 / train/policy_entropy_mean 1.27 / train/policy_entropy_min -2.51 / train/policy_entropy_std 1.5 / train/policy_logprob_mag 13.88 / train/policy_logprob_max 4.09 / train/policy_logprob_mean -1.27 / train/policy_logprob_min -13.88 / train/policy_logprob_std 2.21 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 0.11 / train/policy_randomness_std 0.16 / train/post_ent_mag 38.47 / train/post_ent_max 38.47 / train/post_ent_mean 28.52 / 
train/post_ent_min 16.29 / train/post_ent_std 4.03 / train/prior_ent_mag 60.9 / train/prior_ent_max 60.9 / train/prior_ent_mean 32.72 / train/prior_ent_min 19.79 / train/prior_ent_std 5.61 / train/rep_loss_mean 4.12 / train/rep_loss_std 5.54 / train/reward_avg 7.8e-4 / 
train/reward_loss_mean 2.2e-3 / train/reward_loss_std 0.03 / train/reward_max_data 0.19 / train/reward_max_pred 0.18 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-4 / train/reward_pos_acc 0.92 / train/reward_pos_loss 1.09 / train/reward_pred 7.7e-4 / 
train/reward_rate 1.5e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.39 / report/cont_avg 1 / report/cont_loss_mean 3.9e-10 / report/cont_loss_std 3.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.9e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 5.21 / report/image_loss_mean 2.04 / report/image_loss_std 1.21 / report/model_loss_mean 4.31 / report/model_loss_std 3.95 / report/post_ent_mag 40.8 /
report/post_ent_max 40.8 / report/post_ent_mean 28.8 / report/post_ent_min 17.68 / report/post_ent_std 4.05 / report/prior_ent_mag 60.92 / report/prior_ent_max 60.92 / report/prior_ent_mean 32.51 / report/prior_ent_min 19.89 / report/prior_ent_std 5.53 / 
report/rep_loss_mean 3.78 / report/rep_loss_std 5.21 / report/reward_avg 0 / report/reward_loss_mean 1.3e-6 / report/reward_loss_std 2.9e-6 / report/reward_max_data 0 / report/reward_max_pred 2.4e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 5e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-10 / eval/cont_loss_std 5.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
4.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 8.23 / eval/dyn_loss_std 9.48 / eval/image_loss_mean 3.88 / eval/image_loss_std 4.94 / eval/model_loss_mean 8.86 / eval/model_loss_std 10.05 / eval/post_ent_mag 37.76 / eval/post_ent_max 37.76 / 
eval/post_ent_mean 28.3 / eval/post_ent_min 15.58 / eval/post_ent_std 4.13 / eval/prior_ent_mag 60.92 / eval/prior_ent_max 60.92 / eval/prior_ent_mean 32.35 / eval/prior_ent_min 22.31 / eval/prior_ent_std 6.38 / eval/rep_loss_mean 8.23 / eval/rep_loss_std 9.48 / 
eval/reward_avg 1.2e-3 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.51 / eval/reward_max_data 0.23 / eval/reward_max_pred 0.41 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 0.75 / eval/reward_pos_loss 3.53 / eval/reward_pred 1.4e-3 / 
eval/reward_rate 3.9e-3 / replay/size 4.7e4 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.7e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3792 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.01 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-4 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7800 / timer/agent.policy_total 17.65 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / 
timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1896 / timer/agent.train_total 241.07 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2
/ timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 47000 Counter(47000) 46937
eval_Episode has 500 steps and return 36.0.
train_Episode has 500 steps and return 30.2.
Saved chunk: 20230921T222826F780680-43FqJ7oGC8EuxoMMlpMBlO-2ICPqXeyvRtPqgrxdqwRTf-1024.npz
Starting evaluation at step 47500 Counter(47500) 47437
Saved chunk: 20230921T222859F771708-7Hs4Nmr1gBQrV2FkYsz4hU-7i8RCsmlAiv0WnkKVOxxhP-1024.npz
eval_Episode has 500 steps and return 25.3.
train_Episode has 500 steps and return 31.1.
Starting evaluation at step 48000 Counter(48000) 47937
eval_Episode has 500 steps and return 47.1.
train_Episode has 500 steps and return 42.5.
Saved chunk: 20230921T222947F810086-2ICPqXeyvRtPqgrxdqwRTf-6kL15LQbq2V9eVMBYCtwe2-1024.npz
Starting evaluation at step 48500 Counter(48500) 48437
Saved chunk: 20230921T223019F327532-7i8RCsmlAiv0WnkKVOxxhP-1pccCdZ8SGcfJQ8UIpGJwl-1024.npz
eval_Episode has 500 steps and return 63.2.
train_Episode has 500 steps and return 51.5.
Starting evaluation at step 49000 Counter(49000) 48937
eval_Episode has 500 steps and return 59.9.
train_Episode has 500 steps and return 63.0.
Saved chunk: 20230921T223108F377328-6kL15LQbq2V9eVMBYCtwe2-1N2nXNXmsqtYVTkd8xkHLc-1024.npz
Starting evaluation at step 49500 Counter(49500) 49437
eval_Episode has 500 steps and return 67.5.
Saved chunk: 20230921T223138F219929-1pccCdZ8SGcfJQ8UIpGJwl-7ij2MzENFi8JnAbbxc6ZbW-1024.npz
train_Episode has 500 steps and return 67.6.
Starting evaluation at step 50000 Counter(50000) 49937
eval_Episode has 500 steps and return 60.0.
train_Episode has 500 steps and return 62.4.
Saved chunk: 20230921T223228F612772-1N2nXNXmsqtYVTkd8xkHLc-45fEAt1sxxZQdiRF0hZ5DC-1024.npz
Starting evaluation at step 50500 Counter(50500) 50437
eval_Episode has 500 steps and return 68.6.
Saved chunk: 20230921T223256F782780-7ij2MzENFi8JnAbbxc6ZbW-1V9CTYCXtCAy8s92E7sthF-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 101130 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 68.57 / eval_episode/reward_rate 0.21 / episode/length 500 / episode/score 62.38 / episode/reward_rate 0.2 / train/action_mag 3.12 / train/action_max 3.09 / train/action_mean 0.09 / train/action_min -2.52 / train/action_std 
0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 2.4e4 / train/actor_opt_loss -1050.01 / train/adv_mag 1.03 / train/adv_max 1.02 / train/adv_mean 0.11 / train/adv_min 
-0.43 / train/adv_std 0.11 / train/cont_avg 1 / train/cont_loss_mean 5e-10 / train/cont_loss_std 9.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
4.22 / train/dyn_loss_std 5.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.58 / train/extr_critic_critic_opt_grad_steps 2.4e4 / 
train/extr_critic_critic_opt_loss 1.4e4 / train/extr_critic_mag 10.27 / train/extr_critic_max 10.27 / train/extr_critic_mean 8.67 / train/extr_critic_min 4.06 / train/extr_critic_std 1.09 / train/extr_return_normed_mag 1.58 / train/extr_return_normed_max 1.58 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.11 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 12.67 / train/extr_return_raw_max 12.67 / train/extr_return_raw_mean 9.08 / train/extr_return_raw_min 6.32 / 
train/extr_return_raw_std 1.25 / train/extr_reward_mag 0.96 / train/extr_reward_max 0.96 / train/extr_reward_mean 0.03 / train/extr_reward_min 4.3e-8 / train/extr_reward_std 0.13 / train/image_loss_mean 2.22 / train/image_loss_std 1.83 / train/model_loss_mean 4.76 / 
train/model_loss_std 4.75 / train/model_opt_grad_norm 11.37 / train/model_opt_grad_steps 2.4e4 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6947.37 / train/policy_entropy_mag 4.64 / 
train/policy_entropy_max 4.64 / train/policy_entropy_mean -2.59 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.23 / train/policy_logprob_mag 9.97 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.59 / train/policy_logprob_min -9.97 / 
train/policy_logprob_std 1.88 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.4e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 39.44 / train/post_ent_max 39.44 / 
train/post_ent_mean 29.18 / train/post_ent_min 16.79 / train/post_ent_std 4.21 / train/prior_ent_mag 61.85 / train/prior_ent_max 61.85 / train/prior_ent_mean 33.45 / train/prior_ent_min 20.36 / train/prior_ent_std 5.76 / train/rep_loss_mean 4.22 / train/rep_loss_std 5.64 
/ train/reward_avg 6e-3 / train/reward_loss_mean 9.5e-3 / train/reward_loss_std 0.08 / train/reward_max_data 0.6 / train/reward_max_pred 0.56 / train/reward_neg_acc 1 / train/reward_neg_loss 7.1e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.9 / 
train/reward_pred 5.8e-3 / train/reward_rate 0.01 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.78 / report/cont_avg 1 / report/cont_loss_mean 4.6e-10 / report/cont_loss_std 1.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.67 / report/dyn_loss_std 6.05 / report/image_loss_mean 2.61 / report/image_loss_std 2.15 / report/model_loss_mean 5.43 / report/model_loss_std 5.36 / 
report/post_ent_mag 39.76 / report/post_ent_max 39.76 / report/post_ent_mean 28.56 / report/post_ent_min 16.9 / report/post_ent_std 4.04 / report/prior_ent_mag 62.52 / report/prior_ent_max 62.52 / report/prior_ent_mean 33.32 / report/prior_ent_min 22.02 / 
report/prior_ent_std 6.23 / report/rep_loss_mean 4.67 / report/rep_loss_std 6.05 / report/reward_avg 9.8e-3 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.16 / report/reward_max_data 0.86 / report/reward_max_pred 0.87 / report/reward_neg_acc 1 / 
report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.87 / report/reward_pred 9.8e-3 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-10 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.46 / eval/dyn_loss_std 8.02 / eval/image_loss_mean 3.5 / eval/image_loss_std 4.03 / eval/model_loss_mean 7.99 / eval/model_loss_std 8.25 / eval/post_ent_mag 39.47
/ eval/post_ent_max 39.47 / eval/post_ent_mean 28.12 / eval/post_ent_min 19.49 / eval/post_ent_std 4.24 / eval/prior_ent_mag 62.52 / eval/prior_ent_max 62.52 / eval/prior_ent_mean 32.14 / eval/prior_ent_min 22.04 / eval/prior_ent_std 6.3 / eval/rep_loss_mean 7.46 / 
eval/rep_loss_std 8.02 / eval/reward_avg 3e-4 / eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.44 / eval/reward_max_data 0.21 / eval/reward_max_pred 3.8e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.9e-3 / eval/reward_pos_acc 0 / eval/reward_pos_loss 11.68 / 
eval/reward_pred 1.1e-6 / eval/reward_rate 9.8e-4 / replay/size 5.1e4 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.1e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3794 / timer/env.step_total 19.84 /
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.69 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
1.5e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 17.7 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1897 / 
timer/agent.train_total 241.1 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / 
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 64.7.
Starting evaluation at step 51000 Counter(51000) 50937
eval_Episode has 500 steps and return 73.6.
train_Episode has 500 steps and return 76.3.
Saved chunk: 20230921T223348F581771-45fEAt1sxxZQdiRF0hZ5DC-5Tt1Lky8XQiQ49kaufviiG-1024.npz
Starting evaluation at step 51500 Counter(51500) 51437
eval_Episode has 500 steps and return 68.4.
train_Episode has 500 steps and return 59.9.
Starting evaluation at step 52000 Counter(52000) 51937
Saved chunk: 20230921T223415F134670-1V9CTYCXtCAy8s92E7sthF-2B1qkYQOm4Cm3OYuYqEHnE-1024.npz
eval_Episode has 500 steps and return 81.8.
train_Episode has 500 steps and return 65.9.
Saved chunk: 20230921T223509F408936-5Tt1Lky8XQiQ49kaufviiG-1NE9kGM7TXOv8xhSQ8LYKS-1024.npz
Starting evaluation at step 52500 Counter(52500) 52437
eval_Episode has 500 steps and return 76.5.
train_Episode has 500 steps and return 67.4.
Starting evaluation at step 53000 Counter(53000) 52937
Saved chunk: 20230921T223610F349908-2B1qkYQOm4Cm3OYuYqEHnE-2ObXlriETIHVeTkF1ALpOr-1024.npz
eval_Episode has 500 steps and return 61.0.
train_Episode has 500 steps and return 71.7.
Saved chunk: 20230921T223629F703230-1NE9kGM7TXOv8xhSQ8LYKS-2sa8sZavA3qHJc0aoiT3hk-1024.npz
Starting evaluation at step 53500 Counter(53500) 53437
eval_Episode has 500 steps and return 67.1.
train_Episode has 500 steps and return 72.6.
Starting evaluation at step 54000 Counter(54000) 53937
Saved chunk: 20230921T223728F947158-2ObXlriETIHVeTkF1ALpOr-2TlDCB2pUIsXsFSaWBssrS-1024.npz
eval_Episode has 500 steps and return 77.9.
train_Episode has 500 steps and return 74.8.
Saved chunk: 20230921T223749F777881-2sa8sZavA3qHJc0aoiT3hk-08VSBQqD3vl7npchoql9pW-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 108830 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 74.78 / episode/reward_rate 0.24 / eval_episode/length 500 / eval_episode/score 77.86 / eval_episode/reward_rate 0.24 / train/action_mag 2.7 / train/action_max 2.66 / train/action_mean 0.12 / train/action_min -2.21 / train/action_std 
0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.6e4 / train/actor_opt_loss -927.01 / train/adv_mag 1.89 / train/adv_max 1.89 / train/adv_mean 0.1 / train/adv_min 
-0.54 / train/adv_std 0.11 / train/cont_avg 1 / train/cont_loss_mean 4.3e-10 / train/cont_loss_std 9.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.34 / train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.3 / train/extr_critic_critic_opt_grad_steps 2.6e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 21.68 / train/extr_critic_max 21.68 / train/extr_critic_mean 19.48 / train/extr_critic_min 9.2 / train/extr_critic_std 1.52 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.45 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 24.05 / train/extr_return_raw_max 24.05 / train/extr_return_raw_mean 19.95 / train/extr_return_raw_min 15.63 
/ train/extr_return_raw_std 1.61 / train/extr_reward_mag 1.01 / train/extr_reward_max 1.01 / train/extr_reward_mean 0.04 / train/extr_reward_min -1.6e-7 / train/extr_reward_std 0.15 / train/image_loss_mean 2.24 / train/image_loss_std 1.75 / train/model_loss_mean 4.87 / 
train/model_loss_std 4.78 / train/model_opt_grad_norm 11.13 / train/model_opt_grad_steps 2.6e4 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5572.92 / train/policy_entropy_mag 3.75 / 
train/policy_entropy_max 3.51 / train/policy_entropy_mean -2.81 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 9.08 / train/policy_logprob_max 5.43 / train/policy_logprob_mean 2.81 / train/policy_logprob_min -9.08 / 
train/policy_logprob_std 1.66 / train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 1e-3 / train/policy_randomness_std 0.09 / train/post_ent_mag 40.33 / train/post_ent_max 40.33 / 
train/post_ent_mean 29.77 / train/post_ent_min 16.79 / train/post_ent_std 4.32 / train/prior_ent_mag 62.75 / train/prior_ent_max 62.75 / train/prior_ent_mean 34.18 / train/prior_ent_min 20.62 / train/prior_ent_std 5.81 / train/rep_loss_mean 4.34 / train/rep_loss_std 5.77 
/ train/reward_avg 0.02 / train/reward_loss_mean 0.02 / train/reward_loss_std 0.14 / train/reward_max_data 0.85 / train/reward_max_pred 0.78 / train/reward_neg_acc 1 / train/reward_neg_loss 1.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.82 / 
train/reward_pred 0.02 / train/reward_rate 0.03 / train_stats/mean_log_entropy -2.96 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.5e-10 / report/cont_loss_std 1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 
1 / report/cont_pos_loss 4.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.63 / report/dyn_loss_std 5.61 / report/image_loss_mean 2.53 / report/image_loss_std 1.56 / report/model_loss_mean 5.36 / report/model_loss_std 4.58 / report/post_ent_mag 
40.29 / report/post_ent_max 40.29 / report/post_ent_mean 30.17 / report/post_ent_min 16.33 / report/post_ent_std 3.87 / report/prior_ent_mag 62.79 / report/prior_ent_max 62.79 / report/prior_ent_mean 34.99 / report/prior_ent_min 24.79 / report/prior_ent_std 5.14 / 
report/rep_loss_mean 4.63 / report/rep_loss_std 5.61 / report/reward_avg 0.03 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.26 / report/reward_max_data 1.12 / report/reward_max_pred 1.01 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 1.04 / report/reward_pred 0.03 / report/reward_rate 0.04 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-10 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.2 / eval/dyn_loss_std 8.52 / eval/image_loss_mean 3.49 / eval/image_loss_std 3.92 / eval/model_loss_mean 7.82 / eval/model_loss_std 8.45 / eval/post_ent_mag 40.11 / eval/post_ent_max 
40.11 / eval/post_ent_mean 27.7 / eval/post_ent_min 17.68 / eval/post_ent_std 4.53 / eval/prior_ent_mag 62.79 / eval/prior_ent_max 62.79 / eval/prior_ent_mean 32.3 / eval/prior_ent_min 23.09 / eval/prior_ent_std 6.34 / eval/rep_loss_mean 7.2 / eval/rep_loss_std 8.52 / 
eval/reward_avg 4.2e-4 / eval/reward_loss_mean 7.2e-3 / eval/reward_loss_std 0.15 / eval/reward_max_data 0.43 / eval/reward_max_pred 0.33 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 1.36 / eval/reward_pred 8.5e-4 / 
eval/reward_rate 9.8e-4 / replay/size 5.4e4 / replay/inserts 3850 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.5e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3850 / timer/env.step_total 20.19 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.14 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7357 / timer/agent.policy_total 16.7 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 9.5e-3 / timer/dataset_train_count 1925 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1925 / 
timer/agent.train_total 244.17 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.66

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 54500 Counter(54500) 54437
eval_Episode has 500 steps and return 80.6.
train_Episode has 500 steps and return 85.7.
Starting evaluation at step 55000 Counter(55000) 54937
Saved chunk: 20230921T223847F226537-2TlDCB2pUIsXsFSaWBssrS-4iXjYDyY3Qlsrxtp2ZNFJt-1024.npz
eval_Episode has 500 steps and return 84.4.
train_Episode has 500 steps and return 82.7.
Saved chunk: 20230921T223909F595717-08VSBQqD3vl7npchoql9pW-7f9c2rPWLBxYfV35wTnDxH-1024.npz
Starting evaluation at step 55500 Counter(55500) 55437
eval_Episode has 500 steps and return 83.5.
train_Episode has 500 steps and return 73.0.
Starting evaluation at step 56000 Counter(56000) 55937
Saved chunk: 20230921T224006F561795-4iXjYDyY3Qlsrxtp2ZNFJt-4e5o8KORNMbCAJUa0yn4U6-1024.npz
eval_Episode has 500 steps and return 75.2.
train_Episode has 500 steps and return 79.3.
Saved chunk: 20230921T224030F685638-7f9c2rPWLBxYfV35wTnDxH-1VfFG1arTQ3kax0fT7VZ96-1024.npz
Starting evaluation at step 56500 Counter(56500) 56437
eval_Episode has 500 steps and return 96.7.
train_Episode has 500 steps and return 80.4.
Starting evaluation at step 57000 Counter(57000) 56937
Saved chunk: 20230921T224125F359247-4e5o8KORNMbCAJUa0yn4U6-6GHYNj9st7vA6hnCUZ56yi-1024.npz
eval_Episode has 500 steps and return 91.3.
train_Episode has 500 steps and return 91.4.
Saved chunk: 20230921T224150F969962-1VfFG1arTQ3kax0fT7VZ96-39p3JTIQkYzSk94ZBB9Dqu-1024.npz
Starting evaluation at step 57500 Counter(57500) 57437
eval_Episode has 500 steps and return 82.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T224310F854069-39p3JTIQkYzSk94ZBB9Dqu-0000000000000000000000-257.npz
Saved chunk: 20230921T224243F816491-6GHYNj9st7vA6hnCUZ56yi-0000000000000000000000-870.npz
train_Episode has 500 steps and return 84.8.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 58000 Counter(58000) 57937
Saved chunk: 20230921T224243F816491-6GHYNj9st7vA6hnCUZ56yi-4ojnpOmuwMhM2DljuFtCz2-1024.npz
eval_Episode has 500 steps and return 105.7.
train_Episode has 500 steps and return 97.2.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 116422 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 105.7 / eval_episode/reward_rate 0.34 / episode/length 500 / episode/score 97.19 / episode/reward_rate 0.29 / train/action_mag 2.54 / train/action_max 2.51 / train/action_mean 0.12 / train/action_min -2.1 / train/action_std 
0.84 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.8e4 / train/actor_opt_loss -755.35 / train/adv_mag 2.76 / train/adv_max 2.76 / train/adv_mean 0.08 / train/adv_min 
-0.58 / train/adv_std 0.12 / train/cont_avg 1 / train/cont_loss_mean 3.3e-10 / train/cont_loss_std 9.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.32 / train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 2.8e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 32.65 / train/extr_critic_max 32.65 / train/extr_critic_mean 30.04 / train/extr_critic_min 15.14 / train/extr_critic_std 1.75 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.37 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 34.65 / train/extr_return_raw_max 34.65 / train/extr_return_raw_mean 30.47 / train/extr_return_raw_min 24.98 
/ train/extr_return_raw_std 1.81 / train/extr_reward_mag 1.09 / train/extr_reward_max 1.09 / train/extr_reward_mean 0.05 / train/extr_reward_min -1.1e-8 / train/extr_reward_std 0.16 / train/image_loss_mean 2.15 / train/image_loss_std 1.62 / train/model_loss_mean 4.77 / 
train/model_loss_std 4.73 / train/model_opt_grad_norm 11.06 / train/model_opt_grad_steps 2.8e4 / train/model_opt_loss 4.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9210.53 / train/policy_entropy_mag 3.61 / 
train/policy_entropy_max 2.9 / train/policy_entropy_mean -2.86 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.56 / train/policy_logprob_max 5.43 / train/policy_logprob_mean 2.86 / train/policy_logprob_min -8.56 / 
train/policy_logprob_std 1.59 / train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 9.7e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 41.04 / train/post_ent_max 41.04 / 
train/post_ent_mean 30.38 / train/post_ent_min 17.21 / train/post_ent_std 4.45 / train/prior_ent_mag 63.64 / train/prior_ent_max 63.64 / train/prior_ent_mean 34.77 / train/prior_ent_min 21.14 / train/prior_ent_std 5.87 / train/rep_loss_mean 4.32 / train/rep_loss_std 5.84 
/ train/reward_avg 0.02 / train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 0.96 / train/reward_max_pred 0.91 / train/reward_neg_acc 1 / train/reward_neg_loss 2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.76 / train/reward_pred 
0.02 / train/reward_rate 0.04 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.84 / report/cont_avg 1 / report/cont_loss_mean 2.3e-10 / report/cont_loss_std 4.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.87 / report/dyn_loss_std 5.41 / report/image_loss_mean 1.99 / report/image_loss_std 1.58 / report/model_loss_mean 4.35 / report/model_loss_std 4.45 / report/post_ent_mag 40.04 
/ report/post_ent_max 40.04 / report/post_ent_mean 29.79 / report/post_ent_min 15.12 / report/post_ent_std 4.46 / report/prior_ent_mag 64.12 / report/prior_ent_max 64.12 / report/prior_ent_mean 33.61 / report/prior_ent_min 17.93 / report/prior_ent_std 6.08 / 
report/rep_loss_mean 3.87 / report/rep_loss_std 5.41 / report/reward_avg 0.02 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.16 / report/reward_max_data 0.95 / report/reward_max_pred 0.93 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.71 / report/reward_pred 0.02 / report/reward_rate 0.04 / eval/cont_avg 1 / eval/cont_loss_mean 2e-10 / eval/cont_loss_std 9.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.5 / eval/dyn_loss_std 8.58 / eval/image_loss_mean 3 / eval/image_loss_std 3.55 / eval/model_loss_mean 7.51 / eval/model_loss_std 8.13 / eval/post_ent_mag 39.66 / eval/post_ent_max 39.66 / 
eval/post_ent_mean 29.21 / eval/post_ent_min 18.6 / eval/post_ent_std 4.09 / eval/prior_ent_mag 64.12 / eval/prior_ent_max 64.12 / eval/prior_ent_mean 33.84 / eval/prior_ent_min 23.19 / eval/prior_ent_std 6.13 / eval/rep_loss_mean 7.5 / eval/rep_loss_std 8.58 / 
eval/reward_avg 1.5e-3 / eval/reward_loss_mean 0.01 / eval/reward_loss_std 0.18 / eval/reward_max_data 0.54 / eval/reward_max_pred 0.31 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 2.13 / eval/reward_pred 1.1e-3 / 
eval/reward_rate 2.9e-3 / replay/size 5.8e4 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.9e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3796 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.98 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.8e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7804 / timer/agent.policy_total 17.76 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1898 / timer/agent.train_total 241.05 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / 
timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T224310F854069-39p3JTIQkYzSk94ZBB9Dqu-4lJ2cz3VcjxZCGLLjN5GZR-1024.npz
Starting evaluation at step 58500 Counter(58500) 58437
eval_Episode has 500 steps and return 105.6.
train_Episode has 500 steps and return 88.9.
Starting evaluation at step 59000 Counter(59000) 58937
Saved chunk: 20230921T224402F385822-4ojnpOmuwMhM2DljuFtCz2-1zt2V2m3PNKizdPyjsyZ7J-1024.npz
eval_Episode has 500 steps and return 85.1.
train_Episode has 500 steps and return 112.4.
Saved chunk: 20230921T224431F699759-4lJ2cz3VcjxZCGLLjN5GZR-5tVFkWsSGwkjxwqZrEvbeC-1024.npz
Starting evaluation at step 59500 Counter(59500) 59437
eval_Episode has 500 steps and return 84.5.
train_Episode has 500 steps and return 96.6.
Starting evaluation at step 60000 Counter(60000) 59937
Saved chunk: 20230921T224521F903942-1zt2V2m3PNKizdPyjsyZ7J-4U7jbxEvexydncoXyUv0Ns-1024.npz
eval_Episode has 500 steps and return 99.3.
train_Episode has 500 steps and return 94.7.
Saved chunk: 20230921T224552F913212-5tVFkWsSGwkjxwqZrEvbeC-681tqLUMBUmiFiDO89Bo6w-1024.npz
Starting evaluation at step 60500 Counter(60500) 60437
eval_Episode has 500 steps and return 110.9.
train_Episode has 500 steps and return 104.6.
Starting evaluation at step 61000 Counter(61000) 60937
Saved chunk: 20230921T224641F377626-4U7jbxEvexydncoXyUv0Ns-0ISgqpMmpE1YCmxdfBiywW-1024.npz
eval_Episode has 500 steps and return 102.2.
train_Episode has 500 steps and return 88.4.
Saved chunk: 20230921T224713F165967-681tqLUMBUmiFiDO89Bo6w-7BXo0J0rp16DNDM3Srmbev-1024.npz
Starting evaluation at step 61500 Counter(61500) 61437
eval_Episode has 500 steps and return 101.2.
train_Episode has 500 steps and return 101.6.
Starting evaluation at step 62000 Counter(62000) 61937
Saved chunk: 20230921T224759F896873-0ISgqpMmpE1YCmxdfBiywW-6QY6ZHBPRpOWIy0rLR4joL-1024.npz
eval_Episode has 500 steps and return 112.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 124002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 112.05 / eval_episode/reward_rate 0.31 / episode/length 500 / episode/score 101.57 / episode/reward_rate 0.31 / train/action_mag 2.34 / train/action_max 2.29 / train/action_mean 0.08 / train/action_min -1.98 / train/action_std 
0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 3e4 / train/actor_opt_loss -640.97 / train/adv_mag 3 / train/adv_max 3 / train/adv_mean 0.07 / train/adv_min -0.43 / 
train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 2.6e-10 / train/cont_loss_std 7.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.35 / 
train/dyn_loss_std 5.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.17 / train/extr_critic_critic_opt_grad_steps 3e4 / train/extr_critic_critic_opt_loss 1e4 /
train/extr_critic_mag 43.12 / train/extr_critic_max 43.12 / train/extr_critic_mean 40.01 / train/extr_critic_min 22.65 / train/extr_critic_std 1.95 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.34 / train/extr_return_normed_mean 0.62 / 
train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 44.96 / train/extr_return_raw_max 44.96 / train/extr_return_raw_mean 40.43 / train/extr_return_raw_min 35.26 / train/extr_return_raw_std 2.09 / 
train/extr_reward_mag 1.14 / train/extr_reward_max 1.14 / train/extr_reward_mean 0.06 / train/extr_reward_min -1.9e-9 / train/extr_reward_std 0.19 / train/image_loss_mean 2.1 / train/image_loss_std 1.55 / train/model_loss_mean 4.75 / train/model_loss_std 4.72 / 
train/model_opt_grad_norm 10.78 / train/model_opt_grad_steps 2.9e4 / train/model_opt_loss 4.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 2.38 / 
train/policy_entropy_mean -2.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.93 / train/policy_logprob_min -8.13 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.64 / train/policy_randomness_max 0.64 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 1e-3 / train/policy_randomness_std 0.06 / train/post_ent_mag 41.78 / train/post_ent_max 41.78 / train/post_ent_mean 30.97 / 
train/post_ent_min 17.35 / train/post_ent_std 4.51 / train/prior_ent_mag 64.63 / train/prior_ent_max 64.63 / train/prior_ent_mean 35.39 / train/prior_ent_min 21.64 / train/prior_ent_std 5.89 / train/rep_loss_mean 4.35 / train/rep_loss_std 5.91 / train/reward_avg 0.04 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.19 / train/reward_max_data 1.07 / train/reward_max_pred 1.03 / train/reward_neg_acc 1 / train/reward_neg_loss 2.2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.72 / train/reward_pred 0.04 / train/reward_rate
0.06 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.9 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 4.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.44 / report/dyn_loss_std 6.32 / report/image_loss_mean 2.11 / report/image_loss_std 1.44 / report/model_loss_mean 4.82 / report/model_loss_std 4.85 / report/post_ent_mag 42.45 / report/post_ent_max 42.45 / 
report/post_ent_mean 31.24 / report/post_ent_min 16.96 / report/post_ent_std 4.64 / report/prior_ent_mag 65.2 / report/prior_ent_max 65.2 / report/prior_ent_mean 35.86 / report/prior_ent_min 22.33 / report/prior_ent_std 5.94 / report/rep_loss_mean 4.44 / 
report/rep_loss_std 6.32 / report/reward_avg 0.04 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.21 / report/reward_max_data 1.14 / report/reward_max_pred 1.16 / report/reward_neg_acc 1 / report/reward_neg_loss 4.1e-4 / report/reward_pos_acc 0.98 / 
report/reward_pos_loss 0.76 / report/reward_pred 0.04 / report/reward_rate 0.06 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.02 / eval/dyn_loss_std 6.73 / eval/image_loss_mean 2.2 / eval/image_loss_std 2.58 / eval/model_loss_mean 5.21 / eval/model_loss_std 6.19 / eval/post_ent_mag 41.7 / eval/post_ent_max 41.7 / eval/post_ent_mean 29.77
/ eval/post_ent_min 19.29 / eval/post_ent_std 4.53 / eval/prior_ent_mag 65.2 / eval/prior_ent_max 65.2 / eval/prior_ent_mean 32.22 / eval/prior_ent_min 22.88 / eval/prior_ent_std 5.83 / eval/rep_loss_mean 5.02 / eval/rep_loss_std 6.73 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.8e-6 / eval/reward_loss_std 1.3e-5 / eval/reward_max_data 0 / eval/reward_max_pred 5e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 3.8e-7 / eval/reward_rate 0 / 
replay/size 6.2e4 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.3e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.39 / timer/env.step_count 3790 / timer/env.step_total 19.77 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.66 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 17.6 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / 
timer/dataset_train_count 1895 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1895 / timer/agent.train_total 241.62 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.78 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 100.5.
Saved chunk: 20230921T224833F250179-7BXo0J0rp16DNDM3Srmbev-6cWjcT1Jaih7Hn5lMWpilr-1024.npz
Starting evaluation at step 62500 Counter(62500) 62437
eval_Episode has 500 steps and return 102.2.
train_Episode has 500 steps and return 107.3.
Starting evaluation at step 63000 Counter(63000) 62937
Saved chunk: 20230921T224918F328076-6QY6ZHBPRpOWIy0rLR4joL-2x9KP1pCx4L1JvXVf09iW0-1024.npz
eval_Episode has 500 steps and return 119.6.
train_Episode has 500 steps and return 99.8.
Saved chunk: 20230921T224954F041107-6cWjcT1Jaih7Hn5lMWpilr-0YbmvXC3W4XDbcC2a7VS8R-1024.npz
Starting evaluation at step 63500 Counter(63500) 63437
eval_Episode has 500 steps and return 114.4.
train_Episode has 500 steps and return 114.1.
Starting evaluation at step 64000 Counter(64000) 63937
Saved chunk: 20230921T225037F873198-2x9KP1pCx4L1JvXVf09iW0-11fAkR9xNoULX4eyhKZsss-1024.npz
eval_Episode has 500 steps and return 132.8.
train_Episode has 500 steps and return 123.9.
Starting evaluation at step 64500 Counter(64500) 64437
eval_Episode has 500 steps and return 114.1.
Saved chunk: 20230921T225114F470713-0YbmvXC3W4XDbcC2a7VS8R-7gwF8pkzwfyT8gjhqU1eZ8-1024.npz
train_Episode has 500 steps and return 108.9.
Starting evaluation at step 65000 Counter(65000) 64937
Saved chunk: 20230921T225156F529107-11fAkR9xNoULX4eyhKZsss-2OmyiLBhIIFAA0As4eDKZU-1024.npz
eval_Episode has 500 steps and return 84.9.
train_Episode has 500 steps and return 96.5.
Starting evaluation at step 65500 Counter(65500) 65437
eval_Episode has 500 steps and return 126.0.
Saved chunk: 20230921T225238F030852-7gwF8pkzwfyT8gjhqU1eZ8-3bAmNHYwc1vcmUgBZ2JCLV-1024.npz
train_Episode has 500 steps and return 121.2.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 131698 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 121.16 / episode/reward_rate 0.32 / eval_episode/length 500 / eval_episode/score 125.95 / eval_episode/reward_rate 0.33 / train/action_mag 2.49 / train/action_max 2.3 / train/action_mean 0.09 / train/action_min -2.35 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 3.1e4 / train/actor_opt_loss -570.47 / train/adv_mag 3.6 / train/adv_max 3.6 / train/adv_mean 0.06 / train/adv_min 
-0.44 / train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 2.2e-10 / train/cont_loss_std 7.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.32 / train/dyn_loss_std 5.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 3.1e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 53.69 / train/extr_critic_max 53.69 / train/extr_critic_mean 50.42 / train/extr_critic_min 26.4 / train/extr_critic_std 2.26 / train/extr_return_normed_mag 1.29 / train/extr_return_normed_max 1.29 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 55.57 / train/extr_return_raw_max 55.57 / train/extr_return_raw_mean 50.85 / train/extr_return_raw_min 44.58 
/ train/extr_return_raw_std 2.34 / train/extr_reward_mag 1.26 / train/extr_reward_max 1.26 / train/extr_reward_mean 0.08 / train/extr_reward_min 0 / train/extr_reward_std 0.22 / train/image_loss_mean 2.01 / train/image_loss_std 1.47 / train/model_loss_mean 4.66 / 
train/model_loss_std 4.69 / train/model_opt_grad_norm 10.62 / train/model_opt_grad_steps 3.1e4 / train/model_opt_loss 4.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
2.08 / train/policy_entropy_mean -2.99 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 8.09 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.98 / train/policy_logprob_min -8.09 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.61 / train/policy_randomness_max 0.61 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 9e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 42.58 / train/post_ent_max 42.58 / train/post_ent_mean 31.6 / 
train/post_ent_min 17.59 / train/post_ent_std 4.66 / train/prior_ent_mag 65.42 / train/prior_ent_max 65.42 / train/prior_ent_mean 35.97 / train/prior_ent_min 22.02 / train/prior_ent_std 5.93 / train/rep_loss_mean 4.32 / train/rep_loss_std 5.95 / train/reward_avg 0.05 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.21 / train/reward_max_data 1.16 / train/reward_max_pred 1.1 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.73 / train/reward_pred 0.05 / train/reward_rate 
0.07 / train_stats/mean_log_entropy -2.95 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 5.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 5.91 / report/image_loss_mean 1.63 / report/image_loss_std 1.17 / report/model_loss_mean 3.99 / report/model_loss_std 4.4 / report/post_ent_mag 43.24 / report/post_ent_max 43.24 / 
report/post_ent_mean 32.4 / report/post_ent_min 15.23 / report/post_ent_std 4.23 / report/prior_ent_mag 65.63 / report/prior_ent_max 65.63 / report/prior_ent_mean 36.5 / report/prior_ent_min 23.24 / report/prior_ent_std 5.36 / report/rep_loss_mean 3.85 / 
report/rep_loss_std 5.91 / report/reward_avg 0.04 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.17 / report/reward_max_data 1.22 / report/reward_max_pred 1.19 / report/reward_neg_acc 1 / report/reward_neg_loss 9.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.64 / report/reward_pred 0.04 / report/reward_rate 0.07 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.07 / eval/dyn_loss_std 7.73 / eval/image_loss_mean 1.98 / eval/image_loss_std 3.12 / eval/model_loss_mean 5.07 / eval/model_loss_std 7.43 / eval/post_ent_mag 42.74 / eval/post_ent_max 42.74 / eval/post_ent_mean 
31.36 / eval/post_ent_min 17.47 / eval/post_ent_std 5.03 / eval/prior_ent_mag 65.63 / eval/prior_ent_max 65.63 / eval/prior_ent_mean 35.18 / eval/prior_ent_min 23.16 / eval/prior_ent_std 6.26 / eval/rep_loss_mean 5.07 / eval/rep_loss_std 7.73 / eval/reward_avg 2.2e-3 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.85 / eval/reward_max_data 1.12 / eval/reward_max_pred 0.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.6e-6 / eval/reward_pos_acc 0 / eval/reward_pos_loss 19.17 / eval/reward_pred 1.3e-5 / eval/reward_rate 2e-3 / 
replay/size 6.6e4 / replay/inserts 3848 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.6e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3848 / timer/env.step_total 20.12 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 450.12 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7355 / timer/agent.policy_total 16.68 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1924 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1924 / timer/agent.train_total 244.39 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.64

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 66000 Counter(66000) 65937
Saved chunk: 20230921T225314F974292-2OmyiLBhIIFAA0As4eDKZU-4UZBiMK0EyEblLTy4msyXT-1024.npz
eval_Episode has 500 steps and return 120.8.
train_Episode has 500 steps and return 108.3.
Starting evaluation at step 66500 Counter(66500) 66437
eval_Episode has 500 steps and return 131.4.
Saved chunk: 20230921T225358F067124-3bAmNHYwc1vcmUgBZ2JCLV-3EUMZwWIJzYp2bKCt8zVpk-1024.npz
train_Episode has 500 steps and return 116.4.
Starting evaluation at step 67000 Counter(67000) 66937
Saved chunk: 20230921T225434F134785-4UZBiMK0EyEblLTy4msyXT-2yY3gxKsCljQi9jdo6xaDd-1024.npz
eval_Episode has 500 steps and return 125.1.
train_Episode has 500 steps and return 126.8.
Starting evaluation at step 67500 Counter(67500) 67437
eval_Episode has 500 steps and return 133.8.
Saved chunk: 20230921T225519F159599-3EUMZwWIJzYp2bKCt8zVpk-27k9HyzhcrmBkK6TSCoy2K-1024.npz
train_Episode has 500 steps and return 124.0.
Starting evaluation at step 68000 Counter(68000) 67937
Saved chunk: 20230921T225553F222629-2yY3gxKsCljQi9jdo6xaDd-2gjPwkDY3bwGlNhuMPz1r8-1024.npz
eval_Episode has 500 steps and return 140.0.
train_Episode has 500 steps and return 117.8.
Starting evaluation at step 68500 Counter(68500) 68437
eval_Episode has 500 steps and return 129.6.
Saved chunk: 20230921T225639F601241-27k9HyzhcrmBkK6TSCoy2K-1TpV9wYIPh7q2jPAtFvvYY-1024.npz
train_Episode has 500 steps and return 121.2.
Starting evaluation at step 69000 Counter(69000) 68937
Saved chunk: 20230921T225711F901918-2gjPwkDY3bwGlNhuMPz1r8-6pi81BEJ3NVUaxcCGmQoOc-1024.npz
eval_Episode has 500 steps and return 136.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T225830F455855-6pi81BEJ3NVUaxcCGmQoOc-0000000000000000000000-105.npz
Saved chunk: 20230921T225759F690122-1TpV9wYIPh7q2jPAtFvvYY-0000000000000000000000-492.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 121.8.
Starting evaluation at step 69500 Counter(69500) 69437
eval_Episode has 500 steps and return 141.8.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 139276 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 141.82 / eval_episode/reward_rate 0.36 / episode/length 500 / episode/score 121.78 / episode/reward_rate 0.34 / train/action_mag 3.19 / train/action_max 2.9 / train/action_mean 0.1 / train/action_min -2.93 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 3.3e4 / train/actor_opt_loss -412.19 / train/adv_mag 2.8 / train/adv_max 2.8 / train/adv_mean 0.04 / train/adv_min 
-0.59 / train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 1.9e-10 / train/cont_loss_std 6.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.26 / train/dyn_loss_std 5.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 3.3e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 63.69 / train/extr_critic_max 63.69 / train/extr_critic_mean 59.8 / train/extr_critic_min 38.12 / train/extr_critic_std 2.7 / train/extr_return_normed_mag 1.23 / train/extr_return_normed_max 1.23 / 
train/extr_return_normed_mean 0.65 / train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 65.2 / train/extr_return_raw_max 65.2 / train/extr_return_raw_mean 60.17 / train/extr_return_raw_min 50.02 / 
train/extr_return_raw_std 2.8 / train/extr_reward_mag 1.29 / train/extr_reward_max 1.29 / train/extr_reward_mean 0.09 / train/extr_reward_min -6.3e-10 / train/extr_reward_std 0.23 / train/image_loss_mean 1.93 / train/image_loss_std 1.39 / train/model_loss_mean 4.55 / 
train/model_loss_std 4.62 / train/model_opt_grad_norm 10.44 / train/model_opt_grad_steps 3.3e4 / train/model_opt_loss 4.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
2.28 / train/policy_entropy_mean -2.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.32 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.94 / train/policy_logprob_min -8.32 / train/policy_logprob_std 1.56 / 
train/policy_randomness_mag 0.63 / train/policy_randomness_max 0.63 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 9.5e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 43.32 / train/post_ent_max 43.32 / train/post_ent_mean 32.09 / 
train/post_ent_min 17.8 / train/post_ent_std 4.65 / train/prior_ent_mag 66.03 / train/prior_ent_max 66.03 / train/prior_ent_mean 36.41 / train/prior_ent_min 22.13 / train/prior_ent_std 5.91 / train/rep_loss_mean 4.26 / train/rep_loss_std 5.95 / train/reward_avg 0.06 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.22 / train/reward_max_data 1.2 / train/reward_max_pred 1.15 / train/reward_neg_acc 1 / train/reward_neg_loss 2.6e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.69 / train/reward_pred 0.06 / train/reward_rate 
0.08 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.93 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.91 / report/dyn_loss_std 5.73 / report/image_loss_mean 1.72 / report/image_loss_std 1.12 / report/model_loss_mean 4.1 / report/model_loss_std 4.29 / report/post_ent_mag 43.78 / report/post_ent_max 43.78 / 
report/post_ent_mean 32.92 / report/post_ent_min 16.39 / report/post_ent_std 4.59 / report/prior_ent_mag 66.3 / report/prior_ent_max 66.3 / report/prior_ent_mean 36.91 / report/prior_ent_min 21.67 / report/prior_ent_std 5.67 / report/rep_loss_mean 3.91 / 
report/rep_loss_std 5.73 / report/reward_avg 0.03 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.19 / report/reward_max_data 1.29 / report/reward_max_pred 1.27 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.72 / report/reward_pred 0.03 / report/reward_rate 0.05 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.42 / eval/dyn_loss_std 7.28 / eval/image_loss_mean 1.58 / eval/image_loss_std 2.36 / eval/model_loss_mean 4.23 / eval/model_loss_std 6.3 / eval/post_ent_mag 42.71 / eval/post_ent_max 42.71 / eval/post_ent_mean 
30.15 / eval/post_ent_min 18.61 / eval/post_ent_std 5.39 / eval/prior_ent_mag 66.3 / eval/prior_ent_max 66.3 / eval/prior_ent_mean 33.77 / eval/prior_ent_min 22.43 / eval/prior_ent_std 6.76 / eval/rep_loss_mean 4.42 / eval/rep_loss_std 7.28 / eval/reward_avg 0 / 
eval/reward_loss_mean 6.5e-8 / eval/reward_loss_std 1e-6 / eval/reward_max_data 0 / eval/reward_max_pred 4.9e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.5e-8 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.6e-8 / eval/reward_rate 0 / 
replay/size 7e4 / replay/inserts 3789 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3789 / timer/env.step_total 19.84 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3e4 / timer/replay._sample_total 440.78 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7797 / timer/agent.policy_total 17.63 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1894 / timer/agent.train_total 241.1 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.26

Saved chunk: 20230921T225759F690122-1TpV9wYIPh7q2jPAtFvvYY-3zaUD4DjQJQ8wrZQIadWbL-1024.npz
train_Episode has 500 steps and return 129.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 70000 Counter(70000) 69937
Saved chunk: 20230921T225830F455855-6pi81BEJ3NVUaxcCGmQoOc-14h8QiGkXhdjTkgXx2TMNU-1024.npz
eval_Episode has 500 steps and return 129.1.
train_Episode has 500 steps and return 118.2.
Starting evaluation at step 70500 Counter(70500) 70437
eval_Episode has 500 steps and return 131.4.
train_Episode has 500 steps and return 112.3.
Saved chunk: 20230921T225920F018572-3zaUD4DjQJQ8wrZQIadWbL-3hyvLsw4lGlaUBW5cMeVYK-1024.npz
Starting evaluation at step 71000 Counter(71000) 70937
Saved chunk: 20230921T225949F922031-14h8QiGkXhdjTkgXx2TMNU-0pZLPhq6LKVLWupPDHzqrb-1024.npz
eval_Episode has 500 steps and return 130.7.
train_Episode has 500 steps and return 130.0.
Starting evaluation at step 71500 Counter(71500) 71437
eval_Episode has 500 steps and return 141.5.
train_Episode has 500 steps and return 140.6.
Saved chunk: 20230921T230041F106301-3hyvLsw4lGlaUBW5cMeVYK-2mZQVpQec2LcAmpov3dZs2-1024.npz
Starting evaluation at step 72000 Counter(72000) 71937
Saved chunk: 20230921T230108F817317-0pZLPhq6LKVLWupPDHzqrb-0RiYd1vsszxgYv0WHUJWbj-1024.npz
eval_Episode has 500 steps and return 152.7.
train_Episode has 500 steps and return 145.3.
Starting evaluation at step 72500 Counter(72500) 72437
eval_Episode has 500 steps and return 149.8.
train_Episode has 500 steps and return 133.1.
Saved chunk: 20230921T230201F259148-2mZQVpQec2LcAmpov3dZs2-0nsw49F8qxTc0OMQPvF5Nv-1024.npz
Starting evaluation at step 73000 Counter(73000) 72937
eval_Episode has 500 steps and return 154.5.
Saved chunk: 20230921T230227F239938-0RiYd1vsszxgYv0WHUJWbj-3WQL2kFkiOXEcc9aCYR8BP-1024.npz
train_Episode has 500 steps and return 137.3.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 146978 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 137.26 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 154.51 / eval_episode/reward_rate 0.39 / train/action_mag 2.78 / train/action_max 2.76 / train/action_mean 0.11 / train/action_min -2.09 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 3.5e4 / train/actor_opt_loss -355.85 / train/adv_mag 2.41 / train/adv_max 2.4 / train/adv_mean 0.04 / train/adv_min 
-0.51 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.7e-10 / train/cont_loss_std 6.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.22 / train/dyn_loss_std 6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 3.5e4 / train/extr_critic_critic_opt_loss
9701.11 / train/extr_critic_mag 72.54 / train/extr_critic_max 72.54 / train/extr_critic_mean 68.49 / train/extr_critic_min 47.86 / train/extr_critic_std 2.88 / train/extr_return_normed_mag 1.22 / train/extr_return_normed_max 1.22 / train/extr_return_normed_mean 0.64 / 
train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 74.14 / train/extr_return_raw_max 74.14 / train/extr_return_raw_mean 68.83 / train/extr_return_raw_min 59.27 / train/extr_return_raw_std 2.96 / 
train/extr_reward_mag 1.35 / train/extr_reward_max 1.35 / train/extr_reward_mean 0.09 / train/extr_reward_min 0 / train/extr_reward_std 0.25 / train/image_loss_mean 1.86 / train/image_loss_std 1.35 / train/model_loss_mean 4.46 / train/model_loss_std 4.62 / 
train/model_opt_grad_norm 10.3 / train/model_opt_grad_steps 3.5e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8341.97 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.64 / 
train/policy_entropy_mean -2.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.63 / train/policy_logprob_mag 8.36 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.94 / train/policy_logprob_min -8.36 / train/policy_logprob_std 1.55 / 
train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 1e-3 / train/policy_randomness_std 0.07 / train/post_ent_mag 43.85 / train/post_ent_max 43.85 / train/post_ent_mean 32.66 / 
train/post_ent_min 17.81 / train/post_ent_std 4.74 / train/prior_ent_mag 66.8 / train/prior_ent_max 66.8 / train/prior_ent_mean 36.94 / train/prior_ent_min 22.62 / train/prior_ent_std 5.96 / train/rep_loss_mean 4.22 / train/rep_loss_std 6 / train/reward_avg 0.07 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.22 / train/reward_max_data 1.23 / train/reward_max_pred 1.18 / train/reward_neg_acc 1 / train/reward_neg_loss 2.2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.68 / train/reward_pred 0.07 / train/reward_rate
0.1 / train_stats/mean_log_entropy -2.87 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.8e-10 / report/cont_loss_std 4.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.17 / report/dyn_loss_std 6.06 / report/image_loss_mean 1.79 / report/image_loss_std 1.31 / report/model_loss_mean 4.36 / report/model_loss_std 4.69 / report/post_ent_mag 44.47 / report/post_ent_max 44.47 / 
report/post_ent_mean 33.72 / report/post_ent_min 16.41 / report/post_ent_std 4.76 / report/prior_ent_mag 66.98 / report/prior_ent_max 66.98 / report/prior_ent_mean 37.57 / report/prior_ent_min 22.02 / report/prior_ent_std 5.59 / report/rep_loss_mean 4.17 / 
report/rep_loss_std 6.06 / report/reward_avg 0.08 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.22 / report/reward_max_data 1.36 / report/reward_max_pred 1.27 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.08 / report/reward_rate 0.12 / eval/cont_avg 1 / eval/cont_loss_mean 1e-10 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-10 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 6.24 / eval/dyn_loss_std 8.34 / eval/image_loss_mean 3.06 / eval/image_loss_std 4.02 / eval/model_loss_mean 6.82 / eval/model_loss_std 8.4 / eval/post_ent_mag 42.14 / eval/post_ent_max 42.14 / eval/post_ent_mean 31.61 / 
eval/post_ent_min 18.84 / eval/post_ent_std 4.62 / eval/prior_ent_mag 66.98 / eval/prior_ent_max 66.98 / eval/prior_ent_mean 35.34 / eval/prior_ent_min 23.79 / eval/prior_ent_std 6.19 / eval/rep_loss_mean 6.24 / eval/rep_loss_std 8.34 / eval/reward_avg 9.6e-3 / 
eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.2 / eval/reward_max_data 0.94 / eval/reward_max_pred 0.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 1.17 / eval/reward_pred 9.8e-3 / eval/reward_rate 0.02 / 
replay/size 7.3e4 / replay/inserts 3851 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.4e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3851 / timer/env.step_total 20.05 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.15 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7358 / timer/agent.policy_total 16.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1926 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1926 / timer/agent.train_total 244.43 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 73500 Counter(73500) 73437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 149.3.
train_Episode has 500 steps and return 149.4.
Saved chunk: 20230921T230321F095412-0nsw49F8qxTc0OMQPvF5Nv-55ocNMET0UUm72hnxZWQ39-1024.npz
Starting evaluation at step 74000 Counter(74000) 73937
eval_Episode has 500 steps and return 166.7.
train_Episode has 500 steps and return 144.6.
Starting evaluation at step 74500 Counter(74500) 74437
Saved chunk: 20230921T230345F483471-3WQL2kFkiOXEcc9aCYR8BP-3Ewhb7tzAUF0O79HzzEBiQ-1024.npz
eval_Episode has 500 steps and return 148.9.
train_Episode has 500 steps and return 139.9.
Saved chunk: 20230921T230441F834963-55ocNMET0UUm72hnxZWQ39-0m0Ioa5RQPi0l4NsLCzAEs-1024.npz
Starting evaluation at step 75000 Counter(75000) 74937
eval_Episode has 500 steps and return 132.9.
train_Episode has 500 steps and return 116.1.
Starting evaluation at step 75500 Counter(75500) 75437
Saved chunk: 20230921T230540F673409-3Ewhb7tzAUF0O79HzzEBiQ-1G5tqthTdAPo1aYBpil7Ac-1024.npz
eval_Episode has 500 steps and return 147.6.
train_Episode has 500 steps and return 148.6.
Saved chunk: 20230921T230602F175863-0m0Ioa5RQPi0l4NsLCzAEs-0Ann7OB0loOG4UqdD86o8F-1024.npz
Starting evaluation at step 76000 Counter(76000) 75937
eval_Episode has 500 steps and return 169.1.
train_Episode has 500 steps and return 137.0.
Starting evaluation at step 76500 Counter(76500) 76437
Saved chunk: 20230921T230659F310154-1G5tqthTdAPo1aYBpil7Ac-4O0WepIlNBdyO81XimS6R1-1024.npz
eval_Episode has 500 steps and return 178.4.
train_Episode has 500 steps and return 156.9.
Saved chunk: 20230921T230722F312738-0Ann7OB0loOG4UqdD86o8F-17rBkbraS9N8ja5r99Pu89-1024.npz
Starting evaluation at step 77000 Counter(77000) 76937
eval_Episode has 500 steps and return 141.0.
train_Episode has 500 steps and return 153.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 154574 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 140.96 / eval_episode/reward_rate 0.32 / episode/length 500 / episode/score 153.76 / episode/reward_rate 0.35 / train/action_mag 2.94 / train/action_max 2.94 / train/action_mean 0.12 / train/action_min -2 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 3.7e4 / train/actor_opt_loss -352.22 / train/adv_mag 2.75 / train/adv_max 2.75 / train/adv_mean 0.04 / train/adv_min
-0.5 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.7e-10 / train/cont_loss_std 6.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.25 / train/dyn_loss_std 6.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 3.7e4 / 
train/extr_critic_critic_opt_loss 9361.71 / train/extr_critic_mag 82.21 / train/extr_critic_max 82.21 / train/extr_critic_mean 78.06 / train/extr_critic_min 53.86 / train/extr_critic_std 2.77 / train/extr_return_normed_mag 1.25 / train/extr_return_normed_max 1.25 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 84.2 / train/extr_return_raw_max 84.2 / train/extr_return_raw_mean 78.4 / train/extr_return_raw_min 69.45 /
train/extr_return_raw_std 2.87 / train/extr_reward_mag 1.47 / train/extr_reward_max 1.47 / train/extr_reward_mean 0.11 / train/extr_reward_min 0 / train/extr_reward_std 0.27 / train/image_loss_mean 1.85 / train/image_loss_std 1.37 / train/model_loss_mean 4.48 / 
train/model_loss_std 4.7 / train/model_opt_grad_norm 10.37 / train/model_opt_grad_steps 3.7e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9052.63 / train/policy_entropy_mag 3.53 / train/policy_entropy_max
1.54 / train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 8.01 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 3.01 / train/policy_logprob_min -8.01 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 7.4e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 44.53 / train/post_ent_max 44.53 / train/post_ent_mean 33.25 / 
train/post_ent_min 18.03 / train/post_ent_std 4.82 / train/prior_ent_mag 67.38 / train/prior_ent_max 67.38 / train/prior_ent_mean 37.53 / train/prior_ent_min 22.96 / train/prior_ent_std 5.95 / train/rep_loss_mean 4.25 / train/rep_loss_std 6.1 / train/reward_avg 0.08 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.25 / train/reward_max_data 1.29 / train/reward_max_pred 1.24 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.68 / train/reward_pred 0.08 / train/reward_rate
0.11 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.95 / report/cont_avg 1 / report/cont_loss_mean 1.7e-10 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.28 / report/dyn_loss_std 6.01 / report/image_loss_mean 1.71 / report/image_loss_std 1.04 / report/model_loss_mean 4.4 / report/model_loss_std 4.38 / report/post_ent_mag 44.7 / report/post_ent_max 44.7 / 
report/post_ent_mean 35.31 / report/post_ent_min 18.76 / report/post_ent_std 4.45 / report/prior_ent_mag 68.24 / report/prior_ent_max 68.24 / report/prior_ent_mean 39.51 / report/prior_ent_min 26.66 / report/prior_ent_std 5.07 / report/rep_loss_mean 4.28 / 
report/rep_loss_std 6.01 / report/reward_avg 0.11 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.32 / report/reward_max_data 1.24 / report/reward_max_pred 1.25 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.71 / report/reward_pred 0.11 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.08 / eval/dyn_loss_std 8.2 / eval/image_loss_mean 2.87 / eval/image_loss_std 3.26 / eval/model_loss_mean 7.15 / eval/model_loss_std 7.61 / eval/post_ent_mag 42.41 / eval/post_ent_max 42.41 / eval/post_ent_mean 
32.58 / eval/post_ent_min 17.59 / eval/post_ent_std 5.54 / eval/prior_ent_mag 68.24 / eval/prior_ent_max 68.24 / eval/prior_ent_mean 37.2 / eval/prior_ent_min 24.1 / eval/prior_ent_std 6.53 / eval/rep_loss_mean 7.08 / eval/rep_loss_std 8.2 / eval/reward_avg 0.02 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.2 / eval/reward_max_data 0.88 / eval/reward_max_pred 0.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.02 / eval/reward_rate 0.03 / 
replay/size 7.7e4 / replay/inserts 3798 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3798 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.45 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.4e-4 / timer/replay._sample_max 0.1 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7806 / timer/agent.policy_total 17.89 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.09 / 
timer/dataset_train_count 1899 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1899 / timer/agent.train_total 240.94 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.31

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 77500 Counter(77500) 77437
Saved chunk: 20230921T230817F739923-4O0WepIlNBdyO81XimS6R1-2MDNXCwNIvbX8k87GULTEP-1024.npz
eval_Episode has 500 steps and return 168.6.
train_Episode has 500 steps and return 162.6.
Saved chunk: 20230921T230842F305578-17rBkbraS9N8ja5r99Pu89-59iifEP3OQNic0hJzT8che-1024.npz
Starting evaluation at step 78000 Counter(78000) 77937
eval_Episode has 500 steps and return 176.5.
train_Episode has 500 steps and return 153.8.
Starting evaluation at step 78500 Counter(78500) 78437
Saved chunk: 20230921T230936F842751-2MDNXCwNIvbX8k87GULTEP-4XdNJI0jQExN0IofnWtKAv-1024.npz
eval_Episode has 500 steps and return 162.9.
train_Episode has 500 steps and return 176.4.
Saved chunk: 20230921T231003F130282-59iifEP3OQNic0hJzT8che-09ezzab7YxPKnnMUZVbwcA-1024.npz
Starting evaluation at step 79000 Counter(79000) 78937
eval_Episode has 500 steps and return 180.8.
train_Episode has 500 steps and return 148.8.
Starting evaluation at step 79500 Counter(79500) 79437
Saved chunk: 20230921T231055F737224-4XdNJI0jQExN0IofnWtKAv-3U4A814yxpCKuuqyAkP4QV-1024.npz
eval_Episode has 500 steps and return 184.6.
train_Episode has 500 steps and return 151.9.
Saved chunk: 20230921T231123F515033-09ezzab7YxPKnnMUZVbwcA-4paQ3VRfBjZ8fo19joyEL0-1024.npz
Starting evaluation at step 80000 Counter(80000) 79937
eval_Episode has 500 steps and return 143.0.
train_Episode has 500 steps and return 125.9.
Starting evaluation at step 80500 Counter(80500) 80437
Saved chunk: 20230921T231214F373783-3U4A814yxpCKuuqyAkP4QV-7ff0jvG6HQjEwXX38HGJO4-1024.npz
eval_Episode has 500 steps and return 119.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T231332F716466-7ff0jvG6HQjEwXX38HGJO4-0000000000000000000000-364.npz
Saved chunk: 20230921T231243F593770-4paQ3VRfBjZ8fo19joyEL0-0000000000000000000000-728.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 143.7.
Saved chunk: 20230921T231243F593770-4paQ3VRfBjZ8fo19joyEL0-4tlI69NgQ8KRmnNEkNUhP7-1024.npz
Starting evaluation at step 81000 Counter(81000) 80937
eval_Episode has 500 steps and return 167.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 162166 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 167.66 / eval_episode/reward_rate 0.37 / episode/length 500 / episode/score 143.74 / episode/reward_rate 0.32 / train/action_mag 3.03 / train/action_max 3.02 / train/action_mean 0.1 / train/action_min -2.18 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 3.9e4 / train/actor_opt_loss -340.79 / train/adv_mag 2.74 / train/adv_max 2.74 / train/adv_mean 0.04 / train/adv_min
-0.5 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
4.24 / train/dyn_loss_std 6.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 3.9e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 92.26 / train/extr_critic_max 92.26 / train/extr_critic_mean 87.55 / train/extr_critic_min 59.75 / train/extr_critic_std 3.2 / train/extr_return_normed_mag 1.27 / train/extr_return_normed_max 1.27 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 94.56 / train/extr_return_raw_max 94.56 / train/extr_return_raw_mean 87.93 / train/extr_return_raw_min 
77.36 / train/extr_return_raw_std 3.27 / train/extr_reward_mag 1.53 / train/extr_reward_max 1.53 / train/extr_reward_mean 0.11 / train/extr_reward_min 0 / train/extr_reward_std 0.29 / train/image_loss_mean 1.78 / train/image_loss_std 1.31 / train/model_loss_mean 4.41 / 
train/model_loss_std 4.64 / train/model_opt_grad_norm 10.28 / train/model_opt_grad_steps 3.9e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 5.3e-3 / train/model_opt_model_opt_grad_scale 7342.11 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.44 / train/policy_entropy_mean -3.02 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 3.02 / train/policy_logprob_min -8.04 / 
train/policy_logprob_std 1.55 / train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 5.4e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 45.08 / train/post_ent_max 45.08 / 
train/post_ent_mean 33.86 / train/post_ent_min 18.34 / train/post_ent_std 4.89 / train/prior_ent_mag 67.91 / train/prior_ent_max 67.91 / train/prior_ent_mean 38.14 / train/prior_ent_min 23.35 / train/prior_ent_std 5.95 / train/rep_loss_mean 4.24 / train/rep_loss_std 
6.07 / train/reward_avg 0.09 / train/reward_loss_mean 0.09 / train/reward_loss_std 0.26 / train/reward_max_data 1.37 / train/reward_max_pred 1.33 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.68 / 
train/reward_pred 0.09 / train/reward_rate 0.13 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.94 / report/cont_avg 1 / report/cont_loss_mean 1.5e-10 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.06 / report/dyn_loss_std 5.73 / report/image_loss_mean 1.68 / report/image_loss_std 1.24 / report/model_loss_mean 4.22 / report/model_loss_std 4.4 / 
report/post_ent_mag 45.41 / report/post_ent_max 45.41 / report/post_ent_mean 33.84 / report/post_ent_min 18.23 / report/post_ent_std 4.96 / report/prior_ent_mag 67.89 / report/prior_ent_max 67.89 / report/prior_ent_mean 37.89 / report/prior_ent_min 20.32 / 
report/prior_ent_std 6.23 / report/rep_loss_mean 4.06 / report/rep_loss_std 5.73 / report/reward_avg 0.11 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.27 / report/reward_max_data 1.28 / report/reward_max_pred 1.25 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.68 / report/reward_pred 0.11 / report/reward_rate 0.15 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.98 / eval/dyn_loss_std 8.98 / eval/image_loss_mean 3.16 / eval/image_loss_std 4.03 / eval/model_loss_mean 7.41 / eval/model_loss_std 8.72 / eval/post_ent_mag 
43.41 / eval/post_ent_max 43.41 / eval/post_ent_mean 31.23 / eval/post_ent_min 18.2 / eval/post_ent_std 5.02 / eval/prior_ent_mag 67.89 / eval/prior_ent_max 67.89 / eval/prior_ent_mean 36.32 / eval/prior_ent_min 25.61 / eval/prior_ent_std 6.41 / eval/rep_loss_mean 6.98 
/ eval/rep_loss_std 8.98 / eval/reward_avg 0.04 / eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.28 / eval/reward_max_data 1.16 / eval/reward_max_pred 1.09 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-4 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.87 
/ eval/reward_pred 0.04 / eval/reward_rate 0.07 / replay/size 8.1e4 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.2e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3796 / timer/env.step_total 19.86 
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3e4 / timer/replay._sample_total 446.91 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
6.3e-4 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7804 / timer/agent.policy_total 
17.75 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / 
timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1898 / timer/agent.train_total 241.06 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2
/ timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / 
timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 116.3.
Starting evaluation at step 81500 Counter(81500) 81437
Saved chunk: 20230921T231332F716466-7ff0jvG6HQjEwXX38HGJO4-7J741mRxvKrFyaXXTFPSX8-1024.npz
eval_Episode has 500 steps and return 176.9.
train_Episode has 500 steps and return 153.2.
Saved chunk: 20230921T231403F769138-4tlI69NgQ8KRmnNEkNUhP7-0D5C2wM1RKFjnVoLx35Q7P-1024.npz
Starting evaluation at step 82000 Counter(82000) 81937
eval_Episode has 500 steps and return 148.2.
train_Episode has 500 steps and return 143.1.
Starting evaluation at step 82500 Counter(82500) 82437
Saved chunk: 20230921T231452F209234-7J741mRxvKrFyaXXTFPSX8-6yalYJK3lLlPoCDz0IJRL1-1024.npz
eval_Episode has 500 steps and return 204.5.
train_Episode has 500 steps and return 161.9.
Saved chunk: 20230921T231524F771407-0D5C2wM1RKFjnVoLx35Q7P-6Zud4PKk1lBIgHYcNiAq9G-1024.npz
Starting evaluation at step 83000 Counter(83000) 82937
eval_Episode has 500 steps and return 163.1.
train_Episode has 500 steps and return 161.9.
Starting evaluation at step 83500 Counter(83500) 83437
Saved chunk: 20230921T231611F040517-6yalYJK3lLlPoCDz0IJRL1-5cyU4XOvMwepKeDT4S1nib-1024.npz
eval_Episode has 500 steps and return 181.4.
train_Episode has 500 steps and return 141.2.
Saved chunk: 20230921T231645F110754-6Zud4PKk1lBIgHYcNiAq9G-0cQ7sxJBnTFdHFPBFvNMkC-1024.npz
Starting evaluation at step 84000 Counter(84000) 83937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 171.9.
Starting evaluation at step 84500 Counter(84500) 84437
Saved chunk: 20230921T231729F637467-5cyU4XOvMwepKeDT4S1nib-4aHbvpGJFoOgJI5En6AbdC-1024.npz
eval_Episode has 500 steps and return 175.8.
train_Episode has 500 steps and return 150.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 169866 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 150.45 / episode/reward_rate 0.31 / eval_episode/length 500 / eval_episode/score 175.75 / eval_episode/reward_rate 0.36 / train/action_mag 3.13 / train/action_max 3.12 / train/action_mean 0.1 / train/action_min -2.06 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 4.1e4 / train/actor_opt_loss -353.71 / train/adv_mag 0.97 / train/adv_max 0.95 / train/adv_mean 0.04 / train/adv_min
-0.53 / train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 1.5e-10 / train/cont_loss_std 6.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.25 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 4.1e4 / 
train/extr_critic_critic_opt_loss 9508.01 / train/extr_critic_mag 102.03 / train/extr_critic_max 102.03 / train/extr_critic_mean 96.22 / train/extr_critic_min 82.46 / train/extr_critic_std 3.57 / train/extr_return_normed_mag 1.26 / train/extr_return_normed_max 1.26 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 103.92 / train/extr_return_raw_max 103.92 / train/extr_return_raw_mean 96.66 / train/extr_return_raw_min 
84.77 / train/extr_return_raw_std 3.74 / train/extr_reward_mag 1.66 / train/extr_reward_max 1.66 / train/extr_reward_mean 0.12 / train/extr_reward_min 0 / train/extr_reward_std 0.31 / train/image_loss_mean 1.78 / train/image_loss_std 1.32 / train/model_loss_mean 4.43 / 
train/model_loss_std 4.67 / train/model_opt_grad_norm 10.19 / train/model_opt_grad_steps 4.1e4 / train/model_opt_loss 4.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.62 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 7.95 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -7.95 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.1e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 45.59 / train/post_ent_max 45.59 / train/post_ent_mean 34.28 / 
train/post_ent_min 18.19 / train/post_ent_std 4.98 / train/prior_ent_mag 68.43 / train/prior_ent_max 68.43 / train/prior_ent_mean 38.57 / train/prior_ent_min 23.45 / train/prior_ent_std 6 / train/rep_loss_mean 4.25 / train/rep_loss_std 6.12 / train/reward_avg 0.1 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.26 / train/reward_max_data 1.45 / train/reward_max_pred 1.42 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.67 / train/reward_pred 0.1 / train/reward_rate 
0.13 / train_stats/mean_log_entropy -3.02 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 4.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.29 / report/dyn_loss_std 6.16 / report/image_loss_mean 1.77 / report/image_loss_std 1.3 / report/model_loss_mean 4.48 / report/model_loss_std 4.7 / report/post_ent_mag 46.04 / report/post_ent_max 46.04 / 
report/post_ent_mean 35.65 / report/post_ent_min 18.41 / report/post_ent_std 4.68 / report/prior_ent_mag 68.88 / report/prior_ent_max 68.88 / report/prior_ent_mean 39.89 / report/prior_ent_min 25.13 / report/prior_ent_std 5.7 / report/rep_loss_mean 4.29 / 
report/rep_loss_std 6.16 / report/reward_avg 0.16 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.29 / report/reward_max_data 1.67 / report/reward_max_pred 1.59 / report/reward_neg_acc 1 / report/reward_neg_loss 4.5e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.64 / report/reward_pred 0.15 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-10 / eval/cont_loss_std 1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.93 / eval/dyn_loss_std 9.06 / eval/image_loss_mean 2.57 / eval/image_loss_std 3.36 / eval/model_loss_mean 6.84 / eval/model_loss_std 8.53 / eval/post_ent_mag 44.55 / eval/post_ent_max 44.55 / eval/post_ent_mean 33.21 / 
eval/post_ent_min 17.44 / eval/post_ent_std 5.45 / eval/prior_ent_mag 68.88 / eval/prior_ent_max 68.88 / eval/prior_ent_mean 38.35 / eval/prior_ent_min 22.2 / eval/prior_ent_std 6.45 / eval/rep_loss_mean 6.93 / eval/rep_loss_std 9.06 / eval/reward_avg 0.06 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 1.02 / eval/reward_max_data 1.19 / eval/reward_max_pred 1.18 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 0.96 / eval/reward_pos_loss 1.31 / eval/reward_pred 0.05 / eval/reward_rate 0.09 / 
replay/size 8.5e4 / replay/inserts 3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.5e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3850 / timer/env.step_total 20.11 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.25 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.1 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7357 / timer/agent.policy_total 16.73 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.1e-3 
/ timer/dataset_train_count 1925 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1925 / timer/agent.train_total 244.31 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.66

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T231805F046314-0cQ7sxJBnTFdHFPBFvNMkC-549JfFoNNnvhg04w5aPru4-1024.npz
Starting evaluation at step 85000 Counter(85000) 84937
eval_Episode has 500 steps and return 171.5.
train_Episode has 500 steps and return 164.8.
Starting evaluation at step 85500 Counter(85500) 85437
Saved chunk: 20230921T231848F001973-4aHbvpGJFoOgJI5En6AbdC-0IApvCx8PFpcFDxJQu9iWW-1024.npz
eval_Episode has 500 steps and return 198.7.
train_Episode has 500 steps and return 150.1.
Starting evaluation at step 86000 Counter(86000) 85937
eval_Episode has 500 steps and return 170.1.
Saved chunk: 20230921T231925F474170-549JfFoNNnvhg04w5aPru4-2vu3PB34Dlp1NwVWJSVYVT-1024.npz
train_Episode has 500 steps and return 139.3.
Starting evaluation at step 86500 Counter(86500) 86437
Saved chunk: 20230921T232007F268442-0IApvCx8PFpcFDxJQu9iWW-0cdelO5njMaoKOJTWdN0jT-1024.npz
eval_Episode has 500 steps and return 181.0.
train_Episode has 500 steps and return 183.7.
Starting evaluation at step 87000 Counter(87000) 86937
eval_Episode has 500 steps and return 178.8.
Saved chunk: 20230921T232049F610218-2vu3PB34Dlp1NwVWJSVYVT-6UIvFLa0hB7iEM37abBbWn-1024.npz
train_Episode has 500 steps and return 178.8.
Starting evaluation at step 87500 Counter(87500) 87437
Saved chunk: 20230921T232126F071677-0cdelO5njMaoKOJTWdN0jT-6hevn1ixtVGJADdwfWcYJr-1024.npz
eval_Episode has 500 steps and return 205.5.
train_Episode has 500 steps and return 173.8.
Starting evaluation at step 88000 Counter(88000) 87937
eval_Episode has 500 steps and return 185.2.
Saved chunk: 20230921T232209F833058-6UIvFLa0hB7iEM37abBbWn-6eEwlJSNtBV8zZnZEFmHB2-1024.npz
train_Episode has 500 steps and return 188.7.
Starting evaluation at step 88500 Counter(88500) 88437
Saved chunk: 20230921T232244F729964-6hevn1ixtVGJADdwfWcYJr-0PogDZEDfizNJcdqvzBBK9-1024.npz
eval_Episode has 500 steps and return 175.3.
train_Episode has 500 steps and return 150.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 177450 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 175.31 / eval_episode/reward_rate 0.36 / episode/length 500 / episode/score 150.44 / episode/reward_rate 0.33 / train/action_mag 3 / train/action_max 3 / train/action_mean 0.1 / train/action_min -1.99 / train/action_std 0.86 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 4.3e4 / train/actor_opt_loss -272.8 / train/adv_mag 1.96 / train/adv_max 1.95 / train/adv_mean 0.03 / train/adv_min -0.59
/ train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.4e-10 / train/cont_loss_std 5.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
4.29 / train/dyn_loss_std 6.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 4.3e4 / 
train/extr_critic_critic_opt_loss 9083.05 / train/extr_critic_mag 112.85 / train/extr_critic_max 112.85 / train/extr_critic_mean 107.27 / train/extr_critic_min 78.01 / train/extr_critic_std 3.82 / train/extr_return_normed_mag 1.25 / train/extr_return_normed_max 1.23 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 115.29 / train/extr_return_raw_max 115.29 / train/extr_return_raw_mean 107.63 / train/extr_return_raw_min 
93.35 / train/extr_return_raw_std 3.89 / train/extr_reward_mag 1.83 / train/extr_reward_max 1.83 / train/extr_reward_mean 0.14 / train/extr_reward_min 0 / train/extr_reward_std 0.33 / train/image_loss_mean 1.76 / train/image_loss_std 1.31 / train/model_loss_mean 4.43 / 
train/model_loss_std 4.72 / train/model_opt_grad_norm 10.36 / train/model_opt_grad_steps 4.3e4 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7736.84 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.56 / train/policy_entropy_mean -3.03 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 8.26 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3.02 / train/policy_logprob_min -8.26 / 
train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 5e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 45.87 / train/post_ent_max 45.87 / 
train/post_ent_mean 34.83 / train/post_ent_min 18.42 / train/post_ent_std 5.02 / train/prior_ent_mag 68.87 / train/prior_ent_max 68.87 / train/prior_ent_mean 39.15 / train/prior_ent_min 23.84 / train/prior_ent_std 5.96 / train/rep_loss_mean 4.29 / train/rep_loss_std 
6.19 / train/reward_avg 0.11 / train/reward_loss_mean 0.1 / train/reward_loss_std 0.27 / train/reward_max_data 1.58 / train/reward_max_pred 1.54 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.67 / 
train/reward_pred 0.11 / train/reward_rate 0.14 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.01 / report/cont_avg 1 / report/cont_loss_mean 1.4e-10 / report/cont_loss_std 7.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.58 / report/dyn_loss_std 6.61 / report/image_loss_mean 2.02 / report/image_loss_std 1.42 / report/model_loss_mean 4.86 / report/model_loss_std 4.99 / 
report/post_ent_mag 45.85 / report/post_ent_max 45.85 / report/post_ent_mean 34.91 / report/post_ent_min 17.08 / report/post_ent_std 4.79 / report/prior_ent_mag 69.13 / report/prior_ent_max 69.13 / report/prior_ent_mean 39.77 / report/prior_ent_min 26.8 / 
report/prior_ent_std 5.58 / report/rep_loss_mean 4.58 / report/rep_loss_std 6.61 / report/reward_avg 0.1 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.23 / report/reward_max_data 1.65 / report/reward_max_pred 1.57 / report/reward_neg_acc 1 / 
report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.63 / report/reward_pred 0.1 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 3.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6 / eval/dyn_loss_std 7.93 / eval/image_loss_mean 2.19 / eval/image_loss_std 2.78 / eval/model_loss_mean 5.86 / eval/model_loss_std 7.05 / eval/post_ent_mag 45.21
/ eval/post_ent_max 45.21 / eval/post_ent_mean 33.51 / eval/post_ent_min 19.45 / eval/post_ent_std 4.81 / eval/prior_ent_mag 69.13 / eval/prior_ent_max 69.13 / eval/prior_ent_mean 38.44 / eval/prior_ent_min 26.78 / eval/prior_ent_std 5.92 / eval/rep_loss_mean 6 / 
eval/rep_loss_std 7.93 / eval/reward_avg 0.06 / eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.26 / eval/reward_max_data 1.12 / eval/reward_max_pred 1.09 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.3e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.73 / 
eval/reward_pred 0.06 / eval/reward_rate 0.09 / replay/size 8.9e4 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.9e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3792 / timer/env.step_total 19.8 
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.46 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.7e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7800 / timer/agent.policy_total 17.74 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.1e-4 / 
timer/agent.train_count 1896 / timer/agent.train_total 241.07 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 89000 Counter(89000) 88937
eval_Episode has 500 steps and return 210.8.
Saved chunk: 20230921T232330F050613-6eEwlJSNtBV8zZnZEFmHB2-4zjZScAq0AIHfXYdnMyjg6-1024.npz
train_Episode has 500 steps and return 199.8.
Starting evaluation at step 89500 Counter(89500) 89437
Saved chunk: 20230921T232403F352289-0PogDZEDfizNJcdqvzBBK9-6hn9S6gRpHNtYKkXDC4Rws-1024.npz
eval_Episode has 500 steps and return 212.1.
train_Episode has 500 steps and return 164.4.
Starting evaluation at step 90000 Counter(90000) 89937
eval_Episode has 500 steps and return 222.9.
Saved chunk: 20230921T232450F943240-4zjZScAq0AIHfXYdnMyjg6-6wk1ck5gIaEz8YXhLbezVw-1024.npz
train_Episode has 500 steps and return 172.1.
Starting evaluation at step 90500 Counter(90500) 90437
Saved chunk: 20230921T232522F890020-6hn9S6gRpHNtYKkXDC4Rws-1PEu8iufXQw0WAuMjfv1Kv-1024.npz
eval_Episode has 500 steps and return 229.3.
train_Episode has 500 steps and return 204.8.
Starting evaluation at step 91000 Counter(91000) 90937
eval_Episode has 500 steps and return 211.9.
Saved chunk: 20230921T232611F450890-6wk1ck5gIaEz8YXhLbezVw-0FVGsr7VbUefSBwgloTzV9-1024.npz
train_Episode has 500 steps and return 204.9.
Starting evaluation at step 91500 Counter(91500) 91437
Saved chunk: 20230921T232641F708249-1PEu8iufXQw0WAuMjfv1Kv-0d3pwDo2rNfJcBr7TdffDY-1024.npz
eval_Episode has 500 steps and return 186.8.
train_Episode has 500 steps and return 198.6.
Starting evaluation at step 92000 Counter(92000) 91937
eval_Episode has 500 steps and return 194.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T232800F190873-0d3pwDo2rNfJcBr7TdffDY-0000000000000000000000-623.npz
Saved chunk: 20230921T232731F567604-0FVGsr7VbUefSBwgloTzV9-0000000000000000000000-965.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T232731F567604-0FVGsr7VbUefSBwgloTzV9-2v2K3WhEns1N2bbyotfdpw-1024.npz
train_Episode has 500 steps and return 183.4.
Starting evaluation at step 92500 Counter(92500) 92437
Saved chunk: 20230921T232800F190873-0d3pwDo2rNfJcBr7TdffDY-5Le3YGLdOzvZk4IpbO4Xnn-1024.npz
eval_Episode has 500 steps and return 211.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 185034 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 211.31 / eval_episode/reward_rate 0.4 / episode/length 500 / episode/score 183.35 / episode/reward_rate 0.39 / train/action_mag 2.73 / train/action_max 2.73 / train/action_mean 0.09 / train/action_min -1.85 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 4.5e4 / train/actor_opt_loss -301.43 / train/adv_mag 0.95 / train/adv_max 0.94 / train/adv_mean 0.03 / train/adv_min
-0.5 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 4.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.24 / train/dyn_loss_std 6.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 4.5e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 123.56 / train/extr_critic_max 123.56 / train/extr_critic_mean 116.87 / train/extr_critic_min 97.1 / train/extr_critic_std 4.52 / train/extr_return_normed_mag 1.2 / train/extr_return_normed_max 1.2 / 
train/extr_return_normed_mean 0.65 / train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 125.31 / train/extr_return_raw_max 125.31 / train/extr_return_raw_mean 117.33 / train/extr_return_raw_min 
102.47 / train/extr_return_raw_std 4.58 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.14 / train/extr_reward_min 0 / train/extr_reward_std 0.34 / train/image_loss_mean 1.72 / train/image_loss_std 1.27 / train/model_loss_mean 4.36 /
train/model_loss_std 4.66 / train/model_opt_grad_norm 10.14 / train/model_opt_grad_steps 4.5e4 / train/model_opt_loss 4.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9629.63 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.98 / train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.49 / train/policy_logprob_mag 7.92 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.12 / train/policy_logprob_min -7.92 / 
train/policy_logprob_std 1.5 / train/policy_randomness_mag 0.49 / train/policy_randomness_max 0.49 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.3e-4 / train/policy_randomness_std 0.05 / train/post_ent_mag 46.07 / train/post_ent_max 46.07 / 
train/post_ent_mean 35.37 / train/post_ent_min 18.8 / train/post_ent_std 5.05 / train/prior_ent_mag 69.27 / train/prior_ent_max 69.27 / train/prior_ent_mean 39.63 / train/prior_ent_min 24.43 / train/prior_ent_std 5.94 / train/rep_loss_mean 4.24 / train/rep_loss_std 6.15
/ train/reward_avg 0.12 / train/reward_loss_mean 0.1 / train/reward_loss_std 0.27 / train/reward_max_data 1.68 / train/reward_max_pred 1.64 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.67 / train/reward_pred 
0.12 / train/reward_rate 0.15 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.14 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 3.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.11 / report/dyn_loss_std 5.84 / report/image_loss_mean 1.6 / report/image_loss_std 1.04 / report/model_loss_mean 4.18 / report/model_loss_std 4.26 / report/post_ent_mag 45.3 
/ report/post_ent_max 45.3 / report/post_ent_mean 36.53 / report/post_ent_min 20.93 / report/post_ent_std 4.53 / report/prior_ent_mag 69.47 / report/prior_ent_max 69.47 / report/prior_ent_mean 40.81 / report/prior_ent_min 26.44 / report/prior_ent_std 5.15 / 
report/rep_loss_mean 4.11 / report/rep_loss_std 5.84 / report/reward_avg 0.13 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.29 / report/reward_max_data 1.56 / report/reward_max_pred 1.64 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / 
report/reward_pos_acc 0.99 / report/reward_pos_loss 0.66 / report/reward_pred 0.13 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.66 / eval/dyn_loss_std 8.58 / eval/image_loss_mean 1.99 / eval/image_loss_std 2.95 / eval/model_loss_mean 5.45 / eval/model_loss_std 7.61 / eval/post_ent_mag 46.56 / 
eval/post_ent_max 46.56 / eval/post_ent_mean 33.58 / eval/post_ent_min 16.91 / eval/post_ent_std 5.39 / eval/prior_ent_mag 69.47 / eval/prior_ent_max 69.47 / eval/prior_ent_mean 38.53 / eval/prior_ent_min 25.69 / eval/prior_ent_std 6.6 / eval/rep_loss_mean 5.66 / 
eval/rep_loss_std 8.58 / eval/reward_avg 0.06 / eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.23 / eval/reward_max_data 1.19 / eval/reward_max_pred 1.18 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.67 / 
eval/reward_pred 0.06 / eval/reward_rate 0.09 / replay/size 9.2e4 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.3e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3792 / timer/env.step_total 19.79
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.13 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
5.5e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7800 / timer/agent.policy_total 
17.76 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1896 / timer/agent.train_total 241.09 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 199.7.
Starting evaluation at step 93000 Counter(93000) 92937
eval_Episode has 500 steps and return 175.5.
train_Episode has 500 steps and return 182.3.
Saved chunk: 20230921T232851F811028-2v2K3WhEns1N2bbyotfdpw-77QJjEEStME9jA3V3JaOAO-1024.npz
Starting evaluation at step 93500 Counter(93500) 93437
eval_Episode has 500 steps and return 180.9.
Saved chunk: 20230921T232918F827453-5Le3YGLdOzvZk4IpbO4Xnn-0LW2z3woiw0TeiSm8KugC9-1024.npz
train_Episode has 500 steps and return 161.8.
Starting evaluation at step 94000 Counter(94000) 93937
eval_Episode has 500 steps and return 161.1.
train_Episode has 500 steps and return 197.9.
Saved chunk: 20230921T233012F684539-77QJjEEStME9jA3V3JaOAO-4zetxXXm8MdI2BmGGtF4gL-1024.npz
Starting evaluation at step 94500 Counter(94500) 94437
Saved chunk: 20230921T233038F279120-0LW2z3woiw0TeiSm8KugC9-1UlFhUGxvY8DFso2vqAwoh-1024.npz
eval_Episode has 500 steps and return 211.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 95000 Counter(95000) 94937
eval_Episode has 500 steps and return 223.5.
train_Episode has 500 steps and return 195.9.
Saved chunk: 20230921T233132F942615-4zetxXXm8MdI2BmGGtF4gL-5DvswJvcPXsYKdxVLCKuLx-1024.npz
Starting evaluation at step 95500 Counter(95500) 95437
eval_Episode has 500 steps and return 228.0.
Saved chunk: 20230921T233156F952062-1UlFhUGxvY8DFso2vqAwoh-2hyaEDxOuXZ1RrKOuz0s3g-1024.npz
train_Episode has 500 steps and return 186.6.
Starting evaluation at step 96000 Counter(96000) 95937
eval_Episode has 500 steps and return 220.9.
train_Episode has 500 steps and return 208.1.
Saved chunk: 20230921T233253F070867-5DvswJvcPXsYKdxVLCKuLx-10xo5xgyWh9sHWmceo6iXA-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 192730 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 208.09 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 220.88 / eval_episode/reward_rate 0.42 / train/action_mag 2.43 / train/action_max 2.42 / train/action_mean 0.06 / train/action_min -1.86 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 4.7e4 / train/actor_opt_loss -162.23 / train/adv_mag 1.11 / train/adv_max 1.06 / train/adv_mean 
0.02 / train/adv_min -0.52 / train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 5.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 4.23 / train/dyn_loss_std 6.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 4.7e4 / 
train/extr_critic_critic_opt_loss 8957.23 / train/extr_critic_mag 131.98 / train/extr_critic_max 131.98 / train/extr_critic_mean 125.8 / train/extr_critic_min 104.74 / train/extr_critic_std 4.19 / train/extr_return_normed_mag 1.19 / train/extr_return_normed_max 1.19 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 134.27 / train/extr_return_raw_max 134.27 / train/extr_return_raw_mean 126.04 / train/extr_return_raw_min 
111.96 / train/extr_return_raw_std 4.3 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.14 / train/extr_reward_min 0 / train/extr_reward_std 0.35 / train/image_loss_mean 1.7 / train/image_loss_std 1.28 / train/model_loss_mean 4.35 / 
train/model_loss_std 4.72 / train/model_opt_grad_norm 10.24 / train/model_opt_grad_steps 4.7e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7409.33 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.54 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.48 / train/policy_logprob_mag 7.58 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -7.58 / 
train/policy_logprob_std 1.49 / train/policy_randomness_mag 0.44 / train/policy_randomness_max 0.44 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.2e-4 / train/policy_randomness_std 0.05 / train/post_ent_mag 46.37 / train/post_ent_max 46.37 / 
train/post_ent_mean 35.65 / train/post_ent_min 18.72 / train/post_ent_std 5.22 / train/prior_ent_mag 69.58 / train/prior_ent_max 69.58 / train/prior_ent_mean 39.9 / train/prior_ent_min 24.28 / train/prior_ent_std 6.06 / train/rep_loss_mean 4.23 / train/rep_loss_std 6.22
/ train/reward_avg 0.13 / train/reward_loss_mean 0.11 / train/reward_loss_std 0.28 / train/reward_max_data 1.72 / train/reward_max_pred 1.69 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.66 / train/reward_pred
0.12 / train/reward_rate 0.15 / train_stats/mean_log_entropy -3.06 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 8.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.08 / report/dyn_loss_std 6.46 / report/image_loss_mean 1.65 / report/image_loss_std 1.52 / report/model_loss_mean 4.18 / report/model_loss_std 5.04 / report/post_ent_mag 
46.05 / report/post_ent_max 46.05 / report/post_ent_mean 34.17 / report/post_ent_min 16.98 / report/post_ent_std 5.95 / report/prior_ent_mag 69.33 / report/prior_ent_max 69.33 / report/prior_ent_mean 38.33 / report/prior_ent_min 23.46 / report/prior_ent_std 6.99 / 
report/rep_loss_mean 4.08 / report/rep_loss_std 6.46 / report/reward_avg 0.1 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.24 / report/reward_max_data 1.81 / report/reward_max_pred 1.79 / report/reward_neg_acc 1 / report/reward_neg_loss 6.5e-4 / 
report/reward_pos_acc 0.98 / report/reward_pos_loss 0.64 / report/reward_pred 0.1 / report/reward_rate 0.12 / eval/cont_avg 1 / eval/cont_loss_mean 1e-10 / eval/cont_loss_std 4.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.23 / eval/dyn_loss_std 8.25 / eval/image_loss_mean 2.04 / eval/image_loss_std 3.1 / eval/model_loss_mean 5.28 / eval/model_loss_std 7.64 / eval/post_ent_mag 47.07 / eval/post_ent_max 
47.07 / eval/post_ent_mean 35.21 / eval/post_ent_min 20.35 / eval/post_ent_std 5.39 / eval/prior_ent_mag 69.33 / eval/prior_ent_max 69.33 / eval/prior_ent_mean 39.59 / eval/prior_ent_min 29.08 / eval/prior_ent_std 5.99 / eval/rep_loss_mean 5.23 / eval/rep_loss_std 8.25 
/ eval/reward_avg 0.1 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.27 / eval/reward_max_pred 1.24 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.76 / eval/reward_pred 0.09 / 
eval/reward_rate 0.13 / replay/size 9.6e4 / replay/inserts 3848 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.7e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3848 / timer/env.step_total 20.02 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458.39 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7355 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 8.2e-3 / timer/dataset_train_count 1924 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1924 / 
timer/agent.train_total 244.22 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.65

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 96500 Counter(96500) 96437
eval_Episode has 500 steps and return 227.6.
Saved chunk: 20230921T233315F449956-2hyaEDxOuXZ1RrKOuz0s3g-1xMRog8I31rztMu4E5CRLN-1024.npz
train_Episode has 500 steps and return 181.6.
Starting evaluation at step 97000 Counter(97000) 96937
eval_Episode has 500 steps and return 243.7.
train_Episode has 500 steps and return 211.6.
Saved chunk: 20230921T233413F051696-10xo5xgyWh9sHWmceo6iXA-26rSHef0UcpLbegfuPENQq-1024.npz
Starting evaluation at step 97500 Counter(97500) 97437
eval_Episode has 500 steps and return 203.5.
train_Episode has 500 steps and return 199.0.
Starting evaluation at step 98000 Counter(98000) 97937
Saved chunk: 20230921T233434F592079-1xMRog8I31rztMu4E5CRLN-0r2k8pvPZhui1hpY47rF5I-1024.npz
eval_Episode has 500 steps and return 220.7.
train_Episode has 500 steps and return 197.0.
Saved chunk: 20230921T233534F157585-26rSHef0UcpLbegfuPENQq-7eCVKTSBLc1EkAMzCioYfc-1024.npz
Starting evaluation at step 98500 Counter(98500) 98437
eval_Episode has 500 steps and return 246.2.
train_Episode has 500 steps and return 193.0.
Starting evaluation at step 99000 Counter(99000) 98937
Saved chunk: 20230921T233629F136958-0r2k8pvPZhui1hpY47rF5I-2scobognThiHglbl2Fypac-1024.npz
eval_Episode has 500 steps and return 256.6.
train_Episode has 500 steps and return 199.8.
Saved chunk: 20230921T233654F316281-7eCVKTSBLc1EkAMzCioYfc-2vBpZVb31ykBVBNaAxqr6q-1024.npz
Starting evaluation at step 99500 Counter(99500) 99437
eval_Episode has 500 steps and return 229.6.
train_Episode has 500 steps and return 220.5.
Starting evaluation at step 100000 Counter(100000) 99937
Saved chunk: 20230921T233747F610373-2scobognThiHglbl2Fypac-1L15lHgjp2Qmy9zEKRzzZ3-1024.npz
eval_Episode has 500 steps and return 209.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 200334 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 209.56 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 220.5 / episode/reward_rate 0.46 / train/action_mag 2.2 / train/action_max 2.18 / train/action_mean 0.06 / train/action_min -1.87 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.37 / train/actor_opt_grad_steps 4.9e4 / train/actor_opt_loss -225.32 / train/adv_mag 0.59 / train/adv_max 0.52 / train/adv_mean 0.02 / train/adv_min
-0.51 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 5.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.23 / train/dyn_loss_std 6.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 4.9e4 / 
train/extr_critic_critic_opt_loss 9411.8 / train/extr_critic_mag 140.02 / train/extr_critic_max 140.02 / train/extr_critic_mean 132.5 / train/extr_critic_min 115.55 / train/extr_critic_std 4.87 / train/extr_return_normed_mag 1.18 / train/extr_return_normed_max 1.18 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 141.54 / train/extr_return_raw_max 141.54 / train/extr_return_raw_mean 132.87 / train/extr_return_raw_min 
116.67 / train/extr_return_raw_std 4.98 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.16 / train/extr_reward_min 0 / train/extr_reward_std 0.36 / train/image_loss_mean 1.69 / train/image_loss_std 1.27 / train/model_loss_mean 4.34 /
train/model_loss_std 4.7 / train/model_opt_grad_norm 10 / train/model_opt_grad_steps 4.9e4 / train/model_opt_loss 4.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 0.56
/ train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.46 / train/policy_logprob_mag 7.8 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.12 / train/policy_logprob_min -7.8 / train/policy_logprob_std 1.49 / 
train/policy_randomness_mag 0.44 / train/policy_randomness_max 0.44 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4.1e-4 / train/policy_randomness_std 0.05 / train/post_ent_mag 46.68 / train/post_ent_max 46.68 / train/post_ent_mean 36.03 / 
train/post_ent_min 18.77 / train/post_ent_std 5.3 / train/prior_ent_mag 69.85 / train/prior_ent_max 69.85 / train/prior_ent_mean 40.28 / train/prior_ent_min 24.39 / train/prior_ent_std 6.08 / train/rep_loss_mean 4.23 / train/rep_loss_std 6.21 / train/reward_avg 0.14 / 
train/reward_loss_mean 0.11 / train/reward_loss_std 0.28 / train/reward_max_data 1.8 / train/reward_max_pred 1.77 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.66 / train/reward_pred 0.14 / train/reward_rate 
0.17 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.18 / report/cont_avg 1 / report/cont_loss_mean 9.6e-11 / report/cont_loss_std 2.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 5.85 / report/image_loss_mean 1.45 / report/image_loss_std 1.19 / report/model_loss_mean 3.84 / report/model_loss_std 4.46 / report/post_ent_mag 46.55 / report/post_ent_max 46.55 /
report/post_ent_mean 35.02 / report/post_ent_min 19.56 / report/post_ent_std 5.58 / report/prior_ent_mag 70.06 / report/prior_ent_max 70.06 / report/prior_ent_mean 39.07 / report/prior_ent_min 23.63 / report/prior_ent_std 6.97 / report/rep_loss_mean 3.82 / 
report/rep_loss_std 5.85 / report/reward_avg 0.12 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.26 / report/reward_max_data 1.65 / report/reward_max_pred 1.66 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.66 / report/reward_pred 0.12 / report/reward_rate 0.14 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.93 / eval/dyn_loss_std 7.55 / eval/image_loss_mean 2.07 / eval/image_loss_std 2.55 / eval/model_loss_mean 5.69 / eval/model_loss_std 6.6 / eval/post_ent_mag 46.48 / eval/post_ent_max 46.48 / eval/post_ent_mean 
34.6 / eval/post_ent_min 19.85 / eval/post_ent_std 5.57 / eval/prior_ent_mag 70.06 / eval/prior_ent_max 70.06 / eval/prior_ent_mean 39.63 / eval/prior_ent_min 29.04 / eval/prior_ent_std 6.38 / eval/rep_loss_mean 5.93 / eval/rep_loss_std 7.55 / eval/reward_avg 0.05 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.25 / eval/reward_max_data 1.35 / eval/reward_max_pred 1.39 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.75 / eval/reward_pred 0.05 / eval/reward_rate 0.08 / 
replay/size 1e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3802 / timer/env.step_total 19.62 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.79 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7810 / timer/agent.policy_total 17.74 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / 
timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1901 / timer/agent.train_total 241.3 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 201.4.
Saved chunk: 20230921T233814F175477-2vBpZVb31ykBVBNaAxqr6q-4JfKi5jHL8TqNzPwPj8otD-1024.npz
Starting evaluation at step 100500 Counter(100500) 100437
eval_Episode has 500 steps and return 238.3.
train_Episode has 500 steps and return 221.2.
Starting evaluation at step 101000 Counter(101000) 100937
Saved chunk: 20230921T233905F812569-1L15lHgjp2Qmy9zEKRzzZ3-204PsFvMXIIT9Rd2eh94Vq-1024.npz
eval_Episode has 500 steps and return 233.3.
train_Episode has 500 steps and return 220.1.
Saved chunk: 20230921T233934F776447-4JfKi5jHL8TqNzPwPj8otD-1aIY9l4jqQ7qUZHNurCnDg-1024.npz
Starting evaluation at step 101500 Counter(101500) 101437
eval_Episode has 500 steps and return 223.7.
train_Episode has 500 steps and return 205.0.
Starting evaluation at step 102000 Counter(102000) 101937
Saved chunk: 20230921T234025F463728-204PsFvMXIIT9Rd2eh94Vq-4yPLjoNrEbenSWaIMjgupR-1024.npz
eval_Episode has 500 steps and return 235.0.
train_Episode has 500 steps and return 216.5.
Saved chunk: 20230921T234055F435780-1aIY9l4jqQ7qUZHNurCnDg-2WBckQrdE16T2lwW8GSlM1-1024.npz
Starting evaluation at step 102500 Counter(102500) 102437
eval_Episode has 500 steps and return 243.6.
train_Episode has 500 steps and return 220.0.
Starting evaluation at step 103000 Counter(103000) 102937
Saved chunk: 20230921T234144F370753-4yPLjoNrEbenSWaIMjgupR-36kulokF05eGv42zRvpEJX-1024.npz
eval_Episode has 500 steps and return 203.8.
train_Episode has 500 steps and return 201.8.
Saved chunk: 20230921T234216F774985-2WBckQrdE16T2lwW8GSlM1-5xkGyR5O4oxjW3pGZ0Xoco-1024.npz
Starting evaluation at step 103500 Counter(103500) 103437
eval_Episode has 500 steps and return 230.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T234337F017329-5xkGyR5O4oxjW3pGZ0Xoco-0000000000000000000000-176.npz
Saved chunk: 20230921T234303F996772-36kulokF05eGv42zRvpEJX-0000000000000000000000-882.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 204.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 207974 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 204.74 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 230.16 / eval_episode/reward_rate 0.4 / train/action_mag 2.36 / train/action_max 2.34 / train/action_mean 0.06 / train/action_min -1.88 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 5e4 / train/actor_opt_loss -187.08 / train/adv_mag 0.77 / train/adv_max 0.71 / train/adv_mean 0.02 / train/adv_min 
-0.5 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 5.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.27 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 5e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 149.77 / train/extr_critic_max 149.77 / train/extr_critic_mean 142.92 / train/extr_critic_min 120.88 / train/extr_critic_std 4.92 / train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.15 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 151.37 / train/extr_return_raw_max 151.37 / train/extr_return_raw_mean 143.24 / train/extr_return_raw_min 
126.55 / train/extr_return_raw_std 4.91 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.17 / train/extr_reward_min 0 / train/extr_reward_std 0.38 / train/image_loss_mean 1.67 / train/image_loss_std 1.24 / train/model_loss_mean 4.36 /
train/model_loss_std 4.72 / train/model_opt_grad_norm 10.43 / train/model_opt_grad_steps 5e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9267.02 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.5 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.52 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -7.9 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.44 / train/policy_randomness_max 0.44 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 47.03 / train/post_ent_max 47.03 / train/post_ent_mean 36.66 / 
train/post_ent_min 18.84 / train/post_ent_std 5.3 / train/prior_ent_mag 70.14 / train/prior_ent_max 70.14 / train/prior_ent_mean 40.96 / train/prior_ent_min 24.91 / train/prior_ent_std 5.96 / train/rep_loss_mean 4.27 / train/rep_loss_std 6.27 / train/reward_avg 0.15 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.3 / train/reward_max_data 1.81 / train/reward_max_pred 1.79 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.66 / train/reward_pred 0.15 / train/reward_rate 
0.18 / train_stats/mean_log_entropy -3.11 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.5e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.89 / report/dyn_loss_std 6.47 / report/image_loss_mean 1.57 / report/image_loss_std 1.56 / report/model_loss_mean 4.01 / report/model_loss_std 5.08 / report/post_ent_mag 47.14 / report/post_ent_max 47.14 /
report/post_ent_mean 35.57 / report/post_ent_min 17.85 / report/post_ent_std 6.27 / report/prior_ent_mag 70.26 / report/prior_ent_max 70.26 / report/prior_ent_mean 39.41 / report/prior_ent_min 23.54 / report/prior_ent_std 7.22 / report/rep_loss_mean 3.89 / 
report/rep_loss_std 6.47 / report/reward_avg 0.14 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.26 / report/reward_max_data 1.65 / report/reward_max_pred 1.64 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.64 / report/reward_pred 0.13 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 5.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.14 / eval/dyn_loss_std 8.69 / eval/image_loss_mean 1.77 / eval/image_loss_std 2.59 / eval/model_loss_mean 5 / eval/model_loss_std 7.35 / eval/post_ent_mag 47 / eval/post_ent_max 47 / eval/post_ent_mean 34.94 / 
eval/post_ent_min 19.35 / eval/post_ent_std 6.09 / eval/prior_ent_mag 70.26 / eval/prior_ent_max 70.26 / eval/prior_ent_mean 39.29 / eval/prior_ent_min 26.63 / eval/prior_ent_std 6.78 / eval/rep_loss_mean 5.14 / eval/rep_loss_std 8.69 / eval/reward_avg 0.15 / 
eval/reward_loss_mean 0.14 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.46 / eval/reward_max_pred 1.45 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.1e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.72 / eval/reward_pred 0.14 / eval/reward_rate 0.19 / 
replay/size 1e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3820 / timer/env.step_total 19.87 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 459.9 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7327 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.3e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1910 / timer/agent.train_total 244.03 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.98 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 104000 Counter(104000) 103937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T234303F996772-36kulokF05eGv42zRvpEJX-7wOzvYTiH7ZvkcHTSP9d9b-1024.npz
eval_Episode has 500 steps and return 230.9.
train_Episode has 500 steps and return 204.4.
Saved chunk: 20230921T234337F017329-5xkGyR5O4oxjW3pGZ0Xoco-7uF2PGzMDHn1b9xg4IGw6w-1024.npz
Starting evaluation at step 104500 Counter(104500) 104437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 197.0.
Starting evaluation at step 105000 Counter(105000) 104937
Saved chunk: 20230921T234423F535879-7wOzvYTiH7ZvkcHTSP9d9b-6mxkgguM1dGpzxU18X4bJP-1024.npz
eval_Episode has 500 steps and return 221.5.
train_Episode has 500 steps and return 196.5.
Saved chunk: 20230921T234458F389615-7uF2PGzMDHn1b9xg4IGw6w-03dK6VXmqqQCZXe8C0UTK6-1024.npz
Starting evaluation at step 105500 Counter(105500) 105437
eval_Episode has 500 steps and return 247.5.
train_Episode has 500 steps and return 191.1.
Starting evaluation at step 106000 Counter(106000) 105937
Saved chunk: 20230921T234542F781193-6mxkgguM1dGpzxU18X4bJP-1XWeAIYdQl0tqZHSko2vmW-1024.npz
eval_Episode has 500 steps and return 214.6.
train_Episode has 500 steps and return 219.1.
Saved chunk: 20230921T234619F003563-03dK6VXmqqQCZXe8C0UTK6-3iqtxgNIJhyFbvGP4lD5SE-1024.npz
Starting evaluation at step 106500 Counter(106500) 106437
eval_Episode has 500 steps and return 213.6.
train_Episode has 500 steps and return 206.1.
Starting evaluation at step 107000 Counter(107000) 106937
Saved chunk: 20230921T234701F762479-1XWeAIYdQl0tqZHSko2vmW-6f7zSlW88WnwdyEp2qlovi-1024.npz
eval_Episode has 500 steps and return 208.7.
train_Episode has 500 steps and return 214.1.
Starting evaluation at step 107500 Counter(107500) 107437
eval_Episode has 500 steps and return 234.5.
Saved chunk: 20230921T234739F481940-3iqtxgNIJhyFbvGP4lD5SE-3OuqMiEWiMRoU5lpazXCWF-1024.npz
train_Episode has 500 steps and return 223.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 215538 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 234.52 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 223.74 / episode/reward_rate 0.42 / train/action_mag 2.48 / train/action_max 2.47 / train/action_mean 0.06 / train/action_min -1.94 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.35 / train/actor_opt_grad_steps 5.2e4 / train/actor_opt_loss -87.67 / train/adv_mag 0.57 / train/adv_max 0.42 / train/adv_mean 
9.9e-3 / train/adv_min -0.52 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 / train/cont_rate 1 
/ train/dyn_loss_mean 4.19 / train/dyn_loss_std 6.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 5.2e4 / 
train/extr_critic_critic_opt_loss 8624.99 / train/extr_critic_mag 154.62 / train/extr_critic_max 154.62 / train/extr_critic_mean 148.02 / train/extr_critic_min 132.79 / train/extr_critic_std 4.38 / train/extr_return_normed_mag 1.16 / train/extr_return_normed_max 1.16 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 156.41 / train/extr_return_raw_max 156.41 / train/extr_return_raw_mean 148.17 / train/extr_return_raw_min 
132.8 / train/extr_return_raw_std 4.49 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.17 / train/extr_reward_min 0 / train/extr_reward_std 0.39 / train/image_loss_mean 1.62 / train/image_loss_std 1.21 / train/model_loss_mean 4.25 / 
train/model_loss_std 4.69 / train/model_opt_grad_norm 9.74 / train/model_opt_grad_steps 5.2e4 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8095.24 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.24 / train/policy_entropy_mean -3.03 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.52 / train/policy_logprob_mag 7.99 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.03 / train/policy_logprob_min -7.99 / 
train/policy_logprob_std 1.51 / train/policy_randomness_mag 0.41 / train/policy_randomness_max 0.41 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.5e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 47.4 / train/post_ent_max 47.4 / 
train/post_ent_mean 36.89 / train/post_ent_min 18.99 / train/post_ent_std 5.42 / train/prior_ent_mag 70.42 / train/prior_ent_max 70.42 / train/prior_ent_mean 41.1 / train/prior_ent_min 24.68 / train/prior_ent_std 6.09 / train/rep_loss_mean 4.19 / train/rep_loss_std 6.24
/ train/reward_avg 0.16 / train/reward_loss_mean 0.12 / train/reward_loss_std 0.29 / train/reward_max_data 1.86 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.65 / train/reward_pred
0.16 / train/reward_rate 0.18 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.07 / report/cont_avg 1 / report/cont_loss_mean 9.6e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 9.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.09 / report/dyn_loss_std 6.51 / report/image_loss_mean 1.64 / report/image_loss_std 1.28 / report/model_loss_mean 4.23 / report/model_loss_std 4.86 / report/post_ent_mag 
49.35 / report/post_ent_max 49.35 / report/post_ent_mean 35.46 / report/post_ent_min 18.4 / report/post_ent_std 6.29 / report/prior_ent_mag 70.33 / report/prior_ent_max 70.33 / report/prior_ent_mean 39.68 / report/prior_ent_min 22.06 / report/prior_ent_std 7.49 / 
report/rep_loss_mean 4.09 / report/rep_loss_std 6.51 / report/reward_avg 0.17 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.32 / report/reward_max_data 1.95 / report/reward_max_pred 1.87 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.2e-3 / 
report/reward_pos_acc 0.99 / report/reward_pos_loss 0.68 / report/reward_pred 0.17 / report/reward_rate 0.19 / eval/cont_avg 1 / eval/cont_loss_mean 6.3e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.89 / eval/dyn_loss_std 7.51 / eval/image_loss_mean 1.69 / eval/image_loss_std 2.21 / eval/model_loss_mean 4.73 / eval/model_loss_std 6.3 / eval/post_ent_mag 49.48 / eval/post_ent_max
49.48 / eval/post_ent_mean 35.66 / eval/post_ent_min 18.42 / eval/post_ent_std 6.25 / eval/prior_ent_mag 70.33 / eval/prior_ent_max 70.33 / eval/prior_ent_mean 39.8 / eval/prior_ent_min 26.13 / eval/prior_ent_std 7 / eval/rep_loss_mean 4.89 / eval/rep_loss_std 7.51 / 
eval/reward_avg 0.1 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.72 / eval/reward_max_pred 1.77 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.2e-4 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.75 / eval/reward_pred 0.1 / 
eval/reward_rate 0.14 / replay/size 1.1e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3782 / timer/env.step_total 19.66 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.71 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 8.8e-3 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1891 / 
timer/agent.train_total 240.86 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 108000 Counter(108000) 107937
Saved chunk: 20230921T234820F481464-6f7zSlW88WnwdyEp2qlovi-22duumWa6CH6srScmRUPfc-1024.npz
eval_Episode has 500 steps and return 236.4.
train_Episode has 500 steps and return 206.9.
Starting evaluation at step 108500 Counter(108500) 108437
eval_Episode has 500 steps and return 214.8.
Saved chunk: 20230921T234903F268316-3OuqMiEWiMRoU5lpazXCWF-1lCock6H2koDeAcRQvkoGy-1024.npz
train_Episode has 500 steps and return 184.0.
Starting evaluation at step 109000 Counter(109000) 108937
Saved chunk: 20230921T234939F919695-22duumWa6CH6srScmRUPfc-4FRQADytAM0T4ZNZivyTQS-1024.npz
eval_Episode has 500 steps and return 224.1.
train_Episode has 500 steps and return 229.5.
Starting evaluation at step 109500 Counter(109500) 109437
eval_Episode has 500 steps and return 189.2.
Saved chunk: 20230921T235024F599010-1lCock6H2koDeAcRQvkoGy-1nuYO8Q12nD49sGZ6m68HN-1024.npz
train_Episode has 500 steps and return 229.9.
Starting evaluation at step 110000 Counter(110000) 109937
Saved chunk: 20230921T235059F036238-4FRQADytAM0T4ZNZivyTQS-1fvCHbffiYOxEUHvyJyfzu-1024.npz
eval_Episode has 500 steps and return 204.9.
train_Episode has 500 steps and return 214.1.
Starting evaluation at step 110500 Counter(110500) 110437
eval_Episode has 500 steps and return 204.1.
Saved chunk: 20230921T235145F010340-1nuYO8Q12nD49sGZ6m68HN-7HrSXX8TmgywYw7MO9Ri75-1024.npz
train_Episode has 500 steps and return 229.7.
Starting evaluation at step 111000 Counter(111000) 110937
Saved chunk: 20230921T235217F872999-1fvCHbffiYOxEUHvyJyfzu-6twi2PCdRf3fj5PTrSbkvq-1024.npz
eval_Episode has 500 steps and return 227.2.
train_Episode has 500 steps and return 196.9.
Starting evaluation at step 111500 Counter(111500) 111437
eval_Episode has 500 steps and return 226.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 223110 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 226.57 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 196.86 / episode/reward_rate 0.39 / train/action_mag 2.34 / train/action_max 2.31 / train/action_mean 0.06 / train/action_min -1.97 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.4 / train/actor_opt_grad_steps 5.4e4 / train/actor_opt_loss -132.43 / train/adv_mag 0.6 / train/adv_max 0.51 / train/adv_mean 0.01 
/ train/adv_min -0.53 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 5.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.22 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 5.4e4 / 
train/extr_critic_critic_opt_loss 7569.22 / train/extr_critic_mag 159.65 / train/extr_critic_max 159.65 / train/extr_critic_mean 151.72 / train/extr_critic_min 133.37 / train/extr_critic_std 5.03 / train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.15 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 160.92 / train/extr_return_raw_max 160.92 / train/extr_return_raw_mean 151.96 / train/extr_return_raw_min 
133.72 / train/extr_return_raw_std 5.15 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.18 / train/extr_reward_min 0 / train/extr_reward_std 0.39 / train/image_loss_mean 1.63 / train/image_loss_std 1.24 / train/model_loss_mean 4.29 /
train/model_loss_std 4.73 / train/model_opt_grad_norm 10.15 / train/model_opt_grad_steps 5.4e4 / train/model_opt_loss 4.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.13 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.49 / train/policy_logprob_mag 7.86 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -7.85 / train/policy_logprob_std 1.5 / 
train/policy_randomness_mag 0.4 / train/policy_randomness_max 0.4 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.7e-4 / train/policy_randomness_std 0.05 / train/post_ent_mag 47.68 / train/post_ent_max 47.68 / train/post_ent_mean 37.16 / 
train/post_ent_min 18.79 / train/post_ent_std 5.47 / train/prior_ent_mag 70.61 / train/prior_ent_max 70.61 / train/prior_ent_mean 41.42 / train/prior_ent_min 24.9 / train/prior_ent_std 6.08 / train/rep_loss_mean 4.22 / train/rep_loss_std 6.27 / train/reward_avg 0.16 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.65 / train/reward_pred 0.16 / train/reward_rate 
0.19 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.12 / report/cont_avg 1 / report/cont_loss_mean 6.5e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.98 / report/dyn_loss_std 5.97 / report/image_loss_mean 1.54 / report/image_loss_std 1.15 / report/model_loss_mean 4.02 / report/model_loss_std 4.5 / report/post_ent_mag 48.37 / report/post_ent_max 48.37 / 
report/post_ent_mean 37.38 / report/post_ent_min 20.25 / report/post_ent_std 5.8 / report/prior_ent_mag 70.99 / report/prior_ent_max 70.99 / report/prior_ent_mean 41.19 / report/prior_ent_min 24.31 / report/prior_ent_std 6.46 / report/rep_loss_mean 3.98 / 
report/rep_loss_std 5.97 / report/reward_avg 0.12 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.23 / report/reward_max_data 1.84 / report/reward_max_pred 1.83 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.12 / report/reward_rate 0.15 / eval/cont_avg 1 / eval/cont_loss_mean 6.3e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.27 / eval/dyn_loss_std 8.9 / eval/image_loss_mean 2.66 / eval/image_loss_std 3.43 / eval/model_loss_mean 7.18 / eval/model_loss_std 8.25 / eval/post_ent_mag 47.99 / eval/post_ent_max 47.99 / eval/post_ent_mean 
36.4 / eval/post_ent_min 18.94 / eval/post_ent_std 6.44 / eval/prior_ent_mag 70.99 / eval/prior_ent_max 70.99 / eval/prior_ent_mean 41.73 / eval/prior_ent_min 26.04 / eval/prior_ent_std 6.26 / eval/rep_loss_mean 7.27 / eval/rep_loss_std 8.9 / eval/reward_avg 0.14 / 
eval/reward_loss_mean 0.16 / eval/reward_loss_std 0.48 / eval/reward_max_data 1.75 / eval/reward_max_pred 1.71 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.81 / eval/reward_pred 0.15 / eval/reward_rate 0.18 / 
replay/size 1.1e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3786 / timer/env.step_total 19.56 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.83 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 17.95 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / 
timer/dataset_train_count 1893 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1893 / timer/agent.train_total 241.08 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T235305F340170-7HrSXX8TmgywYw7MO9Ri75-4kZjG8oRvONdfgPF0sHTIv-1024.npz
train_Episode has 500 steps and return 201.8.
Starting evaluation at step 112000 Counter(112000) 111937
Saved chunk: 20230921T235336F540558-6twi2PCdRf3fj5PTrSbkvq-7L0zVKNeZIsaWKUG8kFNiL-1024.npz
eval_Episode has 500 steps and return 232.4.
train_Episode has 500 steps and return 206.0.
Starting evaluation at step 112500 Counter(112500) 112437
eval_Episode has 500 steps and return 234.0.
Saved chunk: 20230921T235426F082616-4kZjG8oRvONdfgPF0sHTIv-4x9GrWxLvpwqcZNbABLE3D-1024.npz
train_Episode has 500 steps and return 238.3.
Starting evaluation at step 113000 Counter(113000) 112937
Saved chunk: 20230921T235455F923462-7L0zVKNeZIsaWKUG8kFNiL-4EvVialZVVkCbEah0jyz7W-1024.npz
eval_Episode has 500 steps and return 232.4.
train_Episode has 500 steps and return 223.8.
Starting evaluation at step 113500 Counter(113500) 113437
eval_Episode has 500 steps and return 177.2.
Saved chunk: 20230921T235546F823209-4x9GrWxLvpwqcZNbABLE3D-1p4FHFrqAgtPKnsttccjFg-1024.npz
train_Episode has 500 steps and return 222.0.
Starting evaluation at step 114000 Counter(114000) 113937
Saved chunk: 20230921T235614F991565-4EvVialZVVkCbEah0jyz7W-1rVaaaU0CziKXT1qjA80kd-1024.npz
eval_Episode has 500 steps and return 263.6.
train_Episode has 500 steps and return 180.7.
Starting evaluation at step 114500 Counter(114500) 114437
eval_Episode has 500 steps and return 268.0.
Saved chunk: 20230921T235707F185033-1p4FHFrqAgtPKnsttccjFg-4c93ndK6aQjuPYuepyEoz2-1024.npz
train_Episode has 500 steps and return 161.6.
Starting evaluation at step 115000 Counter(115000) 114937
Saved chunk: 20230921T235733F746853-1rVaaaU0CziKXT1qjA80kd-6mR1hehXYF06jlvb0SiJNC-1024.npz
eval_Episode has 500 steps and return 195.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230921T235827F395450-4c93ndK6aQjuPYuepyEoz2-0000000000000000000000-413.npz
Saved chunk: 20230921T235852F361810-6mR1hehXYF06jlvb0SiJNC-0000000000000000000000-117.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 217.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 230778 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 217.37 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 195.7 / eval_episode/reward_rate 0.4 / train/action_mag 2.47 / train/action_max 2.45 / train/action_mean 0.06 / train/action_min -1.98 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 5.6e4 / train/actor_opt_loss -155.99 / train/adv_mag 0.61 / train/adv_max 0.52 / train/adv_mean 0.02 / train/adv_min
-0.51 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 9.1e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.21 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 5.6e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 166.4 / train/extr_critic_max 166.4 / train/extr_critic_mean 158.28 / train/extr_critic_min 137.14 / train/extr_critic_std 5.38 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.13 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 167.37 / train/extr_return_raw_max 167.37 / train/extr_return_raw_mean 158.58 / train/extr_return_raw_min 
139.65 / train/extr_return_raw_std 5.41 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.18 / train/extr_reward_min 0 / train/extr_reward_std 0.4 / train/image_loss_mean 1.6 / train/image_loss_std 1.22 / train/model_loss_mean 4.26 / 
train/model_loss_std 4.71 / train/model_opt_grad_norm 10.08 / train/model_opt_grad_steps 5.6e4 / train/model_opt_loss 4.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.32 / train/policy_entropy_mean -3.04 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.52 / train/policy_logprob_mag 7.93 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.04 / train/policy_logprob_min -7.93 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.42 / train/policy_randomness_max 0.42 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.1e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 48.02 / train/post_ent_max 48.02 / train/post_ent_mean 37.54 / 
train/post_ent_min 19.17 / train/post_ent_std 5.43 / train/prior_ent_mag 70.78 / train/prior_ent_max 70.78 / train/prior_ent_mean 41.78 / train/prior_ent_min 25.41 / train/prior_ent_std 6 / train/rep_loss_mean 4.21 / train/rep_loss_std 6.27 / train/reward_avg 0.17 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.29 / train/reward_max_data 1.89 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.64 / train/reward_pred 0.17 / train/reward_rate 
0.2 / train_stats/mean_log_entropy -3.1 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.9e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.18 / report/dyn_loss_std 6.54 / report/image_loss_mean 1.64 / report/image_loss_std 1.39 / report/model_loss_mean 4.26 / report/model_loss_std 5.01 / report/post_ent_mag 47.36 / report/post_ent_max 47.36 /
report/post_ent_mean 36.5 / report/post_ent_min 16.36 / report/post_ent_std 6.6 / report/prior_ent_mag 71.1 / report/prior_ent_max 71.1 / report/prior_ent_mean 40.5 / report/prior_ent_min 21.2 / report/prior_ent_std 7.31 / report/rep_loss_mean 4.18 / report/rep_loss_std
6.54 / report/reward_avg 0.14 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.29 / report/reward_max_data 1.84 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 7.5e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.65 / 
report/reward_pred 0.14 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 9.7e-11 / eval/cont_loss_std 7.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 6.97 / eval/dyn_loss_std 8.07 / eval/image_loss_mean 3.16 / eval/image_loss_std 3.52 / eval/model_loss_mean 7.5 / eval/model_loss_std 7.63 / eval/post_ent_mag 48.48 / eval/post_ent_max 48.48 / eval/post_ent_mean 37.43 / eval/post_ent_min 19.53 / 
eval/post_ent_std 5.56 / eval/prior_ent_mag 71.1 / eval/prior_ent_max 71.1 / eval/prior_ent_mean 42.1 / eval/prior_ent_min 26.84 / eval/prior_ent_std 6.58 / eval/rep_loss_mean 6.97 / eval/rep_loss_std 8.07 / eval/reward_avg 0.16 / eval/reward_loss_mean 0.16 / 
eval/reward_loss_std 0.43 / eval/reward_max_data 1.74 / eval/reward_max_pred 1.77 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.6e-5 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.81 / eval/reward_pred 0.16 / eval/reward_rate 0.2 / replay/size 1.2e5 / 
replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3834 / timer/env.step_total 19.94 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 
4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.98 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7341 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1917 / timer/agent.train_total 244.08 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / 
timer/dataset_eval_max 4.7e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 115500 Counter(115500) 115437
eval_Episode has 500 steps and return 262.8.
Saved chunk: 20230921T235827F395450-4c93ndK6aQjuPYuepyEoz2-7fEPRqok6lOzkGf4hFJjfR-1024.npz
train_Episode has 500 steps and return 216.6.
Starting evaluation at step 116000 Counter(116000) 115937
Saved chunk: 20230921T235852F361810-6mR1hehXYF06jlvb0SiJNC-0kzeBPDZ2awn2Wus3JzPBo-1024.npz
eval_Episode has 500 steps and return 209.6.
train_Episode has 500 steps and return 221.5.
Starting evaluation at step 116500 Counter(116500) 116437
eval_Episode has 500 steps and return 254.2.
train_Episode has 500 steps and return 206.3.
Saved chunk: 20230921T235948F610144-7fEPRqok6lOzkGf4hFJjfR-7FU4iCuEEsAfbcuXGHmzJW-1024.npz
Starting evaluation at step 117000 Counter(117000) 116937
Saved chunk: 20230922T000012F187368-0kzeBPDZ2awn2Wus3JzPBo-15AFISsXyzJSEOXnY3gdfy-1024.npz
eval_Episode has 500 steps and return 255.8.
train_Episode has 500 steps and return 230.9.
Starting evaluation at step 117500 Counter(117500) 117437
eval_Episode has 500 steps and return 245.0.
train_Episode has 500 steps and return 236.0.
Saved chunk: 20230922T000109F214748-7FU4iCuEEsAfbcuXGHmzJW-5zseWEkvStfYtCnlUCqpKi-1024.npz
Starting evaluation at step 118000 Counter(118000) 117937
Saved chunk: 20230922T000131F163057-15AFISsXyzJSEOXnY3gdfy-0PASD8EFMB4VOecKfVbo9U-1024.npz
eval_Episode has 500 steps and return 262.8.
train_Episode has 500 steps and return 215.9.
Starting evaluation at step 118500 Counter(118500) 118437
eval_Episode has 500 steps and return 276.0.
train_Episode has 500 steps and return 223.6.
Saved chunk: 20230922T000229F590217-5zseWEkvStfYtCnlUCqpKi-6lTHH2bY9wIxYR1WS1tLuh-1024.npz
Starting evaluation at step 119000 Counter(119000) 118937
eval_Episode has 500 steps and return 259.5.
Saved chunk: 20230922T000249F881555-0PASD8EFMB4VOecKfVbo9U-4sydoLcoWdjb88zvgrNkEp-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 238354 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 259.54 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 223.57 / episode/reward_rate 0.43 / train/action_mag 2.52 / train/action_max 2.5 / train/action_mean 0.06 / train/action_min -1.96 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 5.8e4 / train/actor_opt_loss -129.48 / train/adv_mag 0.67 / train/adv_max 0.6 / train/adv_mean 0.01 / train/adv_min 
-0.51 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 8.8e-11 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.2 / train/dyn_loss_std 6.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 5.8e4 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 173.5 / train/extr_critic_max 173.5 / train/extr_critic_mean 165.68 / train/extr_critic_min 142.06 / train/extr_critic_std 5.34 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 174.64 / train/extr_return_raw_max 174.64 / train/extr_return_raw_mean 165.93 / train/extr_return_raw_min 
146.48 / train/extr_return_raw_std 5.34 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.19 / train/extr_reward_min 0 / train/extr_reward_std 0.41 / train/image_loss_mean 1.6 / train/image_loss_std 1.24 / train/model_loss_mean 4.26 / 
train/model_loss_std 4.73 / train/model_opt_grad_norm 10 / train/model_opt_grad_steps 5.8e4 / train/model_opt_loss 4.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.33 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.52 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -7.9 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.42 / train/policy_randomness_max 0.42 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.1e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 48.04 / train/post_ent_max 48.04 / train/post_ent_mean 37.63 / 
train/post_ent_min 19.29 / train/post_ent_std 5.46 / train/prior_ent_mag 70.96 / train/prior_ent_max 70.96 / train/prior_ent_mean 41.86 / train/prior_ent_min 25.53 / train/prior_ent_std 6.04 / train/rep_loss_mean 4.2 / train/rep_loss_std 6.28 / train/reward_avg 0.18 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.64 / train/reward_pred 0.18 / train/reward_rate 
0.2 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.09 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 9.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.12 / report/dyn_loss_std 6.09 / report/image_loss_mean 1.85 / report/image_loss_std 1.54 / report/model_loss_mean 4.38 / report/model_loss_std 4.89 / report/post_ent_mag 47.43 / report/post_ent_max 47.43 /
report/post_ent_mean 36.65 / report/post_ent_min 19.01 / report/post_ent_std 5.55 / report/prior_ent_mag 70.66 / report/prior_ent_max 70.66 / report/prior_ent_mean 40.76 / report/prior_ent_min 26.44 / report/prior_ent_std 5.94 / report/rep_loss_mean 4.12 / 
report/rep_loss_std 6.09 / report/reward_avg 0.08 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.17 / report/reward_max_data 1.9 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.08 / report/reward_rate 0.08 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.15 / eval/dyn_loss_std 8.33 / eval/image_loss_mean 2.33 / eval/image_loss_std 3.1 / eval/model_loss_mean 6.1 / eval/model_loss_std 7.55 / eval/post_ent_mag 49.16 / eval/post_ent_max 49.16 / eval/post_ent_mean 
35.51 / eval/post_ent_min 17.9 / eval/post_ent_std 6.08 / eval/prior_ent_mag 70.66 / eval/prior_ent_max 70.66 / eval/prior_ent_mean 40.5 / eval/prior_ent_min 28.12 / eval/prior_ent_std 6.36 / eval/rep_loss_mean 6.15 / eval/rep_loss_std 8.33 / eval/reward_avg 0.1 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.29 / eval/reward_max_data 1.58 / eval/reward_max_pred 1.59 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-4 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.67 / eval/reward_pred 0.1 / eval/reward_rate 0.13 / 
replay/size 1.2e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3788 / timer/env.step_total 19.59 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.25 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 18.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1894 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1894 / timer/agent.train_total 240.95 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 250.6.
Starting evaluation at step 119500 Counter(119500) 119437
eval_Episode has 500 steps and return 235.7.
train_Episode has 500 steps and return 204.0.
Saved chunk: 20230922T000349F740438-6lTHH2bY9wIxYR1WS1tLuh-6IkyO5lBwMINNF4bLdSWkz-1024.npz
Starting evaluation at step 120000 Counter(120000) 119937
eval_Episode has 500 steps and return 244.7.
Saved chunk: 20230922T000408F436803-4sydoLcoWdjb88zvgrNkEp-4v8vkNYYP2gTfGCXZRIqGk-1024.npz
train_Episode has 500 steps and return 243.8.
Starting evaluation at step 120500 Counter(120500) 120437
eval_Episode has 500 steps and return 217.6.
train_Episode has 500 steps and return 202.9.
Saved chunk: 20230922T000510F772933-6IkyO5lBwMINNF4bLdSWkz-5GG9fjBBYi9xZGZZHNhbpq-1024.npz
Starting evaluation at step 121000 Counter(121000) 120937
eval_Episode has 500 steps and return 258.1.
train_Episode has 500 steps and return 219.3.
Starting evaluation at step 121500 Counter(121500) 121437
Saved chunk: 20230922T000528F069954-4v8vkNYYP2gTfGCXZRIqGk-4uvfEKV1uwnzmHOv3FCRzQ-1024.npz
eval_Episode has 500 steps and return 213.7.
train_Episode has 500 steps and return 196.8.
Saved chunk: 20230922T000631F338410-5GG9fjBBYi9xZGZZHNhbpq-1NMfczfhL6KuH20BGBrp2P-1024.npz
Starting evaluation at step 122000 Counter(122000) 121937
eval_Episode has 500 steps and return 249.7.
train_Episode has 500 steps and return 242.5.
Starting evaluation at step 122500 Counter(122500) 122437
Saved chunk: 20230922T000722F842769-4uvfEKV1uwnzmHOv3FCRzQ-5LZToyto1HGQmLSugqE5LE-1024.npz
eval_Episode has 500 steps and return 257.0.
train_Episode has 500 steps and return 225.1.
Saved chunk: 20230922T000751F650815-1NMfczfhL6KuH20BGBrp2P-3DLtYjqdi25yGfkO6NSgaX-1024.npz
Starting evaluation at step 123000 Counter(123000) 122937
eval_Episode has 500 steps and return 244.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 246002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 225.12 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 244.78 / eval_episode/reward_rate 0.45 / train/action_mag 2.53 / train/action_max 2.51 / train/action_mean 0.05 / train/action_min -2.02 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.35 / train/actor_opt_grad_steps 6e4 / train/actor_opt_loss -64.61 / train/adv_mag 0.6 / train/adv_max 0.46 / train/adv_mean 7.5e-3 
/ train/adv_min -0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 8.5e-11 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.21 / train/dyn_loss_std 6.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 6e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 178.5 / train/extr_critic_max 178.5 / train/extr_critic_mean 171.46 / train/extr_critic_min 151.72 / train/extr_critic_std 5.06 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 180.02 / train/extr_return_raw_max 180.02 / train/extr_return_raw_mean 171.58 / train/extr_return_raw_min 
152.04 / train/extr_return_raw_std 5.11 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.2 / train/extr_reward_min 0 / train/extr_reward_std 0.42 / train/image_loss_mean 1.57 / train/image_loss_std 1.23 / train/model_loss_mean 4.23 / 
train/model_loss_std 4.75 / train/model_opt_grad_norm 10.11 / train/model_opt_grad_steps 6e4 / train/model_opt_loss 4.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.32 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.51 / train/policy_logprob_mag 7.84 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -7.84 / train/policy_logprob_std 1.5 / 
train/policy_randomness_mag 0.42 / train/policy_randomness_max 0.42 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.9e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 48.38 / train/post_ent_max 48.38 / train/post_ent_mean 38.08 / 
train/post_ent_min 19.17 / train/post_ent_std 5.51 / train/prior_ent_mag 71.1 / train/prior_ent_max 71.1 / train/prior_ent_mean 42.3 / train/prior_ent_min 25.53 / train/prior_ent_std 6.02 / train/rep_loss_mean 4.21 / train/rep_loss_std 6.31 / train/reward_avg 0.19 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.64 / train/reward_pred 0.19 / train/reward_rate 
0.21 / train_stats/mean_log_entropy -3.12 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.2e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.2 / report/dyn_loss_std 6.64 / report/image_loss_mean 1.69 / report/image_loss_std 1.09 / report/model_loss_mean 4.29 / report/model_loss_std 4.78 / report/post_ent_mag 47.96 / report/post_ent_max 47.96 / 
report/post_ent_mean 36.74 / report/post_ent_min 16.07 / report/post_ent_std 5.34 / report/prior_ent_mag 71.14 / report/prior_ent_max 71.14 / report/prior_ent_mean 41.13 / report/prior_ent_min 26.74 / report/prior_ent_std 6.07 / report/rep_loss_mean 4.2 / 
report/rep_loss_std 6.64 / report/reward_avg 0.08 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.23 / report/reward_max_data 2 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.08 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 8.3e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.01 / eval/dyn_loss_std 8.52 / eval/image_loss_mean 2.22 / eval/image_loss_std 3.05 / eval/model_loss_mean 6.01 / eval/model_loss_std 7.7 / eval/post_ent_mag 48.62 / eval/post_ent_max 48.62 / eval/post_ent_mean 
37.9 / eval/post_ent_min 16.35 / eval/post_ent_std 5.85 / eval/prior_ent_mag 71.14 / eval/prior_ent_max 71.14 / eval/prior_ent_mean 42.6 / eval/prior_ent_min 23.38 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 6.01 / eval/rep_loss_std 8.52 / eval/reward_avg 0.22 / 
eval/reward_loss_mean 0.18 / eval/reward_loss_std 0.46 / eval/reward_max_data 1.7 / eval/reward_max_pred 1.67 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.68 / eval/reward_pred 0.22 / eval/reward_rate 0.26 / 
replay/size 1.2e5 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.59 / timer/env.step_count 3824 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.21 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7832 / timer/agent.policy_total 17.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1912 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1912 / timer/agent.train_total 243.34 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 203.9.
Starting evaluation at step 123500 Counter(123500) 123437
Saved chunk: 20230922T000841F367962-5LZToyto1HGQmLSugqE5LE-3uxkaKdnF693Yvx0LouXCl-1024.npz
eval_Episode has 500 steps and return 230.8.
train_Episode has 500 steps and return 234.9.
Saved chunk: 20230922T000911F680526-3DLtYjqdi25yGfkO6NSgaX-2du4tfwabxQo3hJdvIDeld-1024.npz
Starting evaluation at step 124000 Counter(124000) 123937
eval_Episode has 500 steps and return 234.8.
train_Episode has 500 steps and return 242.4.
Starting evaluation at step 124500 Counter(124500) 124437
Saved chunk: 20230922T001000F827439-3uxkaKdnF693Yvx0LouXCl-6CIeSMauAAYNPMDBCfQCN2-1024.npz
eval_Episode has 500 steps and return 228.4.
train_Episode has 500 steps and return 213.8.
Saved chunk: 20230922T001032F965170-2du4tfwabxQo3hJdvIDeld-4mxZMXUEUHinjnkIINufLZ-1024.npz
Starting evaluation at step 125000 Counter(125000) 124937
eval_Episode has 500 steps and return 228.4.
train_Episode has 500 steps and return 267.7.
Starting evaluation at step 125500 Counter(125500) 125437
Saved chunk: 20230922T001119F824295-6CIeSMauAAYNPMDBCfQCN2-7cCyU84T3n69mSzXqC8ndV-1024.npz
eval_Episode has 500 steps and return 241.3.
train_Episode has 500 steps and return 232.2.
Saved chunk: 20230922T001153F492698-4mxZMXUEUHinjnkIINufLZ-6ySsmVjzgZHApZbR798vYC-1024.npz
Starting evaluation at step 126000 Counter(126000) 125937
eval_Episode has 500 steps and return 276.1.
train_Episode has 500 steps and return 203.0.
Starting evaluation at step 126500 Counter(126500) 126437
Saved chunk: 20230922T001238F700956-7cCyU84T3n69mSzXqC8ndV-00DTzAztS7dboZZcMVJ4fL-1024.npz
eval_Episode has 500 steps and return 259.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T001357F346460-00DTzAztS7dboZZcMVJ4fL-0000000000000000000000-376.npz
Saved chunk: 20230922T001313F804743-6ySsmVjzgZHApZbR798vYC-0000000000000000000000-648.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 232.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 253666 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 232.46 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 259.3 / eval_episode/reward_rate 0.49 / train/action_mag 2.66 / train/action_max 2.64 / train/action_mean 0.05 / train/action_min -2.05 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.36 / train/actor_opt_grad_steps 6.2e4 / train/actor_opt_loss -41.78 / train/adv_mag 0.58 / train/adv_max 0.42 / train/adv_mean 5.2e-3 / 
train/adv_min -0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 8e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.2 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 6.2e4 / 
train/extr_critic_critic_opt_loss 8652.52 / train/extr_critic_mag 180.47 / train/extr_critic_max 180.47 / train/extr_critic_mean 173.33 / train/extr_critic_min 155.43 / train/extr_critic_std 4.97 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 181.93 / train/extr_return_raw_max 181.93 / train/extr_return_raw_mean 173.42 / train/extr_return_raw_min 
154.72 / train/extr_return_raw_std 5.06 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.22 / train/extr_reward_min 0 / train/extr_reward_std 0.44 / train/image_loss_mean 1.56 / train/image_loss_std 1.23 / train/model_loss_mean 4.23 /
train/model_loss_std 4.75 / train/model_opt_grad_norm 10.21 / train/model_opt_grad_steps 6.2e4 / train/model_opt_loss 4.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.41 / train/policy_entropy_mean -3.05 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3.04 / train/policy_logprob_min -7.9 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.43 / train/policy_randomness_max 0.43 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.3e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 48.5 / train/post_ent_max 48.5 / train/post_ent_mean 38.34 / 
train/post_ent_min 19.31 / train/post_ent_std 5.44 / train/prior_ent_mag 71.23 / train/prior_ent_max 71.23 / train/prior_ent_mean 42.55 / train/prior_ent_min 25.77 / train/prior_ent_std 5.9 / train/rep_loss_mean 4.2 / train/rep_loss_std 6.29 / train/reward_avg 0.2 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred 0.2 / train/reward_rate 
0.22 / train_stats/mean_log_entropy -3.11 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.3e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.15 / report/dyn_loss_std 6.25 / report/image_loss_mean 1.71 / report/image_loss_std 1.03 / report/model_loss_mean 4.32 / report/model_loss_std 4.53 / report/post_ent_mag 48.37 / report/post_ent_max 48.37 /
report/post_ent_mean 37.02 / report/post_ent_min 17.93 / report/post_ent_std 6 / report/prior_ent_mag 71.12 / report/prior_ent_max 71.12 / report/prior_ent_mean 41.15 / report/prior_ent_min 20.47 / report/prior_ent_std 6.66 / report/rep_loss_mean 4.15 / 
report/rep_loss_std 6.25 / report/reward_avg 0.17 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.27 / report/reward_max_data 1.86 / report/reward_max_pred 1.81 / report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.17 / report/reward_rate 0.19 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.47 / eval/dyn_loss_std 6.87 / eval/image_loss_mean 1.75 / eval/image_loss_std 2.01 / eval/model_loss_mean 5.15 / eval/model_loss_std 5.59 / eval/post_ent_mag 48.78 / eval/post_ent_max 48.78 / eval/post_ent_mean 
37.88 / eval/post_ent_min 18.98 / eval/post_ent_std 5.65 / eval/prior_ent_mag 71.12 / eval/prior_ent_max 71.12 / eval/prior_ent_mean 41.79 / eval/prior_ent_min 25.56 / eval/prior_ent_std 6.41 / eval/rep_loss_mean 5.47 / eval/rep_loss_std 6.87 / eval/reward_avg 0.15 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.15 / eval/reward_rate 0.17 /
replay/size 1.3e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3832 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458.91 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7339 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.3e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1916 / timer/agent.train_total 244.1 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T001313F804743-6ySsmVjzgZHApZbR798vYC-2fBrYmPdJ3b3LKMfaCBSiq-1024.npz
Starting evaluation at step 127000 Counter(127000) 126937
eval_Episode has 500 steps and return 238.5.
train_Episode has 500 steps and return 231.4.
Starting evaluation at step 127500 Counter(127500) 127437
Saved chunk: 20230922T001357F346460-00DTzAztS7dboZZcMVJ4fL-10f67FANkS2dEhJPCCuyBE-1024.npz
eval_Episode has 500 steps and return 244.6.
train_Episode has 500 steps and return 228.6.
Starting evaluation at step 128000 Counter(128000) 127937
Saved chunk: 20230922T001434F848570-2fBrYmPdJ3b3LKMfaCBSiq-0qrRQVTMCY9AEOfBNVSCOQ-1024.npz
eval_Episode has 500 steps and return 257.3.
train_Episode has 500 steps and return 253.0.
Starting evaluation at step 128500 Counter(128500) 128437
Saved chunk: 20230922T001517F180184-10f67FANkS2dEhJPCCuyBE-2JX7OpSXEGs0Y6o6aJdfYz-1024.npz
eval_Episode has 500 steps and return 267.1.
train_Episode has 500 steps and return 232.3.
Starting evaluation at step 129000 Counter(129000) 128937
eval_Episode has 500 steps and return 259.8.
Saved chunk: 20230922T001555F538764-0qrRQVTMCY9AEOfBNVSCOQ-7pmEgyYqbTz9CGqh3lyNOP-1024.npz
train_Episode has 500 steps and return 258.3.
Starting evaluation at step 129500 Counter(129500) 129437
Saved chunk: 20230922T001636F127887-2JX7OpSXEGs0Y6o6aJdfYz-1ybY11DH7KtU16kwkVTTIe-1024.npz
eval_Episode has 500 steps and return 219.4.
train_Episode has 500 steps and return 239.9.
Starting evaluation at step 130000 Counter(130000) 129937
eval_Episode has 500 steps and return 254.5.
Saved chunk: 20230922T001719F519510-7pmEgyYqbTz9CGqh3lyNOP-2oAF1slO09ey3TEztwtdnm-1024.npz
train_Episode has 500 steps and return 218.1.
Starting evaluation at step 130500 Counter(130500) 130437
Saved chunk: 20230922T001754F799289-1ybY11DH7KtU16kwkVTTIe-2J2KVcK7QfufZ5GkZtxXT2-1024.npz
eval_Episode has 500 steps and return 264.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 261242 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 264.93 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 218.09 / episode/reward_rate 0.45 / train/action_mag 2.77 / train/action_max 2.7 / train/action_mean 0.04 / train/action_min -2.4 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.4 / train/actor_opt_grad_steps 6.4e4 / train/actor_opt_loss -52.24 / train/adv_mag 0.68 / train/adv_max 0.53 / train/adv_mean 6.2e-3 / train/adv_min
-0.53 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 7.6e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.2 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 6.4e4 / 
train/extr_critic_critic_opt_loss 8097.75 / train/extr_critic_mag 183.56 / train/extr_critic_max 183.56 / train/extr_critic_mean 174.39 / train/extr_critic_min 153.76 / train/extr_critic_std 5.31 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.13 / 
train/extr_return_normed_mean 0.59 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 184.01 / train/extr_return_raw_max 184.01 / train/extr_return_raw_mean 174.5 / train/extr_return_raw_min 
155.02 / train/extr_return_raw_std 5.42 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.21 / train/extr_reward_min 0 / train/extr_reward_std 0.44 / train/image_loss_mean 1.56 / train/image_loss_std 1.22 / train/model_loss_mean 4.22 /
train/model_loss_std 4.74 / train/model_opt_grad_norm 10.04 / train/model_opt_grad_steps 6.4e4 / train/model_opt_loss 4.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.65 / train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 7.85 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3.01 / train/policy_logprob_min -7.85 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.45 / train/policy_randomness_max 0.45 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 48.48 / train/post_ent_max 48.48 / train/post_ent_mean 38.44 / 
train/post_ent_min 19.11 / train/post_ent_std 5.43 / train/prior_ent_mag 71.32 / train/prior_ent_max 71.32 / train/prior_ent_mean 42.66 / train/prior_ent_min 26.18 / train/prior_ent_std 5.88 / train/rep_loss_mean 4.2 / train/rep_loss_std 6.29 / train/reward_avg 0.2 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.3 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred 0.2 / train/reward_rate 
0.22 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.12 / report/cont_avg 1 / report/cont_loss_mean 7e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.03 / report/image_loss_mean 1.32 / report/image_loss_std 0.82 / report/model_loss_mean 3.85 / report/model_loss_std 4.25 / report/post_ent_mag 48.76 / report/post_ent_max 48.76 /
report/post_ent_mean 39.07 / report/post_ent_min 20.42 / report/post_ent_std 5.71 / report/prior_ent_mag 71.46 / report/prior_ent_max 71.46 / report/prior_ent_mean 42.82 / report/prior_ent_min 25.87 / report/prior_ent_std 6.36 / report/rep_loss_mean 3.95 / 
report/rep_loss_std 6.03 / report/reward_avg 0.27 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 8.4e-4 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.27 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.05 / eval/dyn_loss_std 8.2 / eval/image_loss_mean 1.97 / eval/image_loss_std 2.53 / eval/model_loss_mean 5.76 / eval/model_loss_std 7.05 / eval/post_ent_mag 48.22 / eval/post_ent_max 48.22 / eval/post_ent_mean 
37.62 / eval/post_ent_min 19.7 / eval/post_ent_std 6.68 / eval/prior_ent_mag 71.46 / eval/prior_ent_max 71.46 / eval/prior_ent_mean 41.99 / eval/prior_ent_min 23.54 / eval/prior_ent_std 6.71 / eval/rep_loss_mean 6.05 / eval/rep_loss_std 8.2 / eval/reward_avg 0.23 / 
eval/reward_loss_mean 0.16 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.91 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.23 / eval/reward_rate 0.25 / 
replay/size 1.3e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3788 / timer/env.step_total 19.56 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-4 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 17.89 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.8e-3 
/ timer/dataset_train_count 1894 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1894 / timer/agent.train_total 241.12 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 261.9.
Starting evaluation at step 131000 Counter(131000) 130937
eval_Episode has 500 steps and return 256.1.
Saved chunk: 20230922T001839F621716-2oAF1slO09ey3TEztwtdnm-3P9IA3cZtmkCty8WQMnucx-1024.npz
train_Episode has 500 steps and return 244.5.
Starting evaluation at step 131500 Counter(131500) 131437
Saved chunk: 20230922T001913F351506-2J2KVcK7QfufZ5GkZtxXT2-3mt6Ijt8n4qQUEducMaUJH-1024.npz
eval_Episode has 500 steps and return 233.1.
train_Episode has 500 steps and return 211.9.
Starting evaluation at step 132000 Counter(132000) 131937
eval_Episode has 500 steps and return 233.2.
Saved chunk: 20230922T002000F777033-3P9IA3cZtmkCty8WQMnucx-4m9cmeYnY1xSRzbbIxekeQ-1024.npz
train_Episode has 500 steps and return 239.5.
Starting evaluation at step 132500 Counter(132500) 132437
Saved chunk: 20230922T002033F219300-3mt6Ijt8n4qQUEducMaUJH-0LE6HU0RStBmCyNUSV2ufp-1024.npz
eval_Episode has 500 steps and return 220.9.
train_Episode has 500 steps and return 255.4.
Starting evaluation at step 133000 Counter(133000) 132937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002121F530800-4m9cmeYnY1xSRzbbIxekeQ-7F43Sefo3egeXx0qB5YBCL-1024.npz
train_Episode has 500 steps and return 223.1.
Starting evaluation at step 133500 Counter(133500) 133437
Saved chunk: 20230922T002152F295646-0LE6HU0RStBmCyNUSV2ufp-0r1lyYQgfHrw80UMUiqxXM-1024.npz
eval_Episode has 500 steps and return 248.1.
train_Episode has 500 steps and return 174.9.
Starting evaluation at step 134000 Counter(134000) 133937
eval_Episode has 500 steps and return 107.6.
Saved chunk: 20230922T002241F937742-7F43Sefo3egeXx0qB5YBCL-6mUalderFCac63ruWbg3NB-1024.npz
train_Episode has 500 steps and return 100.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 268902 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 100.91 / episode/reward_rate 0.32 / eval_episode/length 500 / eval_episode/score 107.61 / eval_episode/reward_rate 0.36 / train/action_mag 2.77 / train/action_max 2.74 / train/action_mean 0.07 / train/action_min -2.25 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.37 / train/actor_opt_grad_steps 6.6e4 / train/actor_opt_loss -9.96 / train/adv_mag 1.07 / train/adv_max 0.85 / train/adv_mean 
1.9e-3 / train/adv_min -1 / train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 7.4e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.4e-11 / train/cont_pred 1 / train/cont_rate 1
/ train/dyn_loss_mean 4.17 / train/dyn_loss_std 6.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 6.6e4 / 
train/extr_critic_critic_opt_loss 8633.99 / train/extr_critic_mag 184.63 / train/extr_critic_max 184.63 / train/extr_critic_mean 172.92 / train/extr_critic_min 130.13 / train/extr_critic_std 9.9 / train/extr_return_normed_mag 1.07 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.67 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 185.15 / train/extr_return_raw_max 185.15 / train/extr_return_raw_mean 172.97 / train/extr_return_raw_min 
130.6 / train/extr_return_raw_std 10.34 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.21 / train/extr_reward_min 0 / train/extr_reward_std 0.43 / train/image_loss_mean 1.52 / train/image_loss_std 1.2 / train/model_loss_mean 4.17 / 
train/model_loss_std 4.73 / train/model_opt_grad_norm 9.91 / train/model_opt_grad_steps 6.6e4 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.9 / train/policy_entropy_mean -2.88 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.64 / train/policy_logprob_mag 8.35 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.89 / train/policy_logprob_min -8.35 / 
train/policy_logprob_std 1.56 / train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 6.1e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 48.74 / train/post_ent_max 48.74 / 
train/post_ent_mean 38.74 / train/post_ent_min 19.3 / train/post_ent_std 5.46 / train/prior_ent_mag 71.44 / train/prior_ent_max 71.44 / train/prior_ent_mean 42.93 / train/prior_ent_min 26.55 / train/prior_ent_std 5.88 / train/rep_loss_mean 4.17 / train/rep_loss_std 6.31
/ train/reward_avg 0.21 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.3 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred 
0.21 / train/reward_rate 0.23 / train_stats/mean_log_entropy -3.08 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.7e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 8.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.94 / report/dyn_loss_std 5.98 / report/image_loss_mean 1.41 / report/image_loss_std 1.12 / report/model_loss_mean 3.97 / report/model_loss_std 4.58 / report/post_ent_mag 49 /
report/post_ent_max 49 / report/post_ent_mean 39.72 / report/post_ent_min 20.35 / report/post_ent_std 5.35 / report/prior_ent_mag 71.47 / report/prior_ent_max 71.47 / report/prior_ent_mean 43.85 / report/prior_ent_min 27.37 / report/prior_ent_std 5.64 / 
report/rep_loss_mean 3.94 / report/rep_loss_std 5.98 / report/reward_avg 0.28 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.64 / report/reward_pred 0.27 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.96 / eval/dyn_loss_std 9.31 / eval/image_loss_mean 2.54 / eval/image_loss_std 2.67 / eval/model_loss_mean 7.45 / eval/model_loss_std 7.83 / eval/post_ent_mag 49.76 / 
eval/post_ent_max 49.76 / eval/post_ent_mean 37.48 / eval/post_ent_min 16.25 / eval/post_ent_std 6.42 / eval/prior_ent_mag 71.47 / eval/prior_ent_max 71.47 / eval/prior_ent_mean 43.22 / eval/prior_ent_min 31.3 / eval/prior_ent_std 5.47 / eval/rep_loss_mean 7.96 / 
eval/rep_loss_std 9.31 / eval/reward_avg 0.17 / eval/reward_loss_mean 0.13 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.78 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-3 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.67 / 
eval/reward_pred 0.17 / eval/reward_rate 0.19 / replay/size 1.3e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3830 / timer/env.step_total 19.85 / 
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 452.92 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7337 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.4e-4 
/ timer/agent.train_count 1915 / timer/agent.train_total 244.04 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / 
timer/dataset_eval_max 4.4e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 134500 Counter(134500) 134437
Saved chunk: 20230922T002311F053801-0r1lyYQgfHrw80UMUiqxXM-105gOIXqAkz0dRLm6lzNli-1024.npz
eval_Episode has 500 steps and return 237.5.
train_Episode has 500 steps and return 224.0.
Starting evaluation at step 135000 Counter(135000) 134937
eval_Episode has 500 steps and return 245.5.
Saved chunk: 20230922T002402F124099-6mUalderFCac63ruWbg3NB-0iAAmsaEJsX4TATIzvXekU-1024.npz
train_Episode has 500 steps and return 203.5.
Starting evaluation at step 135500 Counter(135500) 135437
Saved chunk: 20230922T002430F393304-105gOIXqAkz0dRLm6lzNli-5e7zTw9yGuE6ilI9YvMSSQ-1024.npz
eval_Episode has 500 steps and return 230.6.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 136000 Counter(136000) 135937
eval_Episode has 500 steps and return 6.1.
Saved chunk: 20230922T002523F440148-0iAAmsaEJsX4TATIzvXekU-5kQTlKJkrg8MdtUgq8jCzz-1024.npz
train_Episode has 500 steps and return 92.4.
Starting evaluation at step 136500 Counter(136500) 136437
Saved chunk: 20230922T002549F661026-5e7zTw9yGuE6ilI9YvMSSQ-25rH7lHQF3rh3H2xY49QtW-1024.npz
eval_Episode has 500 steps and return 198.6.
train_Episode has 500 steps and return 177.2.
Starting evaluation at step 137000 Counter(137000) 136937
eval_Episode has 500 steps and return 189.8.
Saved chunk: 20230922T002644F162670-5kQTlKJkrg8MdtUgq8jCzz-3wQuSPft1KEzTKIwWkDbIl-1024.npz
train_Episode has 500 steps and return 185.4.
Starting evaluation at step 137500 Counter(137500) 137437
Saved chunk: 20230922T002708F652648-25rH7lHQF3rh3H2xY49QtW-4dunDLya7iDOaWodvXJPPV-1024.npz
eval_Episode has 500 steps and return 255.6.
train_Episode has 500 steps and return 221.5.
Starting evaluation at step 138000 Counter(138000) 137937
eval_Episode has 500 steps and return 244.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T002827F271105-4dunDLya7iDOaWodvXJPPV-0000000000000000000000-635.npz
Saved chunk: 20230922T002804F441724-3wQuSPft1KEzTKIwWkDbIl-0000000000000000000000-884.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 276462 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 244.69 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 221.46 / episode/reward_rate 0.4 / train/action_mag 2.96 / train/action_max 2.94 / train/action_mean 0.1 / train/action_min -2.25 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 6.8e4 / train/actor_opt_loss -64.13 / train/adv_mag 1.3 / train/adv_max 1.08 / train/adv_mean 7.4e-3 / train/adv_min
-1.18 / train/adv_std 0.1 / train/cont_avg 1 / train/cont_loss_mean 7.2e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.14 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.21 / train/extr_critic_critic_opt_grad_steps 6.8e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 180.48 / train/extr_critic_max 180.48 / train/extr_critic_mean 166.4 / train/extr_critic_min 94.75 / train/extr_critic_std 16.47 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.7 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 181.21 / train/extr_return_raw_max 181.21 / train/extr_return_raw_mean 166.78 / train/extr_return_raw_min 
95.61 / train/extr_return_raw_std 16.81 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.21 / train/extr_reward_min 0 / train/extr_reward_std 0.44 / train/image_loss_mean 1.52 / train/image_loss_std 1.19 / train/model_loss_mean 4.15 /
train/model_loss_std 4.69 / train/model_opt_grad_norm 9.99 / train/model_opt_grad_steps 6.8e4 / train/model_opt_loss 4.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.6 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.71 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -8.71 / train/policy_logprob_std 1.64 / 
train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 8.6e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 48.87 / train/post_ent_max 48.87 / train/post_ent_mean 38.82 / 
train/post_ent_min 19.25 / train/post_ent_std 5.57 / train/prior_ent_mag 71.55 / train/prior_ent_max 71.55 / train/prior_ent_mean 42.97 / train/prior_ent_min 26.1 / train/prior_ent_std 6.01 / train/rep_loss_mean 4.14 / train/rep_loss_std 6.27 / train/reward_avg 0.21 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.3 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred 0.21 / train/reward_rate 
0.23 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.49 / report/cont_avg 1 / report/cont_loss_mean 6.8e-11 / report/cont_loss_std 2.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.23 / report/dyn_loss_std 6.36 / report/image_loss_mean 1.49 / report/image_loss_std 1.32 / report/model_loss_mean 4.2 / report/model_loss_std 4.86 / report/post_ent_mag 49.03 / report/post_ent_max 49.03 / 
report/post_ent_mean 40.62 / report/post_ent_min 20.09 / report/post_ent_std 4.81 / report/prior_ent_mag 71.56 / report/prior_ent_max 71.56 / report/prior_ent_mean 44.8 / report/prior_ent_min 30.15 / report/prior_ent_std 4.84 / report/rep_loss_mean 4.23 / 
report/rep_loss_std 6.36 / report/reward_avg 0.22 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.32 / report/reward_max_data 1.89 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.64 / report/reward_pred 0.22 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.51 / eval/dyn_loss_std 8.9 / eval/image_loss_mean 2.34 / eval/image_loss_std 3.49 / eval/model_loss_mean 6.4 / eval/model_loss_std 8.33 / eval/post_ent_mag 48.78 / eval/post_ent_max 48.78 / eval/post_ent_mean 
39.49 / eval/post_ent_min 20.27 / eval/post_ent_std 5.27 / eval/prior_ent_mag 71.56 / eval/prior_ent_max 71.56 / eval/prior_ent_mean 44.23 / eval/prior_ent_min 31.69 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 6.51 / eval/rep_loss_std 8.9 / eval/reward_avg 0.19 / 
eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.83 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.2e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.67 / eval/reward_pred 0.19 / eval/reward_rate 0.22 / 
replay/size 1.4e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3780 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.3 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7788 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1890 / timer/agent.train_total 240.8 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T002804F441724-3wQuSPft1KEzTKIwWkDbIl-7zzHY88DkGO8vzbtDeikQY-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 222.6.
Starting evaluation at step 138500 Counter(138500) 138437
Saved chunk: 20230922T002827F271105-4dunDLya7iDOaWodvXJPPV-50Q1SrjA9T5sFkJka9iEJS-1024.npz
eval_Episode has 500 steps and return 234.2.
train_Episode has 500 steps and return 228.7.
Starting evaluation at step 139000 Counter(139000) 138937
eval_Episode has 500 steps and return 212.6.
Saved chunk: 20230922T002925F144217-7zzHY88DkGO8vzbtDeikQY-6LOCdobdmnHYXzZctRWAJX-1024.npz
train_Episode has 500 steps and return 213.2.
Starting evaluation at step 139500 Counter(139500) 139437
Saved chunk: 20230922T002946F924484-50Q1SrjA9T5sFkJka9iEJS-3zvMxztVLvrDlxhZMbYadw-1024.npz
eval_Episode has 500 steps and return 265.2.
train_Episode has 500 steps and return 252.4.
Starting evaluation at step 140000 Counter(140000) 139937
eval_Episode has 500 steps and return 270.1.
train_Episode has 500 steps and return 244.1.
Saved chunk: 20230922T003046F147251-6LOCdobdmnHYXzZctRWAJX-4adhZYGZsPfPTKqud41NNM-1024.npz
Starting evaluation at step 140500 Counter(140500) 140437
Saved chunk: 20230922T003105F976849-3zvMxztVLvrDlxhZMbYadw-79UQkJQAuLXzDldawaxtxy-1024.npz
eval_Episode has 500 steps and return 289.4.
train_Episode has 500 steps and return 254.8.
Starting evaluation at step 141000 Counter(141000) 140937
eval_Episode has 500 steps and return 260.7.
train_Episode has 500 steps and return 232.1.
Saved chunk: 20230922T003206F620692-4adhZYGZsPfPTKqud41NNM-56I8MNqp3unyqwGoVuCETc-1024.npz
Starting evaluation at step 141500 Counter(141500) 141437
Saved chunk: 20230922T003224F871009-79UQkJQAuLXzDldawaxtxy-2NPzsB5RIprHDh1V1s8OBG-1024.npz
eval_Episode has 500 steps and return 273.9.
train_Episode has 500 steps and return 236.3.
Starting evaluation at step 142000 Counter(142000) 141937
eval_Episode has 500 steps and return 296.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 284036 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 236.28 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 296.37 / eval_episode/reward_rate 0.53 / train/action_mag 2.96 / train/action_max 2.95 / train/action_mean 0.08 / train/action_min -2.24 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.39 / train/actor_opt_grad_steps 7e4 / train/actor_opt_loss -154.82 / train/adv_mag 0.88 / train/adv_max 0.8 / train/adv_mean 0.02 /
train/adv_min -0.68 / train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 7.8e-11 / train/cont_loss_std 4.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.15 / train/dyn_loss_std 6.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 7e4 / 
train/extr_critic_critic_opt_loss 8248.87 / train/extr_critic_mag 185.08 / train/extr_critic_max 185.08 / train/extr_critic_mean 174.14 / train/extr_critic_min 133.08 / train/extr_critic_std 9.45 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.68 / train/extr_return_normed_min -0.57 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 185.47 / train/extr_return_raw_max 185.47 / train/extr_return_raw_mean 174.68 / train/extr_return_raw_min 
135.27 / train/extr_return_raw_std 9.1 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.23 / train/extr_reward_min 0 / train/extr_reward_std 0.46 / train/image_loss_mean 1.5 / train/image_loss_std 1.19 / train/model_loss_mean 4.14 / 
train/model_loss_std 4.69 / train/model_opt_grad_norm 10.09 / train/model_opt_grad_steps 6.9e4 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8174.6 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.57 / train/policy_entropy_mean -2.72 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.73 / train/policy_logprob_mag 8.54 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.71 / train/policy_logprob_min -8.54 / 
train/policy_logprob_std 1.6 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 8.3e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 49.1 / train/post_ent_max 49.1 / 
train/post_ent_mean 39.17 / train/post_ent_min 19.44 / train/post_ent_std 5.54 / train/prior_ent_mag 71.68 / train/prior_ent_max 71.68 / train/prior_ent_mean 43.34 / train/prior_ent_min 26.43 / train/prior_ent_std 5.91 / train/rep_loss_mean 4.15 / train/rep_loss_std 
6.25 / train/reward_avg 0.22 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.31 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / 
train/reward_pred 0.22 / train/reward_rate 0.24 / train_stats/mean_log_entropy -2.89 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.2e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 9.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.18 / report/dyn_loss_std 6.19 / report/image_loss_mean 1.43 / report/image_loss_std 1.25 / report/model_loss_mean 4.13 / report/model_loss_std 4.72 / 
report/post_ent_mag 49.49 / report/post_ent_max 49.49 / report/post_ent_mean 40.91 / report/post_ent_min 19.2 / report/post_ent_std 4.9 / report/prior_ent_mag 71.6 / report/prior_ent_max 71.6 / report/prior_ent_mean 45.04 / report/prior_ent_min 26.05 / 
report/prior_ent_std 4.85 / report/rep_loss_mean 4.18 / report/rep_loss_std 6.19 / report/reward_avg 0.29 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.34 / report/reward_max_data 1.9 / report/reward_max_pred 1.93 / report/reward_neg_acc 0.99 / 
report/reward_neg_loss 8.5e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.62 / report/reward_pred 0.3 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 6.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.11 / eval/dyn_loss_std 9.78 / eval/image_loss_mean 2.75 / eval/image_loss_std 4.46 / eval/model_loss_mean 7.23 / eval/model_loss_std 9.82 / eval/post_ent_mag 
49.34 / eval/post_ent_max 49.34 / eval/post_ent_mean 39.43 / eval/post_ent_min 19.65 / eval/post_ent_std 5.75 / eval/prior_ent_mag 71.6 / eval/prior_ent_max 71.6 / eval/prior_ent_mean 44.27 / eval/prior_ent_min 31.74 / eval/prior_ent_std 5.33 / eval/rep_loss_mean 7.11 /
eval/rep_loss_std 9.78 / eval/reward_avg 0.26 / eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.52 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.68 / 
eval/reward_pred 0.26 / eval/reward_rate 0.28 / replay/size 1.4e5 / replay/inserts 3787 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3787 / timer/env.step_total 19.65
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3e4 / timer/replay._sample_total 446.51 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.7e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7795 / timer/agent.policy_total 17.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 7.8e-4 / 
timer/agent.train_count 1893 / timer/agent.train_total 240.9 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / 
timer/dataset_eval_max 4.5e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 245.6.
Saved chunk: 20230922T003326F773543-56I8MNqp3unyqwGoVuCETc-7lEPlRkLJFp2lvntjqnht5-1024.npz
Starting evaluation at step 142500 Counter(142500) 142437
eval_Episode has 500 steps and return 269.7.
Saved chunk: 20230922T003343F373149-2NPzsB5RIprHDh1V1s8OBG-5mIk2TXA8z4julKsit0Xg0-1024.npz
train_Episode has 500 steps and return 257.5.
Starting evaluation at step 143000 Counter(143000) 142937
eval_Episode has 500 steps and return 270.2.
train_Episode has 500 steps and return 266.7.
Saved chunk: 20230922T003447F665164-7lEPlRkLJFp2lvntjqnht5-0xFdySMwb06yB8JuBaA1FV-1024.npz
Starting evaluation at step 143500 Counter(143500) 143437
eval_Episode has 500 steps and return 218.7.
Saved chunk: 20230922T003502F870396-5mIk2TXA8z4julKsit0Xg0-5EISaPLauav7hoCW9FESOv-1024.npz
train_Episode has 500 steps and return 198.9.
Starting evaluation at step 144000 Counter(144000) 143937
eval_Episode has 500 steps and return 243.4.
train_Episode has 500 steps and return 200.2.
Saved chunk: 20230922T003608F346291-0xFdySMwb06yB8JuBaA1FV-0QDfgwwJCJiUbltgo4Zlgn-1024.npz
Starting evaluation at step 144500 Counter(144500) 144437
eval_Episode has 500 steps and return 258.6.
train_Episode has 500 steps and return 240.6.
Starting evaluation at step 145000 Counter(145000) 144937
Saved chunk: 20230922T003621F917086-5EISaPLauav7hoCW9FESOv-6Wd86jersj9PaBYP8Z7vTy-1024.npz
eval_Episode has 500 steps and return 273.6.
train_Episode has 500 steps and return 264.3.
Saved chunk: 20230922T003728F772449-0QDfgwwJCJiUbltgo4Zlgn-2nnMcGktxZB2yBJqMeyEQW-1024.npz
Starting evaluation at step 145500 Counter(145500) 145437
eval_Episode has 500 steps and return 275.5.
train_Episode has 500 steps and return 265.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 291706 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 265.63 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 275.5 / eval_episode/reward_rate 0.5 / train/action_mag 3.05 / train/action_max 3.04 / train/action_mean 0.08 / train/action_min -2.16 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 7.1e4 / train/actor_opt_loss -14.99 / train/adv_mag 1.12 / train/adv_max 0.88 / train/adv_mean 2.4e-3 / 
train/adv_min -1.06 / train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 6.3e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.12 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 7.1e4 / 
train/extr_critic_critic_opt_loss 8171.11 / train/extr_critic_mag 188.31 / train/extr_critic_max 188.31 / train/extr_critic_mean 176.72 / train/extr_critic_min 123.39 / train/extr_critic_std 11.3 / train/extr_return_normed_mag 1.08 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.72 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 188.94 / train/extr_return_raw_max 188.94 / train/extr_return_raw_mean 176.79 / train/extr_return_raw_min 
123.46 / train/extr_return_raw_std 11.88 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.23 / train/extr_reward_min 0 / train/extr_reward_std 0.46 / train/image_loss_mean 1.48 / train/image_loss_std 1.17 / train/model_loss_mean 4.11 
/ train/model_loss_std 4.69 / train/model_opt_grad_norm 9.97 / train/model_opt_grad_steps 7.1e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9192.71 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.37 / train/policy_entropy_mean -2.76 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.73 / train/policy_logprob_mag 8.45 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.76 / train/policy_logprob_min -8.45 / 
train/policy_logprob_std 1.59 / train/policy_randomness_mag 0.53 / train/policy_randomness_max 0.53 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 7.3e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 49.17 / train/post_ent_max 49.17 / 
train/post_ent_mean 39.25 / train/post_ent_min 19.6 / train/post_ent_std 5.53 / train/prior_ent_mag 71.76 / train/prior_ent_max 71.76 / train/prior_ent_mean 43.38 / train/prior_ent_min 26.71 / train/prior_ent_std 5.93 / train/rep_loss_mean 4.12 / train/rep_loss_std 6.27
/ train/reward_avg 0.23 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.31 / train/reward_max_data 1.96 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred
0.23 / train/reward_rate 0.24 / train_stats/mean_log_entropy -2.95 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.5e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.92 / report/dyn_loss_std 5.79 / report/image_loss_mean 1.41 / report/image_loss_std 1.05 / report/model_loss_mean 3.89 / report/model_loss_std 4.3 / report/post_ent_mag 49.11
/ report/post_ent_max 49.11 / report/post_ent_mean 40.04 / report/post_ent_min 23.13 / report/post_ent_std 4.99 / report/prior_ent_mag 71.72 / report/prior_ent_max 71.72 / report/prior_ent_mean 44.03 / report/prior_ent_min 29.29 / report/prior_ent_std 4.93 / 
report/rep_loss_mean 3.92 / report/rep_loss_std 5.79 / report/reward_avg 0.22 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.27 / report/reward_max_data 1.94 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.22 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.26 / eval/dyn_loss_std 7.97 / eval/image_loss_mean 2.23 / eval/image_loss_std 2.66 / eval/model_loss_mean 6.14 / eval/model_loss_std 6.95 / eval/post_ent_mag 49.18 / 
eval/post_ent_max 49.18 / eval/post_ent_mean 39.13 / eval/post_ent_min 16.65 / eval/post_ent_std 6 / eval/prior_ent_mag 71.72 / eval/prior_ent_max 71.72 / eval/prior_ent_mean 44.16 / eval/prior_ent_min 32.97 / eval/prior_ent_std 5.04 / eval/rep_loss_mean 6.26 / 
eval/rep_loss_std 7.97 / eval/reward_avg 0.21 / eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / 
eval/reward_pred 0.21 / eval/reward_rate 0.22 / replay/size 1.5e5 / replay/inserts 3835 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3835 / timer/env.step_total 19.82
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.66 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 7.3e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7342 / timer/agent.policy_total 17.02 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.8e-3 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.3e-4 
/ timer/agent.train_count 1918 / timer/agent.train_total 244.24 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / 
timer/dataset_eval_max 4.4e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 146000 Counter(146000) 145937
Saved chunk: 20230922T003816F471722-6Wd86jersj9PaBYP8Z7vTy-4pjXtEya0EMSB9MIEqgwta-1024.npz
eval_Episode has 500 steps and return 282.0.
train_Episode has 500 steps and return 238.6.
Saved chunk: 20230922T003848F956582-2nnMcGktxZB2yBJqMeyEQW-7s0fmILdSMtDDd8O5Ik4pW-1024.npz
Starting evaluation at step 146500 Counter(146500) 146437
eval_Episode has 500 steps and return 264.1.
train_Episode has 500 steps and return 232.0.
Starting evaluation at step 147000 Counter(147000) 146937
Saved chunk: 20230922T003935F741775-4pjXtEya0EMSB9MIEqgwta-2wEVXHEDNy1NnGI4VriTnu-1024.npz
eval_Episode has 500 steps and return 248.6.
train_Episode has 500 steps and return 221.0.
Saved chunk: 20230922T004010F135811-7s0fmILdSMtDDd8O5Ik4pW-5ZX7ibP5Ck2UfOA6Nnofo1-1024.npz
Starting evaluation at step 147500 Counter(147500) 147437
eval_Episode has 500 steps and return 227.3.
train_Episode has 500 steps and return 238.3.
Starting evaluation at step 148000 Counter(148000) 147937
Saved chunk: 20230922T004054F995788-2wEVXHEDNy1NnGI4VriTnu-3zC95lnYimYNkkhBSuXEGv-1024.npz
eval_Episode has 500 steps and return 197.6.
train_Episode has 500 steps and return 274.9.
Saved chunk: 20230922T004130F858418-5ZX7ibP5Ck2UfOA6Nnofo1-3baltPYo3KFiPOWrk2cRx8-1024.npz
Starting evaluation at step 148500 Counter(148500) 148437
eval_Episode has 500 steps and return 290.5.
train_Episode has 500 steps and return 240.1.
Starting evaluation at step 149000 Counter(149000) 148937
Saved chunk: 20230922T004214F020988-3zC95lnYimYNkkhBSuXEGv-6ARssfkOdCps3IrzlBq9c7-1024.npz
eval_Episode has 500 steps and return 285.7.
train_Episode has 500 steps and return 245.7.
Starting evaluation at step 149500 Counter(149500) 149437
eval_Episode has 500 steps and return 274.4.
Saved chunk: 20230922T004251F285249-3baltPYo3KFiPOWrk2cRx8-3wsH6MeWCDwoglFr2NkdIU-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T004332F703423-6ARssfkOdCps3IrzlBq9c7-0000000000000000000000-894.npz
Saved chunk: 20230922T004416F050859-3wsH6MeWCDwoglFr2NkdIU-0000000000000000000000-96.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 299234 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 274.4 / eval_episode/reward_rate 0.52 / episode/length 500 / episode/score 245.68 / episode/reward_rate 0.47 / train/action_mag 3.22 / train/action_max 3.21 / train/action_mean 0.06 / train/action_min -2.12 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.4 / train/actor_opt_grad_steps 7.3e4 / train/actor_opt_loss -101.99 / train/adv_mag 0.81 / train/adv_max 0.68 / train/adv_mean 0.01 / train/adv_min 
-0.71 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 6.4e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.14 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 7.3e4 / 
train/extr_critic_critic_opt_loss 9486.26 / train/extr_critic_mag 192.24 / train/extr_critic_max 192.24 / train/extr_critic_mean 183.05 / train/extr_critic_min 150.95 / train/extr_critic_std 6.86 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.65 / train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 192.88 / train/extr_return_raw_max 192.88 / train/extr_return_raw_mean 183.31 / train/extr_return_raw_min 
153.41 / train/extr_return_raw_std 6.73 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.24 / train/extr_reward_min 0 / train/extr_reward_std 0.47 / train/image_loss_mean 1.48 / train/image_loss_std 1.19 / train/model_loss_mean 4.13 /
train/model_loss_std 4.72 / train/model_opt_grad_norm 10.04 / train/model_opt_grad_steps 7.3e4 / train/model_opt_loss 3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7340.43 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.2 / train/policy_entropy_mean -2.79 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.67 / train/policy_logprob_mag 8.35 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.79 / train/policy_logprob_min -8.35 / 
train/policy_logprob_std 1.56 / train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 8.1e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 49.38 / train/post_ent_max 49.38 / 
train/post_ent_mean 39.68 / train/post_ent_min 19.56 / train/post_ent_std 5.49 / train/prior_ent_mag 71.85 / train/prior_ent_max 71.85 / train/prior_ent_mean 43.84 / train/prior_ent_min 27.05 / train/prior_ent_std 5.78 / train/rep_loss_mean 4.14 / train/rep_loss_std 
6.29 / train/reward_avg 0.24 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.31 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / 
train/reward_pred 0.24 / train/reward_rate 0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.86 / report/cont_avg 1 / report/cont_loss_mean 6.4e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 6.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.3 / report/dyn_loss_std 6.61 / report/image_loss_mean 1.44 / report/image_loss_std 1.18 / report/model_loss_mean 4.17 / report/model_loss_std 4.89 / 
report/post_ent_mag 49.08 / report/post_ent_max 49.08 / report/post_ent_mean 39.45 / report/post_ent_min 20.17 / report/post_ent_std 5.5 / report/prior_ent_mag 71.81 / report/prior_ent_max 71.81 / report/prior_ent_mean 43.93 / report/prior_ent_min 27.65 / 
report/prior_ent_std 5.95 / report/rep_loss_mean 4.3 / report/rep_loss_std 6.61 / report/reward_avg 0.24 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.3 / report/reward_max_data 1.94 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.23 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 7e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.42 / eval/dyn_loss_std 7.5 / eval/image_loss_mean 1.99 / eval/image_loss_std 3.16 / eval/model_loss_mean 5.47 / eval/model_loss_std 7.12 / eval/post_ent_mag 49.84
/ eval/post_ent_max 49.84 / eval/post_ent_mean 41.05 / eval/post_ent_min 15.65 / eval/post_ent_std 5.49 / eval/prior_ent_mag 71.81 / eval/prior_ent_max 71.81 / eval/prior_ent_mean 45.83 / eval/prior_ent_min 31.88 / eval/prior_ent_std 4.28 / eval/rep_loss_mean 5.42 / 
eval/rep_loss_std 7.5 / eval/reward_avg 0.28 / eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.47 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.73 / 
eval/reward_pred 0.28 / eval/reward_rate 0.31 / replay/size 1.5e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3764 / timer/env.step_total 19.49
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 446.81 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 2.5e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7772 / 
timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / 
timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1882 / timer/agent.train_total 241.02 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / 
timer/agent.train_max 1.11 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 255.0.
Starting evaluation at step 150000 Counter(150000) 149937
Saved chunk: 20230922T004332F703423-6ARssfkOdCps3IrzlBq9c7-1hkR4ytrl4MVH9adFnmoDi-1024.npz
eval_Episode has 500 steps and return 283.4.
train_Episode has 500 steps and return 239.4.
Starting evaluation at step 150500 Counter(150500) 150437
eval_Episode has 500 steps and return 281.6.
Saved chunk: 20230922T004416F050859-3wsH6MeWCDwoglFr2NkdIU-6XhYqXlvtzrVBJqorfFCsh-1024.npz
train_Episode has 500 steps and return 234.2.
Starting evaluation at step 151000 Counter(151000) 150937
Saved chunk: 20230922T004453F456620-1hkR4ytrl4MVH9adFnmoDi-1vimMnAuTA3UFMbNA3vjNO-1024.npz
eval_Episode has 500 steps and return 262.5.
train_Episode has 500 steps and return 263.4.
Starting evaluation at step 151500 Counter(151500) 151437
eval_Episode has 500 steps and return 280.0.
Saved chunk: 20230922T004537F687437-6XhYqXlvtzrVBJqorfFCsh-0P9SjoumtiVwNj1HKk4L2f-1024.npz
train_Episode has 500 steps and return 274.7.
Starting evaluation at step 152000 Counter(152000) 151937
Saved chunk: 20230922T004612F620989-1vimMnAuTA3UFMbNA3vjNO-24yFnox8FtaF6eMaecXN6B-1024.npz
eval_Episode has 500 steps and return 270.9.
train_Episode has 500 steps and return 259.8.
Starting evaluation at step 152500 Counter(152500) 152437
eval_Episode has 500 steps and return 258.4.
Saved chunk: 20230922T004658F196748-0P9SjoumtiVwNj1HKk4L2f-4p8tB3tZVjWcqSmqal5xZT-1024.npz
train_Episode has 500 steps and return 261.8.
Starting evaluation at step 153000 Counter(153000) 152937
Saved chunk: 20230922T004731F440773-24yFnox8FtaF6eMaecXN6B-40HHv6JKXNbmZPjG3ZAxkg-1024.npz
eval_Episode has 500 steps and return 295.0.
train_Episode has 500 steps and return 223.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 306898 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 223.46 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 294.99 / eval_episode/reward_rate 0.5 / train/action_mag 2.7 / train/action_max 2.7 / train/action_mean 0.06 / train/action_min -1.85 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.4 / train/actor_opt_grad_steps 7.5e4 / train/actor_opt_loss -76.5 / train/adv_mag 0.54 / train/adv_max 0.39 / train/adv_mean 8.7e-3 / train/adv_min 
-0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.7e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.11 / train/dyn_loss_std 6.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 7.5e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 197 / train/extr_critic_max 197 / train/extr_critic_mean 188.6 / train/extr_critic_min 167.8 / train/extr_critic_std 5.43 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 197.72 / train/extr_return_raw_max 197.72 / train/extr_return_raw_mean 188.76 / train/extr_return_raw_min 
169.06 / train/extr_return_raw_std 5.46 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.25 / train/extr_reward_min 0 / train/extr_reward_std 0.48 / train/image_loss_mean 1.46 / train/image_loss_std 1.16 / train/model_loss_mean 4.08 /
train/model_loss_std 4.68 / train/model_opt_grad_norm 9.89 / train/model_opt_grad_steps 7.5e4 / train/model_opt_loss 4.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.79 / train/policy_entropy_mean -3 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.55 / train/policy_logprob_mag 7.91 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3 / train/policy_logprob_min -7.91 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.47 / train/policy_randomness_max 0.47 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 5.5e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 49.31 / train/post_ent_max 49.31 / train/post_ent_mean 39.84 / 
train/post_ent_min 19.63 / train/post_ent_std 5.4 / train/prior_ent_mag 71.92 / train/prior_ent_max 71.92 / train/prior_ent_mean 43.95 / train/prior_ent_min 27.44 / train/prior_ent_std 5.7 / train/rep_loss_mean 4.11 / train/rep_loss_std 6.26 / train/reward_avg 0.24 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.31 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.24 / train/reward_rate 
0.26 / train_stats/mean_log_entropy -3.07 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.19 / report/dyn_loss_std 6.31 / report/image_loss_mean 1.48 / report/image_loss_std 1.2 / report/model_loss_mean 4.19 / report/model_loss_std 4.71 / report/post_ent_mag 49.8 / report/post_ent_max 49.8 / 
report/post_ent_mean 40.66 / report/post_ent_min 20.49 / report/post_ent_std 5.23 / report/prior_ent_mag 71.85 / report/prior_ent_max 71.85 / report/prior_ent_mean 44.7 / report/prior_ent_min 29 / report/prior_ent_std 5.24 / report/rep_loss_mean 4.19 / 
report/rep_loss_std 6.31 / report/reward_avg 0.28 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.27 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 8.3e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.9 / eval/dyn_loss_std 6.84 / eval/image_loss_mean 1.57 / eval/image_loss_std 1.67 / eval/model_loss_mean 4.75 / eval/model_loss_std 5.45 / eval/post_ent_mag 49.65 / eval/post_ent_max 49.65 / eval/post_ent_mean 
40.86 / eval/post_ent_min 20.3 / eval/post_ent_std 4.84 / eval/prior_ent_mag 71.85 / eval/prior_ent_max 71.85 / eval/prior_ent_mean 45.39 / eval/prior_ent_min 33.3 / eval/prior_ent_std 4.35 / eval/rep_loss_mean 4.9 / eval/rep_loss_std 6.84 / eval/reward_avg 0.32 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.46 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.8e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.7 / eval/reward_pred 0.31 / eval/reward_rate 0.34 / 
replay/size 1.5e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3832 / timer/env.step_total 19.85 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 457.91 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-4 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7339 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1916 / timer/agent.train_total 244.17 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 153500 Counter(153500) 153437
eval_Episode has 500 steps and return 284.6.
Saved chunk: 20230922T004818F476528-4p8tB3tZVjWcqSmqal5xZT-6GPQWz5ipdv7qdZO0eWARN-1024.npz
train_Episode has 500 steps and return 253.4.
Starting evaluation at step 154000 Counter(154000) 153937
Saved chunk: 20230922T004850F131817-40HHv6JKXNbmZPjG3ZAxkg-14DjJuYx4T3SREBHDjaC8F-1024.npz
eval_Episode has 500 steps and return 266.2.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 154500 Counter(154500) 154437
eval_Episode has 500 steps and return 288.7.
Saved chunk: 20230922T004939F553174-6GPQWz5ipdv7qdZO0eWARN-1RnPK0y21CSj691UtaUxRU-1024.npz
train_Episode has 500 steps and return 265.4.
Starting evaluation at step 155000 Counter(155000) 154937
Saved chunk: 20230922T005009F907173-14DjJuYx4T3SREBHDjaC8F-6QYgcI1gykUEhIzHBqSATo-1024.npz
eval_Episode has 500 steps and return 295.7.
train_Episode has 500 steps and return 258.7.
Starting evaluation at step 155500 Counter(155500) 155437
eval_Episode has 500 steps and return 284.0.
Saved chunk: 20230922T005100F426560-1RnPK0y21CSj691UtaUxRU-0eANQ05tJmVl89DYAZpEH3-1024.npz
train_Episode has 500 steps and return 254.2.
Starting evaluation at step 156000 Counter(156000) 155937
Saved chunk: 20230922T005129F046020-6QYgcI1gykUEhIzHBqSATo-6q9Ab9fIAS9kRaOs7bOtbz-1024.npz
eval_Episode has 500 steps and return 300.0.
train_Episode has 500 steps and return 256.7.
Starting evaluation at step 156500 Counter(156500) 156437
eval_Episode has 500 steps and return 294.5.
Saved chunk: 20230922T005220F859023-0eANQ05tJmVl89DYAZpEH3-3gwJTV0cqsxbTAcpYjspyh-1024.npz
train_Episode has 500 steps and return 263.4.
Starting evaluation at step 157000 Counter(157000) 156937
Saved chunk: 20230922T005247F875145-6q9Ab9fIAS9kRaOs7bOtbz-3wDMR92jdfyOVKUkqyNS2o-1024.npz
eval_Episode has 500 steps and return 293.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 314462 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 293.8 / eval_episode/reward_rate 0.53 / episode/length 500 / episode/score 263.38 / episode/reward_rate 0.51 / train/action_mag 2.69 / train/action_max 2.69 / train/action_mean 0.05 / train/action_min -1.9 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.37 / train/actor_opt_grad_steps 7.7e4 / train/actor_opt_loss -45.03 / train/adv_mag 0.54 / train/adv_max 0.39 / train/adv_mean 5.5e-3 / 
train/adv_min -0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.1e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.12 / train/dyn_loss_std 6.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 7.7e4 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 201.52 / train/extr_critic_max 201.52 / train/extr_critic_mean 192.61 / train/extr_critic_min 167.93 / train/extr_critic_std 6.27 / train/extr_return_normed_mag 1.16 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 202.25 / train/extr_return_raw_max 202.25 / train/extr_return_raw_mean 192.72 / train/extr_return_raw_min 
170.46 / train/extr_return_raw_std 6.34 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.25 / train/extr_reward_min 0 / train/extr_reward_std 0.48 / train/image_loss_mean 1.46 / train/image_loss_std 1.19 / train/model_loss_mean 4.09 /
train/model_loss_std 4.71 / train/model_opt_grad_norm 9.92 / train/model_opt_grad_steps 7.7e4 / train/model_opt_loss 4.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.03 / train/policy_entropy_mean -3 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 7.99 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3 / train/policy_logprob_min -7.99 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 49.52 / train/post_ent_max 49.52 / train/post_ent_mean 39.68 / 
train/post_ent_min 19.07 / train/post_ent_std 5.77 / train/prior_ent_mag 71.98 / train/prior_ent_max 71.98 / train/prior_ent_mean 43.8 / train/prior_ent_min 26.37 / train/prior_ent_std 6.05 / train/rep_loss_mean 4.12 / train/rep_loss_std 6.28 / train/reward_avg 0.25 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.31 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.25 / train/reward_rate 
0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.99 / report/cont_avg 1 / report/cont_loss_mean 6.1e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.35 / report/dyn_loss_std 6.28 / report/image_loss_mean 1.52 / report/image_loss_std 1.27 / report/model_loss_mean 4.27 / report/model_loss_std 4.73 / report/post_ent_mag 49.48 / report/post_ent_max 49.48 /
report/post_ent_mean 38.65 / report/post_ent_min 19.79 / report/post_ent_std 6.09 / report/prior_ent_mag 71.88 / report/prior_ent_max 71.88 / report/prior_ent_mean 42.96 / report/prior_ent_min 25.93 / report/prior_ent_std 6.82 / report/rep_loss_mean 4.35 / 
report/rep_loss_std 6.28 / report/reward_avg 0.21 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 3.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.21 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.1 / eval/dyn_loss_std 6.65 / eval/image_loss_mean 1.56 / eval/image_loss_std 1.66 / eval/model_loss_mean 4.84 / eval/model_loss_std 5.32 / eval/post_ent_mag 49.18 / eval/post_ent_max 49.18 / eval/post_ent_mean 
40.68 / eval/post_ent_min 18.4 / eval/post_ent_std 4.95 / eval/prior_ent_mag 71.88 / eval/prior_ent_max 71.88 / eval/prior_ent_mean 45.57 / eval/prior_ent_min 34.68 / eval/prior_ent_std 4.41 / eval/rep_loss_mean 5.1 / eval/rep_loss_std 6.65 / eval/reward_avg 0.31 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.8e-4 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.31 / eval/reward_rate 0.35 / 
replay/size 1.6e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.13 / timer/env.step_count 3782 / timer/env.step_total 19.61 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.14 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241.07 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 276.3.
Starting evaluation at step 157500 Counter(157500) 157437
eval_Episode has 500 steps and return 302.2.
Saved chunk: 20230922T005341F107253-3gwJTV0cqsxbTAcpYjspyh-2ekiXvLM4WOrDxuUVl0pbH-1024.npz
train_Episode has 500 steps and return 265.7.
Starting evaluation at step 158000 Counter(158000) 157937
Saved chunk: 20230922T005406F495119-3wDMR92jdfyOVKUkqyNS2o-6SlqzU4vVjhS5sJ7YYYugi-1024.npz
eval_Episode has 500 steps and return 262.5.
train_Episode has 500 steps and return 266.1.
Starting evaluation at step 158500 Counter(158500) 158437
eval_Episode has 500 steps and return 288.3.
Saved chunk: 20230922T005502F260993-2ekiXvLM4WOrDxuUVl0pbH-714l9delqBP2ybRiaZHSZo-1024.npz
train_Episode has 500 steps and return 273.8.
Starting evaluation at step 159000 Counter(159000) 158937
Saved chunk: 20230922T005526F294854-6SlqzU4vVjhS5sJ7YYYugi-4aW7tm6oKgTsGstxZwvf8X-1024.npz
eval_Episode has 500 steps and return 296.4.
train_Episode has 500 steps and return 258.1.
Starting evaluation at step 159500 Counter(159500) 159437
eval_Episode has 500 steps and return 285.4.
Saved chunk: 20230922T005622F904081-714l9delqBP2ybRiaZHSZo-2d4phGXuscsHPKlrfIDc5D-1024.npz
train_Episode has 500 steps and return 281.6.
Starting evaluation at step 160000 Counter(160000) 159937
Saved chunk: 20230922T005645F277877-4aW7tm6oKgTsGstxZwvf8X-0L5Vgq9i1oR2rTLb9u8SLL-1024.npz
eval_Episode has 500 steps and return 275.2.
train_Episode has 500 steps and return 261.1.
Starting evaluation at step 160500 Counter(160500) 160437
eval_Episode has 500 steps and return 304.4.
Saved chunk: 20230922T005743F346415-2d4phGXuscsHPKlrfIDc5D-7dUg0M8Zwyad7nWGDfr3Ul-1024.npz
train_Episode has 500 steps and return 266.4.
Starting evaluation at step 161000 Counter(161000) 160937
Saved chunk: 20230922T005804F044692-0L5Vgq9i1oR2rTLb9u8SLL-72P8DuaFTkMeWs7NWMzGMu-1024.npz
eval_Episode has 500 steps and return 294.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 322030 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 266.37 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 294.91 / eval_episode/reward_rate 0.52 / train/action_mag 2.79 / train/action_max 2.79 / train/action_mean 0.06 / train/action_min -2 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 7.9e4 / train/actor_opt_loss -27.65 / train/adv_mag 0.66 / train/adv_max 0.57 / train/adv_mean 3.7e-3 / 
train/adv_min -0.47 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6.2e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.05 / train/dyn_loss_std 6.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 7.9e4 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 205.19 / train/extr_critic_max 205.19 / train/extr_critic_mean 196.24 / train/extr_critic_min 164.94 / train/extr_critic_std 6.68 / train/extr_return_normed_mag 1.21 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 205.94 / train/extr_return_raw_max 205.94 / train/extr_return_raw_mean 196.34 / train/extr_return_raw_min 
170.53 / train/extr_return_raw_std 6.72 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.25 / train/extr_reward_min 0 / train/extr_reward_std 0.48 / train/image_loss_mean 1.43 / train/image_loss_std 1.15 / train/model_loss_mean 4.02 /
train/model_loss_std 4.65 / train/model_opt_grad_norm 9.82 / train/model_opt_grad_steps 7.9e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.4
/ train/policy_entropy_mean -2.92 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.33 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.91 / train/policy_logprob_min -8.33 / train/policy_logprob_std 1.56 / 
train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 4.8e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 49.65 / train/post_ent_max 49.65 / train/post_ent_mean 40.05 / 
train/post_ent_min 19.26 / train/post_ent_std 5.56 / train/prior_ent_mag 72.01 / train/prior_ent_max 72.01 / train/prior_ent_mean 44.13 / train/prior_ent_min 26.95 / train/prior_ent_std 5.84 / train/rep_loss_mean 4.05 / train/rep_loss_std 6.24 / train/reward_avg 0.25 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.31 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.25 / train/reward_rate 
0.26 / train_stats/mean_log_entropy -3.04 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.8e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.13 / report/dyn_loss_std 6.21 / report/image_loss_mean 1.39 / report/image_loss_std 0.96 / report/model_loss_mean 4.06 / report/model_loss_std 4.55 / report/post_ent_mag 49.14 / report/post_ent_max 49.14 /
report/post_ent_mean 40.15 / report/post_ent_min 20.75 / report/post_ent_std 5.48 / report/prior_ent_mag 71.93 / report/prior_ent_max 71.93 / report/prior_ent_mean 44.37 / report/prior_ent_min 27.76 / report/prior_ent_std 5.64 / report/rep_loss_mean 4.13 / 
report/rep_loss_std 6.21 / report/reward_avg 0.32 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 7.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.32 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.49 / eval/dyn_loss_std 6.95 / eval/image_loss_mean 1.75 / eval/image_loss_std 1.97 / eval/model_loss_mean 5.26 / eval/model_loss_std 5.78 / eval/post_ent_mag 48.93 / eval/post_ent_max 48.93 / eval/post_ent_mean 
40.91 / eval/post_ent_min 18.75 / eval/post_ent_std 5.4 / eval/prior_ent_mag 71.93 / eval/prior_ent_max 71.93 / eval/prior_ent_mean 45.99 / eval/prior_ent_min 25.99 / eval/prior_ent_std 4.56 / eval/rep_loss_mean 5.49 / eval/rep_loss_std 6.95 / eval/reward_avg 0.29 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.29 / eval/reward_rate 0.32 / 
replay/size 1.6e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3784 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.1 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7792 / timer/agent.policy_total 17.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1892 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1892 / timer/agent.train_total 241.05 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T005903F457566-7dUg0M8Zwyad7nWGDfr3Ul-0000000000000000000000-332.npz
Saved chunk: 20230922T005922F591505-72P8DuaFTkMeWs7NWMzGMu-0000000000000000000000-129.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 256.2.
Starting evaluation at step 161500 Counter(161500) 161437
eval_Episode has 500 steps and return 288.1.
Saved chunk: 20230922T005903F457566-7dUg0M8Zwyad7nWGDfr3Ul-1fsmkpQ0SWAtsbhOmY7vl5-1024.npz
train_Episode has 500 steps and return 244.5.
Starting evaluation at step 162000 Counter(162000) 161937
Saved chunk: 20230922T005922F591505-72P8DuaFTkMeWs7NWMzGMu-3kXwZgruzgYUeUuAIt1FRa-1024.npz
eval_Episode has 500 steps and return 270.9.
train_Episode has 500 steps and return 270.9.
Starting evaluation at step 162500 Counter(162500) 162437
eval_Episode has 500 steps and return 277.1.
Saved chunk: 20230922T010024F956421-1fsmkpQ0SWAtsbhOmY7vl5-5TRa4YHbJCR99fdOh5Nv3O-1024.npz
train_Episode has 500 steps and return 282.3.
Starting evaluation at step 163000 Counter(163000) 162937
Saved chunk: 20230922T010042F660538-3kXwZgruzgYUeUuAIt1FRa-3ry89xnsh0WSnZqdBKI6mT-1024.npz
eval_Episode has 500 steps and return 286.1.
train_Episode has 500 steps and return 272.9.
Starting evaluation at step 163500 Counter(163500) 163437
eval_Episode has 500 steps and return 293.3.
train_Episode has 500 steps and return 282.5.
Saved chunk: 20230922T010145F501784-5TRa4YHbJCR99fdOh5Nv3O-4gW71RnL9PN6SUkGe18YGb-1024.npz
Starting evaluation at step 164000 Counter(164000) 163937
eval_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T010201F588646-3ry89xnsh0WSnZqdBKI6mT-4F54c6hlVTJOvIanLYlg7U-1024.npz
train_Episode has 500 steps and return 261.4.
Starting evaluation at step 164500 Counter(164500) 164437
eval_Episode has 500 steps and return 300.3.
train_Episode has 500 steps and return 245.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 329694 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 245.61 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 300.3 / eval_episode/reward_rate 0.54 / train/action_mag 3.02 / train/action_max 3.01 / train/action_mean 0.07 / train/action_min -2.15 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 8.1e4 / train/actor_opt_loss -11.18 / train/adv_mag 0.47 / train/adv_max 0.35 / train/adv_mean 2e-3 / train/adv_min 
-0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6.1e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.05 / train/dyn_loss_std 6.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 8.1e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 207.66 / train/extr_critic_max 207.66 / train/extr_critic_mean 198.02 / train/extr_critic_min 159.56 / train/extr_critic_std 9.63 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.73 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 208.46 / train/extr_return_raw_max 208.46 / train/extr_return_raw_mean 198.08 / train/extr_return_raw_min 
160.88 / train/extr_return_raw_std 9.69 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.49 / train/image_loss_mean 1.41 / train/image_loss_std 1.13 / train/model_loss_mean 4 / 
train/model_loss_std 4.65 / train/model_opt_grad_norm 10.07 / train/model_opt_grad_steps 8.1e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.71 / train/policy_entropy_mean -2.8 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.73 / train/policy_logprob_mag 8.5 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.8 / train/policy_logprob_min -8.5 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 5.4e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 49.82 / train/post_ent_max 49.82 / train/post_ent_mean 40.2 / 
train/post_ent_min 19.11 / train/post_ent_std 5.69 / train/prior_ent_mag 72.07 / train/prior_ent_max 72.07 / train/prior_ent_mean 44.27 / train/prior_ent_min 26.46 / train/prior_ent_std 5.95 / train/rep_loss_mean 4.05 / train/rep_loss_std 6.25 / train/reward_avg 0.26 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.26 / train/reward_rate 
0.27 / train_stats/mean_log_entropy -2.95 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.91 / report/dyn_loss_std 6.06 / report/image_loss_mean 1.35 / report/image_loss_std 0.95 / report/model_loss_mean 3.85 / report/model_loss_std 4.35 / report/post_ent_mag 49.72 / report/post_ent_max 49.72 /
report/post_ent_mean 40.04 / report/post_ent_min 19.64 / report/post_ent_std 5.96 / report/prior_ent_mag 72.23 / report/prior_ent_max 72.23 / report/prior_ent_mean 44.04 / report/prior_ent_min 25.97 / report/prior_ent_std 6.32 / report/rep_loss_mean 3.91 / 
report/rep_loss_std 6.06 / report/reward_avg 0.27 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 5.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.27 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 7.4e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.55 / eval/dyn_loss_std 7.26 / eval/image_loss_mean 1.84 / eval/image_loss_std 2.41 / eval/model_loss_mean 5.4 / eval/model_loss_std 6.31 / eval/post_ent_mag 50.98 / eval/post_ent_max 50.98 / eval/post_ent_mean 
41.45 / eval/post_ent_min 19.73 / eval/post_ent_std 5.34 / eval/prior_ent_mag 72.23 / eval/prior_ent_max 72.23 / eval/prior_ent_mean 46.26 / eval/prior_ent_min 29.52 / eval/prior_ent_std 4.3 / eval/rep_loss_mean 5.55 / eval/rep_loss_std 7.26 / eval/reward_avg 0.32 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.43 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.32 / eval/reward_rate 0.35 / 
replay/size 1.6e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3832 / timer/env.step_total 19.97 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.35 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7339 / timer/agent.policy_total 17.21 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.88 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / 
timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T010305F782139-4gW71RnL9PN6SUkGe18YGb-3nc48z1Vz6bGvpqXhShhjL-1024.npz
Starting evaluation at step 165000 Counter(165000) 164937
eval_Episode has 500 steps and return 276.3.
Saved chunk: 20230922T010320F296459-4F54c6hlVTJOvIanLYlg7U-4UGXlKkV9iVuhX83YQi3YJ-1024.npz
train_Episode has 500 steps and return 274.9.
Starting evaluation at step 165500 Counter(165500) 165437
eval_Episode has 500 steps and return 306.8.
train_Episode has 500 steps and return 264.7.
Saved chunk: 20230922T010426F607626-3nc48z1Vz6bGvpqXhShhjL-4MHaLdhXlhWKcEEv1TOd0U-1024.npz
Starting evaluation at step 166000 Counter(166000) 165937
eval_Episode has 500 steps and return 286.0.
Saved chunk: 20230922T010439F715824-4UGXlKkV9iVuhX83YQi3YJ-5ird3UwXxpB8RgODZwWZU6-1024.npz
train_Episode has 500 steps and return 241.3.
Starting evaluation at step 166500 Counter(166500) 166437
eval_Episode has 500 steps and return 310.2.
train_Episode has 500 steps and return 252.3.
Saved chunk: 20230922T010547F283867-4MHaLdhXlhWKcEEv1TOd0U-55cISHjI4y0wukgku21kwJ-1024.npz
Starting evaluation at step 167000 Counter(167000) 166937
eval_Episode has 500 steps and return 296.3.
train_Episode has 500 steps and return 248.8.
Starting evaluation at step 167500 Counter(167500) 167437
Saved chunk: 20230922T010558F743564-5ird3UwXxpB8RgODZwWZU6-2ZQfzLbNNi4FmqNPzpwcXR-1024.npz
eval_Episode has 500 steps and return 286.6.
train_Episode has 500 steps and return 279.6.
Saved chunk: 20230922T010707F817129-55cISHjI4y0wukgku21kwJ-4kZlpBnvda9XfWBujExplE-1024.npz
Starting evaluation at step 168000 Counter(168000) 167937
eval_Episode has 500 steps and return 310.6.
train_Episode has 500 steps and return 276.3.
Starting evaluation at step 168500 Counter(168500) 168437
Saved chunk: 20230922T010753F427359-2ZQfzLbNNi4FmqNPzpwcXR-4nqxrTFxWb5HVBVsW4YPks-1024.npz
eval_Episode has 500 steps and return 295.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 337266 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 295 / eval_episode/reward_rate 0.54 / episode/length 500 / episode/score 276.26 / episode/reward_rate 0.53 / train/action_mag 3.07 / train/action_max 3.05 / train/action_mean 0.06 / train/action_min -2.41 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 8.3e4 / train/actor_opt_loss -7.42 / train/adv_mag 0.5 / train/adv_max 0.42 / train/adv_mean 1.6e-3 / train/adv_min 
-0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6.4e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
4.07 / train/dyn_loss_std 6.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 8.3e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 209.4 / train/extr_critic_max 209.4 / train/extr_critic_mean 199.88 / train/extr_critic_min 157.89 / train/extr_critic_std 9.62 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 210.39 / train/extr_return_raw_max 210.39 / train/extr_return_raw_mean 199.94 / train/extr_return_raw_min 
162.98 / train/extr_return_raw_std 9.66 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.27 / train/extr_reward_min 0 / train/extr_reward_std 0.5 / train/image_loss_mean 1.42 / train/image_loss_std 1.16 / train/model_loss_mean 4.03 / 
train/model_loss_std 4.69 / train/model_opt_grad_norm 9.93 / train/model_opt_grad_steps 8.3e4 / train/model_opt_loss 3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.87 / train/policy_entropy_mean -2.74 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.77 / train/policy_logprob_mag 8.51 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.73 / train/policy_logprob_min -8.51 / train/policy_logprob_std 1.61 / 
train/policy_randomness_mag 0.59 / train/policy_randomness_max 0.59 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 5.9e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 49.95 / train/post_ent_max 49.95 / train/post_ent_mean 40.32 / 
train/post_ent_min 19.28 / train/post_ent_std 5.62 / train/prior_ent_mag 72.1 / train/prior_ent_max 72.1 / train/prior_ent_mean 44.4 / train/prior_ent_min 27.09 / train/prior_ent_std 5.85 / train/rep_loss_mean 4.07 / train/rep_loss_std 6.28 / train/reward_avg 0.27 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.27 / train/reward_rate 
0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.89 / report/cont_avg 1 / report/cont_loss_mean 5.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.93 / report/dyn_loss_std 6.18 / report/image_loss_mean 1.34 / report/image_loss_std 1.08 / report/model_loss_mean 3.89 / report/model_loss_std 4.55 / report/post_ent_mag 49.71 / report/post_ent_max 49.71 /
report/post_ent_mean 40.79 / report/post_ent_min 20.99 / report/post_ent_std 5.42 / report/prior_ent_mag 72 / report/prior_ent_max 72 / report/prior_ent_mean 45.01 / report/prior_ent_min 24.7 / report/prior_ent_std 5.38 / report/rep_loss_mean 3.93 / report/rep_loss_std 
6.18 / report/reward_avg 0.29 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / 
report/reward_pred 0.29 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 7.4e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 5.06 / eval/dyn_loss_std 6.67 / eval/image_loss_mean 1.62 / eval/image_loss_std 1.91 / eval/model_loss_mean 4.92 / eval/model_loss_std 5.45 / eval/post_ent_mag 49.72 / eval/post_ent_max 49.72 / eval/post_ent_mean 41.48 / eval/post_ent_min 17.8 / 
eval/post_ent_std 5.01 / eval/prior_ent_mag 72 / eval/prior_ent_max 72 / eval/prior_ent_mean 46.21 / eval/prior_ent_min 29.56 / eval/prior_ent_std 4.27 / eval/rep_loss_mean 5.06 / eval/rep_loss_std 6.67 / eval/reward_avg 0.42 / eval/reward_loss_mean 0.27 / 
eval/reward_loss_std 0.4 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.42 / eval/reward_rate 0.43 / replay/size 1.7e5 / replay/inserts 
3786 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3786 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / 
timer/env.step_max 0.11 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.12 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 17.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 1e-2 / timer/dataset_train_count 
1893 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 6.4e-4 / timer/agent.train_count 1893 / timer/agent.train_total 241 / timer/agent.train_frac 0.8 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 276.9.
Saved chunk: 20230922T010828F040543-4kZlpBnvda9XfWBujExplE-1Oq7lYGnIVzBzfBXyn15f5-1024.npz
Starting evaluation at step 169000 Counter(169000) 168937
eval_Episode has 500 steps and return 304.1.
train_Episode has 500 steps and return 262.7.
Starting evaluation at step 169500 Counter(169500) 169437
Saved chunk: 20230922T010911F994753-4nqxrTFxWb5HVBVsW4YPks-32lKw6eLcG4weLYZosenAu-1024.npz
eval_Episode has 500 steps and return 298.4.
train_Episode has 500 steps and return 268.3.
Saved chunk: 20230922T010949F049207-1Oq7lYGnIVzBzfBXyn15f5-0nt6arC2vuKG1Hq0Ryeptw-1024.npz
Starting evaluation at step 170000 Counter(170000) 169937
eval_Episode has 500 steps and return 312.5.
train_Episode has 500 steps and return 292.7.
Starting evaluation at step 170500 Counter(170500) 170437
Saved chunk: 20230922T011031F810308-32lKw6eLcG4weLYZosenAu-7hJ3NogghlsjFObIz1nwle-1024.npz
eval_Episode has 500 steps and return 298.6.
train_Episode has 500 steps and return 256.3.
Starting evaluation at step 171000 Counter(171000) 170937
eval_Episode has 500 steps and return 266.1.
Saved chunk: 20230922T011109F705218-0nt6arC2vuKG1Hq0Ryeptw-4YosweLjK3ZNovbrEhaWxp-1024.npz
train_Episode has 500 steps and return 249.9.
Starting evaluation at step 171500 Counter(171500) 171437
Saved chunk: 20230922T011150F771557-7hJ3NogghlsjFObIz1nwle-6VKXQN0jSP8vzoCwQGPB24-1024.npz
eval_Episode has 500 steps and return 290.0.
train_Episode has 500 steps and return 273.1.
Starting evaluation at step 172000 Counter(172000) 171937
eval_Episode has 500 steps and return 313.9.
Saved chunk: 20230922T011233F743359-4YosweLjK3ZNovbrEhaWxp-2ToptqX6CDAtawPQhIYlYr-1024.npz
train_Episode has 500 steps and return 278.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 344934 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 278.13 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 313.87 / eval_episode/reward_rate 0.54 / train/action_mag 2.99 / train/action_max 2.97 / train/action_mean 0.06 / train/action_min -2.49 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 8.5e4 / train/actor_opt_loss -8.78 / train/adv_mag 0.81 / train/adv_max 0.77 / train/adv_mean 1.7e-3 / train/adv_min
-0.32 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
4.04 / train/dyn_loss_std 6.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 8.5e4 / 
train/extr_critic_critic_opt_loss 9428.15 / train/extr_critic_mag 210.07 / train/extr_critic_max 210.07 / train/extr_critic_mean 201.31 / train/extr_critic_min 150.62 / train/extr_critic_std 8.88 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 211.51 / train/extr_return_raw_max 211.51 / train/extr_return_raw_mean 201.37 / train/extr_return_raw_min 
166.5 / train/extr_return_raw_std 8.93 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.51 / train/image_loss_mean 1.39 / train/image_loss_std 1.14 / train/model_loss_mean 3.99 / 
train/model_loss_std 4.66 / train/model_opt_grad_norm 10.25 / train/model_opt_grad_steps 8.5e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
2.05 / train/policy_entropy_mean -2.74 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.78 / train/policy_logprob_mag 8.64 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.74 / train/policy_logprob_min -8.64 / train/policy_logprob_std 1.62 / 
train/policy_randomness_mag 0.61 / train/policy_randomness_max 0.61 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 6.4e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.17 / train/post_ent_max 50.17 / train/post_ent_mean 40.58 / 
train/post_ent_min 19.43 / train/post_ent_std 5.54 / train/prior_ent_mag 72.11 / train/prior_ent_max 72.11 / train/prior_ent_mean 44.63 / train/prior_ent_min 27.33 / train/prior_ent_std 5.74 / train/rep_loss_mean 4.04 / train/rep_loss_std 6.25 / train/reward_avg 0.27 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.99 / train/reward_max_pred 1.98 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.27 / train/reward_rate 
0.28 / train_stats/mean_log_entropy -2.92 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.9e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.01 / report/dyn_loss_std 6.04 / report/image_loss_mean 1.31 / report/image_loss_std 1.07 / report/model_loss_mean 3.94 / report/model_loss_std 4.51 / report/post_ent_mag 50.29 / report/post_ent_max 50.29 /
report/post_ent_mean 42.2 / report/post_ent_min 16.96 / report/post_ent_std 4.97 / report/prior_ent_mag 72.09 / report/prior_ent_max 72.09 / report/prior_ent_mean 45.97 / report/prior_ent_min 31.29 / report/prior_ent_std 4.71 / report/rep_loss_mean 4.01 / 
report/rep_loss_std 6.04 / report/reward_avg 0.38 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.32 / report/reward_max_data 1.97 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 5.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.39 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 7.3e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.95 / eval/dyn_loss_std 7.58 / eval/image_loss_mean 1.77 / eval/image_loss_std 1.94 / eval/model_loss_mean 5.57 / eval/model_loss_std 6.09 / eval/post_ent_mag 49.96 / eval/post_ent_max 49.96 / eval/post_ent_mean 
41.21 / eval/post_ent_min 14.96 / eval/post_ent_std 5.41 / eval/prior_ent_mag 72.09 / eval/prior_ent_max 72.09 / eval/prior_ent_mean 46.25 / eval/prior_ent_min 27.59 / eval/prior_ent_std 4.6 / eval/rep_loss_mean 5.95 / eval/rep_loss_std 7.58 / eval/reward_avg 0.38 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.38 / eval/reward_rate 0.36 / 
replay/size 1.7e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3834 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.93 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7341 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1917 / timer/agent.train_total 244.23 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 172500 Counter(172500) 172437
Saved chunk: 20230922T011309F518812-6VKXQN0jSP8vzoCwQGPB24-2SsD79W1fUK7DXkYzQejRI-1024.npz
eval_Episode has 500 steps and return 314.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T011353F875915-2ToptqX6CDAtawPQhIYlYr-0000000000000000000000-569.npz
Saved chunk: 20230922T011428F753263-2SsD79W1fUK7DXkYzQejRI-0000000000000000000000-388.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 253.8.
Starting evaluation at step 173000 Counter(173000) 172937
eval_Episode has 500 steps and return 282.0.
Saved chunk: 20230922T011353F875915-2ToptqX6CDAtawPQhIYlYr-4twcHaO9EtEi02FIevOBAW-1024.npz
train_Episode has 500 steps and return 281.0.
Starting evaluation at step 173500 Counter(173500) 173437
Saved chunk: 20230922T011428F753263-2SsD79W1fUK7DXkYzQejRI-47wUetxgVDIrQQ1bYJEeKo-1024.npz
eval_Episode has 500 steps and return 317.3.
train_Episode has 500 steps and return 270.1.
Starting evaluation at step 174000 Counter(174000) 173937
eval_Episode has 500 steps and return 313.5.
Saved chunk: 20230922T011515F307307-4twcHaO9EtEi02FIevOBAW-06yvDfY3iJeuec9hMfUtER-1024.npz
train_Episode has 500 steps and return 252.1.
Starting evaluation at step 174500 Counter(174500) 174437
Saved chunk: 20230922T011548F172785-47wUetxgVDIrQQ1bYJEeKo-717eLFplKXpJ1Afxz5vUwU-1024.npz
eval_Episode has 500 steps and return 277.7.
train_Episode has 500 steps and return 281.4.
Starting evaluation at step 175000 Counter(175000) 174937
eval_Episode has 500 steps and return 295.6.
Saved chunk: 20230922T011635F893492-06yvDfY3iJeuec9hMfUtER-6DY6t0ehwJb5Ya054Et55S-1024.npz
train_Episode has 500 steps and return 279.8.
Starting evaluation at step 175500 Counter(175500) 175437
Saved chunk: 20230922T011707F009707-717eLFplKXpJ1Afxz5vUwU-0q7tvHukd5bRGLuvA8Sesp-1024.npz
eval_Episode has 500 steps and return 290.2.
train_Episode has 500 steps and return 303.1.
Starting evaluation at step 176000 Counter(176000) 175937
eval_Episode has 500 steps and return 297.0.
Saved chunk: 20230922T011756F216880-6DY6t0ehwJb5Ya054Et55S-3q36ZIQkzhKClmleKGOKYl-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 352494 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 297.04 / eval_episode/reward_rate 0.52 / episode/length 500 / episode/score 303.13 / episode/reward_rate 0.53 / train/action_mag 2.98 / train/action_max 2.96 / train/action_mean 0.07 / train/action_min -2.41 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 8.7e4 / train/actor_opt_loss -5.71 / train/adv_mag 1.01 / train/adv_max 0.98 / train/adv_mean 
1.4e-3 / train/adv_min -0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 4.04 / train/dyn_loss_std 6.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / 
train/extr_critic_critic_opt_grad_steps 8.7e4 / train/extr_critic_critic_opt_loss 8918.11 / train/extr_critic_mag 211.01 / train/extr_critic_max 211.01 / train/extr_critic_mean 201.72 / train/extr_critic_min 145.5 / train/extr_critic_std 9.52 / 
train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 212.18 / train/extr_return_raw_max 
212.18 / train/extr_return_raw_mean 201.77 / train/extr_return_raw_min 163.41 / train/extr_return_raw_std 9.55 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.51 / 
train/image_loss_mean 1.4 / train/image_loss_std 1.15 / train/model_loss_mean 3.99 / train/model_loss_std 4.66 / train/model_opt_grad_norm 9.53 / train/model_opt_grad_steps 8.7e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 2.03 / train/policy_entropy_mean -2.72 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.79 / train/policy_logprob_mag 8.4 / train/policy_logprob_max 5.47 / 
train/policy_logprob_mean 2.72 / train/policy_logprob_min -8.4 / train/policy_logprob_std 1.62 / train/policy_randomness_mag 0.6 / train/policy_randomness_max 0.6 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 7.1e-4 / train/policy_randomness_std 0.09
/ train/post_ent_mag 50.26 / train/post_ent_max 50.26 / train/post_ent_mean 40.63 / train/post_ent_min 19.08 / train/post_ent_std 5.56 / train/prior_ent_mag 72.15 / train/prior_ent_max 72.15 / train/prior_ent_mean 44.67 / train/prior_ent_min 27.14 / train/prior_ent_std 
5.75 / train/rep_loss_mean 4.04 / train/rep_loss_std 6.25 / train/reward_avg 0.28 / train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.99 / train/reward_max_pred 1.98 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.28 / train/reward_rate 0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.89 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc
nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 6.2 / report/image_loss_mean 1.39 / report/image_loss_std 1.15 / report/model_loss_mean 3.98 /
report/model_loss_std 4.62 / report/post_ent_mag 50.33 / report/post_ent_max 50.33 / report/post_ent_mean 40.9 / report/post_ent_min 20.14 / report/post_ent_std 5.51 / report/prior_ent_mag 72.08 / report/prior_ent_max 72.08 / report/prior_ent_mean 45 / 
report/prior_ent_min 29.69 / report/prior_ent_std 5.56 / report/rep_loss_mean 3.99 / report/rep_loss_std 6.2 / report/reward_avg 0.34 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 1.99 / report/reward_max_pred 1.97 / 
report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.35 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 7.5e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.19 / eval/dyn_loss_std 5.83 / eval/image_loss_mean 1.25 / eval/image_loss_std 0.87 / eval/model_loss_mean 4.06 / eval/model_loss_std 
4.27 / eval/post_ent_mag 50.72 / eval/post_ent_max 50.72 / eval/post_ent_mean 42.81 / eval/post_ent_min 23.27 / eval/post_ent_std 4.3 / eval/prior_ent_mag 72.08 / eval/prior_ent_max 72.08 / eval/prior_ent_mean 46.87 / eval/prior_ent_min 35.34 / eval/prior_ent_std 3.79 /
eval/rep_loss_mean 4.19 / eval/rep_loss_std 5.83 / eval/reward_avg 0.48 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3e-3 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.61 / eval/reward_pred 0.48 / eval/reward_rate 0.48 / replay/size 1.8e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3780 / 
timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.4 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 2.5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7788 / 
timer/agent.policy_total 18.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / 
timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1890 / timer/agent.train_total 240.81 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / 
timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 224.6.
Starting evaluation at step 176500 Counter(176500) 176437
Saved chunk: 20230922T011825F737749-0q7tvHukd5bRGLuvA8Sesp-4OamPwUluI4pumfElMInk4-1024.npz
eval_Episode has 500 steps and return 307.8.
train_Episode has 500 steps and return 254.6.
Starting evaluation at step 177000 Counter(177000) 176937
eval_Episode has 500 steps and return 309.9.
Saved chunk: 20230922T011916F413485-3q36ZIQkzhKClmleKGOKYl-3O0L6j2yQ9UwkEghGTP8fX-1024.npz
train_Episode has 500 steps and return 266.1.
Starting evaluation at step 177500 Counter(177500) 177437
Saved chunk: 20230922T011945F233691-4OamPwUluI4pumfElMInk4-15q2qOg2NeXveCyOd7WdM5-1024.npz
eval_Episode has 500 steps and return 316.9.
train_Episode has 500 steps and return 292.2.
Starting evaluation at step 178000 Counter(178000) 177937
eval_Episode has 500 steps and return 308.9.
Saved chunk: 20230922T012037F883647-3O0L6j2yQ9UwkEghGTP8fX-6FwVP1Ysc3uM0JvjQRpIlK-1024.npz
train_Episode has 500 steps and return 284.9.
Starting evaluation at step 178500 Counter(178500) 178437
Saved chunk: 20230922T012104F447033-15q2qOg2NeXveCyOd7WdM5-4ffBI4qTi545KS6ob2HSYp-1024.npz
eval_Episode has 500 steps and return 307.0.
train_Episode has 500 steps and return 248.1.
Starting evaluation at step 179000 Counter(179000) 178937
eval_Episode has 500 steps and return 291.3.
Saved chunk: 20230922T012158F411439-6FwVP1Ysc3uM0JvjQRpIlK-6odGpBBvSkjcsd4gjKCqaz-1024.npz
train_Episode has 500 steps and return 271.4.
Starting evaluation at step 179500 Counter(179500) 179437
Saved chunk: 20230922T012223F303720-4ffBI4qTi545KS6ob2HSYp-3G2YyTHF0OiMzkkGw0BAQT-1024.npz
eval_Episode has 500 steps and return 310.2.
train_Episode has 500 steps and return 300.0.
Starting evaluation at step 180000 Counter(180000) 179937
eval_Episode has 500 steps and return 323.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 360060 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 300.04 / episode/reward_rate 0.49 / eval_episode/length 500 / eval_episode/score 323.78 / eval_episode/reward_rate 0.54 / train/action_mag 2.97 / train/action_max 2.96 / train/action_mean 0.08 / train/action_min -2.31 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 8.9e4 / train/actor_opt_loss -10.97 / train/adv_mag 0.99 / train/adv_max 0.96 / train/adv_mean 2e-3
/ train/adv_min -0.3 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.9e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.02 / train/dyn_loss_std 6.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 8.9e4 / 
train/extr_critic_critic_opt_loss 8443.34 / train/extr_critic_mag 212.99 / train/extr_critic_max 212.99 / train/extr_critic_mean 202.53 / train/extr_critic_min 149.25 / train/extr_critic_std 9.27 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 213.06 / train/extr_return_raw_max 213.06 / train/extr_return_raw_mean 202.6 / train/extr_return_raw_min 
165.81 / train/extr_return_raw_std 9.3 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.29 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.37 / train/image_loss_std 1.14 / train/model_loss_mean 3.96 / 
train/model_loss_std 4.65 / train/model_opt_grad_norm 9.66 / train/model_opt_grad_steps 8.8e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.93 / train/policy_entropy_mean -2.77 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.76 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.77 / train/policy_logprob_min -8.69 / train/policy_logprob_std 1.61 / 
train/policy_randomness_mag 0.59 / train/policy_randomness_max 0.59 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 7.2e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.42 / train/post_ent_max 50.42 / train/post_ent_mean 40.87 / 
train/post_ent_min 19.79 / train/post_ent_std 5.49 / train/prior_ent_mag 72.16 / train/prior_ent_max 72.16 / train/prior_ent_mean 44.88 / train/prior_ent_min 27.65 / train/prior_ent_std 5.66 / train/rep_loss_mean 4.02 / train/rep_loss_std 6.23 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.99 / train/reward_max_pred 1.98 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.29 / train/reward_rate 
0.29 / train_stats/mean_log_entropy -2.9 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.7e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 5.83 / report/image_loss_mean 1.14 / report/image_loss_std 1.02 / report/model_loss_mean 3.42 / report/model_loss_std 4.29 / report/post_ent_mag 50 / report/post_ent_max 50 / 
report/post_ent_mean 40.81 / report/post_ent_min 20.78 / report/post_ent_std 5.22 / report/prior_ent_mag 72.18 / report/prior_ent_max 72.18 / report/prior_ent_mean 44.24 / report/prior_ent_min 29.34 / report/prior_ent_std 5.96 / report/rep_loss_mean 3.58 / 
report/rep_loss_std 5.83 / report/reward_avg 0.22 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.26 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.22 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.88 / eval/dyn_loss_std 6.35 / eval/image_loss_mean 1.43 / eval/image_loss_std 1.61 / eval/model_loss_mean 4.66 / eval/model_loss_std 5.02 / eval/post_ent_mag 50.32 / eval/post_ent_max 50.32 / eval/post_ent_mean 
42.16 / eval/post_ent_min 23.39 / eval/post_ent_std 4.57 / eval/prior_ent_mag 72.18 / eval/prior_ent_max 72.18 / eval/prior_ent_mean 46.61 / eval/prior_ent_min 33.35 / eval/prior_ent_std 3.99 / eval/rep_loss_mean 4.88 / eval/rep_loss_std 6.35 / eval/reward_avg 0.48 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.47 / eval/reward_rate 0.46 / 
replay/size 1.8e5 / replay/inserts 3783 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3783 / timer/env.step_total 19.55 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.27 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7791 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / 
timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1891 / timer/agent.train_total 240.94 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T012318F681237-6odGpBBvSkjcsd4gjKCqaz-3J7cVHbrjVxDB297XmpO7D-1024.npz
train_Episode has 500 steps and return 266.5.
Starting evaluation at step 180500 Counter(180500) 180437
Saved chunk: 20230922T012341F927503-3G2YyTHF0OiMzkkGw0BAQT-1dFhDZdINy7yaZyl80wiFF-1024.npz
eval_Episode has 500 steps and return 288.8.
train_Episode has 500 steps and return 233.5.
Starting evaluation at step 181000 Counter(181000) 180937
eval_Episode has 500 steps and return 309.3.
Saved chunk: 20230922T012439F653969-3J7cVHbrjVxDB297XmpO7D-2x2egHblYuKaFqcE0kUxVP-1024.npz
train_Episode has 500 steps and return 292.6.
Starting evaluation at step 181500 Counter(181500) 181437
Saved chunk: 20230922T012501F521432-1dFhDZdINy7yaZyl80wiFF-6EW082E48x7Zo0yOx6kyCZ-1024.npz
eval_Episode has 500 steps and return 245.9.
train_Episode has 500 steps and return 273.0.
Starting evaluation at step 182000 Counter(182000) 181937
eval_Episode has 500 steps and return 332.4.
Saved chunk: 20230922T012600F357058-2x2egHblYuKaFqcE0kUxVP-6N1v2lLveylWEYePR2KD1L-1024.npz
train_Episode has 500 steps and return 261.7.
Starting evaluation at step 182500 Counter(182500) 182437
Saved chunk: 20230922T012620F596583-6EW082E48x7Zo0yOx6kyCZ-1pCULhXx005VXOyho1gJBN-1024.npz
eval_Episode has 500 steps and return 320.3.
train_Episode has 500 steps and return 278.4.
Starting evaluation at step 183000 Counter(183000) 182937
eval_Episode has 500 steps and return 251.5.
Saved chunk: 20230922T012720F794650-6N1v2lLveylWEYePR2KD1L-6C2UmbjebpLtR7nP4RqeVq-1024.npz
train_Episode has 500 steps and return 248.9.
Starting evaluation at step 183500 Counter(183500) 183437
Saved chunk: 20230922T012739F441402-1pCULhXx005VXOyho1gJBN-49Yy8xUiOSPp4Ok4haF4Zs-1024.npz
eval_Episode has 500 steps and return 327.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 367726 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 248.88 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 326.96 / eval_episode/reward_rate 0.54 / train/action_mag 2.98 / train/action_max 2.96 / train/action_mean 0.09 / train/action_min -2.42 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 9e4 / train/actor_opt_loss -9.36 / train/adv_mag 0.68 / train/adv_max 0.62 / train/adv_mean 1.8e-3 
/ train/adv_min -0.33 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 4.01 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 9e4 / 
train/extr_critic_critic_opt_loss 7995.55 / train/extr_critic_mag 214.67 / train/extr_critic_max 214.67 / train/extr_critic_mean 202.93 / train/extr_critic_min 154.49 / train/extr_critic_std 10.54 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.07 /
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 214.52 / train/extr_return_raw_max 214.52 / train/extr_return_raw_mean 202.99 / train/extr_return_raw_min 
161.65 / train/extr_return_raw_std 10.63 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.29 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.37 / train/image_loss_std 1.14 / train/model_loss_mean 3.95 / 
train/model_loss_std 4.67 / train/model_opt_grad_norm 9.91 / train/model_opt_grad_steps 9e4 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7369.79 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 2.25 / train/policy_entropy_mean -2.74 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.82 / train/policy_logprob_mag 8.6 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.74 / train/policy_logprob_min -8.6 / 
train/policy_logprob_std 1.64 / train/policy_randomness_mag 0.63 / train/policy_randomness_max 0.63 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 6.7e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 50.41 / train/post_ent_max 50.41 / 
train/post_ent_mean 40.72 / train/post_ent_min 19.36 / train/post_ent_std 5.64 / train/prior_ent_mag 72.2 / train/prior_ent_max 72.2 / train/prior_ent_mean 44.73 / train/prior_ent_min 27.34 / train/prior_ent_std 5.86 / train/rep_loss_mean 4.01 / train/rep_loss_std 6.27 
/ train/reward_avg 0.28 / train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 2 / train/reward_max_pred 1.98 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 
0.28 / train/reward_rate 0.29 / train_stats/mean_log_entropy -2.91 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 8.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 5.88 / report/image_loss_mean 1.14 / report/image_loss_std 0.98 / report/model_loss_mean 3.39 / report/model_loss_std 4.37 / report/post_ent_mag 
50.25 / report/post_ent_max 50.25 / report/post_ent_mean 40.54 / report/post_ent_min 16.75 / report/post_ent_std 6.84 / report/prior_ent_mag 72.28 / report/prior_ent_max 72.28 / report/prior_ent_mean 44.24 / report/prior_ent_min 19.13 / report/prior_ent_std 7.54 / 
report/rep_loss_mean 3.51 / report/rep_loss_std 5.88 / report/reward_avg 0.23 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.23 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.03 / eval/dyn_loss_std 6.61 / eval/image_loss_mean 1.53 / eval/image_loss_std 1.64 / eval/model_loss_mean 4.8 / eval/model_loss_std 5.22 / eval/post_ent_mag 51.38 / eval/post_ent_max
51.38 / eval/post_ent_mean 41.94 / eval/post_ent_min 18.46 / eval/post_ent_std 5.02 / eval/prior_ent_mag 72.28 / eval/prior_ent_max 72.28 / eval/prior_ent_mean 46.79 / eval/prior_ent_min 32.49 / eval/prior_ent_std 4.3 / eval/rep_loss_mean 5.03 / eval/rep_loss_std 6.61 /
eval/reward_avg 0.37 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.44 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.66 / eval/reward_pred 0.37 / 
eval/reward_rate 0.39 / replay/size 1.8e5 / replay/inserts 3833 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3833 / timer/env.step_total 19.84 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 460.38 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.2e-3 / 
timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7340 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 
/ timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1917 / 
timer/agent.train_total 244.21 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.55

train_Episode has 500 steps and return 260.7.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 184000 Counter(184000) 183937
eval_Episode has 500 steps and return 297.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T012858F087882-49Yy8xUiOSPp4Ok4haF4Zs-0000000000000000000000-647.npz
Saved chunk: 20230922T012841F050565-6C2UmbjebpLtR7nP4RqeVq-0000000000000000000000-804.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T012841F050565-6C2UmbjebpLtR7nP4RqeVq-7taO82ZInFynHRglSEKwTG-1024.npz
train_Episode has 500 steps and return 284.3.
Starting evaluation at step 184500 Counter(184500) 184437
Saved chunk: 20230922T012858F087882-49Yy8xUiOSPp4Ok4haF4Zs-3idtXoa5KpDal7Etc31D1y-1024.npz
eval_Episode has 500 steps and return 292.7.
train_Episode has 500 steps and return 294.6.
Starting evaluation at step 185000 Counter(185000) 184937
eval_Episode has 500 steps and return 285.6.
Saved chunk: 20230922T013002F557451-7taO82ZInFynHRglSEKwTG-3x5DsJIDmLa0oFpCzifnKG-1024.npz
train_Episode has 500 steps and return 274.1.
Starting evaluation at step 185500 Counter(185500) 185437
Saved chunk: 20230922T013018F105145-3idtXoa5KpDal7Etc31D1y-2JxM3vbAVTQ9DDctZVp5ks-1024.npz
eval_Episode has 500 steps and return 328.2.
train_Episode has 500 steps and return 276.1.
Starting evaluation at step 186000 Counter(186000) 185937
eval_Episode has 500 steps and return 305.9.
train_Episode has 500 steps and return 299.0.
Saved chunk: 20230922T013123F097858-3x5DsJIDmLa0oFpCzifnKG-03uvqbA4eDpUZAEK8UM59X-1024.npz
Starting evaluation at step 186500 Counter(186500) 186437
eval_Episode has 500 steps and return 297.0.
Saved chunk: 20230922T013137F078570-2JxM3vbAVTQ9DDctZVp5ks-3Dn3wlO7SdeG25t6aer7AZ-1024.npz
train_Episode has 500 steps and return 262.4.
Starting evaluation at step 187000 Counter(187000) 186937
eval_Episode has 500 steps and return 317.9.
train_Episode has 500 steps and return 284.8.
Saved chunk: 20230922T013243F381474-03uvqbA4eDpUZAEK8UM59X-4qA3MzTFah7dRtXNENZlbq-1024.npz
Starting evaluation at step 187500 Counter(187500) 187437
eval_Episode has 500 steps and return 282.4.
Saved chunk: 20230922T013255F743133-3Dn3wlO7SdeG25t6aer7AZ-0ul63kmvcyvjPvrK4QAMN3-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 375290 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 284.79 / episode/reward_rate 0.49 / eval_episode/length 500 / eval_episode/score 282.35 / eval_episode/reward_rate 0.49 / train_stats/mean_log_entropy -2.97 / train/action_mag 2.93 / train/action_max 2.92 / train/action_mean 0.09 / 
train/action_min -2.29 / train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 9.2e4 / train/actor_opt_loss -12.48 / train/adv_mag 0.48 / train/adv_max 
0.4 / train/adv_mean 2.1e-3 / train/adv_min -0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.5e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.5e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 4.02 / train/dyn_loss_std 6.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / 
train/extr_critic_critic_opt_grad_steps 9.2e4 / train/extr_critic_critic_opt_loss 7393.68 / train/extr_critic_mag 215.35 / train/extr_critic_max 215.35 / train/extr_critic_mean 204.74 / train/extr_critic_min 165.88 / train/extr_critic_std 9.23 / 
train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.07 / train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 215.65 / train/extr_return_raw_max 
215.65 / train/extr_return_raw_mean 204.82 / train/extr_return_raw_min 168.65 / train/extr_return_raw_std 9.32 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean
1.35 / train/image_loss_std 1.12 / train/model_loss_mean 3.94 / train/model_loss_std 4.65 / train/model_opt_grad_norm 9.8 / train/model_opt_grad_steps 9.2e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 3.6 / train/policy_entropy_max 2.31 / train/policy_entropy_mean -2.82 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.79 / train/policy_logprob_mag 8.57 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.82 / 
train/policy_logprob_min -8.57 / train/policy_logprob_std 1.63 / train/policy_randomness_mag 0.63 / train/policy_randomness_max 0.63 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 5.7e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 50.66 / 
train/post_ent_max 50.66 / train/post_ent_mean 41.07 / train/post_ent_min 19.58 / train/post_ent_std 5.53 / train/prior_ent_mag 72.19 / train/prior_ent_max 72.19 / train/prior_ent_mean 45.09 / train/prior_ent_min 27.78 / train/prior_ent_std 5.67 / train/rep_loss_mean 
4.02 / train/rep_loss_std 6.25 / train/reward_avg 0.3 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.99 / train/reward_max_pred 1.98 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / 
train/reward_pos_loss 0.59 / train/reward_pred 0.29 / train/reward_rate 0.3 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.6e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 5.95 / report/image_loss_mean 1.24 / report/image_loss_std 1.16 / report/model_loss_mean 3.75 / report/model_loss_std 4.48 / report/post_ent_mag 49.7
/ report/post_ent_max 49.7 / report/post_ent_mean 42.06 / report/post_ent_min 16 / report/post_ent_std 4.68 / report/prior_ent_mag 72.21 / report/prior_ent_max 72.21 / report/prior_ent_mean 46 / report/prior_ent_min 29.77 / report/prior_ent_std 4.63 / 
report/rep_loss_mean 3.84 / report/rep_loss_std 5.95 / report/reward_avg 0.35 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.35 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.12 / eval/dyn_loss_std 7.2 / eval/image_loss_mean 1.7 / eval/image_loss_std 2.61 / eval/model_loss_mean 5.05 / eval/model_loss_std 6.52 / eval/post_ent_mag 50.64 / eval/post_ent_max 
50.64 / eval/post_ent_mean 42.03 / eval/post_ent_min 20.55 / eval/post_ent_std 5.28 / eval/prior_ent_mag 72.21 / eval/prior_ent_max 72.21 / eval/prior_ent_mean 46.66 / eval/prior_ent_min 32.18 / eval/prior_ent_std 4.38 / eval/rep_loss_mean 5.12 / eval/rep_loss_std 7.2 /
eval/reward_avg 0.43 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.43 / 
eval/reward_rate 0.43 / replay/size 1.9e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3782 / timer/env.step_total 19.89 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.44 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7790 / timer/agent.policy_total 18.1 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1891 / timer/agent.train_total 240.63 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / 
timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 267.6.
Starting evaluation at step 188000 Counter(188000) 187937
eval_Episode has 500 steps and return 329.2.
train_Episode has 500 steps and return 255.1.
Saved chunk: 20230922T013403F531668-4qA3MzTFah7dRtXNENZlbq-4kFNjoJgFS2C6RLMn9T1lK-1024.npz
Starting evaluation at step 188500 Counter(188500) 188437
eval_Episode has 500 steps and return 280.8.
Saved chunk: 20230922T013414F317700-0ul63kmvcyvjPvrK4QAMN3-2abckJMnqU2vGe8iErkaSi-1024.npz
train_Episode has 500 steps and return 253.3.
Starting evaluation at step 189000 Counter(189000) 188937
eval_Episode has 500 steps and return 320.5.
train_Episode has 500 steps and return 273.6.
Saved chunk: 20230922T013524F900991-4kFNjoJgFS2C6RLMn9T1lK-1czrjtKbcSq3vcsIdzfATI-1024.npz
Starting evaluation at step 189500 Counter(189500) 189437
eval_Episode has 500 steps and return 295.4.
Saved chunk: 20230922T013534F202708-2abckJMnqU2vGe8iErkaSi-6AuF1iAnBGSui28jpHCXes-1024.npz
train_Episode has 500 steps and return 293.0.
Starting evaluation at step 190000 Counter(190000) 189937
eval_Episode has 500 steps and return 315.2.
train_Episode has 500 steps and return 292.0.
Saved chunk: 20230922T013645F611073-1czrjtKbcSq3vcsIdzfATI-4ZZli4imh8HNnglEurEMQF-1024.npz
Starting evaluation at step 190500 Counter(190500) 190437
eval_Episode has 500 steps and return 303.4.
train_Episode has 500 steps and return 281.5.
Starting evaluation at step 191000 Counter(191000) 190937
Saved chunk: 20230922T013653F337024-6AuF1iAnBGSui28jpHCXes-3fSxuQ6sk7op0GZB0Wdx6L-1024.npz
eval_Episode has 500 steps and return 299.2.
train_Episode has 500 steps and return 261.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 382938 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 261.52 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 299.24 / eval_episode/reward_rate 0.53 / train/action_mag 2.96 / train/action_max 2.92 / train/action_mean 0.09 / train/action_min -2.33 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 9.4e4 / train/actor_opt_loss -19.7 / train/adv_mag 0.55 / train/adv_max 0.49 / train/adv_mean 
2.9e-3 / train/adv_min -0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.4e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.98 / train/dyn_loss_std 6.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 9.4e4 / train/extr_critic_critic_opt_loss 7144.44 / train/extr_critic_mag 216.07 / train/extr_critic_max 216.07 / train/extr_critic_mean 205.79 / train/extr_critic_min 163.38 / train/extr_critic_std 9.52 / 
train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.07 / train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 216.81 / train/extr_return_raw_max 
216.81 / train/extr_return_raw_mean 205.88 / train/extr_return_raw_min 167.83 / train/extr_return_raw_std 9.48 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean
1.33 / train/image_loss_std 1.11 / train/model_loss_mean 3.9 / train/model_loss_std 4.62 / train/model_opt_grad_norm 9.7 / train/model_opt_grad_steps 9.4e4 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
7879.58 / train/policy_entropy_mag 3.64 / train/policy_entropy_max 2.43 / train/policy_entropy_mean -2.82 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.74 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.82 / 
train/policy_logprob_min -8.74 / train/policy_logprob_std 1.64 / train/policy_randomness_mag 0.65 / train/policy_randomness_max 0.65 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 5.4e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 50.68 / 
train/post_ent_max 50.68 / train/post_ent_mean 41.13 / train/post_ent_min 19.76 / train/post_ent_std 5.45 / train/prior_ent_mag 72.22 / train/prior_ent_max 72.22 / train/prior_ent_mean 45.1 / train/prior_ent_min 28.03 / train/prior_ent_std 5.64 / train/rep_loss_mean 
3.98 / train/rep_loss_std 6.21 / train/reward_avg 0.3 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.99 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / 
train/reward_pos_loss 0.59 / train/reward_pred 0.3 / train/reward_rate 0.3 / train_stats/mean_log_entropy -2.97 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.2e-11 / report/cont_loss_std 3.6e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.03 / report/dyn_loss_std 6.03 / report/image_loss_mean 1.43 / report/image_loss_std 1.57 / report/model_loss_mean 4.02 / 
report/model_loss_std 4.93 / report/post_ent_mag 50.27 / report/post_ent_max 50.27 / report/post_ent_mean 41.04 / report/post_ent_min 20.91 / report/post_ent_std 5.05 / report/prior_ent_mag 72.35 / report/prior_ent_max 72.35 / report/prior_ent_mean 45.3 / 
report/prior_ent_min 30.93 / report/prior_ent_std 4.78 / report/rep_loss_mean 4.03 / report/rep_loss_std 6.03 / report/reward_avg 0.26 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.99 / 
report/reward_neg_acc 1 / report/reward_neg_loss 5.8e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.57 / report/reward_pred 0.26 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.12 / eval/dyn_loss_std 6.67 / eval/image_loss_mean 1.58 / eval/image_loss_std 2.21 / eval/model_loss_mean 4.93 / eval/model_loss_std 
5.76 / eval/post_ent_mag 50.85 / eval/post_ent_max 50.85 / eval/post_ent_mean 41.92 / eval/post_ent_min 20.91 / eval/post_ent_std 5.1 / eval/prior_ent_mag 72.35 / eval/prior_ent_max 72.35 / eval/prior_ent_mean 46.63 / eval/prior_ent_min 32.94 / eval/prior_ent_std 4.19 /
eval/rep_loss_mean 5.12 / eval/rep_loss_std 6.67 / eval/reward_avg 0.46 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.5e-3 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.62 / eval/reward_pred 0.46 / eval/reward_rate 0.44 / replay/size 1.9e5 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3824 / 
timer/env.step_total 19.77 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.77 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 
0.01 / timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7331 / timer/agent.policy_total 17.22 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1912 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 6e-4 / timer/agent.train_count 1912 / timer/agent.train_total 244.03 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / 
timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.49

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T013806F086739-4ZZli4imh8HNnglEurEMQF-0jTiyIFeMxZp512d4Yxt6m-1024.npz
Starting evaluation at step 191500 Counter(191500) 191437
eval_Episode has 500 steps and return 310.7.
train_Episode has 500 steps and return 268.2.
Starting evaluation at step 192000 Counter(192000) 191937
Saved chunk: 20230922T013848F062406-3fSxuQ6sk7op0GZB0Wdx6L-22PdXypF88PXwNzNyvaujY-1024.npz
eval_Episode has 500 steps and return 309.0.
train_Episode has 500 steps and return 246.1.
Starting evaluation at step 192500 Counter(192500) 192437
eval_Episode has 500 steps and return 253.9.
Saved chunk: 20230922T013927F258236-0jTiyIFeMxZp512d4Yxt6m-0vCPqlsEFZYAavi1ZaE1X1-1024.npz
train_Episode has 500 steps and return 273.0.
Starting evaluation at step 193000 Counter(193000) 192937
Saved chunk: 20230922T014008F054724-22PdXypF88PXwNzNyvaujY-0LcdOQQYOwGSX9ILLTi44U-1024.npz
eval_Episode has 500 steps and return 315.8.
train_Episode has 500 steps and return 260.6.
Starting evaluation at step 193500 Counter(193500) 193437
eval_Episode has 500 steps and return 284.9.
Saved chunk: 20230922T014051F824752-0vCPqlsEFZYAavi1ZaE1X1-65wrhR0P62zqXux55lwN3O-1024.npz
train_Episode has 500 steps and return 253.1.
Starting evaluation at step 194000 Counter(194000) 193937
Saved chunk: 20230922T014127F220640-0LcdOQQYOwGSX9ILLTi44U-4oaKJx3wi7497S4jiIfa8i-1024.npz
eval_Episode has 500 steps and return 288.3.
train_Episode has 500 steps and return 271.1.
Starting evaluation at step 194500 Counter(194500) 194437
eval_Episode has 500 steps and return 305.0.
Saved chunk: 20230922T014212F313641-65wrhR0P62zqXux55lwN3O-7DlsyekXwGxremkxdy4Aer-1024.npz
train_Episode has 500 steps and return 256.9.
Starting evaluation at step 195000 Counter(195000) 194937
Saved chunk: 20230922T014246F014264-4oaKJx3wi7497S4jiIfa8i-7wByazsYslMZ9bmjIhzUdq-1024.npz
eval_Episode has 500 steps and return 315.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 390510 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 315.94 / eval_episode/reward_rate 0.53 / episode/length 500 / episode/score 256.87 / episode/reward_rate 0.46 / train/action_mag 2.86 / train/action_max 2.83 / train/action_mean 0.09 / train/action_min -2.22 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.37 / train/actor_opt_grad_steps 9.6e4 / train/actor_opt_loss -26.05 / train/adv_mag 0.61 / train/adv_max 0.52 / train/adv_mean 
3.5e-3 / train/adv_min -0.4 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate
1 / train/dyn_loss_mean 4 / train/dyn_loss_std 6.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 9.6e4 / 
train/extr_critic_critic_opt_loss 6940.35 / train/extr_critic_mag 217.14 / train/extr_critic_max 217.14 / train/extr_critic_mean 207.15 / train/extr_critic_min 168.34 / train/extr_critic_std 8.3 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 217.84 / train/extr_return_raw_max 217.84 / train/extr_return_raw_mean 207.25 / train/extr_return_raw_min 
173.83 / train/extr_return_raw_std 8.21 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.34 / train/image_loss_std 1.11 / train/model_loss_mean 3.92 / 
train/model_loss_std 4.62 / train/model_opt_grad_norm 9.66 / train/model_opt_grad_steps 9.6e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9497.35 / train/policy_entropy_mag 3.55 / 
train/policy_entropy_max 2.18 / train/policy_entropy_mean -2.88 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.74 / train/policy_logprob_mag 8.67 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.88 / train/policy_logprob_min -8.67 / 
train/policy_logprob_std 1.61 / train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 5.3e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.76 / train/post_ent_max 50.76 / 
train/post_ent_mean 41.16 / train/post_ent_min 19.68 / train/post_ent_std 5.43 / train/prior_ent_mag 72.25 / train/prior_ent_max 72.25 / train/prior_ent_mean 45.16 / train/prior_ent_min 28.19 / train/prior_ent_std 5.58 / train/rep_loss_mean 4 / train/rep_loss_std 6.22 /
train/reward_avg 0.3 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.3 / 
train/reward_rate 0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.03 / report/cont_avg 1 / report/cont_loss_mean 4.8e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 6.01 / report/image_loss_mean 1.22 / report/image_loss_std 0.83 / report/model_loss_mean 3.63 / report/model_loss_std 4.26 / report/post_ent_mag 
50.38 / report/post_ent_max 50.38 / report/post_ent_mean 41.27 / report/post_ent_min 23.02 / report/post_ent_std 4.93 / report/prior_ent_mag 72.32 / report/prior_ent_max 72.32 / report/prior_ent_mean 45.12 / report/prior_ent_min 27.77 / report/prior_ent_std 5.23 / 
report/rep_loss_mean 3.75 / report/rep_loss_std 6.01 / report/reward_avg 0.26 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.3 / report/reward_max_data 1.99 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 3.4e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.26 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 7.8e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 7.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.87 / eval/dyn_loss_std 6.86 / eval/image_loss_mean 1.38 / eval/image_loss_std 1.45 / eval/model_loss_mean 4.58 / eval/model_loss_std 5.27 / eval/post_ent_mag 50.61 / 
eval/post_ent_max 50.61 / eval/post_ent_mean 42.36 / eval/post_ent_min 16.27 / eval/post_ent_std 4.95 / eval/prior_ent_mag 72.32 / eval/prior_ent_max 72.32 / eval/prior_ent_mean 46.96 / eval/prior_ent_min 34.51 / eval/prior_ent_std 4.17 / eval/rep_loss_mean 4.87 / 
eval/rep_loss_std 6.86 / eval/reward_avg 0.51 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / 
eval/reward_pred 0.51 / eval/reward_rate 0.47 / replay/size 2e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 
4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3786 / timer/env.step_total 19.62 / 
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.06 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
7.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 18.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.4e-4 / 
timer/agent.train_count 1893 / timer/agent.train_total 241.47 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 269.1.
Starting evaluation at step 195500 Counter(195500) 195437
eval_Episode has 500 steps and return 274.3.
Saved chunk: 20230922T014332F241555-7DlsyekXwGxremkxdy4Aer-7zVBhQqFdkOpoBZuVjtTts-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T014453F113285-7zVBhQqFdkOpoBZuVjtTts-0000000000000000000000-16.npz
Saved chunk: 20230922T014404F314399-7wByazsYslMZ9bmjIhzUdq-0000000000000000000000-906.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 260.4.
Starting evaluation at step 196000 Counter(196000) 195937
Saved chunk: 20230922T014404F314399-7wByazsYslMZ9bmjIhzUdq-5KrWv3k8yfoHQOgt40uEwO-1024.npz
eval_Episode has 500 steps and return 321.3.
train_Episode has 500 steps and return 268.8.
Starting evaluation at step 196500 Counter(196500) 196437
eval_Episode has 500 steps and return 315.7.
Saved chunk: 20230922T014453F113285-7zVBhQqFdkOpoBZuVjtTts-6ebeeHgkp1fjE5SX2vlEDb-1024.npz
train_Episode has 500 steps and return 301.4.
Starting evaluation at step 197000 Counter(197000) 196937
Saved chunk: 20230922T014524F131691-5KrWv3k8yfoHQOgt40uEwO-2fnGqOyAVVREojy4QwnydE-1024.npz
eval_Episode has 500 steps and return 294.5.
train_Episode has 500 steps and return 281.7.
Starting evaluation at step 197500 Counter(197500) 197437
eval_Episode has 500 steps and return 277.5.
Saved chunk: 20230922T014613F948150-6ebeeHgkp1fjE5SX2vlEDb-03xAxRTWGnvr8JBmlFWCJx-1024.npz
train_Episode has 500 steps and return 282.3.
Starting evaluation at step 198000 Counter(198000) 197937
Saved chunk: 20230922T014643F032368-2fnGqOyAVVREojy4QwnydE-33tgBRQ0xqn7lvOUk5Lu7a-1024.npz
eval_Episode has 500 steps and return 275.9.
train_Episode has 500 steps and return 291.6.
Starting evaluation at step 198500 Counter(198500) 198437
eval_Episode has 500 steps and return 314.2.
Saved chunk: 20230922T014734F164323-03xAxRTWGnvr8JBmlFWCJx-5z0SUH3n86nFBo4JTYViZl-1024.npz
train_Episode has 500 steps and return 282.3.
Starting evaluation at step 199000 Counter(199000) 198937
Saved chunk: 20230922T014801F651694-33tgBRQ0xqn7lvOUk5Lu7a-45iQx3YcPjHmNeAsVrSa5t-1024.npz
eval_Episode has 500 steps and return 324.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 398078 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 282.34 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 324.61 / eval_episode/reward_rate 0.55 / train/action_mag 2.87 / train/action_max 2.85 / train/action_mean 0.1 / train/action_min -2.1 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.39 / train/actor_opt_grad_steps 9.8e4 / train/actor_opt_loss -23.85 / train/adv_mag 0.56 / train/adv_max 0.45 / train/adv_mean 3.3e-3 / 
train/adv_min -0.46 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 9.8e4 / 
train/extr_critic_critic_opt_loss 6866.21 / train/extr_critic_mag 218.61 / train/extr_critic_max 218.61 / train/extr_critic_mean 208.68 / train/extr_critic_min 173.72 / train/extr_critic_std 8.02 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.69 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 219.18 / train/extr_return_raw_max 219.18 / train/extr_return_raw_mean 208.77 / train/extr_return_raw_min 
176.25 / train/extr_return_raw_std 8 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.31 / train/image_loss_std 1.08 / train/model_loss_mean 3.86 / 
train/model_loss_std 4.58 / train/model_opt_grad_norm 9.74 / train/model_opt_grad_steps 9.8e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 2
/ train/policy_entropy_mean -2.9 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.73 / train/policy_logprob_mag 8.48 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.9 / train/policy_logprob_min -8.48 / train/policy_logprob_std 1.6 / 
train/policy_randomness_mag 0.6 / train/policy_randomness_max 0.6 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.86 / train/post_ent_max 50.86 / train/post_ent_mean 41.25 / 
train/post_ent_min 19.66 / train/post_ent_std 5.51 / train/prior_ent_mag 72.25 / train/prior_ent_max 72.25 / train/prior_ent_mean 45.21 / train/prior_ent_min 27.59 / train/prior_ent_std 5.68 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.2 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.3 / train/reward_rate 0.3 
/ train_stats/mean_log_entropy -3.05 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 6.05 / report/image_loss_mean 1.27 / report/image_loss_std 1.18 / report/model_loss_mean 3.74 / report/model_loss_std 4.61 / report/post_ent_mag 51.13 / report/post_ent_max 51.13 /
report/post_ent_mean 40.73 / report/post_ent_min 20.62 / report/post_ent_std 6.02 / report/prior_ent_mag 72.22 / report/prior_ent_max 72.22 / report/prior_ent_mean 44.77 / report/prior_ent_min 26.9 / report/prior_ent_std 6.47 / report/rep_loss_mean 3.84 / 
report/rep_loss_std 6.05 / report/reward_avg 0.28 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.27 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.94 / eval/dyn_loss_std 6.11 / eval/image_loss_mean 1.34 / eval/image_loss_std 1.11 / eval/model_loss_mean 4.62 / eval/model_loss_std 4.71 / eval/post_ent_mag 50.88 / eval/post_ent_max 50.88 / eval/post_ent_mean 
42.2 / eval/post_ent_min 20.49 / eval/post_ent_std 4.65 / eval/prior_ent_mag 72.22 / eval/prior_ent_max 72.22 / eval/prior_ent_mean 46.94 / eval/prior_ent_min 32.68 / eval/prior_ent_std 3.98 / eval/rep_loss_mean 4.94 / eval/rep_loss_std 6.11 / eval/reward_avg 0.49 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.62 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.69 / eval/reward_pred 0.48 / eval/reward_rate 0.44 / 
replay/size 2e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3784 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.08 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7792 / timer/agent.policy_total 18.36 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1892 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1892 / timer/agent.train_total 241.53 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 275.6.
Starting evaluation at step 199500 Counter(199500) 199437
eval_Episode has 500 steps and return 337.8.
Saved chunk: 20230922T014854F362422-5z0SUH3n86nFBo4JTYViZl-0kMCRRjNFpr2amWFsAFrWg-1024.npz
train_Episode has 500 steps and return 273.5.
Starting evaluation at step 200000 Counter(200000) 199937
Saved chunk: 20230922T014920F261700-45iQx3YcPjHmNeAsVrSa5t-7f0U7twA225ulSviB4WUei-1024.npz
eval_Episode has 500 steps and return 300.6.
train_Episode has 500 steps and return 277.6.
Starting evaluation at step 200500 Counter(200500) 200437
eval_Episode has 500 steps and return 331.9.
Saved chunk: 20230922T015015F542889-0kMCRRjNFpr2amWFsAFrWg-489OPNq3a0rLLiq0AukvVq-1024.npz
train_Episode has 500 steps and return 296.2.
Starting evaluation at step 201000 Counter(201000) 200937
Saved chunk: 20230922T015039F975077-7f0U7twA225ulSviB4WUei-51NBazfCOmAmPMLjnHbt3e-1024.npz
eval_Episode has 500 steps and return 319.5.
train_Episode has 500 steps and return 273.8.
Starting evaluation at step 201500 Counter(201500) 201437
eval_Episode has 500 steps and return 301.1.
Saved chunk: 20230922T015135F921653-489OPNq3a0rLLiq0AukvVq-1JyDPBqkaATLB35hTrQmQi-1024.npz
train_Episode has 500 steps and return 301.2.
Starting evaluation at step 202000 Counter(202000) 201937
Saved chunk: 20230922T015158F732791-51NBazfCOmAmPMLjnHbt3e-0XjTtpgqJe0HyDnPJCqi7o-1024.npz
eval_Episode has 500 steps and return 275.9.
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 202500 Counter(202500) 202437
eval_Episode has 500 steps and return 279.7.
Saved chunk: 20230922T015256F188438-1JyDPBqkaATLB35hTrQmQi-02rtgrLOs22QyFIRx0GCgT-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 405750 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 280.83 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 279.66 / eval_episode/reward_rate 0.52 / train/action_mag 2.86 / train/action_max 2.85 / train/action_mean 0.1 / train/action_min -2.07 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.46 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -30.21 / train/adv_mag 0.68 / train/adv_max 0.57 / train/adv_mean 4e-3 / train/adv_min 
-0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.5e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.97 / train/dyn_loss_std 6.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 7087.79 / train/extr_critic_mag 220.32 / train/extr_critic_max 220.32 / train/extr_critic_mean 210.78 / train/extr_critic_min 178.55 / train/extr_critic_std 6.95 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.66 / train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 221.03 / train/extr_return_raw_max 221.03 / train/extr_return_raw_mean 210.88 / train/extr_return_raw_min 
182.92 / train/extr_return_raw_std 6.98 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.3 / train/image_loss_std 1.08 / train/model_loss_mean 3.87 / 
train/model_loss_std 4.58 / train/model_opt_grad_norm 9.68 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.75 / train/policy_entropy_mean -2.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.38 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.94 / train/policy_logprob_min -8.38 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.1e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.92 / train/post_ent_max 50.92 / train/post_ent_mean 41.44 / 
train/post_ent_min 19.8 / train/post_ent_std 5.42 / train/prior_ent_mag 72.28 / train/prior_ent_max 72.28 / train/prior_ent_mean 45.39 / train/prior_ent_min 27.88 / train/prior_ent_std 5.56 / train/rep_loss_mean 3.97 / train/rep_loss_std 6.18 / train/reward_avg 0.32 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.32 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -3.08 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.3e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.93 / report/dyn_loss_std 5.65 / report/image_loss_mean 1.24 / report/image_loss_std 0.86 / report/model_loss_mean 3.82 / report/model_loss_std 4.05 / report/post_ent_mag 51.2 / report/post_ent_max 51.2 / 
report/post_ent_mean 42.51 / report/post_ent_min 19.45 / report/post_ent_std 4.74 / report/prior_ent_mag 72.2 / report/prior_ent_max 72.2 / report/prior_ent_mean 46.62 / report/prior_ent_min 32.12 / report/prior_ent_std 4.49 / report/rep_loss_mean 3.93 / 
report/rep_loss_std 5.65 / report/reward_avg 0.37 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.38 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 7.6e-11 / eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.96 / eval/dyn_loss_std 6.93 / eval/image_loss_mean 1.48 / eval/image_loss_std 1.64 / eval/model_loss_mean 4.73 / eval/model_loss_std 5.54 / eval/post_ent_mag 50.28 / eval/post_ent_max 50.28 / eval/post_ent_mean 
42.17 / eval/post_ent_min 21.43 / eval/post_ent_std 4.9 / eval/prior_ent_mag 72.2 / eval/prior_ent_max 72.2 / eval/prior_ent_mean 46.79 / eval/prior_ent_min 30.54 / eval/prior_ent_std 4.21 / eval/rep_loss_mean 4.96 / eval/rep_loss_std 6.93 / eval/reward_avg 0.46 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.47 / eval/reward_rate 0.43 / 
replay/size 2e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3836 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458.9 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1918 / timer/agent.train_total 244.66 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 260.1.
Starting evaluation at step 203000 Counter(203000) 202937
Saved chunk: 20230922T015317F370792-0XjTtpgqJe0HyDnPJCqi7o-7CvQpvNpwz1j96tb3LEtfV-1024.npz
eval_Episode has 500 steps and return 286.9.
train_Episode has 500 steps and return 271.5.
Starting evaluation at step 203500 Counter(203500) 203437
eval_Episode has 500 steps and return 320.1.
Saved chunk: 20230922T015416F469433-02rtgrLOs22QyFIRx0GCgT-1vsTVOCRZXwnvx83TLmqxP-1024.npz
train_Episode has 500 steps and return 296.6.
Starting evaluation at step 204000 Counter(204000) 203937
Saved chunk: 20230922T015436F883429-7CvQpvNpwz1j96tb3LEtfV-05F6TPr3sSJ17Riwxkc6pa-1024.npz
eval_Episode has 500 steps and return 328.1.
train_Episode has 500 steps and return 297.2.
Starting evaluation at step 204500 Counter(204500) 204437
eval_Episode has 500 steps and return 283.4.
Saved chunk: 20230922T015537F843485-1vsTVOCRZXwnvx83TLmqxP-1GWBNXT5ftf2sWh6TBYD74-1024.npz
train_Episode has 500 steps and return 262.1.
Starting evaluation at step 205000 Counter(205000) 204937
Saved chunk: 20230922T015557F148585-05F6TPr3sSJ17Riwxkc6pa-5Aa05VjgdBZ7kjkbnY7Sbc-1024.npz
eval_Episode has 500 steps and return 310.9.
train_Episode has 500 steps and return 260.9.
Starting evaluation at step 205500 Counter(205500) 205437
eval_Episode has 500 steps and return 303.6.
Saved chunk: 20230922T015659F334668-1GWBNXT5ftf2sWh6TBYD74-1ASJ9noAXQjAbXDzwtukNb-1024.npz
train_Episode has 500 steps and return 263.7.
Starting evaluation at step 206000 Counter(206000) 205937
Saved chunk: 20230922T015715F832369-5Aa05VjgdBZ7kjkbnY7Sbc-0emMNVJ4VemtaIlyzOA8Al-1024.npz
eval_Episode has 500 steps and return 320.4.
train_Episode has 500 steps and return 288.7.
Starting evaluation at step 206500 Counter(206500) 206437
eval_Episode has 500 steps and return 282.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 413302 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 288.66 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 282.73 / eval_episode/reward_rate 0.53 / train/action_mag 2.75 / train/action_max 2.74 / train/action_mean 0.1 / train/action_min -1.95 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -34.16 / train/adv_mag 0.65 / train/adv_max 0.54 / train/adv_mean 4.4e-3 / train/adv_min 
-0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.4e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 8011.16 / train/extr_critic_mag 222.68 / train/extr_critic_max 222.68 / train/extr_critic_mean 213.46 / train/extr_critic_min 186.67 / train/extr_critic_std 6.08 / train/extr_return_normed_mag 1.16 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 223.33 / train/extr_return_raw_max 223.33 / train/extr_return_raw_mean 213.55 / train/extr_return_raw_min 
189.64 / train/extr_return_raw_std 6.14 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.29 / train/image_loss_std 1.09 / train/model_loss_mean 3.85 / 
train/model_loss_std 4.55 / train/model_opt_grad_norm 9.94 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.18 / train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 8.16 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.01 / train/policy_logprob_min -8.16 / train/policy_logprob_std 1.55 / 
train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 51.03 / train/post_ent_max 51.03 / train/post_ent_mean 41.54 / 
train/post_ent_min 19.99 / train/post_ent_std 5.4 / train/prior_ent_mag 72.27 / train/prior_ent_max 72.27 / train/prior_ent_mean 45.49 / train/prior_ent_min 28.27 / train/prior_ent_std 5.53 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.13 / train/reward_avg 0.32 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.32 / train/reward_rate 
0.32 / train_stats/mean_log_entropy -3.12 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 9.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 6.45 / report/image_loss_mean 1.5 / report/image_loss_std 1.12 / report/model_loss_mean 4.03 / report/model_loss_std 4.76 / report/post_ent_mag 50.11 / report/post_ent_max 50.11 / 
report/post_ent_mean 40.31 / report/post_ent_min 20.29 / report/post_ent_std 5.74 / report/prior_ent_mag 72.49 / report/prior_ent_max 72.49 / report/prior_ent_mean 44.48 / report/prior_ent_min 26.56 / report/prior_ent_std 5.95 / report/rep_loss_mean 3.99 / 
report/rep_loss_std 6.45 / report/reward_avg 0.24 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.27 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.24 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.14 / eval/dyn_loss_std 5.97 / eval/image_loss_mean 1.24 / eval/image_loss_std 1.26 / eval/model_loss_mean 4.03 / eval/model_loss_std 4.6 / eval/post_ent_mag 51.56 / eval/post_ent_max 51.56 / eval/post_ent_mean 
42.84 / eval/post_ent_min 20.08 / eval/post_ent_std 4.24 / eval/prior_ent_mag 72.49 / eval/prior_ent_max 72.49 / eval/prior_ent_mean 46.92 / eval/prior_ent_min 30.33 / eval/prior_ent_std 3.95 / eval/rep_loss_mean 4.14 / eval/rep_loss_std 5.97 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.58 / eval/reward_rate 0.52 / 
replay/size 2.1e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3776 / timer/env.step_total 19.46 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.1e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.26 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.13 / 
timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1888 / timer/agent.train_total 241.78 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T015819F385072-1ASJ9noAXQjAbXDzwtukNb-0RjerCXm6Mg8NMKhxpWKry-1024.npz
train_Episode has 500 steps and return 300.3.
Starting evaluation at step 207000 Counter(207000) 206937
Saved chunk: 20230922T015834F279531-0emMNVJ4VemtaIlyzOA8Al-2BXapkd4QDtlMZX9JV94JF-1024.npz
eval_Episode has 500 steps and return 275.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T015940F231872-0RjerCXm6Mg8NMKhxpWKry-0000000000000000000000-252.npz
Saved chunk: 20230922T015953F667312-2BXapkd4QDtlMZX9JV94JF-0000000000000000000000-141.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 296.0.
Starting evaluation at step 207500 Counter(207500) 207437
eval_Episode has 500 steps and return 292.5.
Saved chunk: 20230922T015940F231872-0RjerCXm6Mg8NMKhxpWKry-6tKnfvkRK2aayzsnpSTtZd-1024.npz
train_Episode has 500 steps and return 288.9.
Starting evaluation at step 208000 Counter(208000) 207937
Saved chunk: 20230922T015953F667312-2BXapkd4QDtlMZX9JV94JF-1XeevMGpPhc4jLrFNlXeEW-1024.npz
eval_Episode has 500 steps and return 315.9.
train_Episode has 500 steps and return 256.0.
Starting evaluation at step 208500 Counter(208500) 208437
eval_Episode has 500 steps and return 324.3.
Saved chunk: 20230922T020101F001870-6tKnfvkRK2aayzsnpSTtZd-3RzkcUzcZPjCuBjmUnR3Gg-1024.npz
train_Episode has 500 steps and return 266.3.
Starting evaluation at step 209000 Counter(209000) 208937
eval_Episode has 500 steps and return 315.8.
Saved chunk: 20230922T020112F808882-1XeevMGpPhc4jLrFNlXeEW-0ilSfpNL9ElVBXuM4Ef4JK-1024.npz
train_Episode has 500 steps and return 273.2.
Starting evaluation at step 209500 Counter(209500) 209437
eval_Episode has 500 steps and return 328.4.
train_Episode has 500 steps and return 303.1.
Saved chunk: 20230922T020221F258188-3RzkcUzcZPjCuBjmUnR3Gg-4QhurwY4HMspSjNKT6ibc6-1024.npz
Starting evaluation at step 210000 Counter(210000) 209937
eval_Episode has 500 steps and return 249.4.
Saved chunk: 20230922T020231F505083-0ilSfpNL9ElVBXuM4Ef4JK-1sVUjbgNCt778LTucZQp0l-1024.npz
train_Episode has 500 steps and return 296.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 420978 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 296.47 / episode/reward_rate 0.53 / eval_episode/length 500 / eval_episode/score 249.39 / eval_episode/reward_rate 0.49 / train/action_mag 2.75 / train/action_max 2.74 / train/action_mean 0.09 / train/action_min -1.99 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.46 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -31.8 / train/adv_mag 0.59 / train/adv_max 0.47 / train/adv_mean 4.1e-3 
/ train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 9406.75 / train/extr_critic_mag 225.29 / train/extr_critic_max 225.29 / train/extr_critic_mean 215.81 / train/extr_critic_min 189.84 / train/extr_critic_std 6.22 / train/extr_return_normed_mag 1.14 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.49 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 226 / train/extr_return_raw_max 226 / train/extr_return_raw_mean 215.89 / train/extr_return_raw_min 191.99 
/ train/extr_return_raw_std 6.27 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.3 / train/image_loss_std 1.11 / train/model_loss_mean 3.87 / 
train/model_loss_std 4.58 / train/model_opt_grad_norm 9.6 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.29 / train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.63 / train/policy_logprob_mag 8.31 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.01 / train/policy_logprob_min -8.31 / train/policy_logprob_std 1.55 / 
train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.97 / train/post_ent_max 50.97 / train/post_ent_mean 41.45 / 
train/post_ent_min 19.85 / train/post_ent_std 5.39 / train/prior_ent_mag 72.27 / train/prior_ent_max 72.27 / train/prior_ent_mean 45.41 / train/prior_ent_min 28.68 / train/prior_ent_std 5.55 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.17 / train/reward_avg 0.32 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.32 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -3.13 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.2e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.09 / report/dyn_loss_std 6.41 / report/image_loss_mean 1.41 / report/image_loss_std 1.22 / report/model_loss_mean 4.02 / report/model_loss_std 4.75 / report/post_ent_mag 51.67 / report/post_ent_max 51.67 /
report/post_ent_mean 41.21 / report/post_ent_min 21.21 / report/post_ent_std 5.45 / report/prior_ent_mag 72.25 / report/prior_ent_max 72.25 / report/prior_ent_mean 45.52 / report/prior_ent_min 31.05 / report/prior_ent_std 5.23 / report/rep_loss_mean 4.09 / 
report/rep_loss_std 6.41 / report/reward_avg 0.3 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.29 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.91 / eval/dyn_loss_std 6.55 / eval/image_loss_mean 1.47 / eval/image_loss_std 1.59 / eval/model_loss_mean 4.74 / eval/model_loss_std 5.23 / eval/post_ent_mag 50.51 / eval/post_ent_max 50.51 / eval/post_ent_mean 
42.25 / eval/post_ent_min 18.89 / eval/post_ent_std 4.81 / eval/prior_ent_mag 72.25 / eval/prior_ent_max 72.25 / eval/prior_ent_mean 46.81 / eval/prior_ent_min 33.18 / eval/prior_ent_std 4.09 / eval/rep_loss_mean 4.91 / eval/rep_loss_std 6.55 / eval/reward_avg 0.51 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-2 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.49 / eval/reward_rate 0.49 / 
replay/size 2.1e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3838 / timer/env.step_total 19.91 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.21 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7345 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 244.49 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / 
timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 210500 Counter(210500) 210437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 296.2.
train_Episode has 500 steps and return 282.4.
Saved chunk: 20230922T020341F284588-4QhurwY4HMspSjNKT6ibc6-4ofj8tR7TsMk6c3AcIBWjl-1024.npz
Starting evaluation at step 211000 Counter(211000) 210937
eval_Episode has 500 steps and return 316.2.
Saved chunk: 20230922T020349F986233-1sVUjbgNCt778LTucZQp0l-0WpgTcqDmfnygp5zlAa1lJ-1024.npz
train_Episode has 500 steps and return 314.7.
Starting evaluation at step 211500 Counter(211500) 211437
eval_Episode has 500 steps and return 320.1.
train_Episode has 500 steps and return 269.3.
Saved chunk: 20230922T020502F405166-4ofj8tR7TsMk6c3AcIBWjl-5JKDgL8Ni1DgACR1uHdKTA-1024.npz
Starting evaluation at step 212000 Counter(212000) 211937
eval_Episode has 500 steps and return 344.3.
Saved chunk: 20230922T020509F570876-0WpgTcqDmfnygp5zlAa1lJ-7CvOYRtnHdPJM6WpYM0hWf-1024.npz
train_Episode has 500 steps and return 246.2.
Starting evaluation at step 212500 Counter(212500) 212437
eval_Episode has 500 steps and return 292.7.
train_Episode has 500 steps and return 296.4.
Starting evaluation at step 213000 Counter(213000) 212937
Saved chunk: 20230922T020622F859770-5JKDgL8Ni1DgACR1uHdKTA-5Ql6mEdQR6oCPYlTjRgTzL-1024.npz
eval_Episode has 500 steps and return 319.6.
Saved chunk: 20230922T020628F452253-7CvOYRtnHdPJM6WpYM0hWf-4b7ASuiS1H6HH2vyV7UDNF-1024.npz
train_Episode has 500 steps and return 314.2.
Starting evaluation at step 213500 Counter(213500) 213437
eval_Episode has 500 steps and return 294.8.
train_Episode has 500 steps and return 251.3.
Starting evaluation at step 214000 Counter(214000) 213937
eval_Episode has 500 steps and return 306.3.
Saved chunk: 20230922T020743F187425-5Ql6mEdQR6oCPYlTjRgTzL-3dSb9iwhU3ccZZpg0MOgMi-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 428558 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 306.32 / eval_episode/reward_rate 0.51 / episode/length 500 / episode/score 251.29 / episode/reward_rate 0.43 / train/action_mag 2.75 / train/action_max 2.74 / train/action_mean 0.09 / train/action_min -1.97 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.48 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -25.28 / train/adv_mag 0.62 / train/adv_max 0.47 / train/adv_mean 
3.5e-3 / train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.2e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.95 / train/dyn_loss_std 6.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / 
train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 227.81 / train/extr_critic_max 227.81 / train/extr_critic_mean 218.44 / train/extr_critic_min 190.73 / train/extr_critic_std 6.17 / 
train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 228.64 / train/extr_return_raw_max 
228.64 / train/extr_return_raw_mean 218.51 / train/extr_return_raw_min 194.08 / train/extr_return_raw_std 6.23 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.33 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / 
train/image_loss_mean 1.28 / train/image_loss_std 1.07 / train/model_loss_mean 3.84 / train/model_loss_std 4.55 / train/model_opt_grad_norm 9.91 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.29 / train/policy_entropy_mean -3.05 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 8 / train/policy_logprob_max 5.5 / 
train/policy_logprob_mean 3.05 / train/policy_logprob_min -8 / train/policy_logprob_std 1.54 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.07
/ train/post_ent_mag 50.99 / train/post_ent_max 50.99 / train/post_ent_mean 41.72 / train/post_ent_min 20.08 / train/post_ent_std 5.27 / train/prior_ent_mag 72.29 / train/prior_ent_max 72.29 / train/prior_ent_mean 45.66 / train/prior_ent_min 28.86 / train/prior_ent_std 
5.39 / train/rep_loss_mean 3.95 / train/rep_loss_std 6.14 / train/reward_avg 0.33 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 
1 / train/reward_pos_loss 0.58 / train/reward_pred 0.33 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.16 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 3.1e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 5.92 / report/image_loss_mean 1.26 / report/image_loss_std 0.94 / report/model_loss_mean 3.62 / 
report/model_loss_std 4.35 / report/post_ent_mag 50.46 / report/post_ent_max 50.46 / report/post_ent_mean 40.83 / report/post_ent_min 22.78 / report/post_ent_std 5.74 / report/prior_ent_mag 72.26 / report/prior_ent_max 72.26 / report/prior_ent_mean 44.6 / 
report/prior_ent_min 25.17 / report/prior_ent_std 6.26 / report/rep_loss_mean 3.64 / report/rep_loss_std 5.92 / report/reward_avg 0.27 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / 
report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.26 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 7.4e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.23 / eval/dyn_loss_std 7.01 / eval/image_loss_mean 1.72 / eval/image_loss_std 2.41 / eval/model_loss_mean 5.17 / eval/model_loss_std 
6.11 / eval/post_ent_mag 51.08 / eval/post_ent_max 51.08 / eval/post_ent_mean 42.06 / eval/post_ent_min 18.03 / eval/post_ent_std 4.87 / eval/prior_ent_mag 72.26 / eval/prior_ent_max 72.26 / eval/prior_ent_mean 46.66 / eval/prior_ent_min 32.25 / eval/prior_ent_std 4.28 
/ eval/rep_loss_mean 5.23 / eval/rep_loss_std 7.01 / eval/reward_avg 0.49 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.46 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.04 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.64 / eval/reward_pred 0.48 / eval/reward_rate 0.46 / replay/size 2.1e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3790 / 
timer/env.step_total 19.62 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.74 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 
/ timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 17.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 9e-3 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.3e-4 / 
timer/agent.train_count 1895 / timer/agent.train_total 240.95 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 262.6.
Starting evaluation at step 214500 Counter(214500) 214437
Saved chunk: 20230922T020747F210628-4b7ASuiS1H6HH2vyV7UDNF-79Op8DmwYBqCtYFdOOkimI-1024.npz
eval_Episode has 500 steps and return 316.2.
train_Episode has 500 steps and return 271.8.
Starting evaluation at step 215000 Counter(215000) 214937
eval_Episode has 500 steps and return 325.4.
Saved chunk: 20230922T020906F732066-3dSb9iwhU3ccZZpg0MOgMi-5bO8VElkebG6j7P4OE6wgv-1024.npz
train_Episode has 500 steps and return 263.6.
Starting evaluation at step 215500 Counter(215500) 215437
Saved chunk: 20230922T020942F181721-79Op8DmwYBqCtYFdOOkimI-4kQOj06E01N8DgbZvMRKQJ-1024.npz
eval_Episode has 500 steps and return 314.5.
train_Episode has 500 steps and return 305.5.
Starting evaluation at step 216000 Counter(216000) 215937
eval_Episode has 500 steps and return 316.8.
Saved chunk: 20230922T021028F096692-5bO8VElkebG6j7P4OE6wgv-5mWFoHlkDD7KumOdT9Bgnl-1024.npz
train_Episode has 500 steps and return 263.3.
Starting evaluation at step 216500 Counter(216500) 216437
Saved chunk: 20230922T021101F338966-4kQOj06E01N8DgbZvMRKQJ-1wpqDH5kyV8W0ITZCh9dGN-1024.npz
eval_Episode has 500 steps and return 286.2.
train_Episode has 500 steps and return 290.2.
Starting evaluation at step 217000 Counter(217000) 216937
eval_Episode has 500 steps and return 307.0.
Saved chunk: 20230922T021148F675029-5mWFoHlkDD7KumOdT9Bgnl-1dI8uWLvChNQw3BStE42CN-1024.npz
train_Episode has 500 steps and return 300.8.
Starting evaluation at step 217500 Counter(217500) 217437
Saved chunk: 20230922T021220F329757-1wpqDH5kyV8W0ITZCh9dGN-5IXdgPdFLCw7rTfrJ0Ukpf-1024.npz
eval_Episode has 500 steps and return 327.8.
train_Episode has 500 steps and return 294.6.
Starting evaluation at step 218000 Counter(218000) 217937
eval_Episode has 500 steps and return 327.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 436120 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 294.6 / episode/reward_rate 0.51 / eval_episode/length 500 / eval_episode/score 327.38 / eval_episode/reward_rate 0.54 / train/action_mag 2.75 / train/action_max 2.74 / train/action_mean 0.09 / train/action_min -1.94 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -14.43 / train/adv_mag 0.73 / train/adv_max 0.6 / train/adv_mean 2.4e-3 / train/adv_min
-0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 230.05 / train/extr_critic_max 230.05 / train/extr_critic_mean 220.61 / train/extr_critic_min 189.49 / train/extr_critic_std 6.26 / train/extr_return_normed_mag 1.16 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.59 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 230.83 / train/extr_return_raw_max 230.83 / train/extr_return_raw_mean 220.66 / train/extr_return_raw_min 
194.94 / train/extr_return_raw_std 6.31 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.33 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.27 / train/image_loss_std 1.08 / train/model_loss_mean 3.83 /
train/model_loss_std 4.53 / train/model_opt_grad_norm 9.38 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.22 / train/policy_entropy_mean -3.07 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.61 / train/policy_logprob_mag 8.01 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.07 / train/policy_logprob_min -8.01 / 
train/policy_logprob_std 1.55 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 51.12 / train/post_ent_max 51.12 / 
train/post_ent_mean 41.8 / train/post_ent_min 20.1 / train/post_ent_std 5.34 / train/prior_ent_mag 72.26 / train/prior_ent_max 72.26 / train/prior_ent_mean 45.74 / train/prior_ent_min 28.59 / train/prior_ent_std 5.43 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.12 
/ train/reward_avg 0.33 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 
0.33 / train/reward_rate 0.33 / train_stats/mean_log_entropy -3.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.3e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 6.3 / report/image_loss_mean 1.26 / report/image_loss_std 1.05 / report/model_loss_mean 3.69 / report/model_loss_std 4.64 / report/post_ent_mag 51.03
/ report/post_ent_max 51.03 / report/post_ent_mean 42.44 / report/post_ent_min 23.4 / report/post_ent_std 4.58 / report/prior_ent_mag 72.39 / report/prior_ent_max 72.39 / report/prior_ent_mean 46.21 / report/prior_ent_min 31.97 / report/prior_ent_std 4.72 / 
report/rep_loss_mean 3.76 / report/rep_loss_std 6.3 / report/reward_avg 0.31 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.31 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 8.14 / eval/dyn_loss_std 14.77 / eval/image_loss_mean 3.11 / eval/image_loss_std 7.13 / eval/model_loss_mean 8.27 / eval/model_loss_std 15.64 / eval/post_ent_mag 51.25 / 
eval/post_ent_max 51.25 / eval/post_ent_mean 41.5 / eval/post_ent_min 18.17 / eval/post_ent_std 5.76 / eval/prior_ent_mag 72.39 / eval/prior_ent_max 72.39 / eval/prior_ent_mean 46.68 / eval/prior_ent_min 33.84 / eval/prior_ent_std 4.41 / eval/rep_loss_mean 8.14 / 
eval/rep_loss_std 14.77 / eval/reward_avg 0.5 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / 
eval/reward_pred 0.5 / eval/reward_rate 0.47 / replay/size 2.2e5 / replay/inserts 3781 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3781 / timer/env.step_total 19.53
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.68 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7789 / timer/agent.policy_total 17.86 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1890 / timer/agent.train_total 241.13 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 5.1e-5 / timer/dataset_eval_frac 1.7e-7 / timer/dataset_eval_avg 5.1e-5 / timer/dataset_eval_min 5.1e-5 / 
timer/dataset_eval_max 5.1e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T021309F110146-1dI8uWLvChNQw3BStE42CN-1afeo2dICj0aM6VV1H9vrS-1024.npz
train_Episode has 500 steps and return 296.8.
Starting evaluation at step 218500 Counter(218500) 218437
Saved chunk: 20230922T021339F080227-5IXdgPdFLCw7rTfrJ0Ukpf-2MP9kNkfmRIqObVP5OExtn-1024.npz
eval_Episode has 500 steps and return 313.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T021430F001610-1afeo2dICj0aM6VV1H9vrS-0000000000000000000000-488.npz
Saved chunk: 20230922T021458F667187-2MP9kNkfmRIqObVP5OExtn-0000000000000000000000-400.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 293.8.
Starting evaluation at step 219000 Counter(219000) 218937
eval_Episode has 500 steps and return 326.5.
Saved chunk: 20230922T021430F001610-1afeo2dICj0aM6VV1H9vrS-5qXBAIkW1ah8Dt2NWU3JqT-1024.npz
train_Episode has 500 steps and return 306.2.
Starting evaluation at step 219500 Counter(219500) 219437
Saved chunk: 20230922T021458F667187-2MP9kNkfmRIqObVP5OExtn-6ewVdAasa0rvGnF7N9jCTZ-1024.npz
eval_Episode has 500 steps and return 307.9.
train_Episode has 500 steps and return 302.0.
Starting evaluation at step 220000 Counter(220000) 219937
eval_Episode has 500 steps and return 283.9.
Saved chunk: 20230922T021550F988575-5qXBAIkW1ah8Dt2NWU3JqT-4ThdOmkTo55KdbjLptAptV-1024.npz
train_Episode has 500 steps and return 267.8.
Starting evaluation at step 220500 Counter(220500) 220437
Saved chunk: 20230922T021618F029314-6ewVdAasa0rvGnF7N9jCTZ-0uSWRpr4wVTRgnHSlvGbka-1024.npz
eval_Episode has 500 steps and return 330.2.
train_Episode has 500 steps and return 296.7.
Starting evaluation at step 221000 Counter(221000) 220937
eval_Episode has 500 steps and return 329.0.
Saved chunk: 20230922T021711F575110-4ThdOmkTo55KdbjLptAptV-6PaVxw0UQWLVEMjewBJ8y1-1024.npz
train_Episode has 500 steps and return 305.2.
Starting evaluation at step 221500 Counter(221500) 221437
Saved chunk: 20230922T021736F901741-0uSWRpr4wVTRgnHSlvGbka-1qNR6pbMWRqc6nxY7eFWrZ-1024.npz
eval_Episode has 500 steps and return 336.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 443776 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 305.16 / episode/reward_rate 0.52 / eval_episode/length 500 / eval_episode/score 336.84 / eval_episode/reward_rate 0.54 / train/action_mag 2.78 / train/action_max 2.78 / train/action_mean 0.1 / train/action_min -1.95 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -12.32 / train/adv_mag 0.66 / train/adv_max 0.55 / train/adv_mean 2.2e-3 / 
train/adv_min -0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.2e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.52 / train/extr_critic_max 231.52 / train/extr_critic_mean 221.95 / train/extr_critic_min 190.21 / train/extr_critic_std 6.55 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.59 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 232.36 / train/extr_return_raw_max 232.36 / train/extr_return_raw_mean 221.99 / train/extr_return_raw_min 
195.32 / train/extr_return_raw_std 6.6 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 1.27 / train/image_loss_std 1.08 / train/model_loss_mean 3.83 / 
train/model_loss_std 4.54 / train/model_opt_grad_norm 9.54 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.45 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.64 / train/policy_logprob_mag 8.11 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -8.11 / train/policy_logprob_std 1.56 / 
train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 51.08 / train/post_ent_max 51.08 / train/post_ent_mean 41.79 / 
train/post_ent_min 19.99 / train/post_ent_std 5.33 / train/prior_ent_mag 72.29 / train/prior_ent_max 72.29 / train/prior_ent_mean 45.71 / train/prior_ent_min 28.55 / train/prior_ent_std 5.45 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.12 / train/reward_avg 0.34 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.34 / train/reward_rate 0.33 / 
train_stats/mean_log_entropy -3.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 5.8 / report/image_loss_mean 1.21 / report/image_loss_std 0.91 / report/model_loss_mean 3.64 / report/model_loss_std 4.23 / report/post_ent_mag 50.99 / report/post_ent_max 50.99 / 
report/post_ent_mean 41.26 / report/post_ent_min 17.75 / report/post_ent_std 6.68 / report/prior_ent_mag 72.38 / report/prior_ent_max 72.38 / report/prior_ent_mean 45.02 / report/prior_ent_min 23.18 / report/prior_ent_std 6.79 / report/rep_loss_mean 3.74 / 
report/rep_loss_std 5.8 / report/reward_avg 0.3 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.3 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 8.2e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.85 / eval/dyn_loss_std 6.55 / eval/image_loss_mean 1.39 / eval/image_loss_std 1.81 / eval/model_loss_mean 4.63 / eval/model_loss_std 5.35 / eval/post_ent_mag 50.69 / eval/post_ent_max 50.69 / eval/post_ent_mean 
42.44 / eval/post_ent_min 19.94 / eval/post_ent_std 4.7 / eval/prior_ent_mag 72.38 / eval/prior_ent_max 72.38 / eval/prior_ent_mean 46.89 / eval/prior_ent_min 32.6 / eval/prior_ent_std 4.17 / eval/rep_loss_mean 4.85 / eval/rep_loss_std 6.55 / eval/reward_avg 0.54 / 
eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.46 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.55 / eval/reward_rate 0.51 / 
replay/size 2.2e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3828 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 459.73 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8.1e-4 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7335 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.13 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 301.4.
Starting evaluation at step 222000 Counter(222000) 221937
eval_Episode has 500 steps and return 324.9.
Saved chunk: 20230922T021831F785636-6PaVxw0UQWLVEMjewBJ8y1-1bTcgTWY8eHC0rJzyAfc58-1024.npz
train_Episode has 500 steps and return 277.9.
Starting evaluation at step 222500 Counter(222500) 222437
Saved chunk: 20230922T021855F512269-1qNR6pbMWRqc6nxY7eFWrZ-4OF9EP3l8nJMFttFHQJWuy-1024.npz
eval_Episode has 500 steps and return 341.1.
train_Episode has 500 steps and return 297.8.
Starting evaluation at step 223000 Counter(223000) 222937
eval_Episode has 500 steps and return 309.6.
Saved chunk: 20230922T021952F911821-1bTcgTWY8eHC0rJzyAfc58-646VLSnAygaJbBaZ6okCMF-1024.npz
train_Episode has 500 steps and return 300.9.
Starting evaluation at step 223500 Counter(223500) 223437
Saved chunk: 20230922T022015F321711-4OF9EP3l8nJMFttFHQJWuy-14PpyEJsQUKIakx9c3nPmB-1024.npz
eval_Episode has 500 steps and return 334.7.
train_Episode has 500 steps and return 282.8.
Starting evaluation at step 224000 Counter(224000) 223937
eval_Episode has 500 steps and return 332.3.
Saved chunk: 20230922T022113F585946-646VLSnAygaJbBaZ6okCMF-1e83OyU0EsL8Te6RL3RZpA-1024.npz
train_Episode has 500 steps and return 260.9.
Starting evaluation at step 224500 Counter(224500) 224437
Saved chunk: 20230922T022134F295756-14PpyEJsQUKIakx9c3nPmB-3UA41ycGC0JXu9vLyZKGkN-1024.npz
eval_Episode has 500 steps and return 307.2.
train_Episode has 500 steps and return 287.9.
Starting evaluation at step 225000 Counter(225000) 224937
eval_Episode has 500 steps and return 319.2.
Saved chunk: 20230922T022233F958244-1e83OyU0EsL8Te6RL3RZpA-6eZ7VagIPNuBHKpg2sHWkS-1024.npz
train_Episode has 500 steps and return 285.6.
Starting evaluation at step 225500 Counter(225500) 225437
Saved chunk: 20230922T022253F060158-3UA41ycGC0JXu9vLyZKGkN-3sOjvC4Me9OsEucOrvmTmQ-1024.npz
eval_Episode has 500 steps and return 317.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 451338 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 285.58 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 317.69 / eval_episode/reward_rate 0.56 / train/action_mag 2.7 / train/action_max 2.7 / train/action_mean 0.09 / train/action_min -1.97 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -14.15 / train/adv_mag 0.61 / train/adv_max 0.49 / train/adv_mean 2.4e-3 / train/adv_min
-0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.96 / train/dyn_loss_std 6.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.01 / train/extr_critic_max 233.01 / train/extr_critic_mean 223.33 / train/extr_critic_min 193.21 / train/extr_critic_std 6.54 / train/extr_return_normed_mag 1.16 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 233.89 / train/extr_return_raw_max 233.89 / train/extr_return_raw_mean 223.38 / train/extr_return_raw_min 
197.76 / train/extr_return_raw_std 6.58 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 1.28 / train/image_loss_std 1.1 / train/model_loss_mean 3.85 / 
train/model_loss_std 4.59 / train/model_opt_grad_norm 9.58 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.2 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 8.27 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.09 / train/policy_logprob_min -8.27 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 51 / train/post_ent_max 51 / train/post_ent_mean 41.78 / 
train/post_ent_min 20.1 / train/post_ent_std 5.24 / train/prior_ent_mag 72.31 / train/prior_ent_max 72.31 / train/prior_ent_mean 45.73 / train/prior_ent_min 28.95 / train/prior_ent_std 5.34 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.18 / train/reward_avg 0.34 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.34 / train/reward_rate 0.33 / 
train_stats/mean_log_entropy -3.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 6.04 / report/image_loss_mean 1.35 / report/image_loss_std 1.06 / report/model_loss_mean 3.74 / report/model_loss_std 4.39 / report/post_ent_mag 50.63 / report/post_ent_max 50.63 /
report/post_ent_mean 41.12 / report/post_ent_min 18.05 / report/post_ent_std 5.71 / report/prior_ent_mag 72.35 / report/prior_ent_max 72.35 / report/prior_ent_mean 44.82 / report/prior_ent_min 26.98 / report/prior_ent_std 6.07 / report/rep_loss_mean 3.74 / 
report/rep_loss_std 6.04 / report/reward_avg 0.29 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.27 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.28 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.13 / eval/dyn_loss_std 7.87 / eval/image_loss_mean 1.81 / eval/image_loss_std 3.71 / eval/model_loss_mean 5.16 / eval/model_loss_std 7.87 / eval/post_ent_mag 50.85 / eval/post_ent_max 50.85 / eval/post_ent_mean 
42.32 / eval/post_ent_min 18.17 / eval/post_ent_std 4.88 / eval/prior_ent_mag 72.35 / eval/prior_ent_max 72.35 / eval/prior_ent_mean 46.65 / eval/prior_ent_min 32.8 / eval/prior_ent_std 4.33 / eval/rep_loss_mean 5.13 / eval/rep_loss_std 7.87 / eval/reward_avg 0.52 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.51 / eval/reward_rate 0.47 / 
replay/size 2.3e5 / replay/inserts 3781 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3781 / timer/env.step_total 19.55 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.14 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.5e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7789 / timer/agent.policy_total 17.82 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.3e-3 
/ timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241.17 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 280.1.
Starting evaluation at step 226000 Counter(226000) 225937
eval_Episode has 500 steps and return 300.5.
Saved chunk: 20230922T022354F245335-6eZ7VagIPNuBHKpg2sHWkS-0IGqHnX5SZ6YhY8WCCCNGr-1024.npz
train_Episode has 500 steps and return 298.0.
Starting evaluation at step 226500 Counter(226500) 226437
Saved chunk: 20230922T022411F736944-3sOjvC4Me9OsEucOrvmTmQ-4vHVwZRPE4314vAwcxSSJd-1024.npz
eval_Episode has 500 steps and return 337.2.
train_Episode has 500 steps and return 269.4.
Starting evaluation at step 227000 Counter(227000) 226937
eval_Episode has 500 steps and return 312.1.
Saved chunk: 20230922T022515F569407-0IGqHnX5SZ6YhY8WCCCNGr-0E7iPSjgSXJPb7gdvkGVMK-1024.npz
train_Episode has 500 steps and return 253.4.
Starting evaluation at step 227500 Counter(227500) 227437
Saved chunk: 20230922T022531F593998-4vHVwZRPE4314vAwcxSSJd-4peofSedgkD8RTuw4by59l-1024.npz
eval_Episode has 500 steps and return 314.7.
train_Episode has 500 steps and return 305.8.
Starting evaluation at step 228000 Counter(228000) 227937
eval_Episode has 500 steps and return 333.5.
Saved chunk: 20230922T022636F012508-0E7iPSjgSXJPb7gdvkGVMK-06aFOiWb9vWqxQQJLwWdOX-1024.npz
train_Episode has 500 steps and return 305.8.
Starting evaluation at step 228500 Counter(228500) 228437
Saved chunk: 20230922T022650F424334-4peofSedgkD8RTuw4by59l-7EmRXAsZpUWFo0cpTwe6dB-1024.npz
eval_Episode has 500 steps and return 328.7.
train_Episode has 500 steps and return 296.3.
Starting evaluation at step 229000 Counter(229000) 228937
eval_Episode has 500 steps and return 318.6.
Saved chunk: 20230922T022756F324622-06aFOiWb9vWqxQQJLwWdOX-5YeRSC0FbXxOnpnZrBaGUL-1024.npz
train_Episode has 500 steps and return 298.5.
Starting evaluation at step 229500 Counter(229500) 229437
Saved chunk: 20230922T022809F107514-7EmRXAsZpUWFo0cpTwe6dB-3WKPhfsJ9Y6GeXSPUe61pI-1024.npz
eval_Episode has 500 steps and return 303.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 459002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 298.55 / episode/reward_rate 0.52 / eval_episode/length 500 / eval_episode/score 303.42 / eval_episode/reward_rate 0.52 / train/action_mag 2.77 / train/action_max 2.77 / train/action_mean 0.09 / train/action_min -1.97 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -15.91 / train/adv_mag 0.61 / train/adv_max 0.49 / train/adv_mean 
2.5e-3 / train/adv_min -0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.1e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.51 / train/extr_critic_max 234.51 / train/extr_critic_mean 224.97 / train/extr_critic_min 195.36 / train/extr_critic_std 6.44 / 
train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.41 / train/extr_return_raw_max 
235.41 / train/extr_return_raw_mean 225.03 / train/extr_return_raw_min 199.51 / train/extr_return_raw_std 6.47 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / 
train/image_loss_mean 1.27 / train/image_loss_std 1.11 / train/model_loss_mean 3.84 / train/model_loss_std 4.57 / train/model_opt_grad_norm 9.73 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.34 / train/policy_entropy_mean -3.07 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.63 / train/policy_logprob_mag 8.02 / train/policy_logprob_max 5.5 / 
train/policy_logprob_mean 3.07 / train/policy_logprob_min -8.02 / train/policy_logprob_std 1.55 / train/policy_randomness_mag 0.53 / train/policy_randomness_max 0.53 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 
0.07 / train/post_ent_mag 51 / train/post_ent_max 51 / train/post_ent_mean 41.85 / train/post_ent_min 20.01 / train/post_ent_std 5.23 / train/prior_ent_mag 72.3 / train/prior_ent_max 72.3 / train/prior_ent_mean 45.81 / train/prior_ent_min 28.91 / train/prior_ent_std 
5.33 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.15 / train/reward_avg 0.34 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc
1 / train/reward_pos_loss 0.58 / train/reward_pred 0.34 / train/reward_rate 0.33 / train_stats/mean_log_entropy -3.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.07 / report/dyn_loss_std 6 / report/image_loss_mean 1.25 / report/image_loss_std 1.06 / report/model_loss_mean 3.96 / 
report/model_loss_std 4.4 / report/post_ent_mag 51.95 / report/post_ent_max 51.95 / report/post_ent_mean 42.23 / report/post_ent_min 20.34 / report/post_ent_std 4.9 / report/prior_ent_mag 72.43 / report/prior_ent_max 72.43 / report/prior_ent_mean 46.3 / 
report/prior_ent_min 27.7 / report/prior_ent_std 5.12 / report/rep_loss_mean 4.07 / report/rep_loss_std 6 / report/reward_avg 0.47 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 
0.99 / report/reward_neg_loss 4.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.46 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan 
/ eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.1 / eval/dyn_loss_std 6.01 / eval/image_loss_mean 1.24 / eval/image_loss_std 1.58 / eval/model_loss_mean 4.05 / eval/model_loss_std 5 / eval/post_ent_mag 
50.34 / eval/post_ent_max 50.34 / eval/post_ent_mean 42.99 / eval/post_ent_min 21.15 / eval/post_ent_std 4.12 / eval/prior_ent_mag 72.43 / eval/prior_ent_max 72.43 / eval/prior_ent_mean 47.04 / eval/prior_ent_min 34.58 / eval/prior_ent_std 3.87 / eval/rep_loss_mean 4.1 
/ eval/rep_loss_std 6.01 / eval/reward_avg 0.63 / eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.58 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / 
eval/reward_pred 0.63 / eval/reward_rate 0.55 / replay/size 2.3e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.31 / timer/env.step_count 3832 / timer/env.step_total 19.81
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 467.88 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.4e-4 
/ timer/agent.train_count 1916 / timer/agent.train_total 244.03 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / 
timer/dataset_eval_max 4.6e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 317.7.
Starting evaluation at step 230000 Counter(230000) 229937
eval_Episode has 500 steps and return 323.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T022927F624594-3WKPhfsJ9Y6GeXSPUe61pI-0000000000000000000000-659.npz
Saved chunk: 20230922T022916F375802-5YeRSC0FbXxOnpnZrBaGUL-0000000000000000000000-724.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T022916F375802-5YeRSC0FbXxOnpnZrBaGUL-3vQQguUytFIgBmn2UaUnlb-1024.npz
train_Episode has 500 steps and return 320.0.
Starting evaluation at step 230500 Counter(230500) 230437
Saved chunk: 20230922T022927F624594-3WKPhfsJ9Y6GeXSPUe61pI-4QtoJPSBuRYUbx2R7B9vbC-1024.npz
eval_Episode has 500 steps and return 334.4.
train_Episode has 500 steps and return 296.2.
Starting evaluation at step 231000 Counter(231000) 230937
eval_Episode has 500 steps and return 316.5.
Saved chunk: 20230922T023038F020083-3vQQguUytFIgBmn2UaUnlb-3QiVXa3DpEpbckn15FtaOA-1024.npz
train_Episode has 500 steps and return 262.2.
Starting evaluation at step 231500 Counter(231500) 231437
Saved chunk: 20230922T023047F776142-4QtoJPSBuRYUbx2R7B9vbC-3ULd0k9d0OxGiIaJ5ABJbO-1024.npz
eval_Episode has 500 steps and return 301.6.
train_Episode has 500 steps and return 291.1.
Starting evaluation at step 232000 Counter(232000) 231937
eval_Episode has 500 steps and return 322.9.
Saved chunk: 20230922T023158F520927-3QiVXa3DpEpbckn15FtaOA-3pHPUQ3U0fOSy3WAlQEYxF-1024.npz
train_Episode has 500 steps and return 294.1.
Starting evaluation at step 232500 Counter(232500) 232437
Saved chunk: 20230922T023206F715993-3ULd0k9d0OxGiIaJ5ABJbO-2INGuMGvOgEnSbx2ljtbFQ-1024.npz
eval_Episode has 500 steps and return 336.2.
train_Episode has 500 steps and return 309.3.
Starting evaluation at step 233000 Counter(233000) 232937
eval_Episode has 500 steps and return 326.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 466662 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 309.32 / episode/reward_rate 0.52 / eval_episode/length 500 / eval_episode/score 326.56 / eval_episode/reward_rate 0.58 / train/action_mag 2.82 / train/action_max 2.81 / train/action_mean 0.09 / train/action_min -2.02 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -9.27 / train/adv_mag 0.66 / train/adv_max 0.54 / train/adv_mean 
1.9e-3 / train/adv_min -0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate
1 / train/dyn_loss_mean 3.92 / train/dyn_loss_std 6.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.07 / train/extr_critic_max 236.07 / train/extr_critic_mean 226.57 / train/extr_critic_min 196.69 / train/extr_critic_std 6.36 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.57 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.89 / train/extr_return_raw_max 236.89 / train/extr_return_raw_mean 226.61 / train/extr_return_raw_min 
200.74 / train/extr_return_raw_std 6.39 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.25 / train/image_loss_std 1.08 / train/model_loss_mean 3.8 / 
train/model_loss_std 4.53 / train/model_opt_grad_norm 9.55 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.96 / train/policy_entropy_mean -3.07 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 7.83 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.07 / train/policy_logprob_min -7.83 / train/policy_logprob_std 1.55 / 
train/policy_randomness_mag 0.49 / train/policy_randomness_max 0.49 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.93 / train/post_ent_max 50.93 / train/post_ent_mean 41.92 / 
train/post_ent_min 20.06 / train/post_ent_std 5.16 / train/prior_ent_mag 72.28 / train/prior_ent_max 72.28 / train/prior_ent_mean 45.83 / train/prior_ent_min 29.21 / train/prior_ent_std 5.26 / train/rep_loss_mean 3.92 / train/rep_loss_std 6.11 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.35 / train/reward_rate 0.34 / 
train_stats/mean_log_entropy -3.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.5e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 5.94 / report/image_loss_mean 1.22 / report/image_loss_std 1.35 / report/model_loss_mean 3.68 / report/model_loss_std 4.52 / report/post_ent_mag 50.93 / report/post_ent_max 50.93 /
report/post_ent_mean 41.49 / report/post_ent_min 20.86 / report/post_ent_std 5.63 / report/prior_ent_mag 72.23 / report/prior_ent_max 72.23 / report/prior_ent_mean 45.23 / report/prior_ent_min 28.04 / report/prior_ent_std 5.85 / report/rep_loss_mean 3.78 / 
report/rep_loss_std 5.94 / report/reward_avg 0.33 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.33 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 7.8e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.69 / eval/dyn_loss_std 6.35 / eval/image_loss_mean 1.32 / eval/image_loss_std 1.41 / eval/model_loss_mean 4.42 / eval/model_loss_std 4.88 / eval/post_ent_mag 51.13 / eval/post_ent_max 51.13 / eval/post_ent_mean 
42.64 / eval/post_ent_min 22.41 / eval/post_ent_std 4.62 / eval/prior_ent_mag 72.23 / eval/prior_ent_max 72.23 / eval/prior_ent_mean 46.98 / eval/prior_ent_min 34.67 / eval/prior_ent_std 4.17 / eval/rep_loss_mean 4.69 / eval/rep_loss_std 6.35 / eval/reward_avg 0.49 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.49 / eval/reward_rate 0.46 / 
replay/size 2.3e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3830 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.74 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.6e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7337 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1915 / timer/agent.train_total 244 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 260.2.
Saved chunk: 20230922T023318F842097-3pHPUQ3U0fOSy3WAlQEYxF-2R2xRMH5DkTrgAqh227jkm-1024.npz
Starting evaluation at step 233500 Counter(233500) 233437
Saved chunk: 20230922T023325F433008-2INGuMGvOgEnSbx2ljtbFQ-2V8Nox7kRQIQEJ1n88mRmZ-1024.npz
eval_Episode has 500 steps and return 313.5.
train_Episode has 500 steps and return 299.4.
Starting evaluation at step 234000 Counter(234000) 233937
eval_Episode has 500 steps and return 332.4.
train_Episode has 500 steps and return 281.0.
Starting evaluation at step 234500 Counter(234500) 234437
Saved chunk: 20230922T023439F761946-2R2xRMH5DkTrgAqh227jkm-7kk1VZPMAGaMMXM4G6vm7E-1024.npz
eval_Episode has 500 steps and return 333.5.
Saved chunk: 20230922T023444F908736-2V8Nox7kRQIQEJ1n88mRmZ-0HDEJVNLQb7cqznubHs1JV-1024.npz
train_Episode has 500 steps and return 282.1.
Starting evaluation at step 235000 Counter(235000) 234937
eval_Episode has 500 steps and return 309.8.
train_Episode has 500 steps and return 284.5.
Starting evaluation at step 235500 Counter(235500) 235437
eval_Episode has 500 steps and return 341.5.
Saved chunk: 20230922T023604F060471-0HDEJVNLQb7cqznubHs1JV-4XJFEsH3x0JOb23AFahRaL-1024.npz
Saved chunk: 20230922T023600F580861-7kk1VZPMAGaMMXM4G6vm7E-3XHMxjI0jUYguDyeVowQHl-1024.npz
train_Episode has 500 steps and return 305.9.
Starting evaluation at step 236000 Counter(236000) 235937
eval_Episode has 500 steps and return 329.5.
train_Episode has 500 steps and return 309.1.
Starting evaluation at step 236500 Counter(236500) 236437
eval_Episode has 500 steps and return 321.8.
Saved chunk: 20230922T023722F938200-4XJFEsH3x0JOb23AFahRaL-1uDyqcDeOWhgKwMnIxqQzY-1024.npz
Saved chunk: 20230922T023724F587154-3XHMxjI0jUYguDyeVowQHl-44h32aSFsUgJrDEXU1JTJG-1024.npz
train_Episode has 500 steps and return 286.7.
Starting evaluation at step 237000 Counter(237000) 236937
eval_Episode has 500 steps and return 302.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 474222 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 286.71 / episode/reward_rate 0.52 / eval_episode/length 500 / eval_episode/score 302.88 / eval_episode/reward_rate 0.48 / train/action_mag 2.83 / train/action_max 2.81 / train/action_mean 0.08 / train/action_min -2.04 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -10.49 / train/adv_mag 0.58 / train/adv_max 0.47 / train/adv_mean 2e-3
/ train/adv_min -0.48 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.93 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.18 / train/extr_critic_max 237.18 / train/extr_critic_mean 227.5 / train/extr_critic_min 198.55 / train/extr_critic_std 6.5 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.01 / train/extr_return_raw_max 238.01 / train/extr_return_raw_mean 227.54 / train/extr_return_raw_min 
201.18 / train/extr_return_raw_std 6.53 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.25 / train/image_loss_std 1.07 / train/model_loss_mean 3.81 /
train/model_loss_std 4.52 / train/model_opt_grad_norm 9.68 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.87 / train/policy_entropy_mean -3.07 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.61 / train/policy_logprob_mag 8.06 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.07 / train/policy_logprob_min -8.06 / 
train/policy_logprob_std 1.54 / train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.96 / train/post_ent_max 50.96 / 
train/post_ent_mean 41.83 / train/post_ent_min 20.22 / train/post_ent_std 5.17 / train/prior_ent_mag 72.25 / train/prior_ent_max 72.25 / train/prior_ent_mean 45.75 / train/prior_ent_min 29.03 / train/prior_ent_std 5.31 / train/rep_loss_mean 3.93 / train/rep_loss_std 
6.12 / train/reward_avg 0.35 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 
0.35 / train/reward_rate 0.33 / train_stats/mean_log_entropy -3.13 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.79 / report/dyn_loss_std 5.94 / report/image_loss_mean 1.26 / report/image_loss_std 0.88 / report/model_loss_mean 3.7 / report/model_loss_std 4.22 / report/post_ent_mag 51.27
/ report/post_ent_max 51.27 / report/post_ent_mean 41.95 / report/post_ent_min 22.43 / report/post_ent_std 5.3 / report/prior_ent_mag 72.21 / report/prior_ent_max 72.21 / report/prior_ent_mean 45.69 / report/prior_ent_min 30.79 / report/prior_ent_std 5.34 / 
report/rep_loss_mean 3.79 / report/rep_loss_std 5.94 / report/reward_avg 0.24 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.24 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 8.3e-11 / eval/cont_loss_std 5.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.4 / eval/dyn_loss_std 6.01 / eval/image_loss_mean 1.16 / eval/image_loss_std 1.1 / eval/model_loss_mean 4.14 / eval/model_loss_std 4.57 / eval/post_ent_mag 50.63 / eval/post_ent_max 
50.63 / eval/post_ent_mean 42.99 / eval/post_ent_min 20.91 / eval/post_ent_std 4.11 / eval/prior_ent_mag 72.21 / eval/prior_ent_max 72.21 / eval/prior_ent_mean 47.07 / eval/prior_ent_min 28.5 / eval/prior_ent_std 3.86 / eval/rep_loss_mean 4.4 / eval/rep_loss_std 6.01 / 
eval/reward_avg 0.6 / eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.44 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.59 / 
eval/reward_rate 0.53 / replay/size 2.4e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3780 / timer/env.step_total 19.54 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.64 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / 
timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7788 / timer/agent.policy_total 17.87 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1890 / 
timer/agent.train_total 241.14 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 290.0.
Starting evaluation at step 237500 Counter(237500) 237437
eval_Episode has 500 steps and return 314.9.
Saved chunk: 20230922T023844F943384-44h32aSFsUgJrDEXU1JTJG-755FemED0YNRJjjHRJ9G7W-1024.npz
train_Episode has 500 steps and return 260.0.
Starting evaluation at step 238000 Counter(238000) 237937
Saved chunk: 20230922T023841F730034-1uDyqcDeOWhgKwMnIxqQzY-2dTFL7ucZtsOw2iDEDGW7c-1024.npz
eval_Episode has 500 steps and return 333.9.
train_Episode has 500 steps and return 296.8.
Starting evaluation at step 238500 Counter(238500) 238437
eval_Episode has 500 steps and return 315.8.
Saved chunk: 20230922T024006F235023-755FemED0YNRJjjHRJ9G7W-7syYU9KRODum5ztg29l7nu-1024.npz
train_Episode has 500 steps and return 279.5.
Starting evaluation at step 239000 Counter(239000) 238937
Saved chunk: 20230922T024037F399229-2dTFL7ucZtsOw2iDEDGW7c-0NoCnVVhIYZtL66PISw45g-1024.npz
eval_Episode has 500 steps and return 312.2.
train_Episode has 500 steps and return 300.5.
Starting evaluation at step 239500 Counter(239500) 239437
eval_Episode has 500 steps and return 324.0.
Saved chunk: 20230922T024126F890332-7syYU9KRODum5ztg29l7nu-7riA6njbVm1u1IFhGYKOu6-1024.npz
train_Episode has 500 steps and return 264.3.
Starting evaluation at step 240000 Counter(240000) 239937
Saved chunk: 20230922T024156F381195-0NoCnVVhIYZtL66PISw45g-6fI349iFRjB212THkEZMig-1024.npz
eval_Episode has 500 steps and return 309.5.
train_Episode has 500 steps and return 269.0.
Starting evaluation at step 240500 Counter(240500) 240437
eval_Episode has 500 steps and return 308.2.
Saved chunk: 20230922T024247F262140-7riA6njbVm1u1IFhGYKOu6-3kGp0IE28Z1qLlmbX0nJdR-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 481882 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 268.98 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 308.22 / eval_episode/reward_rate 0.5 / train/action_mag 2.84 / train/action_max 2.82 / train/action_mean 0.08 / train/action_min -2.06 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -11.64 / train/adv_mag 0.53 / train/adv_max 0.39 / train/adv_mean 2.1e-3 / train/adv_min
-0.47 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.1e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.93 / train/dyn_loss_std 6.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.47 / train/extr_critic_max 238.47 / train/extr_critic_mean 228.88 / train/extr_critic_min 200.56 / train/extr_critic_std 6.57 / train/extr_return_normed_mag 1.18 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 239.35 / train/extr_return_raw_max 239.35 / train/extr_return_raw_mean 228.92 / train/extr_return_raw_min 
202.11 / train/extr_return_raw_std 6.62 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.24 / train/image_loss_std 1.08 / train/model_loss_mean 3.8 / 
train/model_loss_std 4.53 / train/model_opt_grad_norm 9.77 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.94 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.61 / train/policy_logprob_mag 8.01 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.09 / train/policy_logprob_min -8.01 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.49 / train/policy_randomness_max 0.49 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.98 / train/post_ent_max 50.98 / train/post_ent_mean 41.95 / 
train/post_ent_min 20.11 / train/post_ent_std 5.12 / train/prior_ent_mag 72.25 / train/prior_ent_max 72.25 / train/prior_ent_mean 45.87 / train/prior_ent_min 29.1 / train/prior_ent_std 5.23 / train/rep_loss_mean 3.93 / train/rep_loss_std 6.11 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.36 / train/reward_rate 0.34 / 
train_stats/mean_log_entropy -3.15 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 5.46 / report/image_loss_mean 1.13 / report/image_loss_std 0.89 / report/model_loss_mean 3.6 / report/model_loss_std 4.11 / report/post_ent_mag 51.27 / report/post_ent_max 51.27 / 
report/post_ent_mean 43.05 / report/post_ent_min 23.02 / report/post_ent_std 3.99 / report/prior_ent_mag 72.2 / report/prior_ent_max 72.2 / report/prior_ent_mean 46.78 / report/prior_ent_min 35.18 / report/prior_ent_std 4.02 / report/rep_loss_mean 3.76 / 
report/rep_loss_std 5.46 / report/reward_avg 0.38 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.38 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.68 / eval/dyn_loss_std 6.63 / eval/image_loss_mean 1.56 / eval/image_loss_std 2.15 / eval/model_loss_mean 4.68 / eval/model_loss_std 5.76 / eval/post_ent_mag 51.55 / eval/post_ent_max 51.55 / eval/post_ent_mean 
42.61 / eval/post_ent_min 21.21 / eval/post_ent_std 4.43 / eval/prior_ent_mag 72.2 / eval/prior_ent_max 72.2 / eval/prior_ent_mean 46.86 / eval/prior_ent_min 34.08 / eval/prior_ent_std 3.99 / eval/rep_loss_mean 4.68 / eval/rep_loss_std 6.63 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.58 / eval/reward_rate 0.52 / 
replay/size 2.4e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3830 / timer/env.step_total 19.93 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 459.01 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7337 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1915 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1915 / timer/agent.train_total 244.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 310.6.
Starting evaluation at step 241000 Counter(241000) 240937
Saved chunk: 20230922T024315F166978-6fI349iFRjB212THkEZMig-20cDEwFTEzvKspJqYzk6sQ-1024.npz
eval_Episode has 500 steps and return 342.5.
train_Episode has 500 steps and return 310.4.
Starting evaluation at step 241500 Counter(241500) 241437
eval_Episode has 500 steps and return 341.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T024407F564979-3kGp0IE28Z1qLlmbX0nJdR-0000000000000000000000-960.npz
Saved chunk: 20230922T024434F707358-20cDEwFTEzvKspJqYzk6sQ-0000000000000000000000-918.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T024407F564979-3kGp0IE28Z1qLlmbX0nJdR-6U3c4vXWHwmP1oAOwpwX5R-1024.npz
train_Episode has 500 steps and return 280.5.
Starting evaluation at step 242000 Counter(242000) 241937
Saved chunk: 20230922T024434F707358-20cDEwFTEzvKspJqYzk6sQ-5DNf3iJ8aO7dfyCh7cFIzx-1024.npz
eval_Episode has 500 steps and return 354.9.
train_Episode has 500 steps and return 293.1.
Starting evaluation at step 242500 Counter(242500) 242437
eval_Episode has 500 steps and return 325.5.
Saved chunk: 20230922T024529F337752-6U3c4vXWHwmP1oAOwpwX5R-3g0m6CIYFsAYLAE6GyB4Ua-1024.npz
train_Episode has 500 steps and return 297.6.
Starting evaluation at step 243000 Counter(243000) 242937
Saved chunk: 20230922T024554F202237-5DNf3iJ8aO7dfyCh7cFIzx-02BN9FaHkRzdnbPIiEmMwK-1024.npz
eval_Episode has 500 steps and return 321.0.
train_Episode has 500 steps and return 292.7.
Starting evaluation at step 243500 Counter(243500) 243437
eval_Episode has 500 steps and return 315.3.
Saved chunk: 20230922T024649F833738-3g0m6CIYFsAYLAE6GyB4Ua-2EbJ7vv9enA4fLzFtBriYp-1024.npz
train_Episode has 500 steps and return 298.2.
Starting evaluation at step 244000 Counter(244000) 243937
Saved chunk: 20230922T024713F089461-02BN9FaHkRzdnbPIiEmMwK-27CM8YRcNbUUWfUO3F8Rbl-1024.npz
eval_Episode has 500 steps and return 355.8.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 244500 Counter(244500) 244437
eval_Episode has 500 steps and return 248.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 489438 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.46 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 248.63 / eval_episode/reward_rate 0.4 / train/action_mag 2.75 / train/action_max 2.73 / train/action_mean 0.08 / train/action_min -2.12 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.53 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -7.14 / train/adv_mag 0.54 / train/adv_max 0.39 / train/adv_mean 1.7e-3 / train/adv_min
-0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 239.73 / train/extr_critic_max 239.73 / train/extr_critic_mean 230.24 / train/extr_critic_min 204.47 / train/extr_critic_std 6.22 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 240.61 / train/extr_return_raw_max 240.61 / train/extr_return_raw_mean 230.27 / train/extr_return_raw_min 
204.91 / train/extr_return_raw_std 6.27 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.25 / train/image_loss_std 1.08 / train/model_loss_mean 3.81 /
train/model_loss_std 4.54 / train/model_opt_grad_norm 9.5 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 5.3e-3 / train/model_opt_model_opt_grad_scale 8809.52 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.2 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 7.88 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -7.88 / 
train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1e-4 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.99 / train/post_ent_max 50.99 / 
train/post_ent_mean 42.02 / train/post_ent_min 20.24 / train/post_ent_std 4.99 / train/prior_ent_mag 72.22 / train/prior_ent_max 72.22 / train/prior_ent_mean 45.94 / train/prior_ent_min 29.7 / train/prior_ent_std 5.07 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.11
/ train/reward_avg 0.36 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.36 /
train/reward_rate 0.35 / train_stats/mean_log_entropy -3.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss
4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.11 / report/dyn_loss_std 6.58 / report/image_loss_mean 1.46 / report/image_loss_std 1.21 / report/model_loss_mean 4.08 / report/model_loss_std 4.91 / report/post_ent_mag 52.31 / report/post_ent_max
52.31 / report/post_ent_mean 40.95 / report/post_ent_min 20.81 / report/post_ent_std 5.49 / report/prior_ent_mag 72.09 / report/prior_ent_max 72.09 / report/prior_ent_mean 45.22 / report/prior_ent_min 29.7 / report/prior_ent_std 5.61 / report/rep_loss_mean 4.11 / 
report/rep_loss_std 6.58 / report/reward_avg 0.27 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.27 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 8e-11 / eval/cont_loss_std 4.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.97 / eval/dyn_loss_std 6.63 / eval/image_loss_mean 1.49 / eval/image_loss_std 1.83 / eval/model_loss_mean 4.74 / eval/model_loss_std 5.45 / eval/post_ent_mag 50.15 / eval/post_ent_max 50.15 / eval/post_ent_mean 41.91 / 
eval/post_ent_min 18.31 / eval/post_ent_std 5 / eval/prior_ent_mag 72.09 / eval/prior_ent_max 72.09 / eval/prior_ent_mean 46.7 / eval/prior_ent_min 34.18 / eval/prior_ent_std 4.04 / eval/rep_loss_mean 4.97 / eval/rep_loss_std 6.63 / eval/reward_avg 0.54 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.55 / eval/reward_rate 0.47 / 
replay/size 2.4e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3778 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.72 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7786 / timer/agent.policy_total 17.98 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1889 / timer/agent.train_total 240.9 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T024810F184023-2EbJ7vv9enA4fLzFtBriYp-2n26N1BXoH6uvV81NkBWoS-1024.npz
train_Episode has 500 steps and return 321.3.
Starting evaluation at step 245000 Counter(245000) 244937
Saved chunk: 20230922T024831F773827-27CM8YRcNbUUWfUO3F8Rbl-3fNKS7XwPey776TK1UsplT-1024.npz
eval_Episode has 500 steps and return 296.9.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 245500 Counter(245500) 245437
eval_Episode has 500 steps and return 305.3.
Saved chunk: 20230922T024930F946294-2n26N1BXoH6uvV81NkBWoS-20WPeFoUMKtrkfCPYGwHZ0-1024.npz
train_Episode has 500 steps and return 305.2.
Starting evaluation at step 246000 Counter(246000) 245937
Saved chunk: 20230922T024951F273476-3fNKS7XwPey776TK1UsplT-1iThRPaAWPmrS8MRySeVfv-1024.npz
eval_Episode has 500 steps and return 292.3.
train_Episode has 500 steps and return 312.4.
Starting evaluation at step 246500 Counter(246500) 246437
eval_Episode has 500 steps and return 339.0.
Saved chunk: 20230922T025051F789823-20WPeFoUMKtrkfCPYGwHZ0-2WFUZtsDGFdSW9pF9qjnse-1024.npz
train_Episode has 500 steps and return 336.0.
Starting evaluation at step 247000 Counter(247000) 246937
Saved chunk: 20230922T025110F413312-1iThRPaAWPmrS8MRySeVfv-1jHTY1EilRpdZfCABxgTOH-1024.npz
eval_Episode has 500 steps and return 327.6.
train_Episode has 500 steps and return 305.3.
Starting evaluation at step 247500 Counter(247500) 247437
eval_Episode has 500 steps and return 332.6.
Saved chunk: 20230922T025212F315454-2WFUZtsDGFdSW9pF9qjnse-6jc7tRpsnw3533Rp1uHTBy-1024.npz
train_Episode has 500 steps and return 305.5.
Starting evaluation at step 248000 Counter(248000) 247937
Saved chunk: 20230922T025229F296510-1jHTY1EilRpdZfCABxgTOH-4X9dLeuJm5lF4gqDWCux9Z-1024.npz
eval_Episode has 500 steps and return 332.6.
train_Episode has 500 steps and return 302.0.
Starting evaluation at step 248500 Counter(248500) 248437
eval_Episode has 500 steps and return 322.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 497006 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 301.97 / episode/reward_rate 0.55 / eval_episode/length 500 / eval_episode/score 321.96 / eval_episode/reward_rate 0.54 / train/action_mag 2.77 / train/action_max 2.75 / train/action_mean 0.08 / train/action_min -2.15 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.49 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -9.42 / train/adv_mag 0.53 / train/adv_max 0.37 / train/adv_mean 
1.9e-3 / train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.93 / train/dyn_loss_std 6.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 240.97 / train/extr_critic_max 240.97 / train/extr_critic_mean 231.23 / train/extr_critic_min 205.08 / train/extr_critic_std 6.66 / 
train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 241.82 / train/extr_return_raw_max 
241.82 / train/extr_return_raw_mean 231.28 / train/extr_return_raw_min 204.62 / train/extr_return_raw_std 6.72 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / 
train/image_loss_mean 1.24 / train/image_loss_std 1.1 / train/model_loss_mean 3.8 / train/model_loss_std 4.53 / train/model_opt_grad_norm 9.57 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 2.3e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 6137.57 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.3 / train/policy_entropy_mean -3.11 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 5.5 
/ train/policy_logprob_mean 3.11 / train/policy_logprob_min -8.04 / train/policy_logprob_std 1.54 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 9.9e-5 / train/policy_randomness_std
0.06 / train/post_ent_mag 50.93 / train/post_ent_max 50.93 / train/post_ent_mean 41.95 / train/post_ent_min 20.39 / train/post_ent_std 5.05 / train/prior_ent_mag 72.24 / train/prior_ent_max 72.24 / train/prior_ent_mean 45.86 / train/prior_ent_min 29.64 / 
train/prior_ent_std 5.15 / train/rep_loss_mean 3.93 / train/rep_loss_std 6.09 / train/reward_avg 0.37 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.36 / train/reward_rate 0.35 / train_stats/mean_log_entropy -3.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.08 / report/dyn_loss_std 6.23 / report/image_loss_mean 1.32 / report/image_loss_std 1.27 / 
report/model_loss_mean 3.94 / report/model_loss_std 4.72 / report/post_ent_mag 51.07 / report/post_ent_max 51.07 / report/post_ent_mean 42.12 / report/post_ent_min 21.92 / report/post_ent_std 4.77 / report/prior_ent_mag 72.29 / report/prior_ent_max 72.29 / 
report/prior_ent_mean 46.19 / report/prior_ent_min 31.56 / report/prior_ent_std 4.66 / report/rep_loss_mean 4.08 / report/rep_loss_std 6.23 / report/reward_avg 0.3 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.31 / report/reward_max_data 2 / 
report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.31 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-11 / eval/cont_loss_std 2.6e-10 / 
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.96 / eval/dyn_loss_std 6.87 / eval/image_loss_mean 1.45 / eval/image_loss_std 1.72 / eval/model_loss_mean 4.76 
/ eval/model_loss_std 5.48 / eval/post_ent_mag 51.06 / eval/post_ent_max 51.06 / eval/post_ent_mean 42.35 / eval/post_ent_min 21.21 / eval/post_ent_std 4.74 / eval/prior_ent_mag 72.29 / eval/prior_ent_max 72.29 / eval/prior_ent_mean 46.91 / eval/prior_ent_min 32.93 / 
eval/prior_ent_std 4.08 / eval/rep_loss_mean 4.96 / eval/rep_loss_std 6.87 / eval/reward_avg 0.54 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.45 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.02 / 
eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.53 / eval/reward_rate 0.49 / replay/size 2.5e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / 
timer/env.step_count 3784 / timer/env.step_total 19.72 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.09 / timer/replay._sample_frac 1.53 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7792 / timer/agent.policy_total 17.68 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 / timer/dataset_train_count 1892 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1892 / timer/agent.train_total 241.18 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T025332F515102-6jc7tRpsnw3533Rp1uHTBy-1cJNWg4ODB0OYTRRevbdup-1024.npz
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 249000 Counter(249000) 248937
Saved chunk: 20230922T025347F902790-4X9dLeuJm5lF4gqDWCux9Z-6L35KvtSCWf7f8PKpR1U4f-1024.npz
eval_Episode has 500 steps and return 344.0.
train_Episode has 500 steps and return 290.3.
Starting evaluation at step 249500 Counter(249500) 249437
eval_Episode has 500 steps and return 327.2.
Saved chunk: 20230922T025453F587937-1cJNWg4ODB0OYTRRevbdup-49XOqRswhhYrIaF9VO2chc-1024.npz
train_Episode has 500 steps and return 300.0.
Starting evaluation at step 250000 Counter(250000) 249937
Saved chunk: 20230922T025507F557391-6L35KvtSCWf7f8PKpR1U4f-4fKpZ5CsCUJjcQza6UoI1S-1024.npz
eval_Episode has 500 steps and return 318.6.
train_Episode has 500 steps and return 289.9.
Starting evaluation at step 250500 Counter(250500) 250437
eval_Episode has 500 steps and return 330.3.
Saved chunk: 20230922T025614F224325-49XOqRswhhYrIaF9VO2chc-6faQP2DrvvZEt6TD1aw1Xq-1024.npz
Starting evaluation at step 251000 Counter(251000) 250937
Saved chunk: 20230922T025626F569899-4fKpZ5CsCUJjcQza6UoI1S-20yr1KsY7cPXafa3RzLvfH-1024.npz
eval_Episode has 500 steps and return 354.2.
train_Episode has 500 steps and return 311.3.
Starting evaluation at step 251500 Counter(251500) 251437
eval_Episode has 500 steps and return 344.6.
train_Episode has 500 steps and return 296.9.
Saved chunk: 20230922T025734F528278-6faQP2DrvvZEt6TD1aw1Xq-5IR7bvZNs0mfN30fpbHFmH-1024.npz
Starting evaluation at step 252000 Counter(252000) 251937
Saved chunk: 20230922T025745F258710-20yr1KsY7cPXafa3RzLvfH-3XRJNvRGWRkaIW2WQZuafn-1024.npz
eval_Episode has 500 steps and return 329.1.
train_Episode has 500 steps and return 279.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 504678 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 279.82 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 329.1 / eval_episode/reward_rate 0.52 / train/action_mag 2.79 / train/action_max 2.78 / train/action_mean 0.08 / train/action_min -2.06 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -8.63 / train/adv_mag 0.52 / train/adv_max 0.36 / train/adv_mean 1.8e-3 / train/adv_min
-0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.93 / train/dyn_loss_std 6.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 242.19 / train/extr_critic_max 242.19 / train/extr_critic_mean 232.52 / train/extr_critic_min 207.37 / train/extr_critic_std 6.58 / train/extr_return_normed_mag 1.14 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 243.07 / train/extr_return_raw_max 243.07 / train/extr_return_raw_mean 232.56 / train/extr_return_raw_min 
206.42 / train/extr_return_raw_std 6.62 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.24 / train/image_loss_std 1.08 / train/model_loss_mean 3.79 /
train/model_loss_std 4.53 / train/model_opt_grad_norm 9.4 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9739.58 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.04 / train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 8.11 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.12 / train/policy_logprob_min -8.11 / 
train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8.9e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 51 / train/post_ent_max 51 / 
train/post_ent_mean 41.91 / train/post_ent_min 20.27 / train/post_ent_std 5.07 / train/prior_ent_mag 72.28 / train/prior_ent_max 72.28 / train/prior_ent_mean 45.82 / train/prior_ent_min 29.31 / train/prior_ent_std 5.21 / train/rep_loss_mean 3.93 / train/rep_loss_std 6.1
/ train/reward_avg 0.36 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.36 /
train/reward_rate 0.34 / train_stats/mean_log_entropy -3.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.1e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.45 / report/dyn_loss_std 6.37 / report/image_loss_mean 1.3 / report/image_loss_std 1.24 / report/model_loss_mean 4.22 / report/model_loss_std 4.82 / report/post_ent_mag 50.96
/ report/post_ent_max 50.96 / report/post_ent_mean 42.29 / report/post_ent_min 21.86 / report/post_ent_std 4.69 / report/prior_ent_mag 72.22 / report/prior_ent_max 72.22 / report/prior_ent_mean 46.66 / report/prior_ent_min 32.62 / report/prior_ent_std 4.42 / 
report/rep_loss_mean 4.45 / report/rep_loss_std 6.37 / report/reward_avg 0.44 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.44 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.71 / eval/dyn_loss_std 7.13 / eval/image_loss_mean 1.39 / eval/image_loss_std 2.02 / eval/model_loss_mean 4.51 / eval/model_loss_std 5.86 / eval/post_ent_mag 50.9 / eval/post_ent_max
50.9 / eval/post_ent_mean 42.7 / eval/post_ent_min 20.96 / eval/post_ent_std 4.35 / eval/prior_ent_mag 72.22 / eval/prior_ent_max 72.22 / eval/prior_ent_mean 46.87 / eval/prior_ent_min 32.05 / eval/prior_ent_std 3.97 / eval/rep_loss_mean 4.71 / eval/rep_loss_std 7.13 / 
eval/reward_avg 0.6 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.6 / 
eval/reward_rate 0.51 / replay/size 2.5e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3836 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.37 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-3 / 
timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 16.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.8e-3 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1918 / 
timer/agent.train_total 244.22 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 252500 Counter(252500) 252437
eval_Episode has 500 steps and return 328.6.
train_Episode has 500 steps and return 305.1.
Saved chunk: 20230922T025854F620982-5IR7bvZNs0mfN30fpbHFmH-0gArzejCQwuMZ3TAvj5KiS-1024.npz
Starting evaluation at step 253000 Counter(253000) 252937
Saved chunk: 20230922T025903F754907-3XRJNvRGWRkaIW2WQZuafn-5r1nqnoRjAsYuSrkaupBEb-1024.npz
eval_Episode has 500 steps and return 349.8.
train_Episode has 500 steps and return 316.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T030016F000346-0gArzejCQwuMZ3TAvj5KiS-0000000000000000000000-172.npz
Saved chunk: 20230922T030023F655190-5r1nqnoRjAsYuSrkaupBEb-0000000000000000000000-153.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 253500 Counter(253500) 253437
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 308.0.
Saved chunk: 20230922T030016F000346-0gArzejCQwuMZ3TAvj5KiS-7xzDaux3SyP1pueICBMZRw-1024.npz
Starting evaluation at step 254000 Counter(254000) 253937
Saved chunk: 20230922T030023F655190-5r1nqnoRjAsYuSrkaupBEb-7JDsnBAthqjFFaqKEkiA3O-1024.npz
eval_Episode has 500 steps and return 306.2.
train_Episode has 500 steps and return 302.8.
Starting evaluation at step 254500 Counter(254500) 254437
eval_Episode has 500 steps and return 309.7.
train_Episode has 500 steps and return 285.1.
Saved chunk: 20230922T030136F778737-7xzDaux3SyP1pueICBMZRw-4eH1Iu671q7US8TZ5OUXIV-1024.npz
Starting evaluation at step 255000 Counter(255000) 254937
Saved chunk: 20230922T030142F833329-7JDsnBAthqjFFaqKEkiA3O-5IVh13SmQEcuWgTEHHObCn-1024.npz
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 305.6.
Starting evaluation at step 255500 Counter(255500) 255437
eval_Episode has 500 steps and return 348.7.
train_Episode has 500 steps and return 323.8.
Starting evaluation at step 256000 Counter(256000) 255937
Saved chunk: 20230922T030257F110966-4eH1Iu671q7US8TZ5OUXIV-5sveJplfa3NTwD1OJPu97h-1024.npz
Saved chunk: 20230922T030301F592628-5IVh13SmQEcuWgTEHHObCn-08zG0L5lJB74JqRrAxDqo2-1024.npz
eval_Episode has 500 steps and return 331.3.
train_Episode has 500 steps and return 296.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 512234 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 331.3 / eval_episode/reward_rate 0.53 / episode/length 500 / episode/score 296.83 / episode/reward_rate 0.51 / train/action_mag 2.76 / train/action_max 2.74 / train/action_mean 0.08 / train/action_min -2.05 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.54 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -3.61 / train/adv_mag 0.54 / train/adv_max 0.39 / train/adv_mean 1.3e-3 / train/adv_min
-0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.92 / train/dyn_loss_std 6.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 243.01 / train/extr_critic_max 243.01 / train/extr_critic_mean 233.68 / train/extr_critic_min 207.37 / train/extr_critic_std 6.14 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 243.87 / train/extr_return_raw_max 243.87 / train/extr_return_raw_mean 233.71 / train/extr_return_raw_min 
208.01 / train/extr_return_raw_std 6.19 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.22 / train/image_loss_std 1.08 / train/model_loss_mean 3.78 /
train/model_loss_std 4.51 / train/model_opt_grad_norm 9.57 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.1 / train/policy_entropy_mean -3.13 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.13 / train/policy_logprob_min -8.13 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8.5e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.93 / train/post_ent_max 50.93 / train/post_ent_mean 42.02 / 
train/post_ent_min 20.4 / train/post_ent_std 4.9 / train/prior_ent_mag 72.2 / train/prior_ent_max 72.2 / train/prior_ent_mean 45.92 / train/prior_ent_min 30.09 / train/prior_ent_std 5.01 / train/rep_loss_mean 3.92 / train/rep_loss_std 6.07 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.37 / train/reward_rate 0.35 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.19 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 8.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 5.92 / report/image_loss_mean 1.2 / report/image_loss_std 0.95 / report/model_loss_mean 3.55 / report/model_loss_std 4.28 / report/post_ent_mag 51.25 / report/post_ent_max 51.25 / 
report/post_ent_mean 41.27 / report/post_ent_min 21.12 / report/post_ent_std 4.98 / report/prior_ent_mag 72.21 / report/prior_ent_max 72.21 / report/prior_ent_mean 45.05 / report/prior_ent_min 28.6 / report/prior_ent_std 5.28 / report/rep_loss_mean 3.66 / 
report/rep_loss_std 5.92 / report/reward_avg 0.29 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.28 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 5.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.29 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.07 / eval/dyn_loss_std 5.95 / eval/image_loss_mean 1.2 / eval/image_loss_std 1.5 / eval/model_loss_mean 3.94 / eval/model_loss_std 4.72 / eval/post_ent_mag 50.91 / eval/post_ent_max 50.91 / eval/post_ent_mean 
42.31 / eval/post_ent_min 24.4 / eval/post_ent_std 4.3 / eval/prior_ent_mag 72.21 / eval/prior_ent_max 72.21 / eval/prior_ent_mean 46.12 / eval/prior_ent_min 33.26 / eval/prior_ent_std 4.85 / eval/rep_loss_mean 4.07 / eval/rep_loss_std 5.95 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.55 / eval/reward_rate 0.49 / 
replay/size 2.6e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3778 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.96 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.1e-4 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.04 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / 
timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1889 / timer/agent.train_total 240.72 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 256500 Counter(256500) 256437
eval_Episode has 500 steps and return 347.9.
train_Episode has 500 steps and return 331.6.
Starting evaluation at step 257000 Counter(257000) 256937
eval_Episode has 500 steps and return 326.8.
Saved chunk: 20230922T030420F204142-08zG0L5lJB74JqRrAxDqo2-6PiUcBgfMmMSegkUUWruUh-1024.npz
train_Episode has 500 steps and return 301.7.
Saved chunk: 20230922T030417F303485-5sveJplfa3NTwD1OJPu97h-2AL8InjmiBighSpl0mvQqL-1024.npz
Starting evaluation at step 257500 Counter(257500) 257437
eval_Episode has 500 steps and return 347.1.
train_Episode has 500 steps and return 311.3.
Starting evaluation at step 258000 Counter(258000) 257937
eval_Episode has 500 steps and return 343.7.
Saved chunk: 20230922T030540F045053-6PiUcBgfMmMSegkUUWruUh-37Jhvp2UhcnOFbJDqsXZA8-1024.npz
train_Episode has 500 steps and return 295.8.
Saved chunk: 20230922T030542F281061-2AL8InjmiBighSpl0mvQqL-1Gz54GRyyMqVm46kmcy7ht-1024.npz
Starting evaluation at step 258500 Counter(258500) 258437
eval_Episode has 500 steps and return 325.7.
train_Episode has 500 steps and return 314.9.
Starting evaluation at step 259000 Counter(259000) 258937
eval_Episode has 500 steps and return 328.1.
Saved chunk: 20230922T030659F064606-37Jhvp2UhcnOFbJDqsXZA8-4ns6LRuBOBRv1uf1OxksXr-1024.npz
train_Episode has 500 steps and return 310.4.
Saved chunk: 20230922T030702F841184-1Gz54GRyyMqVm46kmcy7ht-1WdSzWjRn2gQGjoTw1Uoo0-1024.npz
Starting evaluation at step 259500 Counter(259500) 259437
eval_Episode has 500 steps and return 345.4.
train_Episode has 500 steps and return 301.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 519894 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 345.4 / eval_episode/reward_rate 0.56 / episode/length 500 / episode/score 301.27 / episode/reward_rate 0.51 / train/action_mag 2.83 / train/action_max 2.82 / train/action_mean 0.08 / train/action_min -2.06 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.55 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -6.77 / train/adv_mag 0.56 / train/adv_max 0.43 / train/adv_mean 1.6e-3 / train/adv_min
-0.48 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.5e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 243.8 / train/extr_critic_max 243.8 / train/extr_critic_mean 234.35 / train/extr_critic_min 206.91 / train/extr_critic_std 6.43 / train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 244.73 / train/extr_return_raw_max 244.73 / train/extr_return_raw_mean 234.39 / train/extr_return_raw_min 
207.94 / train/extr_return_raw_std 6.47 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.22 / train/image_loss_std 1.08 / train/model_loss_mean 3.77 /
train/model_loss_std 4.5 / train/model_opt_grad_norm 9.74 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.03 / train/policy_entropy_mean -3.13 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 7.86 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.13 / train/policy_logprob_min -7.86 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 51.01 / train/post_ent_max 51.01 / train/post_ent_mean 41.95 / 
train/post_ent_min 20.57 / train/post_ent_std 4.99 / train/prior_ent_mag 72.18 / train/prior_ent_max 72.18 / train/prior_ent_mean 45.85 / train/prior_ent_min 29.66 / train/prior_ent_std 5.13 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.06 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.37 / train/reward_rate 0.35 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.18 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 5.93 / report/image_loss_mean 1.25 / report/image_loss_std 1.26 / report/model_loss_mean 3.74 / report/model_loss_std 4.53 / report/post_ent_mag 51.47 / report/post_ent_max 51.47 /
report/post_ent_mean 41.85 / report/post_ent_min 21.93 / report/post_ent_std 4.88 / report/prior_ent_mag 72.16 / report/prior_ent_max 72.16 / report/prior_ent_mean 45.64 / report/prior_ent_min 28.28 / report/prior_ent_std 5.2 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 5.93 / report/reward_avg 0.39 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.52 / report/reward_pred 0.38 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 7e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.08 / eval/dyn_loss_std 6.19 / eval/image_loss_mean 1.18 / eval/image_loss_std 1.43 / eval/model_loss_mean 3.92 / eval/model_loss_std 4.87 / eval/post_ent_mag 50.19 / eval/post_ent_max 50.19 / eval/post_ent_mean 42.78 / 
eval/post_ent_min 19.87 / eval/post_ent_std 4.09 / eval/prior_ent_mag 72.16 / eval/prior_ent_max 72.16 / eval/prior_ent_mean 46.7 / eval/prior_ent_min 33.9 / eval/prior_ent_std 3.92 / eval/rep_loss_mean 4.08 / eval/rep_loss_std 6.19 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.61 / eval/reward_rate 0.54 / 
replay/size 2.6e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.9e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3830 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.87 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.8e-4 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7337 / timer/agent.policy_total 16.9 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 5.5e-3 /
timer/dataset_train_count 1915 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1915 / timer/agent.train_total 244.44 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 260000 Counter(260000) 259937
eval_Episode has 500 steps and return 344.5.
train_Episode has 500 steps and return 312.7.
Saved chunk: 20230922T030823F202069-1WdSzWjRn2gQGjoTw1Uoo0-2FlHq2dTm1fAYxsVCNjwLf-1024.npz
Starting evaluation at step 260500 Counter(260500) 260437
Saved chunk: 20230922T030817F884669-4ns6LRuBOBRv1uf1OxksXr-7t1LKMhWFz87KdZPptuTEq-1024.npz
eval_Episode has 500 steps and return 333.8.
train_Episode has 500 steps and return 288.3.
Starting evaluation at step 261000 Counter(261000) 260937
eval_Episode has 500 steps and return 345.1.
train_Episode has 500 steps and return 300.6.
Saved chunk: 20230922T030945F717400-2FlHq2dTm1fAYxsVCNjwLf-74nKBTad6DaMuCvQwjg7AJ-1024.npz
Starting evaluation at step 261500 Counter(261500) 261437
Saved chunk: 20230922T031014F753428-7t1LKMhWFz87KdZPptuTEq-2oZz5lTi1x038QEom41P6H-1024.npz
eval_Episode has 500 steps and return 329.2.
train_Episode has 500 steps and return 290.4.
Starting evaluation at step 262000 Counter(262000) 261937
eval_Episode has 500 steps and return 339.8.
train_Episode has 500 steps and return 319.1.
Saved chunk: 20230922T031106F319287-74nKBTad6DaMuCvQwjg7AJ-3Ek8Qd5QewKo8irdjZowZu-1024.npz
Starting evaluation at step 262500 Counter(262500) 262437
Saved chunk: 20230922T031133F707663-2oZz5lTi1x038QEom41P6H-5crbJqlkky4Ewlyl5VCEfH-1024.npz
eval_Episode has 500 steps and return 334.3.
train_Episode has 500 steps and return 233.2.
Starting evaluation at step 263000 Counter(263000) 262937
eval_Episode has 500 steps and return 318.3.
train_Episode has 500 steps and return 273.7.
Saved chunk: 20230922T031226F738914-3Ek8Qd5QewKo8irdjZowZu-0acqASnMwuThlS538sl4TC-1024.npz
Starting evaluation at step 263500 Counter(263500) 263437
Saved chunk: 20230922T031252F549513-5crbJqlkky4Ewlyl5VCEfH-4TihnFAYdMRf3G5Ipn0x8o-1024.npz
eval_Episode has 500 steps and return 321.6.
train_Episode has 500 steps and return 277.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 527422 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 321.58 / eval_episode/reward_rate 0.53 / episode/length 500 / episode/score 277.27 / episode/reward_rate 0.48 / train/action_mag 2.85 / train/action_max 2.83 / train/action_mean 0.08 / train/action_min -2.06 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.54 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -0.47 / train/adv_mag 0.65 / train/adv_max 0.51 / train/adv_mean 1e-3 
/ train/adv_min -0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.5e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.93 / train/dyn_loss_std 6.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 244.63 / train/extr_critic_max 244.63 / train/extr_critic_mean 235.19 / train/extr_critic_min 206.26 / train/extr_critic_std 6.33 / train/extr_return_normed_mag 1.14 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 245.55 / train/extr_return_raw_max 245.55 / train/extr_return_raw_mean 235.21 / train/extr_return_raw_min 
209.29 / train/extr_return_raw_std 6.39 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.22 / train/image_loss_std 1.07 / train/model_loss_mean 3.78 /
train/model_loss_std 4.51 / train/model_opt_grad_norm 9.84 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.1 / train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 7.95 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.12 / train/policy_logprob_min -7.95 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8.7e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.82 / train/post_ent_max 50.82 / train/post_ent_mean 41.97 / 
train/post_ent_min 20.64 / train/post_ent_std 4.89 / train/prior_ent_mag 72.22 / train/prior_ent_max 72.22 / train/prior_ent_mean 45.9 / train/prior_ent_min 29.87 / train/prior_ent_std 5.02 / train/rep_loss_mean 3.93 / train/rep_loss_std 6.09 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.37 / train/reward_rate 0.35 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.17 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.96 / report/dyn_loss_std 6.2 / report/image_loss_mean 1.27 / report/image_loss_std 1.13 / report/model_loss_mean 3.83 / report/model_loss_std 4.61 / report/post_ent_mag 50.65 / report/post_ent_max 50.65 / 
report/post_ent_mean 42.32 / report/post_ent_min 18.84 / report/post_ent_std 4.86 / report/prior_ent_mag 72.26 / report/prior_ent_max 72.26 / report/prior_ent_mean 46.09 / report/prior_ent_min 29.73 / report/prior_ent_std 4.76 / report/rep_loss_mean 3.96 / 
report/rep_loss_std 6.2 / report/reward_avg 0.34 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 1.96 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.34 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 7.8e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.44 / eval/dyn_loss_std 6.9 / eval/image_loss_mean 1.27 / eval/image_loss_std 1.8 / eval/model_loss_mean 4.22 / eval/model_loss_std 5.61 / eval/post_ent_mag 50.15 / eval/post_ent_max 50.15 / eval/post_ent_mean 
42.49 / eval/post_ent_min 21.58 / eval/post_ent_std 4.38 / eval/prior_ent_mag 72.26 / eval/prior_ent_max 72.26 / eval/prior_ent_mean 46.6 / eval/prior_ent_min 34.32 / eval/prior_ent_std 4.01 / eval/rep_loss_mean 4.44 / eval/rep_loss_std 6.9 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.61 / eval/reward_rate 0.53 / 
replay/size 2.6e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3764 / timer/env.step_total 19.43 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.22 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.81 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1882 / timer/agent.train_total 239.99 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 264000 Counter(264000) 263937
eval_Episode has 500 steps and return 343.8.
train_Episode has 500 steps and return 301.1.
Saved chunk: 20230922T031347F092871-0acqASnMwuThlS538sl4TC-0hepw6zdXiLr4GyhGpPKyl-1024.npz
Starting evaluation at step 264500 Counter(264500) 264437
Saved chunk: 20230922T031411F206156-4TihnFAYdMRf3G5Ipn0x8o-3SKqeLsHYsQgCqdqL4gvMy-1024.npz
eval_Episode has 500 steps and return 338.1.
train_Episode has 500 steps and return 307.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T031508F347887-0hepw6zdXiLr4GyhGpPKyl-0000000000000000000000-408.npz
Saved chunk: 20230922T031531F105729-3SKqeLsHYsQgCqdqL4gvMy-0000000000000000000000-412.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 265000 Counter(265000) 264937
eval_Episode has 500 steps and return 338.7.
train_Episode has 500 steps and return 292.1.
Saved chunk: 20230922T031508F347887-0hepw6zdXiLr4GyhGpPKyl-4Fj9R2e9mAbEm6l3yOUgeM-1024.npz
Starting evaluation at step 265500 Counter(265500) 265437
Saved chunk: 20230922T031531F105729-3SKqeLsHYsQgCqdqL4gvMy-3MGQMfG1NPd1UJg3ATA5pH-1024.npz
eval_Episode has 500 steps and return 276.8.
train_Episode has 500 steps and return 300.5.
Starting evaluation at step 266000 Counter(266000) 265937
eval_Episode has 500 steps and return 285.1.
train_Episode has 500 steps and return 283.7.
Saved chunk: 20230922T031629F259451-4Fj9R2e9mAbEm6l3yOUgeM-3VSFpZvae5ivIopNGfF0d4-1024.npz
Starting evaluation at step 266500 Counter(266500) 266437
Saved chunk: 20230922T031650F323757-3MGQMfG1NPd1UJg3ATA5pH-28TZUeoAsaJoKTlcoJxxG6-1024.npz
eval_Episode has 500 steps and return 371.0.
train_Episode has 500 steps and return 300.1.
Starting evaluation at step 267000 Counter(267000) 266937
eval_Episode has 500 steps and return 354.2.
train_Episode has 500 steps and return 316.5.
Saved chunk: 20230922T031749F518705-3VSFpZvae5ivIopNGfF0d4-6cRqKYRDahhWeOr0eDRCK0-1024.npz
Starting evaluation at step 267500 Counter(267500) 267437
Saved chunk: 20230922T031808F960377-28TZUeoAsaJoKTlcoJxxG6-5y8uQCo7YVa6hXNE7i4TNR-1024.npz
eval_Episode has 500 steps and return 347.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 535002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 347.28 / eval_episode/reward_rate 0.61 / episode/length 500 / episode/score 316.46 / episode/reward_rate 0.52 / train/action_mag 2.71 / train/action_max 2.69 / train/action_mean 0.08 / train/action_min -2.01 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.55 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -0.43 / train/adv_mag 0.63 / train/adv_max 0.48 / train/adv_mean 
9.9e-4 / train/adv_min -0.48 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 245.13 / train/extr_critic_max 245.13 / train/extr_critic_mean 235.87 / train/extr_critic_min 208.07 / train/extr_critic_std 6.09 / train/extr_return_normed_mag
1.11 / train/extr_return_normed_max 1.1 / train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 246.05 / train/extr_return_raw_max 246.05 / 
train/extr_return_raw_mean 235.89 / train/extr_return_raw_min 210.99 / train/extr_return_raw_std 6.15 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 
1.2 / train/image_loss_std 1.07 / train/model_loss_mean 3.75 / train/model_loss_std 4.49 / train/model_opt_grad_norm 9.5 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 0.85 / train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.93 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.15 / 
train/policy_logprob_min -7.93 / train/policy_logprob_std 1.51 / train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8.3e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.85 / 
train/post_ent_max 50.85 / train/post_ent_mean 42.04 / train/post_ent_min 20.71 / train/post_ent_std 4.8 / train/prior_ent_mag 72.19 / train/prior_ent_max 72.19 / train/prior_ent_mean 45.92 / train/prior_ent_min 30.11 / train/prior_ent_std 4.96 / train/rep_loss_mean 3.9
/ train/rep_loss_std 6.05 / train/reward_avg 0.38 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 /
train/reward_pred 0.38 / train/reward_rate 0.36 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.19 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.07 / report/dyn_loss_std 6.14 / report/image_loss_mean 1.27 / report/image_loss_std 1.16 / report/model_loss_mean 3.93 / report/model_loss_std 4.61 / 
report/post_ent_mag 50.53 / report/post_ent_max 50.53 / report/post_ent_mean 42.35 / report/post_ent_min 21.17 / report/post_ent_std 4.46 / report/prior_ent_mag 72.2 / report/prior_ent_max 72.2 / report/prior_ent_mean 46.34 / report/prior_ent_min 34.07 / 
report/prior_ent_std 4.31 / report/rep_loss_mean 4.07 / report/rep_loss_std 6.14 / report/reward_avg 0.4 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss
3.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.4 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.58 / eval/dyn_loss_std 6.27 / eval/image_loss_mean 1.27 / eval/image_loss_std 1.59 / eval/model_loss_mean 4.29 / eval/model_loss_std 5 / eval/post_ent_mag 51.41 / eval/post_ent_max 
51.41 / eval/post_ent_mean 42.35 / eval/post_ent_min 22.17 / eval/post_ent_std 4.24 / eval/prior_ent_mag 72.2 / eval/prior_ent_max 72.2 / eval/prior_ent_mean 46.61 / eval/prior_ent_min 32.31 / eval/prior_ent_std 4.03 / eval/rep_loss_mean 4.58 / eval/rep_loss_std 6.27 / 
eval/reward_avg 0.54 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.53 / 
eval/reward_rate 0.47 / replay/size 2.7e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.66 / timer/env.step_count 3790 / timer/env.step_total 19.66 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.38 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.8e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7798 / timer/agent.policy_total 18 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1895 / timer/agent.train_total 241.49 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / 
timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 322.2.
Starting evaluation at step 268000 Counter(268000) 267937
eval_Episode has 500 steps and return 351.1.
train_Episode has 500 steps and return 301.6.
Saved chunk: 20230922T031909F602592-6cRqKYRDahhWeOr0eDRCK0-2RQGOaiccqqqLdX7yzhCGk-1024.npz
Starting evaluation at step 268500 Counter(268500) 268437
Saved chunk: 20230922T031927F470098-5y8uQCo7YVa6hXNE7i4TNR-4GOBQ3u54laecdMbLEbje5-1024.npz
eval_Episode has 500 steps and return 337.9.
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 269000 Counter(269000) 268937
eval_Episode has 500 steps and return 342.2.
train_Episode has 500 steps and return 291.4.
Saved chunk: 20230922T032030F925908-2RQGOaiccqqqLdX7yzhCGk-1m7HUpVDqCobt0zhmLf65Y-1024.npz
Starting evaluation at step 269500 Counter(269500) 269437
Saved chunk: 20230922T032047F358493-4GOBQ3u54laecdMbLEbje5-6RLJlmTODZrScSbgtmso03-1024.npz
eval_Episode has 500 steps and return 345.1.
train_Episode has 500 steps and return 321.6.
Starting evaluation at step 270000 Counter(270000) 269937
eval_Episode has 500 steps and return 331.7.
train_Episode has 500 steps and return 292.9.
Saved chunk: 20230922T032151F458889-1m7HUpVDqCobt0zhmLf65Y-5jXSimWYgbyQ3sI8XV1O8O-1024.npz
Starting evaluation at step 270500 Counter(270500) 270437
Saved chunk: 20230922T032206F334455-6RLJlmTODZrScSbgtmso03-15QBO1upl9IMqHzdBQF13x-1024.npz
eval_Episode has 500 steps and return 315.1.
train_Episode has 500 steps and return 306.0.
Starting evaluation at step 271000 Counter(271000) 270937
eval_Episode has 500 steps and return 345.3.
train_Episode has 500 steps and return 258.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 542670 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 258.19 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 345.31 / eval_episode/reward_rate 0.62 / train/action_mag 2.83 / train/action_max 2.75 / train/action_mean 0.08 / train/action_min -2.06 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.62 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 11.64 / train/adv_mag 0.57 / train/adv_max 0.42 / train/adv_mean 
-2.3e-4 / train/adv_min -0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 245.55 / train/extr_critic_max 245.55 / train/extr_critic_mean 236.15 / train/extr_critic_min 209.48 / train/extr_critic_std 6.24 / train/extr_return_normed_mag
1.12 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 246.55 / train/extr_return_raw_max 246.55 / 
train/extr_return_raw_mean 236.14 / train/extr_return_raw_min 210.33 / train/extr_return_raw_std 6.3 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 
1.21 / train/image_loss_std 1.07 / train/model_loss_mean 3.76 / train/model_loss_std 4.48 / train/model_opt_grad_norm 9.48 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.07 / train/policy_entropy_mean -3.14 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.55 / train/policy_logprob_mag 7.93 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 3.13 / 
train/policy_logprob_min -7.93 / train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8.6e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.84 / 
train/post_ent_max 50.84 / train/post_ent_mean 42.01 / train/post_ent_min 20.55 / train/post_ent_std 4.83 / train/prior_ent_mag 72.14 / train/prior_ent_max 72.14 / train/prior_ent_mean 45.91 / train/prior_ent_min 29.96 / train/prior_ent_std 4.98 / train/rep_loss_mean 
3.91 / train/rep_loss_std 6.03 / train/reward_avg 0.38 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss
0.57 / train/reward_pred 0.38 / train/reward_rate 0.36 / train_stats/mean_log_entropy -3.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.33 / report/dyn_loss_std 6.92 / report/image_loss_mean 1.36 / report/image_loss_std 1.4 / report/model_loss_mean 4.15 / report/model_loss_std 5.17 / 
report/post_ent_mag 51.07 / report/post_ent_max 51.07 / report/post_ent_mean 41.87 / report/post_ent_min 17 / report/post_ent_std 5.12 / report/prior_ent_mag 72.12 / report/prior_ent_max 72.12 / report/prior_ent_mean 46.31 / report/prior_ent_min 29.75 / 
report/prior_ent_std 5.12 / report/rep_loss_mean 4.33 / report/rep_loss_std 6.92 / report/reward_avg 0.36 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / 
report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.36 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.17 / eval/dyn_loss_std 5.73 / eval/image_loss_mean 1.18 / eval/image_loss_std 1.13 / eval/model_loss_mean 3.98 / eval/model_loss_std 4.35 / eval/post_ent_mag 
50.03 / eval/post_ent_max 50.03 / eval/post_ent_mean 42.56 / eval/post_ent_min 23.78 / eval/post_ent_std 3.82 / eval/prior_ent_mag 72.12 / eval/prior_ent_max 72.12 / eval/prior_ent_mean 46.55 / eval/prior_ent_min 38.09 / eval/prior_ent_std 3.76 / eval/rep_loss_mean 4.17
/ eval/rep_loss_std 5.73 / eval/reward_avg 0.64 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / 
eval/reward_pred 0.64 / eval/reward_rate 0.54 / replay/size 2.7e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3834 / timer/env.step_total 19.8 /
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 462.64 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 7.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7341 / timer/agent.policy_total 16.95 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1917 / timer/agent.train_total 244.35 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 5.1e-5 / timer/dataset_eval_frac 1.7e-7 / timer/dataset_eval_avg 5.1e-5 / timer/dataset_eval_min 5.1e-5 / 
timer/dataset_eval_max 5.1e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T032311F803666-5jXSimWYgbyQ3sI8XV1O8O-0T6HBjoo3nuFWme6Etn1eX-1024.npz
Starting evaluation at step 271500 Counter(271500) 271437
Saved chunk: 20230922T032325F060399-15QBO1upl9IMqHzdBQF13x-08IjhZN0DH1IH2yJkOpdPg-1024.npz
eval_Episode has 500 steps and return 346.2.
train_Episode has 500 steps and return 297.4.
Starting evaluation at step 272000 Counter(272000) 271937
eval_Episode has 500 steps and return 327.4.
train_Episode has 500 steps and return 282.2.
Saved chunk: 20230922T032432F745788-0T6HBjoo3nuFWme6Etn1eX-6kpxHaRERkdeMzPCsplloW-1024.npz
Starting evaluation at step 272500 Counter(272500) 272437
Saved chunk: 20230922T032444F573760-08IjhZN0DH1IH2yJkOpdPg-29WPsNp0BePxiAFULy77My-1024.npz
eval_Episode has 500 steps and return 333.6.
train_Episode has 500 steps and return 268.6.
Starting evaluation at step 273000 Counter(273000) 272937
eval_Episode has 500 steps and return 264.6.
train_Episode has 500 steps and return 291.9.
Saved chunk: 20230922T032553F452647-6kpxHaRERkdeMzPCsplloW-1SjQEUgHKheJ2iOvuULrGN-1024.npz
Starting evaluation at step 273500 Counter(273500) 273437
Saved chunk: 20230922T032603F636997-29WPsNp0BePxiAFULy77My-7D4LZ09Fg2dC39AK4mFDFm-1024.npz
eval_Episode has 500 steps and return 329.3.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 274000 Counter(274000) 273937
eval_Episode has 500 steps and return 325.9.
train_Episode has 500 steps and return 268.9.
Saved chunk: 20230922T032713F993487-1SjQEUgHKheJ2iOvuULrGN-3NVpCZ4bCbNI2vv4ApMhpo-1024.npz
Starting evaluation at step 274500 Counter(274500) 274437
Saved chunk: 20230922T032722F615806-7D4LZ09Fg2dC39AK4mFDFm-43Bu4rAL6zVJ0soZNtfEGh-1024.npz
eval_Episode has 500 steps and return 346.3.
train_Episode has 500 steps and return 280.7.
Starting evaluation at step 275000 Counter(275000) 274937
eval_Episode has 500 steps and return 313.7.
train_Episode has 500 steps and return 309.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 550234 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 313.73 / eval_episode/reward_rate 0.53 / episode/length 500 / episode/score 309.63 / episode/reward_rate 0.54 / train/action_mag 2.83 / train/action_max 2.75 / train/action_mean 0.08 / train/action_min -2.11 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.66 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 16.4 / train/adv_mag 0.58 / train/adv_max 0.4 / train/adv_mean -7.1e-4
/ train/adv_min -0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 245.03 / train/extr_critic_max 245.03 / train/extr_critic_mean 235.12 / train/extr_critic_min 208.67 / train/extr_critic_std 6.42 / train/extr_return_normed_mag 1.14 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 245.83 / train/extr_return_raw_max 245.83 / train/extr_return_raw_mean 235.1 / train/extr_return_raw_min 
208.82 / train/extr_return_raw_std 6.49 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.19 / train/image_loss_std 1.05 / train/model_loss_mean 3.74 /
train/model_loss_std 4.46 / train/model_opt_grad_norm 9.42 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.98 / train/policy_entropy_mean -3.14 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.55 / train/policy_logprob_mag 7.98 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.14 / train/policy_logprob_min -7.98 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.49 / train/policy_randomness_max 0.49 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.7e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.74 / train/post_ent_max 50.74 / train/post_ent_mean 41.98 / 
train/post_ent_min 20.52 / train/post_ent_std 4.82 / train/prior_ent_mag 72.11 / train/prior_ent_max 72.11 / train/prior_ent_mean 45.87 / train/prior_ent_min 29.81 / train/prior_ent_std 4.98 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.02 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.39 / train/reward_rate 0.36 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.2 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.22 / report/image_loss_mean 1.17 / report/image_loss_std 0.96 / report/model_loss_mean 3.75 / report/model_loss_std 4.57 / report/post_ent_mag 51.13 / report/post_ent_max 51.13 /
report/post_ent_mean 41.82 / report/post_ent_min 21.43 / report/post_ent_std 5.06 / report/prior_ent_mag 72.12 / report/prior_ent_max 72.12 / report/prior_ent_mean 45.77 / report/prior_ent_min 29.23 / report/prior_ent_std 5.14 / report/rep_loss_mean 3.95 / 
report/rep_loss_std 6.22 / report/reward_avg 0.36 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.36 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.61 / eval/dyn_loss_std 6.66 / eval/image_loss_mean 1.33 / eval/image_loss_std 1.85 / eval/model_loss_mean 4.39 / eval/model_loss_std 5.34 / eval/post_ent_mag 49.99 / eval/post_ent_max 49.99 / eval/post_ent_mean 
42.06 / eval/post_ent_min 19.7 / eval/post_ent_std 4.61 / eval/prior_ent_mag 72.12 / eval/prior_ent_max 72.12 / eval/prior_ent_mean 46.35 / eval/prior_ent_min 32.95 / eval/prior_ent_std 4.25 / eval/rep_loss_mean 4.61 / eval/rep_loss_std 6.66 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.58 / eval/reward_rate 0.52 / 
replay/size 2.8e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3782 / timer/env.step_total 19.56 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.52 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T032834F203300-3NVpCZ4bCbNI2vv4ApMhpo-18ORRR5YSBUqqZgx0fE6OY-1024.npz
Starting evaluation at step 275500 Counter(275500) 275437
Saved chunk: 20230922T032841F232459-43Bu4rAL6zVJ0soZNtfEGh-5lK9cUhhonExLgZf8r95Bo-1024.npz
eval_Episode has 500 steps and return 323.4.
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 276000 Counter(276000) 275937
eval_Episode has 500 steps and return 330.9.
train_Episode has 500 steps and return 275.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T032955F235260-18ORRR5YSBUqqZgx0fE6OY-0000000000000000000000-644.npz
Saved chunk: 20230922T033000F745759-5lK9cUhhonExLgZf8r95Bo-0000000000000000000000-671.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T032955F235260-18ORRR5YSBUqqZgx0fE6OY-1dR8A8LrdcGXpWNIZONqBn-1024.npz
Starting evaluation at step 276500 Counter(276500) 276437
Saved chunk: 20230922T033000F745759-5lK9cUhhonExLgZf8r95Bo-26ehNwdQYWBtUCOO3AzG7k-1024.npz
eval_Episode has 500 steps and return 313.1.
train_Episode has 500 steps and return 290.9.
Starting evaluation at step 277000 Counter(277000) 276937
eval_Episode has 500 steps and return 348.0.
train_Episode has 500 steps and return 264.6.
Starting evaluation at step 277500 Counter(277500) 277437
Saved chunk: 20230922T033119F910995-26ehNwdQYWBtUCOO3AzG7k-60g11Dh74zp1386GDPUxyW-1024.npz
eval_Episode has 500 steps and return 349.9.
Saved chunk: 20230922T033115F984604-1dR8A8LrdcGXpWNIZONqBn-4FUYpZHCjUQBOBwD7kVNHr-1024.npz
train_Episode has 500 steps and return 299.0.
Starting evaluation at step 278000 Counter(278000) 277937
eval_Episode has 500 steps and return 339.5.
train_Episode has 500 steps and return 307.0.
Starting evaluation at step 278500 Counter(278500) 278437
Saved chunk: 20230922T033238F687880-60g11Dh74zp1386GDPUxyW-3CVAWsXFdc0gvAN1ZVK2XR-1024.npz
eval_Episode has 500 steps and return 309.9.
Saved chunk: 20230922T033239F894568-4FUYpZHCjUQBOBwD7kVNHr-5G4pfhADfYmTHnNAuKzlIy-1024.npz
train_Episode has 500 steps and return 298.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 557898 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 309.92 / eval_episode/reward_rate 0.51 / episode/length 500 / episode/score 298.86 / episode/reward_rate 0.51 / train/action_mag 2.75 / train/action_max 2.71 / train/action_mean 0.08 / train/action_min -2.08 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.65 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -6.1 / train/adv_mag 0.52 / train/adv_max 0.34 / train/adv_mean 1.6e-3
/ train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 245.12 / train/extr_critic_max 245.12 / train/extr_critic_mean 235.22 / train/extr_critic_min 209.98 / train/extr_critic_std 6.55 / train/extr_return_normed_mag 1.14 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.62 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 245.99 / train/extr_return_raw_max 245.99 / train/extr_return_raw_mean 235.25 / train/extr_return_raw_min 
208.45 / train/extr_return_raw_std 6.62 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.19 / train/image_loss_std 1.07 / train/model_loss_mean 3.74 /
train/model_loss_std 4.49 / train/model_opt_grad_norm 9.55 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.12 / train/policy_entropy_mean -3.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 8.03 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.16 / train/policy_logprob_min -8.03 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.6e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.82 / train/post_ent_max 50.82 / train/post_ent_mean 41.97 / 
train/post_ent_min 20.31 / train/post_ent_std 4.82 / train/prior_ent_mag 72.18 / train/prior_ent_max 72.18 / train/prior_ent_mean 45.85 / train/prior_ent_min 29.98 / train/prior_ent_std 5.03 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.06 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.38 / train/reward_rate 0.36 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.21 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 5.8 / report/image_loss_mean 1.1 / report/image_loss_std 1.02 / report/model_loss_mean 3.6 / report/model_loss_std 4.38 / report/post_ent_mag 51.6 / report/post_ent_max 51.6 / 
report/post_ent_mean 43 / report/post_ent_min 20.87 / report/post_ent_std 3.92 / report/prior_ent_mag 72.09 / report/prior_ent_max 72.09 / report/prior_ent_mean 46.69 / report/prior_ent_min 29.48 / report/prior_ent_std 4.12 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 5.8 / report/reward_avg 0.52 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.52 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.82 / eval/dyn_loss_std 7.09 / eval/image_loss_mean 1.61 / eval/image_loss_std 3.11 / eval/model_loss_mean 4.83 / eval/model_loss_std 6.98 / eval/post_ent_mag 51.38 / eval/post_ent_max 51.38 / eval/post_ent_mean 
42.35 / eval/post_ent_min 16.34 / eval/post_ent_std 4.46 / eval/prior_ent_mag 72.09 / eval/prior_ent_max 72.09 / eval/prior_ent_mean 46.68 / eval/prior_ent_min 32.52 / eval/prior_ent_std 3.79 / eval/rep_loss_mean 4.82 / eval/rep_loss_std 7.09 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.47 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.09 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.58 / eval/reward_rate 0.49 / 
replay/size 2.8e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3832 / timer/env.step_total 19.83 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.3 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.4e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7339 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1916 / timer/agent.train_total 244.04 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 279000 Counter(279000) 278937
eval_Episode has 500 steps and return 336.9.
train_Episode has 500 steps and return 299.3.
Starting evaluation at step 279500 Counter(279500) 279437
eval_Episode has 500 steps and return 298.8.
Saved chunk: 20230922T033357F264406-3CVAWsXFdc0gvAN1ZVK2XR-78KbugTL6BdRBeBeIKoR7u-1024.npz
train_Episode has 500 steps and return 278.1.
Saved chunk: 20230922T033400F063889-5G4pfhADfYmTHnNAuKzlIy-77bRRab1uE5sJ7hgapvJI5-1024.npz
Starting evaluation at step 280000 Counter(280000) 279937
eval_Episode has 500 steps and return 356.2.
train_Episode has 500 steps and return 285.1.
Starting evaluation at step 280500 Counter(280500) 280437
eval_Episode has 500 steps and return 349.9.
Saved chunk: 20230922T033517F100530-78KbugTL6BdRBeBeIKoR7u-4Lizrpx8CcV36GWAUfbdL9-1024.npz
train_Episode has 500 steps and return 313.3.
Saved chunk: 20230922T033521F463540-77bRRab1uE5sJ7hgapvJI5-1eeRGjVJPxjAxrpBPke3R5-1024.npz
Starting evaluation at step 281000 Counter(281000) 280937
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 294.0.
Starting evaluation at step 281500 Counter(281500) 281437
eval_Episode has 500 steps and return 355.5.
Saved chunk: 20230922T033636F020609-4Lizrpx8CcV36GWAUfbdL9-6d7XhPXK235TzlyCrKI0s8-1024.npz
train_Episode has 500 steps and return 321.0.
Saved chunk: 20230922T033641F911642-1eeRGjVJPxjAxrpBPke3R5-65cxcVEu5AWHVXqQrFjX66-1024.npz
Starting evaluation at step 282000 Counter(282000) 281937
eval_Episode has 500 steps and return 334.8.
train_Episode has 500 steps and return 316.0.
Starting evaluation at step 282500 Counter(282500) 282437
eval_Episode has 500 steps and return 331.0.
Saved chunk: 20230922T033754F759010-6d7XhPXK235TzlyCrKI0s8-7BI3NCnGd9y5ZU2usmwSRV-1024.npz
train_Episode has 500 steps and return 323.5.
Saved chunk: 20230922T033802F200043-65cxcVEu5AWHVXqQrFjX66-6u5P59kGQhUkZFLZz7kWF0-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 565470 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 331.04 / eval_episode/reward_rate 0.54 / episode/length 500 / episode/score 323.49 / episode/reward_rate 0.56 / train/action_mag 2.88 / train/action_max 2.86 / train/action_mean 0.08 / train/action_min -2.04 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.61 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -1.84 / train/adv_mag 0.49 / train/adv_max 0.34 / train/adv_mean 
1.1e-3 / train/adv_min -0.49 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 
/ train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 9794.86 / train/extr_critic_mag 245.81 / train/extr_critic_max 245.81 / train/extr_critic_mean 236.54 / train/extr_critic_min 211.52 / train/extr_critic_std 6.37 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.04 / train/extr_return_raw_max 247.04 / train/extr_return_raw_mean 236.57 / train/extr_return_raw_min 
210.42 / train/extr_return_raw_std 6.43 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.18 / train/image_loss_std 1.04 / train/model_loss_mean 3.73 /
train/model_loss_std 4.45 / train/model_opt_grad_norm 9.46 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.12 / train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 8.01 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.15 / train/policy_logprob_min -8.01 / 
train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.2e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.89 / train/post_ent_max 50.89 / 
train/post_ent_mean 42.05 / train/post_ent_min 20.8 / train/post_ent_std 4.74 / train/prior_ent_mag 72.09 / train/prior_ent_max 72.09 / train/prior_ent_mean 45.92 / train/prior_ent_min 30.11 / train/prior_ent_std 4.93 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.01
/ train/reward_avg 0.39 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.39 
/ train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.18 / report/cont_avg 1 / report/cont_loss_mean 6.4e-11 / report/cont_loss_std 8.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 6.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.96 / report/dyn_loss_std 6.16 / report/image_loss_mean 1.28 / report/image_loss_std 1.2 / report/model_loss_mean 3.86 / report/model_loss_std 4.58 / report/post_ent_mag 50.99
/ report/post_ent_max 50.99 / report/post_ent_mean 41.54 / report/post_ent_min 17.6 / report/post_ent_std 4.96 / report/prior_ent_mag 72.02 / report/prior_ent_max 72.02 / report/prior_ent_mean 45.53 / report/prior_ent_min 30.34 / report/prior_ent_std 4.98 / 
report/rep_loss_mean 3.96 / report/rep_loss_std 6.16 / report/reward_avg 0.38 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.38 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 4.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 7.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.24 / eval/dyn_loss_std 5.91 / eval/image_loss_mean 1.17 / eval/image_loss_std 1.26 / eval/model_loss_mean 3.99 / eval/model_loss_std 4.49 / eval/post_ent_mag 50.55 / 
eval/post_ent_max 50.55 / eval/post_ent_mean 42.38 / eval/post_ent_min 20.92 / eval/post_ent_std 3.97 / eval/prior_ent_mag 72.02 / eval/prior_ent_max 72.02 / eval/prior_ent_mean 46.56 / eval/prior_ent_min 35.3 / eval/prior_ent_std 3.82 / eval/rep_loss_mean 4.24 / 
eval/rep_loss_std 5.91 / eval/reward_avg 0.63 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / 
eval/reward_pred 0.63 / eval/reward_rate 0.52 / replay/size 2.8e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3786 / timer/env.step_total 19.66
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.91 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
5.5e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 18.02 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.3e-4 / 
timer/agent.train_count 1893 / timer/agent.train_total 240.94 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / 
timer/dataset_eval_max 3.9e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 283000 Counter(283000) 282937
eval_Episode has 500 steps and return 344.6.
train_Episode has 500 steps and return 285.1.
Starting evaluation at step 283500 Counter(283500) 283437
eval_Episode has 500 steps and return 312.2.
train_Episode has 500 steps and return 297.3.
Saved chunk: 20230922T033922F302938-6u5P59kGQhUkZFLZz7kWF0-3IoAIXASzdOoIBhqyqAldH-1024.npz
Starting evaluation at step 284000 Counter(284000) 283937
Saved chunk: 20230922T033913F316121-7BI3NCnGd9y5ZU2usmwSRV-0iSYO0FoqoWm6WQaeV8i9t-1024.npz
eval_Episode has 500 steps and return 340.9.
train_Episode has 500 steps and return 317.8.
Starting evaluation at step 284500 Counter(284500) 284437
eval_Episode has 500 steps and return 343.5.
train_Episode has 500 steps and return 294.3.
Saved chunk: 20230922T034043F865536-3IoAIXASzdOoIBhqyqAldH-2YSAyM7K8NdrUs8fCWTz15-1024.npz
Starting evaluation at step 285000 Counter(285000) 284937
Saved chunk: 20230922T034109F193808-0iSYO0FoqoWm6WQaeV8i9t-1WVFTXnYE0q7tnsPniiTQG-1024.npz
eval_Episode has 500 steps and return 341.2.
train_Episode has 500 steps and return 312.5.
Starting evaluation at step 285500 Counter(285500) 285437
eval_Episode has 500 steps and return 329.6.
train_Episode has 500 steps and return 319.2.
Saved chunk: 20230922T034204F394383-2YSAyM7K8NdrUs8fCWTz15-330o9nWTErtPMpAWk3Tu9M-1024.npz
Starting evaluation at step 286000 Counter(286000) 285937
Saved chunk: 20230922T034228F027036-1WVFTXnYE0q7tnsPniiTQG-25L1a2TrhlKgh9hxMwbN3A-1024.npz
eval_Episode has 500 steps and return 318.4.
train_Episode has 500 steps and return 343.0.
Starting evaluation at step 286500 Counter(286500) 286437
eval_Episode has 500 steps and return 324.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 573034 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 324.37 / eval_episode/reward_rate 0.51 / episode/length 500 / episode/score 342.96 / episode/reward_rate 0.57 / train/action_mag 2.92 / train/action_max 2.9 / train/action_mean 0.08 / train/action_min -2 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.64 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 7.61 / train/adv_mag 0.51 / train/adv_max 0.32 / train/adv_mean 1.8e-4 / train/adv_min 
-0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.91 / train/dyn_loss_std 6.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 9774.56 / train/extr_critic_mag 245.94 / train/extr_critic_max 245.94 / train/extr_critic_mean 236.56 / train/extr_critic_min 211.43 / train/extr_critic_std 6.43 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.07 / train/extr_return_raw_max 247.07 / train/extr_return_raw_mean 236.56 / train/extr_return_raw_min 
210.02 / train/extr_return_raw_std 6.5 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.18 / train/image_loss_std 1.04 / train/model_loss_mean 3.74 / 
train/model_loss_std 4.46 / train/model_opt_grad_norm 9.22 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.14 / train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 7.82 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.15 / train/policy_logprob_min -7.82 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.1e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.84 / train/post_ent_max 50.84 / train/post_ent_mean 42.02 / 
train/post_ent_min 20.57 / train/post_ent_std 4.77 / train/prior_ent_mag 72.05 / train/prior_ent_max 72.05 / train/prior_ent_mean 45.92 / train/prior_ent_min 29.94 / train/prior_ent_std 4.96 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.04 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.39 / train/reward_rate 0.37 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.22 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 5.86 / report/image_loss_mean 1.26 / report/image_loss_std 1.26 / report/model_loss_mean 3.69 / report/model_loss_std 4.56 / report/post_ent_mag 51.72 / report/post_ent_max 51.72 /
report/post_ent_mean 41.32 / report/post_ent_min 21.11 / report/post_ent_std 5.01 / report/prior_ent_mag 72.07 / report/prior_ent_max 72.07 / report/prior_ent_mean 45.01 / report/prior_ent_min 27.27 / report/prior_ent_std 5.27 / report/rep_loss_mean 3.75 / 
report/rep_loss_std 5.86 / report/reward_avg 0.35 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.35 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.01 / eval/dyn_loss_std 6.15 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.14 / eval/model_loss_mean 3.81 / eval/model_loss_std 4.59 / eval/post_ent_mag 49.76 / eval/post_ent_max 49.76 / eval/post_ent_mean 
42.89 / eval/post_ent_min 20.78 / eval/post_ent_std 3.61 / eval/prior_ent_mag 72.07 / eval/prior_ent_max 72.07 / eval/prior_ent_mean 46.63 / eval/prior_ent_min 38.02 / eval/prior_ent_std 3.87 / eval/rep_loss_mean 4.01 / eval/rep_loss_std 6.15 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.62 / eval/reward_rate 0.54 / 
replay/size 2.9e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3782 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.92 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.9e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 18.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.14 / 
timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241.04 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 320.2.
Saved chunk: 20230922T034324F607494-330o9nWTErtPMpAWk3Tu9M-6xFxfW5eMQX62KgD7hpXsX-1024.npz
Starting evaluation at step 287000 Counter(287000) 286937
Saved chunk: 20230922T034346F638281-25L1a2TrhlKgh9hxMwbN3A-08VyMPK0K5DgMi5MynWgQA-1024.npz
eval_Episode has 500 steps and return 321.4.
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 287500 Counter(287500) 287437
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 289.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T034506F371230-08VyMPK0K5DgMi5MynWgQA-0000000000000000000000-930.npz
Saved chunk: 20230922T034445F737993-6xFxfW5eMQX62KgD7hpXsX-0000000000000000000000-880.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T034445F737993-6xFxfW5eMQX62KgD7hpXsX-33jFpVIRY1vI3zbJjbSNJi-1024.npz
Starting evaluation at step 288000 Counter(288000) 287937
Saved chunk: 20230922T034506F371230-08VyMPK0K5DgMi5MynWgQA-4lXrNb1AVtmy71xbX2X4Bi-1024.npz
eval_Episode has 500 steps and return 344.3.
train_Episode has 500 steps and return 291.9.
Starting evaluation at step 288500 Counter(288500) 288437
eval_Episode has 500 steps and return 344.3.
train_Episode has 500 steps and return 301.2.
Saved chunk: 20230922T034606F751906-33jFpVIRY1vI3zbJjbSNJi-5G6GopLjsocHqArsuKMzDm-1024.npz
Starting evaluation at step 289000 Counter(289000) 288937
Saved chunk: 20230922T034625F762997-4lXrNb1AVtmy71xbX2X4Bi-3b8NJ8eFGlFgrlLYYnG0gF-1024.npz
eval_Episode has 500 steps and return 351.1.
train_Episode has 500 steps and return 283.5.
Starting evaluation at step 289500 Counter(289500) 289437
eval_Episode has 500 steps and return 346.5.
train_Episode has 500 steps and return 318.1.
Saved chunk: 20230922T034727F201718-5G6GopLjsocHqArsuKMzDm-24T0K1z2RyIgvnTqkEsO5I-1024.npz
Starting evaluation at step 290000 Counter(290000) 289937
Saved chunk: 20230922T034744F592940-3b8NJ8eFGlFgrlLYYnG0gF-3yk1JCTnjpuuB7MZ1RXFUW-1024.npz
eval_Episode has 500 steps and return 336.2.
train_Episode has 500 steps and return 306.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 580686 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 306.49 / episode/reward_rate 0.52 / eval_episode/length 500 / eval_episode/score 336.23 / eval_episode/reward_rate 0.55 / train/action_mag 2.92 / train/action_max 2.91 / train/action_mean 0.08 / train/action_min -2.02 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.7 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 13.35 / train/adv_mag 0.52 / train/adv_max 0.34 / train/adv_mean -4e-4 
/ train/adv_min -0.51 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 9999.01 / train/extr_critic_mag 245.88 / train/extr_critic_max 245.88 / train/extr_critic_mean 236.09 / train/extr_critic_min 211.24 / train/extr_critic_std 6.48 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 246.9 / train/extr_return_raw_max 246.9 / train/extr_return_raw_mean 236.08 / train/extr_return_raw_min 
209.98 / train/extr_return_raw_std 6.56 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.18 / train/image_loss_std 1.06 / train/model_loss_mean 3.73 /
train/model_loss_std 4.48 / train/model_opt_grad_norm 9.62 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.37 / train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.84 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.15 / train/policy_logprob_min -7.84 / 
train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.53 / train/policy_randomness_max 0.53 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.1e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.76 / train/post_ent_max 50.76 / 
train/post_ent_mean 41.95 / train/post_ent_min 20.31 / train/post_ent_std 4.74 / train/prior_ent_mag 72 / train/prior_ent_max 72 / train/prior_ent_mean 45.82 / train/prior_ent_min 30.16 / train/prior_ent_std 4.95 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.06 / 
train/reward_avg 0.39 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.39 / 
train/reward_rate 0.36 / train_stats/mean_log_entropy -3.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.6 / report/dyn_loss_std 5.24 / report/image_loss_mean 0.97 / report/image_loss_std 0.76 / report/model_loss_mean 3.41 / report/model_loss_std 3.8 / report/post_ent_mag 50.83 
/ report/post_ent_max 50.83 / report/post_ent_mean 43.03 / report/post_ent_min 23.92 / report/post_ent_std 3.66 / report/prior_ent_mag 72.07 / report/prior_ent_max 72.07 / report/prior_ent_mean 46.79 / report/prior_ent_min 32.04 / report/prior_ent_std 3.93 / 
report/rep_loss_mean 3.6 / report/rep_loss_std 5.24 / report/reward_avg 0.51 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.51 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.85 / eval/dyn_loss_std 5.5 / eval/image_loss_mean 1.11 / eval/image_loss_std 1.32 / eval/model_loss_mean 3.73 / eval/model_loss_std 4.32 / eval/post_ent_mag 49.15 / eval/post_ent_max
49.15 / eval/post_ent_mean 42.64 / eval/post_ent_min 21.32 / eval/post_ent_std 3.87 / eval/prior_ent_mag 72.07 / eval/prior_ent_max 72.07 / eval/prior_ent_mean 46.52 / eval/prior_ent_min 33.59 / eval/prior_ent_std 3.85 / eval/rep_loss_mean 3.85 / eval/rep_loss_std 5.5 /
eval/reward_avg 0.65 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.64 / 
eval/reward_rate 0.55 / replay/size 2.9e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3826 / timer/env.step_total 19.74 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 460.33 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.7e-4 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7333 / timer/agent.policy_total 17.39 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1913 / timer/agent.train_total 243.87 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac
1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 290500 Counter(290500) 290437
eval_Episode has 500 steps and return 334.8.
train_Episode has 500 steps and return 283.0.
Saved chunk: 20230922T034847F430038-24T0K1z2RyIgvnTqkEsO5I-3ZWqsfyj3UamEKLMO82uTJ-1024.npz
Starting evaluation at step 291000 Counter(291000) 290937
Saved chunk: 20230922T034903F239037-3yk1JCTnjpuuB7MZ1RXFUW-6CKhxNjMyaWVgcEowKg1mf-1024.npz
eval_Episode has 500 steps and return 370.8.
train_Episode has 500 steps and return 323.4.
Starting evaluation at step 291500 Counter(291500) 291437
eval_Episode has 500 steps and return 327.4.
train_Episode has 500 steps and return 305.3.
Saved chunk: 20230922T035008F786414-3ZWqsfyj3UamEKLMO82uTJ-0C5pJGJnuQxHrDgwsPVGMA-1024.npz
Starting evaluation at step 292000 Counter(292000) 291937
Saved chunk: 20230922T035023F153473-6CKhxNjMyaWVgcEowKg1mf-3aBwPHy5in9esRGCOllpFw-1024.npz
eval_Episode has 500 steps and return 312.9.
train_Episode has 500 steps and return 326.1.
Starting evaluation at step 292500 Counter(292500) 292437
eval_Episode has 500 steps and return 331.5.
train_Episode has 500 steps and return 290.9.
Saved chunk: 20230922T035129F468068-0C5pJGJnuQxHrDgwsPVGMA-6dzRbSvTVZht4mwJ9onKMs-1024.npz
Starting evaluation at step 293000 Counter(293000) 292937
Saved chunk: 20230922T035142F200846-3aBwPHy5in9esRGCOllpFw-0FcwnXEPoAiEY4Ml1SyjCj-1024.npz
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 318.8.
Starting evaluation at step 293500 Counter(293500) 293437
eval_Episode has 500 steps and return 300.9.
train_Episode has 500 steps and return 268.6.
Saved chunk: 20230922T035249F978019-6dzRbSvTVZht4mwJ9onKMs-5h1amUBpqRFzOPC3Snu55U-1024.npz
Starting evaluation at step 294000 Counter(294000) 293937
Saved chunk: 20230922T035301F142813-0FcwnXEPoAiEY4Ml1SyjCj-0Ei5Bk0E0aMMqRPWM1RXTL-1024.npz
eval_Episode has 500 steps and return 343.0.
train_Episode has 500 steps and return 297.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 588242 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 342.99 / eval_episode/reward_rate 0.58 / episode/length 500 / episode/score 297.14 / episode/reward_rate 0.51 / train/action_mag 2.91 / train/action_max 2.89 / train/action_mean 0.08 / train/action_min -1.99 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.69 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 5.73 / train/adv_mag 0.52 / train/adv_max 0.32 / train/adv_mean 3.8e-4
/ train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 5.97 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9893.05 / train/extr_critic_mag 245.98 / train/extr_critic_max 245.98 / train/extr_critic_mean 236.39 / train/extr_critic_min 212.08 / train/extr_critic_std 6.32 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.02 / train/extr_return_raw_max 247.02 / train/extr_return_raw_mean 236.39 / train/extr_return_raw_min 
210.65 / train/extr_return_raw_std 6.38 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.16 / train/image_loss_std 1.04 / train/model_loss_mean 3.69 / 
train/model_loss_std 4.42 / train/model_opt_grad_norm 9.72 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.15 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.65 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.65 / 
train/policy_logprob_std 1.51 / train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.83 / train/post_ent_max 50.83 / 
train/post_ent_mean 42.02 / train/post_ent_min 20.71 / train/post_ent_std 4.71 / train/prior_ent_mag 72.03 / train/prior_ent_max 72.03 / train/prior_ent_mean 45.86 / train/prior_ent_min 30.27 / train/prior_ent_std 4.94 / train/rep_loss_mean 3.85 / train/rep_loss_std 
5.97 / train/reward_avg 0.4 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 
0.4 / train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.24 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 5.67 / report/image_loss_mean 1.08 / report/image_loss_std 0.9 / report/model_loss_mean 3.58 / report/model_loss_std 4.08 / report/post_ent_mag 50.88
/ report/post_ent_max 50.88 / report/post_ent_mean 42.67 / report/post_ent_min 20.86 / report/post_ent_std 4.05 / report/prior_ent_mag 72.1 / report/prior_ent_max 72.1 / report/prior_ent_mean 46.44 / report/prior_ent_min 31.43 / report/prior_ent_std 4.28 / 
report/rep_loss_mean 3.81 / report/rep_loss_std 5.67 / report/reward_avg 0.46 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.9e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 0.45 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 7.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.95 / eval/dyn_loss_std 5.81 / eval/image_loss_mean 1.05 / eval/image_loss_std 1.01 / eval/model_loss_mean 3.72 / eval/model_loss_std 4.21 / eval/post_ent_mag 50.03 / 
eval/post_ent_max 50.03 / eval/post_ent_mean 42.66 / eval/post_ent_min 23.42 / eval/post_ent_std 3.78 / eval/prior_ent_mag 72.1 / eval/prior_ent_max 72.1 / eval/prior_ent_mean 46.55 / eval/prior_ent_min 37.55 / eval/prior_ent_std 3.82 / eval/rep_loss_mean 3.95 / 
eval/rep_loss_std 5.81 / eval/reward_avg 0.66 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / 
eval/reward_pred 0.66 / eval/reward_rate 0.55 / replay/size 2.9e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.9e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3778 / timer/env.step_total 19.52
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.58 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.15 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.8e-4 / 
timer/agent.train_count 1889 / timer/agent.train_total 240.83 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 294500 Counter(294500) 294437
eval_Episode has 500 steps and return 362.8.
train_Episode has 500 steps and return 327.4.
Saved chunk: 20230922T035410F194756-5h1amUBpqRFzOPC3Snu55U-1oXpZuQtn4dcy9964PY4jH-1024.npz
Starting evaluation at step 295000 Counter(295000) 294937
Saved chunk: 20230922T035419F751450-0Ei5Bk0E0aMMqRPWM1RXTL-3aJdbHqqJun3GVCbfwCJCV-1024.npz
eval_Episode has 500 steps and return 297.0.
train_Episode has 500 steps and return 307.4.
Starting evaluation at step 295500 Counter(295500) 295437
eval_Episode has 500 steps and return 311.8.
train_Episode has 500 steps and return 290.9.
Saved chunk: 20230922T035531F715068-1oXpZuQtn4dcy9964PY4jH-5CDwAXOGIOM4yixFZT99Mm-1024.npz
Starting evaluation at step 296000 Counter(296000) 295937
Saved chunk: 20230922T035539F801928-3aJdbHqqJun3GVCbfwCJCV-71JdGRNpkmiq4WAKgl7lrQ-1024.npz
eval_Episode has 500 steps and return 348.1.
train_Episode has 500 steps and return 294.2.
Starting evaluation at step 296500 Counter(296500) 296437
eval_Episode has 500 steps and return 335.7.
train_Episode has 500 steps and return 269.5.
Saved chunk: 20230922T035652F245804-5CDwAXOGIOM4yixFZT99Mm-0GGFtrjvOZ4eYjbBb6yBzC-1024.npz
Starting evaluation at step 297000 Counter(297000) 296937
Saved chunk: 20230922T035658F745723-71JdGRNpkmiq4WAKgl7lrQ-6ASJVCpJIptqJvtmEYwVbJ-1024.npz
eval_Episode has 500 steps and return 326.5.
train_Episode has 500 steps and return 325.9.
Starting evaluation at step 297500 Counter(297500) 297437
eval_Episode has 500 steps and return 320.9.
train_Episode has 500 steps and return 320.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 595906 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 320.86 / eval_episode/reward_rate 0.54 / episode/length 500 / episode/score 320.05 / episode/reward_rate 0.54 / train/action_mag 2.93 / train/action_max 2.86 / train/action_mean 0.08 / train/action_min -2.16 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.65 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -1.1 / train/adv_mag 0.51 / train/adv_max 0.33 / train/adv_mean 1.1e-3
/ train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9543.83 / train/extr_critic_mag 246.2 / train/extr_critic_max 246.2 / train/extr_critic_mean 236.96 / train/extr_critic_min 212.25 / train/extr_critic_std 6.34 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.59 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.46 / train/extr_return_raw_max 247.46 / train/extr_return_raw_mean 236.98 / train/extr_return_raw_min 
210.73 / train/extr_return_raw_std 6.42 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.17 / train/image_loss_std 1.05 / train/model_loss_mean 3.72 / 
train/model_loss_std 4.46 / train/model_opt_grad_norm 9.18 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.21 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 7.87 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.87 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.8 / train/post_ent_max 50.8 / train/post_ent_mean 42.01 / 
train/post_ent_min 20.54 / train/post_ent_std 4.72 / train/prior_ent_mag 72.03 / train/prior_ent_max 72.03 / train/prior_ent_mean 45.9 / train/prior_ent_min 30.24 / train/prior_ent_std 4.92 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.02 / train/reward_avg 0.4 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.4 / train/reward_rate 0.37 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.25 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.07 / report/dyn_loss_std 6.09 / report/image_loss_mean 1.22 / report/image_loss_std 1.16 / report/model_loss_mean 3.88 / report/model_loss_std 4.63 / report/post_ent_mag 50.23 / report/post_ent_max 50.23 /
report/post_ent_mean 42.14 / report/post_ent_min 20.1 / report/post_ent_std 4.36 / report/prior_ent_mag 71.79 / report/prior_ent_max 71.79 / report/prior_ent_mean 46.06 / report/prior_ent_min 33.05 / report/prior_ent_std 4.42 / report/rep_loss_mean 4.07 / 
report/rep_loss_std 6.09 / report/reward_avg 0.39 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.39 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.48 / eval/dyn_loss_std 6.23 / eval/image_loss_mean 1.26 / eval/image_loss_std 1.64 / eval/model_loss_mean 4.25 / eval/model_loss_std 4.86 / eval/post_ent_mag 50.06 / eval/post_ent_max 50.06 / eval/post_ent_mean 
42.08 / eval/post_ent_min 18.74 / eval/post_ent_std 4.39 / eval/prior_ent_mag 71.79 / eval/prior_ent_max 71.79 / eval/prior_ent_mean 46.38 / eval/prior_ent_min 33.98 / eval/prior_ent_std 3.99 / eval/rep_loss_mean 4.48 / eval/rep_loss_std 6.23 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.62 / eval/reward_rate 0.53 / 
replay/size 3e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.9e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3832 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.12 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7339 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1916 / timer/agent.train_total 244.15 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T035812F619756-0GGFtrjvOZ4eYjbBb6yBzC-0KIaZHGj9161zc9Z0tr2qc-1024.npz
Starting evaluation at step 298000 Counter(298000) 297937
Saved chunk: 20230922T035817F519878-6ASJVCpJIptqJvtmEYwVbJ-2ckrjg6i2TnCXMvpJLnAKy-1024.npz
eval_Episode has 500 steps and return 288.1.
train_Episode has 500 steps and return 314.8.
Starting evaluation at step 298500 Counter(298500) 298437
eval_Episode has 500 steps and return 317.6.
train_Episode has 500 steps and return 259.9.
Starting evaluation at step 299000 Counter(299000) 298937
Saved chunk: 20230922T035936F968961-2ckrjg6i2TnCXMvpJLnAKy-3463zwmytSd9zS4iC3rm7t-1024.npz
eval_Episode has 500 steps and return 331.4.
Saved chunk: 20230922T035933F566494-0KIaZHGj9161zc9Z0tr2qc-377EYb1gDrHgUaxJRNmYmA-1024.npz
train_Episode has 500 steps and return 272.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T040056F041004-3463zwmytSd9zS4iC3rm7t-0000000000000000000000-165.npz
Saved chunk: 20230922T040057F812322-377EYb1gDrHgUaxJRNmYmA-0000000000000000000000-92.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 299500 Counter(299500) 299437
eval_Episode has 500 steps and return 319.0.
train_Episode has 500 steps and return 301.6.
Starting evaluation at step 300000 Counter(300000) 299937
Saved chunk: 20230922T040056F041004-3463zwmytSd9zS4iC3rm7t-0hDiAuqEUHBRXHwJHscXyS-1024.npz
eval_Episode has 500 steps and return 346.9.
Saved chunk: 20230922T040057F812322-377EYb1gDrHgUaxJRNmYmA-327dbi8gH0HLW0iDA8heUg-1024.npz
train_Episode has 500 steps and return 290.5.
Starting evaluation at step 300500 Counter(300500) 300437
eval_Episode has 500 steps and return 306.5.
train_Episode has 500 steps and return 313.6.
Starting evaluation at step 301000 Counter(301000) 300937
Saved chunk: 20230922T040215F279905-0hDiAuqEUHBRXHwJHscXyS-2WhJIIL2Kl1rJ5w2nZicsz-1024.npz
eval_Episode has 500 steps and return 357.5.
Saved chunk: 20230922T040218F604207-327dbi8gH0HLW0iDA8heUg-6fH4VjR9ZgM9zY3xF93xom-1024.npz
train_Episode has 500 steps and return 307.5.
Starting evaluation at step 301500 Counter(301500) 301437
eval_Episode has 500 steps and return 330.1.
train_Episode has 500 steps and return 314.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 603466 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 330.06 / eval_episode/reward_rate 0.55 / episode/length 500 / episode/score 314.53 / episode/reward_rate 0.53 / train/action_mag 2.91 / train/action_max 2.84 / train/action_mean 0.08 / train/action_min -2.13 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.73 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 9.58 / train/adv_mag 0.51 / train/adv_max 0.32 / train/adv_mean 
-1.4e-5 / train/adv_min -0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.88 / train/dyn_loss_std 5.99 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 246 / train/extr_critic_max 246 / train/extr_critic_mean 236.25 / train/extr_critic_min 212.87 / train/extr_critic_std 6.24 / train/extr_return_normed_mag 1.12 
/ train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 246.9 / train/extr_return_raw_max 246.9 / train/extr_return_raw_mean 
236.25 / train/extr_return_raw_min 211.21 / train/extr_return_raw_std 6.31 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.16 / train/image_loss_std 
1.05 / train/model_loss_mean 3.71 / train/model_loss_std 4.44 / train/model_opt_grad_norm 9.08 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / 
train/policy_entropy_mag 3.54 / train/policy_entropy_max 1.52 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.85 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / 
train/policy_logprob_min -7.85 / train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.3e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.79 / 
train/post_ent_max 50.79 / train/post_ent_mean 42.06 / train/post_ent_min 20.75 / train/post_ent_std 4.61 / train/prior_ent_mag 71.95 / train/prior_ent_max 71.95 / train/prior_ent_mean 45.91 / train/prior_ent_min 30.32 / train/prior_ent_std 4.84 / train/rep_loss_mean 
3.88 / train/rep_loss_std 5.99 / train/reward_avg 0.4 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 
0.57 / train/reward_pred 0.4 / train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.26 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 8.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.61 / report/dyn_loss_std 5.37 / report/image_loss_mean 1.02 / report/image_loss_std 0.84 / report/model_loss_mean 3.44 / report/model_loss_std 3.91 / 
report/post_ent_mag 50.81 / report/post_ent_max 50.81 / report/post_ent_mean 42.82 / report/post_ent_min 21.28 / report/post_ent_std 3.9 / report/prior_ent_mag 71.99 / report/prior_ent_max 71.99 / report/prior_ent_mean 46.47 / report/prior_ent_min 33.88 / 
report/prior_ent_std 4.07 / report/rep_loss_mean 3.61 / report/rep_loss_std 5.37 / report/reward_avg 0.55 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 0.55 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.04 / eval/dyn_loss_std 7.1 / eval/image_loss_mean 1.63 / eval/image_loss_std 2.35 / eval/model_loss_mean 4.93 / eval/model_loss_std 6 / eval/post_ent_mag 50.84 
/ eval/post_ent_max 50.84 / eval/post_ent_mean 41.77 / eval/post_ent_min 19.26 / eval/post_ent_std 4.89 / eval/prior_ent_mag 71.99 / eval/prior_ent_max 71.99 / eval/prior_ent_mean 46.31 / eval/prior_ent_min 34.74 / eval/prior_ent_std 4.2 / eval/rep_loss_mean 5.04 / 
eval/rep_loss_std 7.1 / eval/reward_avg 0.56 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / 
eval/reward_pred 0.56 / eval/reward_rate 0.48 / replay/size 3e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 
4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.9e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3780 / timer/env.step_total 19.59 / 
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.72 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
6e-4 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7788 / timer/agent.policy_total 18.11
/ timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1890 / timer/agent.train_total 240.9 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / 
timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 302000 Counter(302000) 301937
Saved chunk: 20230922T040333F958966-2WhJIIL2Kl1rJ5w2nZicsz-3CnWev0gfp8m5MF2w6lqOr-1024.npz
eval_Episode has 500 steps and return 339.7.
Saved chunk: 20230922T040338F833019-6fH4VjR9ZgM9zY3xF93xom-4QmpQXHgUpRlniCIGEEciR-1024.npz
train_Episode has 500 steps and return 323.7.
Starting evaluation at step 302500 Counter(302500) 302437
eval_Episode has 500 steps and return 325.8.
train_Episode has 500 steps and return 304.3.
Starting evaluation at step 303000 Counter(303000) 302937
eval_Episode has 500 steps and return 341.5.
Saved chunk: 20230922T040453F534436-3CnWev0gfp8m5MF2w6lqOr-1jt6jECl9ADYL9F8XLgcQg-1024.npz
train_Episode has 500 steps and return 314.8.
Saved chunk: 20230922T040500F020428-4QmpQXHgUpRlniCIGEEciR-5heMu4nkyTCIF9wLZ6gDjd-1024.npz
Starting evaluation at step 303500 Counter(303500) 303437
eval_Episode has 500 steps and return 344.7.
train_Episode has 500 steps and return 305.8.
Starting evaluation at step 304000 Counter(304000) 303937
eval_Episode has 500 steps and return 331.4.
Saved chunk: 20230922T040612F534052-1jt6jECl9ADYL9F8XLgcQg-5Sb7P0FnAFAApB5iwnDriY-1024.npz
train_Episode has 500 steps and return 306.2.
Saved chunk: 20230922T040620F525813-5heMu4nkyTCIF9wLZ6gDjd-7hNPXrtgOPvXLJikafUORI-1024.npz
Starting evaluation at step 304500 Counter(304500) 304437
eval_Episode has 500 steps and return 316.1.
train_Episode has 500 steps and return 318.5.
Starting evaluation at step 305000 Counter(305000) 304937
eval_Episode has 500 steps and return 334.8.
Saved chunk: 20230922T040731F260896-5Sb7P0FnAFAApB5iwnDriY-0yQ1xfkK8pN8q0X5rnP7K0-1024.npz
train_Episode has 500 steps and return 296.3.
Saved chunk: 20230922T040740F835246-7hNPXrtgOPvXLJikafUORI-0CFSnSA3Xrp1a6XvX4P08M-1024.npz
Starting evaluation at step 305500 Counter(305500) 305437
eval_Episode has 500 steps and return 321.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 611034 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 321.87 / eval_episode/reward_rate 0.52 / episode/length 500 / episode/score 296.26 / episode/reward_rate 0.5 / train/action_mag 2.97 / train/action_max 2.92 / train/action_mean 0.08 / train/action_min -2.18 / train/action_std
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.73 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 11.22 / train/adv_mag 0.5 / train/adv_max 0.32 / train/adv_mean -1.8e-4 / train/adv_min
-0.5 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 5.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9701.65 / train/extr_critic_mag 246.26 / train/extr_critic_max 246.26 / train/extr_critic_mean 236.83 / train/extr_critic_min 213.65 / train/extr_critic_std 6.08 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.32 / train/extr_return_raw_max 247.32 / train/extr_return_raw_mean 236.82 / train/extr_return_raw_min 
212.27 / train/extr_return_raw_std 6.15 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.14 / train/image_loss_std 1.03 / train/model_loss_mean 3.67 / 
train/model_loss_std 4.41 / train/model_opt_grad_norm 9.41 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.5 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.87 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.86 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.9e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.72 / train/post_ent_max 50.72 / train/post_ent_mean 42.13 / 
train/post_ent_min 20.75 / train/post_ent_std 4.55 / train/prior_ent_mag 71.9 / train/prior_ent_max 71.9 / train/prior_ent_mean 45.97 / train/prior_ent_min 30.79 / train/prior_ent_std 4.76 / train/rep_loss_mean 3.85 / train/rep_loss_std 5.96 / train/reward_avg 0.41 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.41 / train/reward_rate 0.38 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.24 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.03 / report/dyn_loss_std 6.19 / report/image_loss_mean 1.15 / report/image_loss_std 1.02 / report/model_loss_mean 3.83 / report/model_loss_std 4.52 / report/post_ent_mag 50.47 / report/post_ent_max 50.47 /
report/post_ent_mean 41.97 / report/post_ent_min 20.61 / report/post_ent_std 4.56 / report/prior_ent_mag 71.95 / report/prior_ent_max 71.95 / report/prior_ent_mean 45.97 / report/prior_ent_min 28.82 / report/prior_ent_std 4.97 / report/rep_loss_mean 4.03 / 
report/rep_loss_std 6.19 / report/reward_avg 0.52 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.52 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.99 / eval/dyn_loss_std 6.84 / eval/image_loss_mean 1.46 / eval/image_loss_std 2.12 / eval/model_loss_mean 4.72 / eval/model_loss_std 5.74 / eval/post_ent_mag 48.95 / eval/post_ent_max 48.95 / eval/post_ent_mean 
41.69 / eval/post_ent_min 16.6 / eval/post_ent_std 4.41 / eval/prior_ent_mag 71.95 / eval/prior_ent_max 71.95 / eval/prior_ent_mean 46.27 / eval/prior_ent_min 33.36 / eval/prior_ent_std 3.96 / eval/rep_loss_mean 4.99 / eval/rep_loss_std 6.84 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.31 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.49 / eval/reward_pred 0.63 / eval/reward_rate 0.52 / 
replay/size 3.1e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3784 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.64 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7792 / timer/agent.policy_total 17.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1892 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1892 / timer/agent.train_total 241.05 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 302.7.
Starting evaluation at step 306000 Counter(306000) 305937
eval_Episode has 500 steps and return 293.0.
Saved chunk: 20230922T040849F983695-0yQ1xfkK8pN8q0X5rnP7K0-5KtGaiSE3wYyGZ1rkfccBa-1024.npz
train_Episode has 500 steps and return 248.4.
Saved chunk: 20230922T040901F072447-0CFSnSA3Xrp1a6XvX4P08M-3KjOSz6tYIoLwSCydk1q2j-1024.npz
Starting evaluation at step 306500 Counter(306500) 306437
eval_Episode has 500 steps and return 344.1.
train_Episode has 500 steps and return 276.0.
Starting evaluation at step 307000 Counter(307000) 306937
eval_Episode has 500 steps and return 337.0.
train_Episode has 500 steps and return 332.5.
Saved chunk: 20230922T041022F503397-3KjOSz6tYIoLwSCydk1q2j-6pYMGnlL2NdRLA4eerv8cm-1024.npz
Starting evaluation at step 307500 Counter(307500) 307437
Saved chunk: 20230922T041009F696975-5KtGaiSE3wYyGZ1rkfccBa-4SRB3qYwySX8kXFafKTACF-1024.npz
eval_Episode has 500 steps and return 311.5.
train_Episode has 500 steps and return 315.8.
Starting evaluation at step 308000 Counter(308000) 307937
eval_Episode has 500 steps and return 368.0.
train_Episode has 500 steps and return 314.5.
Saved chunk: 20230922T041143F166727-6pYMGnlL2NdRLA4eerv8cm-3j388gyEk4nntld0ial76I-1024.npz
Starting evaluation at step 308500 Counter(308500) 308437
Saved chunk: 20230922T041204F799300-4SRB3qYwySX8kXFafKTACF-4l5meHtoQNJIiBtB3a0tTY-1024.npz
eval_Episode has 500 steps and return 321.1.
train_Episode has 500 steps and return 303.3.
Starting evaluation at step 309000 Counter(309000) 308937
eval_Episode has 500 steps and return 330.4.
train_Episode has 500 steps and return 325.3.
Saved chunk: 20230922T041303F561556-3j388gyEk4nntld0ial76I-1quOFWdqWGb3LwG12QZwrX-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 618686 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 325.32 / episode/reward_rate 0.54 / eval_episode/length 500 / eval_episode/score 330.38 / eval_episode/reward_rate 0.57 / train/action_mag 2.92 / train/action_max 2.89 / train/action_mean 0.08 / train/action_min -2.22 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.69 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 0.93 / train/adv_mag 0.53 / train/adv_max 0.33 / train/adv_mean 8.7e-4
/ train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9684.67 / train/extr_critic_mag 246.29 / train/extr_critic_max 246.29 / train/extr_critic_mean 236.73 / train/extr_critic_min 212.72 / train/extr_critic_std 6.25 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.28 / train/extr_return_raw_max 247.28 / train/extr_return_raw_mean 236.75 / train/extr_return_raw_min 
211.4 / train/extr_return_raw_std 6.31 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 1.15 / train/image_loss_std 1.05 / train/model_loss_mean 3.7 / 
train/model_loss_std 4.45 / train/model_opt_grad_norm 9.74 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9348.96 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.47 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.55 / train/policy_logprob_mag 7.75 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.75 / 
train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.82 / train/post_ent_max 50.82 / 
train/post_ent_mean 41.97 / train/post_ent_min 20.74 / train/post_ent_std 4.61 / train/prior_ent_mag 71.9 / train/prior_ent_max 71.9 / train/prior_ent_mean 45.82 / train/prior_ent_min 30.39 / train/prior_ent_std 4.88 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.01 
/ train/reward_avg 0.41 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.41 
/ train/reward_rate 0.38 / train_stats/mean_log_entropy -3.26 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 8.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.93 / report/dyn_loss_std 6.05 / report/image_loss_mean 1.13 / report/image_loss_std 0.97 / report/model_loss_mean 3.7 / report/model_loss_std 4.45 / report/post_ent_mag 50.57
/ report/post_ent_max 50.57 / report/post_ent_mean 42.17 / report/post_ent_min 20.65 / report/post_ent_std 4.17 / report/prior_ent_mag 71.88 / report/prior_ent_max 71.88 / report/prior_ent_mean 46.14 / report/prior_ent_min 31.37 / report/prior_ent_std 4.48 / 
report/rep_loss_mean 3.93 / report/rep_loss_std 6.05 / report/reward_avg 0.43 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.42 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 7.3e-11 / eval/cont_loss_std 2.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 7.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.24 / eval/dyn_loss_std 5.76 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.07 / eval/model_loss_mean 3.93 / eval/model_loss_std 4.33 / eval/post_ent_mag 50.62 / 
eval/post_ent_max 50.62 / eval/post_ent_mean 42.5 / eval/post_ent_min 20.55 / eval/post_ent_std 3.94 / eval/prior_ent_mag 71.88 / eval/prior_ent_max 71.88 / eval/prior_ent_mean 46.48 / eval/prior_ent_min 38.85 / eval/prior_ent_std 3.8 / eval/rep_loss_mean 4.24 / 
eval/rep_loss_std 5.76 / eval/reward_avg 0.63 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / 
eval/reward_pred 0.62 / eval/reward_rate 0.51 / replay/size 3.1e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3826 / timer/env.step_total 19.84
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.78 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.05 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.5e-3 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 
/ timer/agent.train_count 1913 / timer/agent.train_total 244.03 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / 
timer/dataset_eval_max 4.5e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 309500 Counter(309500) 309437
Saved chunk: 20230922T041323F517905-4l5meHtoQNJIiBtB3a0tTY-1eG8DzRzybnNqDzKlsdeEY-1024.npz
eval_Episode has 500 steps and return 344.0.
train_Episode has 500 steps and return 258.2.
Starting evaluation at step 310000 Counter(310000) 309937
eval_Episode has 500 steps and return 357.3.
train_Episode has 500 steps and return 314.8.
Saved chunk: 20230922T041423F878673-1quOFWdqWGb3LwG12QZwrX-6zyZFLjBPDYVI609Qo0KTv-1024.npz
Starting evaluation at step 310500 Counter(310500) 310437
Saved chunk: 20230922T041443F219154-1eG8DzRzybnNqDzKlsdeEY-61nS1BQvQe9Xvnj2LjzcBq-1024.npz
eval_Episode has 500 steps and return 334.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T041545F652571-6zyZFLjBPDYVI609Qo0KTv-0000000000000000000000-328.npz
Saved chunk: 20230922T041602F527708-61nS1BQvQe9Xvnj2LjzcBq-0000000000000000000000-424.npz
train_Episode has 500 steps and return 328.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 311000 Counter(311000) 310937
eval_Episode has 500 steps and return 346.8.
train_Episode has 500 steps and return 283.7.
Saved chunk: 20230922T041545F652571-6zyZFLjBPDYVI609Qo0KTv-2zqhHgFjYqExQKHAQTmJD0-1024.npz
Starting evaluation at step 311500 Counter(311500) 311437
Saved chunk: 20230922T041602F527708-61nS1BQvQe9Xvnj2LjzcBq-6JFzAbqI5ccKOnWQMVPRXB-1024.npz
eval_Episode has 500 steps and return 343.2.
train_Episode has 500 steps and return 232.3.
Starting evaluation at step 312000 Counter(312000) 311937
eval_Episode has 500 steps and return 349.2.
train_Episode has 500 steps and return 290.5.
Saved chunk: 20230922T041706F405752-2zqhHgFjYqExQKHAQTmJD0-70r1mhoiilPfHIie347OQe-1024.npz
Starting evaluation at step 312500 Counter(312500) 312437
Saved chunk: 20230922T041721F742033-6JFzAbqI5ccKOnWQMVPRXB-1wTIE9g6NZhE1btoU1n7sO-1024.npz
eval_Episode has 500 steps and return 322.8.
train_Episode has 500 steps and return 307.0.
Starting evaluation at step 313000 Counter(313000) 312937
eval_Episode has 500 steps and return 316.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 626238 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 316.49 / eval_episode/reward_rate 0.54 / episode/length 500 / episode/score 306.98 / episode/reward_rate 0.52 / train/action_mag 2.99 / train/action_max 2.97 / train/action_mean 0.08 / train/action_min -2.17 / 
train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.65 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -0.26 / train/adv_mag 0.52 / train/adv_max 0.32 / train/adv_mean 
9.9e-4 / train/adv_min -0.51 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.89 / train/dyn_loss_std 5.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 9288.77 / train/extr_critic_mag 246.91 / train/extr_critic_max 246.91 / train/extr_critic_mean 237.28 / train/extr_critic_min 212.99 / train/extr_critic_std 6.34 / 
train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 247.9 / train/extr_return_raw_max 
247.9 / train/extr_return_raw_mean 237.3 / train/extr_return_raw_min 211.7 / train/extr_return_raw_std 6.4 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / 
train/image_loss_mean 1.16 / train/image_loss_std 1.06 / train/model_loss_mean 3.7 / train/model_loss_std 4.44 / train/model_opt_grad_norm 8.96 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 7460.32 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.33 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 8.01 / train/policy_logprob_max 
5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -8.01 / train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.53 / train/policy_randomness_max 0.53 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.8e-5 / 
train/policy_randomness_std 0.06 / train/post_ent_mag 50.67 / train/post_ent_max 50.67 / train/post_ent_mean 41.92 / train/post_ent_min 20.72 / train/post_ent_std 4.6 / train/prior_ent_mag 71.93 / train/prior_ent_max 71.93 / train/prior_ent_mean 45.77 / 
train/prior_ent_min 30.52 / train/prior_ent_std 4.86 / train/rep_loss_mean 3.89 / train/rep_loss_std 5.98 / train/reward_avg 0.4 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / 
train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.4 / train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.25 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / 
report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 5.74 / report/image_loss_mean 1.11 / 
report/image_loss_std 1.03 / report/model_loss_mean 3.57 / report/model_loss_std 4.23 / report/post_ent_mag 50.37 / report/post_ent_max 50.37 / report/post_ent_mean 41.78 / report/post_ent_min 22.51 / report/post_ent_std 4.32 / report/prior_ent_mag 72.05 / 
report/prior_ent_max 72.05 / report/prior_ent_mean 45.51 / report/prior_ent_min 32.7 / report/prior_ent_std 4.88 / report/rep_loss_mean 3.76 / report/rep_loss_std 5.74 / report/reward_avg 0.37 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / 
report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.55 / report/reward_pred 0.37 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 
4.2e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.05 / eval/dyn_loss_std 6.83 / eval/image_loss_mean 1.53 / 
eval/image_loss_std 2.24 / eval/model_loss_mean 4.83 / eval/model_loss_std 5.87 / eval/post_ent_mag 49.55 / eval/post_ent_max 49.55 / eval/post_ent_mean 41.63 / eval/post_ent_min 20.84 / eval/post_ent_std 4.43 / eval/prior_ent_mag 72.05 / eval/prior_ent_max 72.05 / 
eval/prior_ent_mean 46.28 / eval/prior_ent_min 30.8 / eval/prior_ent_std 4.3 / eval/rep_loss_mean 5.05 / eval/rep_loss_std 6.83 / eval/reward_avg 0.59 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.58 / eval/reward_rate 0.48 / replay/size 3.1e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1
/ replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3776 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 458.91 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / 
timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7784 / timer/agent.policy_total 18.27 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 
0.15 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1888 / timer/agent.train_total 240.72 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.16

train_Episode has 500 steps and return 311.7.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T041826F772012-70r1mhoiilPfHIie347OQe-21o5klhxcm3QODYCbTT91A-1024.npz
Starting evaluation at step 313500 Counter(313500) 313437
Saved chunk: 20230922T041840F419523-1wTIE9g6NZhE1btoU1n7sO-3sjAF7s0dxqGIx6rpEIbiH-1024.npz
eval_Episode has 500 steps and return 341.8.
train_Episode has 500 steps and return 279.7.
Starting evaluation at step 314000 Counter(314000) 313937
eval_Episode has 500 steps and return 326.3.
train_Episode has 500 steps and return 332.4.
Saved chunk: 20230922T041947F808640-21o5klhxcm3QODYCbTT91A-73WiOjWOfEQr2zcPW1Qa1n-1024.npz
Starting evaluation at step 314500 Counter(314500) 314437
Saved chunk: 20230922T042000F043680-3sjAF7s0dxqGIx6rpEIbiH-6NvekOROH0xXW6Gzi3rkDW-1024.npz
eval_Episode has 500 steps and return 336.6.
train_Episode has 500 steps and return 317.8.
Starting evaluation at step 315000 Counter(315000) 314937
eval_Episode has 500 steps and return 361.6.
train_Episode has 500 steps and return 331.9.
Saved chunk: 20230922T042108F472730-73WiOjWOfEQr2zcPW1Qa1n-0qe8hEb1x8gV9qiKUJm2X2-1024.npz
Starting evaluation at step 315500 Counter(315500) 315437
Saved chunk: 20230922T042119F124192-6NvekOROH0xXW6Gzi3rkDW-6Hx4LAdXFvzxrMt31bImrH-1024.npz
eval_Episode has 500 steps and return 339.4.
train_Episode has 500 steps and return 330.1.
Starting evaluation at step 316000 Counter(316000) 315937
eval_Episode has 500 steps and return 333.7.
train_Episode has 500 steps and return 290.1.
Saved chunk: 20230922T042229F027063-0qe8hEb1x8gV9qiKUJm2X2-6fi5f0rDzdrOGXDh0yuQyD-1024.npz
Starting evaluation at step 316500 Counter(316500) 316437
Saved chunk: 20230922T042238F079566-6Hx4LAdXFvzxrMt31bImrH-0XTIP2Zy516wL6YweMxQO1-1024.npz
eval_Episode has 500 steps and return 344.5.
train_Episode has 500 steps and return 270.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 633894 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 270.75 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 344.54 / eval_episode/reward_rate 0.56 / train_stats/mean_log_entropy -3.24 / train/action_mag 2.95 / train/action_max 2.93 / train/action_mean 0.08 / 
train/action_min -2.19 / train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.68 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 1.35 / train/adv_mag 0.53 / train/adv_max 
0.32 / train/adv_mean 8.2e-4 / train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.87 / train/dyn_loss_std 5.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 9027.2 / train/extr_critic_mag 247.51 / train/extr_critic_max 247.51 / train/extr_critic_mean 237.87 / train/extr_critic_min 213.76 / train/extr_critic_std 6.02 / 
train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.61 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 248.13 / train/extr_return_raw_max 
248.13 / train/extr_return_raw_mean 237.89 / train/extr_return_raw_min 212.72 / train/extr_return_raw_std 6.09 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / 
train/image_loss_mean 1.14 / train/image_loss_std 1.04 / train/model_loss_mean 3.68 / train/model_loss_std 4.42 / train/model_opt_grad_norm 9.55 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 7931.94 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.24 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 7.95 / train/policy_logprob_max 
5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.95 / train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.9e-5 / 
train/policy_randomness_std 0.06 / train/post_ent_mag 50.65 / train/post_ent_max 50.65 / train/post_ent_mean 41.98 / train/post_ent_min 20.66 / train/post_ent_std 4.54 / train/prior_ent_mag 71.86 / train/prior_ent_max 71.86 / train/prior_ent_mean 45.83 / 
train/prior_ent_min 30.38 / train/prior_ent_std 4.8 / train/rep_loss_mean 3.87 / train/rep_loss_std 5.96 / train/reward_avg 0.41 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / 
train/reward_neg_loss 6.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.41 / train/reward_rate 0.38 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc 
nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.77 / report/dyn_loss_std 5.73 / report/image_loss_mean 1.14 / report/image_loss_std 1.11 / report/model_loss_mean 
3.67 / report/model_loss_std 4.32 / report/post_ent_mag 51.41 / report/post_ent_max 51.41 / report/post_ent_mean 42.45 / report/post_ent_min 20.84 / report/post_ent_std 4.11 / report/prior_ent_mag 71.95 / report/prior_ent_max 71.95 / report/prior_ent_mean 46.26 / 
report/prior_ent_min 32.53 / report/prior_ent_std 4.34 / report/rep_loss_mean 3.77 / report/rep_loss_std 5.73 / report/reward_avg 0.46 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 2 / 
report/reward_neg_acc 0.99 / report/reward_neg_loss 8.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.46 / report/reward_rate 0.45 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.43 / eval/dyn_loss_std 6.13 / eval/image_loss_mean 1.3 / eval/image_loss_std 1.63 / eval/model_loss_mean 4.23 / eval/model_loss_std 
4.97 / eval/post_ent_mag 49.68 / eval/post_ent_max 49.68 / eval/post_ent_mean 42.18 / eval/post_ent_min 19.95 / eval/post_ent_std 3.93 / eval/prior_ent_mag 71.95 / eval/prior_ent_max 71.95 / eval/prior_ent_mean 46.3 / eval/prior_ent_min 34.26 / eval/prior_ent_std 4.11 /
eval/rep_loss_mean 4.43 / eval/rep_loss_std 6.13 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.6e-3 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.55 / eval/reward_pred 0.62 / eval/reward_rate 0.5 / replay/size 3.2e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3828 / 
timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 462.82 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 
0.02 / timer/replay._sample_min 7.6e-4 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7335 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 5.8e-3 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.14 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / 
timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 317000 Counter(317000) 316937
eval_Episode has 500 steps and return 345.5.
train_Episode has 500 steps and return 307.5.
Saved chunk: 20230922T042349F366331-6fi5f0rDzdrOGXDh0yuQyD-2ZPCtsWDYQCmpD9f26QEi8-1024.npz
Starting evaluation at step 317500 Counter(317500) 317437
Saved chunk: 20230922T042356F860503-0XTIP2Zy516wL6YweMxQO1-2J9btKkag8aJYsBedUtgIb-1024.npz
eval_Episode has 500 steps and return 314.3.
train_Episode has 500 steps and return 289.1.
Starting evaluation at step 318000 Counter(318000) 317937
eval_Episode has 500 steps and return 325.6.
train_Episode has 500 steps and return 323.6.
Saved chunk: 20230922T042510F802419-2ZPCtsWDYQCmpD9f26QEi8-56QrQAiAx3pWN3j8Ze8bQV-1024.npz
Starting evaluation at step 318500 Counter(318500) 318437
Saved chunk: 20230922T042516F750086-2J9btKkag8aJYsBedUtgIb-54GxcdgnlQLoue3BPrnWvr-1024.npz
eval_Episode has 500 steps and return 336.8.
train_Episode has 500 steps and return 296.2.
Starting evaluation at step 319000 Counter(319000) 318937
eval_Episode has 500 steps and return 366.4.
train_Episode has 500 steps and return 317.9.
Saved chunk: 20230922T042631F469612-56QrQAiAx3pWN3j8Ze8bQV-3ynVjfunkKxKlA40o9urNX-1024.npz
Starting evaluation at step 319500 Counter(319500) 319437
Saved chunk: 20230922T042635F740873-54GxcdgnlQLoue3BPrnWvr-1EvnciO3xOX4hxn2T8js7V-1024.npz
eval_Episode has 500 steps and return 367.5.
train_Episode has 500 steps and return 331.6.
Starting evaluation at step 320000 Counter(320000) 319937
eval_Episode has 500 steps and return 335.2.
train_Episode has 500 steps and return 318.2.
Starting evaluation at step 320500 Counter(320500) 320437
Saved chunk: 20230922T042754F491579-1EvnciO3xOX4hxn2T8js7V-5YaskiWJlgE77Mbzw4G1Vm-1024.npz
eval_Episode has 500 steps and return 363.5.
Saved chunk: 20230922T042751F759316-3ynVjfunkKxKlA40o9urNX-116YhaAA7R50Bp1jEdLIl0-1024.npz
train_Episode has 500 steps and return 332.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 641458 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 363.52 / eval_episode/reward_rate 0.58 / episode/length 500 / episode/score 332.78 / episode/reward_rate 0.57 / train/action_mag 2.9 / train/action_max 2.89 / train/action_mean 0.07 / train/action_min -2.18 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.62 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -11.42 / train/adv_mag 0.53 / train/adv_max 0.34 / train/adv_mean 2.1e-3 / 
train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 8643.32 / train/extr_critic_mag 248.52 / train/extr_critic_max 248.52 / train/extr_critic_mean 238.27 / train/extr_critic_min 213.92 / train/extr_critic_std 6.21 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 248.65 / train/extr_return_raw_max 248.65 / train/extr_return_raw_mean 238.31 / train/extr_return_raw_min 
212.69 / train/extr_return_raw_std 6.28 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 1.14 / train/image_loss_std 1.04 / train/model_loss_mean 3.69 /
train/model_loss_std 4.44 / train/model_opt_grad_norm 9.44 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.09 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.89 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.89 / 
train/policy_logprob_std 1.51 / train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.7e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.59 / train/post_ent_max 50.59 / 
train/post_ent_mean 41.95 / train/post_ent_min 20.8 / train/post_ent_std 4.5 / train/prior_ent_mag 71.84 / train/prior_ent_max 71.84 / train/prior_ent_mean 45.81 / train/prior_ent_min 30.95 / train/prior_ent_std 4.76 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.01 
/ train/reward_avg 0.41 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.41 
/ train/reward_rate 0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.24 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 5.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 5.64 / report/image_loss_mean 1.12 / report/image_loss_std 0.93 / report/model_loss_mean 3.51 / report/model_loss_std 4.12 / report/post_ent_mag 
52.12 / report/post_ent_max 52.12 / report/post_ent_mean 42.54 / report/post_ent_min 23.27 / report/post_ent_std 3.89 / report/prior_ent_mag 71.83 / report/prior_ent_max 71.83 / report/prior_ent_mean 46.16 / report/prior_ent_min 30.8 / report/prior_ent_std 4.16 / 
report/rep_loss_mean 3.66 / report/rep_loss_std 5.64 / report/reward_avg 0.42 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.52 / report/reward_pred 0.42 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.86 / eval/dyn_loss_std 7.14 / eval/image_loss_mean 1.46 / eval/image_loss_std 2.23 / eval/model_loss_mean 4.67 / eval/model_loss_std 6.06 / eval/post_ent_mag 49.7 / eval/post_ent_max
49.7 / eval/post_ent_mean 41.85 / eval/post_ent_min 18.43 / eval/post_ent_std 4.38 / eval/prior_ent_mag 71.83 / eval/prior_ent_max 71.83 / eval/prior_ent_mean 46.27 / eval/prior_ent_min 33.38 / eval/prior_ent_std 4.08 / eval/rep_loss_mean 4.86 / eval/rep_loss_std 7.14 /
eval/reward_avg 0.6 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.6 / 
eval/reward_rate 0.5 / replay/size 3.2e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3782 / timer/env.step_total 19.53 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.98 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.1e-3 / 
timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 18.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.15 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1891 / 
timer/agent.train_total 241.04 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 321000 Counter(321000) 320937
eval_Episode has 500 steps and return 371.2.
train_Episode has 500 steps and return 294.5.
Starting evaluation at step 321500 Counter(321500) 321437
Saved chunk: 20230922T042913F146833-5YaskiWJlgE77Mbzw4G1Vm-4vqPFWTGN7noG7Y5MHqj8H-1024.npz
eval_Episode has 500 steps and return 345.8.
Saved chunk: 20230922T042915F471298-116YhaAA7R50Bp1jEdLIl0-268PIAgCUHThCgDGgHu6Z4-1024.npz
train_Episode has 500 steps and return 258.5.
Starting evaluation at step 322000 Counter(322000) 321937
eval_Episode has 500 steps and return 350.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T043036F926304-268PIAgCUHThCgDGgHu6Z4-0000000000000000000000-564.npz
Saved chunk: 20230922T043033F017612-4vqPFWTGN7noG7Y5MHqj8H-0000000000000000000000-683.npz
train_Episode has 500 steps and return 331.4.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 322500 Counter(322500) 322437
Saved chunk: 20230922T043033F017612-4vqPFWTGN7noG7Y5MHqj8H-7KfzC2wUQSbVH2KM5UWhR6-1024.npz
eval_Episode has 500 steps and return 316.2.
Saved chunk: 20230922T043036F926304-268PIAgCUHThCgDGgHu6Z4-7httJ01oxGNmEhIWw5Y3gB-1024.npz
train_Episode has 500 steps and return 290.7.
Starting evaluation at step 323000 Counter(323000) 322937
eval_Episode has 500 steps and return 346.1.
train_Episode has 500 steps and return 315.3.
Starting evaluation at step 323500 Counter(323500) 323437
Saved chunk: 20230922T043152F280070-7KfzC2wUQSbVH2KM5UWhR6-16RvI78xfjNsKDob8JXqE1-1024.npz
eval_Episode has 500 steps and return 336.2.
Saved chunk: 20230922T043157F722798-7httJ01oxGNmEhIWw5Y3gB-0ottX4ASf39FZfdO5y2L27-1024.npz
train_Episode has 500 steps and return 295.7.
Starting evaluation at step 324000 Counter(324000) 323937
eval_Episode has 500 steps and return 348.4.
train_Episode has 500 steps and return 306.8.
Starting evaluation at step 324500 Counter(324500) 324437
Saved chunk: 20230922T043310F993221-16RvI78xfjNsKDob8JXqE1-645A6ngxyIsqlWdlRgxnoW-1024.npz
eval_Episode has 500 steps and return 335.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 649014 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 335.17 / eval_episode/reward_rate 0.55 / episode/length 500 / episode/score 306.8 / episode/reward_rate 0.49 / train/action_mag 2.95 / train/action_max 2.92 / train/action_mean 0.07 / train/action_min -2.33 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.61 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -11.01 / train/adv_mag 0.53 / train/adv_max 0.34 / train/adv_mean 2.1e-3 / 
train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.86 / train/dyn_loss_std 5.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 7891.16 / train/extr_critic_mag 250.02 / train/extr_critic_max 250.02 / train/extr_critic_mean 239.43 / train/extr_critic_min 214.66 / train/extr_critic_std 6.19 / train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.13 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 250.02 / train/extr_return_raw_max 250.02 / train/extr_return_raw_mean 239.47 / train/extr_return_raw_min 
213.49 / train/extr_return_raw_std 6.28 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.12 / train/image_loss_std 1.02 / train/model_loss_mean 3.66 /
train/model_loss_std 4.38 / train/model_opt_grad_norm 9.33 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.14 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 7.71 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.71 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.51 / train/policy_randomness_max 0.51 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 8.8e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.63 / train/post_ent_max 50.63 / train/post_ent_mean 42.03 / 
train/post_ent_min 20.85 / train/post_ent_std 4.44 / train/prior_ent_mag 71.82 / train/prior_ent_max 71.82 / train/prior_ent_mean 45.86 / train/prior_ent_min 30.97 / train/prior_ent_std 4.72 / train/rep_loss_mean 3.86 / train/rep_loss_std 5.93 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 0.39 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.22 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.06 / report/dyn_loss_std 5.91 / report/image_loss_mean 1.09 / report/image_loss_std 1.1 / report/model_loss_mean 3.75 / report/model_loss_std 4.53 / report/post_ent_mag 50.67 / report/post_ent_max 50.67 / 
report/post_ent_mean 42.45 / report/post_ent_min 24.02 / report/post_ent_std 3.94 / report/prior_ent_mag 71.82 / report/prior_ent_max 71.82 / report/prior_ent_mean 46.66 / report/prior_ent_min 32.77 / report/prior_ent_std 4.02 / report/rep_loss_mean 4.06 / 
report/rep_loss_std 5.91 / report/reward_avg 0.49 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.49 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.09 / eval/dyn_loss_std 5.72 / eval/image_loss_mean 1.11 / eval/image_loss_std 1.4 / eval/model_loss_mean 3.88 / eval/model_loss_std 4.51 / eval/post_ent_mag 49.14 / eval/post_ent_max 49.14 / eval/post_ent_mean 
42.11 / eval/post_ent_min 21.68 / eval/post_ent_std 3.88 / eval/prior_ent_mag 71.82 / eval/prior_ent_max 71.82 / eval/prior_ent_mean 46.19 / eval/prior_ent_min 36.28 / eval/prior_ent_std 3.79 / eval/rep_loss_mean 4.09 / eval/rep_loss_std 5.72 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.66 / eval/reward_rate 0.56 / 
replay/size 3.2e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3778 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.83 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.3e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1889 / timer/agent.train_total 240.62 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T043318F010177-0ottX4ASf39FZfdO5y2L27-4FcI7G3AW6ZuNV7j9cCasA-1024.npz
train_Episode has 500 steps and return 318.2.
Starting evaluation at step 325000 Counter(325000) 324937
eval_Episode has 500 steps and return 337.8.
train_Episode has 500 steps and return 289.3.
Starting evaluation at step 325500 Counter(325500) 325437
Saved chunk: 20230922T043429F648495-645A6ngxyIsqlWdlRgxnoW-4q1xYuGmYLbpcNUofs30aK-1024.npz
eval_Episode has 500 steps and return 300.8.
Saved chunk: 20230922T043439F096478-4FcI7G3AW6ZuNV7j9cCasA-2eboZVRf78YxcHZ2I15Jhn-1024.npz
train_Episode has 500 steps and return 266.3.
Starting evaluation at step 326000 Counter(326000) 325937
eval_Episode has 500 steps and return 351.8.
train_Episode has 500 steps and return 280.0.
Starting evaluation at step 326500 Counter(326500) 326437
eval_Episode has 500 steps and return 338.1.
Saved chunk: 20230922T043549F706876-4q1xYuGmYLbpcNUofs30aK-6Gnz7Du9ius03f5RBOz1Lo-1024.npz
train_Episode has 500 steps and return 289.3.
Saved chunk: 20230922T043601F407818-2eboZVRf78YxcHZ2I15Jhn-4BAYbduhvQljeUoP9045FC-1024.npz
Starting evaluation at step 327000 Counter(327000) 326937
eval_Episode has 500 steps and return 345.8.
train_Episode has 500 steps and return 301.4.
Starting evaluation at step 327500 Counter(327500) 327437
eval_Episode has 500 steps and return 361.1.
Saved chunk: 20230922T043710F010170-6Gnz7Du9ius03f5RBOz1Lo-3pSD8Vj560XHv0ZamKcDLI-1024.npz
train_Episode has 500 steps and return 313.1.
Saved chunk: 20230922T043721F721797-4BAYbduhvQljeUoP9045FC-7iBXssRaVX3ObiSXcOqK3p-1024.npz
Starting evaluation at step 328000 Counter(328000) 327937
eval_Episode has 500 steps and return 342.3.
train_Episode has 500 steps and return 293.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 656634 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.35 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 342.29 / eval_episode/reward_rate 0.59 / train/action_mag 2.93 / train/action_max 2.89 / train/action_mean 0.08 / train/action_min -2.45 / train/action_std
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.74 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 21.83 / train/adv_mag 0.54 / train/adv_max 0.32 / train/adv_mean -1.2e-3 / 
train/adv_min -0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.89 / train/dyn_loss_std 5.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 8610.99 / train/extr_critic_mag 249.16 / train/extr_critic_max 249.16 / train/extr_critic_mean 238.53 / train/extr_critic_min 214.9 / train/extr_critic_std 6 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.62 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 249.14 / train/extr_return_raw_max 249.14 / train/extr_return_raw_mean 238.51 / train/extr_return_raw_min 
213.64 / train/extr_return_raw_std 6.08 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 1.14 / train/image_loss_std 1.05 / train/model_loss_mean 3.69 /
train/model_loss_std 4.43 / train/model_opt_grad_norm 9.33 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.67 / train/policy_entropy_mean -3.19 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.51 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.19 / train/policy_logprob_min -7.89 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.46 / train/policy_randomness_max 0.46 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.8e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.57 / train/post_ent_max 50.57 / train/post_ent_mean 42.08 / 
train/post_ent_min 20.79 / train/post_ent_std 4.41 / train/prior_ent_mag 71.76 / train/prior_ent_max 71.76 / train/prior_ent_mean 45.93 / train/prior_ent_min 31.42 / train/prior_ent_std 4.63 / train/rep_loss_mean 3.89 / train/rep_loss_std 5.98 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 0.38 /
train_stats/mean_log_entropy -3.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.37 / report/dyn_loss_std 6.54 / report/image_loss_mean 1.26 / report/image_loss_std 1.09 / report/model_loss_mean 4.09 / report/model_loss_std 4.74 / report/post_ent_mag 50.64 / report/post_ent_max 50.64 /
report/post_ent_mean 41.73 / report/post_ent_min 20.01 / report/post_ent_std 4.66 / report/prior_ent_mag 71.75 / report/prior_ent_max 71.75 / report/prior_ent_mean 46.02 / report/prior_ent_min 31.82 / report/prior_ent_std 4.7 / report/rep_loss_mean 4.37 / 
report/rep_loss_std 6.54 / report/reward_avg 0.41 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.41 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.38 / eval/dyn_loss_std 6.3 / eval/image_loss_mean 1.22 / eval/image_loss_std 1.81 / eval/model_loss_mean 4.16 / eval/model_loss_std 5.17 / eval/post_ent_mag 50.01 / eval/post_ent_max 50.01 / eval/post_ent_mean 
42.14 / eval/post_ent_min 18.94 / eval/post_ent_std 4.02 / eval/prior_ent_mag 71.75 / eval/prior_ent_max 71.75 / eval/prior_ent_mean 46.47 / eval/prior_ent_min 35.54 / eval/prior_ent_std 3.97 / eval/rep_loss_mean 4.38 / eval/rep_loss_std 6.3 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.65 / eval/reward_rate 0.55 / 
replay/size 3.3e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3810 / timer/env.step_total 19.69 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.62 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7317 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.5e-3 
/ timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1905 / timer/agent.train_total 244.26 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.65 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 328500 Counter(328500) 328437
eval_Episode has 500 steps and return 347.3.
Saved chunk: 20230922T043828F843313-3pSD8Vj560XHv0ZamKcDLI-57ARLVt6wfXJTAoGZJWQMz-1024.npz
train_Episode has 500 steps and return 281.7.
Saved chunk: 20230922T043842F072702-7iBXssRaVX3ObiSXcOqK3p-3GKqJDregiC94z2mtBp3eN-1024.npz
Starting evaluation at step 329000 Counter(329000) 328937
eval_Episode has 500 steps and return 328.3.
train_Episode has 500 steps and return 285.0.
Starting evaluation at step 329500 Counter(329500) 329437
eval_Episode has 500 steps and return 336.3.
Saved chunk: 20230922T043948F396521-57ARLVt6wfXJTAoGZJWQMz-2XRgi9wdzq8dxXeAmgSGnB-1024.npz
train_Episode has 500 steps and return 292.4.
Saved chunk: 20230922T044003F249699-3GKqJDregiC94z2mtBp3eN-55tAzTPlmBNjLO9CV5xfa2-1024.npz
Starting evaluation at step 330000 Counter(330000) 329937
eval_Episode has 500 steps and return 361.9.
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 330500 Counter(330500) 330437
eval_Episode has 500 steps and return 359.3.
train_Episode has 500 steps and return 324.2.
Saved chunk: 20230922T044123F860502-55tAzTPlmBNjLO9CV5xfa2-5QPGKcFRIgzemnYJQe1vna-1024.npz
Starting evaluation at step 331000 Counter(331000) 330937
Saved chunk: 20230922T044107F474566-2XRgi9wdzq8dxXeAmgSGnB-3OPfBhTx4jWQZZvyWJGB9Q-1024.npz
eval_Episode has 500 steps and return 323.5.
train_Episode has 500 steps and return 295.0.
Starting evaluation at step 331500 Counter(331500) 331437
eval_Episode has 500 steps and return 331.4.
train_Episode has 500 steps and return 309.2.
Saved chunk: 20230922T044244F300480-5QPGKcFRIgzemnYJQe1vna-5GnmLXoWtRw6HKyZOBVxDr-1024.npz
Starting evaluation at step 332000 Counter(332000) 331937
Saved chunk: 20230922T044302F150046-3OPfBhTx4jWQZZvyWJGB9Q-08HMR62Q62gQfJlTuALIIF-1024.npz
eval_Episode has 500 steps and return 343.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 664198 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 343.28 / eval_episode/reward_rate 0.57 / episode/length 500 / episode/score 309.22 / episode/reward_rate 0.54 / train/action_mag 2.94 / train/action_max 2.89 / train/action_mean 0.08 / train/action_min -2.49 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.64 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -8.65 / train/adv_mag 0.53 / train/adv_max 0.33 / train/adv_mean 
1.8e-3 / train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.86 / train/dyn_loss_std 5.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 8357.27 / train/extr_critic_mag 249.5 / train/extr_critic_max 249.5 / train/extr_critic_mean 238.77 / train/extr_critic_min 214.16 / train/extr_critic_std 6.23 / 
train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.12 / train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.62 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 249.58 / train/extr_return_raw_max 
249.58 / train/extr_return_raw_mean 238.81 / train/extr_return_raw_min 213.01 / train/extr_return_raw_std 6.31 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / 
train/image_loss_mean 1.12 / train/image_loss_std 1.02 / train/model_loss_mean 3.66 / train/model_loss_std 4.38 / train/model_opt_grad_norm 9.36 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 0.98 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.81 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.8 / train/policy_logprob_std 1.51 / train/policy_randomness_mag 0.49 / train/policy_randomness_max 0.49 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.9e-5 / train/policy_randomness_std 
0.06 / train/post_ent_mag 50.54 / train/post_ent_max 50.54 / train/post_ent_mean 41.98 / train/post_ent_min 20.83 / train/post_ent_std 4.5 / train/prior_ent_mag 71.77 / train/prior_ent_max 71.77 / train/prior_ent_mean 45.82 / train/prior_ent_min 30.48 / 
train/prior_ent_std 4.77 / train/rep_loss_mean 3.86 / train/rep_loss_std 5.93 / train/reward_avg 0.42 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.1e-3 /
train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.24 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 7.9e-11 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.05 / report/dyn_loss_std 6.6 / report/image_loss_mean 1.24 / report/image_loss_std 1.13 / 
report/model_loss_mean 3.9 / report/model_loss_std 4.95 / report/post_ent_mag 50.16 / report/post_ent_max 50.16 / report/post_ent_mean 41.19 / report/post_ent_min 20.5 / report/post_ent_std 4.88 / report/prior_ent_mag 71.72 / report/prior_ent_max 71.72 / 
report/prior_ent_mean 45.4 / report/prior_ent_min 26.51 / report/prior_ent_std 5.19 / report/rep_loss_mean 4.05 / report/rep_loss_std 6.6 / report/reward_avg 0.41 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.44 / report/reward_max_data 2 / 
report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.41 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.1e-10 /
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.36 / eval/dyn_loss_std 6.21 / eval/image_loss_mean 1.2 / eval/image_loss_std 1.42 / eval/model_loss_mean 4.12 /
eval/model_loss_std 4.83 / eval/post_ent_mag 49.84 / eval/post_ent_max 49.84 / eval/post_ent_mean 42.19 / eval/post_ent_min 19.87 / eval/post_ent_std 3.92 / eval/prior_ent_mag 71.72 / eval/prior_ent_max 71.72 / eval/prior_ent_mean 46.35 / eval/prior_ent_min 32.98 / 
eval/prior_ent_std 3.97 / eval/rep_loss_mean 4.36 / eval/rep_loss_std 6.21 / eval/reward_avg 0.65 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.64 / eval/reward_rate 0.54 / replay/size 3.3e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / 
timer/env.step_count 3782 / timer/env.step_total 19.52 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.21 / timer/replay._sample_frac 1.52 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.95 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241.02 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 312.1.
Starting evaluation at step 332500 Counter(332500) 332437
eval_Episode has 500 steps and return 324.5.
train_Episode has 500 steps and return 270.3.
Saved chunk: 20230922T044404F529666-5GnmLXoWtRw6HKyZOBVxDr-4Yokxmus25h27cOv3l38g2-1024.npz
Starting evaluation at step 333000 Counter(333000) 332937
Saved chunk: 20230922T044420F780828-08HMR62Q62gQfJlTuALIIF-6Spl64N98AdQSgl6xsZnjt-1024.npz
eval_Episode has 500 steps and return 320.2.
train_Episode has 500 steps and return 346.9.
Starting evaluation at step 333500 Counter(333500) 333437
eval_Episode has 500 steps and return 362.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T044526F138636-4Yokxmus25h27cOv3l38g2-0000000000000000000000-800.npz
Saved chunk: 20230922T044540F955832-6Spl64N98AdQSgl6xsZnjt-0000000000000000000000-942.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 258.8.
Saved chunk: 20230922T044526F138636-4Yokxmus25h27cOv3l38g2-32JSjLdWvk4UGly5XxXyB4-1024.npz
Starting evaluation at step 334000 Counter(334000) 333937
Saved chunk: 20230922T044540F955832-6Spl64N98AdQSgl6xsZnjt-2K6KEAA46HyihLJteXLPIz-1024.npz
eval_Episode has 500 steps and return 337.0.
train_Episode has 500 steps and return 320.2.
Starting evaluation at step 334500 Counter(334500) 334437
eval_Episode has 500 steps and return 334.0.
train_Episode has 500 steps and return 273.9.
Saved chunk: 20230922T044647F016561-32JSjLdWvk4UGly5XxXyB4-4YLm93nTv3IXstQ9mcjBjg-1024.npz
Starting evaluation at step 335000 Counter(335000) 334937
Saved chunk: 20230922T044700F196292-2K6KEAA46HyihLJteXLPIz-40kyfve3OyuUtHi4k54aFp-1024.npz
eval_Episode has 500 steps and return 299.8.
train_Episode has 500 steps and return 329.0.
Starting evaluation at step 335500 Counter(335500) 335437
eval_Episode has 500 steps and return 332.6.
train_Episode has 500 steps and return 300.3.
Saved chunk: 20230922T044807F556744-4YLm93nTv3IXstQ9mcjBjg-07SRzFgbzzp5I98LFuQiJB-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 671834 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 300.27 / episode/reward_rate 0.49 / eval_episode/length 500 / eval_episode/score 332.55 / eval_episode/reward_rate 0.52 / train/action_mag 2.97 / train/action_max 2.86 / train/action_mean 0.08 / train/action_min -2.68 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.73 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 2.73 / train/adv_mag 0.53 / train/adv_max 0.33 / train/adv_mean 6.8e-4
/ train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 5.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 8202.64 / train/extr_critic_mag 249.39 / train/extr_critic_max 249.39 / train/extr_critic_mean 239.12 / train/extr_critic_min 214.8 / train/extr_critic_std 6.07 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 249.69 / train/extr_return_raw_max 249.69 / train/extr_return_raw_mean 239.14 / train/extr_return_raw_min 
213.58 / train/extr_return_raw_std 6.13 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.12 / train/image_loss_std 1.02 / train/model_loss_mean 3.65 /
train/model_loss_std 4.37 / train/model_opt_grad_norm 9.51 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.9 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.7 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.7 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.6e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.59 / train/post_ent_max 50.59 / train/post_ent_mean 42.08 / 
train/post_ent_min 20.97 / train/post_ent_std 4.39 / train/prior_ent_mag 71.75 / train/prior_ent_max 71.75 / train/prior_ent_mean 45.9 / train/prior_ent_min 30.99 / train/prior_ent_std 4.65 / train/rep_loss_mean 3.85 / train/rep_loss_std 5.92 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 
0.39 / train_stats/mean_log_entropy -3.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 6.04 / report/image_loss_mean 1.09 / report/image_loss_std 1.03 / report/model_loss_mean 3.63 / report/model_loss_std 4.43 / report/post_ent_mag 49.78 / report/post_ent_max 49.78 /
report/post_ent_mean 42.04 / report/post_ent_min 22.93 / report/post_ent_std 3.92 / report/prior_ent_mag 71.8 / report/prior_ent_max 71.8 / report/prior_ent_mean 45.73 / report/prior_ent_min 30.86 / report/prior_ent_std 4.15 / report/rep_loss_mean 3.82 / 
report/rep_loss_std 6.04 / report/reward_avg 0.51 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.51 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.49 / eval/dyn_loss_std 6.34 / eval/image_loss_mean 1.19 / eval/image_loss_std 1.71 / eval/model_loss_mean 4.24 / eval/model_loss_std 5.2 / eval/post_ent_mag 48.92 / eval/post_ent_max 48.92 / eval/post_ent_mean 
42.06 / eval/post_ent_min 21.99 / eval/post_ent_std 3.89 / eval/prior_ent_mag 71.8 / eval/prior_ent_max 71.8 / eval/prior_ent_mean 46.42 / eval/prior_ent_min 37.16 / eval/prior_ent_std 3.87 / eval/rep_loss_mean 4.49 / eval/rep_loss_std 6.34 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.71 / eval/reward_rate 0.6 / 
replay/size 3.4e5 / replay/inserts 3818 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3818 / timer/env.step_total 19.85 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 457.92 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-4 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7325 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1909 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1909 / timer/agent.train_total 243.94 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.45

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 336000 Counter(336000) 335937
Saved chunk: 20230922T044819F184103-40kyfve3OyuUtHi4k54aFp-61M4i7u5GBchrFkyLENpsj-1024.npz
eval_Episode has 500 steps and return 331.7.
train_Episode has 500 steps and return 276.2.
Starting evaluation at step 336500 Counter(336500) 336437
eval_Episode has 500 steps and return 329.1.
train_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T044927F919719-07SRzFgbzzp5I98LFuQiJB-1xOIQQCyWvDQLVQh94njdT-1024.npz
Starting evaluation at step 337000 Counter(337000) 336937
Saved chunk: 20230922T044938F907204-61M4i7u5GBchrFkyLENpsj-2RO9E1ltaVqfnpL288OApt-1024.npz
eval_Episode has 500 steps and return 316.4.
train_Episode has 500 steps and return 261.2.
Starting evaluation at step 337500 Counter(337500) 337437
eval_Episode has 500 steps and return 296.2.
train_Episode has 500 steps and return 275.6.
Saved chunk: 20230922T045049F817607-1xOIQQCyWvDQLVQh94njdT-5P6zVeJFGvSXVpgmqabYAt-1024.npz
Starting evaluation at step 338000 Counter(338000) 337937
Saved chunk: 20230922T045058F346054-2RO9E1ltaVqfnpL288OApt-2ERV0Y1uV9i37SzUZVTL1X-1024.npz
eval_Episode has 500 steps and return 297.6.
train_Episode has 500 steps and return 285.4.
Starting evaluation at step 338500 Counter(338500) 338437
eval_Episode has 500 steps and return 320.6.
train_Episode has 500 steps and return 298.1.
Saved chunk: 20230922T045210F451489-5P6zVeJFGvSXVpgmqabYAt-7bsoDtci5UuGAdR9jaLAWl-1024.npz
Starting evaluation at step 339000 Counter(339000) 338937
Saved chunk: 20230922T045217F408120-2ERV0Y1uV9i37SzUZVTL1X-2WbXizIA2kwIar6X5WM2yG-1024.npz
eval_Episode has 500 steps and return 325.0.
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 339500 Counter(339500) 339437
eval_Episode has 500 steps and return 359.0.
train_Episode has 500 steps and return 333.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 679382 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 359.02 / eval_episode/reward_rate 0.58 / episode/length 500 / episode/score 333.29 / episode/reward_rate 0.57 / train/action_mag 2.9 / train/action_max 2.83 / train/action_mean 0.08 / train/action_min -2.49 / train/action_std
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.82 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 23.82 / train/adv_mag 0.54 / train/adv_max 0.32 / train/adv_mean -1.5e-3 / 
train/adv_min -0.53 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 5.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 8954.58 / train/extr_critic_mag 248.14 / train/extr_critic_max 248.14 / train/extr_critic_mean 238.05 / train/extr_critic_min 213.94 / train/extr_critic_std 6.03 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.65 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 248.58 / train/extr_return_raw_max 248.58 / train/extr_return_raw_mean 238.02 / train/extr_return_raw_min 
212.61 / train/extr_return_raw_std 6.09 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.13 / train/image_loss_std 1.05 / train/model_loss_mean 3.68 /
train/model_loss_std 4.43 / train/model_opt_grad_norm 9.43 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.81 / train/policy_entropy_mean -3.21 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.5 / train/policy_logprob_mag 7.67 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.21 / train/policy_logprob_min -7.67 / train/policy_logprob_std 1.5 / 
train/policy_randomness_mag 0.47 / train/policy_randomness_max 0.47 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.4e-5 / train/policy_randomness_std 0.05 / train/post_ent_mag 50.62 / train/post_ent_max 50.62 / train/post_ent_mean 41.98 / 
train/post_ent_min 20.77 / train/post_ent_std 4.49 / train/prior_ent_mag 71.73 / train/prior_ent_max 71.73 / train/prior_ent_mean 45.84 / train/prior_ent_min 30.83 / train/prior_ent_std 4.75 / train/rep_loss_mean 3.88 / train/rep_loss_std 5.96 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 0.39 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.27 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 5.75 / report/image_loss_mean 1.04 / report/image_loss_std 1.04 / report/model_loss_mean 3.54 / report/model_loss_std 4.32 / report/post_ent_mag 50.63 / report/post_ent_max 50.63 /
report/post_ent_mean 42.62 / report/post_ent_min 23.13 / report/post_ent_std 3.94 / report/prior_ent_mag 71.77 / report/prior_ent_max 71.77 / report/prior_ent_mean 46.35 / report/prior_ent_min 34.57 / report/prior_ent_std 4.09 / report/rep_loss_mean 3.74 / 
report/rep_loss_std 5.75 / report/reward_avg 0.49 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.49 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.69 / eval/dyn_loss_std 6.53 / eval/image_loss_mean 1.32 / eval/image_loss_std 1.86 / eval/model_loss_mean 4.42 / eval/model_loss_std 5.45 / eval/post_ent_mag 49.97 / eval/post_ent_max 49.97 / eval/post_ent_mean 
41.83 / eval/post_ent_min 19.01 / eval/post_ent_std 4.21 / eval/prior_ent_mag 71.77 / eval/prior_ent_max 71.77 / eval/prior_ent_mean 46.41 / eval/prior_ent_min 37.83 / eval/prior_ent_std 3.9 / eval/rep_loss_mean 4.69 / eval/rep_loss_std 6.53 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.62 / eval/reward_rate 0.53 / 
replay/size 3.4e5 / replay/inserts 3774 / replay/samples 3e4 / replay/insert_wait_avg 4.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3774 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.73 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7782 / timer/agent.policy_total 18.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1887 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1887 / timer/agent.train_total 240.9 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.15

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T045330F786746-7bsoDtci5UuGAdR9jaLAWl-0TXj6kY8VCTpLicKbp4xVv-1024.npz
Starting evaluation at step 340000 Counter(340000) 339937
Saved chunk: 20230922T045336F142152-2WbXizIA2kwIar6X5WM2yG-2y8H7YrsaYzhL4V7lkeNdu-1024.npz
eval_Episode has 500 steps and return 356.3.
train_Episode has 500 steps and return 302.2.
Starting evaluation at step 340500 Counter(340500) 340437
eval_Episode has 500 steps and return 356.2.
train_Episode has 500 steps and return 336.5.
Saved chunk: 20230922T045452F104814-0TXj6kY8VCTpLicKbp4xVv-1M8NHt6RhrbLqaRHuEf9Zo-1024.npz
Starting evaluation at step 341000 Counter(341000) 340937
Saved chunk: 20230922T045455F939983-2y8H7YrsaYzhL4V7lkeNdu-5bhMMAZYm9idXQWVyXDyed-1024.npz
eval_Episode has 500 steps and return 360.2.
train_Episode has 500 steps and return 317.8.
Starting evaluation at step 341500 Counter(341500) 341437
eval_Episode has 500 steps and return 356.7.
train_Episode has 500 steps and return 314.9.
Starting evaluation at step 342000 Counter(342000) 341937
Saved chunk: 20230922T045615F003631-5bhMMAZYm9idXQWVyXDyed-3gadH04YdKTbVyjXzZogxP-1024.npz
eval_Episode has 500 steps and return 335.1.
Saved chunk: 20230922T045612F771594-1M8NHt6RhrbLqaRHuEf9Zo-3Ggfd8vHAlQD3fzdLYWheR-1024.npz
train_Episode has 500 steps and return 300.9.
Starting evaluation at step 342500 Counter(342500) 342437
eval_Episode has 500 steps and return 346.7.
train_Episode has 500 steps and return 324.4.
Starting evaluation at step 343000 Counter(343000) 342937
Saved chunk: 20230922T045734F163503-3gadH04YdKTbVyjXzZogxP-2vQ49Dy7GR6del0QskFayx-1024.npz
eval_Episode has 500 steps and return 353.5.
Saved chunk: 20230922T045737F072380-3Ggfd8vHAlQD3fzdLYWheR-1mFOY8OOjE2KigyMxbn063-1024.npz
train_Episode has 500 steps and return 317.2.
Starting evaluation at step 343500 Counter(343500) 343437
eval_Episode has 500 steps and return 347.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 687002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 347.73 / eval_episode/reward_rate 0.54 / episode/length 500 / episode/score 317.16 / episode/reward_rate 0.52 / train/action_mag 2.95 / train/action_max 2.88 / train/action_mean 0.08 / train/action_min -2.55 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.67 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -30.28 / train/adv_mag 0.53 / train/adv_max 0.34 / train/adv_mean 4e-3
/ train/adv_min -0.52 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 7739.99 / train/extr_critic_mag 249.66 / train/extr_critic_max 249.66 / train/extr_critic_mean 239.85 / train/extr_critic_min 215.08 / train/extr_critic_std 6.04 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.62 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 250.14 / train/extr_return_raw_max 250.14 / train/extr_return_raw_mean 239.94 / train/extr_return_raw_min 
213.99 / train/extr_return_raw_std 6.12 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.09 / train/image_loss_std 1.01 / train/model_loss_mean 3.62 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 8.96 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 9607.33 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.88 / train/policy_entropy_mean -3.19 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.89 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.19 / train/policy_logprob_min -7.89 / 
train/policy_logprob_std 1.51 / train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.4e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.68 / train/post_ent_max 50.68 / 
train/post_ent_mean 42.08 / train/post_ent_min 21 / train/post_ent_std 4.38 / train/prior_ent_mag 71.66 / train/prior_ent_max 71.66 / train/prior_ent_mean 45.88 / train/prior_ent_min 31.22 / train/prior_ent_std 4.67 / train/rep_loss_mean 3.84 / train/rep_loss_std 5.89 /
train/reward_avg 0.44 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.44
/ train/reward_rate 0.4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.23 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 6.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.45 / report/dyn_loss_std 5.52 / report/image_loss_mean 0.96 / report/image_loss_std 0.83 / report/model_loss_mean 3.26 / report/model_loss_std 3.99 / report/post_ent_mag 50.39 
/ report/post_ent_max 50.39 / report/post_ent_mean 43.06 / report/post_ent_min 17.91 / report/post_ent_std 3.83 / report/prior_ent_mag 71.64 / report/prior_ent_max 71.64 / report/prior_ent_mean 46.43 / report/prior_ent_min 31.42 / report/prior_ent_std 3.98 / 
report/rep_loss_mean 3.45 / report/rep_loss_std 5.52 / report/reward_avg 0.49 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.52 / report/reward_pred 0.48 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.14 / eval/dyn_loss_std 5.66 / eval/image_loss_mean 1.07 / eval/image_loss_std 1.25 / eval/model_loss_mean 3.88 / eval/model_loss_std 4.44 / eval/post_ent_mag 49.8 / eval/post_ent_max
49.8 / eval/post_ent_mean 42.2 / eval/post_ent_min 21.06 / eval/post_ent_std 3.66 / eval/prior_ent_mag 71.64 / eval/prior_ent_max 71.64 / eval/prior_ent_mean 46.43 / eval/prior_ent_min 37.37 / eval/prior_ent_std 3.72 / eval/rep_loss_mean 4.14 / eval/rep_loss_std 5.66 / 
eval/reward_avg 0.76 / eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.75 / 
eval/reward_rate 0.6 / replay/size 3.4e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.57 / timer/env.step_count 3810 / timer/env.step_total 19.72 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.92 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7818 / timer/agent.policy_total 18.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 7.8e-3 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1905 / 
timer/agent.train_total 243.24 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 301.1.
Starting evaluation at step 344000 Counter(344000) 343937
Saved chunk: 20230922T045852F919168-2vQ49Dy7GR6del0QskFayx-0jyQpj9yHzG2bJo2eaKSoL-1024.npz
eval_Episode has 500 steps and return 321.5.
Saved chunk: 20230922T045857F363329-1mFOY8OOjE2KigyMxbn063-7zjXZqKHYvzpTxRxlGOYHv-1024.npz
train_Episode has 500 steps and return 312.9.
Starting evaluation at step 344500 Counter(344500) 344437
eval_Episode has 500 steps and return 347.5.
train_Episode has 500 steps and return 331.9.
Starting evaluation at step 345000 Counter(345000) 344937
Saved chunk: 20230922T050012F729461-0jyQpj9yHzG2bJo2eaKSoL-1Vqp7Ffi6xJiFPYIzoJxp9-1024.npz
eval_Episode has 500 steps and return 351.6.
Saved chunk: 20230922T050018F783855-7zjXZqKHYvzpTxRxlGOYHv-6m6RMiSYDHdHMEqkwXOvzN-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T050131F619852-1Vqp7Ffi6xJiFPYIzoJxp9-0000000000000000000000-177.npz
Saved chunk: 20230922T050139F202370-6m6RMiSYDHdHMEqkwXOvzN-0000000000000000000000-12.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 341.5.
Starting evaluation at step 345500 Counter(345500) 345437
eval_Episode has 500 steps and return 333.4.
train_Episode has 500 steps and return 338.0.
Starting evaluation at step 346000 Counter(346000) 345937
Saved chunk: 20230922T050131F619852-1Vqp7Ffi6xJiFPYIzoJxp9-5CpW8OOIY91ocNN06cn88P-1024.npz
eval_Episode has 500 steps and return 341.8.
Saved chunk: 20230922T050139F202370-6m6RMiSYDHdHMEqkwXOvzN-4oiEIRRnosTb3MOR84Hfdv-1024.npz
train_Episode has 500 steps and return 322.8.
Starting evaluation at step 346500 Counter(346500) 346437
eval_Episode has 500 steps and return 324.3.
train_Episode has 500 steps and return 316.9.
Starting evaluation at step 347000 Counter(347000) 346937
Saved chunk: 20230922T050250F697013-5CpW8OOIY91ocNN06cn88P-2VXl39HkJUdc3ZCVDEWfll-1024.npz
eval_Episode has 500 steps and return 342.3.
Saved chunk: 20230922T050259F793841-4oiEIRRnosTb3MOR84Hfdv-6u4kaLrfkuc9wY2KP9Nkgl-1024.npz
train_Episode has 500 steps and return 343.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 694662 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 343.51 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 342.29 / eval_episode/reward_rate 0.54 / train/action_mag 3.09 / train/action_max 2.9 / train/action_mean 0.08 / train/action_min -2.89 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.66 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -13.89 / train/adv_mag 0.57 / train/adv_max 0.36 / train/adv_mean 2.4e-3 / 
train/adv_min -0.56 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 5.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 7320.69 / train/extr_critic_mag 250.72 / train/extr_critic_max 250.72 / train/extr_critic_mean 240.68 / train/extr_critic_min 212.93 / train/extr_critic_std 6.46 / train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.73 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 251.41 / train/extr_return_raw_max 251.41 / train/extr_return_raw_mean 240.73 / train/extr_return_raw_min 
212.16 / train/extr_return_raw_std 6.54 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.11 / train/image_loss_std 1.01 / train/model_loss_mean 3.63 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 9.38 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7748.69 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.43 / train/policy_entropy_mean -3.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 7.8 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.16 / train/policy_logprob_min -7.8 / 
train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.5e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.66 / train/post_ent_max 50.66 / 
train/post_ent_mean 42 / train/post_ent_min 20.83 / train/post_ent_std 4.44 / train/prior_ent_mag 71.6 / train/prior_ent_max 71.6 / train/prior_ent_mean 45.82 / train/prior_ent_min 31.23 / train/prior_ent_std 4.71 / train/rep_loss_mean 3.84 / train/rep_loss_std 5.9 / 
train/reward_avg 0.42 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / 
train/reward_rate 0.38 / train_stats/mean_log_entropy -3.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 5.96 / report/image_loss_mean 1.06 / report/image_loss_std 0.94 / report/model_loss_mean 3.49 / report/model_loss_std 4.36 / report/post_ent_mag 
51.07 / report/post_ent_max 51.07 / report/post_ent_mean 42.48 / report/post_ent_min 22.11 / report/post_ent_std 4.08 / report/prior_ent_mag 71.58 / report/prior_ent_max 71.58 / report/prior_ent_mean 46.12 / report/prior_ent_min 28.48 / report/prior_ent_std 4.48 / 
report/rep_loss_mean 3.65 / report/rep_loss_std 5.96 / report/reward_avg 0.42 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.42 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 6.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.3 / eval/dyn_loss_std 6.14 / eval/image_loss_mean 1.13 / eval/image_loss_std 1.44 / eval/model_loss_mean 4.02 / eval/model_loss_std 4.89 / eval/post_ent_mag 50.66 / eval/post_ent_max
50.66 / eval/post_ent_mean 42.11 / eval/post_ent_min 19.96 / eval/post_ent_std 3.78 / eval/prior_ent_mag 71.58 / eval/prior_ent_max 71.58 / eval/prior_ent_mean 46.21 / eval/prior_ent_min 33.85 / eval/prior_ent_std 3.9 / eval/rep_loss_mean 4.3 / eval/rep_loss_std 6.14 / 
eval/reward_avg 0.69 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.69 / 
eval/reward_rate 0.57 / replay/size 3.5e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3830 / timer/env.step_total 19.78 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 464.15 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.6e-3 / 
timer/replay._sample_max 0.19 / timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.3e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / timer/agent.policy_count 7337 / timer/agent.policy_total 17.23 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1915 / timer/agent.train_total 244.03 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / 
timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac
1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 347500 Counter(347500) 347437
eval_Episode has 500 steps and return 347.7.
train_Episode has 500 steps and return 325.1.
Starting evaluation at step 348000 Counter(348000) 347937
Saved chunk: 20230922T050409F375197-2VXl39HkJUdc3ZCVDEWfll-0patKVTvlQhycLJ4mw33uH-1024.npz
eval_Episode has 500 steps and return 332.8.
Saved chunk: 20230922T050420F035784-6u4kaLrfkuc9wY2KP9Nkgl-6lIoh3gp6WGBvYUdKmnly5-1024.npz
train_Episode has 500 steps and return 297.1.
Starting evaluation at step 348500 Counter(348500) 348437
eval_Episode has 500 steps and return 354.9.
train_Episode has 500 steps and return 319.7.
Starting evaluation at step 349000 Counter(349000) 348937
eval_Episode has 500 steps and return 360.6.
Saved chunk: 20230922T050529F303957-0patKVTvlQhycLJ4mw33uH-4fXdYQTgEqI4dOQI6XnyLT-1024.npz
Saved chunk: 20230922T050541F587840-6lIoh3gp6WGBvYUdKmnly5-2RmCmH5URPTp78IHSjL9h1-1024.npz
train_Episode has 500 steps and return 297.2.
Starting evaluation at step 349500 Counter(349500) 349437
eval_Episode has 500 steps and return 356.6.
train_Episode has 500 steps and return 328.5.
Starting evaluation at step 350000 Counter(350000) 349937
Saved chunk: 20230922T050648F266081-4fXdYQTgEqI4dOQI6XnyLT-4sQ0DbjBj1r0sTuW4lHS7V-1024.npz
eval_Episode has 500 steps and return 328.9.
train_Episode has 500 steps and return 319.9.
Saved chunk: 20230922T050702F077599-2RmCmH5URPTp78IHSjL9h1-6huB6xd4j75juVn9krNUtp-1024.npz
Starting evaluation at step 350500 Counter(350500) 350437
eval_Episode has 500 steps and return 340.8.
train_Episode has 500 steps and return 274.1.
Starting evaluation at step 351000 Counter(351000) 350937
eval_Episode has 500 steps and return 359.3.
Saved chunk: 20230922T050806F997381-4sQ0DbjBj1r0sTuW4lHS7V-4TrG0vwmCKOaq6MrMtQhd6-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 702226 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 359.28 / eval_episode/reward_rate 0.57 / episode/length 500 / episode/score 274.11 / episode/reward_rate 0.46 / train/action_mag 3.27 / train/action_max 2.96 / train/action_mean 0.08 / train/action_min -3.17 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.68 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -12.09 / train/adv_mag 0.55 / train/adv_max 0.36 / train/adv_mean 
2.2e-3 / train/adv_min -0.53 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.84 / train/dyn_loss_std 5.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 6846.47 / train/extr_critic_mag 251.56 / train/extr_critic_max 251.56 / train/extr_critic_mean 241.85 / train/extr_critic_min 215.18 / train/extr_critic_std 6.38 / 
train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.7 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 252.19 / train/extr_return_raw_max 
252.19 / train/extr_return_raw_mean 241.9 / train/extr_return_raw_min 214.08 / train/extr_return_raw_std 6.44 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / 
train/image_loss_mean 1.1 / train/image_loss_std 1.03 / train/model_loss_mean 3.63 / train/model_loss_std 4.39 / train/model_opt_grad_norm 9.33 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.1 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.9 / train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7e-5 / train/policy_randomness_std 0.06 /
train/post_ent_mag 50.53 / train/post_ent_max 50.53 / train/post_ent_mean 42.07 / train/post_ent_min 20.97 / train/post_ent_std 4.36 / train/prior_ent_mag 71.57 / train/prior_ent_max 71.57 / train/prior_ent_mean 45.88 / train/prior_ent_min 31.4 / train/prior_ent_std 
4.62 / train/rep_loss_mean 3.84 / train/rep_loss_std 5.92 / train/reward_avg 0.43 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.23 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.4e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 6.11 / report/image_loss_mean 1.13 / report/image_loss_std 1.02 / 
report/model_loss_mean 3.63 / report/model_loss_std 4.49 / report/post_ent_mag 50.9 / report/post_ent_max 50.9 / report/post_ent_mean 42.56 / report/post_ent_min 22.59 / report/post_ent_std 4.23 / report/prior_ent_mag 71.59 / report/prior_ent_max 71.59 / 
report/prior_ent_mean 46.32 / report/prior_ent_min 31.12 / report/prior_ent_std 4.46 / report/rep_loss_mean 3.78 / report/rep_loss_std 6.11 / report/reward_avg 0.44 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.32 / report/reward_max_data 2 / 
report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.43 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 1.2e-10 / 
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.78 / eval/dyn_loss_std 6.66 / eval/image_loss_mean 1.35 / eval/image_loss_std 1.85 / eval/model_loss_mean 4.53 / 
eval/model_loss_std 5.35 / eval/post_ent_mag 50.73 / eval/post_ent_max 50.73 / eval/post_ent_mean 41.95 / eval/post_ent_min 22.54 / eval/post_ent_std 4.05 / eval/prior_ent_mag 71.59 / eval/prior_ent_max 71.59 / eval/prior_ent_mean 46.34 / eval/prior_ent_min 35.15 / 
eval/prior_ent_std 4.03 / eval/rep_loss_mean 4.78 / eval/rep_loss_std 6.66 / eval/reward_avg 0.65 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.9e-4 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.65 / eval/reward_rate 0.55 / replay/size 3.5e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3782 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.1 / timer/replay._sample_frac 1.51 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.93 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 9.9e-3 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241.01 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / 
timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 322.7.
Saved chunk: 20230922T050822F364728-6huB6xd4j75juVn9krNUtp-4R4PvqCXHPBWKYPXctIK6R-1024.npz
Starting evaluation at step 351500 Counter(351500) 351437
eval_Episode has 500 steps and return 354.7.
train_Episode has 500 steps and return 309.9.
Starting evaluation at step 352000 Counter(352000) 351937
eval_Episode has 500 steps and return 302.5.
Saved chunk: 20230922T050925F628816-4TrG0vwmCKOaq6MrMtQhd6-1FnRzDHSQ8td28TDU0gyKU-1024.npz
train_Episode has 500 steps and return 335.5.
Saved chunk: 20230922T050943F574786-4R4PvqCXHPBWKYPXctIK6R-22mZZ4M40YqRxoPW9tFYen-1024.npz
Starting evaluation at step 352500 Counter(352500) 352437
eval_Episode has 500 steps and return 354.8.
train_Episode has 500 steps and return 296.7.
Starting evaluation at step 353000 Counter(353000) 352937
eval_Episode has 500 steps and return 361.3.
Saved chunk: 20230922T051045F776475-1FnRzDHSQ8td28TDU0gyKU-4Mo1gw2FybIbLooaWkYvBJ-1024.npz
train_Episode has 500 steps and return 306.2.
Saved chunk: 20230922T051104F261336-22mZZ4M40YqRxoPW9tFYen-7tAIpv4Q6eJtyfEyNHfXNh-1024.npz
Starting evaluation at step 353500 Counter(353500) 353437
eval_Episode has 500 steps and return 354.5.
train_Episode has 500 steps and return 338.6.
Starting evaluation at step 354000 Counter(354000) 353937
eval_Episode has 500 steps and return 352.4.
train_Episode has 500 steps and return 328.7.
Saved chunk: 20230922T051224F692031-7tAIpv4Q6eJtyfEyNHfXNh-5HTTVBGtHw1GRniBiiLj2o-1024.npz
Starting evaluation at step 354500 Counter(354500) 354437
Saved chunk: 20230922T051204F621226-4Mo1gw2FybIbLooaWkYvBJ-7w6Ngvx01QBWZola6MjlJ1-1024.npz
eval_Episode has 500 steps and return 332.8.
train_Episode has 500 steps and return 322.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 709890 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 322.9 / episode/reward_rate 0.55 / eval_episode/length 500 / eval_episode/score 332.82 / eval_episode/reward_rate 0.55 / train/action_mag 3.4 / train/action_max 3.01 / train/action_mean 0.08 / train/action_min -3.28 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.7 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -10.81 / train/adv_mag 0.55 / train/adv_max 0.35 / train/adv_mean 2.1e-3 / train/adv_min
-0.55 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6601.15 / train/extr_critic_mag 252.53 / train/extr_critic_max 252.53 / train/extr_critic_mean 242.93 / train/extr_critic_min 216.67 / train/extr_critic_std 6.23 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.68 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 253.1 / train/extr_return_raw_max 253.1 / train/extr_return_raw_mean 242.97 / train/extr_return_raw_min 
215.53 / train/extr_return_raw_std 6.31 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.09 / train/image_loss_std 1.01 / train/model_loss_mean 3.63 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 8.93 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.4 / train/policy_entropy_mean -3.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 7.78 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.78 / 
train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 7.5e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.58 / train/post_ent_max 50.58 / 
train/post_ent_mean 42.08 / train/post_ent_min 20.96 / train/post_ent_std 4.22 / train/prior_ent_mag 71.53 / train/prior_ent_max 71.53 / train/prior_ent_mean 45.91 / train/prior_ent_min 31.82 / train/prior_ent_std 4.5 / train/rep_loss_mean 3.85 / train/rep_loss_std 5.89
/ train/reward_avg 0.44 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.44 / train/reward_rate 0.4 / train_stats/mean_log_entropy -3.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.08 / report/dyn_loss_std 6.41 / report/image_loss_mean 1.21 / report/image_loss_std 1.23 / report/model_loss_mean 3.87 / report/model_loss_std 4.75 / report/post_ent_mag 
50.18 / report/post_ent_max 50.18 / report/post_ent_mean 41.62 / report/post_ent_min 19.22 / report/post_ent_std 4.63 / report/prior_ent_mag 71.57 / report/prior_ent_max 71.57 / report/prior_ent_mean 45.55 / report/prior_ent_min 32.49 / report/prior_ent_std 4.87 / 
report/rep_loss_mean 4.08 / report/rep_loss_std 6.41 / report/reward_avg 0.41 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 6.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.41 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.27 / eval/dyn_loss_std 6.05 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.22 / eval/model_loss_mean 3.95 / eval/model_loss_std 4.64 / eval/post_ent_mag 50.88 / 
eval/post_ent_max 50.88 / eval/post_ent_mean 42.1 / eval/post_ent_min 24.02 / eval/post_ent_std 3.77 / eval/prior_ent_mag 71.57 / eval/prior_ent_max 71.57 / eval/prior_ent_mean 46.28 / eval/prior_ent_min 38.51 / eval/prior_ent_std 3.71 / eval/rep_loss_mean 4.27 / 
eval/rep_loss_std 6.05 / eval/reward_avg 0.68 / eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.56 / 
eval/reward_pred 0.67 / eval/reward_rate 0.58 / replay/size 3.5e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3832 / timer/env.step_total 19.93
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.95 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7339 / timer/agent.policy_total 17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.5e-4 / 
timer/agent.train_count 1916 / timer/agent.train_total 244.09 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / 
timer/dataset_eval_max 4.3e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 355000 Counter(355000) 354937
eval_Episode has 500 steps and return 317.7.
train_Episode has 500 steps and return 309.0.
Saved chunk: 20230922T051344F776763-5HTTVBGtHw1GRniBiiLj2o-0YOaBtpFVEqgzTnW7vYqb1-1024.npz
Starting evaluation at step 355500 Counter(355500) 355437
Saved chunk: 20230922T051358F911358-7w6Ngvx01QBWZola6MjlJ1-154zexKgw5vSDgpDYgsetT-1024.npz
eval_Episode has 500 steps and return 335.3.
train_Episode has 500 steps and return 322.5.
Starting evaluation at step 356000 Counter(356000) 355937
eval_Episode has 500 steps and return 357.3.
train_Episode has 500 steps and return 337.9.
Saved chunk: 20230922T051506F216593-0YOaBtpFVEqgzTnW7vYqb1-1g5HW3ercZoYnpV23vsSaH-1024.npz
Starting evaluation at step 356500 Counter(356500) 356437
Saved chunk: 20230922T051518F915234-154zexKgw5vSDgpDYgsetT-5vvx530Z9fgDzZpVt89ZBH-1024.npz
eval_Episode has 500 steps and return 340.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T051626F990052-1g5HW3ercZoYnpV23vsSaH-0000000000000000000000-248.npz
Saved chunk: 20230922T051638F062029-5vvx530Z9fgDzZpVt89ZBH-0000000000000000000000-436.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 287.1.
Starting evaluation at step 357000 Counter(357000) 356937
eval_Episode has 500 steps and return 358.4.
train_Episode has 500 steps and return 293.2.
Saved chunk: 20230922T051626F990052-1g5HW3ercZoYnpV23vsSaH-2KAU9YtJ9deNzPf7gKzcyo-1024.npz
Starting evaluation at step 357500 Counter(357500) 357437
Saved chunk: 20230922T051638F062029-5vvx530Z9fgDzZpVt89ZBH-6udrJIFDU9TdF1nPo9ppzH-1024.npz
eval_Episode has 500 steps and return 346.2.
train_Episode has 500 steps and return 329.0.
Starting evaluation at step 358000 Counter(358000) 357937
eval_Episode has 500 steps and return 326.2.
train_Episode has 500 steps and return 310.5.
Saved chunk: 20230922T051747F659827-2KAU9YtJ9deNzPf7gKzcyo-3GqkvHWKVQIGDxC5ZhZNWD-1024.npz
Starting evaluation at step 358500 Counter(358500) 358437
Saved chunk: 20230922T051757F153967-6udrJIFDU9TdF1nPo9ppzH-0xOi06MRQXMqAssgFC5RS3-1024.npz
eval_Episode has 500 steps and return 365.7.
train_Episode has 500 steps and return 321.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 717436 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 365.74 / eval_episode/reward_rate 0.61 / episode/length 500 / episode/score 321.72 / episode/reward_rate 0.55 / train/action_mag 3.42 / train/action_max 3.04 / train/action_mean 0.07 / train/action_min -3.33 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.68 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -10.56 / train/adv_mag 0.54 / train/adv_max 0.35 / train/adv_mean 2e-3
/ train/adv_min -0.53 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 5.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6491.19 / train/extr_critic_mag 253.01 / train/extr_critic_max 253.01 / train/extr_critic_mean 243.41 / train/extr_critic_min 217.38 / train/extr_critic_std 6.11 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.7 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 253.54 / train/extr_return_raw_max 253.54 / train/extr_return_raw_mean 243.45 / train/extr_return_raw_min 
216.55 / train/extr_return_raw_std 6.18 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.1 / train/image_loss_std 1.02 / train/model_loss_mean 3.63 / 
train/model_loss_std 4.36 / train/model_opt_grad_norm 9.44 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7340.43 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 0.89 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.86 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.86 / 
train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 6.6e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.68 / train/post_ent_max 50.68 / 
train/post_ent_mean 42.07 / train/post_ent_min 20.83 / train/post_ent_std 4.29 / train/prior_ent_mag 71.52 / train/prior_ent_max 71.52 / train/prior_ent_mean 45.89 / train/prior_ent_min 31.52 / train/prior_ent_std 4.58 / train/rep_loss_mean 3.85 / train/rep_loss_std 
5.91 / train/reward_avg 0.44 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.43 / train/reward_rate 0.4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.21 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 8.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 5.09 / report/image_loss_mean 0.87 / report/image_loss_std 0.65 / report/model_loss_mean 3.24 / report/model_loss_std 3.68 / report/post_ent_mag 
50.14 / report/post_ent_max 50.14 / report/post_ent_mean 43.08 / report/post_ent_min 21.3 / report/post_ent_std 3.31 / report/prior_ent_mag 71.55 / report/prior_ent_max 71.55 / report/prior_ent_mean 46.56 / report/prior_ent_min 36.78 / report/prior_ent_std 3.79 / 
report/rep_loss_mean 3.49 / report/rep_loss_std 5.09 / report/reward_avg 0.52 / report/reward_loss_mean 0.28 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.52 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.8 / eval/dyn_loss_std 5.54 / eval/image_loss_mean 0.95 / eval/image_loss_std 0.94 / eval/model_loss_mean 3.55 / eval/model_loss_std 4 / eval/post_ent_mag 49.85 / eval/post_ent_max 
49.85 / eval/post_ent_mean 42.5 / eval/post_ent_min 21.79 / eval/post_ent_std 3.6 / eval/prior_ent_mag 71.55 / eval/prior_ent_max 71.55 / eval/prior_ent_mean 46.33 / eval/prior_ent_min 32.79 / eval/prior_ent_std 3.68 / eval/rep_loss_mean 3.8 / eval/rep_loss_std 5.54 / 
eval/reward_avg 0.68 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.67 / 
eval/reward_rate 0.57 / replay/size 3.6e5 / replay/inserts 3773 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3773 / timer/env.step_total 19.63 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.22 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7781 / timer/agent.policy_total 18.09 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1886 / timer/agent.train_total 240.73 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.15

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 359000 Counter(359000) 358937
eval_Episode has 500 steps and return 314.4.
train_Episode has 500 steps and return 345.6.
Saved chunk: 20230922T051907F873299-3GqkvHWKVQIGDxC5ZhZNWD-5J25iNcU4mOVBqTFvxQHdg-1024.npz
Starting evaluation at step 359500 Counter(359500) 359437
Saved chunk: 20230922T051915F770556-0xOi06MRQXMqAssgFC5RS3-2RfK3VwxdBXYBv2lIwmC7d-1024.npz
eval_Episode has 500 steps and return 349.6.
train_Episode has 500 steps and return 323.3.
Starting evaluation at step 360000 Counter(360000) 359937
eval_Episode has 500 steps and return 358.1.
train_Episode has 500 steps and return 309.7.
Starting evaluation at step 360500 Counter(360500) 360437
eval_Episode has 500 steps and return 358.5.
Saved chunk: 20230922T052029F465347-5J25iNcU4mOVBqTFvxQHdg-1QRqTNxbe7UqhU94OE6lLq-1024.npz
Saved chunk: 20230922T052035F853682-2RfK3VwxdBXYBv2lIwmC7d-1JcauIJyG9sc49xHSfJuAX-1024.npz
train_Episode has 500 steps and return 322.7.
Starting evaluation at step 361000 Counter(361000) 360937
eval_Episode has 500 steps and return 366.1.
train_Episode has 500 steps and return 290.8.
Saved chunk: 20230922T052150F029918-1QRqTNxbe7UqhU94OE6lLq-7HOxAenYhFM1pYuv94GIj2-1024.npz
Starting evaluation at step 361500 Counter(361500) 361437
Saved chunk: 20230922T052154F849423-1JcauIJyG9sc49xHSfJuAX-76Usd1mcS96Req1QFVvnzx-1024.npz
eval_Episode has 500 steps and return 339.4.
train_Episode has 500 steps and return 321.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 723894 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 339.45 / eval_episode/reward_rate 0.6 / episode/length 500 / episode/score 321.02 / episode/reward_rate 0.54 / train/action_mag 3.37 / train/action_max 2.93 / train/action_mean 0.07 / train/action_min -3.32 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.71 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 9.07 / train/adv_mag 0.55 / train/adv_max 0.35 / train/adv_mean 3.7e-5 / train/adv_min 
-0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.84 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6481.85 / train/extr_critic_mag 253.44 / train/extr_critic_max 253.44 / train/extr_critic_mean 243.64 / train/extr_critic_min 217.98 / train/extr_critic_std 6.19 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.67 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 253.97 / train/extr_return_raw_max 253.97 / train/extr_return_raw_mean 243.64 / train/extr_return_raw_min 
217.2 / train/extr_return_raw_std 6.25 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.09 / train/image_loss_std 1 / train/model_loss_mean 3.61 / 
train/model_loss_std 4.34 / train/model_opt_grad_norm 9.15 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
0.9 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 8.08 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -8.08 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.48 / train/policy_randomness_max 0.48 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 5.9e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.61 / train/post_ent_max 50.61 / train/post_ent_mean 42.03 / 
train/post_ent_min 20.86 / train/post_ent_std 4.26 / train/prior_ent_mag 71.53 / train/prior_ent_max 71.53 / train/prior_ent_mean 45.85 / train/prior_ent_min 31.6 / train/prior_ent_std 4.57 / train/rep_loss_mean 3.84 / train/rep_loss_std 5.89 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.44 / train/reward_rate 0.4
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.23 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 5.57 / report/image_loss_mean 1.05 / report/image_loss_std 0.95 / report/model_loss_mean 3.57 / report/model_loss_std 4.05 / report/post_ent_mag 51.6 / report/post_ent_max 51.6 / 
report/post_ent_mean 42.12 / report/post_ent_min 22.61 / report/post_ent_std 3.95 / report/prior_ent_mag 71.63 / report/prior_ent_max 71.63 / report/prior_ent_mean 45.89 / report/prior_ent_min 31.91 / report/prior_ent_std 4.25 / report/rep_loss_mean 3.82 / 
report/rep_loss_std 5.57 / report/reward_avg 0.45 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.5e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.45 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 9.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.24 / eval/dyn_loss_std 7.35 / eval/image_loss_mean 1.47 / eval/image_loss_std 2.07 / eval/model_loss_mean 4.88 / eval/model_loss_std 5.97 / eval/post_ent_mag 49.78 / eval/post_ent_max 49.78 / eval/post_ent_mean 
41.24 / eval/post_ent_min 20.37 / eval/post_ent_std 4.52 / eval/prior_ent_mag 71.63 / eval/prior_ent_max 71.63 / eval/prior_ent_mean 45.91 / eval/prior_ent_min 33.24 / eval/prior_ent_std 4.18 / eval/rep_loss_mean 5.24 / eval/rep_loss_std 7.35 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.59 / eval/reward_rate 0.49 / 
replay/size 3.6e5 / replay/inserts 3229 / replay/samples 2.6e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3006 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3229 / timer/env.step_total 16.68 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9.7e-3 / timer/replay._sample_count 2.6e4 / timer/replay._sample_total 390.47 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 9.1e-4 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 6235 / timer/agent.policy_total 14.66 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1615 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1615 / timer/agent.train_total 205.61 / 
timer/agent.train_frac 0.69 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 21.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 362000 Counter(362000) 361937
eval_Episode has 500 steps and return 350.5.
train_Episode has 500 steps and return 306.1.
Starting evaluation at step 362500 Counter(362500) 362437
Saved chunk: 20230922T052356F830585-7HOxAenYhFM1pYuv94GIj2-5RIikeytlSKka0sJHDhQIm-1024.npz
Saved chunk: 20230922T052400F041673-76Usd1mcS96Req1QFVvnzx-5ldUw92vS69oD4PBf8ECOl-1024.npz
eval_Episode has 500 steps and return 350.2.
train_Episode has 500 steps and return 320.9.
Starting evaluation at step 363000 Counter(363000) 362937
eval_Episode has 500 steps and return 346.3.
train_Episode has 500 steps and return 330.2.
Starting evaluation at step 363500 Counter(363500) 363437
Saved chunk: 20230922T052519F754206-5ldUw92vS69oD4PBf8ECOl-4kTTMgFeqnQPh2vQIDJlOG-1024.npz
eval_Episode has 500 steps and return 365.7.
Saved chunk: 20230922T052518F072445-5RIikeytlSKka0sJHDhQIm-0pa7dh9kS6XUAvsLHoZetT-1024.npz
train_Episode has 500 steps and return 299.1.
Starting evaluation at step 364000 Counter(364000) 363937
eval_Episode has 500 steps and return 350.8.
train_Episode has 500 steps and return 292.5.
Starting evaluation at step 364500 Counter(364500) 364437
Saved chunk: 20230922T052638F656765-4kTTMgFeqnQPh2vQIDJlOG-44HrFbUmjT6MS98bxZsECL-1024.npz
eval_Episode has 500 steps and return 370.6.
Saved chunk: 20230922T052642F019500-0pa7dh9kS6XUAvsLHoZetT-4nn59xs8t4sKiessTbNzcc-1024.npz
train_Episode has 500 steps and return 325.9.
Starting evaluation at step 365000 Counter(365000) 364937
eval_Episode has 500 steps and return 345.6.
train_Episode has 500 steps and return 337.2.
Starting evaluation at step 365500 Counter(365500) 365437
Saved chunk: 20230922T052757F312038-44HrFbUmjT6MS98bxZsECL-5dm1aFCXfQtMCu9JjvqX59-1024.npz
eval_Episode has 500 steps and return 360.4.
Saved chunk: 20230922T052802F221300-4nn59xs8t4sKiessTbNzcc-5nQ2ZkEGCsWeXzIXvxTvl0-1024.npz
train_Episode has 500 steps and return 320.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 731466 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 360.43 / eval_episode/reward_rate 0.6 / episode/length 500 / episode/score 320.46 / episode/reward_rate 0.52 / train/action_mag 3.3 / train/action_max 2.94 / train/action_mean 0.07 / train/action_min -3.21 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.74 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 4.33 / train/adv_mag 0.54 / train/adv_max 0.34 / train/adv_mean 5.2e-4 / train/adv_min 
-0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6598.47 / train/extr_critic_mag 252.8 / train/extr_critic_max 252.8 / train/extr_critic_mean 242.98 / train/extr_critic_min 217.59 / train/extr_critic_std 6.05 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.65 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 253.31 / train/extr_return_raw_max 253.31 / train/extr_return_raw_mean 242.99 / train/extr_return_raw_min 
216.48 / train/extr_return_raw_std 6.12 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.09 / train/image_loss_std 1.02 / train/model_loss_mean 3.62 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 9.15 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.09 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.91 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.91 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.5 / train/policy_randomness_max 0.5 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4.6e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.54 / train/post_ent_max 50.54 / train/post_ent_mean 42.1 / 
train/post_ent_min 20.99 / train/post_ent_std 4.23 / train/prior_ent_mag 71.53 / train/prior_ent_max 71.53 / train/prior_ent_mean 45.9 / train/prior_ent_min 31.59 / train/prior_ent_std 4.54 / train/rep_loss_mean 3.84 / train/rep_loss_std 5.89 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.44 / train/reward_rate 0.4 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.24 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.91 / report/dyn_loss_std 6.4 / report/image_loss_mean 1.18 / report/image_loss_std 1.28 / report/model_loss_mean 3.72 / report/model_loss_std 4.92 / report/post_ent_mag 51.91 / report/post_ent_max 51.91 / 
report/post_ent_mean 42 / report/post_ent_min 20.49 / report/post_ent_std 4.44 / report/prior_ent_mag 71.57 / report/prior_ent_max 71.57 / report/prior_ent_mean 45.93 / report/prior_ent_min 33.93 / report/prior_ent_std 4.67 / report/rep_loss_mean 3.91 / 
report/rep_loss_std 6.4 / report/reward_avg 0.37 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 6.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.37 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.08 / eval/dyn_loss_std 7.14 / eval/image_loss_mean 1.48 / eval/image_loss_std 2.12 / eval/model_loss_mean 4.8 / eval/model_loss_std 5.99 / eval/post_ent_mag 49.1 / eval/post_ent_max 49.1 / eval/post_ent_mean 
41.59 / eval/post_ent_min 19.74 / eval/post_ent_std 4.15 / eval/prior_ent_mag 71.57 / eval/prior_ent_max 71.57 / eval/prior_ent_mean 46.25 / eval/prior_ent_min 34.68 / eval/prior_ent_std 4.18 / eval/rep_loss_mean 5.08 / eval/rep_loss_std 7.14 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.61 / eval/reward_rate 0.51 / 
replay/size 3.7e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3786 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.1e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.25 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 17.89 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1893 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1893 / timer/agent.train_total 241.74 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 366000 Counter(366000) 365937
eval_Episode has 500 steps and return 381.4.
train_Episode has 500 steps and return 304.8.
Starting evaluation at step 366500 Counter(366500) 366437
Saved chunk: 20230922T052915F979385-5dm1aFCXfQtMCu9JjvqX59-5OU8RPixpUep7yOibFZzPj-1024.npz
eval_Episode has 500 steps and return 337.7.
Saved chunk: 20230922T052922F452959-5nQ2ZkEGCsWeXzIXvxTvl0-45ot8fd8vpygPPhPRcSl88-1024.npz
train_Episode has 500 steps and return 303.1.
Starting evaluation at step 367000 Counter(367000) 366937
eval_Episode has 500 steps and return 321.5.
train_Episode has 500 steps and return 320.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 367500 Counter(367500) 367437
Saved chunk: 20230922T053043F996403-45ot8fd8vpygPPhPRcSl88-0000000000000000000000-908.npz
Saved chunk: 20230922T053035F857597-5OU8RPixpUep7yOibFZzPj-0000000000000000000000-717.npz
Saved chunk: 20230922T053035F857597-5OU8RPixpUep7yOibFZzPj-55PaN9hoPHqkrkO3RQze7w-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
eval_Episode has 500 steps and return 335.5.
Saved chunk: 20230922T053043F996403-45ot8fd8vpygPPhPRcSl88-4rwbSv8BAOd4ZeNlAyRMql-1024.npz
train_Episode has 500 steps and return 291.5.
Starting evaluation at step 368000 Counter(368000) 367937
eval_Episode has 500 steps and return 342.1.
train_Episode has 500 steps and return 299.3.
Starting evaluation at step 368500 Counter(368500) 368437
Saved chunk: 20230922T053155F300611-55PaN9hoPHqkrkO3RQze7w-2AsRWG425xMrpKlmfmb8WL-1024.npz
eval_Episode has 500 steps and return 365.9.
Saved chunk: 20230922T053204F988441-4rwbSv8BAOd4ZeNlAyRMql-1G5keeRlkvEcLWpGbSidVX-1024.npz
train_Episode has 500 steps and return 280.9.
Starting evaluation at step 369000 Counter(369000) 368937
eval_Episode has 500 steps and return 351.3.
train_Episode has 500 steps and return 304.1.
Starting evaluation at step 369500 Counter(369500) 369437
Saved chunk: 20230922T053313F994800-2AsRWG425xMrpKlmfmb8WL-38Z6awTeqGGIzbCPfyZ6Ch-1024.npz
eval_Episode has 500 steps and return 371.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 739020 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 371.81 / eval_episode/reward_rate 0.63 / episode/length 500 / episode/score 304.07 / episode/reward_rate 0.51 / train/action_mag 3.39 / train/action_max 3.03 / train/action_mean 0.07 / train/action_min -3.27 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.72 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.42 / train/adv_mag 0.58 / train/adv_max 0.37 / train/adv_mean 
1.4e-3 / train/adv_min -0.57 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.82 / train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 6479.73 / train/extr_critic_mag 253.39 / train/extr_critic_max 253.39 / train/extr_critic_mean 243.52 / train/extr_critic_min 216.97 / train/extr_critic_std 6.45 / 
train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 253.97 / train/extr_return_raw_max 
253.97 / train/extr_return_raw_mean 243.55 / train/extr_return_raw_min 215.77 / train/extr_return_raw_std 6.53 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / 
train/image_loss_mean 1.08 / train/image_loss_std 1.02 / train/model_loss_mean 3.6 / train/model_loss_std 4.34 / train/model_opt_grad_norm 9.3 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.47 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 7.71 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.7 / train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 
0.06 / train/post_ent_mag 50.68 / train/post_ent_max 50.68 / train/post_ent_mean 42.08 / train/post_ent_min 21.01 / train/post_ent_std 4.26 / train/prior_ent_mag 71.49 / train/prior_ent_max 71.49 / train/prior_ent_mean 45.87 / train/prior_ent_min 31.59 / 
train/prior_ent_std 4.55 / train/rep_loss_mean 3.82 / train/rep_loss_std 5.84 / train/reward_avg 0.44 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 
5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.44 / train/reward_rate 0.4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.23 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 6.2e-11 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.39 / report/dyn_loss_std 5.57 / report/image_loss_mean 0.89 / report/image_loss_std 0.63 / 
report/model_loss_mean 3.14 / report/model_loss_std 3.85 / report/post_ent_mag 50.46 / report/post_ent_max 50.46 / report/post_ent_mean 41.65 / report/post_ent_min 19.81 / report/post_ent_std 6.06 / report/prior_ent_mag 71.57 / report/prior_ent_max 71.57 / 
report/prior_ent_mean 45 / report/prior_ent_min 21.98 / report/prior_ent_std 6.7 / report/rep_loss_mean 3.39 / report/rep_loss_std 5.57 / report/reward_avg 0.43 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.32 / report/reward_max_data 2 / 
report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 4.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.43 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-11 / eval/cont_loss_std 2.9e-10
/ eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.87 / eval/dyn_loss_std 7.46 / eval/image_loss_mean 1.51 / eval/image_loss_std 2.41 / eval/model_loss_mean 
4.73 / eval/model_loss_std 6.36 / eval/post_ent_mag 50.38 / eval/post_ent_max 50.38 / eval/post_ent_mean 41.45 / eval/post_ent_min 20.43 / eval/post_ent_std 4.61 / eval/prior_ent_mag 71.57 / eval/prior_ent_max 71.57 / eval/prior_ent_mean 46.06 / eval/prior_ent_min 29.99
/ eval/prior_ent_std 4.35 / eval/rep_loss_mean 4.87 / eval/rep_loss_std 7.46 / eval/reward_avg 0.64 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-3 / 
eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.63 / eval/reward_rate 0.53 / replay/size 3.7e5 / replay/inserts 3777 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.9e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.6e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / 
timer/env.step_count 3777 / timer/env.step_total 19.42 / timer/env.step_frac 0.06 / timer/env.step_avg 5.1e-3 / timer/env.step_min 3.9e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.77 / timer/replay._sample_frac 1.52 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / 
timer/agent.policy_count 7785 / timer/agent.policy_total 18.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1888 / timer/agent.train_total 241.1 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T053325F166922-1G5keeRlkvEcLWpGbSidVX-1P5krmezijFANYJVH6RiDC-1024.npz
train_Episode has 500 steps and return 277.5.
Starting evaluation at step 370000 Counter(370000) 369937
eval_Episode has 500 steps and return 358.1.
train_Episode has 500 steps and return 282.7.
Starting evaluation at step 370500 Counter(370500) 370437
Saved chunk: 20230922T053432F505668-38Z6awTeqGGIzbCPfyZ6Ch-1sVzn3fWtSxB8pVibasjLe-1024.npz
eval_Episode has 500 steps and return 372.0.
Saved chunk: 20230922T053446F269195-1P5krmezijFANYJVH6RiDC-2yc49tR6BsT1edOWcmBO6a-1024.npz
train_Episode has 500 steps and return 298.7.
Starting evaluation at step 371000 Counter(371000) 370937
eval_Episode has 500 steps and return 364.6.
train_Episode has 500 steps and return 311.6.
Starting evaluation at step 371500 Counter(371500) 371437
Saved chunk: 20230922T053552F508180-1sVzn3fWtSxB8pVibasjLe-1Ry28hej3IT9pp2Jc7Tsyn-1024.npz
eval_Episode has 500 steps and return 348.6.
Saved chunk: 20230922T053606F933849-2yc49tR6BsT1edOWcmBO6a-11Smdo5YWAroZWwEAdQpPJ-1024.npz
train_Episode has 500 steps and return 285.9.
Starting evaluation at step 372000 Counter(372000) 371937
eval_Episode has 500 steps and return 341.3.
train_Episode has 500 steps and return 259.9.
Starting evaluation at step 372500 Counter(372500) 372437
Saved chunk: 20230922T053711F401976-1Ry28hej3IT9pp2Jc7Tsyn-2JsDoGgv58nDSsc4bmivyP-1024.npz
eval_Episode has 500 steps and return 370.1.
Saved chunk: 20230922T053727F305784-11Smdo5YWAroZWwEAdQpPJ-2Gc7Yjh3b0MbL6kUUZAVdW-1024.npz
train_Episode has 500 steps and return 321.1.
Starting evaluation at step 373000 Counter(373000) 372937
eval_Episode has 500 steps and return 343.9.
train_Episode has 500 steps and return 330.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 746686 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 330.86 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 343.9 / eval_episode/reward_rate 0.57 / train/action_mag 3.37 / train/action_max 3.02 / train/action_mean 0.07 / train/action_min -3.25 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -3.92 / train/adv_mag 0.62 / train/adv_max 0.41 / train/adv_mean 1.4e-3 / train/adv_min 
-0.61 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.83 / train/dyn_loss_std 5.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 6482.43 / train/extr_critic_mag 253.62 / train/extr_critic_max 253.62 / train/extr_critic_mean 243.72 / train/extr_critic_min 216.76 / train/extr_critic_std 6.51 / train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 254.18 / train/extr_return_raw_max 254.18 / train/extr_return_raw_mean 243.75 / train/extr_return_raw_min 
215.64 / train/extr_return_raw_std 6.61 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.08 / train/image_loss_std 1.02 / train/model_loss_mean 3.61 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 9.21 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8880.21 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.77 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 7.97 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -7.97 / 
train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.58 / train/policy_randomness_max 0.58 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.69 / train/post_ent_max 50.69 / 
train/post_ent_mean 42.07 / train/post_ent_min 20.96 / train/post_ent_std 4.2 / train/prior_ent_mag 71.38 / train/prior_ent_max 71.38 / train/prior_ent_mean 45.89 / train/prior_ent_min 31.89 / train/prior_ent_std 4.49 / train/rep_loss_mean 3.83 / train/rep_loss_std 5.87
/ train/reward_avg 0.44 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 
0.44 / train/reward_rate 0.4 / train_stats/mean_log_entropy -3.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 9.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 6.19 / report/image_loss_mean 1.21 / report/image_loss_std 1.12 / report/model_loss_mean 3.67 / report/model_loss_std 4.57 / report/post_ent_mag 
49.95 / report/post_ent_max 49.95 / report/post_ent_mean 41.45 / report/post_ent_min 20.35 / report/post_ent_std 4.22 / report/prior_ent_mag 71.46 / report/prior_ent_max 71.46 / report/prior_ent_mean 45.17 / report/prior_ent_min 31.54 / report/prior_ent_std 4.83 / 
report/rep_loss_mean 3.81 / report/rep_loss_std 6.19 / report/reward_avg 0.35 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 7.8e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.34 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.97 / eval/dyn_loss_std 5.55 / eval/image_loss_mean 1.01 / eval/image_loss_std 1.25 / eval/model_loss_mean 3.71 / eval/model_loss_std 4.33 / eval/post_ent_mag 48.66 / 
eval/post_ent_max 48.66 / eval/post_ent_mean 42.36 / eval/post_ent_min 26.9 / eval/post_ent_std 3.11 / eval/prior_ent_mag 71.46 / eval/prior_ent_max 71.46 / eval/prior_ent_mean 46.25 / eval/prior_ent_min 40.49 / eval/prior_ent_std 3.69 / eval/rep_loss_mean 3.97 / 
eval/rep_loss_std 5.55 / eval/reward_avg 0.68 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / 
eval/reward_pred 0.68 / eval/reward_rate 0.56 / replay/size 3.7e5 / replay/inserts 3833 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3833 / timer/env.step_total 19.77
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 463.53 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7340 / timer/agent.policy_total 17.05 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 
/ timer/agent.train_count 1917 / timer/agent.train_total 244.21 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 373500 Counter(373500) 373437
Saved chunk: 20230922T053830F076895-2JsDoGgv58nDSsc4bmivyP-11WEJEMCnfjN9AyhCTGLOM-1024.npz
eval_Episode has 500 steps and return 344.5.
train_Episode has 500 steps and return 311.5.
Saved chunk: 20230922T053847F461183-2Gc7Yjh3b0MbL6kUUZAVdW-2XLwDfYHWYbElSqs5hwtS8-1024.npz
Starting evaluation at step 374000 Counter(374000) 373937
eval_Episode has 500 steps and return 375.7.
train_Episode has 500 steps and return 323.0.
Starting evaluation at step 374500 Counter(374500) 374437
eval_Episode has 500 steps and return 356.9.
Saved chunk: 20230922T053949F624613-11WEJEMCnfjN9AyhCTGLOM-7a8T0z6PMXnkbmIflrfxeZ-1024.npz
train_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T054008F808332-2XLwDfYHWYbElSqs5hwtS8-4KSbTW3vgLvWMw8khEQr6F-1024.npz
Starting evaluation at step 375000 Counter(375000) 374937
eval_Episode has 500 steps and return 365.6.
train_Episode has 500 steps and return 312.0.
Starting evaluation at step 375500 Counter(375500) 375437
eval_Episode has 500 steps and return 360.7.
Saved chunk: 20230922T054108F775777-7a8T0z6PMXnkbmIflrfxeZ-5zAnwIvaX9ato6KBswzuZB-1024.npz
train_Episode has 500 steps and return 315.9.
Saved chunk: 20230922T054129F424611-4KSbTW3vgLvWMw8khEQr6F-1XVaqClk9Gk4Sr4ltcr97k-1024.npz
Starting evaluation at step 376000 Counter(376000) 375937
eval_Episode has 500 steps and return 372.4.
train_Episode has 500 steps and return 324.9.
Starting evaluation at step 376500 Counter(376500) 376437
eval_Episode has 500 steps and return 344.5.
train_Episode has 500 steps and return 307.7.
Saved chunk: 20230922T054249F763343-1XVaqClk9Gk4Sr4ltcr97k-0049upAXtmXlUpKfMPewNU-1024.npz
Starting evaluation at step 377000 Counter(377000) 376937
Saved chunk: 20230922T054227F585903-5zAnwIvaX9ato6KBswzuZB-6nG7nEKM9V1OSrP1S37Ub5-1024.npz
eval_Episode has 500 steps and return 386.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 754250 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 386.16 / eval_episode/reward_rate 0.62 / episode/length 500 / episode/score 307.67 / episode/reward_rate 0.53 / train/action_mag 3.43 / train/action_max 3.03 / train/action_mean 0.07 / train/action_min -3.33 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.67 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -16.64 / train/adv_mag 0.66 / train/adv_max 0.47 / train/adv_mean 
2.6e-3 / train/adv_min -0.61 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.8 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 6322.19 / train/extr_critic_mag 254.6 / train/extr_critic_max 254.6 / train/extr_critic_mean 244.86 / train/extr_critic_min 215.36 / train/extr_critic_std 6.62 / 
train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.09 / train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.68 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 255.22 / train/extr_return_raw_max 
255.22 / train/extr_return_raw_mean 244.92 / train/extr_return_raw_min 214.62 / train/extr_return_raw_std 6.69 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / 
train/image_loss_mean 1.06 / train/image_loss_std 0.99 / train/model_loss_mean 3.58 / train/model_loss_std 4.3 / train/model_opt_grad_norm 9.2 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 8492.06 / train/policy_entropy_mag 3.63 / train/policy_entropy_max 2.64 / train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.03 / train/policy_logprob_max 
5.51 / train/policy_logprob_mean 3.15 / train/policy_logprob_min -8.03 / train/policy_logprob_std 1.57 / train/policy_randomness_mag 0.67 / train/policy_randomness_max 0.67 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4.6e-5 / 
train/policy_randomness_std 0.07 / train/post_ent_mag 50.61 / train/post_ent_max 50.61 / train/post_ent_mean 42.13 / train/post_ent_min 21.31 / train/post_ent_std 4.2 / train/prior_ent_mag 71.39 / train/prior_ent_max 71.39 / train/prior_ent_mean 45.9 / 
train/prior_ent_min 31.59 / train/prior_ent_std 4.5 / train/rep_loss_mean 3.8 / train/rep_loss_std 5.82 / train/reward_avg 0.45 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / 
train/reward_neg_loss 6.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.45 / train/reward_rate 0.41 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.22 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / 
report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 5.93 / report/image_loss_mean 1.05 / 
report/image_loss_std 1.05 / report/model_loss_mean 3.59 / report/model_loss_std 4.42 / report/post_ent_mag 50.78 / report/post_ent_max 50.78 / report/post_ent_mean 42.28 / report/post_ent_min 20.25 / report/post_ent_std 3.91 / report/prior_ent_mag 71.44 / 
report/prior_ent_max 71.44 / report/prior_ent_mean 46.11 / report/prior_ent_min 31.77 / report/prior_ent_std 4.06 / report/rep_loss_mean 3.85 / report/rep_loss_std 5.93 / report/reward_avg 0.5 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.34 / 
report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 0.5 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / 
eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.52 / eval/dyn_loss_std 6.45 / eval/image_loss_mean 1.26 / eval/image_loss_std 1.73
/ eval/model_loss_mean 4.28 / eval/model_loss_std 5.16 / eval/post_ent_mag 48.9 / eval/post_ent_max 48.9 / eval/post_ent_mean 41.84 / eval/post_ent_min 18.46 / eval/post_ent_std 3.95 / eval/prior_ent_mag 71.44 / eval/prior_ent_max 71.44 / eval/prior_ent_mean 46.2 / 
eval/prior_ent_min 36.8 / eval/prior_ent_std 4.02 / eval/rep_loss_mean 4.52 / eval/rep_loss_std 6.45 / eval/reward_avg 0.68 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / 
eval/reward_neg_loss 1.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.67 / eval/reward_rate 0.56 / replay/size 3.8e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / 
replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac
1 / timer/duration 300.07 / timer/env.step_count 3782 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.57 / 
timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.3e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 
17.9 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1891 / timer/agent.train_total 241.06 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / 
timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 338.7.
Starting evaluation at step 377500 Counter(377500) 377437
eval_Episode has 500 steps and return 356.5.
train_Episode has 500 steps and return 321.3.
Saved chunk: 20230922T054409F867816-0049upAXtmXlUpKfMPewNU-2SC9L3AecWfPKBo4Lw8QO2-1024.npz
Starting evaluation at step 378000 Counter(378000) 377937
Saved chunk: 20230922T054421F927645-6nG7nEKM9V1OSrP1S37Ub5-75CdTdQU8BpZ3DyMpIB2y1-1024.npz
eval_Episode has 500 steps and return 313.2.
train_Episode has 500 steps and return 287.6.
Starting evaluation at step 378500 Counter(378500) 378437
eval_Episode has 500 steps and return 369.5.
train_Episode has 500 steps and return 317.2.
Saved chunk: 20230922T054531F460965-2SC9L3AecWfPKBo4Lw8QO2-3GWV8DBZVuSOFKv3Mao6rD-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T054652F136124-3GWV8DBZVuSOFKv3Mao6rD-0000000000000000000000-20.npz
Saved chunk: 20230922T054542F003995-75CdTdQU8BpZ3DyMpIB2y1-0000000000000000000000-976.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 379000 Counter(379000) 378937
Saved chunk: 20230922T054542F003995-75CdTdQU8BpZ3DyMpIB2y1-2oDPX9u0fUYhz3bwNqJxPE-1024.npz
eval_Episode has 500 steps and return 348.4.
train_Episode has 500 steps and return 331.7.
Starting evaluation at step 379500 Counter(379500) 379437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 307.7.
Saved chunk: 20230922T054652F136124-3GWV8DBZVuSOFKv3Mao6rD-4quzv2SqbjH5ZZU80XzCIi-1024.npz
Starting evaluation at step 380000 Counter(380000) 379937
Saved chunk: 20230922T054701F228999-2oDPX9u0fUYhz3bwNqJxPE-1v0aWvvaGjDNK3OTO1hbjQ-1024.npz
eval_Episode has 500 steps and return 365.3.
train_Episode has 500 steps and return 315.9.
Starting evaluation at step 380500 Counter(380500) 380437
eval_Episode has 500 steps and return 344.2.
train_Episode has 500 steps and return 334.6.
Saved chunk: 20230922T054812F888461-4quzv2SqbjH5ZZU80XzCIi-6xqTiQQFVujuHqjC6c3LJQ-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 761890 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 334.62 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 344.15 / eval_episode/reward_rate 0.57 / train/action_mag 3.49 / train/action_max 3.08 / train/action_mean 0.07 / train/action_min -3.39 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -1.59 / train/adv_mag 0.55 / train/adv_max 0.37 / train/adv_mean 1.1e-3
/ train/adv_min -0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 9.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 6306.89 / train/extr_critic_mag 255.16 / train/extr_critic_max 255.16 / train/extr_critic_mean 245.58 / train/extr_critic_min 219.72 / train/extr_critic_std 6.06 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.67 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 255.83 / train/extr_return_raw_max 255.83 / train/extr_return_raw_mean 245.6 / train/extr_return_raw_min 
218.95 / train/extr_return_raw_std 6.13 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.08 / train/image_loss_std 1.04 / train/model_loss_mean 3.62 /
train/model_loss_std 4.37 / train/model_opt_grad_norm 9.26 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.61 / train/policy_entropy_max 
2.36 / train/policy_entropy_mean -3.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.64 / train/policy_logprob_mag 7.98 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.16 / train/policy_logprob_min -7.98 / train/policy_logprob_std 1.56 / 
train/policy_randomness_mag 0.64 / train/policy_randomness_max 0.64 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4.1e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.86 / train/post_ent_max 50.86 / train/post_ent_mean 42.07 / 
train/post_ent_min 20.9 / train/post_ent_std 4.2 / train/prior_ent_mag 71.38 / train/prior_ent_max 71.38 / train/prior_ent_mean 45.9 / train/prior_ent_min 31.96 / train/prior_ent_std 4.5 / train/rep_loss_mean 3.85 / train/rep_loss_std 5.89 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.44 / train/reward_rate 0.4 / 
train_stats/mean_log_entropy -3.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 5.27 / report/image_loss_mean 0.91 / report/image_loss_std 0.69 / report/model_loss_mean 3.31 / report/model_loss_std 3.69 / report/post_ent_mag 50.31 / report/post_ent_max 50.31 /
report/post_ent_mean 42.54 / report/post_ent_min 20.6 / report/post_ent_std 3.55 / report/prior_ent_mag 71.28 / report/prior_ent_max 71.28 / report/prior_ent_mean 46.13 / report/prior_ent_min 33.8 / report/prior_ent_std 3.94 / report/rep_loss_mean 3.58 / 
report/rep_loss_std 5.27 / report/reward_avg 0.55 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.52 / report/reward_pred 0.55 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 7.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4 / eval/dyn_loss_std 5.63 / eval/image_loss_mean 0.98 / eval/image_loss_std 1.06 / eval/model_loss_mean 3.71 / eval/model_loss_std 4.33 / eval/post_ent_mag 50.75 / eval/post_ent_max 50.75 / eval/post_ent_mean 
42.38 / eval/post_ent_min 23.61 / eval/post_ent_std 3.28 / eval/prior_ent_mag 71.28 / eval/prior_ent_max 71.28 / eval/prior_ent_mean 46.28 / eval/prior_ent_min 37.28 / eval/prior_ent_std 3.8 / eval/rep_loss_mean 4 / eval/rep_loss_std 5.63 / eval/reward_avg 0.67 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.49 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.67 / eval/reward_rate 0.57 / 
replay/size 3.8e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3820 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 466.4 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7327 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1910 / timer/agent.train_total 243.83 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.47

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 381000 Counter(381000) 380937
Saved chunk: 20230922T054820F273991-1v0aWvvaGjDNK3OTO1hbjQ-3KCmLxMEqzjoOMHQq03tjU-1024.npz
eval_Episode has 500 steps and return 356.8.
train_Episode has 500 steps and return 325.1.
Starting evaluation at step 381500 Counter(381500) 381437
eval_Episode has 500 steps and return 349.3.
train_Episode has 500 steps and return 318.1.
Saved chunk: 20230922T054933F138138-6xqTiQQFVujuHqjC6c3LJQ-4VEJNufMhCSIgD3DH2nHOf-1024.npz
Starting evaluation at step 382000 Counter(382000) 381937
Saved chunk: 20230922T054939F922162-3KCmLxMEqzjoOMHQq03tjU-7kSOJKqOMq6XRRPAeS0zTY-1024.npz
eval_Episode has 500 steps and return 352.0.
train_Episode has 500 steps and return 311.6.
Starting evaluation at step 382500 Counter(382500) 382437
eval_Episode has 500 steps and return 365.1.
train_Episode has 500 steps and return 279.6.
Saved chunk: 20230922T055054F901246-4VEJNufMhCSIgD3DH2nHOf-58ZtIduqZicci6utAygeSK-1024.npz
Starting evaluation at step 383000 Counter(383000) 382937
Saved chunk: 20230922T055059F153782-7kSOJKqOMq6XRRPAeS0zTY-7JNIqI8Ff0UuXjWxozqxMD-1024.npz
eval_Episode has 500 steps and return 371.5.
train_Episode has 500 steps and return 278.0.
Starting evaluation at step 383500 Counter(383500) 383437
eval_Episode has 500 steps and return 321.5.
train_Episode has 500 steps and return 331.3.
Starting evaluation at step 384000 Counter(384000) 383937
Saved chunk: 20230922T055215F475218-58ZtIduqZicci6utAygeSK-5AzzYrJccB2nUPhcDgDrHI-1024.npz
Saved chunk: 20230922T055218F145922-7JNIqI8Ff0UuXjWxozqxMD-1io2xx2zlo33jZyXTvUggg-1024.npz
eval_Episode has 500 steps and return 358.4.
train_Episode has 500 steps and return 305.4.
Starting evaluation at step 384500 Counter(384500) 384437
eval_Episode has 500 steps and return 339.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 769446 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 339.82 / eval_episode/reward_rate 0.56 / episode/length 500 / episode/score 305.36 / episode/reward_rate 0.5 / train/action_mag 3.36 / train/action_max 2.99 / train/action_mean 0.07 / train/action_min -3.27 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.78 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 9.91 / train/adv_mag 0.59 / train/adv_max 0.41 / train/adv_mean -4.6e-5 / train/adv_min
-0.56 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9.5e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.81 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 6271.08 / train/extr_critic_mag 255.39 / train/extr_critic_max 255.39 / train/extr_critic_mean 245.72 / train/extr_critic_min 219.2 / train/extr_critic_std 6.13 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.69 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 256.01 / train/extr_return_raw_max 256.01 / train/extr_return_raw_mean 245.72 / train/extr_return_raw_min 
218.26 / train/extr_return_raw_std 6.2 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.06 / train/image_loss_std 1 / train/model_loss_mean 3.58 / 
train/model_loss_std 4.3 / train/model_opt_grad_norm 9.47 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.62 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.58 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -8.04 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.7 / train/post_ent_max 50.7 / train/post_ent_mean 42.14 / 
train/post_ent_min 21.15 / train/post_ent_std 4.16 / train/prior_ent_mag 71.34 / train/prior_ent_max 71.34 / train/prior_ent_mean 45.92 / train/prior_ent_min 31.79 / train/prior_ent_std 4.47 / train/rep_loss_mean 3.81 / train/rep_loss_std 5.82 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.45 / train/reward_rate 0.41 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.23 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 8.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 5.57 / report/image_loss_mean 1.01 / report/image_loss_std 1.18 / report/model_loss_mean 3.47 / report/model_loss_std 4.35 / report/post_ent_mag 49.5 / report/post_ent_max 49.5 / 
report/post_ent_mean 41.86 / report/post_ent_min 21.58 / report/post_ent_std 3.87 / report/prior_ent_mag 71.42 / report/prior_ent_max 71.42 / report/prior_ent_mean 45.51 / report/prior_ent_min 35.45 / report/prior_ent_std 4.53 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 5.57 / report/reward_avg 0.49 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.49 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.47 / eval/dyn_loss_std 5.94 / eval/image_loss_mean 1.12 / eval/image_loss_std 1.35 / eval/model_loss_mean 4.1 / eval/model_loss_std 4.54 / eval/post_ent_mag 49.85 / eval/post_ent_max 49.85 / eval/post_ent_mean 
41.69 / eval/post_ent_min 20.87 / eval/post_ent_std 3.69 / eval/prior_ent_mag 71.42 / eval/prior_ent_max 71.42 / eval/prior_ent_mean 46.01 / eval/prior_ent_min 36.73 / eval/prior_ent_std 3.9 / eval/rep_loss_mean 4.47 / eval/rep_loss_std 5.94 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.63 / eval/reward_rate 0.53 / 
replay/size 3.8e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3778 / timer/env.step_total 19.52 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.46 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 17.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8e-3 / 
timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1889 / timer/agent.train_total 241.09 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 310.2.
Starting evaluation at step 385000 Counter(385000) 384937
Saved chunk: 20230922T055336F881144-1io2xx2zlo33jZyXTvUggg-2LYcoydJaJWOzeJ30XBiYS-1024.npz
eval_Episode has 500 steps and return 311.6.
Saved chunk: 20230922T055335F771507-5AzzYrJccB2nUPhcDgDrHI-3yP6pnJaDfEA17tLBnn1ok-1024.npz
train_Episode has 500 steps and return 288.4.
Starting evaluation at step 385500 Counter(385500) 385437
eval_Episode has 500 steps and return 368.5.
train_Episode has 500 steps and return 321.4.
Starting evaluation at step 386000 Counter(386000) 385937
Saved chunk: 20230922T055456F634601-2LYcoydJaJWOzeJ30XBiYS-3YJ8kCr7nLv8holMEKIl6P-1024.npz
eval_Episode has 500 steps and return 373.1.
Saved chunk: 20230922T055500F674775-3yP6pnJaDfEA17tLBnn1ok-3IsUHOlOAO8fU29oL8MxoY-1024.npz
train_Episode has 500 steps and return 307.5.
Starting evaluation at step 386500 Counter(386500) 386437
eval_Episode has 500 steps and return 376.6.
train_Episode has 500 steps and return 316.8.
Starting evaluation at step 387000 Counter(387000) 386937
Saved chunk: 20230922T055615F733608-3YJ8kCr7nLv8holMEKIl6P-4jAXHgCu8C3mDUmXWQeU5f-1024.npz
eval_Episode has 500 steps and return 355.9.
Saved chunk: 20230922T055621F331228-3IsUHOlOAO8fU29oL8MxoY-6mCDA7y7vyimTozezuUF4a-1024.npz
train_Episode has 500 steps and return 315.2.
Starting evaluation at step 387500 Counter(387500) 387437
eval_Episode has 500 steps and return 331.5.
train_Episode has 500 steps and return 291.5.
Starting evaluation at step 388000 Counter(388000) 387937
Saved chunk: 20230922T055734F604789-4jAXHgCu8C3mDUmXWQeU5f-3GxoFbrpsHzim0bByxSI7N-1024.npz
eval_Episode has 500 steps and return 387.8.
Saved chunk: 20230922T055741F735673-6mCDA7y7vyimTozezuUF4a-3ZkGDc2qOZDRZLYcE2YIBx-1024.npz
train_Episode has 500 steps and return 307.6.
Starting evaluation at step 388500 Counter(388500) 388437
eval_Episode has 500 steps and return 322.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 777002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 307.62 / episode/reward_rate 0.51 / eval_episode/length 500 / eval_episode/score 322.62 / eval_episode/reward_rate 0.58 / train/action_mag 3.41 / train/action_max 2.92 / train/action_mean 0.07 / train/action_min -3.34 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.73 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -15.4 / train/adv_mag 0.57 / train/adv_max 0.37 / train/adv_mean 
2.5e-3 / train/adv_min -0.56 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.84 / train/dyn_loss_std 5.88 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 6376.79 / train/extr_critic_mag 256.02 / train/extr_critic_max 256.02 / train/extr_critic_mean 246.38 / train/extr_critic_min 219.93 / train/extr_critic_std 6.17 / 
train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.7 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 256.68 / train/extr_return_raw_max 
256.68 / train/extr_return_raw_mean 246.44 / train/extr_return_raw_min 219.25 / train/extr_return_raw_std 6.23 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / 
train/image_loss_mean 1.08 / train/image_loss_std 1.04 / train/model_loss_mean 3.61 / train/model_loss_std 4.37 / train/model_opt_grad_norm 9.16 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 1.29 / train/policy_entropy_mean -3.2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 7.79 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.2 / train/policy_logprob_min -7.79 / train/policy_logprob_std 1.52 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.5e-5 / train/policy_randomness_std 
0.06 / train/post_ent_mag 50.8 / train/post_ent_max 50.8 / train/post_ent_mean 42.04 / train/post_ent_min 20.97 / train/post_ent_std 4.2 / train/prior_ent_mag 71.35 / train/prior_ent_max 71.35 / train/prior_ent_mean 45.85 / train/prior_ent_min 31.74 / 
train/prior_ent_std 4.52 / train/rep_loss_mean 3.84 / train/rep_loss_std 5.88 / train/reward_avg 0.45 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 
5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.45 / train/reward_rate 0.4 / train_stats/mean_log_entropy -3.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 8.8e-11 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.67 / report/dyn_loss_std 5.49 / report/image_loss_mean 0.94 / report/image_loss_std 0.97 / 
report/model_loss_mean 3.42 / report/model_loss_std 4.11 / report/post_ent_mag 50.69 / report/post_ent_max 50.69 / report/post_ent_mean 42.67 / report/post_ent_min 20.58 / report/post_ent_std 3.46 / report/prior_ent_mag 71.38 / report/prior_ent_max 71.38 / 
report/prior_ent_mean 46.3 / report/prior_ent_min 35.85 / report/prior_ent_std 3.81 / report/rep_loss_mean 3.67 / report/rep_loss_std 5.49 / report/reward_avg 0.53 / report/reward_loss_mean 0.28 / report/reward_loss_std 0.32 / report/reward_max_data 2 / 
report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.54 / report/reward_rate 0.49 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1e-10 /
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.29 / eval/dyn_loss_std 6.15 / eval/image_loss_mean 1.17 / eval/image_loss_std 1.47 / eval/model_loss_mean 4.03 
/ eval/model_loss_std 4.8 / eval/post_ent_mag 49.75 / eval/post_ent_max 49.75 / eval/post_ent_mean 41.91 / eval/post_ent_min 18.96 / eval/post_ent_std 3.93 / eval/prior_ent_mag 71.38 / eval/prior_ent_max 71.38 / eval/prior_ent_mean 46.16 / eval/prior_ent_min 33.69 / 
eval/prior_ent_std 3.96 / eval/rep_loss_mean 4.29 / eval/rep_loss_std 6.15 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.62 / eval/reward_rate 0.5 / replay/size 3.9e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3778 / timer/env.step_total 19.5 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.68 / timer/replay._sample_frac 1.52 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.1 / timer/agent.policy_frac 0.06
/ timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1889 / timer/agent.train_total 240.93 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 290.0.
Starting evaluation at step 389000 Counter(389000) 388937
Saved chunk: 20230922T055853F332713-3GxoFbrpsHzim0bByxSI7N-0HcjpyVGX1qx4hQUlbNsjf-1024.npz
eval_Episode has 500 steps and return 359.9.
Saved chunk: 20230922T055902F020052-3ZkGDc2qOZDRZLYcE2YIBx-5HQV89oc08RUTwH9HrWXOq-1024.npz
train_Episode has 500 steps and return 316.3.
Starting evaluation at step 389500 Counter(389500) 389437
eval_Episode has 500 steps and return 358.1.
train_Episode has 500 steps and return 299.7.
Starting evaluation at step 390000 Counter(390000) 389937
Saved chunk: 20230922T060013F177366-0HcjpyVGX1qx4hQUlbNsjf-2KdkCGAPD6tU0Eeb3Zl2Ky-1024.npz
eval_Episode has 500 steps and return 343.0.
Saved chunk: 20230922T060023F536708-5HQV89oc08RUTwH9HrWXOq-0EsiWYgwuqsV16SkcDozz3-1024.npz
train_Episode has 500 steps and return 302.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T060132F299573-2KdkCGAPD6tU0Eeb3Zl2Ky-0000000000000000000000-211.npz
Saved chunk: 20230922T060144F144658-0EsiWYgwuqsV16SkcDozz3-0000000000000000000000-156.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 390500 Counter(390500) 390437
eval_Episode has 500 steps and return 366.8.
train_Episode has 500 steps and return 308.7.
Starting evaluation at step 391000 Counter(391000) 390937
Saved chunk: 20230922T060132F299573-2KdkCGAPD6tU0Eeb3Zl2Ky-18XAviYAXl2VYV328loqnp-1024.npz
eval_Episode has 500 steps and return 360.7.
Saved chunk: 20230922T060144F144658-0EsiWYgwuqsV16SkcDozz3-3LsAjeBfFb12gjKrBQfeV0-1024.npz
train_Episode has 500 steps and return 333.2.
Starting evaluation at step 391500 Counter(391500) 391437
eval_Episode has 500 steps and return 348.6.
train_Episode has 500 steps and return 316.5.
Starting evaluation at step 392000 Counter(392000) 391937
Saved chunk: 20230922T060251F357736-18XAviYAXl2VYV328loqnp-0qvrDsRhXzv1crBPqoemFB-1024.npz
eval_Episode has 500 steps and return 337.3.
Saved chunk: 20230922T060304F687763-3LsAjeBfFb12gjKrBQfeV0-5cHd0d12Dg4dnedgDgQTFs-1024.npz
train_Episode has 500 steps and return 314.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 784656 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 314.69 / episode/reward_rate 0.55 / eval_episode/length 500 / eval_episode/score 337.27 / eval_episode/reward_rate 0.55 / train/action_mag 3.37 / train/action_max 2.95 / train/action_mean 0.07 / train/action_min -3.3 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.76 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 17.08 / train/adv_mag 0.56 / train/adv_max 0.37 / train/adv_mean -7.7e-4 / 
train/adv_min -0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 9.7e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.81 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 6401.16 / train/extr_critic_mag 256.19 / train/extr_critic_max 256.19 / train/extr_critic_mean 246.27 / train/extr_critic_min 220.08 / train/extr_critic_std 6.3 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.7 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 256.75 / train/extr_return_raw_max 256.75 / train/extr_return_raw_mean 246.25 / train/extr_return_raw_min 
219.4 / train/extr_return_raw_std 6.36 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.07 / train/image_loss_std 1.01 / train/model_loss_mean 3.58 / 
train/model_loss_std 4.3 / train/model_opt_grad_norm 9.32 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.55 / train/policy_entropy_mean -3.19 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 7.84 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.19 / train/policy_logprob_min -7.84 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.3e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.59 / train/post_ent_max 50.59 / train/post_ent_mean 42.05 / 
train/post_ent_min 21.03 / train/post_ent_std 4.17 / train/prior_ent_mag 71.3 / train/prior_ent_max 71.3 / train/prior_ent_mean 45.83 / train/prior_ent_min 31.67 / train/prior_ent_std 4.5 / train/rep_loss_mean 3.81 / train/rep_loss_std 5.82 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.45 / train/reward_rate 0.4
/ train_stats/mean_log_entropy -3.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 6.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.17 / report/image_loss_mean 1.16 / report/image_loss_std 1.16 / report/model_loss_mean 3.75 / report/model_loss_std 4.61 / report/post_ent_mag 49.76 / report/post_ent_max 49.76 /
report/post_ent_mean 41.57 / report/post_ent_min 19.13 / report/post_ent_std 4.62 / report/prior_ent_mag 71.32 / report/prior_ent_max 71.32 / report/prior_ent_mean 45.45 / report/prior_ent_min 30.35 / report/prior_ent_std 4.93 / report/rep_loss_mean 3.95 / 
report/rep_loss_std 6.17 / report/reward_avg 0.41 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 6.7e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.42 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 8.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.14 / eval/dyn_loss_std 6.02 / eval/image_loss_mean 1.15 / eval/image_loss_std 1.83 / eval/model_loss_mean 3.95 / eval/model_loss_std 4.98 / eval/post_ent_mag 49.83 / eval/post_ent_max 49.83 / eval/post_ent_mean 
42.29 / eval/post_ent_min 22.36 / eval/post_ent_std 3.45 / eval/prior_ent_mag 71.32 / eval/prior_ent_max 71.32 / eval/prior_ent_mean 46.15 / eval/prior_ent_min 36.03 / eval/prior_ent_std 3.84 / eval/rep_loss_mean 4.14 / eval/rep_loss_std 6.02 / eval/reward_avg 0.7 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.7 / eval/reward_rate 0.58 / 
replay/size 3.9e5 / replay/inserts 3827 / replay/samples 3.1e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3827 / timer/env.step_total 19.91 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 462.54 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.4e-3 / timer/replay._sample_max 0.05 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7334 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1913 / timer/agent.train_total 243.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 392500 Counter(392500) 392437
eval_Episode has 500 steps and return 340.8.
train_Episode has 500 steps and return 318.2.
Starting evaluation at step 393000 Counter(393000) 392937
Saved chunk: 20230922T060409F937153-0qvrDsRhXzv1crBPqoemFB-0cPN1j2nqG0JxsITY8krLk-1024.npz
eval_Episode has 500 steps and return 354.5.
Saved chunk: 20230922T060424F809109-5cHd0d12Dg4dnedgDgQTFs-5DVCLTyTicEtDIDzRrPNBv-1024.npz
train_Episode has 500 steps and return 279.5.
Starting evaluation at step 393500 Counter(393500) 393437
eval_Episode has 500 steps and return 352.3.
train_Episode has 500 steps and return 329.4.
Starting evaluation at step 394000 Counter(394000) 393937
Saved chunk: 20230922T060529F885405-0cPN1j2nqG0JxsITY8krLk-6p9fQhn1tjJKREEMeYXzda-1024.npz
eval_Episode has 500 steps and return 375.6.
Saved chunk: 20230922T060546F438584-5DVCLTyTicEtDIDzRrPNBv-13hWnUfk3aKQZzAokaDme5-1024.npz
train_Episode has 500 steps and return 318.7.
Starting evaluation at step 394500 Counter(394500) 394437
eval_Episode has 500 steps and return 336.0.
train_Episode has 500 steps and return 314.2.
Starting evaluation at step 395000 Counter(395000) 394937
eval_Episode has 500 steps and return 360.8.
Saved chunk: 20230922T060648F991639-6p9fQhn1tjJKREEMeYXzda-6lzaT1AUKbSgXuFVOUD9ST-1024.npz
Saved chunk: 20230922T060707F081217-13hWnUfk3aKQZzAokaDme5-6uCqge5OojCvwv3z08KqpY-1024.npz
train_Episode has 500 steps and return 315.6.
Starting evaluation at step 395500 Counter(395500) 395437
eval_Episode has 500 steps and return 353.7.
train_Episode has 500 steps and return 314.5.
Starting evaluation at step 396000 Counter(396000) 395937
Saved chunk: 20230922T060807F790379-6lzaT1AUKbSgXuFVOUD9ST-0O2LrEkCWEa1KgDrzrras8-1024.npz
eval_Episode has 500 steps and return 362.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 792210 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 362.47 / eval_episode/reward_rate 0.59 / episode/length 500 / episode/score 314.47 / episode/reward_rate 0.53 / train/action_mag 3.44 / train/action_max 3.03 / train/action_mean 0.07 / train/action_min -3.36 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.77 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -14.76 / train/adv_mag 0.57 / train/adv_max 0.37 / train/adv_mean 2.5e-3
/ train/adv_min -0.56 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.82 / train/dyn_loss_std 5.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 6375.15 / train/extr_critic_mag 256.1 / train/extr_critic_max 256.1 / train/extr_critic_mean 246.49 / train/extr_critic_min 220.78 / train/extr_critic_std 6.11 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.67 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 256.71 / train/extr_return_raw_max 256.71 / train/extr_return_raw_mean 246.54 / train/extr_return_raw_min 
220.24 / train/extr_return_raw_std 6.17 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1.06 / train/image_loss_std 1 / train/model_loss_mean 3.58 / 
train/model_loss_std 4.31 / train/model_opt_grad_norm 9.47 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7539.68 / train/policy_entropy_mag 3.53 / train/policy_entropy_max
1.4 / train/policy_entropy_mean -3.19 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 8.02 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.19 / train/policy_logprob_min -8.02 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.76 / train/post_ent_max 50.76 / train/post_ent_mean 42.03 / 
train/post_ent_min 21.13 / train/post_ent_std 4.12 / train/prior_ent_mag 71.27 / train/prior_ent_max 71.27 / train/prior_ent_mean 45.82 / train/prior_ent_min 32.09 / train/prior_ent_std 4.46 / train/rep_loss_mean 3.82 / train/rep_loss_std 5.83 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.45 / train/reward_rate 
0.41 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.24 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 6.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.6 / report/dyn_loss_std 5.68 / report/image_loss_mean 1 / report/image_loss_std 0.97 / report/model_loss_mean 3.39 / report/model_loss_std 4.14 / report/post_ent_mag 51.47 / report/post_ent_max 51.47 / 
report/post_ent_mean 42.74 / report/post_ent_min 20.53 / report/post_ent_std 3.86 / report/prior_ent_mag 71.36 / report/prior_ent_max 71.36 / report/prior_ent_mean 46.46 / report/prior_ent_min 37.23 / report/prior_ent_std 3.92 / report/rep_loss_mean 3.6 / 
report/rep_loss_std 5.68 / report/reward_avg 0.48 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.52 / report/reward_pred 0.48 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-11 / eval/cont_loss_std 9.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.79 / eval/dyn_loss_std 5.44 / eval/image_loss_mean 0.94 / eval/image_loss_std 0.89 / eval/model_loss_mean 3.54 / eval/model_loss_std 4.04 / eval/post_ent_mag 50.08 / eval/post_ent_max 50.08 / eval/post_ent_mean 
42.29 / eval/post_ent_min 23.23 / eval/post_ent_std 3.27 / eval/prior_ent_mag 71.36 / eval/prior_ent_max 71.36 / eval/prior_ent_mean 46.04 / eval/prior_ent_min 35.52 / eval/prior_ent_std 3.67 / eval/rep_loss_mean 3.79 / eval/rep_loss_std 5.44 / eval/reward_avg 0.68 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.68 / eval/reward_rate 0.58 / 
replay/size 4e5 / replay/inserts 3777 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3777 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.08 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7785 / timer/agent.policy_total 18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 9e-3 / 
timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1889 / timer/agent.train_total 240.95 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 314.9.
Saved chunk: 20230922T060827F340294-6uCqge5OojCvwv3z08KqpY-09kSbOSJjUvImgkNOKBwLe-1024.npz
Starting evaluation at step 396500 Counter(396500) 396437
eval_Episode has 500 steps and return 372.4.
train_Episode has 500 steps and return 330.2.
Starting evaluation at step 397000 Counter(397000) 396937
eval_Episode has 500 steps and return 379.0.
Saved chunk: 20230922T060926F487769-0O2LrEkCWEa1KgDrzrras8-1Ziyz6ZgQmoIspxUUIcsNq-1024.npz
train_Episode has 500 steps and return 342.7.
Saved chunk: 20230922T060950F256049-09kSbOSJjUvImgkNOKBwLe-1tJ8SxTivEKtK8EJI93VMu-1024.npz
Starting evaluation at step 397500 Counter(397500) 397437
eval_Episode has 500 steps and return 359.6.
train_Episode has 500 steps and return 338.1.
Starting evaluation at step 398000 Counter(398000) 397937
eval_Episode has 500 steps and return 355.2.
Saved chunk: 20230922T061048F171586-1Ziyz6ZgQmoIspxUUIcsNq-65L7ghPqyQ2bWQVzqmy8mp-1024.npz
train_Episode has 500 steps and return 319.9.
Saved chunk: 20230922T061110F905510-1tJ8SxTivEKtK8EJI93VMu-1sGlXP5o7iNLWIHwJ7xZdk-1024.npz
Starting evaluation at step 398500 Counter(398500) 398437
eval_Episode has 500 steps and return 384.4.
train_Episode has 500 steps and return 318.2.
Starting evaluation at step 399000 Counter(399000) 398937
eval_Episode has 500 steps and return 338.0.
Saved chunk: 20230922T061207F044269-65L7ghPqyQ2bWQVzqmy8mp-0CuZgZh6eNL55vvtWco6vi-1024.npz
train_Episode has 500 steps and return 290.2.
Saved chunk: 20230922T061231F386794-1sGlXP5o7iNLWIHwJ7xZdk-7MOJYxpCwHyuq9jIcbUD0Q-1024.npz
Starting evaluation at step 399500 Counter(399500) 399437
eval_Episode has 500 steps and return 380.5.
train_Episode has 500 steps and return 342.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 799826 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 342.59 / episode/reward_rate 0.58 / eval_episode/length 500 / eval_episode/score 380.47 / eval_episode/reward_rate 0.62 / train/action_mag 3.45 / train/action_max 3.09 / train/action_mean 0.07 / train/action_min -3.36 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.63 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -8.93 / train/adv_mag 0.56 / train/adv_max 0.39 / train/adv_mean 1.9e-3 
/ train/adv_min -0.55 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9.4e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.82 / train/dyn_loss_std 5.85 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 6738.14 / train/extr_critic_mag 257.83 / train/extr_critic_max 257.83 / train/extr_critic_mean 248.15 / train/extr_critic_min 220.63 / train/extr_critic_std 6.32 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.72 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 258.45 / train/extr_return_raw_max 258.45 / train/extr_return_raw_mean 248.19 / train/extr_return_raw_min 
220.2 / train/extr_return_raw_std 6.38 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.06 / train/image_loss_std 1.01 / train/model_loss_mean 3.59 / 
train/model_loss_std 4.33 / train/model_opt_grad_norm 9.13 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9815.79 / train/policy_entropy_mag 3.54 / train/policy_entropy_max
1.76 / train/policy_entropy_mean -3.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 8.09 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -8.09 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.8e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.75 / train/post_ent_max 50.75 / train/post_ent_mean 42.09 / 
train/post_ent_min 20.68 / train/post_ent_std 4.12 / train/prior_ent_mag 71.24 / train/prior_ent_max 71.24 / train/prior_ent_mean 45.88 / train/prior_ent_min 31.97 / train/prior_ent_std 4.45 / train/rep_loss_mean 3.82 / train/rep_loss_std 5.85 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.46 / train/reward_rate 
0.41 / train_stats/mean_log_entropy -3.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.71 / report/dyn_loss_std 5.51 / report/image_loss_mean 1.03 / report/image_loss_std 0.9 / report/model_loss_mean 3.51 / report/model_loss_std 4.12 / report/post_ent_mag 51.99 / report/post_ent_max 51.99 / 
report/post_ent_mean 42.61 / report/post_ent_min 23.15 / report/post_ent_std 3.87 / report/prior_ent_mag 71.2 / report/prior_ent_max 71.2 / report/prior_ent_mean 46.36 / report/prior_ent_min 31.19 / report/prior_ent_std 4.23 / report/rep_loss_mean 3.71 / 
report/rep_loss_std 5.51 / report/reward_avg 0.47 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.5e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.47 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 4.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.25 / eval/dyn_loss_std 6.17 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.52 / eval/model_loss_mean 3.92 / eval/model_loss_std 4.92 / eval/post_ent_mag 48.55 / eval/post_ent_max 48.55 / eval/post_ent_mean 
42.04 / eval/post_ent_min 21.56 / eval/post_ent_std 3.75 / eval/prior_ent_mag 71.2 / eval/prior_ent_max 71.2 / eval/prior_ent_mean 46.14 / eval/prior_ent_min 40.13 / eval/prior_ent_std 3.73 / eval/rep_loss_mean 4.25 / eval/rep_loss_std 6.17 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / eval/reward_pred 0.7 / eval/reward_rate 0.57 / 
replay/size 4e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3808 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 471.85 / timer/replay._sample_frac 1.57 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.6e-3 / timer/replay._sample_max 1.72 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 17.18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.17 / 
timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.23 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.7 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 400000 Counter(400000) 399937
eval_Episode has 500 steps and return 302.1.
train_Episode has 500 steps and return 326.4.
Saved chunk: 20230922T061351F663518-7MOJYxpCwHyuq9jIcbUD0Q-0YaLgdnoOqXUuQJGpxUw2j-1024.npz
Starting evaluation at step 400500 Counter(400500) 400437
Saved chunk: 20230922T061325F853887-0CuZgZh6eNL55vvtWco6vi-6VrBvvFa1jRhBYpPHWo3Cj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 301.4.
Starting evaluation at step 401000 Counter(401000) 400937
eval_Episode has 500 steps and return 348.3.
train_Episode has 500 steps and return 291.0.
Saved chunk: 20230922T061513F043032-0YaLgdnoOqXUuQJGpxUw2j-0Ap1MGYj8qRyaKA98UG3KI-1024.npz
Starting evaluation at step 401500 Counter(401500) 401437
Saved chunk: 20230922T061521F497940-6VrBvvFa1jRhBYpPHWo3Cj-3Splhenx0YTcfPRj6SNg5w-1024.npz
eval_Episode has 500 steps and return 342.4.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T061633F745194-0Ap1MGYj8qRyaKA98UG3KI-0000000000000000000000-292.npz
Saved chunk: 20230922T061640F617974-3Splhenx0YTcfPRj6SNg5w-0000000000000000000000-470.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 334.0.
Starting evaluation at step 402000 Counter(402000) 401937
eval_Episode has 500 steps and return 360.6.
train_Episode has 500 steps and return 333.6.
Saved chunk: 20230922T061633F745194-0Ap1MGYj8qRyaKA98UG3KI-6495DKsgvET2zStA1rCKcI-1024.npz
Starting evaluation at step 402500 Counter(402500) 402437
Saved chunk: 20230922T061640F617974-3Splhenx0YTcfPRj6SNg5w-7GmvkRJvah5jK5H2QuHA8q-1024.npz
eval_Episode has 500 steps and return 355.8.
train_Episode has 500 steps and return 333.9.
Starting evaluation at step 403000 Counter(403000) 402937
eval_Episode has 500 steps and return 376.3.
train_Episode has 500 steps and return 321.8.
Saved chunk: 20230922T061754F450200-6495DKsgvET2zStA1rCKcI-7fR614fzbr3vbERkU4nPDh-1024.npz
Starting evaluation at step 403500 Counter(403500) 403437
Saved chunk: 20230922T061759F684718-7GmvkRJvah5jK5H2QuHA8q-06KTG9GAbtgF4qKiCFnrKb-1024.npz
eval_Episode has 500 steps and return 360.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 807374 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 360.72 / eval_episode/reward_rate 0.63 / episode/length 500 / episode/score 321.81 / episode/reward_rate 0.55 / train/action_mag 3.57 / train/action_max 3.13 / train/action_mean 0.08 / train/action_min -3.51 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.67 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -11.45 / train/adv_mag 0.61 / train/adv_max 0.43 / train/adv_mean 2.1e-3
/ train/adv_min -0.58 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 5.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 6903.71 / train/extr_critic_mag 258.35 / train/extr_critic_max 258.35 / train/extr_critic_mean 248.67 / train/extr_critic_min 220.36 / train/extr_critic_std 6.36 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.73 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 258.96 / train/extr_return_raw_max 258.96 / train/extr_return_raw_mean 248.71 / train/extr_return_raw_min 
220.07 / train/extr_return_raw_std 6.43 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.05 / train/image_loss_std 1.01 / train/model_loss_mean 3.57 /
train/model_loss_std 4.3 / train/model_opt_grad_norm 9.03 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.56 / train/policy_entropy_max 2.31
/ train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.65 / train/policy_logprob_mag 8.05 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.15 / train/policy_logprob_min -8.05 / train/policy_logprob_std 1.56 / 
train/policy_randomness_mag 0.63 / train/policy_randomness_max 0.63 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.81 / train/post_ent_max 50.81 / train/post_ent_mean 42.06 / 
train/post_ent_min 21.29 / train/post_ent_std 4.11 / train/prior_ent_mag 71.23 / train/prior_ent_max 71.23 / train/prior_ent_mean 45.84 / train/prior_ent_min 32.18 / train/prior_ent_std 4.47 / train/rep_loss_mean 3.8 / train/rep_loss_std 5.81 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.46 / train/reward_rate 
0.41 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.22 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.96 / report/dyn_loss_std 6.34 / report/image_loss_mean 1.14 / report/image_loss_std 1.22 / report/model_loss_mean 3.71 / report/model_loss_std 4.82 / report/post_ent_mag 50.05 / report/post_ent_max 50.05 /
report/post_ent_mean 41.7 / report/post_ent_min 19.15 / report/post_ent_std 4.35 / report/prior_ent_mag 71.29 / report/prior_ent_max 71.29 / report/prior_ent_mean 45.57 / report/prior_ent_min 31.96 / report/prior_ent_std 4.61 / report/rep_loss_mean 3.96 / 
report/rep_loss_std 6.34 / report/reward_avg 0.43 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.5 / report/reward_pred 0.44 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 8.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.2 / eval/dyn_loss_std 6.08 / eval/image_loss_mean 1.2 / eval/image_loss_std 1.68 / eval/model_loss_mean 4.07 / eval/model_loss_std 4.95 / eval/post_ent_mag 50.45 / eval/post_ent_max 50.45 / eval/post_ent_mean 
42.11 / eval/post_ent_min 22.92 / eval/post_ent_std 3.8 / eval/prior_ent_mag 71.29 / eval/prior_ent_max 71.29 / eval/prior_ent_mean 46.19 / eval/prior_ent_min 39.38 / eval/prior_ent_std 3.77 / eval/rep_loss_mean 4.2 / eval/rep_loss_std 6.08 / eval/reward_avg 0.68 / 
eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.67 / eval/reward_rate 0.58 / 
replay/size 4e5 / replay/inserts 3774 / replay/samples 3e4 / replay/insert_wait_avg 3.9e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3774 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.06 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7782 / timer/agent.policy_total 18.08 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1887 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1887 / timer/agent.train_total 240.87 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 325.2.
Starting evaluation at step 404000 Counter(404000) 403937
eval_Episode has 500 steps and return 360.6.
train_Episode has 500 steps and return 332.7.
Saved chunk: 20230922T061914F636995-7fR614fzbr3vbERkU4nPDh-4FJt7AL0x0SoSUIXsKtM84-1024.npz
Starting evaluation at step 404500 Counter(404500) 404437
Saved chunk: 20230922T061918F306777-06KTG9GAbtgF4qKiCFnrKb-23SfLGvjk9a3EeGbHi56ZW-1024.npz
eval_Episode has 500 steps and return 346.3.
train_Episode has 500 steps and return 324.2.
Starting evaluation at step 405000 Counter(405000) 404937
eval_Episode has 500 steps and return 340.3.
train_Episode has 500 steps and return 321.8.
Starting evaluation at step 405500 Counter(405500) 405437
Saved chunk: 20230922T062038F466159-23SfLGvjk9a3EeGbHi56ZW-1PB75eVuqVLudqVWVOrlTj-1024.npz
eval_Episode has 500 steps and return 361.6.
Saved chunk: 20230922T062036F347323-4FJt7AL0x0SoSUIXsKtM84-6A4fYvrvKKe2Qu3ZpOllAW-1024.npz
train_Episode has 500 steps and return 325.3.
Starting evaluation at step 406000 Counter(406000) 405937
eval_Episode has 500 steps and return 347.9.
train_Episode has 500 steps and return 325.2.
Starting evaluation at step 406500 Counter(406500) 406437
Saved chunk: 20230922T062157F577502-1PB75eVuqVLudqVWVOrlTj-3zbIraI7quKkp5JJYSKV0X-1024.npz
eval_Episode has 500 steps and return 367.9.
Saved chunk: 20230922T062200F594145-6A4fYvrvKKe2Qu3ZpOllAW-3hkEbJjugBIqulkaE0tNtd-1024.npz
train_Episode has 500 steps and return 328.2.
Starting evaluation at step 407000 Counter(407000) 406937
eval_Episode has 500 steps and return 353.4.
train_Episode has 500 steps and return 333.9.
Starting evaluation at step 407500 Counter(407500) 407437
Saved chunk: 20230922T062316F357507-3zbIraI7quKkp5JJYSKV0X-1Y0J3If4AUS2BxH3YE6qlZ-1024.npz
eval_Episode has 500 steps and return 377.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 815002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 333.91 / episode/reward_rate 0.53 / eval_episode/length 500 / eval_episode/score 377.09 / eval_episode/reward_rate 0.65 / train/action_mag 3.54 / train/action_max 3.04 / train/action_mean 0.07 / train/action_min -3.46 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.67 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -10.28 / train/adv_mag 0.59 / train/adv_max 0.41 / train/adv_mean 2e-3 /
train/adv_min -0.56 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.83 / train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 7287.76 / train/extr_critic_mag 259.3 / train/extr_critic_max 259.3 / train/extr_critic_mean 249.55 / train/extr_critic_min 221.4 / train/extr_critic_std 6.4 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.76 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 259.93 / train/extr_return_raw_max 259.93 / train/extr_return_raw_mean 249.59 / train/extr_return_raw_min 
221.36 / train/extr_return_raw_std 6.45 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.06 / train/image_loss_std 1.02 / train/model_loss_mean 3.59 /
train/model_loss_std 4.33 / train/model_opt_grad_norm 9.4 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9528.8 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.68 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 8.02 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.17 / train/policy_logprob_min -8.02 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.9e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.75 / train/post_ent_max 50.75 / train/post_ent_mean 41.98 / 
train/post_ent_min 21.14 / train/post_ent_std 4.13 / train/prior_ent_mag 71.17 / train/prior_ent_max 71.17 / train/prior_ent_mean 45.77 / train/prior_ent_min 32 / train/prior_ent_std 4.49 / train/rep_loss_mean 3.83 / train/rep_loss_std 5.84 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.46 / train/reward_rate 0.41 /
train_stats/mean_log_entropy -3.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 6.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.73 / report/dyn_loss_std 5.82 / report/image_loss_mean 0.99 / report/image_loss_std 1.06 / report/model_loss_mean 3.46 / report/model_loss_std 4.37 / report/post_ent_mag 52.23 / report/post_ent_max 52.23 /
report/post_ent_mean 42.26 / report/post_ent_min 20.79 / report/post_ent_std 3.98 / report/prior_ent_mag 70.99 / report/prior_ent_max 70.99 / report/prior_ent_mean 46.15 / report/prior_ent_min 34.42 / report/prior_ent_std 4.09 / report/rep_loss_mean 3.73 / 
report/rep_loss_std 5.82 / report/reward_avg 0.48 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.47 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.25 / eval/dyn_loss_std 6.35 / eval/image_loss_mean 1.13 / eval/image_loss_std 1.57 / eval/model_loss_mean 4.02 / eval/model_loss_std 5.01 / eval/post_ent_mag 48.58 / eval/post_ent_max 48.58 / eval/post_ent_mean 
41.99 / eval/post_ent_min 18.52 / eval/post_ent_std 3.66 / eval/prior_ent_mag 70.99 / eval/prior_ent_max 70.99 / eval/prior_ent_mean 46.02 / eval/prior_ent_min 36.06 / eval/prior_ent_std 3.75 / eval/rep_loss_mean 4.25 / eval/rep_loss_std 6.35 / eval/reward_avg 0.74 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.74 / eval/reward_rate 0.6 / 
replay/size 4.1e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.8 / timer/env.step_count 3814 / timer/env.step_total 19.69 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.88 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.3e-4 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7822 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.5e-3 
/ timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1907 / timer/agent.train_total 243.53 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T062320F943522-3hkEbJjugBIqulkaE0tNtd-4Cb0gKhEjVn3sZ8lnHk9SR-1024.npz
train_Episode has 500 steps and return 336.6.
Starting evaluation at step 408000 Counter(408000) 407937
eval_Episode has 500 steps and return 339.2.
train_Episode has 500 steps and return 316.7.
Starting evaluation at step 408500 Counter(408500) 408437
Saved chunk: 20230922T062435F002976-1Y0J3If4AUS2BxH3YE6qlZ-1cepRkBbLrUqmvdTuOhDlN-1024.npz
eval_Episode has 500 steps and return 387.0.
Saved chunk: 20230922T062442F130000-4Cb0gKhEjVn3sZ8lnHk9SR-4nHkHZfkK24CIUspNssvXL-1024.npz
train_Episode has 500 steps and return 338.5.
Starting evaluation at step 409000 Counter(409000) 408937
eval_Episode has 500 steps and return 362.7.
train_Episode has 500 steps and return 294.7.
Starting evaluation at step 409500 Counter(409500) 409437
Saved chunk: 20230922T062555F224624-1cepRkBbLrUqmvdTuOhDlN-4x47LKmrvZBAlmKNbw332k-1024.npz
eval_Episode has 500 steps and return 352.8.
Saved chunk: 20230922T062602F957807-4nHkHZfkK24CIUspNssvXL-0KamA9UfoLJnsmfRdi72w1-1024.npz
train_Episode has 500 steps and return 290.0.
Starting evaluation at step 410000 Counter(410000) 409937
eval_Episode has 500 steps and return 344.5.
train_Episode has 500 steps and return 311.7.
Starting evaluation at step 410500 Counter(410500) 410437
Saved chunk: 20230922T062714F245727-4x47LKmrvZBAlmKNbw332k-3DLFHJ28dy4ANoZ6jxNRYt-1024.npz
eval_Episode has 500 steps and return 314.3.
Saved chunk: 20230922T062723F564616-0KamA9UfoLJnsmfRdi72w1-2mA4NYfVmB5MAnDWLxuK8C-1024.npz
train_Episode has 500 steps and return 318.6.
Starting evaluation at step 411000 Counter(411000) 410937
eval_Episode has 500 steps and return 369.5.
train_Episode has 500 steps and return 334.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 822654 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 334.34 / episode/reward_rate 0.54 / eval_episode/length 500 / eval_episode/score 369.45 / eval_episode/reward_rate 0.61 / train/action_mag 3.52 / train/action_max 3.02 / train/action_mean 0.07 / train/action_min -3.46 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.72 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 14.84 / train/adv_mag 0.58 / train/adv_max 0.39 / train/adv_mean -5.4e-4
/ train/adv_min -0.56 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 7226.01 / train/extr_critic_mag 259.52 / train/extr_critic_max 259.52 / train/extr_critic_mean 249.79 / train/extr_critic_min 222.08 / train/extr_critic_std 6.17 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.78 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 260.09 / train/extr_return_raw_max 260.09 / train/extr_return_raw_mean 249.78 / train/extr_return_raw_min 
221.57 / train/extr_return_raw_std 6.23 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.05 / train/image_loss_std 0.99 / train/model_loss_mean 3.55 /
train/model_loss_std 4.27 / train/model_opt_grad_norm 8.86 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7853.4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.26 / train/policy_entropy_mean -3.2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 7.82 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.2 / train/policy_logprob_min -7.81 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.8e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.81 / train/post_ent_max 50.81 / train/post_ent_mean 42.09 / 
train/post_ent_min 21.11 / train/post_ent_std 4.08 / train/prior_ent_mag 71.1 / train/prior_ent_max 71.1 / train/prior_ent_mean 45.86 / train/prior_ent_min 32.27 / train/prior_ent_std 4.39 / train/rep_loss_mean 3.79 / train/rep_loss_std 5.77 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.46 / train/reward_rate 0.41 /
train_stats/mean_log_entropy -3.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 6.05 / report/image_loss_mean 1.17 / report/image_loss_std 1.19 / report/model_loss_mean 3.69 / report/model_loss_std 4.63 / report/post_ent_mag 50.69 / report/post_ent_max 50.69 /
report/post_ent_mean 41.92 / report/post_ent_min 20.43 / report/post_ent_std 4.15 / report/prior_ent_mag 70.87 / report/prior_ent_max 70.87 / report/prior_ent_mean 45.75 / report/prior_ent_min 33.4 / report/prior_ent_std 4.64 / report/rep_loss_mean 3.84 / 
report/rep_loss_std 6.05 / report/reward_avg 0.4 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 8.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.4 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 9.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.16 / eval/dyn_loss_std 6.02 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.29 / eval/model_loss_mean 3.84 / eval/model_loss_std 4.64 / eval/post_ent_mag 48.93 / eval/post_ent_max 48.93 / eval/post_ent_mean 
41.92 / eval/post_ent_min 21.84 / eval/post_ent_std 3.66 / eval/prior_ent_mag 70.87 / eval/prior_ent_max 70.87 / eval/prior_ent_mean 45.98 / eval/prior_ent_min 35.18 / eval/prior_ent_std 3.78 / eval/rep_loss_mean 4.16 / eval/rep_loss_std 6.02 / eval/reward_avg 0.67 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.67 / eval/reward_rate 0.56 / 
replay/size 4.1e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3826 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 17.05 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1913 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1913 / timer/agent.train_total 244.06 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 411500 Counter(411500) 411437
Saved chunk: 20230922T062833F065134-3DLFHJ28dy4ANoZ6jxNRYt-0NBiEXgrbWsdBFSjb8w0Ft-1024.npz
eval_Episode has 500 steps and return 359.0.
Saved chunk: 20230922T062843F892725-2mA4NYfVmB5MAnDWLxuK8C-0xfBpBYw9J6lebOfBxCFp0-1024.npz
train_Episode has 500 steps and return 340.5.
Starting evaluation at step 412000 Counter(412000) 411937
eval_Episode has 500 steps and return 362.9.
train_Episode has 500 steps and return 0.2.
Starting evaluation at step 412500 Counter(412500) 412437
Saved chunk: 20230922T062952F762908-0NBiEXgrbWsdBFSjb8w0Ft-54TK53C4fxKTmTCmU6tV3O-1024.npz
eval_Episode has 500 steps and return 372.7.
Saved chunk: 20230922T063005F255223-0xfBpBYw9J6lebOfBxCFp0-07jJcJshMaDm8oQWLgPnGP-1024.npz
train_Episode has 500 steps and return 310.8.
Starting evaluation at step 413000 Counter(413000) 412937
eval_Episode has 500 steps and return 380.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T063126F106128-07jJcJshMaDm8oQWLgPnGP-0000000000000000000000-428.npz
Saved chunk: 20230922T063112F131689-54TK53C4fxKTmTCmU6tV3O-0000000000000000000000-729.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 336.1.
Starting evaluation at step 413500 Counter(413500) 413437
Saved chunk: 20230922T063112F131689-54TK53C4fxKTmTCmU6tV3O-6y5Z3IHZluXDtE7ZmWawi5-1024.npz
eval_Episode has 500 steps and return 355.9.
Saved chunk: 20230922T063126F106128-07jJcJshMaDm8oQWLgPnGP-45BgGNVjsOKlBGBvBxUbl8-1024.npz
train_Episode has 500 steps and return 302.0.
Starting evaluation at step 414000 Counter(414000) 413937
eval_Episode has 500 steps and return 371.2.
train_Episode has 500 steps and return 284.2.
Starting evaluation at step 414500 Counter(414500) 414437
Saved chunk: 20230922T063231F379141-6y5Z3IHZluXDtE7ZmWawi5-6PD9NPfYzDnwBM344M78ea-1024.npz
eval_Episode has 500 steps and return 358.9.
Saved chunk: 20230922T063246F922577-45BgGNVjsOKlBGBvBxUbl8-4ztZk36xhFekiapBfeAPmQ-1024.npz
train_Episode has 500 steps and return 323.0.
Starting evaluation at step 415000 Counter(415000) 414937
eval_Episode has 500 steps and return 371.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 830194 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 371.77 / eval_episode/reward_rate 0.61 / episode/length 500 / episode/score 322.98 / episode/reward_rate 0.52 / train/action_mag 3.56 / train/action_max 2.99 / train/action_mean 0.07 / train/action_min -3.52 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.75 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -1.94 / train/adv_mag 0.59 / train/adv_max 0.41 / train/adv_mean 
1.2e-3 / train/adv_min -0.57 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.82 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 7242.06 / train/extr_critic_mag 259.38 / train/extr_critic_max 259.38 / train/extr_critic_mean 249.69 / train/extr_critic_min 222.31 / train/extr_critic_std 6.18 / 
train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.73 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 260.02 / train/extr_return_raw_max 
260.02 / train/extr_return_raw_mean 249.72 / train/extr_return_raw_min 222.3 / train/extr_return_raw_std 6.24 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / 
train/image_loss_mean 1.05 / train/image_loss_std 1.02 / train/model_loss_mean 3.58 / train/model_loss_std 4.31 / train/model_opt_grad_norm 9.04 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 1.38 / train/policy_entropy_mean -3.21 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 7.97 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.2 / train/policy_logprob_min -7.97 / train/policy_logprob_std 1.53 / train/policy_randomness_mag 0.53 / train/policy_randomness_max 0.53 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.6e-5 / train/policy_randomness_std 
0.06 / train/post_ent_mag 50.75 / train/post_ent_max 50.75 / train/post_ent_mean 42 / train/post_ent_min 21.06 / train/post_ent_std 4.11 / train/prior_ent_mag 71.12 / train/prior_ent_max 71.12 / train/prior_ent_mean 45.79 / train/prior_ent_min 32.13 / 
train/prior_ent_std 4.46 / train/rep_loss_mean 3.82 / train/rep_loss_std 5.82 / train/reward_avg 0.46 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 
5.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.46 / train/reward_rate 0.41 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.29 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.2e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 5.23 / report/image_loss_mean 0.91 / report/image_loss_std 0.95 / 
report/model_loss_mean 3.41 / report/model_loss_std 4.02 / report/post_ent_mag 50.26 / report/post_ent_max 50.26 / report/post_ent_mean 42.68 / report/post_ent_min 24.23 / report/post_ent_std 3.52 / report/prior_ent_mag 71.13 / report/prior_ent_max 71.13 / 
report/prior_ent_mean 46.38 / report/prior_ent_min 32.43 / report/prior_ent_std 3.82 / report/rep_loss_mean 3.7 / report/rep_loss_std 5.23 / report/reward_avg 0.55 / report/reward_loss_mean 0.28 / report/reward_loss_std 0.34 / report/reward_max_data 2 / 
report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.5e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.55 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.5e-10 / 
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.38 / eval/dyn_loss_std 6.11 / eval/image_loss_mean 1.21 / eval/image_loss_std 1.57 / eval/model_loss_mean 4.16 
/ eval/model_loss_std 4.81 / eval/post_ent_mag 49.66 / eval/post_ent_max 49.66 / eval/post_ent_mean 41.77 / eval/post_ent_min 20.04 / eval/post_ent_std 3.79 / eval/prior_ent_mag 71.13 / eval/prior_ent_max 71.13 / eval/prior_ent_mean 45.94 / eval/prior_ent_min 38.13 / 
eval/prior_ent_std 3.97 / eval/rep_loss_mean 4.38 / eval/rep_loss_std 6.11 / eval/reward_avg 0.7 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.69 / eval/reward_rate 0.59 / replay/size 4.2e5 / replay/inserts 3770 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3770 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.02 / timer/replay._sample_frac 1.5 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / 
timer/agent.policy_count 7778 / timer/agent.policy_total 18.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1885 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1885 / timer/agent.train_total 240.47 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 321.7.
Starting evaluation at step 415500 Counter(415500) 415437
Saved chunk: 20230922T063350F198064-6PD9NPfYzDnwBM344M78ea-6iTNqDHSZzBaz9O6LAD0ck-1024.npz
eval_Episode has 500 steps and return 374.0.
Saved chunk: 20230922T063407F227344-4ztZk36xhFekiapBfeAPmQ-0BxtwwWcM9EJaX0IOi6A6S-1024.npz
train_Episode has 500 steps and return 324.1.
Starting evaluation at step 416000 Counter(416000) 415937
eval_Episode has 500 steps and return 359.1.
train_Episode has 500 steps and return 321.5.
Starting evaluation at step 416500 Counter(416500) 416437
Saved chunk: 20230922T063510F020872-6iTNqDHSZzBaz9O6LAD0ck-5fd77OCBeHcxy1lDjzUigG-1024.npz
eval_Episode has 500 steps and return 374.9.
Saved chunk: 20230922T063528F807792-0BxtwwWcM9EJaX0IOi6A6S-32ygDz7rPhrTvFbUWqkJsl-1024.npz
train_Episode has 500 steps and return 325.8.
Starting evaluation at step 417000 Counter(417000) 416937
eval_Episode has 500 steps and return 394.8.
train_Episode has 500 steps and return 329.5.
Starting evaluation at step 417500 Counter(417500) 417437
Saved chunk: 20230922T063629F248994-5fd77OCBeHcxy1lDjzUigG-64eAy3bX0IpUXYQQbR1ZcV-1024.npz
eval_Episode has 500 steps and return 384.9.
Saved chunk: 20230922T063649F475236-32ygDz7rPhrTvFbUWqkJsl-7I8GpuLyTnID4wza1TuXtI-1024.npz
train_Episode has 500 steps and return 339.2.
Starting evaluation at step 418000 Counter(418000) 417937
eval_Episode has 500 steps and return 376.9.
train_Episode has 500 steps and return 335.3.
Starting evaluation at step 418500 Counter(418500) 418437
Saved chunk: 20230922T063748F072519-64eAy3bX0IpUXYQQbR1ZcV-7EriLFovrXQwwKK2I3OSgO-1024.npz
eval_Episode has 500 steps and return 385.1.
Saved chunk: 20230922T063809F779498-7I8GpuLyTnID4wza1TuXtI-4FCn0ejv6ufwHeFEQVN3lO-1024.npz
train_Episode has 500 steps and return 337.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 837850 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 337.01 / episode/reward_rate 0.57 / eval_episode/length 500 / eval_episode/score 385.12 / eval_episode/reward_rate 0.62 / train/action_mag 3.58 / train/action_max 3 / train/action_mean 0.06 / train/action_min -3.55 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.72 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -22 / train/adv_mag 0.58 / train/adv_max 0.41 / train/adv_mean 3.2e-3 / train/adv_min 
-0.55 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9.2e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.81 / train/dyn_loss_std 5.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 8158.82 / train/extr_critic_mag 260.89 / train/extr_critic_max 260.89 / train/extr_critic_mean 251.5 / train/extr_critic_min 223.41 / train/extr_critic_std 6.1 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.76 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 261.63 / train/extr_return_raw_max 261.63 / train/extr_return_raw_mean 251.56 / train/extr_return_raw_min 
223.33 / train/extr_return_raw_std 6.14 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.04 / train/image_loss_std 1.01 / train/model_loss_mean 3.56 /
train/model_loss_std 4.29 / train/model_opt_grad_norm 9.49 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.28 / train/policy_entropy_mean -3.21 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.57 / train/policy_logprob_mag 7.83 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.21 / train/policy_logprob_min -7.83 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.4e-5 / train/policy_randomness_std 0.06 / train/post_ent_mag 50.64 / train/post_ent_max 50.64 / train/post_ent_mean 42.03 / 
train/post_ent_min 21.03 / train/post_ent_std 4.03 / train/prior_ent_mag 71.07 / train/prior_ent_max 71.07 / train/prior_ent_mean 45.81 / train/prior_ent_min 32.6 / train/prior_ent_std 4.39 / train/rep_loss_mean 3.81 / train/rep_loss_std 5.78 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.47 / train/reward_rate 0.42 /
train_stats/mean_log_entropy -3.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 6.46 / report/image_loss_mean 1.2 / report/image_loss_std 1.11 / report/model_loss_mean 3.66 / report/model_loss_std 4.67 / report/post_ent_mag 50.86 / report/post_ent_max 50.86 / 
report/post_ent_mean 41.53 / report/post_ent_min 20.12 / report/post_ent_std 4.65 / report/prior_ent_mag 71.29 / report/prior_ent_max 71.29 / report/prior_ent_mean 45.38 / report/prior_ent_min 29.23 / report/prior_ent_std 4.85 / report/rep_loss_mean 3.81 / 
report/rep_loss_std 6.46 / report/reward_avg 0.35 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.34 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.98 / eval/dyn_loss_std 5.83 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.38 / eval/model_loss_mean 3.77 / eval/model_loss_std 4.54 / eval/post_ent_mag 48.45 / eval/post_ent_max 48.45 / eval/post_ent_mean 
41.83 / eval/post_ent_min 19.85 / eval/post_ent_std 3.74 / eval/prior_ent_mag 71.29 / eval/prior_ent_max 71.29 / eval/prior_ent_mean 45.79 / eval/prior_ent_min 36.12 / eval/prior_ent_std 3.88 / eval/rep_loss_mean 3.98 / eval/rep_loss_std 5.83 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.71 / eval/reward_rate 0.59 / 
replay/size 4.2e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3828 / timer/env.step_total 19.97 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 460.25 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7335 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1914 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1914 / timer/agent.train_total 243.95 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 419000 Counter(419000) 418937
eval_Episode has 500 steps and return 370.9.
train_Episode has 500 steps and return 311.7.
Starting evaluation at step 419500 Counter(419500) 419437
Saved chunk: 20230922T063906F702680-7EriLFovrXQwwKK2I3OSgO-2m6ReTeeF0eIRcQJwV636a-1024.npz
eval_Episode has 500 steps and return 378.1.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063929F955761-4FCn0ejv6ufwHeFEQVN3lO-3TBPbN9vnGEcEeyrK0NeIu-1024.npz
Starting evaluation at step 420000 Counter(420000) 419937
eval_Episode has 500 steps and return 385.0.
train_Episode has 500 steps and return 333.8.
Starting evaluation at step 420500 Counter(420500) 420437
eval_Episode has 500 steps and return 364.3.
Saved chunk: 20230922T064026F743276-2m6ReTeeF0eIRcQJwV636a-5kACMlZTKxbYL6eJCmpLRu-1024.npz
train_Episode has 500 steps and return 327.3.
Saved chunk: 20230922T064051F756620-3TBPbN9vnGEcEeyrK0NeIu-1TP43S8wMHmH3ALupJpES2-1024.npz
Starting evaluation at step 421000 Counter(421000) 420937
eval_Episode has 500 steps and return 390.1.
train_Episode has 500 steps and return 319.7.
Starting evaluation at step 421500 Counter(421500) 421437
eval_Episode has 500 steps and return 384.7.
Saved chunk: 20230922T064145F783189-5kACMlZTKxbYL6eJCmpLRu-0d8wVkpR8p0MxtWyrJWMaD-1024.npz
train_Episode has 500 steps and return 279.8.
Saved chunk: 20230922T064212F238332-1TP43S8wMHmH3ALupJpES2-5H8ePU5jaT5HDxFgFHbD6d-1024.npz
Starting evaluation at step 422000 Counter(422000) 421937
eval_Episode has 500 steps and return 395.7.
train_Episode has 500 steps and return 344.9.
Starting evaluation at step 422500 Counter(422500) 422437
eval_Episode has 500 steps and return 347.5.
Saved chunk: 20230922T064304F607593-0d8wVkpR8p0MxtWyrJWMaD-5iwZcmVTr650ykuH6QV5U5-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 845410 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 347.46 / eval_episode/reward_rate 0.57 / episode/length 500 / episode/score 344.95 / episode/reward_rate 0.6 / train/action_mag 3.55 / train/action_max 3.05 / train/action_mean 0.06 / train/action_min -3.5 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.61 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -5.24 / train/adv_mag 0.59 / train/adv_max 0.43 / train/adv_mean 1.5e-3 / train/adv_min
-0.54 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.82 / train/dyn_loss_std 5.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 9053.11 / train/extr_critic_mag 262.5 / train/extr_critic_max 262.5 / train/extr_critic_mean 252.78 / train/extr_critic_min 222.27 / train/extr_critic_std 6.46 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.67 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 263.15 / train/extr_return_raw_max 263.15 / train/extr_return_raw_mean 252.81 / train/extr_return_raw_min 
223.39 / train/extr_return_raw_std 6.52 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.06 / train/image_loss_std 1.05 / train/model_loss_mean 3.58 /
train/model_loss_std 4.37 / train/model_opt_grad_norm 9.74 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.69 / train/policy_entropy_mean -3.2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.2 / train/policy_logprob_min -7.9 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.3e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.66 / train/post_ent_max 50.66 / train/post_ent_mean 41.92 / 
train/post_ent_min 20.7 / train/post_ent_std 4.12 / train/prior_ent_mag 71.12 / train/prior_ent_max 71.12 / train/prior_ent_mean 45.7 / train/prior_ent_min 31.89 / train/prior_ent_std 4.47 / train/rep_loss_mean 3.82 / train/rep_loss_std 5.87 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.32 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.46 / train/reward_rate 0.42 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.23 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 6.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.15 / report/image_loss_mean 1.07 / report/image_loss_std 0.89 / report/model_loss_mean 3.56 / report/model_loss_std 4.39 / report/post_ent_mag 51.12 / report/post_ent_max 51.12 /
report/post_ent_mean 41.89 / report/post_ent_min 21.19 / report/post_ent_std 4.23 / report/prior_ent_mag 71.02 / report/prior_ent_max 71.02 / report/prior_ent_mean 45.75 / report/prior_ent_min 34.14 / report/prior_ent_std 4.49 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 6.15 / report/reward_avg 0.39 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.39 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 7.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.1 / eval/dyn_loss_std 7.23 / eval/image_loss_mean 1.47 / eval/image_loss_std 2.22 / eval/model_loss_mean 4.82 / eval/model_loss_std 6.08 / eval/post_ent_mag 50.26 / eval/post_ent_max 50.26 / eval/post_ent_mean 41.46 / 
eval/post_ent_min 20.2 / eval/post_ent_std 4.45 / eval/prior_ent_mag 71.02 / eval/prior_ent_max 71.02 / eval/prior_ent_mean 45.91 / eval/prior_ent_min 36.6 / eval/prior_ent_std 4.11 / eval/rep_loss_mean 5.1 / eval/rep_loss_std 7.23 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.63 / eval/reward_rate 0.53 / 
replay/size 4.2e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3780 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.22 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7788 / timer/agent.policy_total 17.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 
/ timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1890 / timer/agent.train_total 240.84 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 302.5.
Saved chunk: 20230922T064332F548161-5H8ePU5jaT5HDxFgFHbD6d-1HBI3KUSSpAqtUSq4i7CyM-1024.npz
Starting evaluation at step 423000 Counter(423000) 422937
eval_Episode has 500 steps and return 332.0.
train_Episode has 500 steps and return 333.6.
Starting evaluation at step 423500 Counter(423500) 423437
eval_Episode has 500 steps and return 318.3.
train_Episode has 500 steps and return 334.8.
Saved chunk: 20230922T064453F732922-1HBI3KUSSpAqtUSq4i7CyM-5c3ov49x5wOcTzjOT5rfZT-1024.npz
Starting evaluation at step 424000 Counter(424000) 423937
Saved chunk: 20230922T064423F182823-5iwZcmVTr650ykuH6QV5U5-1rIyGCAN97j2YoRtA7731l-1024.npz
eval_Episode has 500 steps and return 359.9.
train_Episode has 500 steps and return 300.3.
Starting evaluation at step 424500 Counter(424500) 424437
eval_Episode has 500 steps and return 385.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T064614F560414-5c3ov49x5wOcTzjOT5rfZT-0000000000000000000000-664.npz
Saved chunk: 20230922T064619F277305-1rIyGCAN97j2YoRtA7731l-0000000000000000000000-988.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 329.6.
Saved chunk: 20230922T064614F560414-5c3ov49x5wOcTzjOT5rfZT-3IBMPMP3R3V5VHWNp0M4NS-1024.npz
Starting evaluation at step 425000 Counter(425000) 424937
Saved chunk: 20230922T064619F277305-1rIyGCAN97j2YoRtA7731l-1cKQlvTNVFGyGarptOg6rz-1024.npz
eval_Episode has 500 steps and return 374.6.
train_Episode has 500 steps and return 335.0.
Starting evaluation at step 425500 Counter(425500) 425437
eval_Episode has 500 steps and return 363.3.
train_Episode has 500 steps and return 329.8.
Saved chunk: 20230922T064735F357033-3IBMPMP3R3V5VHWNp0M4NS-61Iih4sUKod8nMjFXyr45M-1024.npz
Starting evaluation at step 426000 Counter(426000) 425937
Saved chunk: 20230922T064738F482541-1cKQlvTNVFGyGarptOg6rz-3tU5YkegMTMDqXJqv400pU-1024.npz
eval_Episode has 500 steps and return 376.0.
train_Episode has 500 steps and return 330.3.
Starting evaluation at step 426500 Counter(426500) 426437
eval_Episode has 500 steps and return 374.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 853002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 330.28 / episode/reward_rate 0.53 / eval_episode/length 500 / eval_episode/score 373.99 / eval_episode/reward_rate 0.66 / train/action_mag 3.7 / train/action_max 3.13 / train/action_mean 0.06 / train/action_min -3.65 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.53 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -0.59 / train/adv_mag 0.79 / train/adv_max 0.7 / train/adv_mean 1e-3 / train/adv_min 
-0.46 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 8.5e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.79 / train/dyn_loss_std 5.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 9310.18 / train/extr_critic_mag 262.96 / train/extr_critic_max 262.96 / train/extr_critic_mean 253.05 / train/extr_critic_min 212.19 / train/extr_critic_std 7.14 / train/extr_return_normed_mag 1.21 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.68 / train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 263.64 / train/extr_return_raw_max 263.64 / train/extr_return_raw_mean 253.08 / train/extr_return_raw_min 
220.26 / train/extr_return_raw_std 7.18 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.04 / train/image_loss_std 1.01 / train/model_loss_mean 3.54 /
train/model_loss_std 4.3 / train/model_opt_grad_norm 9.13 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.34 / train/policy_entropy_mean -3.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.61 / train/policy_logprob_mag 7.9 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.18 / train/policy_logprob_min -7.9 / train/policy_logprob_std 1.54 / 
train/policy_randomness_mag 0.53 / train/policy_randomness_max 0.53 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.2e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.58 / train/post_ent_max 50.58 / train/post_ent_mean 41.93 / 
train/post_ent_min 21 / train/post_ent_std 4.12 / train/prior_ent_mag 71.06 / train/prior_ent_max 71.06 / train/prior_ent_mean 45.69 / train/prior_ent_min 32.06 / train/prior_ent_std 4.5 / train/rep_loss_mean 3.79 / train/rep_loss_std 5.81 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.47 / train/reward_rate 
0.42 / train_stats/mean_log_entropy -3.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.79 / report/dyn_loss_std 5.78 / report/image_loss_mean 0.94 / report/image_loss_std 0.84 / report/model_loss_mean 3.49 / report/model_loss_std 4.13 / report/post_ent_mag 51.14 / report/post_ent_max 51.14 /
report/post_ent_mean 42.57 / report/post_ent_min 20.44 / report/post_ent_std 3.57 / report/prior_ent_mag 70.79 / report/prior_ent_max 70.79 / report/prior_ent_mean 46.26 / report/prior_ent_min 37.41 / report/prior_ent_std 4 / report/rep_loss_mean 3.79 / 
report/rep_loss_std 5.78 / report/reward_avg 0.56 / report/reward_loss_mean 0.28 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.56 / report/reward_rate 0.51 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4 / eval/dyn_loss_std 5.56 / eval/image_loss_mean 0.94 / eval/image_loss_std 0.91 / eval/model_loss_mean 3.69 / eval/model_loss_std 4.08 / eval/post_ent_mag 48.83 / eval/post_ent_max 48.83 / eval/post_ent_mean 
42.04 / eval/post_ent_min 19.88 / eval/post_ent_std 3.33 / eval/prior_ent_mag 70.79 / eval/prior_ent_max 70.79 / eval/prior_ent_mean 45.97 / eval/prior_ent_min 40.28 / eval/prior_ent_std 3.75 / eval/rep_loss_mean 4 / eval/rep_loss_std 5.56 / eval/reward_avg 0.74 / 
eval/reward_loss_mean 0.36 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.73 / eval/reward_rate 0.64 / 
replay/size 4.3e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 4.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.93 / timer/env.step_count 3796 / timer/env.step_total 19.75 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.38 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.8e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7804 / timer/agent.policy_total 18.23 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1898 / timer/agent.train_total 242.43 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 334.7.
Starting evaluation at step 427000 Counter(427000) 426937
Saved chunk: 20230922T064857F301587-3tU5YkegMTMDqXJqv400pU-79M5gPp8XyZr1WCreJ0yhf-1024.npz
eval_Episode has 500 steps and return 369.4.
Saved chunk: 20230922T064855F746772-61Iih4sUKod8nMjFXyr45M-6Inevv4Wlhg2UxxLvM6jgN-1024.npz
train_Episode has 500 steps and return 340.8.
Starting evaluation at step 427500 Counter(427500) 427437
eval_Episode has 500 steps and return 386.5.
train_Episode has 500 steps and return 339.9.
Starting evaluation at step 428000 Counter(428000) 427937
Saved chunk: 20230922T065017F223004-79M5gPp8XyZr1WCreJ0yhf-583YkP6eIvgZaaL3QT0lCM-1024.npz
eval_Episode has 500 steps and return 343.8.
Saved chunk: 20230922T065020F846746-6Inevv4Wlhg2UxxLvM6jgN-5RgHgG92Dm9qfbl4pm5MRM-1024.npz
train_Episode has 500 steps and return 359.4.
Starting evaluation at step 428500 Counter(428500) 428437
eval_Episode has 500 steps and return 359.1.
train_Episode has 500 steps and return 295.0.
Starting evaluation at step 429000 Counter(429000) 428937
Saved chunk: 20230922T065136F390162-583YkP6eIvgZaaL3QT0lCM-6v1Fghpvi4WQNSX9kqpPHw-1024.npz
eval_Episode has 500 steps and return 383.1.
Saved chunk: 20230922T065141F548089-5RgHgG92Dm9qfbl4pm5MRM-5GTRZnODt5lEfUlyw9w35B-1024.npz
train_Episode has 500 steps and return 309.8.
Starting evaluation at step 429500 Counter(429500) 429437
eval_Episode has 500 steps and return 365.2.
train_Episode has 500 steps and return 286.2.
Starting evaluation at step 430000 Counter(430000) 429937
Saved chunk: 20230922T065255F235871-6v1Fghpvi4WQNSX9kqpPHw-3OiJc3PMkG8jsrLwtsO4QM-1024.npz
eval_Episode has 500 steps and return 367.6.
Saved chunk: 20230922T065301F926164-5GTRZnODt5lEfUlyw9w35B-0EuB1FQPe9b3OrGy2SE7Ob-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 860654 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 286.21 / episode/reward_rate 0.48 / eval_episode/length 500 / eval_episode/score 367.62 / eval_episode/reward_rate 0.62 / train/action_mag 3.68 / train/action_max 3.1 / train/action_mean 0.06 / train/action_min -3.65 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.53 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -0.73 / train/adv_mag 0.64 / train/adv_max 0.55 / train/adv_mean 1e-3 / train/adv_min 
-0.47 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.83 / train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 9642.96 / train/extr_critic_mag 263.55 / train/extr_critic_max 263.55 / train/extr_critic_mean 253.36 / train/extr_critic_min 211.67 / train/extr_critic_std 8.06 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.68 / train/extr_return_normed_min -0.68 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 264.2 / train/extr_return_raw_max 264.2 / train/extr_return_raw_mean 253.38 / train/extr_return_raw_min 
216.52 / train/extr_return_raw_std 8.12 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.06 / train/image_loss_std 1.05 / train/model_loss_mean 3.59 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 8.69 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7617.8 / train/policy_entropy_mag 3.54 / 
train/policy_entropy_max 1.59 / train/policy_entropy_mean -3.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 8.11 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.16 / train/policy_logprob_min -8.11 / 
train/policy_logprob_std 1.55 / train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.2e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.75 / train/post_ent_max 50.75 / 
train/post_ent_mean 41.92 / train/post_ent_min 21 / train/post_ent_std 4.1 / train/prior_ent_mag 71.02 / train/prior_ent_max 71.02 / train/prior_ent_mean 45.71 / train/prior_ent_min 32.14 / train/prior_ent_std 4.46 / train/rep_loss_mean 3.83 / train/rep_loss_std 5.84 / 
train/reward_avg 0.46 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.46 / 
train/reward_rate 0.41 / train_stats/mean_log_entropy -3.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 6.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 5.4 / report/image_loss_mean 0.98 / report/image_loss_std 0.82 / report/model_loss_mean 3.5 / report/model_loss_std 3.87 / report/post_ent_mag 50.12 / 
report/post_ent_max 50.12 / report/post_ent_mean 42.1 / report/post_ent_min 17.59 / report/post_ent_std 3.91 / report/prior_ent_mag 70.98 / report/prior_ent_max 70.98 / report/prior_ent_mean 46.01 / report/prior_ent_min 32.54 / report/prior_ent_std 4.11 / 
report/rep_loss_mean 3.81 / report/rep_loss_std 5.4 / report/reward_avg 0.5 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.5 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-11 / eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.65 / eval/dyn_loss_std 5.05 / eval/image_loss_mean 0.87 / eval/image_loss_std 0.78 / eval/model_loss_mean 3.39 / eval/model_loss_std 3.71 / eval/post_ent_mag 49.2 / eval/post_ent_max
49.2 / eval/post_ent_mean 42.43 / eval/post_ent_min 23.19 / eval/post_ent_std 3 / eval/prior_ent_mag 70.98 / eval/prior_ent_max 70.98 / eval/prior_ent_mean 45.97 / eval/prior_ent_min 40.35 / eval/prior_ent_std 3.64 / eval/rep_loss_mean 3.65 / eval/rep_loss_std 5.05 / 
eval/reward_avg 0.71 / eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.7 / 
eval/reward_rate 0.6 / replay/size 4.3e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 4.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3826 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 466.19 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.8e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 
/ timer/agent.policy_max 0.18 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1913 / 
timer/agent.train_total 243.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 311.4.
Starting evaluation at step 430500 Counter(430500) 430437
eval_Episode has 500 steps and return 340.7.
train_Episode has 500 steps and return 309.0.
Starting evaluation at step 431000 Counter(431000) 430937
Saved chunk: 20230922T065414F013298-3OiJc3PMkG8jsrLwtsO4QM-5M50Q3IIO1QQ4deMY58FYA-1024.npz
eval_Episode has 500 steps and return 361.0.
Saved chunk: 20230922T065422F257740-0EuB1FQPe9b3OrGy2SE7Ob-0xLt5GycjHuvwisQrbFgu8-1024.npz
train_Episode has 500 steps and return 337.0.
Starting evaluation at step 431500 Counter(431500) 431437
eval_Episode has 500 steps and return 389.2.
train_Episode has 500 steps and return 344.4.
Starting evaluation at step 432000 Counter(432000) 431937
Saved chunk: 20230922T065534F046014-5M50Q3IIO1QQ4deMY58FYA-5gOMQFtxyoHxWIVXUzCFLe-1024.npz
eval_Episode has 500 steps and return 376.4.
Saved chunk: 20230922T065543F897833-0xLt5GycjHuvwisQrbFgu8-1EIwtHkTXPOlsdx7hC2Him-1024.npz
train_Episode has 500 steps and return 347.5.
Starting evaluation at step 432500 Counter(432500) 432437
eval_Episode has 500 steps and return 365.2.
train_Episode has 500 steps and return 321.6.
Starting evaluation at step 433000 Counter(433000) 432937
Saved chunk: 20230922T065653F154582-5gOMQFtxyoHxWIVXUzCFLe-1HoSwCuO6u3rRnydxOlWb9-1024.npz
eval_Episode has 500 steps and return 369.1.
Saved chunk: 20230922T065704F592166-1EIwtHkTXPOlsdx7hC2Him-3qEhgJd7IvwrbAgk96ytD5-1024.npz
train_Episode has 500 steps and return 333.7.
Starting evaluation at step 433500 Counter(433500) 433437
eval_Episode has 500 steps and return 379.1.
train_Episode has 500 steps and return 305.9.
Starting evaluation at step 434000 Counter(434000) 433937
Saved chunk: 20230922T065812F071735-1HoSwCuO6u3rRnydxOlWb9-76Jed2PC6NqGzBvJyuHjne-1024.npz
eval_Episode has 500 steps and return 380.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 868202 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 305.85 / episode/reward_rate 0.51 / eval_episode/length 500 / eval_episode/score 380.49 / eval_episode/reward_rate 0.62 / train/action_mag 3.69 / train/action_max 3.17 / train/action_mean 0.06 / train/action_min -3.62 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.48 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -3.59 / train/adv_mag 2.02 / train/adv_max 2 / train/adv_mean 1.3e-3 /
train/adv_min -0.4 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 8.5e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 5.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 264.23 / train/extr_critic_max 264.23 / train/extr_critic_mean 254.03 / train/extr_critic_min 174.42 / train/extr_critic_std 8.72 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 264.85 / train/extr_return_raw_max 264.85 / train/extr_return_raw_mean 254.07 / train/extr_return_raw_min 
214.93 / train/extr_return_raw_std 8.7 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.03 / train/image_loss_std 0.99 / train/model_loss_mean 3.53 / 
train/model_loss_std 4.27 / train/model_opt_grad_norm 9.46 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9761.9 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.53 / train/policy_entropy_mean -3.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.63 / train/policy_logprob_mag 7.93 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.16 / train/policy_logprob_min -7.93 / 
train/policy_logprob_std 1.55 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.5e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.84 / train/post_ent_max 50.84 / 
train/post_ent_mean 42 / train/post_ent_min 21.21 / train/post_ent_std 4.08 / train/prior_ent_mag 71.05 / train/prior_ent_max 71.05 / train/prior_ent_mean 45.75 / train/prior_ent_min 32.12 / train/prior_ent_std 4.48 / train/rep_loss_mean 3.78 / train/rep_loss_std 5.78 /
train/reward_avg 0.47 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.47 / 
train/reward_rate 0.42 / train_stats/mean_log_entropy -3.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 5.6 / report/image_loss_mean 0.97 / report/image_loss_std 0.98 / report/model_loss_mean 3.36 / report/model_loss_std 4.19 / report/post_ent_mag 52.13
/ report/post_ent_max 52.13 / report/post_ent_mean 42.31 / report/post_ent_min 19.98 / report/post_ent_std 4.09 / report/prior_ent_mag 71.06 / report/prior_ent_max 71.06 / report/prior_ent_mean 45.85 / report/prior_ent_min 31.35 / report/prior_ent_std 4.75 / 
report/rep_loss_mean 3.54 / report/rep_loss_std 5.6 / report/reward_avg 0.53 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 0.01 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.53 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 6.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.81 / eval/dyn_loss_std 5.33 / eval/image_loss_mean 0.94 / eval/image_loss_std 0.98 / eval/model_loss_mean 3.56 / eval/model_loss_std 4.02 / eval/post_ent_mag 49.94 / eval/post_ent_max 
49.94 / eval/post_ent_mean 42.03 / eval/post_ent_min 21.36 / eval/post_ent_std 3.22 / eval/prior_ent_mag 71.06 / eval/prior_ent_max 71.06 / eval/prior_ent_mean 45.81 / eval/prior_ent_min 32.01 / eval/prior_ent_std 3.77 / eval/rep_loss_mean 3.81 / eval/rep_loss_std 5.33 
/ eval/reward_avg 0.71 / eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.71 / 
eval/reward_rate 0.6 / replay/size 4.3e5 / replay/inserts 3774 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3774 / timer/env.step_total 19.54 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.47 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.4e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7782 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 
/ timer/agent.policy_max 0.02 / timer/dataset_train_count 1887 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1887 / 
timer/agent.train_total 241 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / 
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.15

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T065825F007468-3qEhgJd7IvwrbAgk96ytD5-6jJbH7Jzy83dewuhnHLEtn-1024.npz
train_Episode has 500 steps and return 331.2.
Starting evaluation at step 434500 Counter(434500) 434437
eval_Episode has 500 steps and return 344.6.
train_Episode has 500 steps and return 302.1.
Starting evaluation at step 435000 Counter(435000) 434937
Saved chunk: 20230922T065930F877162-76Jed2PC6NqGzBvJyuHjne-52x7Iz7amMCTwXq3ybhG9H-1024.npz
eval_Episode has 500 steps and return 371.7.
Saved chunk: 20230922T065946F363274-6jJbH7Jzy83dewuhnHLEtn-0UMa6pRmhrYDeHq58te0Kl-1024.npz
train_Episode has 500 steps and return 338.0.
Starting evaluation at step 435500 Counter(435500) 435437
eval_Episode has 500 steps and return 383.8.
train_Episode has 500 steps and return 353.2.
Starting evaluation at step 436000 Counter(436000) 435937
Saved chunk: 20230922T070050F957372-52x7Iz7amMCTwXq3ybhG9H-7pzEF8bHshIarj0pNOxfNY-1024.npz
eval_Episode has 500 steps and return 346.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T070107F075472-0UMa6pRmhrYDeHq58te0Kl-0000000000000000000000-900.npz
Saved chunk: 20230922T070209F904036-7pzEF8bHshIarj0pNOxfNY-0000000000000000000000-223.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T070107F075472-0UMa6pRmhrYDeHq58te0Kl-3sEj0I7zHlmJ4DjwY3CpCG-1024.npz
train_Episode has 500 steps and return 320.0.
Starting evaluation at step 436500 Counter(436500) 436437
eval_Episode has 500 steps and return 331.8.
train_Episode has 500 steps and return 328.3.
Starting evaluation at step 437000 Counter(437000) 436937
Saved chunk: 20230922T070209F904036-7pzEF8bHshIarj0pNOxfNY-28vu3scW9T75d9CZNDlFac-1024.npz
eval_Episode has 500 steps and return 358.5.
Saved chunk: 20230922T070227F701214-3sEj0I7zHlmJ4DjwY3CpCG-2iaZek1NHVyzxvFOi1vTn6-1024.npz
train_Episode has 500 steps and return 325.4.
Starting evaluation at step 437500 Counter(437500) 437437
eval_Episode has 500 steps and return 375.7.
train_Episode has 500 steps and return 344.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 875862 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 344.26 / episode/reward_rate 0.58 / eval_episode/length 500 / eval_episode/score 375.66 / eval_episode/reward_rate 0.63 / train/action_mag 3.61 / train/action_max 3.19 / train/action_mean 0.06 / train/action_min -3.53 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.47 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -2.34 / train/adv_mag 1.18 / train/adv_max 1.11 / train/adv_mean 
1.2e-3 / train/adv_min -0.48 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.79 / train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 264.99 / train/extr_critic_max 264.99 / train/extr_critic_mean 254.92 / train/extr_critic_min 195.2 / train/extr_critic_std 8.46 / train/extr_return_normed_mag 
1.4 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.68 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 265.66 / train/extr_return_raw_max 265.66 / 
train/extr_return_raw_mean 254.96 / train/extr_return_raw_min 214.48 / train/extr_return_raw_std 8.47 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 
1.03 / train/image_loss_std 1 / train/model_loss_mean 3.54 / train/model_loss_std 4.27 / train/model_opt_grad_norm 9.25 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
7382.2 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.62 / train/policy_entropy_mean -3.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.64 / train/policy_logprob_mag 8.16 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.15 / 
train/policy_logprob_min -8.16 / train/policy_logprob_std 1.55 / train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 2.8e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.66 / 
train/post_ent_max 50.66 / train/post_ent_mean 41.94 / train/post_ent_min 21.02 / train/post_ent_std 4.08 / train/prior_ent_mag 70.95 / train/prior_ent_max 70.95 / train/prior_ent_mean 45.7 / train/prior_ent_min 32.6 / train/prior_ent_std 4.47 / train/rep_loss_mean 3.79
/ train/rep_loss_std 5.77 / train/reward_avg 0.48 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 6.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 
0.55 / train/reward_pred 0.48 / train/reward_rate 0.43 / train_stats/mean_log_entropy -3.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.53 / report/dyn_loss_std 5.3 / report/image_loss_mean 0.97 / report/image_loss_std 0.84 / report/model_loss_mean 3.36 / report/model_loss_std 3.91 / 
report/post_ent_mag 52.5 / report/post_ent_max 52.5 / report/post_ent_mean 42.62 / report/post_ent_min 23.69 / report/post_ent_std 3.46 / report/prior_ent_mag 71.17 / report/prior_ent_max 71.17 / report/prior_ent_mean 46.27 / report/prior_ent_min 29.67 / 
report/prior_ent_std 3.95 / report/rep_loss_mean 3.53 / report/rep_loss_std 5.3 / report/reward_avg 0.55 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / 
report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.55 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.16 / eval/dyn_loss_std 6.05 / eval/image_loss_mean 1.1 / eval/image_loss_std 1.27 / eval/model_loss_mean 3.88 / eval/model_loss_std 4.54 / eval/post_ent_mag 
49.11 / eval/post_ent_max 49.11 / eval/post_ent_mean 40.37 / eval/post_ent_min 19.85 / eval/post_ent_std 6.03 / eval/prior_ent_mag 71.17 / eval/prior_ent_max 71.17 / eval/prior_ent_mean 44.56 / eval/prior_ent_min 23.12 / eval/prior_ent_std 6.69 / eval/rep_loss_mean 4.16
/ eval/rep_loss_std 6.05 / eval/reward_avg 0.68 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / 
eval/reward_pred 0.67 / eval/reward_rate 0.54 / replay/size 4.4e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3830 / timer/env.step_total 19.92
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.09 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7337 / 
timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / 
timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / 
timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 438000 Counter(438000) 437937
Saved chunk: 20230922T070328F741006-28vu3scW9T75d9CZNDlFac-1UlmkGhaSY6IVpO8w2JgZA-1024.npz
eval_Episode has 500 steps and return 379.7.
Saved chunk: 20230922T070347F845546-2iaZek1NHVyzxvFOi1vTn6-7L8bOzMQsu1uVNTgWtEtQe-1024.npz
train_Episode has 500 steps and return 322.8.
Starting evaluation at step 438500 Counter(438500) 438437
eval_Episode has 500 steps and return 372.3.
train_Episode has 500 steps and return 318.0.
Starting evaluation at step 439000 Counter(439000) 438937
Saved chunk: 20230922T070448F361958-1UlmkGhaSY6IVpO8w2JgZA-2imQw1hUCIGRviLl0KdMLo-1024.npz
eval_Episode has 500 steps and return 358.5.
Saved chunk: 20230922T070509F285281-7L8bOzMQsu1uVNTgWtEtQe-3ZO7IBTRUOAP4tX4wnhMiZ-1024.npz
train_Episode has 500 steps and return 332.9.
Starting evaluation at step 439500 Counter(439500) 439437
eval_Episode has 500 steps and return 379.0.
train_Episode has 500 steps and return 331.1.
Starting evaluation at step 440000 Counter(440000) 439937
Saved chunk: 20230922T070607F617801-2imQw1hUCIGRviLl0KdMLo-3MWhQqUVNxn43JBMHhyFUb-1024.npz
eval_Episode has 500 steps and return 358.4.
Saved chunk: 20230922T070629F992731-3ZO7IBTRUOAP4tX4wnhMiZ-3yubUkL1YmcJFvQR63yclz-1024.npz
train_Episode has 500 steps and return 342.9.
Starting evaluation at step 440500 Counter(440500) 440437
eval_Episode has 500 steps and return 341.3.
train_Episode has 500 steps and return 329.7.
Starting evaluation at step 441000 Counter(441000) 440937
Saved chunk: 20230922T070726F506623-3MWhQqUVNxn43JBMHhyFUb-6m7ge9M1sxvUBBS58slK81-1024.npz
eval_Episode has 500 steps and return 376.2.
Saved chunk: 20230922T070750F341414-3yubUkL1YmcJFvQR63yclz-2dO14rM9zhDi4dxBP3uZqC-1024.npz
train_Episode has 500 steps and return 325.7.
Starting evaluation at step 441500 Counter(441500) 441437
eval_Episode has 500 steps and return 359.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 883418 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 359.01 / eval_episode/reward_rate 0.59 / episode/length 500 / episode/score 325.65 / episode/reward_rate 0.54 / train/action_mag 3.67 / train/action_max 3.2 / train/action_mean 0.06 / train/action_min -3.6 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.43 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -8.55 / train/adv_mag 1.46 / train/adv_max 1.41 / train/adv_mean 1.8e-3 / train/adv_min
-0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.76 / train/dyn_loss_std 5.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 265.6 / train/extr_critic_max 265.6 / train/extr_critic_mean 255.39 / train/extr_critic_min 185.05 / train/extr_critic_std 9.04 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.73 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 266.25 / train/extr_return_raw_max 266.25 / train/extr_return_raw_mean 255.46 / train/extr_return_raw_min 
214.82 / train/extr_return_raw_std 8.92 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.01 / train/image_loss_std 0.98 / train/model_loss_mean 3.5 / 
train/model_loss_std 4.24 / train/model_opt_grad_norm 9.56 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8280.42 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.52 / train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.23 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.12 / train/policy_logprob_min -8.23 / 
train/policy_logprob_std 1.57 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.8 / train/post_ent_max 50.8 / 
train/post_ent_mean 41.98 / train/post_ent_min 21.28 / train/post_ent_std 4.03 / train/prior_ent_mag 70.92 / train/prior_ent_max 70.92 / train/prior_ent_mean 45.7 / train/prior_ent_min 32.43 / train/prior_ent_std 4.43 / train/rep_loss_mean 3.76 / train/rep_loss_std 5.73
/ train/reward_avg 0.48 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2.01 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 
0.48 / train/reward_rate 0.43 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.18 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 5.86 / report/image_loss_mean 0.97 / report/image_loss_std 0.93 / report/model_loss_mean 3.37 / report/model_loss_std 4.32 / report/post_ent_mag 
50.97 / report/post_ent_max 50.97 / report/post_ent_mean 42.16 / report/post_ent_min 20.91 / report/post_ent_std 3.88 / report/prior_ent_mag 70.92 / report/prior_ent_max 70.92 / report/prior_ent_mean 45.76 / report/prior_ent_min 32.47 / report/prior_ent_std 4.26 / 
report/rep_loss_mean 3.65 / report/rep_loss_std 5.86 / report/reward_avg 0.45 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.45 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.7 / eval/dyn_loss_std 6.73 / eval/image_loss_mean 1.25 / eval/image_loss_std 1.61 / eval/model_loss_mean 4.37 / eval/model_loss_std 5.26 / eval/post_ent_mag 50.39 / eval/post_ent_max
50.39 / eval/post_ent_mean 41.62 / eval/post_ent_min 18.06 / eval/post_ent_std 4.05 / eval/prior_ent_mag 70.92 / eval/prior_ent_max 70.92 / eval/prior_ent_mean 46.02 / eval/prior_ent_min 35.17 / eval/prior_ent_std 4.26 / eval/rep_loss_mean 4.7 / eval/rep_loss_std 6.73 /
eval/reward_avg 0.68 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.68 / 
eval/reward_rate 0.55 / replay/size 4.4e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3778 / timer/env.step_total 19.67 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.13 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.1e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1889 / 
timer/agent.train_total 240.86 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 346.7.
Starting evaluation at step 442000 Counter(442000) 441937
Saved chunk: 20230922T070845F207771-6m7ge9M1sxvUBBS58slK81-5GmmzYc1BXSzmRLKZYB2jg-1024.npz
eval_Episode has 500 steps and return 380.0.
Saved chunk: 20230922T070910F576957-2dO14rM9zhDi4dxBP3uZqC-3Ivieod1zg8OGP9qkZ9Rdh-1024.npz
train_Episode has 500 steps and return 313.1.
Starting evaluation at step 442500 Counter(442500) 442437
eval_Episode has 500 steps and return 377.6.
train_Episode has 500 steps and return 297.1.
Starting evaluation at step 443000 Counter(443000) 442937
Saved chunk: 20230922T071005F041472-5GmmzYc1BXSzmRLKZYB2jg-7fYD9q0roVmLpwuLO2YTNj-1024.npz
eval_Episode has 500 steps and return 350.2.
train_Episode has 500 steps and return 325.8.
Saved chunk: 20230922T071032F207516-3Ivieod1zg8OGP9qkZ9Rdh-1PeaW9ofk7KrofcOqlDebR-1024.npz
Starting evaluation at step 443500 Counter(443500) 443437
eval_Episode has 500 steps and return 336.4.
train_Episode has 500 steps and return 313.9.
Starting evaluation at step 444000 Counter(444000) 443937
eval_Episode has 500 steps and return 392.8.
Saved chunk: 20230922T071124F170185-7fYD9q0roVmLpwuLO2YTNj-0SlvIZvcHAhF43IFQNlgYA-1024.npz
train_Episode has 500 steps and return 333.4.
Saved chunk: 20230922T071152F794524-1PeaW9ofk7KrofcOqlDebR-1StObgEUOzMZ4QPLsPZi6Y-1024.npz
Starting evaluation at step 444500 Counter(444500) 444437
eval_Episode has 500 steps and return 365.9.
train_Episode has 500 steps and return 309.2.
Starting evaluation at step 445000 Counter(445000) 444937
eval_Episode has 500 steps and return 380.2.
Saved chunk: 20230922T071243F125089-0SlvIZvcHAhF43IFQNlgYA-2g8M3zdgpncDu3WQax3gB5-1024.npz
train_Episode has 500 steps and return 314.4.
Saved chunk: 20230922T071313F196576-1StObgEUOzMZ4QPLsPZi6Y-6M00qtFDT4Upu0vazNbF6F-1024.npz
Starting evaluation at step 445500 Counter(445500) 445437
eval_Episode has 500 steps and return 381.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 891002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 314.35 / episode/reward_rate 0.5 / eval_episode/length 500 / eval_episode/score 381.44 / eval_episode/reward_rate 0.62 / train/action_mag 3.61 / train/action_max 3.24 / train/action_mean 0.06 / train/action_min -3.51 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.44 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 3.49 / train/adv_mag 0.7 / train/adv_max 0.61 / train/adv_mean 5.8e-4 / train/adv_min 
-0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.78 / train/dyn_loss_std 5.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 266.19 / train/extr_critic_max 266.19 / train/extr_critic_mean 256.04 / train/extr_critic_min 206.22 / train/extr_critic_std 8.39 / train/extr_return_normed_mag 1.29 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 266.8 / train/extr_return_raw_max 266.8 / train/extr_return_raw_mean 256.06 / train/extr_return_raw_min 
218.43 / train/extr_return_raw_std 8.4 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1.02 / train/image_loss_std 0.99 / train/model_loss_mean 3.53 / 
train/model_loss_std 4.25 / train/model_opt_grad_norm 8.98 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 2.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6894.74 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.61 / train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 7.89 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.12 / train/policy_logprob_min -7.89 / 
train/policy_logprob_std 1.56 / train/policy_randomness_mag 0.56 / train/policy_randomness_max 0.56 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.67 / train/post_ent_max 50.67 / 
train/post_ent_mean 41.99 / train/post_ent_min 21.3 / train/post_ent_std 4 / train/prior_ent_mag 70.94 / train/prior_ent_max 70.94 / train/prior_ent_mean 45.74 / train/prior_ent_min 32.79 / train/prior_ent_std 4.38 / train/rep_loss_mean 3.78 / train/rep_loss_std 5.75 / 
train/reward_avg 0.48 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / 
train/reward_rate 0.42 / train_stats/mean_log_entropy -3.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.6 / report/dyn_loss_std 5.01 / report/image_loss_mean 0.9 / report/image_loss_std 0.72 / report/model_loss_mean 3.35 / report/model_loss_std 3.65 / report/post_ent_mag 51.07 
/ report/post_ent_max 51.07 / report/post_ent_mean 42.52 / report/post_ent_min 24.94 / report/post_ent_std 3.48 / report/prior_ent_mag 70.96 / report/prior_ent_max 70.96 / report/prior_ent_mean 46.22 / report/prior_ent_min 35.14 / report/prior_ent_std 3.86 / 
report/rep_loss_mean 3.6 / report/rep_loss_std 5.01 / report/reward_avg 0.56 / report/reward_loss_mean 0.28 / report/reward_loss_std 0.39 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.56 / report/reward_rate 0.49 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.03 / eval/dyn_loss_std 5.89 / eval/image_loss_mean 0.98 / eval/image_loss_std 1.1 / eval/model_loss_mean 3.75 / eval/model_loss_std 4.47 / eval/post_ent_mag 49.59 / eval/post_ent_max
49.59 / eval/post_ent_mean 41.95 / eval/post_ent_min 21.4 / eval/post_ent_std 3.46 / eval/prior_ent_mag 70.96 / eval/prior_ent_max 70.96 / eval/prior_ent_mean 45.87 / eval/prior_ent_min 36.75 / eval/prior_ent_std 3.94 / eval/rep_loss_mean 4.03 / eval/rep_loss_std 5.89 /
eval/reward_avg 0.72 / eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.55 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.71 / 
eval/reward_rate 0.6 / replay/size 4.5e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.02 / timer/env.step_count 3792 / timer/env.step_total 19.58 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.82 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.6e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7800 / timer/agent.policy_total 18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / 
timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1896 / 
timer/agent.train_total 241.9 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 362.6.
Starting evaluation at step 446000 Counter(446000) 445937
eval_Episode has 500 steps and return 358.0.
Saved chunk: 20230922T071401F750620-2g8M3zdgpncDu3WQax3gB5-1o5bmvlStfIUwb3fTscW2u-1024.npz
train_Episode has 500 steps and return 322.8.
Saved chunk: 20230922T071433F321779-6M00qtFDT4Upu0vazNbF6F-7Gz6Vey4eAJJCQKbz51LXT-1024.npz
Starting evaluation at step 446500 Counter(446500) 446437
eval_Episode has 500 steps and return 339.9.
train_Episode has 500 steps and return 320.0.
Starting evaluation at step 447000 Counter(447000) 446937
eval_Episode has 500 steps and return 383.2.
train_Episode has 500 steps and return 345.2.
Saved chunk: 20230922T071554F941285-7Gz6Vey4eAJJCQKbz51LXT-1l9y43LusjOrINtRW9Svtt-1024.npz
Starting evaluation at step 447500 Counter(447500) 447437
Saved chunk: 20230922T071521F621047-1o5bmvlStfIUwb3fTscW2u-5zSJMTNm0gncYB0XuvqGGf-1024.npz
eval_Episode has 500 steps and return 376.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T071715F487174-1l9y43LusjOrINtRW9Svtt-0000000000000000000000-112.npz
Saved chunk: 20230922T071716F486917-5zSJMTNm0gncYB0XuvqGGf-0000000000000000000000-482.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 333.0.
Starting evaluation at step 448000 Counter(448000) 447937
eval_Episode has 500 steps and return 364.8.
train_Episode has 500 steps and return 358.0.
Starting evaluation at step 448500 Counter(448500) 448437
Saved chunk: 20230922T071716F486917-5zSJMTNm0gncYB0XuvqGGf-5Bk9a9MdZ1gx7fyP4gKWLQ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071715F487174-1l9y43LusjOrINtRW9Svtt-0IUZ9VWjx4n8LM33eNrG5K-1024.npz
train_Episode has 500 steps and return 325.4.
Starting evaluation at step 449000 Counter(449000) 448937
eval_Episode has 500 steps and return 360.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 898646 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 325.41 / episode/reward_rate 0.55 / eval_episode/length 500 / eval_episode/score 360.92 / eval_episode/reward_rate 0.65 / train/action_mag 3.59 / train/action_max 3.23 / train/action_mean 0.06 / train/action_min -3.49 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.43 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 5.31 / train/adv_mag 0.61 / train/adv_max 0.52 / train/adv_mean 3.9e-4
/ train/adv_min -0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 8.5e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 266.27 / train/extr_critic_max 266.27 / train/extr_critic_mean 256.19 / train/extr_critic_min 210.46 / train/extr_critic_std 8.2 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 266.91 / train/extr_return_raw_max 266.91 / train/extr_return_raw_mean 256.21 / train/extr_return_raw_min 
216.78 / train/extr_return_raw_std 8.22 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.02 / train/image_loss_std 1 / train/model_loss_mean 3.52 / 
train/model_loss_std 4.28 / train/model_opt_grad_norm 9.28 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9554.97 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.8 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.68 / train/policy_logprob_mag 8.09 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -8.09 / 
train/policy_logprob_std 1.57 / train/policy_randomness_mag 0.58 / train/policy_randomness_max 0.58 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.1e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.79 / train/post_ent_max 50.79 / 
train/post_ent_mean 41.92 / train/post_ent_min 21.05 / train/post_ent_std 4.04 / train/prior_ent_mag 70.93 / train/prior_ent_max 70.93 / train/prior_ent_mean 45.68 / train/prior_ent_min 32.34 / train/prior_ent_std 4.46 / train/rep_loss_mean 3.78 / train/rep_loss_std 
5.77 / train/reward_avg 0.47 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 
0.47 / train/reward_rate 0.42 / train_stats/mean_log_entropy -3.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 5.89 / report/image_loss_mean 1.03 / report/image_loss_std 0.88 / report/model_loss_mean 3.53 / report/model_loss_std 4.22 / report/post_ent_mag 
48.61 / report/post_ent_max 48.61 / report/post_ent_mean 41.88 / report/post_ent_min 19.61 / report/post_ent_std 3.93 / report/prior_ent_mag 70.82 / report/prior_ent_max 70.82 / report/prior_ent_mean 45.75 / report/prior_ent_min 32.84 / report/prior_ent_std 4.19 / 
report/rep_loss_mean 3.78 / report/rep_loss_std 5.89 / report/reward_avg 0.47 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.48 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.76 / eval/dyn_loss_std 5.24 / eval/image_loss_mean 0.88 / eval/image_loss_std 0.78 / eval/model_loss_mean 3.45 / eval/model_loss_std 3.84 / eval/post_ent_mag 48.7 / eval/post_ent_max
48.7 / eval/post_ent_mean 41.9 / eval/post_ent_min 25.67 / eval/post_ent_std 3.34 / eval/prior_ent_mag 70.82 / eval/prior_ent_max 70.82 / eval/prior_ent_mean 45.67 / eval/prior_ent_min 34.62 / eval/prior_ent_std 3.79 / eval/rep_loss_mean 3.76 / eval/rep_loss_std 5.24 / 
eval/reward_avg 0.73 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.73 / 
eval/reward_rate 0.59 / replay/size 4.5e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.6e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3822 / timer/env.step_total 20.06 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.21 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.9e-3 / 
timer/replay._sample_max 0.22 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7329 / timer/agent.policy_total 17.19 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1911 / timer/agent.train_total 243.57 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.9e-5 / timer/dataset_eval_frac 1.6e-7 / 
timer/dataset_eval_avg 4.9e-5 / timer/dataset_eval_min 4.9e-5 / timer/dataset_eval_max 4.9e-5 / fps 25.48

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 309.2.
Starting evaluation at step 449500 Counter(449500) 449437
Saved chunk: 20230922T071835F617790-5Bk9a9MdZ1gx7fyP4gKWLQ-1PcjDMyfd77CGE4pXFasCs-1024.npz
eval_Episode has 500 steps and return 386.4.
Saved chunk: 20230922T071839F802420-0IUZ9VWjx4n8LM33eNrG5K-1J4dsMOHynpS8Iu3JzEu06-1024.npz
train_Episode has 500 steps and return 337.3.
Starting evaluation at step 450000 Counter(450000) 449937
eval_Episode has 500 steps and return 347.0.
train_Episode has 500 steps and return 355.9.
Starting evaluation at step 450500 Counter(450500) 450437
Saved chunk: 20230922T071955F421238-1PcjDMyfd77CGE4pXFasCs-1Ac4Cuk2jHrPg5cmVQqdyM-1024.npz
eval_Episode has 500 steps and return 372.9.
Saved chunk: 20230922T072001F205273-1J4dsMOHynpS8Iu3JzEu06-5PVUphosAyY4n4U80TqH8u-1024.npz
train_Episode has 500 steps and return 332.3.
Starting evaluation at step 451000 Counter(451000) 450937
eval_Episode has 500 steps and return 334.9.
train_Episode has 500 steps and return 341.1.
Starting evaluation at step 451500 Counter(451500) 451437
Saved chunk: 20230922T072114F608318-1Ac4Cuk2jHrPg5cmVQqdyM-4hju4AEx1Lcx2gFL93aD8V-1024.npz
eval_Episode has 500 steps and return 371.9.
Saved chunk: 20230922T072121F913445-5PVUphosAyY4n4U80TqH8u-5Ai9L3Tu67Dqh0iQ9fqJsk-1024.npz
train_Episode has 500 steps and return 278.5.
Starting evaluation at step 452000 Counter(452000) 451937
eval_Episode has 500 steps and return 354.5.
train_Episode has 500 steps and return 323.8.
Starting evaluation at step 452500 Counter(452500) 452437
Saved chunk: 20230922T072233F635584-4hju4AEx1Lcx2gFL93aD8V-2PvN7Il5nGZX5r96Wi6gog-1024.npz
eval_Episode has 500 steps and return 380.9.
Saved chunk: 20230922T072242F459237-5Ai9L3Tu67Dqh0iQ9fqJsk-2SGyMl5vCh1gIR0B2n7ywp-1024.npz
train_Episode has 500 steps and return 341.7.
Starting evaluation at step 453000 Counter(453000) 452937
eval_Episode has 500 steps and return 374.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 906198 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 341.67 / episode/reward_rate 0.58 / eval_episode/length 500 / eval_episode/score 374.69 / eval_episode/reward_rate 0.62 / train/action_mag 3.67 / train/action_max 3.3 / train/action_mean 0.06 / train/action_min -3.55 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.45 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 6.53 / train/adv_mag 0.56 / train/adv_max 0.46 / train/adv_mean 2.7e-4 / train/adv_min 
-0.37 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 266.17 / train/extr_critic_max 266.17 / train/extr_critic_mean 255.74 / train/extr_critic_min 209.82 / train/extr_critic_std 9.38 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.61 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 266.85 / train/extr_return_raw_max 266.85 / train/extr_return_raw_mean 255.74 / train/extr_return_raw_min 
213.47 / train/extr_return_raw_std 9.4 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1.02 / train/image_loss_std 1 / train/model_loss_mean 3.52 / 
train/model_loss_std 4.26 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
2.16 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.26 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -8.26 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 2.8e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.77 / train/post_ent_max 50.77 / train/post_ent_mean 41.91 / 
train/post_ent_min 21.25 / train/post_ent_std 4.04 / train/prior_ent_mag 70.9 / train/prior_ent_max 70.9 / train/prior_ent_mean 45.65 / train/prior_ent_min 32.2 / train/prior_ent_std 4.46 / train/rep_loss_mean 3.78 / train/rep_loss_std 5.76 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / train/reward_rate 0.43 /
train_stats/mean_log_entropy -3.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 8.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.39 / report/dyn_loss_std 5.32 / report/image_loss_mean 0.93 / report/image_loss_std 0.87 / report/model_loss_mean 3.21 / report/model_loss_std 3.85 / report/post_ent_mag 51.35 / report/post_ent_max 51.35 /
report/post_ent_mean 41.47 / report/post_ent_min 24.23 / report/post_ent_std 4.29 / report/prior_ent_mag 70.9 / report/prior_ent_max 70.9 / report/prior_ent_mean 44.97 / report/prior_ent_min 30.29 / report/prior_ent_std 4.81 / report/rep_loss_mean 3.39 / 
report/rep_loss_std 5.32 / report/reward_avg 0.56 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.56 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.1 / eval/dyn_loss_std 5.94 / eval/image_loss_mean 1.01 / eval/image_loss_std 1.21 / eval/model_loss_mean 3.75 / eval/model_loss_std 4.52 / eval/post_ent_mag 50.06 / eval/post_ent_max 50.06 / eval/post_ent_mean 
41.8 / eval/post_ent_min 18.79 / eval/post_ent_std 3.53 / eval/prior_ent_mag 70.9 / eval/prior_ent_max 70.9 / eval/prior_ent_mean 45.72 / eval/prior_ent_min 36.49 / eval/prior_ent_std 4.01 / eval/rep_loss_mean 4.1 / eval/rep_loss_std 5.94 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / eval/reward_pred 0.66 / eval/reward_rate 0.53 / 
replay/size 4.5e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3776 / timer/env.step_total 19.48 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.69 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1888 / timer/agent.train_total 240.99 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 346.4.
Starting evaluation at step 453500 Counter(453500) 453437
Saved chunk: 20230922T072352F357241-2PvN7Il5nGZX5r96Wi6gog-5QyYJQ2grkq0nIJgcRAKQI-1024.npz
eval_Episode has 500 steps and return 359.2.
Saved chunk: 20230922T072402F730535-2SGyMl5vCh1gIR0B2n7ywp-5wLhEg4C3lhBWchtSWrGzs-1024.npz
train_Episode has 500 steps and return 323.6.
Starting evaluation at step 454000 Counter(454000) 453937
eval_Episode has 500 steps and return 369.0.
train_Episode has 500 steps and return 333.5.
Starting evaluation at step 454500 Counter(454500) 454437
Saved chunk: 20230922T072512F284910-5QyYJQ2grkq0nIJgcRAKQI-4CK9ES6CQkqDoUeWdVSOjM-1024.npz
eval_Episode has 500 steps and return 362.9.
Saved chunk: 20230922T072524F344605-5wLhEg4C3lhBWchtSWrGzs-1RGt9ZmVSRNJB8wxYMuBaK-1024.npz
train_Episode has 500 steps and return 314.8.
Starting evaluation at step 455000 Counter(455000) 454937
eval_Episode has 500 steps and return 370.9.
train_Episode has 500 steps and return 345.4.
Starting evaluation at step 455500 Counter(455500) 455437
Saved chunk: 20230922T072631F545389-4CK9ES6CQkqDoUeWdVSOjM-6rpEpPfyaA4JRZv0hP0Nh8-1024.npz
eval_Episode has 500 steps and return 383.1.
Saved chunk: 20230922T072645F104393-1RGt9ZmVSRNJB8wxYMuBaK-3aRBvdaqL4jYlXxJHpalUs-1024.npz
train_Episode has 500 steps and return 331.5.
Starting evaluation at step 456000 Counter(456000) 455937
eval_Episode has 500 steps and return 372.4.
train_Episode has 500 steps and return 319.1.
Starting evaluation at step 456500 Counter(456500) 456437
Saved chunk: 20230922T072750F357872-6rpEpPfyaA4JRZv0hP0Nh8-45difTxp6QAnTjyEaKg93i-1024.npz
eval_Episode has 500 steps and return 366.1.
Saved chunk: 20230922T072805F452341-3aRBvdaqL4jYlXxJHpalUs-2yeS2tvY8ntcJLJXQ8rGRI-1024.npz
train_Episode has 500 steps and return 339.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 913854 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 339.54 / episode/reward_rate 0.61 / eval_episode/length 500 / eval_episode/score 366.09 / eval_episode/reward_rate 0.6 / train/action_mag 3.69 / train/action_max 3.28 / train/action_mean 0.06 / train/action_min -3.6 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.43 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 0.73 / train/adv_mag 0.59 / train/adv_max 0.49 / train/adv_mean 8.6e-4 / train/adv_min 
-0.37 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.77 / train/dyn_loss_std 5.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 266.43 / train/extr_critic_max 266.43 / train/extr_critic_mean 256.44 / train/extr_critic_min 215.49 / train/extr_critic_std 7.75 / train/extr_return_normed_mag 1.24 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 267.16 / train/extr_return_raw_max 267.16 / train/extr_return_raw_mean 256.47 / train/extr_return_raw_min 
221.07 / train/extr_return_raw_std 7.79 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.02 / train/image_loss_std 1 / train/model_loss_mean 3.52 / 
train/model_loss_std 4.26 / train/model_opt_grad_norm 9.19 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.56 / train/policy_entropy_max 
2.01 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.16 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.09 / train/policy_logprob_min -8.16 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.6 / train/policy_randomness_max 0.6 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.76 / train/post_ent_max 50.76 / train/post_ent_mean 41.96 / 
train/post_ent_min 21.18 / train/post_ent_std 3.96 / train/prior_ent_mag 70.91 / train/prior_ent_max 70.91 / train/prior_ent_mean 45.69 / train/prior_ent_min 32.71 / train/prior_ent_std 4.39 / train/rep_loss_mean 3.77 / train/rep_loss_std 5.74 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.47 / train/reward_rate 0.42 /
train_stats/mean_log_entropy -3.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 5.94 / report/image_loss_mean 0.98 / report/image_loss_std 0.93 / report/model_loss_mean 3.53 / report/model_loss_std 4.25 / report/post_ent_mag 51.55 / report/post_ent_max 51.55 /
report/post_ent_mean 42.23 / report/post_ent_min 21.54 / report/post_ent_std 3.92 / report/prior_ent_mag 71.01 / report/prior_ent_max 71.01 / report/prior_ent_mean 46.07 / report/prior_ent_min 33.94 / report/prior_ent_std 4.34 / report/rep_loss_mean 3.84 / 
report/rep_loss_std 5.94 / report/reward_avg 0.51 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.51 / report/reward_rate 0.45 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 8.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.89 / eval/dyn_loss_std 5.83 / eval/image_loss_mean 0.98 / eval/image_loss_std 1.36 / eval/model_loss_mean 3.65 / eval/model_loss_std 4.67 / eval/post_ent_mag 47.83 / eval/post_ent_max 47.83 / eval/post_ent_mean 
41.87 / eval/post_ent_min 18.66 / eval/post_ent_std 3.32 / eval/prior_ent_mag 71.01 / eval/prior_ent_max 71.01 / eval/prior_ent_mean 45.45 / eval/prior_ent_min 35.08 / eval/prior_ent_std 3.96 / eval/rep_loss_mean 3.89 / eval/rep_loss_std 5.83 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.69 / eval/reward_rate 0.6 / 
replay/size 4.6e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 4.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3828 / timer/env.step_total 19.77 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 462.63 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7335 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1914 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.2 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 457000 Counter(457000) 456937
eval_Episode has 500 steps and return 374.7.
train_Episode has 500 steps and return 321.1.
Starting evaluation at step 457500 Counter(457500) 457437
Saved chunk: 20230922T072908F976834-45difTxp6QAnTjyEaKg93i-1ixUmX6OoE0sarJWR9fwWm-1024.npz
eval_Episode has 500 steps and return 369.3.
Saved chunk: 20230922T072925F568426-2yeS2tvY8ntcJLJXQ8rGRI-77TfCoS3w1pTg4InovtKLC-1024.npz
train_Episode has 500 steps and return 314.1.
Starting evaluation at step 458000 Counter(458000) 457937
eval_Episode has 500 steps and return 373.5.
train_Episode has 500 steps and return 306.9.
Starting evaluation at step 458500 Counter(458500) 458437
Saved chunk: 20230922T073029F045686-1ixUmX6OoE0sarJWR9fwWm-1H1hcN73mzO2LT22GjfAX6-1024.npz
eval_Episode has 500 steps and return 337.7.
Saved chunk: 20230922T073047F340387-77TfCoS3w1pTg4InovtKLC-49PCK8S6Fj0nY5w2riVhg5-1024.npz
train_Episode has 500 steps and return 349.7.
Starting evaluation at step 459000 Counter(459000) 458937
eval_Episode has 500 steps and return 340.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T073207F954149-49PCK8S6Fj0nY5w2riVhg5-0000000000000000000000-348.npz
Saved chunk: 20230922T073148F163629-1H1hcN73mzO2LT22GjfAX6-0000000000000000000000-741.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 317.0.
Starting evaluation at step 459500 Counter(459500) 459437
Saved chunk: 20230922T073148F163629-1H1hcN73mzO2LT22GjfAX6-1BggAOeo6Y57yBxRgytoPh-1024.npz
eval_Episode has 500 steps and return 389.8.
Saved chunk: 20230922T073207F954149-49PCK8S6Fj0nY5w2riVhg5-1HK2KHFVX3oayVJMz07NQ1-1024.npz
train_Episode has 500 steps and return 299.2.
Starting evaluation at step 460000 Counter(460000) 459937
eval_Episode has 500 steps and return 367.3.
train_Episode has 500 steps and return 353.3.
Starting evaluation at step 460500 Counter(460500) 460437
Saved chunk: 20230922T073307F299867-1BggAOeo6Y57yBxRgytoPh-6beJdc83dCi947TWJqV5Ll-1024.npz
eval_Episode has 500 steps and return 362.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 921398 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 362.34 / eval_episode/reward_rate 0.64 / episode/length 500 / episode/score 353.31 / episode/reward_rate 0.6 / train/action_mag 3.77 / train/action_max 3.34 / train/action_mean 0.05 / train/action_min -3.68 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.48 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -1.33 / train/adv_mag 0.85 / train/adv_max 0.75 / train/adv_mean 1.1e-3 / train/adv_min
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.8 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 267.07 / train/extr_critic_max 267.07 / train/extr_critic_mean 256.84 / train/extr_critic_min 205.81 / train/extr_critic_std 8.35 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.57 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 267.8 / train/extr_return_raw_max 267.8 / train/extr_return_raw_mean 256.87 / train/extr_return_raw_min 
217.97 / train/extr_return_raw_std 8.38 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.04 / train/image_loss_std 1.05 / train/model_loss_mean 3.55 /
train/model_loss_std 4.34 / train/model_opt_grad_norm 9.27 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.64 / train/policy_entropy_max 
2.69 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.19 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -8.19 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.76 / train/post_ent_max 50.76 / train/post_ent_mean 41.95 / 
train/post_ent_min 20.94 / train/post_ent_std 4 / train/prior_ent_mag 70.83 / train/prior_ent_max 70.83 / train/prior_ent_mean 45.71 / train/prior_ent_min 32.33 / train/prior_ent_std 4.41 / train/rep_loss_mean 3.8 / train/rep_loss_std 5.82 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.47 / train/reward_rate 0.42 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.15 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.03 / report/dyn_loss_std 6.35 / report/image_loss_mean 1.28 / report/image_loss_std 1.16 / report/model_loss_mean 3.88 / report/model_loss_std 4.67 / report/post_ent_mag 51.39 / report/post_ent_max 51.39 /
report/post_ent_mean 41.15 / report/post_ent_min 19.65 / report/post_ent_std 5.47 / report/prior_ent_mag 71.01 / report/prior_ent_max 71.01 / report/prior_ent_mean 45.37 / report/prior_ent_min 23.43 / report/prior_ent_std 5.99 / report/rep_loss_mean 4.03 / 
report/rep_loss_std 6.35 / report/reward_avg 0.31 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.31 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.55 / eval/dyn_loss_std 5.67 / eval/image_loss_mean 0.91 / eval/image_loss_std 1.01 / eval/model_loss_mean 3.33 / eval/model_loss_std 4.17 / eval/post_ent_mag 50.09 / eval/post_ent_max 50.09 / eval/post_ent_mean 
40.81 / eval/post_ent_min 20.89 / eval/post_ent_std 5.51 / eval/prior_ent_mag 71.01 / eval/prior_ent_max 71.01 / eval/prior_ent_mean 44.31 / eval/prior_ent_min 24.1 / eval/prior_ent_std 6.33 / eval/rep_loss_mean 3.55 / eval/rep_loss_std 5.67 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / eval/reward_pred 0.68 / eval/reward_rate 0.57 / 
replay/size 4.6e5 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3772 / timer/env.step_total 19.46 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.11 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.3e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / timer/agent.policy_count 7780 / timer/agent.policy_total 18.14 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1886 / timer/agent.train_total 240.9 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T073328F609506-1HK2KHFVX3oayVJMz07NQ1-4JYhU9tay6WmTgfEIC8t5v-1024.npz
train_Episode has 500 steps and return 301.3.
Starting evaluation at step 461000 Counter(461000) 460937
eval_Episode has 500 steps and return 378.2.
train_Episode has 500 steps and return 338.9.
Starting evaluation at step 461500 Counter(461500) 461437
Saved chunk: 20230922T073425F901504-6beJdc83dCi947TWJqV5Ll-0SKuBDDsfLiWHIFjiro2fr-1024.npz
eval_Episode has 500 steps and return 355.6.
Saved chunk: 20230922T073449F804537-4JYhU9tay6WmTgfEIC8t5v-26sPddqZK02pwzt6KdLYhe-1024.npz
train_Episode has 500 steps and return 324.7.
Starting evaluation at step 462000 Counter(462000) 461937
eval_Episode has 500 steps and return 371.6.
train_Episode has 500 steps and return 315.3.
Starting evaluation at step 462500 Counter(462500) 462437
Saved chunk: 20230922T073546F115014-0SKuBDDsfLiWHIFjiro2fr-5H50apy43QBBpU4wibDGf0-1024.npz
eval_Episode has 500 steps and return 353.4.
Saved chunk: 20230922T073610F685308-26sPddqZK02pwzt6KdLYhe-7ikeJ3UGjBApd2tEB0scgh-1024.npz
train_Episode has 500 steps and return 277.6.
Starting evaluation at step 463000 Counter(463000) 462937
eval_Episode has 500 steps and return 379.0.
train_Episode has 500 steps and return 328.3.
Starting evaluation at step 463500 Counter(463500) 463437
Saved chunk: 20230922T073705F132788-5H50apy43QBBpU4wibDGf0-1iN39hPe2HsEpL8snsxh4r-1024.npz
eval_Episode has 500 steps and return 376.4.
Saved chunk: 20230922T073731F153049-7ikeJ3UGjBApd2tEB0scgh-00XoBESdlCIdk5cioZgBEW-1024.npz
train_Episode has 500 steps and return 356.8.
Starting evaluation at step 464000 Counter(464000) 463937
eval_Episode has 500 steps and return 370.3.
train_Episode has 500 steps and return 343.5.
Starting evaluation at step 464500 Counter(464500) 464437
Saved chunk: 20230922T073823F889950-1iN39hPe2HsEpL8snsxh4r-4ipu18bwd7pWOY1sNfuInV-1024.npz
eval_Episode has 500 steps and return 370.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 929002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 343.49 / episode/reward_rate 0.57 / eval_episode/length 500 / eval_episode/score 370.44 / eval_episode/reward_rate 0.63 / train/action_mag 3.75 / train/action_max 3.31 / train/action_mean 0.06 / train/action_min -3.65 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.42 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 1.65 / train/adv_mag 0.66 / train/adv_max 0.58 / train/adv_mean 7.6e-4
/ train/adv_min -0.36 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 5.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 267.75 / train/extr_critic_max 267.75 / train/extr_critic_mean 256.88 / train/extr_critic_min 201.09 / train/extr_critic_std 10.63 / train/extr_return_normed_mag 1.51 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.69 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 268.51 / train/extr_return_raw_max 268.51 / train/extr_return_raw_mean 256.9 / train/extr_return_raw_min 
209.25 / train/extr_return_raw_std 10.65 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1.02 / train/image_loss_std 1.01 / train/model_loss_mean 3.53 
/ train/model_loss_std 4.3 / train/model_opt_grad_norm 8.86 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.56 / train/policy_entropy_max 
2.12 / train/policy_entropy_mean -3.11 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.11 / train/policy_logprob_min -8 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.61 / train/policy_randomness_max 0.61 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.77 / train/post_ent_max 50.77 / train/post_ent_mean 41.8 / 
train/post_ent_min 21.07 / train/post_ent_std 4.06 / train/prior_ent_mag 70.8 / train/prior_ent_max 70.8 / train/prior_ent_mean 45.57 / train/prior_ent_min 31.94 / train/prior_ent_std 4.51 / train/rep_loss_mean 3.79 / train/rep_loss_std 5.81 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.47 / train/reward_rate 0.42 /
train_stats/mean_log_entropy -3.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.07 / report/image_loss_mean 1.05 / report/image_loss_std 1.09 / report/model_loss_mean 3.55 / report/model_loss_std 4.57 / report/post_ent_mag 50.36 / report/post_ent_max 50.36 /
report/post_ent_mean 42.4 / report/post_ent_min 20.17 / report/post_ent_std 3.73 / report/prior_ent_mag 70.71 / report/prior_ent_max 70.71 / report/prior_ent_mean 46.07 / report/prior_ent_min 36.03 / report/prior_ent_std 4.16 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.07 / report/reward_avg 0.5 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.5 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.7 / eval/dyn_loss_std 5.25 / eval/image_loss_mean 0.92 / eval/image_loss_std 0.94 / eval/model_loss_mean 3.48 / eval/model_loss_std 3.98 / eval/post_ent_mag 49.09 / eval/post_ent_max 49.09 / eval/post_ent_mean 
42.08 / eval/post_ent_min 23.45 / eval/post_ent_std 3.16 / eval/prior_ent_mag 70.71 / eval/prior_ent_max 70.71 / eval/prior_ent_mean 45.81 / eval/prior_ent_min 36.22 / eval/prior_ent_std 3.83 / eval/rep_loss_mean 3.7 / eval/rep_loss_std 5.25 / eval/reward_avg 0.72 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.71 / eval/reward_rate 0.62 / 
replay/size 4.6e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.84 / timer/env.step_count 3802 / timer/env.step_total 19.63 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 1e-2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.64 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7810 / timer/agent.policy_total 18.05 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.3e-3 
/ timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1901 / timer/agent.train_total 242.64 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T073851F370809-00XoBESdlCIdk5cioZgBEW-3gMuQcJqXcjg0XlvJNsdAZ-1024.npz
train_Episode has 500 steps and return 332.1.
Starting evaluation at step 465000 Counter(465000) 464937
eval_Episode has 500 steps and return 360.7.
train_Episode has 500 steps and return 319.1.
Starting evaluation at step 465500 Counter(465500) 465437
Saved chunk: 20230922T073942F475499-4ipu18bwd7pWOY1sNfuInV-0Z3NeQwiK3fDQa2ptuJkbN-1024.npz
eval_Episode has 500 steps and return 356.8.
Saved chunk: 20230922T074012F806818-3gMuQcJqXcjg0XlvJNsdAZ-2xed3miv4Au2nWw1YymD3F-1024.npz
train_Episode has 500 steps and return 301.0.
Starting evaluation at step 466000 Counter(466000) 465937
eval_Episode has 500 steps and return 373.3.
train_Episode has 500 steps and return 356.4.
Starting evaluation at step 466500 Counter(466500) 466437
eval_Episode has 500 steps and return 372.5.
Saved chunk: 20230922T074102F819646-0Z3NeQwiK3fDQa2ptuJkbN-4a0XKYAb0f66OCc2Pvlz9U-1024.npz
train_Episode has 500 steps and return 312.6.
Saved chunk: 20230922T074133F584014-2xed3miv4Au2nWw1YymD3F-6QjszRNftobzZaONcmw8C6-1024.npz
Starting evaluation at step 467000 Counter(467000) 466937
eval_Episode has 500 steps and return 352.0.
train_Episode has 500 steps and return 333.6.
Starting evaluation at step 467500 Counter(467500) 467437
eval_Episode has 500 steps and return 390.4.
Saved chunk: 20230922T074221F873544-4a0XKYAb0f66OCc2Pvlz9U-1XJk6Uyta5nmpf8GTlJHwY-1024.npz
train_Episode has 500 steps and return 339.1.
Saved chunk: 20230922T074254F092331-6QjszRNftobzZaONcmw8C6-0ZZQkZC7Y5f3pQhsQMy9kk-1024.npz
Starting evaluation at step 468000 Counter(468000) 467937
eval_Episode has 500 steps and return 363.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 936654 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 339.08 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 363.52 / eval_episode/reward_rate 0.61 / train/action_mag 3.72 / train/action_max 3.28 / train/action_mean 0.06 / train/action_min -3.64 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.44 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 4.29 / train/adv_mag 0.7 / train/adv_max 0.61 / train/adv_mean 4.9e-4 
/ train/adv_min -0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 268.09 / train/extr_critic_max 268.09 / train/extr_critic_mean 257.95 / train/extr_critic_min 208.84 / train/extr_critic_std 8.47 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 268.8 / train/extr_return_raw_max 268.8 / train/extr_return_raw_mean 257.96 / train/extr_return_raw_min 
218.1 / train/extr_return_raw_std 8.5 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1.01 / train/image_loss_std 1 / train/model_loss_mean 3.52 / 
train/model_loss_std 4.26 / train/model_opt_grad_norm 9.11 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.55 / train/policy_entropy_max 
1.83 / train/policy_entropy_mean -3.11 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 7.99 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -7.99 / train/policy_logprob_std 1.57 / 
train/policy_randomness_mag 0.58 / train/policy_randomness_max 0.58 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.5e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.84 / train/post_ent_max 50.84 / train/post_ent_mean 41.89 / 
train/post_ent_min 21.3 / train/post_ent_std 3.95 / train/prior_ent_mag 70.77 / train/prior_ent_max 70.77 / train/prior_ent_mean 45.64 / train/prior_ent_min 32.48 / train/prior_ent_std 4.38 / train/rep_loss_mean 3.78 / train/rep_loss_std 5.76 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / train/reward_rate 0.43 /
train_stats/mean_log_entropy -3.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 6.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 5.3 / report/image_loss_mean 0.93 / report/image_loss_std 0.78 / report/model_loss_mean 3.41 / report/model_loss_std 3.86 / report/post_ent_mag 50.23 / report/post_ent_max 50.23 / 
report/post_ent_mean 41.47 / report/post_ent_min 24.39 / report/post_ent_std 3.78 / report/prior_ent_mag 70.69 / report/prior_ent_max 70.69 / report/prior_ent_mean 45.02 / report/prior_ent_min 32.86 / report/prior_ent_std 4.55 / report/rep_loss_mean 3.7 / 
report/rep_loss_std 5.3 / report/reward_avg 0.49 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.57 / report/reward_pred 0.49 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / eval/cont_pred 1 / eval/cont_rate 
1 / eval/dyn_loss_mean 3.93 / eval/dyn_loss_std 5.94 / eval/image_loss_mean 1 / eval/image_loss_std 1.32 / eval/model_loss_mean 3.68 / eval/model_loss_std 4.57 / eval/post_ent_mag 51.04 / eval/post_ent_max 51.04 / eval/post_ent_mean 41.72 / eval/post_ent_min 22.25 / 
eval/post_ent_std 3.44 / eval/prior_ent_mag 70.69 / eval/prior_ent_max 70.69 / eval/prior_ent_mean 45.56 / eval/prior_ent_min 35.28 / eval/prior_ent_std 4.02 / eval/rep_loss_mean 3.93 / eval/rep_loss_std 5.94 / eval/reward_avg 0.68 / eval/reward_loss_mean 0.32 / 
eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.68 / eval/reward_rate 0.59 / replay/size 4.7e5 / replay/inserts
3826 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3826 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 9.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 460.09 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 
1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1913 / timer/agent.train_total 244.27 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 303.4.
Starting evaluation at step 468500 Counter(468500) 468437
eval_Episode has 500 steps and return 340.6.
Saved chunk: 20230922T074340F537683-1XJk6Uyta5nmpf8GTlJHwY-6JnJlUJMAUDoWLC0hHXr7a-1024.npz
train_Episode has 500 steps and return 317.2.
Saved chunk: 20230922T074414F225577-0ZZQkZC7Y5f3pQhsQMy9kk-13ETUWtcYpIGRnNrZg7K8K-1024.npz
Starting evaluation at step 469000 Counter(469000) 468937
eval_Episode has 500 steps and return 336.1.
train_Episode has 500 steps and return 319.8.
Starting evaluation at step 469500 Counter(469500) 469437
eval_Episode has 500 steps and return 351.8.
train_Episode has 500 steps and return 332.9.
Starting evaluation at step 470000 Counter(470000) 469937
Saved chunk: 20230922T074500F283811-6JnJlUJMAUDoWLC0hHXr7a-0hX09WNyicq2C3u0BXVDpl-1024.npz
eval_Episode has 500 steps and return 354.4.
Saved chunk: 20230922T074535F870314-13ETUWtcYpIGRnNrZg7K8K-7EPoal2MCVkB5DMKxYjWAi-1024.npz
train_Episode has 500 steps and return 345.7.
Starting evaluation at step 470500 Counter(470500) 470437
eval_Episode has 500 steps and return 378.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T074655F421691-0hX09WNyicq2C3u0BXVDpl-0000000000000000000000-1000.npz
Saved chunk: 20230922T074700F109851-7EPoal2MCVkB5DMKxYjWAi-0000000000000000000000-584.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 333.8.
Starting evaluation at step 471000 Counter(471000) 470937
Saved chunk: 20230922T074655F421691-0hX09WNyicq2C3u0BXVDpl-2dX6q6sAFJoUpmD3Z7ikbe-1024.npz
eval_Episode has 500 steps and return 311.3.
Saved chunk: 20230922T074700F109851-7EPoal2MCVkB5DMKxYjWAi-6I8nQ2hpuFbqLyauvBZzsk-1024.npz
train_Episode has 500 steps and return 350.7.
Starting evaluation at step 471500 Counter(471500) 471437
eval_Episode has 500 steps and return 377.6.
train_Episode has 500 steps and return 347.5.
Starting evaluation at step 472000 Counter(472000) 471937
Saved chunk: 20230922T074814F497307-2dX6q6sAFJoUpmD3Z7ikbe-235yyzrcErRxDB1HeTvtqL-1024.npz
eval_Episode has 500 steps and return 379.5.
Saved chunk: 20230922T074820F748316-6I8nQ2hpuFbqLyauvBZzsk-4pQSuFEdDM3CCDdkZpVhwt-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 944198 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 347.53 / episode/reward_rate 0.57 / eval_episode/length 500 / eval_episode/score 379.48 / eval_episode/reward_rate 0.6 / train/action_mag 3.62 / train/action_max 3.32 / train/action_mean 0.06 / train/action_min -3.49 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.41 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 3.26 / train/adv_mag 0.56 / train/adv_max 0.48 / train/adv_mean 5.9e-4 / train/adv_min 
-0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.77 / train/dyn_loss_std 5.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 268.66 / train/extr_critic_max 268.66 / train/extr_critic_mean 258.21 / train/extr_critic_min 209.23 / train/extr_critic_std 9.13 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 269.42 / train/extr_return_raw_max 269.42 / train/extr_return_raw_mean 258.23 / train/extr_return_raw_min 
216.75 / train/extr_return_raw_std 9.16 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1.01 / train/image_loss_std 0.99 / train/model_loss_mean 3.51 /
train/model_loss_std 4.24 / train/model_opt_grad_norm 9.19 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.9 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.37 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.37 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.59 / train/policy_randomness_max 0.59 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.96 / train/post_ent_max 50.96 / train/post_ent_mean 41.95 / 
train/post_ent_min 21.54 / train/post_ent_std 3.94 / train/prior_ent_mag 70.71 / train/prior_ent_max 70.71 / train/prior_ent_mean 45.69 / train/prior_ent_min 32.92 / train/prior_ent_std 4.36 / train/rep_loss_mean 3.77 / train/rep_loss_std 5.73 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / train/reward_rate 0.43 /
train_stats/mean_log_entropy -3.12 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.38 / report/dyn_loss_std 5.47 / report/image_loss_mean 0.85 / report/image_loss_std 0.95 / report/model_loss_mean 3.09 / report/model_loss_std 4.11 / report/post_ent_mag 49.82 / report/post_ent_max 49.82 /
report/post_ent_mean 40.35 / report/post_ent_min 18.26 / report/post_ent_std 5.85 / report/prior_ent_mag 70.53 / report/prior_ent_max 70.53 / report/prior_ent_mean 43.79 / report/prior_ent_min 22.35 / report/prior_ent_std 6.97 / report/rep_loss_mean 3.38 / 
report/rep_loss_std 5.47 / report/reward_avg 0.45 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.45 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 7.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.27 / eval/dyn_loss_std 6.06 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.58 / eval/model_loss_mean 3.95 / eval/model_loss_std 4.91 / eval/post_ent_mag 47.68 / eval/post_ent_max 47.68 / eval/post_ent_mean 
41.44 / eval/post_ent_min 20.81 / eval/post_ent_std 3.51 / eval/prior_ent_mag 70.53 / eval/prior_ent_max 70.53 / eval/prior_ent_mean 45.42 / eval/prior_ent_min 34.64 / eval/prior_ent_std 3.87 / eval/rep_loss_mean 4.27 / eval/rep_loss_std 6.06 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / eval/reward_pred 0.65 / eval/reward_rate 0.56 / 
replay/size 4.7e5 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3772 / timer/env.step_total 19.5 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.64 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7780 / timer/agent.policy_total 18.32 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1886 / timer/agent.train_total 240.71 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 335.3.
Starting evaluation at step 472500 Counter(472500) 472437
eval_Episode has 500 steps and return 361.5.
train_Episode has 500 steps and return 272.6.
Starting evaluation at step 473000 Counter(473000) 472937
Saved chunk: 20230922T074933F191461-235yyzrcErRxDB1HeTvtqL-3TWKWcldRHUPQOgfs4kNdY-1024.npz
eval_Episode has 500 steps and return 334.3.
Saved chunk: 20230922T074940F976007-4pQSuFEdDM3CCDdkZpVhwt-2JYeSt7dgQBj2PG5FPqcgk-1024.npz
train_Episode has 500 steps and return 322.6.
Starting evaluation at step 473500 Counter(473500) 473437
eval_Episode has 500 steps and return 370.1.
train_Episode has 500 steps and return 359.2.
Starting evaluation at step 474000 Counter(474000) 473937
Saved chunk: 20230922T075055F307635-3TWKWcldRHUPQOgfs4kNdY-6dhC03mKGyi6penma011WP-1024.npz
eval_Episode has 500 steps and return 388.7.
Saved chunk: 20230922T075104F677845-2JYeSt7dgQBj2PG5FPqcgk-2saKheo74z2Xkuk2JXIJnS-1024.npz
train_Episode has 500 steps and return 347.8.
Starting evaluation at step 474500 Counter(474500) 474437
eval_Episode has 500 steps and return 372.3.
train_Episode has 500 steps and return 337.8.
Starting evaluation at step 475000 Counter(475000) 474937
Saved chunk: 20230922T075214F190797-6dhC03mKGyi6penma011WP-27esvMdfqLuXxSd5rqerdw-1024.npz
eval_Episode has 500 steps and return 397.4.
Saved chunk: 20230922T075225F115300-2saKheo74z2Xkuk2JXIJnS-7IXEQT529V08a0w267sbdL-1024.npz
train_Episode has 500 steps and return 350.0.
Starting evaluation at step 475500 Counter(475500) 475437
eval_Episode has 500 steps and return 357.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 951802 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 349.99 / episode/reward_rate 0.61 / eval_episode/length 500 / eval_episode/score 357.03 / eval_episode/reward_rate 0.62 / train/action_mag 3.67 / train/action_max 3.24 / train/action_mean 0.06 / train/action_min -3.57 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.39 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 0.72 / train/adv_mag 0.65 / train/adv_max 0.57 / train/adv_mean 8.5e-4
/ train/adv_min -0.36 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.3e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 269.12 / train/extr_critic_max 269.12 / train/extr_critic_mean 258.68 / train/extr_critic_min 204.94 / train/extr_critic_std 9.39 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 269.86 / train/extr_return_raw_max 269.86 / train/extr_return_raw_mean 258.71 / train/extr_return_raw_min 
216.47 / train/extr_return_raw_std 9.41 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1 / train/image_loss_std 1 / train/model_loss_mean 3.51 / 
train/model_loss_std 4.27 / train/model_opt_grad_norm 9.29 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.93 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.22 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.22 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.59 / train/policy_randomness_max 0.59 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.78 / train/post_ent_max 50.78 / train/post_ent_mean 41.91 / 
train/post_ent_min 21.32 / train/post_ent_std 3.96 / train/prior_ent_mag 70.73 / train/prior_ent_max 70.73 / train/prior_ent_mean 45.65 / train/prior_ent_min 32.67 / train/prior_ent_std 4.38 / train/rep_loss_mean 3.78 / train/rep_loss_std 5.76 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / train/reward_rate 0.43 /
train_stats/mean_log_entropy -3.12 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 5.09 / report/image_loss_mean 0.94 / report/image_loss_std 0.8 / report/model_loss_mean 3.32 / report/model_loss_std 3.64 / report/post_ent_mag 50.68 / report/post_ent_max 50.68 / 
report/post_ent_mean 42.16 / report/post_ent_min 20.19 / report/post_ent_std 3.54 / report/prior_ent_mag 70.62 / report/prior_ent_max 70.62 / report/prior_ent_mean 45.69 / report/prior_ent_min 36.26 / report/prior_ent_std 3.96 / report/rep_loss_mean 3.54 / 
report/rep_loss_std 5.09 / report/reward_avg 0.53 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.53 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 9.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.56 / eval/dyn_loss_std 5.46 / eval/image_loss_mean 0.83 / eval/image_loss_std 0.89 / eval/model_loss_mean 3.3 / eval/model_loss_std 4.02 / eval/post_ent_mag 50.58 / eval/post_ent_max 50.58 / eval/post_ent_mean 
40.91 / eval/post_ent_min 20.7 / eval/post_ent_std 5.39 / eval/prior_ent_mag 70.62 / eval/prior_ent_max 70.62 / eval/prior_ent_mean 44.43 / eval/prior_ent_min 27.5 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 3.56 / eval/rep_loss_std 5.46 / eval/reward_avg 0.73 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.72 / eval/reward_rate 0.6 / 
replay/size 4.8e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3802 / timer/env.step_total 19.62 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.28 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.7e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 8e-3 / 
timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.51 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 2.03 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 349.9.
Starting evaluation at step 476000 Counter(476000) 475937
Saved chunk: 20230922T075332F991820-27esvMdfqLuXxSd5rqerdw-4xTrxnbLcij5HJf81uWC4a-1024.npz
eval_Episode has 500 steps and return 382.6.
Saved chunk: 20230922T075345F465977-7IXEQT529V08a0w267sbdL-0kouoWVcCKj7rLKRqf1Uta-1024.npz
train_Episode has 500 steps and return 336.2.
Starting evaluation at step 476500 Counter(476500) 476437
eval_Episode has 500 steps and return 373.6.
train_Episode has 500 steps and return 334.6.
Starting evaluation at step 477000 Counter(477000) 476937
Saved chunk: 20230922T075452F662217-4xTrxnbLcij5HJf81uWC4a-6qVw2az1r786HJB5nqqbKw-1024.npz
eval_Episode has 500 steps and return 357.2.
Saved chunk: 20230922T075506F820568-0kouoWVcCKj7rLKRqf1Uta-0IPjooVwFsQTrdrq1rNltz-1024.npz
train_Episode has 500 steps and return 273.0.
Starting evaluation at step 477500 Counter(477500) 477437
eval_Episode has 500 steps and return 385.4.
train_Episode has 500 steps and return 366.1.
Starting evaluation at step 478000 Counter(478000) 477937
Saved chunk: 20230922T075611F973126-6qVw2az1r786HJB5nqqbKw-0WueX7xfittyADsseypR2Y-1024.npz
eval_Episode has 500 steps and return 361.8.
Saved chunk: 20230922T075627F613887-0IPjooVwFsQTrdrq1rNltz-0jIG0y4XHrN8MCTihIei5q-1024.npz
train_Episode has 500 steps and return 349.5.
Starting evaluation at step 478500 Counter(478500) 478437
eval_Episode has 500 steps and return 360.4.
train_Episode has 500 steps and return 296.3.
Starting evaluation at step 479000 Counter(479000) 478937
Saved chunk: 20230922T075730F862721-0WueX7xfittyADsseypR2Y-5Vq2dyWOqZkooulbQuKjTC-1024.npz
eval_Episode has 500 steps and return 373.0.
Saved chunk: 20230922T075748F021216-0jIG0y4XHrN8MCTihIei5q-1jB2NwftgIPPgzdExT3msS-1024.npz
train_Episode has 500 steps and return 135.9.
Starting evaluation at step 479500 Counter(479500) 479437
eval_Episode has 500 steps and return 0.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 959358 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 135.88 / episode/reward_rate 0.27 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 3.64 / train/action_max 3.34 / train/action_mean 0.08 / train/action_min -3.49 / train/action_std 0.88 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.45 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 80.42 / train/adv_mag 0.75 / train/adv_max 0.63 / train/adv_mean -7.3e-3 / train/adv_min -0.5 
/ train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.76 / train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 268.7 / train/extr_critic_max 268.7 / train/extr_critic_mean 255.93 / train/extr_critic_min 199.18 / train/extr_critic_std 12.23 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.65 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 269.18 / train/extr_return_raw_max 269.18 / train/extr_return_raw_mean 255.54 / train/extr_return_raw_min 
205.81 / train/extr_return_raw_std 12.52 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 1.01 / train/image_loss_std 1 / train/model_loss_mean 3.5 / 
train/model_loss_std 4.27 / train/model_opt_grad_norm 9.2 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.54 / train/policy_entropy_max
2.19 / train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.77 / train/policy_logprob_mag 8.3 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.01 / train/policy_logprob_min -8.3 / train/policy_logprob_std 1.61 / 
train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.8 / train/post_ent_max 50.8 / train/post_ent_mean 41.88 / 
train/post_ent_min 21.1 / train/post_ent_std 4 / train/prior_ent_mag 70.65 / train/prior_ent_max 70.65 / train/prior_ent_mean 45.59 / train/prior_ent_min 32.31 / train/prior_ent_std 4.43 / train/rep_loss_mean 3.76 / train/rep_loss_std 5.77 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / train/reward_rate 0.43 /
train_stats/mean_log_entropy -3.08 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.19 / report/dyn_loss_std 6.95 / report/image_loss_mean 1.21 / report/image_loss_std 1.19 / report/model_loss_mean 3.93 / report/model_loss_std 5.14 / report/post_ent_mag 50.9 / report/post_ent_max 50.9 / 
report/post_ent_mean 41.25 / report/post_ent_min 19.85 / report/post_ent_std 4.34 / report/prior_ent_mag 70.6 / report/prior_ent_max 70.6 / report/prior_ent_mean 45.42 / report/prior_ent_min 33.33 / report/prior_ent_std 5.06 / report/rep_loss_mean 4.19 / 
report/rep_loss_std 6.95 / report/reward_avg 0.41 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.41 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 7.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.59 / eval/dyn_loss_std 4.96 / eval/image_loss_mean 0.84 / eval/image_loss_std 0.7 / eval/model_loss_mean 3.35 / eval/model_loss_std 3.55 / eval/post_ent_mag 48.41 / eval/post_ent_max 48.41 / eval/post_ent_mean 
42.02 / eval/post_ent_min 26.42 / eval/post_ent_std 2.96 / eval/prior_ent_mag 70.6 / eval/prior_ent_max 70.6 / eval/prior_ent_mean 45.65 / eval/prior_ent_min 38.67 / eval/prior_ent_std 3.8 / eval/rep_loss_mean 3.59 / eval/rep_loss_std 4.96 / eval/reward_avg 0.8 / 
eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.81 / eval/reward_rate 0.66 / 
replay/size 4.8e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3778 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.39 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.7e-3 
/ timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1889 / timer/agent.train_total 241.03 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 127.9.
Starting evaluation at step 480000 Counter(480000) 479937
Saved chunk: 20230922T075849F455565-5Vq2dyWOqZkooulbQuKjTC-6GPsDp59EKJb57qD2pcBN9-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075908F194607-1jB2NwftgIPPgzdExT3msS-48Iq5pt0c4OLTItkGfMzkV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 480500 Counter(480500) 480437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 107.1.
Starting evaluation at step 481000 Counter(481000) 480937
Saved chunk: 20230922T080009F344815-6GPsDp59EKJb57qD2pcBN9-7IGa8Qw8ulwq3RqHA3Ruzu-1024.npz
eval_Episode has 500 steps and return 172.2.
Saved chunk: 20230922T080029F765304-48Iq5pt0c4OLTItkGfMzkV-4LZQ3FQmy2lqah3SBn9qIl-1024.npz
train_Episode has 500 steps and return 102.0.
Starting evaluation at step 481500 Counter(481500) 481437
eval_Episode has 500 steps and return 142.7.
train_Episode has 500 steps and return 203.2.
Starting evaluation at step 482000 Counter(482000) 481937
Saved chunk: 20230922T080128F475561-7IGa8Qw8ulwq3RqHA3Ruzu-4Npc6KE2SKzHBnObBHXcu7-1024.npz
eval_Episode has 500 steps and return 189.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T080247F290311-4Npc6KE2SKzHBnObBHXcu7-0000000000000000000000-235.npz
Saved chunk: 20230922T080150F389156-4LZQ3FQmy2lqah3SBn9qIl-0000000000000000000000-820.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T080150F389156-4LZQ3FQmy2lqah3SBn9qIl-2LakqgXwCincOONRyqZNxz-1024.npz
train_Episode has 500 steps and return 301.1.
Starting evaluation at step 482500 Counter(482500) 482437
eval_Episode has 500 steps and return 289.3.
train_Episode has 500 steps and return 287.9.
Starting evaluation at step 483000 Counter(483000) 482937
Saved chunk: 20230922T080247F290311-4Npc6KE2SKzHBnObBHXcu7-5724n7hoY2cEj91Ie4BYPA-1024.npz
eval_Episode has 500 steps and return 354.0.
Saved chunk: 20230922T080310F941948-2LakqgXwCincOONRyqZNxz-75xfdEFDhqctfYLDsdUUlw-1024.npz
train_Episode has 500 steps and return 307.7.
Starting evaluation at step 483500 Counter(483500) 483437
eval_Episode has 500 steps and return 356.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 967002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 307.65 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 356.88 / eval_episode/reward_rate 0.59 / train/action_mag 3.5 / train/action_max 3.31 / train/action_mean 0.08 / train/action_min -3.22 / train/action_std
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.67 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 21.97 / train/adv_mag 0.78 / train/adv_max 0.55 / train/adv_mean -1.3e-3 / 
train/adv_min -0.69 / train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.3e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.76 / train/dyn_loss_std 5.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 242.46 / train/extr_critic_max 242.46 / train/extr_critic_mean 226.69 / train/extr_critic_min 183.33 / train/extr_critic_std 13.44 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.65 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 242.84 / train/extr_return_raw_max 242.84 / train/extr_return_raw_mean 226.59 / train/extr_return_raw_min 
184.93 / train/extr_return_raw_std 13.58 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1 / train/image_loss_std 1 / train/model_loss_mean 3.5 / 
train/model_loss_std 4.24 / train/model_opt_grad_norm 9.4 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9397.91 / train/policy_entropy_mag 3.53 / 
train/policy_entropy_max 1.52 / train/policy_entropy_mean -2.98 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.75 / train/policy_logprob_mag 8.39 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.98 / train/policy_logprob_min -8.39 / 
train/policy_logprob_std 1.61 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 7.9e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.93 / train/post_ent_max 50.93 / 
train/post_ent_mean 41.91 / train/post_ent_min 21.35 / train/post_ent_std 4.05 / train/prior_ent_mag 70.65 / train/prior_ent_max 70.65 / train/prior_ent_mean 45.62 / train/prior_ent_min 32.38 / train/prior_ent_std 4.49 / train/rep_loss_mean 3.76 / train/rep_loss_std 
5.72 / train/reward_avg 0.48 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 
0.48 / train/reward_rate 0.43 / train_stats/mean_log_entropy -3.04 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 5.98 / report/image_loss_mean 1.13 / report/image_loss_std 1.15 / report/model_loss_mean 3.73 / report/model_loss_std 4.45 / report/post_ent_mag 
49.68 / report/post_ent_max 49.68 / report/post_ent_mean 41.64 / report/post_ent_min 18.73 / report/post_ent_std 4.02 / report/prior_ent_mag 70.6 / report/prior_ent_max 70.6 / report/prior_ent_mean 45.62 / report/prior_ent_min 31.75 / report/prior_ent_std 4.49 / 
report/rep_loss_mean 3.99 / report/rep_loss_std 5.98 / report/reward_avg 0.42 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 9.5e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.42 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.05 / eval/dyn_loss_std 5.66 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.3 / eval/model_loss_mean 3.82 / eval/model_loss_std 4.32 / eval/post_ent_mag 51.12 / eval/post_ent_max
51.12 / eval/post_ent_mean 41.46 / eval/post_ent_min 21.21 / eval/post_ent_std 3.79 / eval/prior_ent_mag 70.6 / eval/prior_ent_max 70.6 / eval/prior_ent_mean 45.38 / eval/prior_ent_min 31.06 / eval/prior_ent_std 4.07 / eval/rep_loss_mean 4.05 / eval/rep_loss_std 5.66 / 
eval/reward_avg 0.67 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.67 / 
eval/reward_rate 0.58 / replay/size 4.8e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.21 / timer/env.step_count 3822 / timer/env.step_total 19.96 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.59 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.4e-3 / 
timer/replay._sample_max 0.23 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7830 / timer/agent.policy_total 18.14 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / 
timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1911 / timer/agent.train_total 243.58 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 296.2.
Starting evaluation at step 484000 Counter(484000) 483937
Saved chunk: 20230922T080406F143584-5724n7hoY2cEj91Ie4BYPA-2idyNTHgZoXn4NSFh0FJZl-1024.npz
eval_Episode has 500 steps and return 327.2.
Saved chunk: 20230922T080431F040262-75xfdEFDhqctfYLDsdUUlw-77J47NHCL0h3haucReBUGD-1024.npz
train_Episode has 500 steps and return 296.0.
Starting evaluation at step 484500 Counter(484500) 484437
eval_Episode has 500 steps and return 343.4.
train_Episode has 500 steps and return 308.3.
Starting evaluation at step 485000 Counter(485000) 484937
Saved chunk: 20230922T080526F070056-2idyNTHgZoXn4NSFh0FJZl-1LOXAE86cIdWGulI70p2GI-1024.npz
eval_Episode has 500 steps and return 348.6.
Saved chunk: 20230922T080552F752466-77J47NHCL0h3haucReBUGD-0nXUjtDwSJyoH6QA3L2Z4K-1024.npz
train_Episode has 500 steps and return 309.8.
Starting evaluation at step 485500 Counter(485500) 485437
eval_Episode has 500 steps and return 386.6.
train_Episode has 500 steps and return 343.0.
Starting evaluation at step 486000 Counter(486000) 485937
Saved chunk: 20230922T080645F036109-1LOXAE86cIdWGulI70p2GI-4CwLaOkqgtCOC8D5qjcxOi-1024.npz
eval_Episode has 500 steps and return 383.1.
Saved chunk: 20230922T080713F197326-0nXUjtDwSJyoH6QA3L2Z4K-5op4HhCHJYTzSyFtEEWcPW-1024.npz
train_Episode has 500 steps and return 338.9.
Starting evaluation at step 486500 Counter(486500) 486437
eval_Episode has 500 steps and return 381.1.
train_Episode has 500 steps and return 331.0.
Starting evaluation at step 487000 Counter(487000) 486937
Saved chunk: 20230922T080803F880029-4CwLaOkqgtCOC8D5qjcxOi-5riBcul41jKt3vKIbuJVjn-1024.npz
eval_Episode has 500 steps and return 376.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 974660 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 330.99 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 376.21 / eval_episode/reward_rate 0.61 / train/action_mag 3.69 / train/action_max 3.17 / train/action_mean 0.07 / train/action_min -3.66 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.42 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -88.84 / train/adv_mag 0.54 / train/adv_max 0.29 / train/adv_mean 1e-2
/ train/adv_min -0.53 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 9.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.75 / train/dyn_loss_std 5.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 9774 / train/extr_critic_mag 245.56 / train/extr_critic_max 245.56 / train/extr_critic_mean 235.74 / train/extr_critic_min 203.16 / train/extr_critic_std 7.68 / train/extr_return_normed_mag 1.28 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.73 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 246.8 / train/extr_return_raw_max 246.8 / train/extr_return_raw_mean 236.02 / train/extr_return_raw_min 
201.93 / train/extr_return_raw_std 7.74 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1 / train/image_loss_std 0.98 / train/model_loss_mean 3.49 / 
train/model_loss_std 4.23 / train/model_opt_grad_norm 9.23 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7984.29 / train/policy_entropy_mag 3.54 / 
train/policy_entropy_max 1.25 / train/policy_entropy_mean -3.11 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 7.94 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.11 / train/policy_logprob_min -7.94 / 
train/policy_logprob_std 1.56 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 5e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 51.03 / train/post_ent_max 51.03 / 
train/post_ent_mean 42 / train/post_ent_min 21.52 / train/post_ent_std 3.96 / train/prior_ent_mag 70.63 / train/prior_ent_max 70.63 / train/prior_ent_mean 45.71 / train/prior_ent_min 32.71 / train/prior_ent_std 4.39 / train/rep_loss_mean 3.75 / train/rep_loss_std 5.72 /
train/reward_avg 0.48 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.48 / 
train/reward_rate 0.43 / train_stats/mean_log_entropy -3.15 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.67 / report/dyn_loss_std 5.92 / report/image_loss_mean 1.01 / report/image_loss_std 0.83 / report/model_loss_mean 3.42 / report/model_loss_std 4.13 / report/post_ent_mag 
51.31 / report/post_ent_max 51.31 / report/post_ent_mean 41.78 / report/post_ent_min 18.36 / report/post_ent_std 4.21 / report/prior_ent_mag 70.78 / report/prior_ent_max 70.78 / report/prior_ent_mean 45.43 / report/prior_ent_min 33.93 / report/prior_ent_std 4.58 / 
report/rep_loss_mean 3.67 / report/rep_loss_std 5.92 / report/reward_avg 0.4 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.7e-3 / 
report/reward_pos_acc 0.99 / report/reward_pos_loss 0.54 / report/reward_pred 0.4 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.1 / eval/dyn_loss_std 6 / eval/image_loss_mean 1.12 / eval/image_loss_std 1.73 / eval/model_loss_mean 3.91 / eval/model_loss_std 4.9 / eval/post_ent_mag 48.18 / eval/post_ent_max 48.18
/ eval/post_ent_mean 41.43 / eval/post_ent_min 23.85 / eval/post_ent_std 3.81 / eval/prior_ent_mag 70.78 / eval/prior_ent_max 70.78 / eval/prior_ent_mean 45.39 / eval/prior_ent_min 30.93 / eval/prior_ent_std 4.13 / eval/rep_loss_mean 4.1 / eval/rep_loss_std 6 / 
eval/reward_avg 0.71 / eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.7 / 
eval/reward_rate 0.58 / replay/size 4.9e5 / replay/inserts 3829 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3829 / timer/env.step_total 19.77 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.91 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.9e-4 / 
timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7336 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 /
timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1914 / 
timer/agent.train_total 244.11 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T080833F525443-5op4HhCHJYTzSyFtEEWcPW-698kJXp7aH5GjcSY5ugqZr-1024.npz
train_Episode has 500 steps and return 316.1.
Starting evaluation at step 487500 Counter(487500) 487437
eval_Episode has 500 steps and return 358.1.
train_Episode has 500 steps and return 288.5.
Starting evaluation at step 488000 Counter(488000) 487937
Saved chunk: 20230922T080922F443090-5riBcul41jKt3vKIbuJVjn-2enata08fqMBWX4l7Xpwr4-1024.npz
eval_Episode has 500 steps and return 354.1.
Saved chunk: 20230922T080954F727672-698kJXp7aH5GjcSY5ugqZr-6BAhVGRENA7DzxH78p2Foz-1024.npz
train_Episode has 500 steps and return 301.8.
Starting evaluation at step 488500 Counter(488500) 488437
eval_Episode has 500 steps and return 383.8.
train_Episode has 500 steps and return 347.4.
Starting evaluation at step 489000 Counter(489000) 488937
eval_Episode has 500 steps and return 312.7.
Saved chunk: 20230922T081042F611691-2enata08fqMBWX4l7Xpwr4-21uMuIHZjLwdFrgNXIV5zg-1024.npz
train_Episode has 500 steps and return 315.3.
Saved chunk: 20230922T081115F473013-6BAhVGRENA7DzxH78p2Foz-1v9vMlmUcC9Cyz9k9Y9ZV8-1024.npz
Starting evaluation at step 489500 Counter(489500) 489437
eval_Episode has 500 steps and return 375.5.
train_Episode has 500 steps and return 344.1.
Starting evaluation at step 490000 Counter(490000) 489937
eval_Episode has 500 steps and return 381.2.
Saved chunk: 20230922T081201F554044-21uMuIHZjLwdFrgNXIV5zg-2PYgQXFJsxPy9AcuhmGgo7-1024.npz
train_Episode has 500 steps and return 326.4.
Starting evaluation at step 490500 Counter(490500) 490437
Saved chunk: 20230922T081235F881768-1v9vMlmUcC9Cyz9k9Y9ZV8-1KqaUHfBdaPDeN43S6zkKP-1024.npz
eval_Episode has 500 steps and return 349.0.
train_Episode has 500 steps and return 343.5.
Starting evaluation at step 491000 Counter(491000) 490937
eval_Episode has 500 steps and return 382.6.
Saved chunk: 20230922T081320F307292-2PYgQXFJsxPy9AcuhmGgo7-66BDk5ildTxLavhGtcQfNn-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 982218 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 343.54 / episode/reward_rate 0.57 / eval_episode/length 500 / eval_episode/score 382.59 / eval_episode/reward_rate 0.67 / train/action_mag 3.59 / train/action_max 3.21 / train/action_mean 0.06 / train/action_min -3.52 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -64.77 / train/adv_mag 0.45 / train/adv_max 0.33 / train/adv_mean 
7.5e-3 / train/adv_min -0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.5e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.75 / train/dyn_loss_std 5.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 6631.49 / train/extr_critic_mag 256.06 / train/extr_critic_max 256.06 / train/extr_critic_mean 245.67 / train/extr_critic_min 209.05 / train/extr_critic_std 8.06 / 
train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.1 / train/extr_return_normed_mean 0.73 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 256.85 / train/extr_return_raw_max 
256.85 / train/extr_return_raw_mean 245.9 / train/extr_return_raw_min 210.1 / train/extr_return_raw_std 8.1 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / 
train/image_loss_mean 0.99 / train/image_loss_std 0.98 / train/model_loss_mean 3.48 / train/model_loss_std 4.23 / train/model_opt_grad_norm 9.27 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 1.53 / train/policy_entropy_mean -3.11 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.12 / train/policy_logprob_max 5.51
/ train/policy_logprob_mean 3.11 / train/policy_logprob_min -8.12 / train/policy_logprob_std 1.56 / train/policy_randomness_mag 0.55 / train/policy_randomness_max 0.55 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.7e-5 / train/policy_randomness_std
0.07 / train/post_ent_mag 50.74 / train/post_ent_max 50.74 / train/post_ent_mean 41.97 / train/post_ent_min 21.31 / train/post_ent_std 3.95 / train/prior_ent_mag 70.61 / train/prior_ent_max 70.61 / train/prior_ent_mean 45.68 / train/prior_ent_min 32.59 / 
train/prior_ent_std 4.4 / train/rep_loss_mean 3.75 / train/rep_loss_std 5.71 / train/reward_avg 0.49 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.49 / train/reward_rate 0.44 / train_stats/mean_log_entropy -3.13 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.2e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.79 / report/dyn_loss_std 6.22 / report/image_loss_mean 1.05 / report/image_loss_std 1.03 / 
report/model_loss_mean 3.51 / report/model_loss_std 4.49 / report/post_ent_mag 51.31 / report/post_ent_max 51.31 / report/post_ent_mean 40.88 / report/post_ent_min 19.28 / report/post_ent_std 4.48 / report/prior_ent_mag 70.6 / report/prior_ent_max 70.6 / 
report/prior_ent_mean 44.6 / report/prior_ent_min 28.54 / report/prior_ent_std 5.23 / report/rep_loss_mean 3.79 / report/rep_loss_std 6.22 / report/reward_avg 0.44 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.29 / report/reward_max_data 2 / 
report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 0.44 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 6.5e-11 / eval/cont_loss_std 5.2e-10 / 
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.5 / eval/dyn_loss_std 5.02 / eval/image_loss_mean 0.84 / eval/image_loss_std 0.8 / eval/model_loss_mean 3.31 / 
eval/model_loss_std 3.7 / eval/post_ent_mag 50.56 / eval/post_ent_max 50.56 / eval/post_ent_mean 42.26 / eval/post_ent_min 24.63 / eval/post_ent_std 2.92 / eval/prior_ent_mag 70.6 / eval/prior_ent_max 70.6 / eval/prior_ent_mean 45.7 / eval/prior_ent_min 39.58 / 
eval/prior_ent_std 3.86 / eval/rep_loss_mean 3.5 / eval/rep_loss_std 5.02 / eval/reward_avg 0.82 / eval/reward_loss_mean 0.37 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.8e-3 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.81 / eval/reward_rate 0.68 / replay/size 4.9e5 / replay/inserts 3779 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3779 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.07 / timer/replay._sample_frac 1.53 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7787 / timer/agent.policy_total 17.94 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.9e-3 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1890 / timer/agent.train_total 240.84 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.9e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.9e-5 / 
timer/dataset_eval_min 4.9e-5 / timer/dataset_eval_max 4.9e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 336.8.
Starting evaluation at step 491500 Counter(491500) 491437
eval_Episode has 500 steps and return 356.5.
Saved chunk: 20230922T081356F131916-1KqaUHfBdaPDeN43S6zkKP-0Z3tAaGzIESKe06U8BtjqV-1024.npz
train_Episode has 500 steps and return 352.5.
Starting evaluation at step 492000 Counter(492000) 491937
eval_Episode has 500 steps and return 381.5.
Saved chunk: 20230922T081438F874249-66BDk5ildTxLavhGtcQfNn-1hVaMa9385HGQ4RSXu2EpO-1024.npz
train_Episode has 500 steps and return 327.8.
Starting evaluation at step 492500 Counter(492500) 492437
eval_Episode has 500 steps and return 371.0.
Saved chunk: 20230922T081521F206225-0Z3tAaGzIESKe06U8BtjqV-5DtsRwNfbXjva6vVAiB6k8-1024.npz
train_Episode has 500 steps and return 337.6.
Starting evaluation at step 493000 Counter(493000) 492937
eval_Episode has 500 steps and return 330.2.
train_Episode has 500 steps and return 365.5.
Starting evaluation at step 493500 Counter(493500) 493437
Saved chunk: 20230922T081559F141521-1hVaMa9385HGQ4RSXu2EpO-4g2dTL4hnoQ9g6nSni5Emj-1024.npz
eval_Episode has 500 steps and return 375.8.
Saved chunk: 20230922T081641F891945-5DtsRwNfbXjva6vVAiB6k8-7rJHKZT1CELO5ZkszTrsA7-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T081754F008452-4g2dTL4hnoQ9g6nSni5Emj-0000000000000000000000-494.npz
Saved chunk: 20230922T081802F411505-7rJHKZT1CELO5ZkszTrsA7-0000000000000000000000-32.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
train_Episode has 500 steps and return 327.5.
Starting evaluation at step 494000 Counter(494000) 493937
eval_Episode has 500 steps and return 373.2.
train_Episode has 500 steps and return 320.7.
Starting evaluation at step 494500 Counter(494500) 494437
Saved chunk: 20230922T081754F008452-4g2dTL4hnoQ9g6nSni5Emj-4kRyzviCXuVLHNAZH7bBVb-1024.npz
eval_Episode has 500 steps and return 376.7.
Saved chunk: 20230922T081802F411505-7rJHKZT1CELO5ZkszTrsA7-6tSPARaF4iGJRCQl3ydzea-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 989862 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 320.67 / episode/reward_rate 0.53 / eval_episode/length 500 / eval_episode/score 376.73 / eval_episode/reward_rate 0.63 / train/action_mag 3.65 / train/action_max 3.28 / train/action_mean 0.06 / train/action_min -3.56 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.46 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -34.47 / train/adv_mag 0.44 / train/adv_max 0.32 / train/adv_mean 
4.4e-3 / train/adv_min -0.37 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.75 / train/dyn_loss_std 5.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 8639.24 / train/extr_critic_mag 261.66 / train/extr_critic_max 261.66 / train/extr_critic_mean 251.68 / train/extr_critic_min 212.18 / train/extr_critic_std 8.71 / 
train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.73 / train/extr_return_normed_min -0.49 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 262.73 / train/extr_return_raw_max 
262.73 / train/extr_return_raw_mean 251.81 / train/extr_return_raw_min 212.87 / train/extr_return_raw_std 8.76 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / 
train/image_loss_mean 1 / train/image_loss_std 0.99 / train/model_loss_mean 3.49 / train/model_loss_std 4.25 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 1.21 / train/policy_entropy_mean -3.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.12 / train/policy_logprob_min -8.13 / train/policy_logprob_std 1.56 / train/policy_randomness_mag 0.52 / train/policy_randomness_max 0.52 / train/policy_randomness_mean 0.04 / train/policy_randomness_min 4e-5 / train/policy_randomness_std 
0.07 / train/post_ent_mag 50.95 / train/post_ent_max 50.95 / train/post_ent_mean 41.97 / train/post_ent_min 21.28 / train/post_ent_std 3.95 / train/prior_ent_mag 70.59 / train/prior_ent_max 70.59 / train/prior_ent_mean 45.68 / train/prior_ent_min 32.92 / 
train/prior_ent_std 4.4 / train/rep_loss_mean 3.75 / train/rep_loss_std 5.73 / train/reward_avg 0.49 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.49 / train/reward_rate 0.44 / train_stats/mean_log_entropy -3.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 7.8e-11 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.55 / report/dyn_loss_std 5.4 / report/image_loss_mean 0.93 / report/image_loss_std 0.8 / 
report/model_loss_mean 3.29 / report/model_loss_std 3.87 / report/post_ent_mag 53.7 / report/post_ent_max 53.7 / report/post_ent_mean 42.38 / report/post_ent_min 21.69 / report/post_ent_std 3.34 / report/prior_ent_mag 70.57 / report/prior_ent_max 70.57 / 
report/prior_ent_mean 45.88 / report/prior_ent_min 33.52 / report/prior_ent_std 3.89 / report/rep_loss_mean 3.55 / report/rep_loss_std 5.4 / report/reward_avg 0.45 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.31 / report/reward_max_data 2 / 
report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.45 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 7.7e-11 / 
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.76 / eval/dyn_loss_std 6.94 / eval/image_loss_mean 1.46 / eval/image_loss_std 2.19 / eval/model_loss_mean 4.63 
/ eval/model_loss_std 5.93 / eval/post_ent_mag 52.85 / eval/post_ent_max 52.85 / eval/post_ent_mean 41.58 / eval/post_ent_min 22.2 / eval/post_ent_std 3.84 / eval/prior_ent_mag 70.57 / eval/prior_ent_max 70.57 / eval/prior_ent_mean 45.86 / eval/prior_ent_min 35.63 / 
eval/prior_ent_std 4.17 / eval/rep_loss_mean 4.76 / eval/rep_loss_std 6.94 / eval/reward_avg 0.68 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.67 / eval/reward_rate 0.59 / replay/size 4.9e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.7e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3822 / timer/env.step_total 19.96 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 462.14 / timer/replay._sample_frac 1.54 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-4 / timer/replay._sample_max 0.23 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / 
timer/agent.policy_count 7329 / timer/agent.policy_total 17.2 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.17 / 
timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1911 / timer/agent.train_total 243.78 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.48

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 342.7.
Starting evaluation at step 495000 Counter(495000) 494937
eval_Episode has 500 steps and return 404.7.
train_Episode has 500 steps and return 331.9.
Starting evaluation at step 495500 Counter(495500) 495437
Saved chunk: 20230922T081912F865465-4kRyzviCXuVLHNAZH7bBVb-0ndI7Wi7cGFYeBUmjDf6OF-1024.npz
eval_Episode has 500 steps and return 379.8.
Saved chunk: 20230922T081922F777489-6tSPARaF4iGJRCQl3ydzea-0vSkDFDftSmw7cI4P0X5lr-1024.npz
train_Episode has 500 steps and return 313.0.
Starting evaluation at step 496000 Counter(496000) 495937
eval_Episode has 500 steps and return 377.0.
train_Episode has 500 steps and return 350.3.
Starting evaluation at step 496500 Counter(496500) 496437
Saved chunk: 20230922T082032F919871-0ndI7Wi7cGFYeBUmjDf6OF-29N15UasqvO8oyHfjevnhr-1024.npz
eval_Episode has 500 steps and return 398.1.
Saved chunk: 20230922T082044F456411-0vSkDFDftSmw7cI4P0X5lr-70U2yao6sgZsYupPIzWxmM-1024.npz
train_Episode has 500 steps and return 308.1.
Starting evaluation at step 497000 Counter(497000) 496937
eval_Episode has 500 steps and return 397.2.
train_Episode has 500 steps and return 345.4.
Starting evaluation at step 497500 Counter(497500) 497437
Saved chunk: 20230922T082151F947080-29N15UasqvO8oyHfjevnhr-6HYfJn3Kfb0f5xVll7o6NZ-1024.npz
eval_Episode has 500 steps and return 390.2.
Saved chunk: 20230922T082205F035883-70U2yao6sgZsYupPIzWxmM-2z2gpVsKEzmkmyrbJGCABT-1024.npz
train_Episode has 500 steps and return 333.2.
Starting evaluation at step 498000 Counter(498000) 497937
eval_Episode has 500 steps and return 362.4.
train_Episode has 500 steps and return 331.2.
Starting evaluation at step 498500 Counter(498500) 498437
Saved chunk: 20230922T082310F765884-6HYfJn3Kfb0f5xVll7o6NZ-65f8t1ULgJejVvICCPO8lt-1024.npz
eval_Episode has 500 steps and return 392.7.
Saved chunk: 20230922T082325F400810-2z2gpVsKEzmkmyrbJGCABT-1djLUjcJlquzPOm8LUKxdC-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 997414 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 331.22 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 392.69 / eval_episode/reward_rate 0.68 / train/action_mag 3.62 / train/action_max 3.31 / train/action_mean 0.06 / train/action_min -3.5 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.46 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -22.83 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean 3.3e-3 / 
train/adv_min -0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.75 / train/dyn_loss_std 5.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 265.59 / train/extr_critic_max 265.59 / train/extr_critic_mean 255.26 / train/extr_critic_min 212.71 / train/extr_critic_std 9.37 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.65 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 266.61 / train/extr_return_raw_max 266.61 / train/extr_return_raw_mean 255.36 / train/extr_return_raw_min 
213.93 / train/extr_return_raw_std 9.41 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1 / train/image_loss_std 0.99 / train/model_loss_mean 3.49 / 
train/model_loss_std 4.22 / train/model_opt_grad_norm 9.11 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.76 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 7.88 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -7.88 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.3e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 50.96 / train/post_ent_max 50.96 / train/post_ent_mean 41.96 / 
train/post_ent_min 21.41 / train/post_ent_std 3.93 / train/prior_ent_mag 70.49 / train/prior_ent_max 70.49 / train/prior_ent_mean 45.67 / train/prior_ent_min 32.82 / train/prior_ent_std 4.37 / train/rep_loss_mean 3.75 / train/rep_loss_std 5.7 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.49 / train/reward_rate 0.43 /
train_stats/mean_log_entropy -3.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.98 / report/dyn_loss_std 5.92 / report/image_loss_mean 1.06 / report/image_loss_std 1.08 / report/model_loss_mean 3.71 / report/model_loss_std 4.42 / report/post_ent_mag 51.29 / report/post_ent_max 51.29 /
report/post_ent_mean 42.02 / report/post_ent_min 22.72 / report/post_ent_std 4.2 / report/prior_ent_mag 70.56 / report/prior_ent_max 70.56 / report/prior_ent_mean 45.95 / report/prior_ent_min 30.75 / report/prior_ent_std 4.57 / report/rep_loss_mean 3.98 / 
report/rep_loss_std 5.92 / report/reward_avg 0.48 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.48 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.79 / eval/dyn_loss_std 5.35 / eval/image_loss_mean 0.9 / eval/image_loss_std 0.82 / eval/model_loss_mean 3.48 / eval/model_loss_std 3.9 / eval/post_ent_mag 49.73 / eval/post_ent_max 49.73 / eval/post_ent_mean 
40.97 / eval/post_ent_min 20.83 / eval/post_ent_std 5.16 / eval/prior_ent_mag 70.56 / eval/prior_ent_max 70.56 / eval/prior_ent_mean 44.66 / eval/prior_ent_min 27.66 / eval/prior_ent_std 5.49 / eval/rep_loss_mean 3.79 / eval/rep_loss_std 5.35 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.68 / eval/reward_rate 0.58 / 
replay/size 5e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3776 / timer/env.step_total 19.7 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.74 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 8.9e-3 
/ timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1888 / timer/agent.train_total 240.87 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 341.3.
Starting evaluation at step 499000 Counter(499000) 498937
eval_Episode has 500 steps and return 410.4.
train_Episode has 500 steps and return 336.4.
Starting evaluation at step 499500 Counter(499500) 499437
Saved chunk: 20230922T082429F575313-65f8t1ULgJejVvICCPO8lt-2ONvNQTJfNpTxFyptgP1ba-1024.npz
eval_Episode has 500 steps and return 394.2.
Saved chunk: 20230922T082445F707320-1djLUjcJlquzPOm8LUKxdC-1FlZApxxZWBfwxy8gJNtG3-1024.npz
train_Episode has 500 steps and return 348.7.
Starting evaluation at step 500000 Counter(500000) 499937
eval_Episode has 500 steps and return 390.5.
train_Episode has 500 steps and return 350.1.
Starting evaluation at step 500500 Counter(500500) 500437
Saved chunk: 20230922T082549F859454-2ONvNQTJfNpTxFyptgP1ba-1dxCuVlPBFd3o9DgZWanJ3-1024.npz
eval_Episode has 500 steps and return 395.3.
Saved chunk: 20230922T082607F674066-1FlZApxxZWBfwxy8gJNtG3-3AGGedvz0EACxBhj9jGngY-1024.npz
train_Episode has 500 steps and return 353.7.
Starting evaluation at step 501000 Counter(501000) 500937
eval_Episode has 500 steps and return 384.7.
Starting evaluation at step 501500 Counter(501500) 501437
Saved chunk: 20230922T082708F903591-1dxCuVlPBFd3o9DgZWanJ3-2HApNlQabSYIKZWNcObWyK-1024.npz
eval_Episode has 500 steps and return 374.8.
train_Episode has 500 steps and return 363.9.
Saved chunk: 20230922T082728F251726-3AGGedvz0EACxBhj9jGngY-3XR0ZB7xzivU6DQQtiDjzz-1024.npz
Starting evaluation at step 502000 Counter(502000) 501937
eval_Episode has 500 steps and return 379.4.
train_Episode has 500 steps and return 332.3.
Starting evaluation at step 502500 Counter(502500) 502437
Saved chunk: 20230922T082827F864221-2HApNlQabSYIKZWNcObWyK-24BtFa0UJo8JJdjfhUNB2n-1024.npz
eval_Episode has 500 steps and return 388.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1005002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 332.28 / episode/reward_rate 0.56 / eval_episode/length 500 / eval_episode/score 388.83 / eval_episode/reward_rate 0.65 / train/action_mag 3.63 / train/action_max 3.35 / train/action_mean 0.06 / train/action_min -3.5 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -12.2 / train/adv_mag 0.47 / train/adv_max 0.34 / train/adv_mean 2.2e-3 / train/adv_min 
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.74 / train/dyn_loss_std 5.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 268.62 / train/extr_critic_max 268.62 / train/extr_critic_mean 258.65 / train/extr_critic_min 218.57 / train/extr_critic_std 8.28 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.61 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 269.58 / train/extr_return_raw_max 269.58 / train/extr_return_raw_mean 258.71 / train/extr_return_raw_min 
220.06 / train/extr_return_raw_std 8.34 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.98 / train/image_loss_std 0.97 / train/model_loss_mean 3.47 / 
train/model_loss_std 4.18 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
1.75 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -8.13 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.57 / train/policy_randomness_max 0.57 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.94 / train/post_ent_max 50.94 / train/post_ent_mean 41.93 / 
train/post_ent_min 21.49 / train/post_ent_std 3.94 / train/prior_ent_mag 70.53 / train/prior_ent_max 70.53 / train/prior_ent_mean 45.63 / train/prior_ent_min 32.51 / train/prior_ent_std 4.39 / train/rep_loss_mean 3.74 / train/rep_loss_std 5.66 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.54 / train/reward_pred 0.5 / train/reward_rate 0.44 / 
train_stats/mean_log_entropy -3.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.16 / report/dyn_loss_std 6.4 / report/image_loss_mean 1.16 / report/image_loss_std 1.37 / report/model_loss_mean 3.85 / report/model_loss_std 4.99 / report/post_ent_mag 51.53 / report/post_ent_max 51.53 / 
report/post_ent_mean 41.75 / report/post_ent_min 20.33 / report/post_ent_std 4.1 / report/prior_ent_mag 70.58 / report/prior_ent_max 70.58 / report/prior_ent_mean 45.87 / report/prior_ent_min 34.81 / report/prior_ent_std 4.17 / report/rep_loss_mean 4.16 / 
report/rep_loss_std 6.4 / report/reward_avg 0.43 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.52 / report/reward_pred 0.43 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.51 / eval/dyn_loss_std 4.92 / eval/image_loss_mean 0.81 / eval/image_loss_std 0.62 / eval/model_loss_mean 3.24 / eval/model_loss_std 3.48 / eval/post_ent_mag 51 / eval/post_ent_max 51 / eval/post_ent_mean 41.03 
/ eval/post_ent_min 22.49 / eval/post_ent_std 4.99 / eval/prior_ent_mag 70.58 / eval/prior_ent_max 70.58 / eval/prior_ent_mean 44.5 / eval/prior_ent_min 27.47 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 3.51 / eval/rep_loss_std 4.92 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.71 / eval/reward_rate 0.6 / 
replay/size 5e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 4.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.7 / timer/env.step_count 3794 / timer/env.step_total 19.59 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.42 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.2e-4 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 18.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1897 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1897 / timer/agent.train_total 242.48 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.15

train_Episode has 500 steps and return 357.2.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T082848F750316-3XR0ZB7xzivU6DQQtiDjzz-41a3obqA30xgvJXjmigBv4-1024.npz
Starting evaluation at step 503000 Counter(503000) 502937
eval_Episode has 500 steps and return 389.7.
train_Episode has 500 steps and return 361.0.
Starting evaluation at step 503500 Counter(503500) 503437
Saved chunk: 20230922T082946F561807-24BtFa0UJo8JJdjfhUNB2n-2EdoQUrgDue11X3t40PC0n-1024.npz
eval_Episode has 500 steps and return 386.7.
train_Episode has 500 steps and return 337.7.
Saved chunk: 20230922T083010F188931-41a3obqA30xgvJXjmigBv4-3BiQ5TJlW3kOCclUVlBkTD-1024.npz
Starting evaluation at step 504000 Counter(504000) 503937
eval_Episode has 500 steps and return 400.0.
train_Episode has 500 steps and return 359.3.
Starting evaluation at step 504500 Counter(504500) 504437
Saved chunk: 20230922T083106F938282-2EdoQUrgDue11X3t40PC0n-1S0zSkmcyRrwUbeDCQdFgb-1024.npz
eval_Episode has 500 steps and return 400.1.
train_Episode has 500 steps and return 345.8.
Saved chunk: 20230922T083131F000659-3BiQ5TJlW3kOCclUVlBkTD-1bB3jABPHcctT1BsRcG06G-1024.npz
Starting evaluation at step 505000 Counter(505000) 504937
eval_Episode has 500 steps and return 360.5.
train_Episode has 500 steps and return 338.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T083251F488653-1bB3jABPHcctT1BsRcG06G-0000000000000000000000-268.npz
Saved chunk: 20230922T083225F932474-1S0zSkmcyRrwUbeDCQdFgb-0000000000000000000000-753.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 505500 Counter(505500) 505437
Saved chunk: 20230922T083225F932474-1S0zSkmcyRrwUbeDCQdFgb-059zbsfwUuojqpAqXz7gUW-1024.npz
eval_Episode has 500 steps and return 379.9.
train_Episode has 500 steps and return 352.4.
Saved chunk: 20230922T083251F488653-1bB3jABPHcctT1BsRcG06G-5XMikHMuH37eeQhNt0w48r-1024.npz
Starting evaluation at step 506000 Counter(506000) 505937
eval_Episode has 500 steps and return 405.7.
train_Episode has 500 steps and return 354.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1012646 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 354.86 / episode/reward_rate 0.59 / eval_episode/length 500 / eval_episode/score 405.71 / eval_episode/reward_rate 0.73 / train_stats/mean_log_entropy -3.16 / train/action_mag 3.69 / train/action_max 3.38 / train/action_mean 0.06 / 
train/action_min -3.56 / train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.48 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.21 / train/adv_mag 0.51 / train/adv_max 
0.39 / train/adv_mean 1.4e-3 / train/adv_min -0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.75 / train/dyn_loss_std 5.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 270.1 / train/extr_critic_max 270.1 / train/extr_critic_mean 259.88 / train/extr_critic_min 216.82 / train/extr_critic_std 8.49 / train/extr_return_normed_mag
1.36 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 271 / train/extr_return_raw_max 271 / train/extr_return_raw_mean
259.93 / train/extr_return_raw_min 219.67 / train/extr_return_raw_std 8.53 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 1 / train/image_loss_std 
0.99 / train/model_loss_mean 3.49 / train/model_loss_std 4.23 / train/model_opt_grad_norm 9.22 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / 
train/policy_entropy_mag 3.54 / train/policy_entropy_max 2.16 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.18 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.09 / 
train/policy_logprob_min -8.18 / train/policy_logprob_std 1.59 / train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.98 / 
train/post_ent_max 50.98 / train/post_ent_mean 41.96 / train/post_ent_min 21.26 / train/post_ent_std 3.9 / train/prior_ent_mag 70.45 / train/prior_ent_max 70.45 / train/prior_ent_mean 45.67 / train/prior_ent_min 33.01 / train/prior_ent_std 4.33 / train/rep_loss_mean 
3.75 / train/rep_loss_std 5.7 / train/reward_avg 0.49 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 
0.55 / train/reward_pred 0.49 / train/reward_rate 0.43 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 5.95 / report/image_loss_mean 0.99 / report/image_loss_std 1.02 / report/model_loss_mean 3.54 / report/model_loss_std 4.41 / report/post_ent_mag 51.01 / 
report/post_ent_max 51.01 / report/post_ent_mean 42.06 / report/post_ent_min 20.38 / report/post_ent_std 3.88 / report/prior_ent_mag 70.46 / report/prior_ent_max 70.46 / report/prior_ent_mean 45.96 / report/prior_ent_min 32.62 / report/prior_ent_std 4.51 / 
report/rep_loss_mean 3.81 / report/rep_loss_std 5.95 / report/reward_avg 0.51 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 6.2e-3 / 
report/reward_pos_acc 0.99 / report/reward_pos_loss 0.57 / report/reward_pred 0.5 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.09 / eval/dyn_loss_std 6.05 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.39 / eval/model_loss_mean 3.84 / eval/model_loss_std 4.79 / eval/post_ent_mag 48.16 / 
eval/post_ent_max 48.16 / eval/post_ent_mean 41.35 / eval/post_ent_min 21.54 / eval/post_ent_std 3.63 / eval/prior_ent_mag 70.46 / eval/prior_ent_max 70.46 / eval/prior_ent_mean 45.41 / eval/prior_ent_min 32.29 / eval/prior_ent_std 4.14 / eval/rep_loss_mean 4.09 / 
eval/rep_loss_std 6.05 / eval/reward_avg 0.73 / eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.47 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / 
eval/reward_pred 0.72 / eval/reward_rate 0.61 / replay/size 5.1e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3822 / timer/env.step_total 19.79 
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 469.48 / timer/replay._sample_frac 1.56 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.23 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7329 / 
timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / 
timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1911 / timer/agent.train_total 244.04 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.47

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 506500 Counter(506500) 506437
Saved chunk: 20230922T083344F901208-059zbsfwUuojqpAqXz7gUW-4XUQk9nap1ET8BONNhiQz4-1024.npz
eval_Episode has 500 steps and return 386.2.
train_Episode has 500 steps and return 355.1.
Saved chunk: 20230922T083411F998922-5XMikHMuH37eeQhNt0w48r-0X9v6Pp2xve2txBURdPU3Y-1024.npz
Starting evaluation at step 507000 Counter(507000) 506937
eval_Episode has 500 steps and return 396.5.
train_Episode has 500 steps and return 323.9.
Starting evaluation at step 507500 Counter(507500) 507437
Saved chunk: 20230922T083504F760668-4XUQk9nap1ET8BONNhiQz4-4iQFWDyd7bOlFaQhY8njYl-1024.npz
eval_Episode has 500 steps and return 405.3.
train_Episode has 500 steps and return 342.3.
Saved chunk: 20230922T083533F581896-0X9v6Pp2xve2txBURdPU3Y-7khQ9KIwg32y3IzdmprevE-1024.npz
Starting evaluation at step 508000 Counter(508000) 507937
eval_Episode has 500 steps and return 397.2.
train_Episode has 500 steps and return 363.7.
Starting evaluation at step 508500 Counter(508500) 508437
Saved chunk: 20230922T083623F876228-4iQFWDyd7bOlFaQhY8njYl-5RDNdLG4mEKrYEtcZRRm2N-1024.npz
eval_Episode has 500 steps and return 383.3.
train_Episode has 500 steps and return 365.3.
Saved chunk: 20230922T083654F165089-7khQ9KIwg32y3IzdmprevE-4ckUAa2Qk3pqrcxuFYhaQn-1024.npz
Starting evaluation at step 509000 Counter(509000) 508937
eval_Episode has 500 steps and return 370.3.
train_Episode has 500 steps and return 327.3.
Starting evaluation at step 509500 Counter(509500) 509437
Saved chunk: 20230922T083742F808174-5RDNdLG4mEKrYEtcZRRm2N-5AQdF7ouy9ltHDGRS6b9AK-1024.npz
eval_Episode has 500 steps and return 380.1.
train_Episode has 500 steps and return 338.6.
Saved chunk: 20230922T083814F645758-4ckUAa2Qk3pqrcxuFYhaQn-5GmJe2EwAipgSfTvwUtK3l-1024.npz
Starting evaluation at step 510000 Counter(510000) 509937
eval_Episode has 500 steps and return 382.3.
train_Episode has 500 steps and return 349.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1020198 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 382.26 / eval_episode/reward_rate 0.72 / episode/length 500 / episode/score 349.78 / episode/reward_rate 0.63 / train/action_mag 3.64 / train/action_max 3.3 / train/action_mean 0.06 / train/action_min -3.55 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.47 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -2.35 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 1.2e-3 / train/adv_min 
-0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 9.4e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 5.69 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 271.64 / train/extr_critic_max 271.64 / train/extr_critic_mean 261.2 / train/extr_critic_min 220.02 / train/extr_critic_std 8.83 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 272.54 / train/extr_return_raw_max 272.54 / train/extr_return_raw_mean 261.24 / train/extr_return_raw_min 
222 / train/extr_return_raw_std 8.86 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.98 / train/image_loss_std 0.98 / train/model_loss_mean 3.45 / 
train/model_loss_std 4.21 / train/model_opt_grad_norm 9.46 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.96 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.21 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.21 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.6 / train/policy_randomness_max 0.6 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.84 / train/post_ent_max 50.84 / train/post_ent_mean 41.97 / 
train/post_ent_min 21.51 / train/post_ent_std 3.96 / train/prior_ent_mag 70.52 / train/prior_ent_max 70.52 / train/prior_ent_mean 45.64 / train/prior_ent_min 32.76 / train/prior_ent_std 4.41 / train/rep_loss_mean 3.73 / train/rep_loss_std 5.69 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.49 / train/reward_rate 0.44 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.15 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 5.32 / report/image_loss_mean 0.95 / report/image_loss_std 0.86 / report/model_loss_mean 3.42 / report/model_loss_std 3.83 / report/post_ent_mag 50.7 / report/post_ent_max 50.7 / 
report/post_ent_mean 42.13 / report/post_ent_min 21.46 / report/post_ent_std 3.69 / report/prior_ent_mag 70.65 / report/prior_ent_max 70.65 / report/prior_ent_mean 45.89 / report/prior_ent_min 36.4 / report/prior_ent_std 4.02 / report/rep_loss_mean 3.7 / 
report/rep_loss_std 5.32 / report/reward_avg 0.54 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.54 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.26 / eval/dyn_loss_std 5.07 / eval/image_loss_mean 0.75 / eval/image_loss_std 0.62 / eval/model_loss_mean 3 / eval/model_loss_std 3.63 / eval/post_ent_mag 48.01 / eval/post_ent_max 48.01 / eval/post_ent_mean 
40.91 / eval/post_ent_min 26.84 / eval/post_ent_std 4.45 / eval/prior_ent_mag 70.65 / eval/prior_ent_max 70.65 / eval/prior_ent_mean 44.13 / eval/prior_ent_min 27.56 / eval/prior_ent_std 5.67 / eval/rep_loss_mean 3.26 / eval/rep_loss_std 5.07 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.66 / eval/reward_rate 0.56 / 
replay/size 5.1e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3776 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.4 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.25 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 18.02 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.6e-3 
/ timer/dataset_train_count 1888 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1888 / timer/agent.train_total 241.04 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 510500 Counter(510500) 510437
Saved chunk: 20230922T083901F607724-5AQdF7ouy9ltHDGRS6b9AK-65lmHi6Om0EQd4AjcV7h2z-1024.npz
eval_Episode has 500 steps and return 405.2.
train_Episode has 500 steps and return 335.4.
Saved chunk: 20230922T083934F926882-5GmJe2EwAipgSfTvwUtK3l-2gySJY6eFITOumV6OFLxKM-1024.npz
Starting evaluation at step 511000 Counter(511000) 510937
eval_Episode has 500 steps and return 405.2.
train_Episode has 500 steps and return 376.6.
Starting evaluation at step 511500 Counter(511500) 511437
Saved chunk: 20230922T084021F530448-65lmHi6Om0EQd4AjcV7h2z-5u6QLzxS89ps4iuFsrl456-1024.npz
eval_Episode has 500 steps and return 377.5.
train_Episode has 500 steps and return 306.6.
Starting evaluation at step 512000 Counter(512000) 511937
Saved chunk: 20230922T084056F673108-2gySJY6eFITOumV6OFLxKM-0qG8NmEQwiUfIa97FdBzXZ-1024.npz
eval_Episode has 500 steps and return 374.6.
train_Episode has 500 steps and return 338.3.
Starting evaluation at step 512500 Counter(512500) 512437
eval_Episode has 500 steps and return 367.1.
Saved chunk: 20230922T084140F716643-5u6QLzxS89ps4iuFsrl456-6WCkb2KsTkbzBZJ1bTzYl5-1024.npz
train_Episode has 500 steps and return 335.6.
Starting evaluation at step 513000 Counter(513000) 512937
eval_Episode has 500 steps and return 387.9.
train_Episode has 500 steps and return 346.5.
Saved chunk: 20230922T084217F297962-0qG8NmEQwiUfIa97FdBzXZ-1kRt8GWTg9chDcJ7u612yI-1024.npz
Starting evaluation at step 513500 Counter(513500) 513437
eval_Episode has 500 steps and return 420.7.
Saved chunk: 20230922T084259F556908-6WCkb2KsTkbzBZJ1bTzYl5-55YXLO6LxZaDura81u0N0q-1024.npz
train_Episode has 500 steps and return 336.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1027854 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 420.71 / eval_episode/reward_rate 0.72 / episode/length 500 / episode/score 336.68 / episode/reward_rate 0.59 / train/action_mag 3.7 / train/action_max 3.29 / train/action_mean 0.06 / train/action_min -3.62 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 7.46 / train/adv_mag 0.53 / train/adv_max 0.4 / train/adv_mean 1.8e-4 / train/adv_min 
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 8.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 5.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 271.97 / train/extr_critic_max 271.97 / train/extr_critic_mean 261.54 / train/extr_critic_min 220.99 / train/extr_critic_std 8.73 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 272.77 / train/extr_return_raw_max 272.77 / train/extr_return_raw_mean 261.55 / train/extr_return_raw_min 
222.16 / train/extr_return_raw_std 8.78 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.97 / train/model_loss_mean 3.46 / 
train/model_loss_std 4.18 / train/model_opt_grad_norm 9.6 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.79 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 7.98 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -7.98 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.58 / train/policy_randomness_max 0.58 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.81 / train/post_ent_max 50.81 / train/post_ent_mean 42 / 
train/post_ent_min 21.34 / train/post_ent_std 3.91 / train/prior_ent_mag 70.47 / train/prior_ent_max 70.47 / train/prior_ent_mean 45.69 / train/prior_ent_min 32.99 / train/prior_ent_std 4.33 / train/rep_loss_mean 3.73 / train/rep_loss_std 5.65 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / train/reward_rate 0.44 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.15 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 5.77 / report/image_loss_mean 0.93 / report/image_loss_std 0.88 / report/model_loss_mean 3.36 / report/model_loss_std 4.2 / report/post_ent_mag 51.94 / report/post_ent_max 51.94 / 
report/post_ent_mean 41.27 / report/post_ent_min 18.64 / report/post_ent_std 5.58 / report/prior_ent_mag 70.43 / report/prior_ent_max 70.43 / report/prior_ent_mean 44.79 / report/prior_ent_min 24.81 / report/prior_ent_std 6.31 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 5.77 / report/reward_avg 0.51 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 7.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.52 / report/reward_rate 0.45 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.22 / eval/dyn_loss_std 5.99 / eval/image_loss_mean 0.94 / eval/image_loss_std 1.16 / eval/model_loss_mean 3.79 / eval/model_loss_std 4.56 / eval/post_ent_mag 51.29 / eval/post_ent_max 51.29 / eval/post_ent_mean 
41.51 / eval/post_ent_min 21.56 / eval/post_ent_std 3.68 / eval/prior_ent_mag 70.43 / eval/prior_ent_max 70.43 / eval/prior_ent_mean 45.49 / eval/prior_ent_min 37.81 / eval/prior_ent_std 3.74 / eval/rep_loss_mean 4.22 / eval/rep_loss_std 5.99 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.4 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.68 / eval/reward_rate 0.56 / 
replay/size 5.1e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3828 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 461.27 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.7e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7335 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1914 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.15 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 514000 Counter(514000) 513937
eval_Episode has 500 steps and return 380.6.
train_Episode has 500 steps and return 361.4.
Saved chunk: 20230922T084341F063549-1kRt8GWTg9chDcJ7u612yI-5bFaEbVZbVisf5XoQNR86c-1024.npz
Starting evaluation at step 514500 Counter(514500) 514437
eval_Episode has 500 steps and return 332.4.
Saved chunk: 20230922T084418F157998-55YXLO6LxZaDura81u0N0q-4QzCpBRQhb6hpGaEy1SmKA-1024.npz
train_Episode has 500 steps and return 346.3.
Starting evaluation at step 515000 Counter(515000) 514937
eval_Episode has 500 steps and return 395.1.
train_Episode has 500 steps and return 331.3.
Saved chunk: 20230922T084502F365555-5bFaEbVZbVisf5XoQNR86c-2MLpze20WbhUjtKDhv1BP9-1024.npz
Starting evaluation at step 515500 Counter(515500) 515437
eval_Episode has 500 steps and return 372.5.
Saved chunk: 20230922T084538F141455-4QzCpBRQhb6hpGaEy1SmKA-71AVbnvH9AaJEOhagLjBjJ-1024.npz
train_Episode has 500 steps and return 339.5.
Starting evaluation at step 516000 Counter(516000) 515937
eval_Episode has 500 steps and return 383.1.
train_Episode has 500 steps and return 305.0.
Saved chunk: 20230922T084623F034935-2MLpze20WbhUjtKDhv1BP9-4VkAOuzDj1TlLFjCokkr2S-1024.npz
Starting evaluation at step 516500 Counter(516500) 516437
eval_Episode has 500 steps and return 327.8.
train_Episode has 500 steps and return 299.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T084743F497066-4VkAOuzDj1TlLFjCokkr2S-0000000000000000000000-504.npz
Saved chunk: 20230922T084657F213171-71AVbnvH9AaJEOhagLjBjJ-0000000000000000000000-1012.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 517000 Counter(517000) 516937
Saved chunk: 20230922T084657F213171-71AVbnvH9AaJEOhagLjBjJ-6lz1iYbqxp6klhmBYsAyub-1024.npz
eval_Episode has 500 steps and return 322.1.
train_Episode has 500 steps and return 317.6.
Saved chunk: 20230922T084743F497066-4VkAOuzDj1TlLFjCokkr2S-2bPckUuNJz15DsH7ClxkIJ-1024.npz
Starting evaluation at step 517500 Counter(517500) 517437
eval_Episode has 500 steps and return 337.0.
train_Episode has 500 steps and return 321.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1035402 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 337.04 / eval_episode/reward_rate 0.61 / episode/length 500 / episode/score 321.48 / episode/reward_rate 0.56 / train/action_mag 3.72 / train/action_max 3.34 / train/action_mean 0.06 / train/action_min -3.62 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.54 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 55.45 / train/adv_mag 0.41 / train/adv_max 0.28 / train/adv_mean 
-4.7e-3 / train/adv_min -0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9.7e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.74 / train/dyn_loss_std 5.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 270.15 / train/extr_critic_max 270.15 / train/extr_critic_mean 259.7 / train/extr_critic_min 223.86 / train/extr_critic_std 7.81 / 
train/extr_return_normed_mag 1.28 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 270.84 / train/extr_return_raw_max 
270.84 / train/extr_return_raw_mean 259.56 / train/extr_return_raw_min 224.51 / train/extr_return_raw_std 7.88 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / 
train/image_loss_mean 0.98 / train/image_loss_std 1 / train/model_loss_mean 3.47 / train/model_loss_std 4.24 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 1.87 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.08 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.09 / train/policy_logprob_min -8.08 / train/policy_logprob_std 1.59 / train/policy_randomness_mag 0.59 / train/policy_randomness_max 0.59 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.3e-5 / train/policy_randomness_std 
0.08 / train/post_ent_mag 51.11 / train/post_ent_max 51.11 / train/post_ent_mean 41.97 / train/post_ent_min 21.28 / train/post_ent_std 3.93 / train/prior_ent_mag 70.46 / train/prior_ent_max 70.46 / train/prior_ent_mean 45.68 / train/prior_ent_min 33.19 / 
train/prior_ent_std 4.37 / train/rep_loss_mean 3.74 / train/rep_loss_std 5.72 / train/reward_avg 0.5 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / train/reward_rate 0.44 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.15 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 9.2e-11 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 5.9 / report/image_loss_mean 0.91 / report/image_loss_std 0.9 / 
report/model_loss_mean 3.39 / report/model_loss_std 4.26 / report/post_ent_mag 52.99 / report/post_ent_max 52.99 / report/post_ent_mean 41.98 / report/post_ent_min 22.27 / report/post_ent_std 3.71 / report/prior_ent_mag 70.35 / report/prior_ent_max 70.35 / 
report/prior_ent_mean 45.64 / report/prior_ent_min 36.74 / report/prior_ent_std 4.29 / report/rep_loss_mean 3.74 / report/rep_loss_std 5.9 / report/reward_avg 0.49 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.31 / report/reward_max_data 2 / 
report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.48 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1e-10 /
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.23 / eval/dyn_loss_std 4.88 / eval/image_loss_mean 0.76 / eval/image_loss_std 0.79 / eval/model_loss_mean 3.04 
/ eval/model_loss_std 3.61 / eval/post_ent_mag 47.84 / eval/post_ent_max 47.84 / eval/post_ent_mean 41.95 / eval/post_ent_min 23 / eval/post_ent_std 2.79 / eval/prior_ent_mag 70.35 / eval/prior_ent_max 70.35 / eval/prior_ent_mean 45.14 / eval/prior_ent_min 37.23 / 
eval/prior_ent_std 4.02 / eval/rep_loss_mean 3.23 / eval/rep_loss_std 4.88 / eval/reward_avg 0.74 / eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.5e-4 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.73 / eval/reward_rate 0.63 / replay/size 5.2e5 / replay/inserts 3774 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.7e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / 
timer/env.step_count 3774 / timer/env.step_total 19.51 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.56 / timer/replay._sample_frac 1.52 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.23 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / 
timer/agent.policy_count 7782 / timer/agent.policy_total 18.18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1887 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1887 / timer/agent.train_total 240.87 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.15

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 518000 Counter(518000) 517937
Saved chunk: 20230922T084852F000422-6lz1iYbqxp6klhmBYsAyub-6Kbjqkc0E57pwGzsC1uvfq-1024.npz
eval_Episode has 500 steps and return 370.2.
train_Episode has 500 steps and return 281.3.
Saved chunk: 20230922T084904F045892-2bPckUuNJz15DsH7ClxkIJ-2m9lmj27R73co19P2uGDoU-1024.npz
Starting evaluation at step 518500 Counter(518500) 518437
eval_Episode has 500 steps and return 353.9.
train_Episode has 500 steps and return 317.2.
Starting evaluation at step 519000 Counter(519000) 518937
Saved chunk: 20230922T085011F936644-6Kbjqkc0E57pwGzsC1uvfq-4w3W0vGSavlztovTHTaX8K-1024.npz
eval_Episode has 500 steps and return 347.6.
train_Episode has 500 steps and return 337.2.
Saved chunk: 20230922T085025F644654-2m9lmj27R73co19P2uGDoU-77QcMHp1R2oaJ2NsWMb5Oj-1024.npz
Starting evaluation at step 519500 Counter(519500) 519437
eval_Episode has 500 steps and return 401.5.
train_Episode has 500 steps and return 333.6.
Starting evaluation at step 520000 Counter(520000) 519937
Saved chunk: 20230922T085131F057173-4w3W0vGSavlztovTHTaX8K-5OUf0Yf2uj4YSzjOBNLtef-1024.npz
eval_Episode has 500 steps and return 357.2.
train_Episode has 500 steps and return 315.9.
Saved chunk: 20230922T085146F273239-77QcMHp1R2oaJ2NsWMb5Oj-6RKpY0fsbp5KBceqFOCHop-1024.npz
Starting evaluation at step 520500 Counter(520500) 520437
eval_Episode has 500 steps and return 350.7.
train_Episode has 500 steps and return 337.3.
Starting evaluation at step 521000 Counter(521000) 520937
Saved chunk: 20230922T085249F857747-5OUf0Yf2uj4YSzjOBNLtef-5EVTGSTxMOFw2UInlknIJ4-1024.npz
eval_Episode has 500 steps and return 386.0.
train_Episode has 500 steps and return 359.7.
Saved chunk: 20230922T085306F571352-6RKpY0fsbp5KBceqFOCHop-67lEKhaau8WiuK6AYDKHDG-1024.npz
Starting evaluation at step 521500 Counter(521500) 521437
eval_Episode has 500 steps and return 378.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1043002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 378.4 / eval_episode/reward_rate 0.66 / episode/length 500 / episode/score 359.66 / episode/reward_rate 0.63 / train/action_mag 3.73 / train/action_max 3.32 / train/action_mean 0.07 / train/action_min -3.63 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.55 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -8.53 / train/adv_mag 0.41 / train/adv_max 0.28 / train/adv_mean 1.8e-3 / train/adv_min
-0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 9.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.72 / train/dyn_loss_std 5.67 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 266.69 / train/extr_critic_max 266.69 / train/extr_critic_mean 256.37 / train/extr_critic_min 222.35 / train/extr_critic_std 7.78 / train/extr_return_normed_mag 1.26 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 267.53 / train/extr_return_raw_max 267.53 / train/extr_return_raw_mean 256.42 / train/extr_return_raw_min 
221.63 / train/extr_return_raw_std 7.83 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.97 / train/model_loss_mean 3.45 /
train/model_loss_std 4.19 / train/model_opt_grad_norm 9.27 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
2.14 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.1 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.09 / train/policy_logprob_min -8.1 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.04 / train/post_ent_max 51.04 / train/post_ent_mean 41.99 / 
train/post_ent_min 21.5 / train/post_ent_std 3.89 / train/prior_ent_mag 70.38 / train/prior_ent_max 70.38 / train/prior_ent_mean 45.69 / train/prior_ent_min 33.1 / train/prior_ent_std 4.33 / train/rep_loss_mean 3.72 / train/rep_loss_std 5.67 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.49 / train/reward_rate 0.44 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.16 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 7.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 5.74 / report/image_loss_mean 1.08 / report/image_loss_std 1 / report/model_loss_mean 3.6 / report/model_loss_std 4.25 / report/post_ent_mag 52.04 / report/post_ent_max 52.04 / 
report/post_ent_mean 42.07 / report/post_ent_min 21.3 / report/post_ent_std 4.15 / report/prior_ent_mag 70.42 / report/prior_ent_max 70.42 / report/prior_ent_mean 45.87 / report/prior_ent_min 34.14 / report/prior_ent_std 4.29 / report/rep_loss_mean 3.76 / 
report/rep_loss_std 5.74 / report/reward_avg 0.42 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.62 / report/reward_pred 0.42 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 3.9e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.26 / eval/dyn_loss_std 5.44 / eval/image_loss_mean 0.74 / eval/image_loss_std 0.82 / eval/model_loss_mean 2.98 / eval/model_loss_std 3.98 / eval/post_ent_mag 50.46 / eval/post_ent_max 50.46 / eval/post_ent_mean 41.18 / 
eval/post_ent_min 22.28 / eval/post_ent_std 2.96 / eval/prior_ent_mag 70.42 / eval/prior_ent_max 70.42 / eval/prior_ent_mean 44.54 / eval/prior_ent_min 39.29 / eval/prior_ent_std 4.29 / eval/rep_loss_mean 3.26 / eval/rep_loss_std 5.44 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.63 / eval/reward_rate 0.53 / 
replay/size 5.2e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.48 / timer/env.step_count 3800 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 464.54 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7808 / timer/agent.policy_total 18.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.2 / 
timer/dataset_train_count 1900 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1900 / timer/agent.train_total 242.04 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 342.4.
Starting evaluation at step 522000 Counter(522000) 521937
Saved chunk: 20230922T085408F469500-5EVTGSTxMOFw2UInlknIJ4-1cok6poQlNbwOTh9yL1igg-1024.npz
eval_Episode has 500 steps and return 384.4.
train_Episode has 500 steps and return 335.5.
Saved chunk: 20230922T085426F709856-67lEKhaau8WiuK6AYDKHDG-414mXEhVGoWGLbyfjyfTG0-1024.npz
Starting evaluation at step 522500 Counter(522500) 522437
eval_Episode has 500 steps and return 404.0.
train_Episode has 500 steps and return 343.5.
Starting evaluation at step 523000 Counter(523000) 522937
Saved chunk: 20230922T085528F416462-1cok6poQlNbwOTh9yL1igg-2lSqNyDDfGAsHpyPfctiuP-1024.npz
eval_Episode has 500 steps and return 351.5.
train_Episode has 500 steps and return 324.8.
Saved chunk: 20230922T085548F365710-414mXEhVGoWGLbyfjyfTG0-1c6oZPyQ1izWlZ6KCHNx5y-1024.npz
Starting evaluation at step 523500 Counter(523500) 523437
eval_Episode has 500 steps and return 387.4.
train_Episode has 500 steps and return 332.8.
Starting evaluation at step 524000 Counter(524000) 523937
Saved chunk: 20230922T085647F514308-2lSqNyDDfGAsHpyPfctiuP-66KcEUicHjeBAsUs8EmD1k-1024.npz
eval_Episode has 500 steps and return 379.6.
train_Episode has 500 steps and return 335.3.
Saved chunk: 20230922T085708F991330-1c6oZPyQ1izWlZ6KCHNx5y-323Jpb5uHo65rpz3sdsnej-1024.npz
Starting evaluation at step 524500 Counter(524500) 524437
eval_Episode has 500 steps and return 381.6.
train_Episode has 500 steps and return 365.0.
Starting evaluation at step 525000 Counter(525000) 524937
Saved chunk: 20230922T085806F318538-66KcEUicHjeBAsUs8EmD1k-60ESNLXylRknMH6oCZALTz-1024.npz
eval_Episode has 500 steps and return 347.5.
train_Episode has 500 steps and return 311.7.
Saved chunk: 20230922T085829F262761-323Jpb5uHo65rpz3sdsnej-0CaxNJe2CaNT8G36aUFFuo-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1050662 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 311.74 / episode/reward_rate 0.57 / eval_episode/length 500 / eval_episode/score 347.48 / eval_episode/reward_rate 0.71 / train/action_mag 3.69 / train/action_max 3.31 / train/action_mean 0.07 / train/action_min -3.6 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.5 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 5.01 / train/adv_mag 0.51 / train/adv_max 0.38 / train/adv_mean 4.2e-4 / train/adv_min 
-0.4 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.73 / train/dyn_loss_std 5.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 267.73 / train/extr_critic_max 267.73 / train/extr_critic_mean 257.3 / train/extr_critic_min 218.95 / train/extr_critic_std 8.01 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 268.55 / train/extr_return_raw_max 268.55 / train/extr_return_raw_mean 257.32 / train/extr_return_raw_min 
220.13 / train/extr_return_raw_std 8.07 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.97 / train/model_loss_mean 3.46 / 
train/model_loss_std 4.18 / train/model_opt_grad_norm 9.23 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.55 / train/policy_entropy_max 
2.02 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.22 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -8.22 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.6 / train/policy_randomness_max 0.6 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.02 / train/post_ent_max 51.02 / train/post_ent_mean 41.98 / 
train/post_ent_min 21.5 / train/post_ent_std 3.88 / train/prior_ent_mag 70.4 / train/prior_ent_max 70.4 / train/prior_ent_mean 45.68 / train/prior_ent_min 33.03 / train/prior_ent_std 4.31 / train/rep_loss_mean 3.73 / train/rep_loss_std 5.66 / train/reward_avg 0.51 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.51 / train/reward_rate 0.45 /
train_stats/mean_log_entropy -3.15 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 7.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 5.41 / report/image_loss_mean 0.97 / report/image_loss_std 0.95 / report/model_loss_mean 3.37 / report/model_loss_std 3.95 / report/post_ent_mag 50.78 / report/post_ent_max 50.78 /
report/post_ent_mean 42.08 / report/post_ent_min 23.11 / report/post_ent_std 3.72 / report/prior_ent_mag 70.29 / report/prior_ent_max 70.29 / report/prior_ent_mean 45.73 / report/prior_ent_min 29.02 / report/prior_ent_std 4.03 / report/rep_loss_mean 3.58 / 
report/rep_loss_std 5.41 / report/reward_avg 0.53 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.53 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.57 / eval/dyn_loss_std 6.5 / eval/image_loss_mean 1.25 / eval/image_loss_std 1.73 / eval/model_loss_mean 4.29 / eval/model_loss_std 5.2 / eval/post_ent_mag 51.59 / eval/post_ent_max 51.59 / eval/post_ent_mean 
41.27 / eval/post_ent_min 21.19 / eval/post_ent_std 3.84 / eval/prior_ent_mag 70.29 / eval/prior_ent_max 70.29 / eval/prior_ent_mean 45.48 / eval/prior_ent_min 32.5 / eval/prior_ent_std 4.41 / eval/rep_loss_mean 4.57 / eval/rep_loss_std 6.5 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.64 / eval/reward_rate 0.55 / 
replay/size 5.3e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3830 / timer/env.step_total 20.02 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.34 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7337 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1915 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.99 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 525500 Counter(525500) 525437
eval_Episode has 500 steps and return 372.6.
train_Episode has 500 steps and return 341.8.
Starting evaluation at step 526000 Counter(526000) 525937
Saved chunk: 20230922T085924F879374-60ESNLXylRknMH6oCZALTz-6woxBVSuEj2YCHW3a0ekLb-1024.npz
eval_Episode has 500 steps and return 353.2.
train_Episode has 500 steps and return 284.6.
Saved chunk: 20230922T085949F371280-0CaxNJe2CaNT8G36aUFFuo-5NK1mvdSi6oQ7sgbnmfRbF-1024.npz
Starting evaluation at step 526500 Counter(526500) 526437
eval_Episode has 500 steps and return 377.6.
train_Episode has 500 steps and return 308.1.
Starting evaluation at step 527000 Counter(527000) 526937
Saved chunk: 20230922T090045F066809-6woxBVSuEj2YCHW3a0ekLb-0ikBVkjCgBadneYsieXWen-1024.npz
eval_Episode has 500 steps and return 391.5.
train_Episode has 500 steps and return 348.8.
Saved chunk: 20230922T090111F257750-5NK1mvdSi6oQ7sgbnmfRbF-00Y1i0vRRaGemyUhSpjfIA-1024.npz
Starting evaluation at step 527500 Counter(527500) 527437
eval_Episode has 500 steps and return 411.8.
train_Episode has 500 steps and return 340.6.
Starting evaluation at step 528000 Counter(528000) 527937
Saved chunk: 20230922T090204F028816-0ikBVkjCgBadneYsieXWen-7kmCd2jUa9R2SeY83AJota-1024.npz
eval_Episode has 500 steps and return 390.1.
train_Episode has 500 steps and return 322.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T090322F851599-7kmCd2jUa9R2SeY83AJota-0000000000000000000000-247.npz
Saved chunk: 20230922T090231F720092-00Y1i0vRRaGemyUhSpjfIA-0000000000000000000000-740.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T090231F720092-00Y1i0vRRaGemyUhSpjfIA-2ngnhUN7cYFIMod3OBsfCm-1024.npz
Starting evaluation at step 528500 Counter(528500) 528437
eval_Episode has 500 steps and return 366.6.
train_Episode has 500 steps and return 358.6.
Starting evaluation at step 529000 Counter(529000) 528937
Saved chunk: 20230922T090322F851599-7kmCd2jUa9R2SeY83AJota-21UBNq9i9CmBhrN7CkS2tY-1024.npz
eval_Episode has 500 steps and return 394.7.
train_Episode has 500 steps and return 334.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1058202 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 394.68 / eval_episode/reward_rate 0.68 / episode/length 500 / episode/score 334.75 / episode/reward_rate 0.59 / train/action_mag 3.69 / train/action_max 3.34 / train/action_mean 0.07 / train/action_min -3.6 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.49 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -4.8 / train/adv_mag 0.49 / train/adv_max 0.38 / train/adv_mean 1.4e-3 / train/adv_min 
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.71 / train/dyn_loss_std 5.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 268.75 / train/extr_critic_max 268.75 / train/extr_critic_mean 257.88 / train/extr_critic_min 214.09 / train/extr_critic_std 9.8 / train/extr_return_normed_mag 1.5 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.69 / train/extr_return_normed_min -0.76 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 269.59 / train/extr_return_raw_max 269.59 / train/extr_return_raw_mean 257.92 / train/extr_return_raw_min 
214.57 / train/extr_return_raw_std 9.85 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.97 / train/model_loss_mean 3.44 / 
train/model_loss_std 4.17 / train/model_opt_grad_norm 9.54 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.56 / train/policy_entropy_max 
2.21 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.74 / train/policy_logprob_mag 8.23 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -8.23 / train/policy_logprob_std 1.6 / 
train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.08 / train/post_ent_max 51.08 / train/post_ent_mean 41.93 / 
train/post_ent_min 21.39 / train/post_ent_std 3.92 / train/prior_ent_mag 70.35 / train/prior_ent_max 70.35 / train/prior_ent_mean 45.62 / train/prior_ent_min 32.66 / train/prior_ent_std 4.37 / train/rep_loss_mean 3.71 / train/rep_loss_std 5.64 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / train/reward_rate 0.45 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.14 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 6.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.6 / report/dyn_loss_std 5.7 / report/image_loss_mean 0.96 / report/image_loss_std 0.95 / report/model_loss_mean 3.35 / report/model_loss_std 4.26 / report/post_ent_mag 51.9 / report/post_ent_max 51.9 / 
report/post_ent_mean 42.33 / report/post_ent_min 21.96 / report/post_ent_std 4.73 / report/prior_ent_mag 70.34 / report/prior_ent_max 70.34 / report/prior_ent_mean 45.86 / report/prior_ent_min 27.49 / report/prior_ent_std 5.35 / report/rep_loss_mean 3.6 / 
report/rep_loss_std 5.7 / report/reward_avg 0.44 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 5.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.44 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 8.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.3 / eval/dyn_loss_std 6.54 / eval/image_loss_mean 1.13 / eval/image_loss_std 2.26 / eval/model_loss_mean 4.07 / eval/model_loss_std 5.81 / eval/post_ent_mag 48.65 / eval/post_ent_max 48.65 / eval/post_ent_mean 
41.6 / eval/post_ent_min 20.44 / eval/post_ent_std 3.68 / eval/prior_ent_mag 70.34 / eval/prior_ent_max 70.34 / eval/prior_ent_mean 45.67 / eval/prior_ent_min 37.01 / eval/prior_ent_std 3.97 / eval/rep_loss_mean 4.3 / eval/rep_loss_std 6.54 / eval/reward_avg 0.73 / 
eval/reward_loss_mean 0.36 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.72 / eval/reward_rate 0.64 / 
replay/size 5.3e5 / replay/inserts 3770 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3770 / timer/env.step_total 19.56 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.11 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7778 / timer/agent.policy_total 18.21 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1885 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1885 / timer/agent.train_total 240.72 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 
0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / 
timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T090352F306519-2ngnhUN7cYFIMod3OBsfCm-6uhxZ4vb1e6Qc7jkb621XQ-1024.npz
Starting evaluation at step 529500 Counter(529500) 529437
eval_Episode has 500 steps and return 369.3.
train_Episode has 500 steps and return 353.9.
Starting evaluation at step 530000 Counter(530000) 529937
Saved chunk: 20230922T090441F881806-21UBNq9i9CmBhrN7CkS2tY-7EAp7IVCjDJuj31aJqjSr1-1024.npz
eval_Episode has 500 steps and return 362.8.
train_Episode has 500 steps and return 328.3.
Saved chunk: 20230922T090513F932587-6uhxZ4vb1e6Qc7jkb621XQ-10Fn4Me9jz9imaamSS5wYZ-1024.npz
Starting evaluation at step 530500 Counter(530500) 530437
eval_Episode has 500 steps and return 370.1.
train_Episode has 500 steps and return 305.5.
Starting evaluation at step 531000 Counter(531000) 530937
Saved chunk: 20230922T090602F160534-7EAp7IVCjDJuj31aJqjSr1-3ZG2XiVzuqiXsdL6GVT740-1024.npz
eval_Episode has 500 steps and return 371.5.
train_Episode has 500 steps and return 321.8.
Saved chunk: 20230922T090634F560951-10Fn4Me9jz9imaamSS5wYZ-2r81n3bW9CnVeA2zapaiGL-1024.npz
Starting evaluation at step 531500 Counter(531500) 531437
eval_Episode has 500 steps and return 387.1.
train_Episode has 500 steps and return 305.1.
Starting evaluation at step 532000 Counter(532000) 531937
Saved chunk: 20230922T090721F014084-3ZG2XiVzuqiXsdL6GVT740-6o11Y7xENTkVlr0P48qZgG-1024.npz
eval_Episode has 500 steps and return 393.4.
train_Episode has 500 steps and return 278.6.
Saved chunk: 20230922T090754F914849-2r81n3bW9CnVeA2zapaiGL-1wo5LKzlT0LqOoFntookzn-1024.npz
Starting evaluation at step 532500 Counter(532500) 532437
eval_Episode has 500 steps and return 388.7.
train_Episode has 500 steps and return 338.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1065858 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 388.69 / eval_episode/reward_rate 0.73 / episode/length 500 / episode/score 338.11 / episode/reward_rate 0.58 / train/action_mag 3.76 / train/action_max 3.37 / train/action_mean 0.07 / train/action_min -3.66 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.53 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 11.78 / train/adv_mag 0.54 / train/adv_max 0.4 / train/adv_mean 
-2.8e-4 / train/adv_min -0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 8.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.74 / train/dyn_loss_std 5.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 268.53 / train/extr_critic_max 268.53 / train/extr_critic_mean 258.11 / train/extr_critic_min 221.48 / train/extr_critic_std 7.52 / 
train/extr_return_normed_mag 1.25 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 269.4 / train/extr_return_raw_max 
269.4 / train/extr_return_raw_mean 258.1 / train/extr_return_raw_min 223.5 / train/extr_return_raw_std 7.58 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / 
train/image_loss_mean 0.97 / train/image_loss_std 0.97 / train/model_loss_mean 3.46 / train/model_loss_std 4.19 / train/model_opt_grad_norm 9.11 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.56 / train/policy_entropy_max 2.51 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.75 / train/policy_logprob_mag 8.17 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.06 / train/policy_logprob_min -8.17 / train/policy_logprob_std 1.6 / train/policy_randomness_mag 0.66 / train/policy_randomness_max 0.66 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4e-5 / train/policy_randomness_std 0.08
/ train/post_ent_mag 51.17 / train/post_ent_max 51.17 / train/post_ent_mean 41.97 / train/post_ent_min 21.4 / train/post_ent_std 3.9 / train/prior_ent_mag 70.32 / train/prior_ent_max 70.32 / train/prior_ent_mean 45.65 / train/prior_ent_min 32.96 / train/prior_ent_std 
4.35 / train/rep_loss_mean 3.74 / train/rep_loss_std 5.66 / train/reward_avg 0.5 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.2e-3 / train/reward_pos_acc
1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / train/reward_rate 0.44 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.11 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.69 / report/dyn_loss_std 5.76 / report/image_loss_mean 0.9 / report/image_loss_std 0.78 / report/model_loss_mean 3.38 / 
report/model_loss_std 4.09 / report/post_ent_mag 50.02 / report/post_ent_max 50.02 / report/post_ent_mean 42.18 / report/post_ent_min 22.25 / report/post_ent_std 3.61 / report/prior_ent_mag 70.3 / report/prior_ent_max 70.3 / report/prior_ent_mean 45.89 / 
report/prior_ent_min 36.26 / report/prior_ent_std 4.06 / report/rep_loss_mean 3.69 / report/rep_loss_std 5.76 / report/reward_avg 0.54 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / 
report/reward_neg_acc 0.99 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.54 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.89 / eval/dyn_loss_std 5.9 / eval/image_loss_mean 1.05 / eval/image_loss_std 1.28 / eval/model_loss_mean 3.72 / eval/model_loss_std 4.5
/ eval/post_ent_mag 49.67 / eval/post_ent_max 49.67 / eval/post_ent_mean 41.44 / eval/post_ent_min 21.98 / eval/post_ent_std 3.5 / eval/prior_ent_mag 70.3 / eval/prior_ent_max 70.3 / eval/prior_ent_mean 45.24 / eval/prior_ent_min 35.4 / eval/prior_ent_std 4.16 / 
eval/rep_loss_mean 3.89 / eval/rep_loss_std 5.9 / eval/reward_avg 0.74 / eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.55 / eval/reward_pred 0.73 / eval/reward_rate 0.62 / replay/size 5.3e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3828 / 
timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 467.41 / timer/replay._sample_frac 1.56 / timer/replay._sample_avg 
0.02 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7335 / timer/agent.policy_total 17.24 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.2 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.05 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 533000 Counter(533000) 532937
Saved chunk: 20230922T090839F820268-6o11Y7xENTkVlr0P48qZgG-0xmjMGGFqtlUzzuOoEUwzS-1024.npz
eval_Episode has 500 steps and return 378.1.
train_Episode has 500 steps and return 340.0.
Starting evaluation at step 533500 Counter(533500) 533437
eval_Episode has 500 steps and return 365.6.
Saved chunk: 20230922T090915F245915-1wo5LKzlT0LqOoFntookzn-55s3EIPgAvPaMrOsrA6tjT-1024.npz
train_Episode has 500 steps and return 336.2.
Starting evaluation at step 534000 Counter(534000) 533937
Saved chunk: 20230922T090959F625088-0xmjMGGFqtlUzzuOoEUwzS-01G7wpRQb8zjdzVZyD3S4B-1024.npz
eval_Episode has 500 steps and return 379.0.
train_Episode has 500 steps and return 348.9.
Starting evaluation at step 534500 Counter(534500) 534437
eval_Episode has 500 steps and return 368.5.
Saved chunk: 20230922T091040F508099-55s3EIPgAvPaMrOsrA6tjT-4MXCOgLElle8iH7CY5DZ8E-1024.npz
train_Episode has 500 steps and return 339.1.
Starting evaluation at step 535000 Counter(535000) 534937
Saved chunk: 20230922T091118F832408-01G7wpRQb8zjdzVZyD3S4B-5dCSRGUxIpgY4kvW7fjwY2-1024.npz
eval_Episode has 500 steps and return 393.5.
train_Episode has 500 steps and return 327.4.
Starting evaluation at step 535500 Counter(535500) 535437
eval_Episode has 500 steps and return 377.1.
Saved chunk: 20230922T091201F099121-4MXCOgLElle8iH7CY5DZ8E-7mQGMblnjg8sDeOigKVhmi-1024.npz
train_Episode has 500 steps and return 354.5.
Starting evaluation at step 536000 Counter(536000) 535937
eval_Episode has 500 steps and return 329.7.
Saved chunk: 20230922T091237F749531-5dCSRGUxIpgY4kvW7fjwY2-6wHWYGIyD0RYy3B5gPswqt-1024.npz
train_Episode has 500 steps and return 362.0.
Starting evaluation at step 536500 Counter(536500) 536437
eval_Episode has 500 steps and return 380.3.
train_Episode has 500 steps and return 328.9.
Saved chunk: 20230922T091321F450426-7mQGMblnjg8sDeOigKVhmi-2MKUmVDzRVYbvwnMnDKtF4-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1073414 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 380.32 / eval_episode/reward_rate 0.62 / episode/length 500 / episode/score 328.88 / episode/reward_rate 0.57 / train/action_mag 3.75 / train/action_max 3.3 / train/action_mean 0.07 / train/action_min -3.67 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.56 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -7.5 / train/adv_mag 0.49 / train/adv_max 0.35 / train/adv_mean 1.7e-3 / train/adv_min 
-0.43 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.72 / train/dyn_loss_std 5.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 269.87 / train/extr_critic_max 269.87 / train/extr_critic_mean 259.5 / train/extr_critic_min 221.21 / train/extr_critic_std 7.91 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 270.75 / train/extr_return_raw_max 270.75 / train/extr_return_raw_mean 259.54 / train/extr_return_raw_min 
222.67 / train/extr_return_raw_std 7.95 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.98 / train/model_loss_mean 3.44 / 
train/model_loss_std 4.19 / train/model_opt_grad_norm 9.38 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.61 / train/policy_entropy_max 
2.77 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.74 / train/policy_logprob_mag 8.22 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.22 / train/policy_logprob_std 1.6 / 
train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.05 / train/post_ent_max 51.05 / train/post_ent_mean 41.99 / 
train/post_ent_min 21.57 / train/post_ent_std 3.91 / train/prior_ent_mag 70.3 / train/prior_ent_max 70.3 / train/prior_ent_mean 45.66 / train/prior_ent_min 33.14 / train/prior_ent_std 4.35 / train/rep_loss_mean 3.72 / train/rep_loss_std 5.65 / train/reward_avg 0.51 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / train/reward_rate 0.45 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.14 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.69 / report/dyn_loss_std 5.81 / report/image_loss_mean 0.99 / report/image_loss_std 1.06 / report/model_loss_mean 3.44 / report/model_loss_std 4.41 / report/post_ent_mag 50.04 / report/post_ent_max 50.04 /
report/post_ent_mean 42.22 / report/post_ent_min 21.71 / report/post_ent_std 3.69 / report/prior_ent_mag 70.3 / report/prior_ent_max 70.3 / report/prior_ent_mean 45.88 / report/prior_ent_min 36.01 / report/prior_ent_std 4.06 / report/rep_loss_mean 3.69 / 
report/rep_loss_std 5.81 / report/reward_avg 0.48 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.48 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.73 / eval/dyn_loss_std 5.51 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.07 / eval/model_loss_mean 3.55 / eval/model_loss_std 4.08 / eval/post_ent_mag 49.9 / eval/post_ent_max 49.9 / eval/post_ent_mean 40.8 / 
eval/post_ent_min 22.14 / eval/post_ent_std 4.67 / eval/prior_ent_mag 70.3 / eval/prior_ent_max 70.3 / eval/prior_ent_mean 44.49 / eval/prior_ent_min 27.92 / eval/prior_ent_std 5.59 / eval/rep_loss_mean 3.73 / eval/rep_loss_std 5.51 / eval/reward_avg 0.72 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.71 / eval/reward_rate 0.61 / 
replay/size 5.4e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3778 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.39 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 18.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1889 / timer/agent.train_total 240.92 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 537000 Counter(537000) 536937
eval_Episode has 500 steps and return 366.3.
Saved chunk: 20230922T091356F364487-6wHWYGIyD0RYy3B5gPswqt-1bf3rA7ySPFG8AEWAnE2XY-1024.npz
train_Episode has 500 steps and return 302.9.
Starting evaluation at step 537500 Counter(537500) 537437
eval_Episode has 500 steps and return 389.1.
train_Episode has 500 steps and return 343.6.
Saved chunk: 20230922T091441F479467-2MKUmVDzRVYbvwnMnDKtF4-0JyMIrECQge62cedpxpJ55-1024.npz
Starting evaluation at step 538000 Counter(538000) 537937
eval_Episode has 500 steps and return 355.2.
Saved chunk: 20230922T091516F260003-1bf3rA7ySPFG8AEWAnE2XY-1jHCBhtfr1ZeiYAM0dk6pX-1024.npz
train_Episode has 500 steps and return 331.5.
Starting evaluation at step 538500 Counter(538500) 538437
eval_Episode has 500 steps and return 362.0.
train_Episode has 500 steps and return 305.1.
Saved chunk: 20230922T091603F332894-0JyMIrECQge62cedpxpJ55-6PdwGtkLHYm2fvuvLUrkeV-1024.npz
Starting evaluation at step 539000 Counter(539000) 538937
eval_Episode has 500 steps and return 357.4.
Saved chunk: 20230922T091635F370487-1jHCBhtfr1ZeiYAM0dk6pX-3AaUMMcYFWIwNQLbNAhS12-1024.npz
train_Episode has 500 steps and return 308.9.
Starting evaluation at step 539500 Counter(539500) 539437
eval_Episode has 500 steps and return 381.7.
train_Episode has 500 steps and return 322.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T091723F819727-6PdwGtkLHYm2fvuvLUrkeV-0000000000000000000000-976.npz
Saved chunk: 20230922T091754F204691-3AaUMMcYFWIwNQLbNAhS12-0000000000000000000000-506.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T091723F819727-6PdwGtkLHYm2fvuvLUrkeV-1nl4VHNiOqsH4CKTJMdBl5-1024.npz
Starting evaluation at step 540000 Counter(540000) 539937
eval_Episode has 500 steps and return 348.7.
train_Episode has 500 steps and return 327.4.
Starting evaluation at step 540500 Counter(540500) 540437
Saved chunk: 20230922T091754F204691-3AaUMMcYFWIwNQLbNAhS12-4G8HjdjYcPtyxAOgh2rNKv-1024.npz
eval_Episode has 500 steps and return 366.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1081002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 366.48 / eval_episode/reward_rate 0.63 / episode/length 500 / episode/score 327.44 / episode/reward_rate 0.55 / train/action_mag 3.71 / train/action_max 3.34 / train/action_mean 0.07 / train/action_min -3.63 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.55 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 12.77 / train/adv_mag 0.47 / train/adv_max 0.34 / train/adv_mean 
-3.8e-4 / train/adv_min -0.4 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 3.73 / train/dyn_loss_std 5.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 269.64 / train/extr_critic_max 269.64 / train/extr_critic_mean 259.31 / train/extr_critic_min 223.28 / train/extr_critic_std 7.6 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.49 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 270.42 / train/extr_return_raw_max 270.42 / train/extr_return_raw_mean 259.3 / train/extr_return_raw_min 
224.15 / train/extr_return_raw_std 7.66 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.97 / train/model_loss_mean 3.45 / 
train/model_loss_std 4.17 / train/model_opt_grad_norm 9.27 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.62 / train/policy_entropy_max 
2.74 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.76 / train/policy_logprob_mag 8.4 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -8.4 / train/policy_logprob_std 1.61 / 
train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.7e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.03 / train/post_ent_max 51.03 / train/post_ent_mean 41.95 / 
train/post_ent_min 21.13 / train/post_ent_std 3.87 / train/prior_ent_mag 70.25 / train/prior_ent_max 70.25 / train/prior_ent_mean 45.64 / train/prior_ent_min 33.14 / train/prior_ent_std 4.31 / train/rep_loss_mean 3.73 / train/rep_loss_std 5.65 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / train/reward_rate 0.45 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.13 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 5.24 / report/image_loss_mean 0.95 / report/image_loss_std 0.82 / report/model_loss_mean 3.32 / report/model_loss_std 3.77 / report/post_ent_mag 50.17 / report/post_ent_max 50.17 /
report/post_ent_mean 41.86 / report/post_ent_min 21.84 / report/post_ent_std 3.57 / report/prior_ent_mag 70.26 / report/prior_ent_max 70.26 / report/prior_ent_mean 45.37 / report/prior_ent_min 32.66 / report/prior_ent_std 4.06 / report/rep_loss_mean 3.49 / 
report/rep_loss_std 5.24 / report/reward_avg 0.57 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.57 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-11 / eval/cont_loss_std 8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.06 / eval/dyn_loss_std 6.05 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.29 / eval/model_loss_mean 3.77 / eval/model_loss_std 4.73 / eval/post_ent_mag 51.67 / eval/post_ent_max 51.67 / eval/post_ent_mean 41.52 / 
eval/post_ent_min 21.75 / eval/post_ent_std 3.65 / eval/prior_ent_mag 70.26 / eval/prior_ent_max 70.26 / eval/prior_ent_mean 45.38 / eval/prior_ent_min 35.32 / eval/prior_ent_std 3.79 / eval/rep_loss_mean 4.06 / eval/rep_loss_std 6.05 / eval/reward_avg 0.76 / 
eval/reward_loss_mean 0.36 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.75 / eval/reward_rate 0.65 / 
replay/size 5.4e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.49 / timer/env.step_count 3794 / timer/env.step_total 19.84 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.52 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.09 / timer/agent.save_frac 3.1e-4 / timer/agent.save_avg 0.09 / timer/agent.save_min 0.09 / timer/agent.save_max 0.09 / timer/agent.policy_count 7802 / timer/agent.policy_total 18.33 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1897 / timer/agent.train_total 241.76 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 
0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 317.0.
Saved chunk: 20230922T091844F386172-1nl4VHNiOqsH4CKTJMdBl5-15xNL3xgd4n0NDdC4FlrZR-1024.npz
Starting evaluation at step 541000 Counter(541000) 540937
eval_Episode has 500 steps and return 350.7.
train_Episode has 500 steps and return 340.0.
Starting evaluation at step 541500 Counter(541500) 541437
Saved chunk: 20230922T091948F815065-4G8HjdjYcPtyxAOgh2rNKv-2ago6Jt7CCUGA7aSLkz2cm-1024.npz
eval_Episode has 500 steps and return 393.0.
train_Episode has 500 steps and return 340.8.
Saved chunk: 20230922T092005F744293-15xNL3xgd4n0NDdC4FlrZR-614J2Em5qkWSfdrO5xUVcB-1024.npz
Starting evaluation at step 542000 Counter(542000) 541937
eval_Episode has 500 steps and return 367.2.
train_Episode has 500 steps and return 364.8.
Starting evaluation at step 542500 Counter(542500) 542437
Saved chunk: 20230922T092109F216685-2ago6Jt7CCUGA7aSLkz2cm-0h9lkTNEfcbC9U3aAiHrev-1024.npz
eval_Episode has 500 steps and return 384.9.
train_Episode has 500 steps and return 335.6.
Saved chunk: 20230922T092126F595369-614J2Em5qkWSfdrO5xUVcB-6VOvfshhzoUTvQDqoraXEP-1024.npz
Starting evaluation at step 543000 Counter(543000) 542937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 345.4.
Starting evaluation at step 543500 Counter(543500) 543437
Saved chunk: 20230922T092228F286707-0h9lkTNEfcbC9U3aAiHrev-5ih7fFxoEoB4EEbuPulh0U-1024.npz
eval_Episode has 500 steps and return 347.9.
train_Episode has 500 steps and return 380.6.
Saved chunk: 20230922T092247F202116-6VOvfshhzoUTvQDqoraXEP-03NCuADKaju10XBATqYNcB-1024.npz
Starting evaluation at step 544000 Counter(544000) 543937
eval_Episode has 500 steps and return 391.0.
train_Episode has 500 steps and return 352.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1088642 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 352.75 / episode/reward_rate 0.6 / eval_episode/length 500 / eval_episode/score 391.04 / eval_episode/reward_rate 0.64 / train/action_mag 3.62 / train/action_max 3.29 / train/action_mean 0.07 / train/action_min -3.54 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.54 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -8.15 / train/adv_mag 0.57 / train/adv_max 0.44 / train/adv_mean 1.8e-3 / train/adv_min
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 8.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.71 / train/dyn_loss_std 5.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 270.69 / train/extr_critic_max 270.69 / train/extr_critic_mean 260.81 / train/extr_critic_min 224.68 / train/extr_critic_std 6.94 / train/extr_return_normed_mag 1.19 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 271.54 / train/extr_return_raw_max 271.54 / train/extr_return_raw_mean 260.87 / train/extr_return_raw_min 
228.31 / train/extr_return_raw_std 6.99 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.97 / train/model_loss_mean 3.43 /
train/model_loss_std 4.16 / train/model_opt_grad_norm 9.13 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.55 / train/policy_entropy_max 
2.07 / train/policy_entropy_mean -3.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.68 / train/policy_logprob_mag 8.24 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.1 / train/policy_logprob_min -8.24 / train/policy_logprob_std 1.57 / 
train/policy_randomness_mag 0.61 / train/policy_randomness_max 0.61 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.7e-5 / train/policy_randomness_std 0.07 / train/post_ent_mag 51.02 / train/post_ent_max 51.02 / train/post_ent_mean 41.97 / 
train/post_ent_min 21.57 / train/post_ent_std 3.86 / train/prior_ent_mag 70.2 / train/prior_ent_max 70.2 / train/prior_ent_mean 45.63 / train/prior_ent_min 33.36 / train/prior_ent_std 4.28 / train/rep_loss_mean 3.71 / train/rep_loss_std 5.63 / train/reward_avg 0.51 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.54 / train/reward_pred 0.51 / train/reward_rate 0.45 /
train_stats/mean_log_entropy -3.15 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.59 / report/dyn_loss_std 5.43 / report/image_loss_mean 0.9 / report/image_loss_std 0.8 / report/model_loss_mean 3.34 / report/model_loss_std 3.97 / report/post_ent_mag 51.02 / report/post_ent_max 51.02 / 
report/post_ent_mean 42.36 / report/post_ent_min 23.55 / report/post_ent_std 3.67 / report/prior_ent_mag 70.18 / report/prior_ent_max 70.18 / report/prior_ent_mean 46.15 / report/prior_ent_min 33.91 / report/prior_ent_std 4.02 / report/rep_loss_mean 3.59 / 
report/rep_loss_std 5.43 / report/reward_avg 0.54 / report/reward_loss_mean 0.29 / report/reward_loss_std 0.37 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.54 / report/reward_rate 0.51 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 9.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.48 / eval/dyn_loss_std 5.02 / eval/image_loss_mean 0.77 / eval/image_loss_std 0.62 / eval/model_loss_mean 3.23 / eval/model_loss_std 3.59 / eval/post_ent_mag 48.32 / eval/post_ent_max 48.32 / eval/post_ent_mean 
41.73 / eval/post_ent_min 25.18 / eval/post_ent_std 3.03 / eval/prior_ent_mag 70.18 / eval/prior_ent_max 70.18 / eval/prior_ent_mean 45.37 / eval/prior_ent_min 40.68 / eval/prior_ent_std 3.68 / eval/rep_loss_mean 3.48 / eval/rep_loss_std 5.02 / eval/reward_avg 0.8 / 
eval/reward_loss_mean 0.37 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.78 / eval/reward_rate 0.67 / 
replay/size 5.4e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3820 / timer/env.step_total 19.75 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458.02 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1910 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1910 / timer/agent.train_total 244 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.14 / timer/agent.report_frac 4.7e-4 / timer/agent.report_avg 0.07 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.08 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 544500 Counter(544500) 544437
Saved chunk: 20230922T092347F140797-5ih7fFxoEoB4EEbuPulh0U-5cmYh9C4IS8ugbaeYz8Xcs-1024.npz
eval_Episode has 500 steps and return 361.8.
train_Episode has 500 steps and return 326.7.
Saved chunk: 20230922T092407F533933-03NCuADKaju10XBATqYNcB-3fthyh4l0lrJD584WuLK3Y-1024.npz
Starting evaluation at step 545000 Counter(545000) 544937
eval_Episode has 500 steps and return 380.7.
train_Episode has 500 steps and return 319.6.
Starting evaluation at step 545500 Counter(545500) 545437
Saved chunk: 20230922T092507F182589-5cmYh9C4IS8ugbaeYz8Xcs-2yyL92Tq1WahcbvIXb9xYk-1024.npz
eval_Episode has 500 steps and return 342.6.
train_Episode has 500 steps and return 313.4.
Saved chunk: 20230922T092529F397560-3fthyh4l0lrJD584WuLK3Y-3gptJjBTQTMjzXLrcj9Eml-1024.npz
Starting evaluation at step 546000 Counter(546000) 545937
eval_Episode has 500 steps and return 374.7.
train_Episode has 500 steps and return 307.7.
Starting evaluation at step 546500 Counter(546500) 546437
Saved chunk: 20230922T092626F699286-2yyL92Tq1WahcbvIXb9xYk-6U1FITWHDotKTBZhYasOLE-1024.npz
eval_Episode has 500 steps and return 363.5.
train_Episode has 500 steps and return 324.7.
Saved chunk: 20230922T092650F280197-3gptJjBTQTMjzXLrcj9Eml-6RB5MvNfXkSKpVnFVFirRr-1024.npz
Starting evaluation at step 547000 Counter(547000) 546937
eval_Episode has 500 steps and return 368.9.
train_Episode has 500 steps and return 315.9.
Starting evaluation at step 547500 Counter(547500) 547437
Saved chunk: 20230922T092745F704286-6U1FITWHDotKTBZhYasOLE-6wk2XkYXWr9OjeTehRRRlX-1024.npz
eval_Episode has 500 steps and return 401.8.
train_Episode has 500 steps and return 347.0.
Saved chunk: 20230922T092810F897142-6RB5MvNfXkSKpVnFVFirRr-4CqQQvVwKbXn2akaJoEqhs-1024.npz
Starting evaluation at step 548000 Counter(548000) 547937
eval_Episode has 500 steps and return 387.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1096170 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 387.94 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 346.98 / episode/reward_rate 0.6 / train/action_mag 3.77 / train/action_max 3.35 / train/action_mean 0.07 / train/action_min -3.67 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.57 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 25.68 / train/adv_mag 0.47 / train/adv_max 0.33 / train/adv_mean -1.7e-3 / 
train/adv_min -0.43 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 5.69 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 269.64 / train/extr_critic_max 269.64 / train/extr_critic_mean 258.49 / train/extr_critic_min 214.09 / train/extr_critic_std 9.95 / train/extr_return_normed_mag 1.54 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.68 / train/extr_return_normed_min -0.81 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 270.42 / train/extr_return_raw_max 270.42 / train/extr_return_raw_mean 258.44 / train/extr_return_raw_min 
214.31 / train/extr_return_raw_std 10.02 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.98 / train/model_loss_mean 3.45 
/ train/model_loss_std 4.21 / train/model_opt_grad_norm 9.59 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7340.43 / train/policy_entropy_mag 3.57 / 
train/policy_entropy_max 2.5 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.75 / train/policy_logprob_mag 8.24 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.24 / 
train/policy_logprob_std 1.61 / train/policy_randomness_mag 0.65 / train/policy_randomness_max 0.65 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.4e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.21 / train/post_ent_max 51.21 / 
train/post_ent_mean 41.87 / train/post_ent_min 21.53 / train/post_ent_std 4 / train/prior_ent_mag 70.19 / train/prior_ent_max 70.19 / train/prior_ent_mean 45.57 / train/prior_ent_min 32.82 / train/prior_ent_std 4.45 / train/rep_loss_mean 3.73 / train/rep_loss_std 5.69 /
train/reward_avg 0.5 / train/reward_loss_mean 0.24 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.5 / 
train/reward_rate 0.44 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.16 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 8.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 5.69 / report/image_loss_mean 1.08 / report/image_loss_std 1.18 / report/model_loss_mean 3.54 / report/model_loss_std 4.4 / report/post_ent_mag 52.03
/ report/post_ent_max 52.03 / report/post_ent_mean 41.89 / report/post_ent_min 17.35 / report/post_ent_std 3.94 / report/prior_ent_mag 70.22 / report/prior_ent_max 70.22 / report/prior_ent_mean 45.66 / report/prior_ent_min 35.02 / report/prior_ent_std 4.07 / 
report/rep_loss_mean 3.75 / report/rep_loss_std 5.69 / report/reward_avg 0.44 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 0.44 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.26 / eval/dyn_loss_std 6.42 / eval/image_loss_mean 1.05 / eval/image_loss_std 1.62 / eval/model_loss_mean 3.93 / eval/model_loss_std 5.15 / eval/post_ent_mag 50.3 / eval/post_ent_max
50.3 / eval/post_ent_mean 41.33 / eval/post_ent_min 21.92 / eval/post_ent_std 3.61 / eval/prior_ent_mag 70.22 / eval/prior_ent_max 70.22 / eval/prior_ent_mean 45.37 / eval/prior_ent_min 35.89 / eval/prior_ent_std 4.02 / eval/rep_loss_mean 4.26 / eval/rep_loss_std 6.42 /
eval/reward_avg 0.73 / eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.72 / 
eval/reward_rate 0.58 / replay/size 5.5e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3764 / timer/env.step_total 19.5 / timer/env.step_frac 0.06 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.58 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-4 / 
timer/replay._sample_max 0.24 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 18.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 /
timer/agent.policy_max 8.5e-3 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1882 / 
timer/agent.train_total 240.94 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 324.2.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 548500 Counter(548500) 548437
Saved chunk: 20230922T092904F639313-6wk2XkYXWr9OjeTehRRRlX-4XiZZP6oXRerrGclYJLKyH-1024.npz
eval_Episode has 500 steps and return 367.8.
train_Episode has 500 steps and return 326.0.
Saved chunk: 20230922T092931F397152-4CqQQvVwKbXn2akaJoEqhs-0aGmMWIVaq69kCEN4x3ZPP-1024.npz
Starting evaluation at step 549000 Counter(549000) 548937
eval_Episode has 500 steps and return 399.4.
train_Episode has 500 steps and return 334.5.
Starting evaluation at step 549500 Counter(549500) 549437
Saved chunk: 20230922T093024F804470-4XiZZP6oXRerrGclYJLKyH-5Fcx4WkH1w6CGrbcES7Dqt-1024.npz
eval_Episode has 500 steps and return 369.2.
train_Episode has 500 steps and return 335.1.
Saved chunk: 20230922T093053F267204-0aGmMWIVaq69kCEN4x3ZPP-79L6xlNU2tAiW5XdyF5MPT-1024.npz
Starting evaluation at step 550000 Counter(550000) 549937
eval_Episode has 500 steps and return 377.8.
train_Episode has 500 steps and return 372.1.
Starting evaluation at step 550500 Counter(550500) 550437
Saved chunk: 20230922T093144F055940-5Fcx4WkH1w6CGrbcES7Dqt-4gyYYhBSRBL0RX9xarrHq8-1024.npz
eval_Episode has 500 steps and return 402.9.
train_Episode has 500 steps and return 360.6.
Saved chunk: 20230922T093213F949049-79L6xlNU2tAiW5XdyF5MPT-5QqC1egIXxIuUwdJ8qAw62-1024.npz
Starting evaluation at step 551000 Counter(551000) 550937
eval_Episode has 500 steps and return 390.9.
train_Episode has 500 steps and return 335.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Saved chunk: 20230922T093334F395295-5QqC1egIXxIuUwdJ8qAw62-0000000000000000000000-188.npz
Saved chunk: 20230922T093303F040824-4gyYYhBSRBL0RX9xarrHq8-0000000000000000000000-765.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 551500 Counter(551500) 551437
Saved chunk: 20230922T093303F040824-4gyYYhBSRBL0RX9xarrHq8-5ehtPl1w2qGWrlnMBVEA6r-1024.npz
eval_Episode has 500 steps and return 389.2.
train_Episode has 500 steps and return 329.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1103750 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 329.5 / episode/reward_rate 0.63 / eval_episode/length 500 / eval_episode/score 389.22 / eval_episode/reward_rate 0.69 / train_stats/mean_log_entropy -3.15 / train/action_mag 3.7 / train/action_max 3.3 / train/action_mean 0.07 / 
train/action_min -3.61 / train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.52 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -14.5 / train/adv_mag 0.51 / train/adv_max 
0.37 / train/adv_mean 2.4e-3 / train/adv_min -0.45 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 8.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.69 / train/dyn_loss_std 5.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 271.06 / train/extr_critic_max 271.06 / train/extr_critic_mean 260.45 / train/extr_critic_min 218.91 / train/extr_critic_std 9.2 / 
train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.66 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 271.89 / train/extr_return_raw_max 
271.89 / train/extr_return_raw_mean 260.52 / train/extr_return_raw_min 219.37 / train/extr_return_raw_std 9.28 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.52 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / 
train/image_loss_mean 0.94 / train/image_loss_std 0.94 / train/model_loss_mean 3.41 / train/model_loss_std 4.13 / train/model_opt_grad_norm 9.14 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 1.77 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.11 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.11 / train/policy_logprob_std 1.59 / train/policy_randomness_mag 0.58 / train/policy_randomness_max 0.58 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 
0.08 / train/post_ent_mag 51.02 / train/post_ent_max 51.02 / train/post_ent_mean 41.93 / train/post_ent_min 21.44 / train/post_ent_std 3.88 / train/prior_ent_mag 70.2 / train/prior_ent_max 70.2 / train/prior_ent_mean 45.58 / train/prior_ent_min 33.32 / 
train/prior_ent_std 4.34 / train/rep_loss_mean 3.69 / train/rep_loss_std 5.6 / train/reward_avg 0.52 / train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.1e-3 / 
train/reward_pos_acc 1 / train/reward_pos_loss 0.54 / train/reward_pred 0.52 / train/reward_rate 0.46 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 5.76 / report/image_loss_mean 0.93 / report/image_loss_std 0.91 / report/model_loss_mean 3.42 / report/model_loss_std 4.22 / 
report/post_ent_mag 50.01 / report/post_ent_max 50.01 / report/post_ent_mean 41.07 / report/post_ent_min 19.78 / report/post_ent_std 5.38 / report/prior_ent_mag 70.02 / report/prior_ent_max 70.02 / report/prior_ent_mean 44.72 / report/prior_ent_min 25.28 / 
report/prior_ent_std 6.22 / report/rep_loss_mean 3.75 / report/rep_loss_std 5.76 / report/reward_avg 0.47 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / 
report/reward_neg_loss 1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.47 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 5.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.49 / eval/dyn_loss_std 5.26 / eval/image_loss_mean 0.81 / eval/image_loss_std 0.91 / eval/model_loss_mean 3.26 / eval/model_loss_std 3.89 / eval/post_ent_mag 
50.77 / eval/post_ent_max 50.77 / eval/post_ent_mean 41.85 / eval/post_ent_min 23.95 / eval/post_ent_std 3.13 / eval/prior_ent_mag 70.02 / eval/prior_ent_max 70.02 / eval/prior_ent_mean 45.35 / eval/prior_ent_min 35.52 / eval/prior_ent_std 3.86 / eval/rep_loss_mean 3.49
/ eval/rep_loss_std 5.26 / eval/reward_avg 0.79 / eval/reward_loss_mean 0.35 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / 
eval/reward_pred 0.79 / eval/reward_rate 0.66 / replay/size 5.5e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3790 / timer/env.step_total 19.7 
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.9 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
6e-3 / timer/replay._sample_max 0.24 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7297 / timer/agent.policy_total 
17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1895 / timer/agent.train_total 244.21 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 2.2 / timer/agent.report_count
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / 
timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T093334F395295-5QqC1egIXxIuUwdJ8qAw62-13ytJEzJ2aTstm0aoY3tZb-1024.npz
Starting evaluation at step 552000 Counter(552000) 551937
eval_Episode has 500 steps and return 379.6.
train_Episode has 500 steps and return 317.3.
Starting evaluation at step 552500 Counter(552500) 552437
Saved chunk: 20230922T093421F954684-5ehtPl1w2qGWrlnMBVEA6r-38P4LsQMfkcicEZILfuKVC-1024.npz
eval_Episode has 500 steps and return 388.9.
train_Episode has 500 steps and return 314.2.
Saved chunk: 20230922T093458F048707-13ytJEzJ2aTstm0aoY3tZb-5vTpRiYX0UCGT59UMhYJ1T-1024.npz
Starting evaluation at step 553000 Counter(553000) 552937
eval_Episode has 500 steps and return 354.5.
train_Episode has 500 steps and return 328.4.
Starting evaluation at step 553500 Counter(553500) 553437
Saved chunk: 20230922T093544F297493-38P4LsQMfkcicEZILfuKVC-0RphLLLqDs51jgJBDFTzgU-1024.npz
eval_Episode has 500 steps and return 387.3.
train_Episode has 500 steps and return 328.1.
Saved chunk: 20230922T093618F962067-5vTpRiYX0UCGT59UMhYJ1T-2hsmvEwGDNeXbovTmgQyKc-1024.npz
Starting evaluation at step 554000 Counter(554000) 553937
eval_Episode has 500 steps and return 387.9.
train_Episode has 500 steps and return 354.2.
Starting evaluation at step 554500 Counter(554500) 554437
Saved chunk: 20230922T093703F342137-0RphLLLqDs51jgJBDFTzgU-1R9rgqX2PRvkuB1hRdLvzI-1024.npz
eval_Episode has 500 steps and return 397.2.
train_Episode has 500 steps and return 366.1.
Starting evaluation at step 555000 Counter(555000) 554937
eval_Episode has 500 steps and return 411.5.
Saved chunk: 20230922T093739F477235-2hsmvEwGDNeXbovTmgQyKc-4QPGUx6qa7qBnRTOhYahUn-1024.npz
train_Episode has 500 steps and return 338.3.
Starting evaluation at step 555500 Counter(555500) 555437
Saved chunk: 20230922T093822F291099-1R9rgqX2PRvkuB1hRdLvzI-6ddy0Bipc8Wi4JVSCCLZXS-1024.npz
eval_Episode has 500 steps and return 392.9.
train_Episode has 500 steps and return 349.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1111294 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 392.93 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 349.93 / episode/reward_rate 0.62 / train/action_mag 3.78 / train/action_max 3.42 / train/action_mean 0.07 / train/action_min -3.65 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -1.97 / train/adv_mag 0.45 / train/adv_max 0.33 / train/adv_mean 
1.1e-3 / train/adv_min -0.4 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 8.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate
1 / train/dyn_loss_mean 3.72 / train/dyn_loss_std 5.67 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 271.86 / train/extr_critic_max 271.86 / train/extr_critic_mean 261.41 / train/extr_critic_min 223.91 / train/extr_critic_std 8.03 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.49 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 272.73 / train/extr_return_raw_max 272.73 / train/extr_return_raw_mean 261.44 / train/extr_return_raw_min 
224.64 / train/extr_return_raw_std 8.08 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.95 / train/model_loss_mean 3.43 / 
train/model_loss_std 4.17 / train/model_opt_grad_norm 9.27 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.55 / train/policy_entropy_max 
2.14 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.74 / train/policy_logprob_mag 8.32 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -8.32 / train/policy_logprob_std 1.6 / 
train/policy_randomness_mag 0.62 / train/policy_randomness_max 0.62 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.1e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.09 / train/post_ent_max 51.09 / train/post_ent_mean 41.93 / 
train/post_ent_min 21.4 / train/post_ent_std 3.88 / train/prior_ent_mag 70.16 / train/prior_ent_max 70.16 / train/prior_ent_mean 45.61 / train/prior_ent_min 32.98 / train/prior_ent_std 4.32 / train/rep_loss_mean 3.72 / train/rep_loss_std 5.67 / train/reward_avg 0.51 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.55 / train/reward_pred 0.51 / train/reward_rate 0.45 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.11 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 5.5 / report/image_loss_mean 0.98 / report/image_loss_std 1.16 / report/model_loss_mean 3.55 / report/model_loss_std 4.19 / report/post_ent_mag 49.39 / report/post_ent_max 49.39 / 
report/post_ent_mean 42.24 / report/post_ent_min 22.37 / report/post_ent_std 3.42 / report/prior_ent_mag 70.17 / report/prior_ent_max 70.17 / report/prior_ent_mean 45.95 / report/prior_ent_min 37.44 / report/prior_ent_std 3.8 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 5.5 / report/reward_avg 0.53 / report/reward_loss_mean 0.28 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.4e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.53 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.9 / eval/dyn_loss_std 5.73 / eval/image_loss_mean 0.95 / eval/image_loss_std 1.24 / eval/model_loss_mean 3.61 / eval/model_loss_std 4.42 / eval/post_ent_mag 51.97 / eval/post_ent_max 51.97 / eval/post_ent_mean 
41.49 / eval/post_ent_min 21.12 / eval/post_ent_std 3.51 / eval/prior_ent_mag 70.17 / eval/prior_ent_max 70.17 / eval/prior_ent_mean 45.34 / eval/prior_ent_min 34.62 / eval/prior_ent_std 3.98 / eval/rep_loss_mean 3.9 / eval/rep_loss_std 5.73 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.71 / eval/reward_rate 0.6 / 
replay/size 5.6e5 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3772 / timer/env.step_total 19.5 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.06 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.25 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7780 / timer/agent.policy_total 18.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 7.8e-3 
/ timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1886 / timer/agent.train_total 240.96 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 556000 Counter(556000) 555937
eval_Episode has 500 steps and return 393.0.
Saved chunk: 20230922T093903F448615-4QPGUx6qa7qBnRTOhYahUn-0JWg0QnS6rDk22Du6tFvi6-1024.npz
train_Episode has 500 steps and return 349.4.
Starting evaluation at step 556500 Counter(556500) 556437
Saved chunk: 20230922T093940F989310-6ddy0Bipc8Wi4JVSCCLZXS-7esBVbEu82Mn7P5JPKTNa1-1024.npz
eval_Episode has 500 steps and return 376.0.
train_Episode has 500 steps and return 345.5.
Starting evaluation at step 557000 Counter(557000) 556937
eval_Episode has 500 steps and return 365.5.
Saved chunk: 20230922T094025F057824-0JWg0QnS6rDk22Du6tFvi6-6myMtxNG34MLycsRT3FNVY-1024.npz
train_Episode has 500 steps and return 353.1.
Starting evaluation at step 557500 Counter(557500) 557437
Saved chunk: 20230922T094101F380421-7esBVbEu82Mn7P5JPKTNa1-6EA0TBmYw117e8fc8YUiBC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 353.2.
Starting evaluation at step 558000 Counter(558000) 557937
eval_Episode has 500 steps and return 385.7.
Saved chunk: 20230922T094145F809242-6myMtxNG34MLycsRT3FNVY-09K1zJWFcn63YBvNKqqlHi-1024.npz
train_Episode has 500 steps and return 347.2.
Starting evaluation at step 558500 Counter(558500) 558437
Saved chunk: 20230922T094220F479643-6EA0TBmYw117e8fc8YUiBC-5ZEbsG35PlyvrwEO6zkebo-1024.npz
eval_Episode has 500 steps and return 388.5.
train_Episode has 500 steps and return 327.2.
Starting evaluation at step 559000 Counter(559000) 558937
eval_Episode has 500 steps and return 385.9.
Saved chunk: 20230922T094306F460261-09K1zJWFcn63YBvNKqqlHi-2sgvHzuw78Tt31cfrMLZXZ-1024.npz
train_Episode has 500 steps and return 333.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1118938 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 385.89 / eval_episode/reward_rate 0.66 / episode/length 500 / episode/score 333.45 / episode/reward_rate 0.58 / train/action_mag 3.71 / train/action_max 3.34 / train/action_mean 0.07 / train/action_min -3.64 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.55 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 2.79 / train/adv_mag 0.56 / train/adv_max 0.44 / train/adv_mean 6.4e-4
/ train/adv_min -0.4 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 8.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 273.64 / train/extr_critic_max 273.64 / train/extr_critic_mean 263.45 / train/extr_critic_min 221.31 / train/extr_critic_std 7.9 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.71 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 274.46 / train/extr_return_raw_max 274.46 / train/extr_return_raw_mean 263.47 / train/extr_return_raw_min 
226.44 / train/extr_return_raw_std 7.94 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.95 / train/image_loss_std 0.95 / train/model_loss_mean 3.42 /
train/model_loss_std 4.16 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.56 / train/policy_entropy_max 
2.11 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.75 / train/policy_logprob_mag 8.22 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.07 / train/policy_logprob_min -8.22 / train/policy_logprob_std 1.6 / 
train/policy_randomness_mag 0.61 / train/policy_randomness_max 0.61 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.2e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.14 / train/post_ent_max 51.14 / train/post_ent_mean 41.95 / 
train/post_ent_min 21.58 / train/post_ent_std 3.83 / train/prior_ent_mag 70.17 / train/prior_ent_max 70.17 / train/prior_ent_mean 45.63 / train/prior_ent_min 33.31 / train/prior_ent_std 4.28 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.64 / train/reward_avg 0.51 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.54 / train/reward_pred 0.51 / train/reward_rate 0.45 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.13 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 5.82 / report/image_loss_mean 0.94 / report/image_loss_std 1.01 / report/model_loss_mean 3.37 / report/model_loss_std 4.27 / report/post_ent_mag 50.65 / report/post_ent_max 50.65 /
report/post_ent_mean 41.3 / report/post_ent_min 21.72 / report/post_ent_std 5.29 / report/prior_ent_mag 70.27 / report/prior_ent_max 70.27 / report/prior_ent_mean 44.93 / report/prior_ent_min 23.68 / report/prior_ent_std 6.23 / report/rep_loss_mean 3.64 / 
report/rep_loss_std 5.82 / report/reward_avg 0.48 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.48 / report/reward_rate 0.45 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.44 / eval/dyn_loss_std 5.1 / eval/image_loss_mean 0.8 / eval/image_loss_std 1 / eval/model_loss_mean 3.23 / eval/model_loss_std 3.93 / eval/post_ent_mag 48.23 / eval/post_ent_max 48.23 / eval/post_ent_mean 41.23
/ eval/post_ent_min 22.32 / eval/post_ent_std 3.38 / eval/prior_ent_mag 70.27 / eval/prior_ent_max 70.27 / eval/prior_ent_mean 44.89 / eval/prior_ent_min 37.08 / eval/prior_ent_std 3.88 / eval/rep_loss_mean 3.44 / eval/rep_loss_std 5.1 / eval/reward_avg 0.79 / 
eval/reward_loss_mean 0.36 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.2e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.78 / eval/reward_rate 0.68 / 
replay/size 5.6e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3822 / timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 459.89 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7329 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1911 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1911 / timer/agent.train_total 244.19 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.47

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 559500 Counter(559500) 559437
eval_Episode has 500 steps and return 365.8.
Saved chunk: 20230922T094339F319741-5ZEbsG35PlyvrwEO6zkebo-02CURhjU9Ag6M9PPkjTHzH-1024.npz
train_Episode has 500 steps and return 333.5.
Starting evaluation at step 560000 Counter(560000) 559937
eval_Episode has 500 steps and return 397.3.
train_Episode has 500 steps and return 366.9.
Saved chunk: 20230922T094426F635680-2sgvHzuw78Tt31cfrMLZXZ-5OKZzSf0CjStboqswqCH7y-1024.npz
Starting evaluation at step 560500 Counter(560500) 560437
eval_Episode has 500 steps and return 353.5.
Saved chunk: 20230922T094459F117906-02CURhjU9Ag6M9PPkjTHzH-2Lx3IFTKSAUVjPajIQTJPe-1024.npz
train_Episode has 500 steps and return 304.9.
Starting evaluation at step 561000 Counter(561000) 560937
eval_Episode has 500 steps and return 360.1.
train_Episode has 500 steps and return 325.1.
Saved chunk: 20230922T094548F504770-5OKZzSf0CjStboqswqCH7y-4bMXQUmgxkL5ShxNMUYH6f-1024.npz
Starting evaluation at step 561500 Counter(561500) 561437
eval_Episode has 500 steps and return 397.7.
Saved chunk: 20230922T094618F494866-2Lx3IFTKSAUVjPajIQTJPe-0o6Dqowg3Pnrn3lic92vwz-1024.npz
train_Episode has 500 steps and return 316.2.
Starting evaluation at step 562000 Counter(562000) 561937
eval_Episode has 500 steps and return 370.5.
train_Episode has 500 steps and return 319.2.
Saved chunk: 20230922T094709F108811-4bMXQUmgxkL5ShxNMUYH6f-2PJaBiGjsfOspb63zuGuMY-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
Starting evaluation at step 562500 Counter(562500) 562437
Saved chunk: 20230922T094829F613987-2PJaBiGjsfOspb63zuGuMY-0000000000000000000000-324.npz
Saved chunk: 20230922T094737F519110-0o6Dqowg3Pnrn3lic92vwz-0000000000000000000000-523.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/4/checkpoint.ckpt
eval_Episode has 500 steps and return 385.5.
Saved chunk: 20230922T094737F519110-0o6Dqowg3Pnrn3lic92vwz-3KZMmoshJ40GGPSEFn8N4A-1024.npz
train_Episode has 500 steps and return 364.5.
Starting evaluation at step 563000 Counter(563000) 562937
eval_Episode has 500 steps and return 413.8.
train_Episode has 500 steps and return 341.2.
Saved chunk: 20230922T094829F613987-2PJaBiGjsfOspb63zuGuMY-01ondNd83tqr94RVRMjeeL-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1126462 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 413.8 / eval_episode/reward_rate 0.73 / episode/length 500 / episode/score 341.16 / episode/reward_rate 0.6 / train/action_mag 3.73 / train/action_max 3.32 / train/action_mean 0.06 / train/action_min -3.63 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.51 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 1.23 / train/adv_mag 0.48 / train/adv_max 0.34 / train/adv_mean 8e-4 / train/adv_min 
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 8.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.72 / train/dyn_loss_std 5.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 273.43 / train/extr_critic_max 273.43 / train/extr_critic_mean 263.16 / train/extr_critic_min 227.79 / train/extr_critic_std 7.48 / train/extr_return_normed_mag 1.23 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 274.2 / train/extr_return_raw_max 274.2 / train/extr_return_raw_mean 263.19 / train/extr_return_raw_min 
229.48 / train/extr_return_raw_std 7.53 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.97 / train/model_loss_mean 3.45 /
train/model_loss_std 4.2 / train/model_opt_grad_norm 9.16 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 
1.92 / train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 8.23 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.23 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 0.59 / train/policy_randomness_max 0.59 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.7e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 50.98 / train/post_ent_max 50.98 / train/post_ent_mean 41.91 / 
train/post_ent_min 21.31 / train/post_ent_std 3.87 / train/prior_ent_mag 70.15 / train/prior_ent_max 70.15 / train/prior_ent_mean 45.6 / train/prior_ent_min 33.29 / train/prior_ent_std 4.32 / train/rep_loss_mean 3.72 / train/rep_loss_std 5.68 / train/reward_avg 0.51 / 
train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.54 / train/reward_pred 0.51 / train/reward_rate 0.45 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.13 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.11 / report/dyn_loss_std 6.24 / report/image_loss_mean 1.18 / report/image_loss_std 1.38 / report/model_loss_mean 3.89 / report/model_loss_std 4.93 / report/post_ent_mag 50.22 / report/post_ent_max 50.22 /
report/post_ent_mean 41.38 / report/post_ent_min 20.69 / report/post_ent_std 4.43 / report/prior_ent_mag 70.11 / report/prior_ent_max 70.11 / report/prior_ent_mean 45.45 / report/prior_ent_min 30.77 / report/prior_ent_std 4.4 / report/rep_loss_mean 4.11 / 
report/rep_loss_std 6.24 / report/reward_avg 0.45 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.39 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.45 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.8 / eval/dyn_loss_std 5.51 / eval/image_loss_mean 1.01 / eval/image_loss_std 1.32 / eval/model_loss_mean 3.6 / eval/model_loss_std 4.25 / eval/post_ent_mag 52 / eval/post_ent_max 52 / eval/post_ent_mean 41.3 / 
eval/post_ent_min 24.4 / eval/post_ent_std 3.91 / eval/prior_ent_mag 70.11 / eval/prior_ent_max 70.11 / eval/prior_ent_mean 44.88 / eval/prior_ent_min 28.6 / eval/prior_ent_std 4.65 / eval/rep_loss_mean 3.8 / eval/rep_loss_std 5.51 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.31 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.51 / eval/reward_pred 0.7 / eval/reward_rate 0.6 / replay/size
5.6e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3762 / timer/env.step_total 19.45 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.87 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7770 / timer/agent.policy_total 18.31 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.4e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1881 / timer/agent.train_total 240.74 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.56 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / 
timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 563500 Counter(563500) 563437
eval_Episode has 500 steps and return 386.0.
train_Episode has 500 steps and return 335.9.
Starting evaluation at step 564000 Counter(564000) 563937
Saved chunk: 20230922T094856F614975-3KZMmoshJ40GGPSEFn8N4A-2jCt2QtztCwMFyclXdtKHf-1024.npz
eval_Episode has 500 steps and return 371.3.
train_Episode has 500 steps and return 323.1.
Saved chunk: 20230922T094950F544900-01ondNd83tqr94RVRMjeeL-6eeoipB7wke8BSI0D6w3J8-1024.npz
Starting evaluation at step 564500 Counter(564500) 564437
eval_Episode has 500 steps and return 393.7.
train_Episode has 500 steps and return 314.9.
Starting evaluation at step 565000 Counter(565000) 564937
Saved chunk: 20230922T095052F979067-2jCt2QtztCwMFyclXdtKHf-2qhQR92qHrSLhSL3Wng5AZ-1024.npz
eval_Episode has 500 steps and return 385.1.
train_Episode has 500 steps and return 326.3.
Saved chunk: 20230922T095112F509909-6eeoipB7wke8BSI0D6w3J8-1Ww8gj1AE7qqOTPeMiH7MX-1024.npz
Starting evaluation at step 565500 Counter(565500) 565437
eval_Episode has 500 steps and return 390.9.
train_Episode has 500 steps and return 342.9.
Starting evaluation at step 566000 Counter(566000) 565937
Saved chunk: 20230922T095212F048181-2qhQR92qHrSLhSL3Wng5AZ-05ckrwphMryXiiOVLxjbb2-1024.npz
eval_Episode has 500 steps and return 395.7.
train_Episode has 500 steps and return 313.1.
Saved chunk: 20230922T095233F070278-1Ww8gj1AE7qqOTPeMiH7MX-6fdEIPCSdi9PrgjQXKHAtF-1024.npz
Starting evaluation at step 566500 Counter(566500) 566437
eval_Episode has 500 steps and return 393.5.
train_Episode has 500 steps and return 340.3.
Starting evaluation at step 567000 Counter(567000) 566937
Saved chunk: 20230922T095330F877607-05ckrwphMryXiiOVLxjbb2-18sSFfRCgr9jt4KFhTJYQu-1024.npz
eval_Episode has 500 steps and return 386.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1134010 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 386.84 / eval_episode/reward_rate 0.71 / episode/length 500 / episode/score 340.26 / episode/reward_rate 0.59 / train/action_mag 3.78 / train/action_max 3.36 / train/action_mean 0.06 / train/action_min -3.67 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.47 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -8.62 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 
1.8e-3 / train/adv_min -0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 8.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.69 / train/dyn_loss_std 5.61 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / 
train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 274.7 / train/extr_critic_max 274.7 / train/extr_critic_mean 264.22 / train/extr_critic_min 218.59 / train/extr_critic_std 9.59 / train/extr_return_normed_mag
1.48 / train/extr_return_normed_max 1.08 / train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.66 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 275.51 / train/extr_return_raw_max 275.51 / 
train/extr_return_raw_mean 264.28 / train/extr_return_raw_min 220.98 / train/extr_return_raw_std 9.63 / train/extr_reward_mag 2.01 / train/extr_reward_max 2.01 / train/extr_reward_mean 0.52 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 
0.94 / train/image_loss_std 0.96 / train/model_loss_mean 3.41 / train/model_loss_std 4.15 / train/model_opt_grad_norm 9.39 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 3.55 / train/policy_entropy_max 1.42 / train/policy_entropy_mean -3.09 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 3.09 / 
train/policy_logprob_min -8.04 / train/policy_logprob_std 1.59 / train/policy_randomness_mag 0.54 / train/policy_randomness_max 0.54 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.08 / train/post_ent_mag 51.14 / 
train/post_ent_max 51.14 / train/post_ent_mean 41.97 / train/post_ent_min 21.4 / train/post_ent_std 3.88 / train/prior_ent_mag 70.13 / train/prior_ent_max 70.13 / train/prior_ent_mean 45.64 / train/prior_ent_min 33.37 / train/prior_ent_std 4.32 / train/rep_loss_mean 
3.69 / train/rep_loss_std 5.61 / train/reward_avg 0.52 / train/reward_loss_mean 0.25 / train/reward_loss_std 0.33 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss
0.54 / train/reward_pred 0.52 / train/reward_rate 0.46 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.13 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.55 / report/dyn_loss_std 5.43 / report/image_loss_mean 0.97 / report/image_loss_std 0.82 / report/model_loss_mean 3.36 / report/model_loss_std 3.94 / 
report/post_ent_mag 50.14 / report/post_ent_max 50.14 / report/post_ent_mean 41.74 / report/post_ent_min 19.95 / report/post_ent_std 3.55 / report/prior_ent_mag 69.95 / report/prior_ent_max 69.95 / report/prior_ent_mean 45.25 / report/prior_ent_min 34.64 / 
report/prior_ent_std 4.16 / report/rep_loss_mean 3.55 / report/rep_loss_std 5.43 / report/reward_avg 0.49 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 2.01 / report/reward_neg_acc 1 / 
report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.49 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 6.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.1 / eval/dyn_loss_std 6.48 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.5 / eval/model_loss_mean 3.82 / eval/model_loss_std 5.11 / eval/post_ent_mag 
48.73 / eval/post_ent_max 48.73 / eval/post_ent_mean 40.47 / eval/post_ent_min 21.59 / eval/post_ent_std 4.62 / eval/prior_ent_mag 69.95 / eval/prior_ent_max 69.95 / eval/prior_ent_mean 44.13 / eval/prior_ent_min 29.09 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 4.1 
/ eval/rep_loss_std 6.48 / eval/reward_avg 0.65 / eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.4 / eval/reward_max_data 2 / eval/reward_max_pred 2.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / 
eval/reward_pred 0.65 / eval/reward_rate 0.58 / replay/size 5.7e5 / replay/inserts 3774 / replay/samples 3e4 / replay/insert_wait_avg 4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3774 / timer/env.step_total 19.53
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.56 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7782 / timer/agent.policy_total 17.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1887 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.4e-4 / 
timer/agent.train_count 1887 / timer/agent.train_total 241.14 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / 
timer/dataset_eval_max 4.7e-5 / fps 25.15
