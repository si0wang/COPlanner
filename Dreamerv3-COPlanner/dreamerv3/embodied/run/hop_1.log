Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {}
JAX devices (1): [gpu(id=0)]
Policy devices: gpu:0
Train devices:  gpu:0
Tracing train function.
Optimizer model_opt has 15,686,787 variables.
{'action': Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>, 'deter': Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>, 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>, 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>}
{'action': Traced<ShapedArray(float32[15,1024,4])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,4])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,4]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10ac16ecd0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f10ac16a130; dead>, <weakref at 0x7f10ac16aa90; dead>, <weakref at 0x7f10ac16a720; dead>, <weakref at 0x7f10ac16ab80; dead>, <weakref at 0x7f10ac16af90; to 'JaxprTracer' at 0x7f10ac0631d0>, <weakref at 0x7f10ac16a950; to 'JaxprTracer' at 0x7f10ac0632c0>, <weakref at 0x7f10ac16af40; to 'JaxprTracer' at 0x7f10ac063450>, <weakref at 0x7f10ac16a5e0; to 'JaxprTracer' at 0x7f10ac16a400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f10ac043830>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10ac16ecd0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f10ac16a130; dead>, <weakref at 0x7f10ac16aa90; dead>, <weakref at 0x7f10ac16a720; dead>, <weakref at 0x7f10ac16ab80; dead>, <weakref at 0x7f10ac16af90; to 'JaxprTracer' at 0x7f10ac0631d0>, <weakref at 0x7f10ac16a950; to 'JaxprTracer' at 0x7f10ac0632c0>, <weakref at 0x7f10ac16af40; to 'JaxprTracer' at 0x7f10ac063450>, <weakref at 0x7f10ac16a5e0; to 'JaxprTracer' at 0x7f10ac16a400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f10ac043830>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10ac16ecd0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f10ac16a130; dead>, <weakref at 0x7f10ac16aa90; dead>, <weakref at 0x7f10ac16a720; dead>, <weakref at 0x7f10ac16ab80; dead>, <weakref at 0x7f10ac16af90; to 'JaxprTracer' at 0x7f10ac0631d0>, <weakref at 0x7f10ac16a950; to 'JaxprTracer' at 0x7f10ac0632c0>, <weakref at 0x7f10ac16af40; to 'JaxprTracer' at 0x7f10ac063450>, <weakref at 0x7f10ac16a5e0; to 'JaxprTracer' at 0x7f10ac16a400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f10ac043830>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10ac16ecd0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f10ac16a130; dead>, <weakref at 0x7f10ac16aa90; dead>, <weakref at 0x7f10ac16a720; dead>, <weakref at 0x7f10ac16ab80; dead>, <weakref at 0x7f10ac16af90; to 'JaxprTracer' at 0x7f10ac0631d0>, <weakref at 0x7f10ac16a950; to 'JaxprTracer' at 0x7f10ac0632c0>, <weakref at 0x7f10ac16af40; to 'JaxprTracer' at 0x7f10ac063450>, <weakref at 0x7f10ac16a5e0; to 'JaxprTracer' at 0x7f10ac16a400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f10ac043830>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Optimizer actor_opt has 1,054,728 variables.
Optimizer critic_opt has 1,181,439 variables.
Logdir /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp
Observation space:
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  position         Space(dtype=float64, shape=(6,), low=-inf, high=inf)
  velocity         Space(dtype=float64, shape=(7,), low=-inf, high=inf)
  touch            Space(dtype=float64, shape=(2,), low=-inf, high=inf)
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
Action space:
  reset            Space(dtype=bool, shape=(), low=False, high=True)
  action           Space(dtype=float32, shape=(4,), low=-1.0, high=1.0)
Prefill train dataset.
train_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212753F449662-56WLTDcA3hzqcJjE6CzjWV-3D3E5vV0sOElEhi70sp9Yq-1024.npz
Prefill eval dataset.
eval_Episode has 500 steps and return 0.0.
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212757F859483-4mb4CRwQJQp6BpKfoQ9YFY-7GpyUesaqYWqJdHk8QCQbO-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2200 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0
warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'


Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100 Counter(1100) 1037
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Tracing policy function.
Tracing policy function.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T212757F250512-3D3E5vV0sOElEhi70sp9Yq-0000000000000000000000-76.npz
Saved chunk: 20230921T212801F581257-7GpyUesaqYWqJdHk8QCQbO-0000000000000000000000-76.npz
eval_Episode has 500 steps and return 0.0.
Tracing policy function.
Tracing train function.
{'action': Traced<ShapedArray(float32[15,1024,4])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,4])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,4]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10d03c24a0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f1074eec540; dead>, <weakref at 0x7f1074eec220; dead>, <weakref at 0x7f1074eec0e0; dead>, <weakref at 0x7f1074eeca40; dead>, <weakref at 0x7f1074eecc20; to 'JaxprTracer' at 0x7f0e206aa900>, <weakref at 0x7f1074eecef0; to 'JaxprTracer' at 0x7f1074eec680>, <weakref at 0x7f1074eec950; to 'JaxprTracer' at 0x7f1074eec1d0>, <weakref at 0x7f1074eec720; to 'JaxprTracer' at 0x7f1074eeca90>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f0e201653f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10d03c24a0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f1074eec540; dead>, <weakref at 0x7f1074eec220; dead>, <weakref at 0x7f1074eec0e0; dead>, <weakref at 0x7f1074eeca40; dead>, <weakref at 0x7f1074eecc20; to 'JaxprTracer' at 0x7f0e206aa900>, <weakref at 0x7f1074eecef0; to 'JaxprTracer' at 0x7f1074eec680>, <weakref at 0x7f1074eec950; to 'JaxprTracer' at 0x7f1074eec1d0>, <weakref at 0x7f1074eec720; to 'JaxprTracer' at 0x7f1074eeca90>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f0e201653f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10d03c24a0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f1074eec540; dead>, <weakref at 0x7f1074eec220; dead>, <weakref at 0x7f1074eec0e0; dead>, <weakref at 0x7f1074eeca40; dead>, <weakref at 0x7f1074eecc20; to 'JaxprTracer' at 0x7f0e206aa900>, <weakref at 0x7f1074eecef0; to 'JaxprTracer' at 0x7f1074eec680>, <weakref at 0x7f1074eec950; to 'JaxprTracer' at 0x7f1074eec1d0>, <weakref at 0x7f1074eec720; to 'JaxprTracer' at 0x7f1074eeca90>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f0e201653f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f10d03c24a0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f1074eec540; dead>, <weakref at 0x7f1074eec220; dead>, <weakref at 0x7f1074eec0e0; dead>, <weakref at 0x7f1074eeca40; dead>, <weakref at 0x7f1074eecc20; to 'JaxprTracer' at 0x7f0e206aa900>, <weakref at 0x7f1074eecef0; to 'JaxprTracer' at 0x7f1074eec680>, <weakref at 0x7f1074eec950; to 'JaxprTracer' at 0x7f1074eec1d0>, <weakref at 0x7f1074eec720; to 'JaxprTracer' at 0x7f1074eeca90>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f0e201653f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Tracing report function.
Tracing report function.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2202 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.62 / train/action_max 4.62 / train/action_mean 0.22 / train/action_min -4.13 / train/action_std 1.02 / train/actor_opt_actor_opt_grad_overflow 0 / 
train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.9e-5 / train/actor_opt_grad_steps 1 / train/actor_opt_loss -1.13 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 1.3
/ train/cont_loss_std 0.48 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 0.09 / train/cont_pos_loss 1.3 / train/cont_pred 0.3 / train/cont_rate 1 / train/dyn_loss_mean 6.77 / train/dyn_loss_std 0.29 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.2 / train/extr_critic_critic_opt_grad_steps 1 / train/extr_critic_critic_opt_loss 8207.62 / train/extr_critic_mag 0 
/ train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 0 / train/extr_return_normed_max -inf / train/extr_return_normed_mean 0 / train/extr_return_normed_min 0 / 
train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / 
train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2714.78 / train/image_loss_std 30.38 / train/model_loss_mean 2725.68 / train/model_loss_std 30.43 / train/model_opt_grad_norm nan / train/model_opt_grad_steps 0 / 
train/model_opt_loss 2.7e7 / train/model_opt_model_opt_grad_overflow 1 / train/model_opt_model_opt_grad_scale 5000 / train/policy_entropy_mag 5.55 / train/policy_entropy_max 5.55 / train/policy_entropy_mean 5.06 / train/policy_entropy_min 3.72 / train/policy_entropy_std 
0.22 / train/policy_logprob_mag 16.04 / train/policy_logprob_max -2.33 / train/policy_logprob_mean -5.06 / train/policy_logprob_min -16.04 / train/policy_logprob_std 1.44 / train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 
0.93 / train/policy_randomness_min 0.79 / train/policy_randomness_std 0.02 / train/post_ent_mag 107.91 / train/post_ent_max 107.91 / train/post_ent_mean 107.64 / train/post_ent_min 107.23 / train/post_ent_std 0.1 / train/prior_ent_mag 108.1 / train/prior_ent_max 108.1 / 
train/prior_ent_mean 107.38 / train/prior_ent_min 106.62 / train/prior_ent_std 0.22 / train/rep_loss_mean 6.77 / train/rep_loss_std 0.29 / train/reward_avg 5.8e-4 / train/reward_loss_mean 5.54 / train/reward_loss_std 9.5e-7 / train/reward_max_data 0.16 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 5.54 / train/reward_pos_acc 0 / train/reward_pos_loss 5.54 / train/reward_pred 0 / train/reward_rate 3.9e-3 / train/params_agent/wm/model_opt 1.6e7 / 
train/params_agent/task_behavior/critic/critic_opt 1.2e6 / train/params_agent/task_behavior/ac/actor_opt 1.1e6 / report/cont_avg 1 / report/cont_loss_mean 1.3 / report/cont_loss_std 0.46 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 0.07 / 
report/cont_pos_loss 1.3 / report/cont_pred 0.3 / report/cont_rate 1 / report/dyn_loss_mean 6.78 / report/dyn_loss_std 0.3 / report/image_loss_mean 2713.59 / report/image_loss_std 30.28 / report/model_loss_mean 2724.5 / report/model_loss_std 30.31 / report/post_ent_mag 
107.91 / report/post_ent_max 107.91 / report/post_ent_mean 107.63 / report/post_ent_min 107.22 / report/post_ent_std 0.1 / report/prior_ent_mag 108.04 / report/prior_ent_max 108.04 / report/prior_ent_mean 107.39 / report/prior_ent_min 106.62 / report/prior_ent_std 0.21 / 
report/rep_loss_mean 6.78 / report/rep_loss_std 0.3 / report/reward_avg 5.8e-4 / report/reward_loss_mean 5.54 / report/reward_loss_std 9.5e-7 / report/reward_max_data 0.16 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 5.54 / 
report/reward_pos_acc 0 / report/reward_pos_loss 5.54 / report/reward_pred 0 / report/reward_rate 3.9e-3 / eval/cont_avg 1 / eval/cont_loss_mean 1.31 / eval/cont_loss_std 0.5 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 0.1 / eval/cont_pos_loss 
1.31 / eval/cont_pred 0.3 / eval/cont_rate 1 / eval/dyn_loss_mean 6.81 / eval/dyn_loss_std 0.3 / eval/image_loss_mean 2712.1 / eval/image_loss_std 30.06 / eval/model_loss_mean 2723.04 / eval/model_loss_std 30.07 / eval/post_ent_mag 107.9 / eval/post_ent_max 107.9 / 
eval/post_ent_mean 107.62 / eval/post_ent_min 107.2 / eval/post_ent_std 0.11 / eval/prior_ent_mag 108.09 / eval/prior_ent_max 108.09 / eval/prior_ent_mean 107.38 / eval/prior_ent_min 106.6 / eval/prior_ent_std 0.23 / eval/rep_loss_mean 6.81 / eval/rep_loss_std 0.3 / 
eval/reward_avg 0 / eval/reward_loss_mean 5.54 / eval/reward_loss_std 9.5e-7 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.54 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 
0 / replay/size 1038 / replay/inserts 1038 / replay/samples 112 / replay/insert_wait_avg 2.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.5e-6 / replay/sample_wait_frac 1 / eval_replay/size 1538 / eval_replay/inserts 1538 / eval_replay/samples 112 / 
eval_replay/insert_wait_avg 2.2e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.6e-6 / eval_replay/sample_wait_frac 1 / timer/duration 87.92 / timer/env.step_count 1101 / timer/env.step_total 4.28 / timer/env.step_frac 0.05 / timer/env.step_avg 3.9e-3 
/ timer/env.step_min 3.3e-3 / timer/env.step_max 0.44 / timer/replay._sample_count 112 / timer/replay._sample_total 18.74 / timer/replay._sample_frac 0.21 / timer/replay._sample_avg 0.17 / timer/replay._sample_min 7.7e-4 / timer/replay._sample_max 0.99 / 
timer/agent.save_count 1 / timer/agent.save_total 0.27 / timer/agent.save_frac 3.1e-3 / timer/agent.save_avg 0.27 / timer/agent.save_min 0.27 / timer/agent.save_max 0.27 / timer/agent.policy_count 502 / timer/agent.policy_total 6.88 / timer/agent.policy_frac 0.08 / 
timer/agent.policy_avg 0.01 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 4.16 / timer/dataset_train_count 1 / timer/dataset_train_total 2.6e-5 / timer/dataset_train_frac 2.9e-7 / timer/dataset_train_avg 2.6e-5 / timer/dataset_train_min 2.6e-5 / 
timer/dataset_train_max 2.6e-5 / timer/agent.train_count 1 / timer/agent.train_total 59.62 / timer/agent.train_frac 0.68 / timer/agent.train_avg 59.62 / timer/agent.train_min 59.62 / timer/agent.train_max 59.62 / timer/agent.report_count 2 / timer/agent.report_total 9.2 /
timer/agent.report_frac 0.1 / timer/agent.report_avg 4.6 / timer/agent.report_min 0.07 / timer/agent.report_max 9.14 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 3e-7 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 
2.7e-5 / timer/dataset_eval_max 2.7e-5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 1500 Counter(1500) 1437
Saved chunk: 20230921T212801F581257-7GpyUesaqYWqJdHk8QCQbO-51rCGXlLLTZf9lLn90a3FY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.3.
Starting evaluation at step 2000 Counter(2000) 1937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212757F250512-3D3E5vV0sOElEhi70sp9Yq-12AMsNdzb3mqcilaT2KkHS-1024.npz
Starting evaluation at step 2500 Counter(2500) 2437
Saved chunk: 20230921T212952F575548-51rCGXlLLTZf9lLn90a3FY-0WErn9IIfKZ4Kak9Da2OEI-1024.npz
eval_Episode has 500 steps and return 0.4.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 3000 Counter(3000) 2937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213035F394825-12AMsNdzb3mqcilaT2KkHS-1q32Ct232uO2YExRAyOjOe-1024.npz
Starting evaluation at step 3500 Counter(3500) 3437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213110F850326-0WErn9IIfKZ4Kak9Da2OEI-5m4sQoIHTz7MfkTRhPrJwc-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 4000 Counter(4000) 3937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213155F370857-1q32Ct232uO2YExRAyOjOe-1Yle2GhYNjbYZ2UCikyJZh-1024.npz
Starting evaluation at step 4500 Counter(4500) 4437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 9656 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5 / train/action_max 4.7 / train/action_mean -0.21 / train/action_min -4.9 / train/action_std 1.17 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.9e-4 / train/actor_opt_grad_steps 935 / train/actor_opt_loss -21.39 / train/adv_mag 0.04 / train/adv_max 0.04 / train/adv_mean 4.9e-4 / train/adv_min -3.3e-6
/ train/adv_std 1.2e-3 / train/cont_avg 1 / train/cont_loss_mean 6.9e-3 / train/cont_loss_std 2.7e-3 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.9e-3 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.28 /
train/dyn_loss_std 2.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.31 / train/extr_critic_critic_opt_grad_steps 935 / train/extr_critic_critic_opt_loss 1.2e4
/ train/extr_critic_mag 3.8e-3 / train/extr_critic_max -inf / train/extr_critic_mean 3.6e-3 / train/extr_critic_min 3.5e-3 / train/extr_critic_std 1.9e-5 / train/extr_return_normed_mag 0.04 / train/extr_return_normed_max 0.04 / train/extr_return_normed_mean 8.4e-4 / 
train/extr_return_normed_min 3.8e-4 / train/extr_return_normed_std 1.2e-3 / train/extr_return_rate 1.4e-6 / train/extr_return_raw_mag 0.04 / train/extr_return_raw_max 0.04 / train/extr_return_raw_mean 4.1e-3 / train/extr_return_raw_min 3.6e-3 / train/extr_return_raw_std 
1.2e-3 / train/extr_reward_mag 0.01 / train/extr_reward_max 0.01 / train/extr_reward_mean 8.9e-5 / train/extr_reward_min 7.5e-5 / train/extr_reward_std 2.4e-4 / train/image_loss_mean 40.58 / train/image_loss_std 6.72 / train/model_loss_mean 42.75 / train/model_loss_std 
7.42 / train/model_opt_grad_norm 116.71 / train/model_opt_grad_steps 926 / train/model_opt_loss 949.83 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 28.56 / train/policy_entropy_mag 5.66 / train/policy_entropy_max 5.66 / 
train/policy_entropy_mean 5.65 / train/policy_entropy_min 5.47 / train/policy_entropy_std 0.01 / train/policy_logprob_mag 16.42 / train/policy_logprob_max -3.63 / train/policy_logprob_mean -5.64 / train/policy_logprob_min -16.42 / train/policy_logprob_std 1.41 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 1.2e-3 / train/post_ent_mag 59.92 / train/post_ent_max 59.92 / train/post_ent_mean 49 / train/post_ent_min 42.65
/ train/post_ent_std 2.81 / train/prior_ent_mag 65.81 / train/prior_ent_max 65.81 / train/prior_ent_mean 53.88 / train/prior_ent_min 48.32 / train/prior_ent_std 3.13 / train/rep_loss_mean 3.28 / train/rep_loss_std 2.32 / train/reward_avg 1.9e-4 / train/reward_loss_mean 
0.19 / train/reward_loss_std 0.09 / train/reward_max_data 0.07 / train/reward_max_pred 3.9e-3 / train/reward_neg_acc 1 / train/reward_neg_loss 0.19 / train/reward_pos_acc 0.02 / train/reward_pos_loss 5.1 / train/reward_pred 9e-5 / train/reward_rate 9.5e-4 / 
train_stats/mean_log_entropy 5.63 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-6 / report/cont_loss_std 2.6e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-6 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 4.1 / report/dyn_loss_std 3.49 / report/image_loss_mean 8.51 / report/image_loss_std 4.71 / report/model_loss_mean 10.97 / report/model_loss_std 5.76 / report/post_ent_mag 34.35 / report/post_ent_max 34.35 / 
report/post_ent_mean 24.22 / report/post_ent_min 15.35 / report/post_ent_std 2.72 / report/prior_ent_mag 47.65 / report/prior_ent_max 47.65 / report/prior_ent_mean 29.27 / report/prior_ent_min 21.09 / report/prior_ent_std 4.09 / report/rep_loss_mean 4.1 / 
report/rep_loss_std 3.49 / report/reward_avg 0 / report/reward_loss_mean 1.5e-3 / report/reward_loss_std 1.1e-3 / report/reward_max_data 0 / report/reward_max_pred 2.4e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 7.8e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-6 / eval/cont_loss_std 1.7e-6 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-6 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 6.85 / eval/dyn_loss_std 4.34 / eval/image_loss_mean 10.39 / eval/image_loss_std 4.32 / eval/model_loss_mean 14.5 / eval/model_loss_std 5.83 / eval/post_ent_mag 44.07 / eval/post_ent_max 44.07 / eval/post_ent_mean 26.01 / 
eval/post_ent_min 18.59 / eval/post_ent_std 2.99 / eval/prior_ent_mag 47.65 / eval/prior_ent_max 47.65 / eval/prior_ent_mean 31.23 / eval/prior_ent_min 22.7 / eval/prior_ent_std 3.3 / eval/rep_loss_mean 6.85 / eval/rep_loss_std 4.34 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.4e-3 / eval/reward_loss_std 1.4e-4 / eval/reward_max_data 0 / eval/reward_max_pred 3.1e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 7.1e-5 / eval/reward_rate 0 / 
replay/size 4765 / replay/inserts 3727 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5045 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 290.94 / timer/env.step_count 3727 / timer/env.step_total 19.58 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 427.74 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-4 / timer/replay._sample_max 0.08 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7234 / timer/agent.policy_total 16 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.05 / 
timer/dataset_train_count 1863 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 2.6e-4 / timer/agent.train_count 1863 / timer/agent.train_total 236.49 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 5000 Counter(5000) 4937
Saved chunk: 20230921T213229F365478-5m4sQoIHTz7MfkTRhPrJwc-7bok1ZsxakqqpWwqSHeazW-1024.npz
eval_Episode has 500 steps and return 12.8.
train_Episode has 500 steps and return 3.9.
Saved chunk: 20230921T213315F707095-1Yle2GhYNjbYZ2UCikyJZh-78KVAqYNZliLM1fWsAutxJ-1024.npz
Starting evaluation at step 5500 Counter(5500) 5437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 6000 Counter(6000) 5937
Saved chunk: 20230921T213424F683595-7bok1ZsxakqqpWwqSHeazW-7Gpo2pFMtsw7Y1s8JtGTG4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 3.2.
Saved chunk: 20230921T213436F830594-78KVAqYNZliLM1fWsAutxJ-03tin5x2Tp3FEOeYiD5RE9-1024.npz
Starting evaluation at step 6500 Counter(6500) 6437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 7000 Counter(7000) 6937
Saved chunk: 20230921T213543F925990-7Gpo2pFMtsw7Y1s8JtGTG4-3JjWWHmTO0LxfIrUw2tEXC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213557F598082-03tin5x2Tp3FEOeYiD5RE9-4hkGS3k8efdTiQ8PnFWQek-1024.npz
Starting evaluation at step 7500 Counter(7500) 7437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 8000 Counter(8000) 7937
Saved chunk: 20230921T213702F940331-3JjWWHmTO0LxfIrUw2tEXC-1mR3XQ14gPProJdT3V1AQ8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213718F090629-4hkGS3k8efdTiQ8PnFWQek-3IzAJZ2AzttMmMoQHVy3HJ-1024.npz
Starting evaluation at step 8500 Counter(8500) 8437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 17210 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.11 / train/action_max 4.93 / train/action_mean -0.09 / train/action_min -4.99 / train/action_std 1.29 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 2810 / train/actor_opt_loss -37.71 / train/adv_mag 1.1 / train/adv_max 1.1 / train/adv_mean 2.2e-3 / train/adv_min -0.03 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.8e-6 / train/cont_loss_std 1.1e-6 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-6 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.91 / 
train/dyn_loss_std 3.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 2810 / train/extr_critic_critic_opt_loss 
7041.55 / train/extr_critic_mag 0.08 / train/extr_critic_max 0.08 / train/extr_critic_mean 0.02 / train/extr_critic_min 0.02 / train/extr_critic_std 3e-3 / train/extr_return_normed_mag 1.14 / train/extr_return_normed_max 1.14 / train/extr_return_normed_mean 3.7e-3 / 
train/extr_return_normed_min 3.4e-4 / train/extr_return_normed_std 0.04 / train/extr_return_rate 1.4e-3 / train/extr_return_raw_mag 1.16 / train/extr_return_raw_max 1.16 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.02 / train/extr_return_raw_std 0.04 / 
train/extr_reward_mag 0.34 / train/extr_reward_max 0.34 / train/extr_reward_mean 5.3e-4 / train/extr_reward_min 3.3e-5 / train/extr_reward_std 8.9e-3 / train/image_loss_mean 6.59 / train/image_loss_std 4.17 / train/model_loss_mean 8.93 / train/model_loss_std 5.59 / 
train/model_opt_grad_norm 34.08 / train/model_opt_grad_steps 2801 / train/model_opt_loss 912.87 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 105.61 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.46 / train/policy_entropy_min -2.04 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 16.52 / train/policy_logprob_max 3.47 / train/policy_logprob_mean -5.46 / train/policy_logprob_min -16.52 / train/policy_logprob_std 1.66 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.98 / train/policy_randomness_min 0.16 / train/policy_randomness_std 0.09 / train/post_ent_mag 33.41 / train/post_ent_max 33.41 / train/post_ent_mean 21.97 / train/post_ent_min 
14.32 / train/post_ent_std 2.81 / train/prior_ent_mag 47.79 / train/prior_ent_max 47.79 / train/prior_ent_mean 26.61 / train/prior_ent_min 18.17 / train/prior_ent_std 4.49 / train/rep_loss_mean 3.91 / train/rep_loss_std 3.92 / train/reward_avg 1.2e-3 / 
train/reward_loss_mean 4.3e-3 / train/reward_loss_std 0.05 / train/reward_max_data 0.28 / train/reward_max_pred 0.19 / train/reward_neg_acc 1 / train/reward_neg_loss 1.3e-3 / train/reward_pos_acc 0.89 / train/reward_pos_loss 1.45 / train/reward_pred 9e-4 / 
train/reward_rate 2e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.31 / report/cont_avg 1 / report/cont_loss_mean 7.9e-7 / report/cont_loss_std 4.2e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
7.9e-7 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.05 / report/dyn_loss_std 4.41 / report/image_loss_mean 5.49 / report/image_loss_std 3.58 / report/model_loss_mean 7.92 / report/model_loss_std 5.35 / report/post_ent_mag 30.64 / report/post_ent_max 
30.64 / report/post_ent_mean 21.51 / report/post_ent_min 13.81 / report/post_ent_std 2.52 / report/prior_ent_mag 46.48 / report/prior_ent_max 46.48 / report/prior_ent_mean 26.33 / report/prior_ent_min 17.34 / report/prior_ent_std 4.26 / report/rep_loss_mean 4.05 / 
report/rep_loss_std 4.41 / report/reward_avg 0 / report/reward_loss_mean 3.1e-4 / report/reward_loss_std 1.3e-4 / report/reward_max_data 0 / report/reward_max_pred 4.2e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-4 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 1.6e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.9e-7 / eval/cont_loss_std 2.4e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.9e-7 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 9.18 / eval/dyn_loss_std 5.54 / eval/image_loss_mean 8.38 / eval/image_loss_std 3.62 / eval/model_loss_mean 13.89 / eval/model_loss_std 6.2 / eval/post_ent_mag 34.33 / eval/post_ent_max 34.33 / eval/post_ent_mean 22.9 / 
eval/post_ent_min 15.67 / eval/post_ent_std 2.81 / eval/prior_ent_mag 46.48 / eval/prior_ent_max 46.48 / eval/prior_ent_mean 27.95 / eval/prior_ent_min 19 / eval/prior_ent_std 3.88 / eval/rep_loss_mean 9.18 / eval/rep_loss_std 5.54 / eval/reward_avg 0 / 
eval/reward_loss_mean 2.8e-4 / eval/reward_loss_std 1.7e-5 / eval/reward_max_data 0 / eval/reward_max_pred 3.4e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.3e-5 / eval/reward_rate 0 / 
replay/size 8542 / replay/inserts 3777 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9053 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3777 / timer/env.step_total 19.86 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 435.44 / timer/replay._sample_frac 1.45 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7785 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.1e-3 / 
timer/dataset_train_count 1889 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1889 / timer/agent.train_total 241.86 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 9000 Counter(9000) 8937
Saved chunk: 20230921T213821F785157-1mR3XQ14gPProJdT3V1AQ8-7jVLwXVmgQzorsxGE4cRpF-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.7.
Saved chunk: 20230921T213838F542838-3IzAJZ2AzttMmMoQHVy3HJ-5P3Nz3qL4EUFrsP8OmvhEp-1024.npz
Starting evaluation at step 9500 Counter(9500) 9437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 10000 Counter(10000) 9937
Saved chunk: 20230921T213941F400837-7jVLwXVmgQzorsxGE4cRpF-0Yb7MYlf7lPeAuEcMMslR1-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213959F851777-5P3Nz3qL4EUFrsP8OmvhEp-6X7PCy66Fqbzig03vWs0oC-1024.npz
Starting evaluation at step 10500 Counter(10500) 10437
eval_Episode has 500 steps and return 11.4.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 11000 Counter(11000) 10937
Saved chunk: 20230921T214100F714887-0Yb7MYlf7lPeAuEcMMslR1-6f4fBkjw6VfyuJqD47Fnal-1024.npz
eval_Episode has 500 steps and return 7.1.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214120F635625-6X7PCy66Fqbzig03vWs0oC-1VoxQzoAYwxcF6SsktJjQh-1024.npz
Starting evaluation at step 11500 Counter(11500) 11437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T214241F090446-1VoxQzoAYwxcF6SsktJjQh-0000000000000000000000-336.npz
Saved chunk: 20230921T214219F668151-6f4fBkjw6VfyuJqD47Fnal-0000000000000000000000-858.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 12000 Counter(12000) 11937
Saved chunk: 20230921T214219F668151-6f4fBkjw6VfyuJqD47Fnal-4xGCs1tGNcjd8LGSw3H1dj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214241F090446-1VoxQzoAYwxcF6SsktJjQh-5HjLPAkTpHqornMO9wziB3-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 24854 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.13 / train/action_max 4.89 / train/action_mean -0.21 / train/action_min -5.05 / train/action_std 1.28 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 8.4e-3 / train/actor_opt_grad_steps 4710 / train/actor_opt_loss -21.36 / train/adv_mag 0.64 / train/adv_max 0.58 / train/adv_mean 5e-4 / train/adv_min -0.15 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.6e-7 / train/cont_loss_std 2.2e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.59 / 
train/dyn_loss_std 4.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 4710 / train/extr_critic_critic_opt_loss 
7618.09 / train/extr_critic_mag 0.27 / train/extr_critic_max 0.27 / train/extr_critic_mean 0.02 / train/extr_critic_min 0.02 / train/extr_critic_std 7.8e-3 / train/extr_return_normed_mag 0.72 / train/extr_return_normed_max 0.72 / train/extr_return_normed_mean 1.5e-3 / 
train/extr_return_normed_min -8.6e-4 / train/extr_return_normed_std 0.02 / train/extr_return_rate 5.3e-4 / train/extr_return_raw_mag 0.74 / train/extr_return_raw_max 0.74 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.02 / train/extr_return_raw_std 0.02 /
train/extr_reward_mag 0.23 / train/extr_reward_max 0.23 / train/extr_reward_mean 2.8e-4 / train/extr_reward_min 4.2e-6 / train/extr_reward_std 5.9e-3 / train/image_loss_mean 4.57 / train/image_loss_std 3.53 / train/model_loss_mean 6.73 / train/model_loss_std 5.24 / 
train/model_opt_grad_norm 25.51 / train/model_opt_grad_steps 4701 / train/model_opt_loss 2595.39 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 397.58 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.56 / train/policy_entropy_min -1.61 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 16.45 / train/policy_logprob_max 2.75 / train/policy_logprob_mean -5.56 / train/policy_logprob_min -16.45 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.21 / train/policy_randomness_std 0.06 / train/post_ent_mag 31.09 / train/post_ent_max 31.09 / train/post_ent_mean 21.17 / train/post_ent_min 
13.57 / train/post_ent_std 2.54 / train/prior_ent_mag 48 / train/prior_ent_max 48 / train/prior_ent_mean 25.22 / train/prior_ent_min 17.14 / train/prior_ent_std 4.37 / train/rep_loss_mean 3.59 / train/rep_loss_std 4.23 / train/reward_avg 5.6e-4 / train/reward_loss_mean 
1.4e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.17 / train/reward_max_pred 0.15 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-4 / train/reward_pos_acc 0.93 / train/reward_pos_loss 0.76 / train/reward_pred 5.5e-4 / train/reward_rate 1.2e-3 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.48 / report/cont_avg 1 / report/cont_loss_mean 2.3e-7 / report/cont_loss_std 7.9e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-7 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 3.1 / report/dyn_loss_std 4.02 / report/image_loss_mean 3.05 / report/image_loss_std 2.49 / report/model_loss_mean 4.92 / report/model_loss_std 4.14 / report/post_ent_mag 28.85 / report/post_ent_max 28.85 / 
report/post_ent_mean 21.11 / report/post_ent_min 14.74 / report/post_ent_std 2.42 / report/prior_ent_mag 48.47 / report/prior_ent_max 48.47 / report/prior_ent_mean 24.64 / report/prior_ent_min 15.8 / report/prior_ent_std 4.1 / report/rep_loss_mean 3.1 / 
report/rep_loss_std 4.02 / report/reward_avg 3.8e-3 / report/reward_loss_mean 3e-3 / report/reward_loss_std 0.04 / report/reward_max_data 1.28 / report/reward_max_pred 1.19 / report/reward_neg_acc 1 / report/reward_neg_loss 5.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.63 / report/reward_pred 3.6e-3 / report/reward_rate 3.9e-3 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-7 / eval/cont_loss_std 7.2e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-7 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 10.97 / eval/dyn_loss_std 6.81 / eval/image_loss_mean 8.1 / eval/image_loss_std 4.86 / eval/model_loss_mean 14.68 / eval/model_loss_std 7.88 / eval/post_ent_mag 37.21 / eval/post_ent_max 37.21 / eval/post_ent_mean 
21.86 / eval/post_ent_min 14.77 / eval/post_ent_std 2.99 / eval/prior_ent_mag 48.47 / eval/prior_ent_max 48.47 / eval/prior_ent_mean 26.71 / eval/prior_ent_min 18.04 / eval/prior_ent_std 4.55 / eval/rep_loss_mean 10.97 / eval/rep_loss_std 6.81 / eval/reward_avg 0 / 
eval/reward_loss_mean 9.2e-5 / eval/reward_loss_std 5.4e-5 / eval/reward_max_data 0 / eval/reward_max_pred 1.5e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.2e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 3.9e-6 / eval/reward_rate 0 / 
replay/size 1.2e4 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3822 / timer/env.step_total 20.14 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 443.04 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7329 / timer/agent.policy_total 16.19 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1911 / timer/agent.train_total 244.83 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.47

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 12500 Counter(12500) 12437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 13000 Counter(13000) 12937
Saved chunk: 20230921T214338F762043-4xGCs1tGNcjd8LGSw3H1dj-6RnZwLd6IqVEME5tWdiQvr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214401F793223-5HjLPAkTpHqornMO9wziB3-7i6s8Am5qtl7GeJoJjEKlj-1024.npz
Starting evaluation at step 13500 Counter(13500) 13437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 14000 Counter(14000) 13937
Saved chunk: 20230921T214458F600785-6RnZwLd6IqVEME5tWdiQvr-30Ru0cy4ktF6eyheBV8QFx-1024.npz
eval_Episode has 500 steps and return 0.6.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214523F320650-7i6s8Am5qtl7GeJoJjEKlj-5EpajfKtY4F83z2ueGtCQR-1024.npz
Starting evaluation at step 14500 Counter(14500) 14437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.3.
Starting evaluation at step 15000 Counter(15000) 14937
Saved chunk: 20230921T214617F780078-30Ru0cy4ktF6eyheBV8QFx-6ohR3MlwebahvV5W1LekK3-1024.npz
eval_Episode has 500 steps and return 0.5.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214643F986082-5EpajfKtY4F83z2ueGtCQR-2LElklhgyQoIdJwUAhUsuD-1024.npz
Starting evaluation at step 15500 Counter(15500) 15437
eval_Episode has 500 steps and return 0.6.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 16000 Counter(16000) 15937
Saved chunk: 20230921T214736F726992-6ohR3MlwebahvV5W1LekK3-4Tsgk0FRTgIwgI2WXupfX0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 32406 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.24 / train/action_max 4.85 / train/action_mean -0.49 / train/action_min -5.18 / train/action_std 1.26 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 6610 / train/actor_opt_loss -22.93 / train/adv_mag 0.7 / train/adv_max 0.6 / train/adv_mean 6.4e-4 / train/adv_min -0.27 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.4e-7 / train/cont_loss_std 5e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.41 / 
train/dyn_loss_std 4.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 6610 / train/extr_critic_critic_opt_loss 
5940.21 / train/extr_critic_mag 0.46 / train/extr_critic_max 0.46 / train/extr_critic_mean 0.02 / train/extr_critic_min 0.01 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.86 / train/extr_return_normed_max 0.86 / train/extr_return_normed_mean 1.8e-3 / 
train/extr_return_normed_min -5.5e-4 / train/extr_return_normed_std 0.03 / train/extr_return_rate 6.8e-4 / train/extr_return_raw_mag 0.88 / train/extr_return_raw_max 0.88 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.01 / train/extr_return_raw_std 0.03 /
train/extr_reward_mag 0.29 / train/extr_reward_max 0.29 / train/extr_reward_mean 3.6e-4 / train/extr_reward_min 1.3e-6 / train/extr_reward_std 8e-3 / train/image_loss_mean 3.45 / train/image_loss_std 2.97 / train/model_loss_mean 5.5 / train/model_loss_std 4.81 / 
train/model_opt_grad_norm 19.4 / train/model_opt_grad_steps 6601 / train/model_opt_loss 8021.83 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1491.4 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.63 / train/policy_entropy_min -1.15 / train/policy_entropy_std 0.32 / train/policy_logprob_mag 16.55 / train/policy_logprob_max 2.18 / train/policy_logprob_mean -5.63 / train/policy_logprob_min -16.55 / train/policy_logprob_std 1.46 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.26 / train/policy_randomness_std 0.03 / train/post_ent_mag 30.74 / train/post_ent_max 30.74 / train/post_ent_mean 21.68 / train/post_ent_min 13.4
/ train/post_ent_std 2.62 / train/prior_ent_mag 48.56 / train/prior_ent_max 48.56 / train/prior_ent_mean 25.39 / train/prior_ent_min 16.89 / train/prior_ent_std 4.33 / train/rep_loss_mean 3.41 / train/rep_loss_std 4.34 / train/reward_avg 7e-4 / train/reward_loss_mean 
1.3e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.19 / train/reward_max_pred 0.18 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-4 / train/reward_pos_acc 0.88 / train/reward_pos_loss 0.87 / train/reward_pred 6.9e-4 / train/reward_rate 1.4e-3 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.62 / report/cont_avg 1 / report/cont_loss_mean 7.8e-8 / report/cont_loss_std 2.4e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.8e-8 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 3.47 / report/dyn_loss_std 4.58 / report/image_loss_mean 3.61 / report/image_loss_std 3.07 / report/model_loss_mean 5.69 / report/model_loss_std 5.04 / report/post_ent_mag 31.28 / report/post_ent_max 31.28 / 
report/post_ent_mean 21.82 / report/post_ent_min 13.63 / report/post_ent_std 2.66 / report/prior_ent_mag 48.82 / report/prior_ent_max 48.82 / report/prior_ent_mean 25.79 / report/prior_ent_min 16.43 / report/prior_ent_std 4.4 / report/rep_loss_mean 3.47 / 
report/rep_loss_std 4.58 / report/reward_avg 1.5e-5 / report/reward_loss_mean 6.3e-4 / report/reward_loss_std 0.01 / report/reward_max_data 0.01 / report/reward_max_pred 0.05 / report/reward_neg_acc 1 / report/reward_neg_loss 6.3e-4 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 5.8e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-8 / eval/cont_loss_std 1.6e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-8 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 12.69 / eval/dyn_loss_std 7.45 / eval/image_loss_mean 7.65 / eval/image_loss_std 4.4 / eval/model_loss_mean 15.26 / eval/model_loss_std 7.74 / eval/post_ent_mag 33.77 / eval/post_ent_max 33.77 / eval/post_ent_mean 21.52 / 
eval/post_ent_min 14.15 / eval/post_ent_std 3.06 / eval/prior_ent_mag 48.82 / eval/prior_ent_max 48.82 / eval/prior_ent_mean 26.63 / eval/prior_ent_min 17.42 / eval/prior_ent_std 4.64 / eval/rep_loss_mean 12.69 / eval/rep_loss_std 7.45 / eval/reward_avg 0 / 
eval/reward_loss_mean 3.8e-5 / eval/reward_loss_std 9.4e-5 / eval/reward_max_data 0 / eval/reward_max_pred 3.4e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 2e-6 / eval/reward_rate 0 / 
replay/size 1.6e4 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3776 / timer/env.step_total 19.87 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 437.27 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.1 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 16.87 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1888 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1888 / timer/agent.train_total 241.84 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T214804F392538-2LElklhgyQoIdJwUAhUsuD-7gvavzrVfqoxhOrmodp6Qv-1024.npz
Starting evaluation at step 16500 Counter(16500) 16437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 17000 Counter(17000) 16937
Saved chunk: 20230921T214855F484351-4Tsgk0FRTgIwgI2WXupfX0-2oaABHXIX7z8J8Akplw5Dw-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 4.6.
Saved chunk: 20230921T214925F397783-7gvavzrVfqoxhOrmodp6Qv-0uG1eWo3rimK7l7Qz71oU7-1024.npz
Starting evaluation at step 17500 Counter(17500) 17437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 18000 Counter(18000) 17937
Saved chunk: 20230921T215015F399909-2oaABHXIX7z8J8Akplw5Dw-2i4JQaY88K2ibS9VpVK8yk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215046F427999-0uG1eWo3rimK7l7Qz71oU7-1aYNdQvnixarlPmBCXGnU7-1024.npz
Starting evaluation at step 18500 Counter(18500) 18437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 19000 Counter(19000) 18937
Saved chunk: 20230921T215134F704792-2i4JQaY88K2ibS9VpVK8yk-3DvpfcPHiCX2Xg7tQnB1YA-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215207F251751-1aYNdQvnixarlPmBCXGnU7-7h6HiW8L2sKhUmGCg8M4ao-1024.npz
Starting evaluation at step 19500 Counter(19500) 19437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 1.9.
Starting evaluation at step 20000 Counter(20000) 19937
Saved chunk: 20230921T215253F773937-3DvpfcPHiCX2Xg7tQnB1YA-1qvLIq6Xxe4LFkLa3HbFEL-1024.npz
eval_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 40002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 1.87 / episode/reward_rate 1e-2 / train/action_mag 5.24 / train/action_max 4.88 / train/action_mean -0.51 / train/action_min -5.19 / train/action_std 1.27 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.3e-3 / train/actor_opt_grad_steps 8505 / train/actor_opt_loss -20.29 / train/adv_mag 0.78 / train/adv_max 0.65 / train/adv_mean 3.8e-4 / train/adv_min -0.38 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5e-8 / train/cont_loss_std 1.2e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.13 / 
train/dyn_loss_std 4.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 8505 / train/extr_critic_critic_opt_loss 
4723.01 / train/extr_critic_mag 0.76 / train/extr_critic_max 0.76 / train/extr_critic_mean 0.01 / train/extr_critic_min 9.5e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 2e-3 / 
train/extr_return_normed_min -3.7e-4 / train/extr_return_normed_std 0.03 / train/extr_return_rate 8.2e-4 / train/extr_return_raw_mag 1.06 / train/extr_return_raw_max 1.06 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 9.5e-3 / train/extr_return_raw_std 0.03
/ train/extr_reward_mag 0.38 / train/extr_reward_max 0.38 / train/extr_reward_mean 3.6e-4 / train/extr_reward_min 6e-7 / train/extr_reward_std 8.4e-3 / train/image_loss_mean 2.68 / train/image_loss_std 2.47 / train/model_loss_mean 4.56 / train/model_loss_std 4.41 / 
train/model_opt_grad_norm 17.8 / train/model_opt_grad_steps 8495.77 / train/model_opt_loss 2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4421.05 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.63 / train/policy_entropy_min -1.78 / train/policy_entropy_std 0.35 / train/policy_logprob_mag 16.56 / train/policy_logprob_max 2.92 / train/policy_logprob_mean -5.63 / train/policy_logprob_min -16.56 / train/policy_logprob_std 1.47 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.19 / train/policy_randomness_std 0.04 / train/post_ent_mag 30.6 / train/post_ent_max 30.6 / train/post_ent_mean 22.22 / train/post_ent_min 13.44 
/ train/post_ent_std 2.63 / train/prior_ent_mag 49.54 / train/prior_ent_max 49.54 / train/prior_ent_mean 25.56 / train/prior_ent_min 16.89 / train/prior_ent_std 4.27 / train/rep_loss_mean 3.13 / train/rep_loss_std 4.36 / train/reward_avg 6.1e-4 / train/reward_loss_mean 
1.1e-3 / train/reward_loss_std 0.01 / train/reward_max_data 0.18 / train/reward_max_pred 0.16 / train/reward_neg_acc 1 / train/reward_neg_loss 2.5e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.68 / train/reward_pred 6e-4 / train/reward_rate 1.3e-3 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.56 / report/cont_avg 1 / report/cont_loss_mean 3.4e-8 / report/cont_loss_std 5.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-8 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 2.78 / report/dyn_loss_std 4.41 / report/image_loss_mean 2.45 / report/image_loss_std 2.37 / report/model_loss_mean 4.12 / report/model_loss_std 4.23 / report/post_ent_mag 31.17 / report/post_ent_max 31.17 / 
report/post_ent_mean 22.47 / report/post_ent_min 12.05 / report/post_ent_std 2.93 / report/prior_ent_mag 50.07 / report/prior_ent_max 50.07 / report/prior_ent_mean 25.46 / report/prior_ent_min 17.71 / report/prior_ent_std 4.3 / report/rep_loss_mean 2.78 / 
report/rep_loss_std 4.41 / report/reward_avg 2.7e-4 / report/reward_loss_mean 7.3e-4 / report/reward_loss_std 0.02 / report/reward_max_data 0.28 / report/reward_max_pred 0.26 / report/reward_neg_acc 1 / report/reward_neg_loss 3.5e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.71 / report/reward_pred 2.6e-4 / report/reward_rate 9.8e-4 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-8 / eval/cont_loss_std 4.9e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-8 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 13.14 / eval/dyn_loss_std 7.63 / eval/image_loss_mean 7.12 / eval/image_loss_std 3.29 / eval/model_loss_mean 15.01 / eval/model_loss_std 7.03 / eval/post_ent_mag 29.97 / eval/post_ent_max 29.97 / eval/post_ent_mean 
21.64 / eval/post_ent_min 13.69 / eval/post_ent_std 2.93 / eval/prior_ent_mag 50.07 / eval/prior_ent_max 50.07 / eval/prior_ent_mean 26.4 / eval/prior_ent_min 17.86 / eval/prior_ent_std 4.49 / eval/rep_loss_mean 13.14 / eval/rep_loss_std 7.63 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.2e-5 / eval/reward_loss_std 2.1e-6 / eval/reward_max_data 0 / eval/reward_max_pred 6e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 4.7e-7 / eval/reward_rate 0 / 
replay/size 2e4 / replay/inserts 3798 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.22 / timer/env.step_count 3798 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 440.93 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.1 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7806 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1899 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1899 / timer/agent.train_total 243.62 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215327F849268-7h6HiW8L2sKhUmGCg8M4ao-7EzFcW5GdPyl07KIiCYHk1-1024.npz
Starting evaluation at step 20500 Counter(20500) 20437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21000 Counter(21000) 20937
Saved chunk: 20230921T215412F815323-1qvLIq6Xxe4LFkLa3HbFEL-4bygiqRs2W9VfMFWdB63p6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21500 Counter(21500) 21437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215449F121965-7EzFcW5GdPyl07KIiCYHk1-223WZomvQRYsiDFiQOcvU8-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22000 Counter(22000) 21937
Saved chunk: 20230921T215532F751145-4bygiqRs2W9VfMFWdB63p6-49PJv191max3opUg6rvEPS-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22500 Counter(22500) 22437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215613F595631-223WZomvQRYsiDFiQOcvU8-2579KBfnmrYP5P2LFpl6iO-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 23000 Counter(23000) 22937
Saved chunk: 20230921T215652F011750-49PJv191max3opUg6rvEPS-497di5fGp1EENl1e0WAZtk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T215811F071926-497di5fGp1EENl1e0WAZtk-0000000000000000000000-93.npz
Saved chunk: 20230921T215734F336337-2579KBfnmrYP5P2LFpl6iO-0000000000000000000000-572.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 23500 Counter(23500) 23437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215734F336337-2579KBfnmrYP5P2LFpl6iO-38QzXJpl5QUKVa9RQMk1OC-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 47630 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 5.19 / train/action_max 4.89 / train/action_mean -0.46 / train/action_min -5.14 / train/action_std 1.27 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 1e4 / train/actor_opt_loss -22.36 / train/adv_mag 0.98 / train/adv_max 0.86 / train/adv_mean 5.9e-4 / train/adv_min -0.5 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-8 / train/cont_loss_std 4.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.98 / 
train/dyn_loss_std 4.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 1e4 / train/extr_critic_critic_opt_loss 
3407.26 / train/extr_critic_mag 1.09 / train/extr_critic_max 1.09 / train/extr_critic_mean 8.9e-3 / train/extr_critic_min 5.9e-3 / train/extr_critic_std 0.04 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.45 / train/extr_return_normed_mean 3.2e-3 / 
train/extr_return_normed_min -3e-4 / train/extr_return_normed_std 0.05 / train/extr_return_rate 1.4e-3 / train/extr_return_raw_mag 1.46 / train/extr_return_raw_max 1.46 / train/extr_return_raw_mean 9.4e-3 / train/extr_return_raw_min 6e-3 / train/extr_return_raw_std 0.05 /
train/extr_reward_mag 0.57 / train/extr_reward_max 0.57 / train/extr_reward_mean 5.7e-4 / train/extr_reward_min 1.9e-7 / train/extr_reward_std 0.01 / train/image_loss_mean 2.24 / train/image_loss_std 2.11 / train/model_loss_mean 4.03 / train/model_loss_std 4.14 / 
train/model_opt_grad_norm 14.62 / train/model_opt_grad_steps 1e4 / train/model_opt_loss 2.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5131.58 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.62 / train/policy_entropy_min -2.38 / train/policy_entropy_std 0.43 / train/policy_logprob_mag 16.53 / train/policy_logprob_max 3.54 / train/policy_logprob_mean -5.62 / train/policy_logprob_min -16.53 / train/policy_logprob_std 1.49 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.12 / train/policy_randomness_std 0.05 / train/post_ent_mag 31.27 / train/post_ent_max 31.27 / train/post_ent_mean 22.99 / train/post_ent_min 
13.68 / train/post_ent_std 2.8 / train/prior_ent_mag 50.44 / train/prior_ent_max 50.44 / train/prior_ent_mean 26.15 / train/prior_ent_min 17.08 / train/prior_ent_std 4.29 / train/rep_loss_mean 2.98 / train/rep_loss_std 4.41 / train/reward_avg 7.8e-4 / 
train/reward_loss_mean 1.3e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.19 / train/reward_max_pred 0.19 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.61 / train/reward_pred 7.8e-4 / 
train/reward_rate 1.7e-3 / train_stats/mean_log_entropy 5.61 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-8 / report/cont_loss_std 2.7e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.6e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.92 / report/dyn_loss_std 4.81 / report/image_loss_mean 2.12 / report/image_loss_std 2.37 / report/model_loss_mean 3.87 / report/model_loss_std 4.54 / report/post_ent_mag 31.2 / 
report/post_ent_max 31.2 / report/post_ent_mean 23.72 / report/post_ent_min 13.66 / report/post_ent_std 2.63 / report/prior_ent_mag 50.62 / report/prior_ent_max 50.62 / report/prior_ent_mean 26.89 / report/prior_ent_min 18.36 / report/prior_ent_std 4.36 / 
report/rep_loss_mean 2.92 / report/rep_loss_std 4.81 / report/reward_avg 0 / report/reward_loss_mean 9.1e-6 / report/reward_loss_std 5.6e-5 / report/reward_max_data 0 / report/reward_max_pred 3.8e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 9.1e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.1e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-8 / eval/cont_loss_std 2.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
1.4e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 15.34 / eval/dyn_loss_std 8.15 / eval/image_loss_mean 7.92 / eval/image_loss_std 3.67 / eval/model_loss_mean 17.12 / eval/model_loss_std 7.9 / eval/post_ent_mag 31.77 / eval/post_ent_max 31.77 / 
eval/post_ent_mean 22.59 / eval/post_ent_min 12.92 / eval/post_ent_std 3.02 / eval/prior_ent_mag 50.62 / eval/prior_ent_max 50.62 / eval/prior_ent_mean 27.65 / eval/prior_ent_min 17.74 / eval/prior_ent_std 4.64 / eval/rep_loss_mean 15.34 / eval/rep_loss_std 8.15 / 
eval/reward_avg 0 / eval/reward_loss_mean 4.4e-6 / eval/reward_loss_std 2.2e-6 / eval/reward_max_data 0 / eval/reward_max_pred 1.2e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.4e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.9e-7 / 
eval/reward_rate 0 / replay/size 2.4e4 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.4e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3814 / timer/env.step_total 20.21 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 443.96 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 9.4e-4 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.15 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / 
timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.6 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / 
timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 24000 Counter(24000) 23937
Saved chunk: 20230921T215811F071926-497di5fGp1EENl1e0WAZtk-2GvtyeNMP9p48wjJBxp9X7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 24500 Counter(24500) 24437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215855F234358-38QzXJpl5QUKVa9RQMk1OC-7rBjjLEq3UzljzCuSTkYv1-1024.npz
Starting evaluation at step 25000 Counter(25000) 24937
Saved chunk: 20230921T215931F110618-2GvtyeNMP9p48wjJBxp9X7-092aoNmoA1KNPIaWwx0UXN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 25500 Counter(25500) 25437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 3.7.
Saved chunk: 20230921T220016F810124-7rBjjLEq3UzljzCuSTkYv1-1u6lVfYZ6X5lh3PJqJICdA-1024.npz
Starting evaluation at step 26000 Counter(26000) 25937
Saved chunk: 20230921T220050F522713-092aoNmoA1KNPIaWwx0UXN-3efbzlzO9MhHK8eFnFrfZe-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 26500 Counter(26500) 26437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220137F576794-1u6lVfYZ6X5lh3PJqJICdA-6cenTAe6utHNd0Y0KXCyBs-1024.npz
Starting evaluation at step 27000 Counter(27000) 26937
eval_Episode has 500 steps and return 1.0.
Saved chunk: 20230921T220209F669675-3efbzlzO9MhHK8eFnFrfZe-2vTvuE0u6YklGSE12lJqA2-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 27500 Counter(27500) 27437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.5.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 55170 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0.53 / episode/reward_rate 2e-3 / train/action_mag 5.21 / train/action_max 4.93 / train/action_mean -0.4 / train/action_min -5.14 / train/action_std 1.3 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1e-2 / train/actor_opt_grad_steps 1.2e4 / train/actor_opt_loss -20.86 / train/adv_mag 0.78 / train/adv_max 0.67 / train/adv_mean 4.4e-4 / train/adv_min -0.38 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 9.9e-9 / train/cont_loss_std 2.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.9e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.81 / 
train/dyn_loss_std 4.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 1.2e4 / train/extr_critic_critic_opt_loss 
2134.01 / train/extr_critic_mag 1.04 / train/extr_critic_max 1.04 / train/extr_critic_mean 6.1e-3 / train/extr_critic_min 3.2e-3 / train/extr_critic_std 0.04 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.34 / train/extr_return_normed_mean 3.1e-3 / 
train/extr_return_normed_min -1.8e-4 / train/extr_return_normed_std 0.05 / train/extr_return_rate 1.3e-3 / train/extr_return_raw_mag 1.34 / train/extr_return_raw_max 1.34 / train/extr_return_raw_mean 6.5e-3 / train/extr_return_raw_min 3.2e-3 / train/extr_return_raw_std 
0.05 / train/extr_reward_mag 0.37 / train/extr_reward_max 0.37 / train/extr_reward_mean 5.6e-4 / train/extr_reward_min 2.9e-8 / train/extr_reward_std 0.01 / train/image_loss_mean 1.87 / train/image_loss_std 1.94 / train/model_loss_mean 3.56 / train/model_loss_std 4.03 / 
train/model_opt_grad_norm 13.44 / train/model_opt_grad_steps 1.2e4 / train/model_opt_loss 1.9e4 / train/model_opt_model_opt_grad_overflow 5.3e-3 / train/model_opt_model_opt_grad_scale 5264.55 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.63 / train/policy_entropy_min -2.54 / train/policy_entropy_std 0.45 / train/policy_logprob_mag 16.56 / train/policy_logprob_max 3.75 / train/policy_logprob_mean -5.63 / train/policy_logprob_min -16.56 / train/policy_logprob_std 1.5 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.11 / train/policy_randomness_std 0.05 / train/post_ent_mag 32.09 / train/post_ent_max 32.09 / train/post_ent_mean 23.87 / train/post_ent_min 
14.04 / train/post_ent_std 3.02 / train/prior_ent_mag 51.23 / train/prior_ent_max 51.23 / train/prior_ent_mean 26.82 / train/prior_ent_min 17.08 / train/prior_ent_std 4.38 / train/rep_loss_mean 2.81 / train/rep_loss_std 4.42 / train/reward_avg 7.8e-4 / 
train/reward_loss_mean 1.2e-3 / train/reward_loss_std 0.01 / train/reward_max_data 0.2 / train/reward_max_pred 0.19 / train/reward_neg_acc 1 / train/reward_neg_loss 2.1e-4 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.64 / train/reward_pred 7.7e-4 / 
train/reward_rate 1.6e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.57 / report/cont_avg 1 / report/cont_loss_mean 5.9e-9 / report/cont_loss_std 1.3e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.9e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.53 / report/dyn_loss_std 4.03 / report/image_loss_mean 1.45 / report/image_loss_std 1.74 / report/model_loss_mean 2.97 / report/model_loss_std 3.57 / report/post_ent_mag 31.79 /
report/post_ent_max 31.79 / report/post_ent_mean 24.51 / report/post_ent_min 15.14 / report/post_ent_std 2.71 / report/prior_ent_mag 51.54 / report/prior_ent_max 51.54 / report/prior_ent_mean 27.15 / report/prior_ent_min 17.13 / report/prior_ent_std 4.19 / 
report/rep_loss_mean 2.53 / report/rep_loss_std 4.03 / report/reward_avg 0 / report/reward_loss_mean 8.2e-6 / report/reward_loss_std 7.8e-5 / report/reward_max_data 0 / report/reward_max_pred 2.6e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.1e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-9 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
5.6e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 12.71 / eval/dyn_loss_std 12.79 / eval/image_loss_mean 8.33 / eval/image_loss_std 8.22 / eval/model_loss_mean 15.95 / eval/model_loss_std 15.38 / eval/post_ent_mag 34.43 / eval/post_ent_max 34.43 / 
eval/post_ent_mean 23.48 / eval/post_ent_min 11.92 / eval/post_ent_std 4 / eval/prior_ent_mag 51.54 / eval/prior_ent_max 51.54 / eval/prior_ent_mean 27.43 / eval/prior_ent_min 17.03 / eval/prior_ent_std 5.64 / eval/rep_loss_mean 12.71 / eval/rep_loss_std 12.79 / 
eval/reward_avg 0 / eval/reward_loss_mean 5.9e-4 / eval/reward_loss_std 0.01 / eval/reward_max_data 0 / eval/reward_max_pred 0.1 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.9e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.3e-4 / 
eval/reward_rate 0 / replay/size 2.8e4 / replay/inserts 3770 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.8e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3770 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.94 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7778 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.08 / timer/dataset_train_count 1885 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1885 / 
timer/agent.train_total 241.63 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T220258F177140-6cenTAe6utHNd0Y0KXCyBs-7oG4RnRgPY5DBKU7GDw2st-1024.npz
Starting evaluation at step 28000 Counter(28000) 27937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 28500 Counter(28500) 28437
Saved chunk: 20230921T220328F622973-2vTvuE0u6YklGSE12lJqA2-05FxSQPyp1jmwJVbrYPzVx-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220419F653430-7oG4RnRgPY5DBKU7GDw2st-4Ls23YJc05zj3YhscerePp-1024.npz
Starting evaluation at step 29000 Counter(29000) 28937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 29500 Counter(29500) 29437
Saved chunk: 20230921T220524F696313-05FxSQPyp1jmwJVbrYPzVx-6bujOzdPJVjWMrvHuyRlO8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 2.9.
Saved chunk: 20230921T220540F534869-4Ls23YJc05zj3YhscerePp-3nGFyOh6t5wPWStBj5rkai-1024.npz
Starting evaluation at step 30000 Counter(30000) 29937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 30500 Counter(30500) 30437
Saved chunk: 20230921T220643F887521-6bujOzdPJVjWMrvHuyRlO8-3y2fryOljkpqcWsrDb7bMX-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220701F200866-3nGFyOh6t5wPWStBj5rkai-42841ngp8hbf0KicBlcBlK-1024.npz
Starting evaluation at step 31000 Counter(31000) 30937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 62810 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.22 / train/action_max 4.91 / train/action_mean -0.35 / train/action_min -5.17 / train/action_std 1.29 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1e-2 / train/actor_opt_grad_steps 1.4e4 / train/actor_opt_loss -20.75 / train/adv_mag 0.67 / train/adv_max 0.54 / train/adv_mean 4.3e-4 / train/adv_min -0.41 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.9e-9 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.71 / 
train/dyn_loss_std 4.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.01 / train/extr_critic_critic_opt_grad_steps 1.4e4 / train/extr_critic_critic_opt_loss 
1262.51 / train/extr_critic_mag 1.1 / train/extr_critic_max 1.1 / train/extr_critic_mean 4.9e-3 / train/extr_critic_min 1.6e-3 / train/extr_critic_std 0.04 / train/extr_return_normed_mag 1.24 / train/extr_return_normed_max 1.24 / train/extr_return_normed_mean 3.6e-3 / 
train/extr_return_normed_min -1e-4 / train/extr_return_normed_std 0.05 / train/extr_return_rate 1.4e-3 / train/extr_return_raw_mag 1.24 / train/extr_return_raw_max 1.24 / train/extr_return_raw_mean 5.3e-3 / train/extr_return_raw_min 1.6e-3 / train/extr_return_raw_std 0.05
/ train/extr_reward_mag 0.29 / train/extr_reward_max 0.29 / train/extr_reward_mean 5.9e-4 / train/extr_reward_min 0 / train/extr_reward_std 9.4e-3 / train/image_loss_mean 1.61 / train/image_loss_std 1.75 / train/model_loss_mean 3.24 / train/model_loss_std 3.88 / 
train/model_opt_grad_norm 12.02 / train/model_opt_grad_steps 1.4e4 / train/model_opt_loss 1.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5130.89 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.62 / train/policy_entropy_min -2.31 / train/policy_entropy_std 0.48 / train/policy_logprob_mag 16.55 / train/policy_logprob_max 3.63 / train/policy_logprob_mean -5.62 / train/policy_logprob_min -16.55 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.13 / train/policy_randomness_std 0.05 / train/post_ent_mag 32.84 / train/post_ent_max 32.84 / train/post_ent_mean 24.76 / train/post_ent_min 
14.33 / train/post_ent_std 3.15 / train/prior_ent_mag 51.98 / train/prior_ent_max 51.98 / train/prior_ent_mean 27.57 / train/prior_ent_min 17.32 / train/prior_ent_std 4.39 / train/rep_loss_mean 2.71 / train/rep_loss_std 4.41 / train/reward_avg 8.7e-4 / 
train/reward_loss_mean 1.4e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.2 / train/reward_max_pred 0.19 / train/reward_neg_acc 1 / train/reward_neg_loss 2.3e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.73 / train/reward_pred 8.7e-4 / 
train/reward_rate 1.9e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.59 / report/cont_avg 1 / report/cont_loss_mean 4.4e-9 / report/cont_loss_std 8.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.4e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.5 / report/dyn_loss_std 3.9 / report/image_loss_mean 1.42 / report/image_loss_std 1.52 / report/model_loss_mean 2.92 / report/model_loss_std 3.4 / report/post_ent_mag 33.44 / 
report/post_ent_max 33.44 / report/post_ent_mean 25.68 / report/post_ent_min 12.4 / report/post_ent_std 3.39 / report/prior_ent_mag 52.3 / report/prior_ent_max 52.3 / report/prior_ent_mean 28 / report/prior_ent_min 14.57 / report/prior_ent_std 4.47 / report/rep_loss_mean 
2.5 / report/rep_loss_std 3.9 / report/reward_avg 0 / report/reward_loss_mean 1e-6 / report/reward_loss_std 4.4e-7 / report/reward_max_data 0 / report/reward_max_pred 2.9e-6 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-6 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 1.8e-8 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-9 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-9 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 9.86 / eval/dyn_loss_std 10.66 / eval/image_loss_mean 5.52 / eval/image_loss_std 7.07 / eval/model_loss_mean 11.44 / eval/model_loss_std 12.94 / eval/post_ent_mag 34.61 / eval/post_ent_max 34.61 / eval/post_ent_mean 25 / 
eval/post_ent_min 14.49 / eval/post_ent_std 3.47 / eval/prior_ent_mag 52.3 / eval/prior_ent_max 52.3 / eval/prior_ent_mean 28.86 / eval/prior_ent_min 18.35 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 9.86 / eval/rep_loss_std 10.66 / eval/reward_avg 0 / 
eval/reward_loss_mean 2.3e-6 / eval/reward_loss_std 1.7e-5 / eval/reward_max_data 0 / eval/reward_max_pred 7e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 2.6e-7 / eval/reward_rate 0 / 
replay/size 3.1e4 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.2e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3820 / timer/env.step_total 20.08 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 447.05 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 16.05 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1910 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1910 / timer/agent.train_total 244.57 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 31500 Counter(31500) 31437
Saved chunk: 20230921T220802F810549-3y2fryOljkpqcWsrDb7bMX-241GEUtzxNa4U7Ugblo9aJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220821F675506-42841ngp8hbf0KicBlcBlK-56LnR63tgwVuqozfVmVjfE-1024.npz
Starting evaluation at step 32000 Counter(32000) 31937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.1.
Starting evaluation at step 32500 Counter(32500) 32437
Saved chunk: 20230921T220922F207182-241GEUtzxNa4U7Ugblo9aJ-0sGnZS2j2rM646xmkLHSAW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.6.
Saved chunk: 20230921T220942F788216-56LnR63tgwVuqozfVmVjfE-7JGn2wu5TrFhahDV6W26W2-1024.npz
Starting evaluation at step 33000 Counter(33000) 32937
eval_Episode has 500 steps and return 1.2.
train_Episode has 500 steps and return 0.1.
Starting evaluation at step 33500 Counter(33500) 33437
Saved chunk: 20230921T221041F526268-0sGnZS2j2rM646xmkLHSAW-0TXFEbopbUG3tu9f40sh9Y-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221103F538997-7JGn2wu5TrFhahDV6W26W2-5PnQq6AEV8kUmurZ5Stpmr-1024.npz
Starting evaluation at step 34000 Counter(34000) 33937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 34500 Counter(34500) 34437
Saved chunk: 20230921T221200F506433-0TXFEbopbUG3tu9f40sh9Y-5ye8NAYeZSt5MKEuOofbBl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T221319F311951-5ye8NAYeZSt5MKEuOofbBl-0000000000000000000000-352.npz
Saved chunk: 20230921T221224F079945-5PnQq6AEV8kUmurZ5Stpmr-0000000000000000000000-808.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T221224F079945-5PnQq6AEV8kUmurZ5Stpmr-06Lsq5i8uHLmW3NSDfxW4k-1024.npz
Starting evaluation at step 35000 Counter(35000) 34937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.5.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 70362 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0.52 / episode/reward_rate 4e-3 / train/action_mag 5.23 / train/action_max 4.9 / train/action_mean -0.39 / train/action_min -5.15 / train/action_std 1.27 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.6e-3 / train/actor_opt_grad_steps 1.6e4 / train/actor_opt_loss -20.39 / train/adv_mag 0.68 / train/adv_max 0.59 / train/adv_mean 3.9e-4 / train/adv_min -0.35
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-9 / train/cont_loss_std 1.2e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.68 / 
train/dyn_loss_std 4.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 1.6e4 / train/extr_critic_critic_opt_loss 
827.45 / train/extr_critic_mag 1.25 / train/extr_critic_max 1.25 / train/extr_critic_mean 4.6e-3 / train/extr_critic_min 8.9e-4 / train/extr_critic_std 0.05 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.47 / train/extr_return_normed_mean 4.1e-3 / 
train/extr_return_normed_min -3.8e-5 / train/extr_return_normed_std 0.06 / train/extr_return_rate 1.5e-3 / train/extr_return_raw_mag 1.47 / train/extr_return_raw_max 1.47 / train/extr_return_raw_mean 5e-3 / train/extr_return_raw_min 9e-4 / train/extr_return_raw_std 0.06 /
train/extr_reward_mag 0.31 / train/extr_reward_max 0.31 / train/extr_reward_mean 6.2e-4 / train/extr_reward_min 0 / train/extr_reward_std 0.01 / train/image_loss_mean 1.45 / train/image_loss_std 1.63 / train/model_loss_mean 3.05 / train/model_loss_std 3.79 / 
train/model_opt_grad_norm 12.19 / train/model_opt_grad_steps 1.6e4 / train/model_opt_loss 1.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5291.01 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.62 / train/policy_entropy_min -2.49 / train/policy_entropy_std 0.49 / train/policy_logprob_mag 16.54 / train/policy_logprob_max 3.75 / train/policy_logprob_mean -5.62 / train/policy_logprob_min -16.54 / train/policy_logprob_std 1.52 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.11 / train/policy_randomness_std 0.05 / train/post_ent_mag 33.62 / train/post_ent_max 33.62 / train/post_ent_mean 25.72 / train/post_ent_min 
14.87 / train/post_ent_std 3.24 / train/prior_ent_mag 53.13 / train/prior_ent_max 53.13 / train/prior_ent_mean 28.49 / train/prior_ent_min 17.91 / train/prior_ent_std 4.45 / train/rep_loss_mean 2.68 / train/rep_loss_std 4.42 / train/reward_avg 7.9e-4 / 
train/reward_loss_mean 1.3e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.2 / train/reward_max_pred 0.2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-4 / train/reward_pos_acc 0.92 / train/reward_pos_loss 0.73 / train/reward_pred 7.9e-4 / 
train/reward_rate 1.8e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.54 / report/cont_avg 1 / report/cont_loss_mean 3.7e-9 / report/cont_loss_std 3e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
3.7e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.09 / report/dyn_loss_std 4.54 / report/image_loss_mean 1.78 / report/image_loss_std 2.16 / report/model_loss_mean 3.65 / report/model_loss_std 4.38 / report/post_ent_mag 34.41 / report/post_ent_max 
34.41 / report/post_ent_mean 26.64 / report/post_ent_min 14.74 / report/post_ent_std 3.84 / report/prior_ent_mag 53.84 / report/prior_ent_max 53.84 / report/prior_ent_mean 29.72 / report/prior_ent_min 15.67 / report/prior_ent_std 4.62 / report/rep_loss_mean 3.09 / 
report/rep_loss_std 4.54 / report/reward_avg 3.6e-3 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.2 / report/reward_max_data 0.64 / report/reward_max_pred 0.65 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 0.78 / 
report/reward_pos_loss 1.42 / report/reward_pred 3.1e-3 / report/reward_rate 8.8e-3 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-9 / eval/cont_loss_std 9.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-9 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 8.59 / eval/dyn_loss_std 8.78 / eval/image_loss_mean 4.4 / eval/image_loss_std 4.79 / eval/model_loss_mean 9.55 / eval/model_loss_std 9.44 / eval/post_ent_mag 34.64 / eval/post_ent_max 34.64 / eval/post_ent_mean 
25.14 / eval/post_ent_min 14.8 / eval/post_ent_std 3.66 / eval/prior_ent_mag 53.84 / eval/prior_ent_max 53.84 / eval/prior_ent_mean 28.46 / eval/prior_ent_min 19.06 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 8.59 / eval/rep_loss_std 8.78 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.6e-6 / eval/reward_loss_std 8.2e-6 / eval/reward_max_data 0 / eval/reward_max_pred 4.6e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.9e-7 / eval/reward_rate 0 / 
replay/size 3.5e4 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.6e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3776 / timer/env.step_total 19.94 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 440.14 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1888 / timer/agent.train_total 241.56 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 35500 Counter(35500) 35437
Saved chunk: 20230921T221319F311951-5ye8NAYeZSt5MKEuOofbBl-1hFb2jjIoG9SOEOTLe0zzQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221344F659081-06Lsq5i8uHLmW3NSDfxW4k-7EbsrA7vrhyTlhppp45Jp4-1024.npz
Starting evaluation at step 36000 Counter(36000) 35937
eval_Episode has 500 steps and return 0.2.
train_Episode has 500 steps and return 3.6.
Starting evaluation at step 36500 Counter(36500) 36437
Saved chunk: 20230921T221439F038284-1hFb2jjIoG9SOEOTLe0zzQ-4E3lbiR8PCP8WRLuvKP3TA-1024.npz
eval_Episode has 500 steps and return 10.1.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221505F925979-7EbsrA7vrhyTlhppp45Jp4-559HeGFOGxVgPfFPuFQAvE-1024.npz
Starting evaluation at step 37000 Counter(37000) 36937
eval_Episode has 500 steps and return 21.3.
train_Episode has 500 steps and return 10.3.
Starting evaluation at step 37500 Counter(37500) 37437
Saved chunk: 20230921T221558F396017-4E3lbiR8PCP8WRLuvKP3TA-3EjIi0IeZV7Muwwy5XQM6G-1024.npz
eval_Episode has 500 steps and return 18.0.
train_Episode has 500 steps and return 25.5.
Saved chunk: 20230921T221626F726513-559HeGFOGxVgPfFPuFQAvE-0lCUw7PBxEjWw3eKAMZWNn-1024.npz
Starting evaluation at step 38000 Counter(38000) 37937
eval_Episode has 500 steps and return 62.3.
train_Episode has 500 steps and return 40.9.
Starting evaluation at step 38500 Counter(38500) 38437
Saved chunk: 20230921T221717F408401-3EjIi0IeZV7Muwwy5XQM6G-0OdYXoDP7j0BGIGcA1bdAJ-1024.npz
eval_Episode has 500 steps and return 34.4.
train_Episode has 500 steps and return 39.3.
Saved chunk: 20230921T221747F302853-0lCUw7PBxEjWw3eKAMZWNn-5hBzVRnbY5uCEtH3EjCEvX-1024.npz
Starting evaluation at step 39000 Counter(39000) 38937
eval_Episode has 500 steps and return 38.2.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 78002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 38.17 / eval_episode/reward_rate 0.12 / episode/length 500 / episode/score 39.33 / episode/reward_rate 0.12 / train/action_mag 4.17 / train/action_max 3.98 / train/action_mean -0.02 / train/action_min -3.9 / train/action_std 1 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.21 / train/actor_opt_grad_steps 1.8e4 / train/actor_opt_loss -657.74 / train/adv_mag 1.11 / train/adv_max 1.1 / train/adv_mean 0.07 / train/adv_min -0.49 /
train/adv_std 0.11 / train/cont_avg 1 / train/cont_loss_mean 3.1e-9 / train/cont_loss_std 1.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.91 / 
train/dyn_loss_std 4.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.03 / train/extr_critic_critic_opt_grad_steps 1.8e4 / train/extr_critic_critic_opt_loss 
1.5e4 / train/extr_critic_mag 2.6 / train/extr_critic_max 2.6 / train/extr_critic_mean 0.96 / train/extr_critic_min 0.33 / train/extr_critic_std 0.38 / train/extr_return_normed_mag 2.12 / train/extr_return_normed_max 2.12 / train/extr_return_normed_mean 0.31 / 
train/extr_return_normed_min -0.03 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.56 / train/extr_return_raw_mag 3.82 / train/extr_return_raw_max 3.82 / train/extr_return_raw_mean 1.08 / train/extr_return_raw_min 0.43 / train/extr_return_raw_std 0.48 / 
train/extr_reward_mag 0.65 / train/extr_reward_max 0.65 / train/extr_reward_mean 8.7e-3 / train/extr_reward_min 4.1e-8 / train/extr_reward_std 0.05 / train/image_loss_mean 1.6 / train/image_loss_std 1.96 / train/model_loss_mean 3.35 / train/model_loss_std 4.33 / 
train/model_opt_grad_norm 12.4 / train/model_opt_grad_steps 1.8e4 / train/model_opt_loss 1.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5261.78 / train/policy_entropy_mag 5.27 / train/policy_entropy_max 5.27 / 
train/policy_entropy_mean -0.62 / train/policy_entropy_min -3.49 / train/policy_entropy_std 1.87 / train/policy_logprob_mag 12.28 / train/policy_logprob_max 5.37 / train/policy_logprob_mean 0.62 / train/policy_logprob_min -12.28 / train/policy_logprob_std 2.39 / 
train/policy_randomness_mag 0.96 / train/policy_randomness_max 0.96 / train/policy_randomness_mean 0.32 / train/policy_randomness_min 4.3e-3 / train/policy_randomness_std 0.2 / train/post_ent_mag 34.61 / train/post_ent_max 34.61 / train/post_ent_mean 26.45 / 
train/post_ent_min 15.01 / train/post_ent_std 3.43 / train/prior_ent_mag 54.95 / train/prior_ent_max 54.95 / train/prior_ent_mean 29.41 / train/prior_ent_min 18.23 / train/prior_ent_std 4.77 / train/rep_loss_mean 2.91 / train/rep_loss_std 4.76 / train/reward_avg 1.7e-3 / 
train/reward_loss_mean 3.5e-3 / train/reward_loss_std 0.04 / train/reward_max_data 0.3 / train/reward_max_pred 0.27 / train/reward_neg_acc 1 / train/reward_neg_loss 6.3e-4 / train/reward_pos_acc 0.94 / train/reward_pos_loss 0.9 / train/reward_pred 1.7e-3 / 
train/reward_rate 3.2e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.24 / report/cont_avg 1 / report/cont_loss_mean 2.4e-9 / report/cont_loss_std 5.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.4e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.62 / report/dyn_loss_std 4.3 / report/image_loss_mean 1.53 / report/image_loss_std 1.61 / report/model_loss_mean 3.1 / report/model_loss_std 3.8 / report/post_ent_mag 34.76 / 
report/post_ent_max 34.76 / report/post_ent_mean 25.79 / report/post_ent_min 14.47 / report/post_ent_std 3.52 / report/prior_ent_mag 55.75 / report/prior_ent_max 55.75 / report/prior_ent_mean 28.21 / report/prior_ent_min 17 / report/prior_ent_std 4.83 / 
report/rep_loss_mean 2.62 / report/rep_loss_std 4.3 / report/reward_avg 0 / report/reward_loss_mean 2e-5 / report/reward_loss_std 3.1e-4 / report/reward_max_data 0 / report/reward_max_pred 1.6e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-5 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 4.3e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-9 / eval/cont_loss_std 1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
2.5e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.78 / eval/dyn_loss_std 6.64 / eval/image_loss_mean 2.48 / eval/image_loss_std 3.85 / eval/model_loss_mean 5.35 / eval/model_loss_std 7.36 / eval/post_ent_mag 33.57 / eval/post_ent_max 33.57 / 
eval/post_ent_mean 27.71 / eval/post_ent_min 13.67 / eval/post_ent_std 3.4 / eval/prior_ent_mag 55.75 / eval/prior_ent_max 55.75 / eval/prior_ent_mean 30.43 / eval/prior_ent_min 19.72 / eval/prior_ent_std 4.05 / eval/rep_loss_mean 4.78 / eval/rep_loss_std 6.64 / 
eval/reward_avg 0 / eval/reward_loss_mean 5.7e-4 / eval/reward_loss_std 0.01 / eval/reward_max_data 0 / eval/reward_max_pred 0.2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.7e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 2.9e-4 / 
eval/reward_rate 0 / replay/size 3.9e4 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.33 / timer/env.step_count 3820 / timer/env.step_total 20.06 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 451.27 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / 
timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7828 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.01 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1910 / 
timer/agent.train_total 244.83 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 35.3.
Starting evaluation at step 39500 Counter(39500) 39437
Saved chunk: 20230921T221836F304903-0OdYXoDP7j0BGIGcA1bdAJ-2cUb0CfFwSuV3VTXYjnzs5-1024.npz
eval_Episode has 500 steps and return 36.3.
train_Episode has 500 steps and return 51.9.
Saved chunk: 20230921T221907F705884-5hBzVRnbY5uCEtH3EjCEvX-34oLrQU9I3rEOeOIVKRbJp-1024.npz
Starting evaluation at step 40000 Counter(40000) 39937
eval_Episode has 500 steps and return 39.7.
train_Episode has 500 steps and return 37.1.
Starting evaluation at step 40500 Counter(40500) 40437
Saved chunk: 20230921T221955F965805-2cUb0CfFwSuV3VTXYjnzs5-64sIIdNFUq4DQ9DoflAwfr-1024.npz
eval_Episode has 500 steps and return 49.1.
train_Episode has 500 steps and return 45.3.
Saved chunk: 20230921T222029F139021-34oLrQU9I3rEOeOIVKRbJp-4tyvFh0X4wYhgadK7PSOd2-1024.npz
Starting evaluation at step 41000 Counter(41000) 40937
eval_Episode has 500 steps and return 59.7.
train_Episode has 500 steps and return 55.9.
Starting evaluation at step 41500 Counter(41500) 41437
Saved chunk: 20230921T222115F383602-64sIIdNFUq4DQ9DoflAwfr-3BnbGqoHN6X2KLkswHRxn1-1024.npz
eval_Episode has 500 steps and return 63.7.
train_Episode has 500 steps and return 64.5.
Saved chunk: 20230921T222149F995972-4tyvFh0X4wYhgadK7PSOd2-1SLDTSti12LubRd2OcS4TV-1024.npz
Starting evaluation at step 42000 Counter(42000) 41937
eval_Episode has 500 steps and return 81.5.
train_Episode has 500 steps and return 56.8.
Starting evaluation at step 42500 Counter(42500) 42437
Saved chunk: 20230921T222234F343862-3BnbGqoHN6X2KLkswHRxn1-2C0xIwEnCQj5yab4BTqC3j-1024.npz
eval_Episode has 500 steps and return 63.0.
train_Episode has 500 steps and return 46.9.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 85650 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 46.89 / episode/reward_rate 0.13 / eval_episode/length 500 / eval_episode/score 63 / eval_episode/reward_rate 0.19 / train/action_mag 3.16 / train/action_max 3.05 / train/action_mean 0.01 / train/action_min -2.87 / train/action_std 0.91 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2e4 / train/actor_opt_loss -860.91 / train/adv_mag 1.11 / train/adv_max 1.11 / train/adv_mean 0.09 / train/adv_min -0.53 / 
train/adv_std 0.12 / train/cont_avg 1 / train/cont_loss_mean 2.1e-9 / train/cont_loss_std 2.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.24 / 
train/dyn_loss_std 5.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.78 / train/extr_critic_critic_opt_grad_steps 2e4 / train/extr_critic_critic_opt_loss 1.5e4
/ train/extr_critic_mag 10.26 / train/extr_critic_max 10.26 / train/extr_critic_mean 7.87 / train/extr_critic_min 3.45 / train/extr_critic_std 1.18 / train/extr_return_normed_mag 1.8 / train/extr_return_normed_max 1.8 / train/extr_return_normed_mean 0.52 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 13.46 / train/extr_return_raw_max 13.46 / train/extr_return_raw_mean 8.24 / train/extr_return_raw_min 5.26 / train/extr_return_raw_std 1.38 / 
train/extr_reward_mag 1.12 / train/extr_reward_max 1.12 / train/extr_reward_mean 0.02 / train/extr_reward_min -4.4e-9 / train/extr_reward_std 0.12 / train/image_loss_mean 1.87 / train/image_loss_std 2.16 / train/model_loss_mean 3.82 / train/model_loss_std 4.67 / 
train/model_opt_grad_norm 11.43 / train/model_opt_grad_steps 2e4 / train/model_opt_loss 2e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 5314.14 / train/policy_entropy_mag 4.69 / train/policy_entropy_max 4.68 / 
train/policy_entropy_mean -2.77 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.06 / train/policy_logprob_mag 9.49 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.77 / train/policy_logprob_min -9.49 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 6.5e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 35.8 / train/post_ent_max 35.8 / train/post_ent_mean 27.04 / 
train/post_ent_min 15.78 / train/post_ent_std 3.48 / train/prior_ent_mag 57.51 / train/prior_ent_max 57.51 / train/prior_ent_mean 30.33 / train/prior_ent_min 18.88 / train/prior_ent_std 5.11 / train/rep_loss_mean 3.24 / train/rep_loss_std 5.05 / train/reward_avg 9.1e-3 / 
train/reward_loss_mean 0.01 / train/reward_loss_std 0.09 / train/reward_max_data 0.78 / train/reward_max_pred 0.73 / train/reward_neg_acc 1 / train/reward_neg_loss 1.2e-3 / train/reward_pos_acc 0.98 / train/reward_pos_loss 0.82 / train/reward_pred 9e-3 / train/reward_rate
0.01 / train_stats/mean_log_entropy -2.47 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-9 / report/cont_loss_std 2.8e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 5.18 / report/image_loss_mean 2.09 / report/image_loss_std 2.35 / report/model_loss_mean 4.31 / report/model_loss_std 4.96 / report/post_ent_mag 35.66 / report/post_ent_max 35.66 / 
report/post_ent_mean 27.89 / report/post_ent_min 14.74 / report/post_ent_std 3.2 / report/prior_ent_mag 59.28 / report/prior_ent_max 59.28 / report/prior_ent_mean 31.62 / report/prior_ent_min 21.02 / report/prior_ent_std 4.93 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 5.18 / report/reward_avg 0.04 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.19 / report/reward_max_data 1.19 / report/reward_max_pred 1.11 / report/reward_neg_acc 1 / report/reward_neg_loss 5e-4 / report/reward_pos_acc 0.98 / 
report/reward_pos_loss 0.75 / report/reward_pred 0.04 / report/reward_rate 0.05 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-9 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-9 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.7 / eval/dyn_loss_std 9.29 / eval/image_loss_mean 2.93 / eval/image_loss_std 5.47 / eval/model_loss_mean 6.35 / eval/model_loss_std 10.74 / eval/post_ent_mag 36.15 / eval/post_ent_max 36.15 / eval/post_ent_mean 27.9 / 
eval/post_ent_min 15.06 / eval/post_ent_std 3.36 / eval/prior_ent_mag 59.28 / eval/prior_ent_max 59.28 / eval/prior_ent_mean 31.24 / eval/prior_ent_min 18.46 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 5.7 / eval/rep_loss_std 9.29 / eval/reward_avg 0 / 
eval/reward_loss_mean 3.8e-6 / eval/reward_loss_std 8.5e-5 / eval/reward_max_data 0 / eval/reward_max_pred 6.4e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 9.6e-7 / eval/reward_rate 0 / 
replay/size 4.3e4 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3824 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 451.05 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7331 / timer/agent.policy_total 16.13 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1912 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1912 / timer/agent.train_total 245.11 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.49

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 43000 Counter(43000) 42937
eval_Episode has 500 steps and return 75.0.
Saved chunk: 20230921T222310F451378-1SLDTSti12LubRd2OcS4TV-3TRQTPrIlTdYKcfXr3KrGK-1024.npz
train_Episode has 500 steps and return 86.4.
Starting evaluation at step 43500 Counter(43500) 43437
Saved chunk: 20230921T222353F173145-2C0xIwEnCQj5yab4BTqC3j-0YuD0Vz0ncwHegjEodi5Fk-1024.npz
eval_Episode has 500 steps and return 62.5.
train_Episode has 500 steps and return 68.4.
Starting evaluation at step 44000 Counter(44000) 43937
eval_Episode has 500 steps and return 44.1.
Saved chunk: 20230921T222434F997004-3TRQTPrIlTdYKcfXr3KrGK-7KjAMIRj3VzHNsb0HkXsE8-1024.npz
train_Episode has 500 steps and return 79.6.
Starting evaluation at step 44500 Counter(44500) 44437
Saved chunk: 20230921T222512F887203-0YuD0Vz0ncwHegjEodi5Fk-0nLfWj8tcUjLalqD5jdf4Q-1024.npz
eval_Episode has 500 steps and return 41.2.
train_Episode has 500 steps and return 66.9.
Starting evaluation at step 45000 Counter(45000) 44937
eval_Episode has 500 steps and return 63.8.
Saved chunk: 20230921T222555F888682-7KjAMIRj3VzHNsb0HkXsE8-6yBlQZ8Pe42RExxGIrVv1p-1024.npz
train_Episode has 500 steps and return 67.5.
Starting evaluation at step 45500 Counter(45500) 45437
Saved chunk: 20230921T222632F128419-0nLfWj8tcUjLalqD5jdf4Q-0lZwiFeA9O8FZkYR2srAB5-1024.npz
eval_Episode has 500 steps and return 52.5.
train_Episode has 500 steps and return 61.6.
Starting evaluation at step 46000 Counter(46000) 45937
eval_Episode has 500 steps and return 40.5.
Saved chunk: 20230921T222716F488397-6yBlQZ8Pe42RExxGIrVv1p-33z5EclUy293SkqfBrHsGu-1024.npz
train_Episode has 500 steps and return 80.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T222837F035289-33z5EclUy293SkqfBrHsGu-0000000000000000000000-20.npz
Saved chunk: 20230921T222751F052129-0lZwiFeA9O8FZkYR2srAB5-0000000000000000000000-611.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 46500 Counter(46500) 46437
Saved chunk: 20230921T222751F052129-0lZwiFeA9O8FZkYR2srAB5-4XA23boYhxpkP4OQ35w3NO-1024.npz
eval_Episode has 500 steps and return 72.8.
train_Episode has 500 steps and return 62.6.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 93194 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 72.8 / eval_episode/reward_rate 0.19 / episode/length 500 / episode/score 62.58 / episode/reward_rate 0.17 / train/action_mag 3.04 / train/action_max 2.85 / train/action_mean -0.02 / train/action_min -2.78 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 2.2e4 / train/actor_opt_loss -828.64 / train/adv_mag 2.06 / train/adv_max 2.06 / train/adv_mean 0.09 / train/adv_min 
-0.68 / train/adv_std 0.12 / train/cont_avg 1 / train/cont_loss_mean 1.2e-9 / train/cont_loss_std 2.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.41 / train/dyn_loss_std 5.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.43 / train/extr_critic_critic_opt_grad_steps 2.2e4 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 21.28 / train/extr_critic_max 21.28 / train/extr_critic_mean 17.99 / train/extr_critic_min 5.8 / train/extr_critic_std 1.66 / train/extr_return_normed_mag 1.63 / train/extr_return_normed_max 1.61 / 
train/extr_return_normed_mean 0.53 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 24.04 / train/extr_return_raw_max 24.04 / train/extr_return_raw_mean 18.43 / train/extr_return_raw_min 13.56 
/ train/extr_return_raw_std 1.78 / train/extr_reward_mag 1.16 / train/extr_reward_max 1.16 / train/extr_reward_mean 0.03 / train/extr_reward_min 0 / train/extr_reward_std 0.14 / train/image_loss_mean 1.93 / train/image_loss_std 2.03 / train/model_loss_mean 4 / 
train/model_loss_std 4.67 / train/model_opt_grad_norm 11.35 / train/model_opt_grad_steps 2.2e4 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 5.3e-3 / train/model_opt_model_opt_grad_scale 6196.81 / train/policy_entropy_mag 4.16 / 
train/policy_entropy_max 4.11 / train/policy_entropy_mean -2.84 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.97 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.84 / train/policy_logprob_min -8.97 / 
train/policy_logprob_std 1.69 / train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 5.7e-4 / train/policy_randomness_std 0.1 / train/post_ent_mag 36.86 / train/post_ent_max 36.86 / 
train/post_ent_mean 27.6 / train/post_ent_min 16.06 / train/post_ent_std 3.66 / train/prior_ent_mag 59.92 / train/prior_ent_max 59.92 / train/prior_ent_mean 31.1 / train/prior_ent_min 19.16 / train/prior_ent_std 5.32 / train/rep_loss_mean 3.41 / train/rep_loss_std 5.24 / 
train/reward_avg 0.02 / train/reward_loss_mean 0.02 / train/reward_loss_std 0.14 / train/reward_max_data 1.07 / train/reward_max_pred 1.03 / train/reward_neg_acc 1 / train/reward_neg_loss 1.4e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.76 / train/reward_pred 
0.02 / train/reward_rate 0.03 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.76 / report/cont_avg 1 / report/cont_loss_mean 9.3e-10 / report/cont_loss_std 2.4e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 9.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.55 / report/dyn_loss_std 4.72 / report/image_loss_mean 1.16 / report/image_loss_std 1.48 / report/model_loss_mean 2.71 / report/model_loss_std 3.94 / report/post_ent_mag 37.42 
/ report/post_ent_max 37.42 / report/post_ent_mean 28.29 / report/post_ent_min 14.57 / report/post_ent_std 4.53 / report/prior_ent_mag 61.53 / report/prior_ent_max 61.53 / report/prior_ent_mean 30.76 / report/prior_ent_min 18.08 / report/prior_ent_std 5.89 / 
report/rep_loss_mean 2.55 / report/rep_loss_std 4.72 / report/reward_avg 0.01 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.13 / report/reward_max_data 0.81 / report/reward_max_pred 0.82 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-6 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.78 / report/reward_pred 0.01 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-10 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.73 / eval/dyn_loss_std 8.07 / eval/image_loss_mean 3.17 / eval/image_loss_std 4.21 / eval/model_loss_mean 7.21 / eval/model_loss_std 8.6 / eval/post_ent_mag 40.32 / eval/post_ent_max 
40.32 / eval/post_ent_mean 27.75 / eval/post_ent_min 14.56 / eval/post_ent_std 4.02 / eval/prior_ent_mag 61.53 / eval/prior_ent_max 61.53 / eval/prior_ent_mean 31.47 / eval/prior_ent_min 20.3 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 6.73 / eval/rep_loss_std 8.07 / 
eval/reward_avg 3.5e-8 / eval/reward_loss_mean 1.1e-5 / eval/reward_loss_std 3.3e-4 / eval/reward_max_data 3.6e-5 / eval/reward_max_pred 1.8e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 
2e-6 / eval/reward_rate 0 / replay/size 4.7e4 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.7e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3772 / timer/env.step_total 19.73 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.77 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / 
timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7780 / timer/agent.policy_total 17.18 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1886 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1886 / timer/agent.train_total 241.82 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 47000 Counter(47000) 46937
eval_Episode has 500 steps and return 80.9.
train_Episode has 500 steps and return 77.1.
Saved chunk: 20230921T222837F035289-33z5EclUy293SkqfBrHsGu-7pk6T19ZUb0ls5vY0JywMm-1024.npz
Starting evaluation at step 47500 Counter(47500) 47437
Saved chunk: 20230921T222910F194558-4XA23boYhxpkP4OQ35w3NO-1foq4H9V1FPUZwBo02jmur-1024.npz
eval_Episode has 500 steps and return 86.3.
train_Episode has 500 steps and return 86.3.
Starting evaluation at step 48000 Counter(48000) 47937
eval_Episode has 500 steps and return 71.3.
train_Episode has 500 steps and return 79.1.
Saved chunk: 20230921T222958F517944-7pk6T19ZUb0ls5vY0JywMm-0NKNMyuRXb0oN2KkxbQIRV-1024.npz
Starting evaluation at step 48500 Counter(48500) 48437
Saved chunk: 20230921T223030F130943-1foq4H9V1FPUZwBo02jmur-3fowtU0reB88V4I0dtbTHR-1024.npz
eval_Episode has 500 steps and return 84.1.
train_Episode has 500 steps and return 74.7.
Starting evaluation at step 49000 Counter(49000) 48937
eval_Episode has 500 steps and return 91.8.
train_Episode has 500 steps and return 93.2.
Saved chunk: 20230921T223119F342852-0NKNMyuRXb0oN2KkxbQIRV-3CjTl4RYUMw6lVEQfQiAs4-1024.npz
Starting evaluation at step 49500 Counter(49500) 49437
eval_Episode has 500 steps and return 79.2.
Saved chunk: 20230921T223149F248146-3fowtU0reB88V4I0dtbTHR-4L30qIpcGoYy1zZSX2DPgy-1024.npz
train_Episode has 500 steps and return 68.5.
Starting evaluation at step 50000 Counter(50000) 49937
eval_Episode has 500 steps and return 92.9.
train_Episode has 500 steps and return 81.5.
Saved chunk: 20230921T223239F896575-3CjTl4RYUMw6lVEQfQiAs4-4iorNpvmca9JRRhAWnQOoa-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 100846 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 92.92 / eval_episode/reward_rate 0.25 / episode/length 500 / episode/score 81.54 / episode/reward_rate 0.22 / train/action_mag 3.15 / train/action_max 3.06 / train/action_mean -0.03 / train/action_min -2.55 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 2.4e4 / train/actor_opt_loss -684.94 / train/adv_mag 2.49 / train/adv_max 2.49 / train/adv_mean 0.07 / train/adv_min 
-0.63 / train/adv_std 0.11 / train/cont_avg 1 / train/cont_loss_mean 8.9e-10 / train/cont_loss_std 7.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.47 / train/dyn_loss_std 5.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.32 / train/extr_critic_critic_opt_grad_steps 2.4e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 32.78 / train/extr_critic_max 32.78 / train/extr_critic_mean 28.83 / train/extr_critic_min 13.34 / train/extr_critic_std 2.04 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.46 / 
train/extr_return_normed_mean 0.53 / train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 35.27 / train/extr_return_raw_max 35.27 / train/extr_return_raw_mean 29.29 / train/extr_return_raw_min 23.81 
/ train/extr_return_raw_std 2.14 / train/extr_reward_mag 1.21 / train/extr_reward_max 1.21 / train/extr_reward_mean 0.04 / train/extr_reward_min 0 / train/extr_reward_std 0.17 / train/image_loss_mean 1.84 / train/image_loss_std 1.85 / train/model_loss_mean 3.96 / 
train/model_loss_std 4.64 / train/model_opt_grad_norm 10.53 / train/model_opt_grad_steps 2.4e4 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6640.62 / train/policy_entropy_mag 3.67 / 
train/policy_entropy_max 3.1 / train/policy_entropy_mean -2.96 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.76 / train/policy_logprob_mag 8.48 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.96 / train/policy_logprob_min -8.48 / 
train/policy_logprob_std 1.61 / train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.5e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 37.79 / train/post_ent_max 37.79 / 
train/post_ent_mean 28.02 / train/post_ent_min 16.41 / train/post_ent_std 3.73 / train/prior_ent_mag 61.94 / train/prior_ent_max 61.94 / train/prior_ent_mean 31.57 / train/prior_ent_min 19.61 / train/prior_ent_std 5.51 / train/rep_loss_mean 3.47 / train/rep_loss_std 5.43 
/ train/reward_avg 0.03 / train/reward_loss_mean 0.03 / train/reward_loss_std 0.16 / train/reward_max_data 1.13 / train/reward_max_pred 1.09 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.71 / 
train/reward_pred 0.03 / train/reward_rate 0.04 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.9 / report/cont_avg 1 / report/cont_loss_mean 6.1e-10 / report/cont_loss_std 9.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 6.1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.27 / report/dyn_loss_std 5.19 / report/image_loss_mean 1.58 / report/image_loss_std 1.48 / report/model_loss_mean 3.58 / report/model_loss_std 4.15 / 
report/post_ent_mag 38.68 / report/post_ent_max 38.68 / report/post_ent_mean 28.73 / report/post_ent_min 13.11 / report/post_ent_std 4.74 / report/prior_ent_mag 62.43 / report/prior_ent_max 62.43 / report/prior_ent_mean 32.22 / report/prior_ent_min 17.48 / 
report/prior_ent_std 6.23 / report/rep_loss_mean 3.27 / report/rep_loss_std 5.19 / report/reward_avg 0.05 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.18 / report/reward_max_data 1.36 / report/reward_max_pred 1.11 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.2e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.68 / report/reward_pred 0.04 / report/reward_rate 0.06 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-10 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.45 / eval/dyn_loss_std 8.4 / eval/image_loss_mean 2.83 / eval/image_loss_std 3.88 / eval/model_loss_mean 6.71 / eval/model_loss_std 8.5 / eval/post_ent_mag 38.66 
/ eval/post_ent_max 38.66 / eval/post_ent_mean 28.24 / eval/post_ent_min 16.96 / eval/post_ent_std 4.25 / eval/prior_ent_mag 62.43 / eval/prior_ent_max 62.43 / eval/prior_ent_mean 32.54 / eval/prior_ent_min 21.53 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 6.45 / 
eval/rep_loss_std 8.4 / eval/reward_avg 5.6e-4 / eval/reward_loss_mean 0.01 / eval/reward_loss_std 0.2 / eval/reward_max_data 0.27 / eval/reward_max_pred 0.44 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 3.17 / 
eval/reward_pred 1.5e-3 / eval/reward_rate 2e-3 / replay/size 5e4 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.1e4 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3826 / timer/env.step_total 19.94 / 
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.29 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.2e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 16.17 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1913 / 
timer/agent.train_total 245.15 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 50500 Counter(50500) 50437
eval_Episode has 500 steps and return 97.6.
Saved chunk: 20230921T223308F183305-4L30qIpcGoYy1zZSX2DPgy-2qs0msHU1Q4fHcST1RKfLj-1024.npz
train_Episode has 500 steps and return 81.8.
Starting evaluation at step 51000 Counter(51000) 50937
eval_Episode has 500 steps and return 88.7.
train_Episode has 500 steps and return 84.3.
Saved chunk: 20230921T223400F229559-4iorNpvmca9JRRhAWnQOoa-4dAZ5cgHO66VuF4V2jF8rB-1024.npz
Starting evaluation at step 51500 Counter(51500) 51437
eval_Episode has 500 steps and return 98.7.
train_Episode has 500 steps and return 90.4.
Starting evaluation at step 52000 Counter(52000) 51937
Saved chunk: 20230921T223427F581930-2qs0msHU1Q4fHcST1RKfLj-12ckHtNsNsrhSRUTeyXDv3-1024.npz
eval_Episode has 500 steps and return 98.8.
train_Episode has 500 steps and return 111.7.
Saved chunk: 20230921T223521F687676-4dAZ5cgHO66VuF4V2jF8rB-2tRxzGXnlKS0FhaD7ipE3d-1024.npz
Starting evaluation at step 52500 Counter(52500) 52437
eval_Episode has 500 steps and return 102.1.
train_Episode has 500 steps and return 80.2.
Starting evaluation at step 53000 Counter(53000) 52937
Saved chunk: 20230921T223622F970288-12ckHtNsNsrhSRUTeyXDv3-1quKFYcDEWf0C4G0JnYqHq-1024.npz
eval_Episode has 500 steps and return 112.7.
train_Episode has 500 steps and return 107.4.
Saved chunk: 20230921T223642F411944-2tRxzGXnlKS0FhaD7ipE3d-1nAdREOzUCZ6Xce0fpUcTH-1024.npz
Starting evaluation at step 53500 Counter(53500) 53437
eval_Episode has 500 steps and return 89.7.
train_Episode has 500 steps and return 88.3.
Starting evaluation at step 54000 Counter(54000) 53937
Saved chunk: 20230921T223741F923028-1quKFYcDEWf0C4G0JnYqHq-4mjVWx3Ej8SxrKJt2XjkHH-1024.npz
eval_Episode has 500 steps and return 105.5.
train_Episode has 500 steps and return 0.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 108390 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 105.52 / eval_episode/reward_rate 0.27 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 2.87 / train/action_max 2.76 / train/action_mean -0.03 / train/action_min -2.37 / train/action_std 0.89 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 2.6e4 / train/actor_opt_loss -563.81 / train/adv_mag 2.4 / train/adv_max 2.4 / train/adv_mean 0.06 / train/adv_min -0.58 / 
train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 4.8e-10 / train/cont_loss_std 1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.58 / 
train/dyn_loss_std 5.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.23 / train/extr_critic_critic_opt_grad_steps 2.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 44.18 / train/extr_critic_max 44.18 / train/extr_critic_mean 39.76 / train/extr_critic_min 22.05 / train/extr_critic_std 2.34 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.44 / train/extr_return_normed_mean 0.54 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 46.74 / train/extr_return_raw_max 46.74 / train/extr_return_raw_mean 40.18 / train/extr_return_raw_min 33.84 / train/extr_return_raw_std 2.46 / 
train/extr_reward_mag 1.31 / train/extr_reward_max 1.31 / train/extr_reward_mean 0.05 / train/extr_reward_min 0 / train/extr_reward_std 0.2 / train/image_loss_mean 1.82 / train/image_loss_std 1.75 / train/model_loss_mean 4 / train/model_loss_std 4.67 / 
train/model_opt_grad_norm 10.54 / train/model_opt_grad_steps 2.6e4 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7340.43 / train/policy_entropy_mag 3.59 / train/policy_entropy_max 2.59 / 
train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.44 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 3 / train/policy_logprob_min -8.44 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.67 / train/policy_randomness_max 0.67 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 4.6e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 38.68 / train/post_ent_max 38.68 / train/post_ent_mean 28.46 / 
train/post_ent_min 16.56 / train/post_ent_std 3.76 / train/prior_ent_mag 63.72 / train/prior_ent_max 63.72 / train/prior_ent_mean 32.08 / train/prior_ent_min 19.81 / train/prior_ent_std 5.63 / train/rep_loss_mean 3.58 / train/rep_loss_std 5.6 / train/reward_avg 0.04 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 1.2 / train/reward_max_pred 1.16 / train/reward_neg_acc 1 / train/reward_neg_loss 1.9e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.71 / train/reward_pred 0.04 / train/reward_rate 
0.05 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3 / report/cont_avg 1 / report/cont_loss_mean 4.4e-10 / report/cont_loss_std 6.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.35 / report/dyn_loss_std 5.37 / report/image_loss_mean 1.59 / report/image_loss_std 1.52 / report/model_loss_mean 3.64 / report/model_loss_std 4.27 / report/post_ent_mag 39.86 / report/post_ent_max 39.86 / 
report/post_ent_mean 28.67 / report/post_ent_min 18.96 / report/post_ent_std 3.52 / report/prior_ent_mag 64.52 / report/prior_ent_max 64.52 / report/prior_ent_mean 32.17 / report/prior_ent_min 21.48 / report/prior_ent_std 5.47 / report/rep_loss_mean 3.35 / 
report/rep_loss_std 5.37 / report/reward_avg 0.04 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.19 / report/reward_max_data 1.13 / report/reward_max_pred 1.22 / report/reward_neg_acc 1 / report/reward_neg_loss 6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.04 / report/reward_rate 0.06 / eval/cont_avg 1 / eval/cont_loss_mean 3e-10 / eval/cont_loss_std 8.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-10 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 7.19 / eval/dyn_loss_std 13.01 / eval/image_loss_mean 3.2 / eval/image_loss_std 6.99 / eval/model_loss_mean 7.51 / eval/model_loss_std 14.62 / eval/post_ent_mag 39.32 / eval/post_ent_max 39.32 / eval/post_ent_mean 30.55 / 
eval/post_ent_min 17.96 / eval/post_ent_std 3.23 / eval/prior_ent_mag 64.52 / eval/prior_ent_max 64.52 / eval/prior_ent_mean 33.96 / eval/prior_ent_min 25.69 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 7.19 / eval/rep_loss_std 13.01 / eval/reward_avg 0 / 
eval/reward_loss_mean 3.1e-6 / eval/reward_loss_std 6.7e-5 / eval/reward_max_data 0 / eval/reward_max_pred 4e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.1e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 6.6e-7 / eval/reward_rate 0 / 
replay/size 5.4e4 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3772 / timer/env.step_total 19.71 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.76 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7780 / timer/agent.policy_total 17.22 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.09 / 
timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1886 / timer/agent.train_total 241.78 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T223802F971563-1nAdREOzUCZ6Xce0fpUcTH-4Ugbi4VthBaKBuF62Bq9uF-1024.npz
Starting evaluation at step 54500 Counter(54500) 54437
eval_Episode has 500 steps and return 105.7.
train_Episode has 500 steps and return 105.8.
Starting evaluation at step 55000 Counter(55000) 54937
Saved chunk: 20230921T223900F928012-4mjVWx3Ej8SxrKJt2XjkHH-1U4rXMiSUbyLUUiRcdIybp-1024.npz
eval_Episode has 500 steps and return 125.9.
train_Episode has 500 steps and return 102.5.
Saved chunk: 20230921T223924F098840-4Ugbi4VthBaKBuF62Bq9uF-5HxfZks4rKCA2teQZRWyJ4-1024.npz
Starting evaluation at step 55500 Counter(55500) 55437
eval_Episode has 500 steps and return 113.5.
train_Episode has 500 steps and return 100.4.
Starting evaluation at step 56000 Counter(56000) 55937
Saved chunk: 20230921T224020F749340-1U4rXMiSUbyLUUiRcdIybp-6CNJxgchHTza9n8ABCcBTd-1024.npz
eval_Episode has 500 steps and return 118.5.
train_Episode has 500 steps and return 122.4.
Saved chunk: 20230921T224045F030384-5HxfZks4rKCA2teQZRWyJ4-4Axw7eRW32j3O51KNSUE4u-1024.npz
Starting evaluation at step 56500 Counter(56500) 56437
eval_Episode has 500 steps and return 106.5.
train_Episode has 500 steps and return 99.1.
Starting evaluation at step 57000 Counter(57000) 56937
Saved chunk: 20230921T224139F851202-6CNJxgchHTza9n8ABCcBTd-3xhyUdH9Drba3NKa5V6i8j-1024.npz
eval_Episode has 500 steps and return 104.5.
train_Episode has 500 steps and return 104.9.
Saved chunk: 20230921T224205F593676-4Axw7eRW32j3O51KNSUE4u-4DgpenW2s8HXQzLkq8hjwh-1024.npz
Starting evaluation at step 57500 Counter(57500) 57437
eval_Episode has 500 steps and return 135.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T224326F047948-4DgpenW2s8HXQzLkq8hjwh-0000000000000000000000-256.npz
Saved chunk: 20230921T224258F743127-3xhyUdH9Drba3NKa5V6i8j-0000000000000000000000-870.npz
train_Episode has 500 steps and return 0.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 58000 Counter(58000) 57937
Saved chunk: 20230921T224258F743127-3xhyUdH9Drba3NKa5V6i8j-1g1vTXmsHpqC6u8XRy85kH-1024.npz
eval_Episode has 500 steps and return 82.2.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 116002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 82.21 / eval_episode/reward_rate 0.2 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 2.54 / train/action_max 2.31 / train/action_mean -0.05 / train/action_min -2.4 / train/action_std 0.88 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 2.8e4 / train/actor_opt_loss -499.02 / train/adv_mag 2.76 / train/adv_max 2.75 / train/adv_mean 0.05 / train/adv_min -0.6 / 
train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 4.1e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.65 / 
train/dyn_loss_std 5.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.21 / train/extr_critic_critic_opt_grad_steps 2.8e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 55.27 / train/extr_critic_max 55.27 / train/extr_critic_mean 50.4 / train/extr_critic_min 27.92 / train/extr_critic_std 2.79 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.37 / train/extr_return_normed_mean 0.54 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 58.06 / train/extr_return_raw_max 58.06 / train/extr_return_raw_mean 50.86 / train/extr_return_raw_min 43.73 / train/extr_return_raw_std 2.91 / 
train/extr_reward_mag 1.43 / train/extr_reward_max 1.43 / train/extr_reward_mean 0.07 / train/extr_reward_min 0 / train/extr_reward_std 0.22 / train/image_loss_mean 1.78 / train/image_loss_std 1.67 / train/model_loss_mean 4.02 / train/model_loss_std 4.71 / 
train/model_opt_grad_norm 10.56 / train/model_opt_grad_steps 2.7e4 / train/model_opt_loss 2.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5497.38 / train/policy_entropy_mag 3.57 / train/policy_entropy_max 2.28 / 
train/policy_entropy_mean -3.08 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.63 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.08 / train/policy_logprob_min -8.13 / train/policy_logprob_std 1.55 / 
train/policy_randomness_mag 0.63 / train/policy_randomness_max 0.63 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 4.6e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 39.48 / train/post_ent_max 39.48 / train/post_ent_mean 29.01 / 
train/post_ent_min 17 / train/post_ent_std 3.77 / train/prior_ent_mag 65.37 / train/prior_ent_max 65.37 / train/prior_ent_mean 32.72 / train/prior_ent_min 20.18 / train/prior_ent_std 5.73 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.78 / train/reward_avg 0.05 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.2 / train/reward_max_data 1.27 / train/reward_max_pred 1.23 / train/reward_neg_acc 1 / train/reward_neg_loss 2.2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.7 / train/reward_pred 0.05 / train/reward_rate 
0.06 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.74 / report/cont_avg 1 / report/cont_loss_mean 3.4e-10 / report/cont_loss_std 5.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.34 / report/dyn_loss_std 5.44 / report/image_loss_mean 1.54 / report/image_loss_std 1.25 / report/model_loss_mean 3.59 / report/model_loss_std 4.13 / report/post_ent_mag 38.11 / report/post_ent_max 38.11 / 
report/post_ent_mean 29.01 / report/post_ent_min 15.14 / report/post_ent_std 4.93 / report/prior_ent_mag 66.27 / report/prior_ent_max 66.27 / report/prior_ent_mean 32.63 / report/prior_ent_min 17.68 / report/prior_ent_std 6.54 / report/rep_loss_mean 3.34 / 
report/rep_loss_std 5.44 / report/reward_avg 0.05 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.18 / report/reward_max_data 1.21 / report/reward_max_pred 1.19 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.62 / report/reward_pred 0.05 / report/reward_rate 0.08 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-10 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.04 / eval/dyn_loss_std 9.54 / eval/image_loss_mean 3.3 / eval/image_loss_std 4.69 / eval/model_loss_mean 7.56 / eval/model_loss_std 10.02 / eval/post_ent_mag 41.09 / eval/post_ent_max 41.09 / eval/post_ent_mean 
31.27 / eval/post_ent_min 18.74 / eval/post_ent_std 3.4 / eval/prior_ent_mag 66.27 / eval/prior_ent_max 66.27 / eval/prior_ent_mean 35.53 / eval/prior_ent_min 25.37 / eval/prior_ent_std 5.16 / eval/rep_loss_mean 7.04 / eval/rep_loss_std 9.54 / eval/reward_avg 9.9e-4 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.48 / eval/reward_max_data 0.26 / eval/reward_max_pred 0.42 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.3e-3 / eval/reward_pos_acc 0 / eval/reward_pos_loss 6.67 / eval/reward_pred 9e-4 / eval/reward_rate 4.9e-3 / 
replay/size 5.8e4 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.9e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.47 / timer/env.step_count 3806 / timer/env.step_total 19.92 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.08 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7814 / timer/agent.policy_total 17.32 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1903 / timer/agent.train_total 243.89 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 104.5.
Saved chunk: 20230921T224326F047948-4DgpenW2s8HXQzLkq8hjwh-5kNRrDegXTPPmy3Amtpp2n-1024.npz
Starting evaluation at step 58500 Counter(58500) 58437
eval_Episode has 500 steps and return 148.5.
train_Episode has 500 steps and return 107.5.
Starting evaluation at step 59000 Counter(59000) 58937
Saved chunk: 20230921T224417F929382-1g1vTXmsHpqC6u8XRy85kH-2LhYq6JCkYXanpqqHCwZ54-1024.npz
eval_Episode has 500 steps and return 140.6.
train_Episode has 500 steps and return 123.4.
Saved chunk: 20230921T224447F588140-5kNRrDegXTPPmy3Amtpp2n-5ma2JPPEzqAdr9BTT97ty9-1024.npz
Starting evaluation at step 59500 Counter(59500) 59437
eval_Episode has 500 steps and return 151.5.
train_Episode has 500 steps and return 148.4.
Starting evaluation at step 60000 Counter(60000) 59937
Saved chunk: 20230921T224538F045048-2LhYq6JCkYXanpqqHCwZ54-2nC8pF6fIq3lX2ppEyqq8w-1024.npz
eval_Episode has 500 steps and return 112.3.
train_Episode has 500 steps and return 109.7.
Saved chunk: 20230921T224608F578734-5ma2JPPEzqAdr9BTT97ty9-2T3KYqJ8HJQCTFn9mrOSkB-1024.npz
Starting evaluation at step 60500 Counter(60500) 60437
eval_Episode has 500 steps and return 146.7.
train_Episode has 500 steps and return 128.9.
Starting evaluation at step 61000 Counter(61000) 60937
Saved chunk: 20230921T224657F235630-2nC8pF6fIq3lX2ppEyqq8w-2A2jw8iXJIugno2f2fIj9H-1024.npz
eval_Episode has 500 steps and return 116.4.
train_Episode has 500 steps and return 119.5.
Saved chunk: 20230921T224729F219733-2T3KYqJ8HJQCTFn9mrOSkB-6uz5AgniPXuyZoLSw7w9dV-1024.npz
Starting evaluation at step 61500 Counter(61500) 61437
eval_Episode has 500 steps and return 121.0.
train_Episode has 500 steps and return 119.1.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 123642 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 119.12 / episode/reward_rate 0.28 / eval_episode/length 500 / eval_episode/score 121.01 / eval_episode/reward_rate 0.3 / train/action_mag 2.94 / train/action_max 2.55 / train/action_mean -6e-3 / train/action_min -2.86 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 2.9e4 / train/actor_opt_loss -290.9 / train/adv_mag 2.14 / train/adv_max 2.14 / train/adv_mean 0.03 / train/adv_min 
-0.52 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 3.7e-10 / train/cont_loss_std 1.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.7 / train/dyn_loss_std 5.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.17 / train/extr_critic_critic_opt_grad_steps 2.9e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 67.76 / train/extr_critic_max 67.76 / train/extr_critic_mean 61.62 / train/extr_critic_min 33.1 / train/extr_critic_std 4.4 / train/extr_return_normed_mag 1.28 / train/extr_return_normed_max 1.23 / 
train/extr_return_normed_mean 0.65 / train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 70.29 / train/extr_return_raw_max 70.29 / train/extr_return_raw_mean 62.04 / train/extr_return_raw_min 47.59 
/ train/extr_return_raw_std 4.56 / train/extr_reward_mag 1.52 / train/extr_reward_max 1.52 / train/extr_reward_mean 0.08 / train/extr_reward_min 0 / train/extr_reward_std 0.25 / train/image_loss_mean 1.72 / train/image_loss_std 1.58 / train/model_loss_mean 4 / 
train/model_loss_std 4.72 / train/model_opt_grad_norm 10.08 / train/model_opt_grad_steps 2.9e4 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6649.21 / train/policy_entropy_mag 3.75 / 
train/policy_entropy_max 2.61 / train/policy_entropy_mean -2.83 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.99 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.83 / train/policy_logprob_min -8.99 / 
train/policy_logprob_std 1.73 / train/policy_randomness_mag 0.67 / train/policy_randomness_max 0.67 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 6.1e-4 / train/policy_randomness_std 0.1 / train/post_ent_mag 40.34 / train/post_ent_max 40.34 / 
train/post_ent_mean 29.37 / train/post_ent_min 17.3 / train/post_ent_std 3.84 / train/prior_ent_mag 66.92 / train/prior_ent_max 66.92 / train/prior_ent_mean 33.12 / train/prior_ent_min 20.81 / train/prior_ent_std 5.92 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.92 / 
train/reward_avg 0.06 / train/reward_loss_mean 0.06 / train/reward_loss_std 0.21 / train/reward_max_data 1.34 / train/reward_max_pred 1.31 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.69 / train/reward_pred 
0.06 / train/reward_rate 0.08 / train_stats/mean_log_entropy -3.07 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-10 / report/cont_loss_std 7.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.9e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.92 / report/dyn_loss_std 5.36 / report/image_loss_mean 1.28 / report/image_loss_std 1.34 / report/model_loss_mean 3.08 / report/model_loss_std 4.22 / report/post_ent_mag 41.76 
/ report/post_ent_max 41.76 / report/post_ent_mean 28.54 / report/post_ent_min 16.93 / report/post_ent_std 3.51 / report/prior_ent_mag 68.01 / report/prior_ent_max 68.01 / report/prior_ent_mean 31.67 / report/prior_ent_min 21.07 / report/prior_ent_std 6.05 / 
report/rep_loss_mean 2.92 / report/rep_loss_std 5.36 / report/reward_avg 0.05 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.22 / report/reward_max_data 1.34 / report/reward_max_pred 1.31 / report/reward_neg_acc 1 / report/reward_neg_loss 4.9e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.66 / report/reward_pred 0.05 / report/reward_rate 0.06 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.86 / eval/dyn_loss_std 4.63 / eval/image_loss_mean 0.9 / eval/image_loss_std 1.42 / eval/model_loss_mean 2.62 / eval/model_loss_std 3.88 / eval/post_ent_mag 41.78 / eval/post_ent_max 
41.78 / eval/post_ent_mean 32 / eval/post_ent_min 22.61 / eval/post_ent_std 2.83 / eval/prior_ent_mag 68.01 / eval/prior_ent_max 68.01 / eval/prior_ent_mean 35.17 / eval/prior_ent_min 27.28 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 2.86 / eval/rep_loss_std 4.63 / 
eval/reward_avg 5.9e-3 / eval/reward_loss_mean 7.4e-3 / eval/reward_loss_std 0.08 / eval/reward_max_data 0.71 / eval/reward_max_pred 0.68 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.5e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.76 / eval/reward_pred 5.5e-3 / 
eval/reward_rate 9.8e-3 / replay/size 6.2e4 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.2e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3820 / timer/env.step_total 19.9 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1e-3 / 
timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 16.17 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.01 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1910 / 
timer/agent.train_total 245.16 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 62000 Counter(62000) 61937
Saved chunk: 20230921T224816F095051-2A2jw8iXJIugno2f2fIj9H-2TrS7LtOyXYwYLG5M5gxQO-1024.npz
eval_Episode has 500 steps and return 153.5.
train_Episode has 500 steps and return 117.4.
Saved chunk: 20230921T224849F642833-6uz5AgniPXuyZoLSw7w9dV-4IO9ylemE6MxL5HJg2RMh3-1024.npz
Starting evaluation at step 62500 Counter(62500) 62437
eval_Episode has 500 steps and return 150.9.
train_Episode has 500 steps and return 138.2.
Starting evaluation at step 63000 Counter(63000) 62937
Saved chunk: 20230921T224935F724504-2TrS7LtOyXYwYLG5M5gxQO-6sY1bL2UUaDxwrN3gYMaXG-1024.npz
eval_Episode has 500 steps and return 141.5.
train_Episode has 500 steps and return 130.4.
Saved chunk: 20230921T225011F091892-4IO9ylemE6MxL5HJg2RMh3-0udyd9mULJXFWMDffUluzw-1024.npz
Starting evaluation at step 63500 Counter(63500) 63437
eval_Episode has 500 steps and return 159.0.
train_Episode has 500 steps and return 136.4.
Starting evaluation at step 64000 Counter(64000) 63937
Saved chunk: 20230921T225055F102808-6sY1bL2UUaDxwrN3gYMaXG-1LBN6e3XHZJQmNfB5KpiM4-1024.npz
eval_Episode has 500 steps and return 147.6.
train_Episode has 500 steps and return 153.5.
Starting evaluation at step 64500 Counter(64500) 64437
eval_Episode has 500 steps and return 142.6.
Saved chunk: 20230921T225131F922191-0udyd9mULJXFWMDffUluzw-2KYg08dE1mMhJR5tsYmkNy-1024.npz
train_Episode has 500 steps and return 128.3.
Starting evaluation at step 65000 Counter(65000) 64937
Saved chunk: 20230921T225214F192856-1LBN6e3XHZJQmNfB5KpiM4-6jS9S05JcHeFFTf5kyfgFN-1024.npz
eval_Episode has 500 steps and return 139.5.
train_Episode has 500 steps and return 124.8.
Starting evaluation at step 65500 Counter(65500) 65437
eval_Episode has 500 steps and return 175.9.
Saved chunk: 20230921T225256F610644-2KYg08dE1mMhJR5tsYmkNy-33o1of7DaeumdYAGEZ494v-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 131174 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 175.86 / eval_episode/reward_rate 0.37 / episode/length 500 / episode/score 124.8 / episode/reward_rate 0.27 / train/action_mag 3.01 / train/action_max 2.81 / train/action_mean 0.02 / train/action_min -2.87 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 3.1e4 / train/actor_opt_loss -196.01 / train/adv_mag 1.1 / train/adv_max 1.09 / train/adv_mean 0.02 / train/adv_min 
-0.39 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 2.9e-10 / train/cont_loss_std 8.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.72 / train/dyn_loss_std 5.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.17 / train/extr_critic_critic_opt_grad_steps 3.1e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 79.14 / train/extr_critic_max 79.14 / train/extr_critic_mean 71.98 / train/extr_critic_min 45.21 / train/extr_critic_std 6.04 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.15 / 
train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 81.42 / train/extr_return_raw_max 81.42 / train/extr_return_raw_mean 72.41 / train/extr_return_raw_min 53.36 /
train/extr_return_raw_std 6.21 / train/extr_reward_mag 1.55 / train/extr_reward_max 1.55 / train/extr_reward_mean 0.08 / train/extr_reward_min 0 / train/extr_reward_std 0.26 / train/image_loss_mean 1.67 / train/image_loss_std 1.51 / train/model_loss_mean 3.97 / 
train/model_loss_std 4.68 / train/model_opt_grad_norm 10.15 / train/model_opt_grad_steps 3.1e4 / train/model_opt_loss 2.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5744.68 / train/policy_entropy_mag 3.97 / 
train/policy_entropy_max 3.2 / train/policy_entropy_mean -2.67 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.09 / train/policy_logprob_mag 9.36 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.67 / train/policy_logprob_min -9.36 / 
train/policy_logprob_std 1.82 / train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 9.9e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 41.16 / train/post_ent_max 41.16 / 
train/post_ent_mean 29.97 / train/post_ent_min 17.79 / train/post_ent_std 3.84 / train/prior_ent_mag 68.25 / train/prior_ent_max 68.25 / train/prior_ent_mean 33.74 / train/prior_ent_min 21.27 / train/prior_ent_std 5.94 / train/rep_loss_mean 3.72 / train/rep_loss_std 5.93 
/ train/reward_avg 0.07 / train/reward_loss_mean 0.06 / train/reward_loss_std 0.22 / train/reward_max_data 1.42 / train/reward_max_pred 1.38 / train/reward_neg_acc 1 / train/reward_neg_loss 2.6e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.69 / 
train/reward_pred 0.07 / train/reward_rate 0.09 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.92 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 4.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.79 / report/dyn_loss_std 6.04 / report/image_loss_mean 1.66 / report/image_loss_std 1.62 / report/model_loss_mean 3.99 / report/model_loss_std 4.83 / 
report/post_ent_mag 41.96 / report/post_ent_max 41.96 / report/post_ent_mean 30.39 / report/post_ent_min 19.2 / report/post_ent_std 3.68 / report/prior_ent_mag 68.92 / report/prior_ent_max 68.92 / report/prior_ent_mean 34.15 / report/prior_ent_min 23.14 / 
report/prior_ent_std 5.8 / report/rep_loss_mean 3.79 / report/rep_loss_std 6.04 / report/reward_avg 0.07 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.2 / report/reward_max_data 1.42 / report/reward_max_pred 1.43 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.65 / report/reward_pred 0.07 / report/reward_rate 0.08 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.2 / eval/dyn_loss_std 8.62 / eval/image_loss_mean 2.69 / eval/image_loss_std 3.83 / eval/model_loss_mean 6.44 / eval/model_loss_std 8.62 / eval/post_ent_mag 42.9 
/ eval/post_ent_max 42.9 / eval/post_ent_mean 31.21 / eval/post_ent_min 17.49 / eval/post_ent_std 4.12 / eval/prior_ent_mag 68.92 / eval/prior_ent_max 68.92 / eval/prior_ent_mean 35.09 / eval/prior_ent_min 22.38 / eval/prior_ent_std 5.61 / eval/rep_loss_mean 6.2 / 
eval/rep_loss_std 8.62 / eval/reward_avg 0.01 / eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.29 / eval/reward_max_data 0.93 / eval/reward_max_pred 0.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.9e-6 / eval/reward_pos_acc 0.91 / eval/reward_pos_loss 1.25 / 
eval/reward_pred 0.01 / eval/reward_rate 0.02 / replay/size 6.6e4 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.6e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3766 / timer/env.step_total 19.63 /
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.53 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.9e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1883 / 
timer/agent.train_total 242.17 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.78 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 134.8.
Starting evaluation at step 66000 Counter(66000) 65937
Saved chunk: 20230921T225333F690436-6jS9S05JcHeFFTf5kyfgFN-4aVWmsxqnA3jnxEafCWHgg-1024.npz
eval_Episode has 500 steps and return 148.2.
train_Episode has 500 steps and return 156.6.
Starting evaluation at step 66500 Counter(66500) 66437
eval_Episode has 500 steps and return 158.5.
Saved chunk: 20230921T225416F961480-33o1of7DaeumdYAGEZ494v-0hKbu0qE3aGfQTk5TAq5WT-1024.npz
train_Episode has 500 steps and return 166.0.
Starting evaluation at step 67000 Counter(67000) 66937
Saved chunk: 20230921T225453F455088-4aVWmsxqnA3jnxEafCWHgg-3cswMTqvaNmIBPJF1SjRBO-1024.npz
eval_Episode has 500 steps and return 144.2.
train_Episode has 500 steps and return 125.4.
Starting evaluation at step 67500 Counter(67500) 67437
eval_Episode has 500 steps and return 142.7.
Saved chunk: 20230921T225538F600794-0hKbu0qE3aGfQTk5TAq5WT-0sFaqEH5wNzbQoM1cppMcH-1024.npz
train_Episode has 500 steps and return 135.6.
Starting evaluation at step 68000 Counter(68000) 67937
Saved chunk: 20230921T225612F719008-3cswMTqvaNmIBPJF1SjRBO-3I75UEYqCG5JfXMzzyMsHw-1024.npz
eval_Episode has 500 steps and return 138.9.
train_Episode has 500 steps and return 160.5.
Starting evaluation at step 68500 Counter(68500) 68437
eval_Episode has 500 steps and return 158.0.
Saved chunk: 20230921T225659F328488-0sFaqEH5wNzbQoM1cppMcH-6u7REHknR3vzjHZPUxNhoR-1024.npz
train_Episode has 500 steps and return 135.9.
Starting evaluation at step 69000 Counter(69000) 68937
Saved chunk: 20230921T225731F745247-3I75UEYqCG5JfXMzzyMsHw-3WwRdBeCzB8NGxhQc0zX95-1024.npz
eval_Episode has 500 steps and return 157.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T225850F669441-3WwRdBeCzB8NGxhQc0zX95-0000000000000000000000-105.npz
Saved chunk: 20230921T225819F790961-6u7REHknR3vzjHZPUxNhoR-0000000000000000000000-492.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 166.4.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 138806 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 166.38 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 157.31 / eval_episode/reward_rate 0.37 / train/action_mag 3 / train/action_max 2.83 / train/action_mean 0.02 / train/action_min -2.85 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 3.3e4 / train/actor_opt_loss -166.28 / train/adv_mag 0.98 / train/adv_max 0.93 / train/adv_mean 0.02 / train/adv_min 
-0.36 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 2.6e-10 / train/cont_loss_std 8.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.77 / train/dyn_loss_std 6.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 3.3e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 90.47 / train/extr_critic_max 90.47 / train/extr_critic_mean 82.53 / train/extr_critic_min 46.91 / train/extr_critic_std 7.43 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 92.49 / train/extr_return_raw_max 92.49 / train/extr_return_raw_mean 82.98 / train/extr_return_raw_min 57.35 /
train/extr_return_raw_std 7.56 / train/extr_reward_mag 1.6 / train/extr_reward_max 1.6 / train/extr_reward_mean 0.1 / train/extr_reward_min 0 / train/extr_reward_std 0.28 / train/image_loss_mean 1.65 / train/image_loss_std 1.46 / train/model_loss_mean 3.99 / 
train/model_loss_std 4.72 / train/model_opt_grad_norm 10.02 / train/model_opt_grad_steps 3.3e4 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6335.08 / train/policy_entropy_mag 4.05 / 
train/policy_entropy_max 3.44 / train/policy_entropy_mean -2.69 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.61 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.69 / train/policy_logprob_min -9.61 / 
train/policy_logprob_std 1.82 / train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 1.3e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 41.93 / train/post_ent_max 41.93 / 
train/post_ent_mean 30.46 / train/post_ent_min 17.98 / train/post_ent_std 3.9 / train/prior_ent_mag 69.56 / train/prior_ent_max 69.56 / train/prior_ent_mean 34.28 / train/prior_ent_min 21.49 / train/prior_ent_std 6.07 / train/rep_loss_mean 3.77 / train/rep_loss_std 6.06 /
train/reward_avg 0.08 / train/reward_loss_mean 0.07 / train/reward_loss_std 0.23 / train/reward_max_data 1.47 / train/reward_max_pred 1.42 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.66 / train/reward_pred 0.08 
/ train/reward_rate 0.1 / train_stats/mean_log_entropy -2.89 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-10 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.7e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.67 / report/dyn_loss_std 5.71 / report/image_loss_mean 1.53 / report/image_loss_std 1.42 / report/model_loss_mean 3.82 / report/model_loss_std 4.54 / report/post_ent_mag 42.19 
/ report/post_ent_max 42.19 / report/post_ent_mean 31.3 / report/post_ent_min 22.09 / report/post_ent_std 3.56 / report/prior_ent_mag 70.14 / report/prior_ent_max 70.14 / report/prior_ent_mean 35.13 / report/prior_ent_min 23.88 / report/prior_ent_std 5.66 / 
report/rep_loss_mean 3.67 / report/rep_loss_std 5.71 / report/reward_avg 0.1 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.26 / report/reward_max_data 1.69 / report/reward_max_pred 1.7 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.65 / report/reward_pred 0.09 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-10 / eval/cont_loss_std 4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
1.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 9.73 / eval/dyn_loss_std 12.01 / eval/image_loss_mean 4.23 / eval/image_loss_std 5.34 / eval/model_loss_mean 10.11 / eval/model_loss_std 12.05 / eval/post_ent_mag 42.79 / eval/post_ent_max 42.79 / 
eval/post_ent_mean 29.15 / eval/post_ent_min 16.59 / eval/post_ent_std 3.37 / eval/prior_ent_mag 70.14 / eval/prior_ent_max 70.14 / eval/prior_ent_mean 34.88 / eval/prior_ent_min 24.27 / eval/prior_ent_std 6 / eval/rep_loss_mean 9.73 / eval/rep_loss_std 12.01 / 
eval/reward_avg 0.03 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.29 / eval/reward_max_data 1.09 / eval/reward_max_pred 1.08 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.92 / eval/reward_pred 0.03 / 
eval/reward_rate 0.04 / replay/size 6.9e4 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3816 / timer/env.step_total 19.92 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.75 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-4 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7323 / timer/agent.policy_total 16.24 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1908 / timer/agent.train_total 244.99 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.44

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 69500 Counter(69500) 69437
eval_Episode has 500 steps and return 162.8.
Saved chunk: 20230921T225819F790961-6u7REHknR3vzjHZPUxNhoR-2NMNveSWFbrmTKAtdPYELw-1024.npz
train_Episode has 500 steps and return 139.5.
Starting evaluation at step 70000 Counter(70000) 69937
Saved chunk: 20230921T225850F669441-3WwRdBeCzB8NGxhQc0zX95-5VWVzRkDcEjSG0Iibh7jmM-1024.npz
eval_Episode has 500 steps and return 171.9.
train_Episode has 500 steps and return 157.6.
Starting evaluation at step 70500 Counter(70500) 70437
eval_Episode has 500 steps and return 166.1.
train_Episode has 500 steps and return 171.6.
Saved chunk: 20230921T225941F439741-2NMNveSWFbrmTKAtdPYELw-3B0dmuTaTYTBTamKwpvG9d-1024.npz
Starting evaluation at step 71000 Counter(71000) 70937
Saved chunk: 20230921T230010F913214-5VWVzRkDcEjSG0Iibh7jmM-1ECNNMt67OCUi9tLAftPrX-1024.npz
eval_Episode has 500 steps and return 171.9.
train_Episode has 500 steps and return 166.5.
Starting evaluation at step 71500 Counter(71500) 71437
eval_Episode has 500 steps and return 166.6.
train_Episode has 500 steps and return 166.0.
Saved chunk: 20230921T230102F316389-3B0dmuTaTYTBTamKwpvG9d-6GnF3igeQ3FYntDi5HBMjH-1024.npz
Starting evaluation at step 72000 Counter(72000) 71937
Saved chunk: 20230921T230130F128862-1ECNNMt67OCUi9tLAftPrX-4iege6yzBt3QvsF7PrA5CV-1024.npz
eval_Episode has 500 steps and return 142.7.
train_Episode has 500 steps and return 119.3.
Starting evaluation at step 72500 Counter(72500) 72437
eval_Episode has 500 steps and return 174.5.
train_Episode has 500 steps and return 162.6.
Saved chunk: 20230921T230222F847287-6GnF3igeQ3FYntDi5HBMjH-7MA8RZoSGMcmZ3B3H7Rci3-1024.npz
Starting evaluation at step 73000 Counter(73000) 72937
eval_Episode has 500 steps and return 138.0.
Saved chunk: 20230921T230248F987539-4iege6yzBt3QvsF7PrA5CV-13Rh5nvIyoGxDi31KwLjJL-1024.npz
train_Episode has 500 steps and return 153.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 146354 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 138.03 / eval_episode/reward_rate 0.32 / episode/length 500 / episode/score 153.02 / episode/reward_rate 0.32 / train/action_mag 3.12 / train/action_max 3 / train/action_mean 8.6e-3 / train/action_min -2.9 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 3.5e4 / train/actor_opt_loss -124.29 / train/adv_mag 0.84 / train/adv_max 0.79 / train/adv_mean 0.01 / train/adv_min 
-0.41 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 2.3e-10 / train/cont_loss_std 8.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.76 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 3.5e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 100.33 / train/extr_critic_max 100.33 / train/extr_critic_mean 91.67 / train/extr_critic_min 50.72 / train/extr_critic_std 8.99 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 102.19 / train/extr_return_raw_max 102.19 / train/extr_return_raw_mean 92.04 / train/extr_return_raw_min 
58.35 / train/extr_return_raw_std 9.07 / train/extr_reward_mag 1.68 / train/extr_reward_max 1.68 / train/extr_reward_mean 0.11 / train/extr_reward_min 0 / train/extr_reward_std 0.3 / train/image_loss_mean 1.6 / train/image_loss_std 1.4 / train/model_loss_mean 3.93 / 
train/model_loss_std 4.71 / train/model_opt_grad_norm 9.84 / train/model_opt_grad_steps 3.5e4 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7340.43 / train/policy_entropy_mag 4.07 / train/policy_entropy_max
3.48 / train/policy_entropy_mean -2.54 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.14 / train/policy_logprob_mag 9.87 / train/policy_logprob_max 5.43 / train/policy_logprob_mean 2.54 / train/policy_logprob_min -9.87 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.9e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 42.6 / train/post_ent_max 42.6 / train/post_ent_mean 30.98 / 
train/post_ent_min 18.38 / train/post_ent_std 4.01 / train/prior_ent_mag 70.64 / train/prior_ent_max 70.64 / train/prior_ent_mean 34.78 / train/prior_ent_min 21.87 / train/prior_ent_std 6.22 / train/rep_loss_mean 3.76 / train/rep_loss_std 6.12 / train/reward_avg 0.09 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.24 / train/reward_max_data 1.51 / train/reward_max_pred 1.46 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.66 / train/reward_pred 0.09 / train/reward_rate
0.11 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.76 / report/cont_avg 1 / report/cont_loss_mean 2.4e-10 / report/cont_loss_std 5.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.44 / report/image_loss_mean 1.71 / report/image_loss_std 1.34 / report/model_loss_mean 4.19 / report/model_loss_std 4.91 / report/post_ent_mag 44.05 / report/post_ent_max 44.05 / 
report/post_ent_mean 30.86 / report/post_ent_min 16.08 / report/post_ent_std 3.78 / report/prior_ent_mag 71.32 / report/prior_ent_max 71.32 / report/prior_ent_mean 35.14 / report/prior_ent_min 22.24 / report/prior_ent_std 6.09 / report/rep_loss_mean 3.95 / 
report/rep_loss_std 6.44 / report/reward_avg 0.13 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.25 / report/reward_max_data 1.64 / report/reward_max_pred 1.56 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.8e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.13 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 3.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 9.07 / eval/dyn_loss_std 13.67 / eval/image_loss_mean 4.17 / eval/image_loss_std 7.02 / eval/model_loss_mean 9.65 / eval/model_loss_std 14.88 / eval/post_ent_mag 44.09 / eval/post_ent_max 44.09 / eval/post_ent_mean 
30.77 / eval/post_ent_min 13.23 / eval/post_ent_std 4.5 / eval/prior_ent_mag 71.32 / eval/prior_ent_max 71.32 / eval/prior_ent_mean 35.79 / eval/prior_ent_min 24.55 / eval/prior_ent_std 6.19 / eval/rep_loss_mean 9.07 / eval/rep_loss_std 13.67 / eval/reward_avg 0.04 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.19 / eval/reward_max_data 1.47 / eval/reward_max_pred 1.32 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.1e-3 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.69 / eval/reward_pred 0.04 / eval/reward_rate 0.05 / 
replay/size 7.3e4 / replay/inserts 3774 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3774 / timer/env.step_total 19.77 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3e4 / timer/replay._sample_total 446.12 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.2e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7782 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.7e-3 / 
timer/dataset_train_count 1887 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1887 / timer/agent.train_total 241.83 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 73500 Counter(73500) 73437
eval_Episode has 500 steps and return 158.1.
train_Episode has 500 steps and return 171.7.
Saved chunk: 20230921T230343F263102-7MA8RZoSGMcmZ3B3H7Rci3-7zcvc2RZvKnIxR734UidNP-1024.npz
Starting evaluation at step 74000 Counter(74000) 73937
eval_Episode has 500 steps and return 165.3.
train_Episode has 500 steps and return 151.8.
Starting evaluation at step 74500 Counter(74500) 74437
Saved chunk: 20230921T230407F825013-13Rh5nvIyoGxDi31KwLjJL-41ZiJHZfaA2bcIkNZTGWLt-1024.npz
eval_Episode has 500 steps and return 162.5.
train_Episode has 500 steps and return 152.4.
Saved chunk: 20230921T230504F555297-7zcvc2RZvKnIxR734UidNP-0ATZxgzsuwg6I4Q1YyxYyN-1024.npz
Starting evaluation at step 75000 Counter(75000) 74937
eval_Episode has 500 steps and return 174.6.
train_Episode has 500 steps and return 172.4.
Starting evaluation at step 75500 Counter(75500) 75437
Saved chunk: 20230921T230603F705213-41ZiJHZfaA2bcIkNZTGWLt-5W7baNRWrlVzxsCsLre55D-1024.npz
eval_Episode has 500 steps and return 140.9.
train_Episode has 500 steps and return 122.3.
Saved chunk: 20230921T230625F333762-0ATZxgzsuwg6I4Q1YyxYyN-6k41Hht9A0lJjdo4xxl9f6-1024.npz
Starting evaluation at step 76000 Counter(76000) 75937
eval_Episode has 500 steps and return 170.0.
train_Episode has 500 steps and return 143.8.
Starting evaluation at step 76500 Counter(76500) 76437
Saved chunk: 20230921T230722F630108-5W7baNRWrlVzxsCsLre55D-0Qy0wel2RHGrL2GOwT5s7U-1024.npz
eval_Episode has 500 steps and return 180.1.
train_Episode has 500 steps and return 126.7.
Saved chunk: 20230921T230745F745979-6k41Hht9A0lJjdo4xxl9f6-2tXHlS147GHtuQyptBjX4S-1024.npz
Starting evaluation at step 77000 Counter(77000) 76937
eval_Episode has 500 steps and return 174.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 154002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 174.37 / eval_episode/reward_rate 0.38 / episode/length 500 / episode/score 126.71 / episode/reward_rate 0.29 / train/action_mag 3.23 / train/action_max 3.07 / train/action_mean 9.1e-3 / train/action_min -2.97 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 3.7e4 / train/actor_opt_loss -100.22 / train/adv_mag 0.71 / train/adv_max 0.69 / train/adv_mean 0.01
/ train/adv_min -0.29 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.2e-10 / train/cont_loss_std 1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 3.7e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 110.27 / train/extr_critic_max 110.27 / train/extr_critic_mean 101.99 / train/extr_critic_min 60.97 / train/extr_critic_std 9.11 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 112.65 / train/extr_return_raw_max 112.65 / train/extr_return_raw_mean 102.34 / train/extr_return_raw_min 
69.28 / train/extr_return_raw_std 9.17 / train/extr_reward_mag 1.78 / train/extr_reward_max 1.78 / train/extr_reward_mean 0.12 / train/extr_reward_min 0 / train/extr_reward_std 0.32 / train/image_loss_mean 1.58 / train/image_loss_std 1.38 / train/model_loss_mean 3.95 / 
train/model_loss_std 4.75 / train/model_opt_grad_norm 9.68 / train/model_opt_grad_steps 3.7e4 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7369.79 / train/policy_entropy_mag 4.04 / 
train/policy_entropy_max 3.7 / train/policy_entropy_mean -2.28 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 9.86 / train/policy_logprob_max 5.41 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -9.86 / 
train/policy_logprob_std 1.87 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.7e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 43.46 / train/post_ent_max 43.46 / 
train/post_ent_mean 31.57 / train/post_ent_min 18.44 / train/post_ent_std 4.07 / train/prior_ent_mag 71.75 / train/prior_ent_max 71.75 / train/prior_ent_mean 35.41 / train/prior_ent_min 22 / train/prior_ent_std 6.3 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.21 / 
train/reward_avg 0.11 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.25 / train/reward_max_data 1.56 / train/reward_max_pred 1.52 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.65 / 
train/reward_pred 0.1 / train/reward_rate 0.12 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.33 / report/cont_avg 1 / report/cont_loss_mean 2.3e-10 / report/cont_loss_std 7.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.1 / report/dyn_loss_std 6.57 / report/image_loss_mean 1.76 / report/image_loss_std 1.32 / report/model_loss_mean 4.33 / report/model_loss_std 4.94 / 
report/post_ent_mag 42.98 / report/post_ent_max 42.98 / report/post_ent_mean 32.63 / report/post_ent_min 20.67 / report/post_ent_std 3.6 / report/prior_ent_mag 71.96 / report/prior_ent_max 71.96 / report/prior_ent_mean 36.93 / report/prior_ent_min 26.25 / 
report/prior_ent_std 5.57 / report/rep_loss_mean 4.1 / report/rep_loss_std 6.57 / report/reward_avg 0.14 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.26 / report/reward_max_data 1.46 / report/reward_max_pred 1.39 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4.7e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.62 / report/reward_pred 0.14 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 4.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.18 / eval/dyn_loss_std 7.72 / eval/image_loss_mean 1.85 / eval/image_loss_std 2.88 / eval/model_loss_mean 5.06 / eval/model_loss_std 7.18 / eval/post_ent_mag 
45.01 / eval/post_ent_max 45.01 / eval/post_ent_mean 31.94 / eval/post_ent_min 17.93 / eval/post_ent_std 3.65 / eval/prior_ent_mag 71.96 / eval/prior_ent_max 71.96 / eval/prior_ent_mean 36.07 / eval/prior_ent_min 21.44 / eval/prior_ent_std 5.97 / eval/rep_loss_mean 5.18
/ eval/rep_loss_std 7.72 / eval/reward_avg 0.05 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.5 / eval/reward_max_data 1.26 / eval/reward_max_pred 1.2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 1.15 / 
eval/reward_pred 0.05 / eval/reward_rate 0.07 / replay/size 7.7e4 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.8e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.33 / timer/env.step_count 3824 / timer/env.step_total 19.94
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.93 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7832 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1912 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.6e-4 / 
timer/agent.train_count 1912 / timer/agent.train_total 244.89 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / 
timer/dataset_eval_max 4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 169.6.
Starting evaluation at step 77500 Counter(77500) 77437
Saved chunk: 20230921T230841F446000-0Qy0wel2RHGrL2GOwT5s7U-5H2YqGz53ARE15bVmBO31v-1024.npz
eval_Episode has 500 steps and return 173.5.
train_Episode has 500 steps and return 163.9.
Saved chunk: 20230921T230906F090648-2tXHlS147GHtuQyptBjX4S-2WSpJI8TQGGhZ2Ss5tWMGA-1024.npz
Starting evaluation at step 78000 Counter(78000) 77937
eval_Episode has 500 steps and return 148.9.
train_Episode has 500 steps and return 137.8.
Starting evaluation at step 78500 Counter(78500) 78437
Saved chunk: 20230921T231001F192980-5H2YqGz53ARE15bVmBO31v-3ZR7KYr7qMveub7kp77rAP-1024.npz
eval_Episode has 500 steps and return 176.6.
train_Episode has 500 steps and return 181.7.
Saved chunk: 20230921T231027F620317-2WSpJI8TQGGhZ2Ss5tWMGA-3i1Ehb9FYpSI6RKWiUT7Uj-1024.npz
Starting evaluation at step 79000 Counter(79000) 78937
eval_Episode has 500 steps and return 149.2.
train_Episode has 500 steps and return 146.3.
Starting evaluation at step 79500 Counter(79500) 79437
Saved chunk: 20230921T231120F525102-3ZR7KYr7qMveub7kp77rAP-0AYf1JPubRL5dJyIaxK4QN-1024.npz
eval_Episode has 500 steps and return 175.6.
train_Episode has 500 steps and return 157.8.
Saved chunk: 20230921T231148F396555-3i1Ehb9FYpSI6RKWiUT7Uj-2Y37gwtYJV79XOri7cQNJY-1024.npz
Starting evaluation at step 80000 Counter(80000) 79937
eval_Episode has 500 steps and return 158.7.
train_Episode has 500 steps and return 177.9.
Starting evaluation at step 80500 Counter(80500) 80437
Saved chunk: 20230921T231239F483959-0AYf1JPubRL5dJyIaxK4QN-1UeKAfqgF9kNMkAE8lRV5y-1024.npz
eval_Episode has 500 steps and return 187.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T231358F344834-1UeKAfqgF9kNMkAE8lRV5y-0000000000000000000000-364.npz
Saved chunk: 20230921T231308F868622-2Y37gwtYJV79XOri7cQNJY-0000000000000000000000-729.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 147.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 161638 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 147.84 / episode/reward_rate 0.31 / eval_episode/length 500 / eval_episode/score 187.14 / eval_episode/reward_rate 0.4 / train/action_mag 3.38 / train/action_max 3.2 / train/action_mean -3.4e-3 / train/action_min -3.02 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 3.9e4 / train/actor_opt_loss -94.54 / train/adv_mag 1.01 / train/adv_max 0.99 / train/adv_mean 0.01
/ train/adv_min -0.27 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2e-10 / train/cont_loss_std 8.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 3.9e4 / 
train/extr_critic_critic_opt_loss 9122.57 / train/extr_critic_mag 117.73 / train/extr_critic_max 117.73 / train/extr_critic_mean 108.43 / train/extr_critic_min 62.08 / train/extr_critic_std 9.22 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 119.12 / train/extr_return_raw_max 119.12 / train/extr_return_raw_mean 108.75 / train/extr_return_raw_min 
76.41 / train/extr_return_raw_std 9.34 / train/extr_reward_mag 1.83 / train/extr_reward_max 1.83 / train/extr_reward_mean 0.13 / train/extr_reward_min 0 / train/extr_reward_std 0.33 / train/image_loss_mean 1.55 / train/image_loss_std 1.31 / train/model_loss_mean 3.95 / 
train/model_loss_std 4.74 / train/model_opt_grad_norm 9.7 / train/model_opt_grad_steps 3.9e4 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 3.97 / train/policy_entropy_max
3.49 / train/policy_entropy_mean -2.22 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 10.1 / train/policy_logprob_max 5.41 / train/policy_logprob_mean 2.22 / train/policy_logprob_min -10.1 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 3e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 44.08 / train/post_ent_max 44.08 / train/post_ent_mean 32.25 / 
train/post_ent_min 18.84 / train/post_ent_std 4.21 / train/prior_ent_mag 72.71 / train/prior_ent_max 72.71 / train/prior_ent_mean 36.11 / train/prior_ent_min 22.49 / train/prior_ent_std 6.39 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.29 / train/reward_avg 0.12 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.26 / train/reward_max_data 1.59 / train/reward_max_pred 1.56 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.64 / train/reward_pred 0.12 / 
train/reward_rate 0.14 / train_stats/mean_log_entropy -2.34 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.7e-10 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.7e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 6.29 / report/image_loss_mean 1.36 / report/image_loss_std 1.19 / report/model_loss_mean 3.68 / report/model_loss_std 4.67 / report/post_ent_mag 44.9
/ report/post_ent_max 44.9 / report/post_ent_mean 32.42 / report/post_ent_min 20.18 / report/post_ent_std 3.95 / report/prior_ent_mag 73.15 / report/prior_ent_max 73.15 / report/prior_ent_mean 35.88 / report/prior_ent_min 23.09 / report/prior_ent_std 6.39 / 
report/rep_loss_mean 3.75 / report/rep_loss_std 6.29 / report/reward_avg 0.09 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.24 / report/reward_max_data 1.69 / report/reward_max_pred 1.53 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.64 / report/reward_pred 0.09 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.55 / eval/dyn_loss_std 9.17 / eval/image_loss_mean 3.21 / eval/image_loss_std 3.77 / eval/model_loss_mean 7.8 / eval/model_loss_std 8.58 / eval/post_ent_mag 43.88 / eval/post_ent_max
43.88 / eval/post_ent_mean 31.09 / eval/post_ent_min 16.6 / eval/post_ent_std 4.65 / eval/prior_ent_mag 73.15 / eval/prior_ent_max 73.15 / eval/prior_ent_mean 36.38 / eval/prior_ent_min 21.84 / eval/prior_ent_std 6.37 / eval/rep_loss_mean 7.55 / eval/rep_loss_std 9.17 /
eval/reward_avg 0.05 / eval/reward_loss_mean 0.05 / eval/reward_loss_std 0.27 / eval/reward_max_data 1.52 / eval/reward_max_pred 1.42 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.6e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.74 / eval/reward_pred 0.05 / 
eval/reward_rate 0.07 / replay/size 8.1e4 / replay/inserts 3818 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.1e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3818 / timer/env.step_total 20.04 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458.17 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.5e-3 / 
timer/replay._sample_max 0.13 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7325 / timer/agent.policy_total 16.27 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1909 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1909 / timer/agent.train_total 244.86 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac
1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.45

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T231308F868622-2Y37gwtYJV79XOri7cQNJY-2FFRm0A6JHxHgXMwL1XJ31-1024.npz
Starting evaluation at step 81000 Counter(81000) 80937
eval_Episode has 500 steps and return 186.0.
train_Episode has 500 steps and return 163.7.
Starting evaluation at step 81500 Counter(81500) 81437
Saved chunk: 20230921T231358F344834-1UeKAfqgF9kNMkAE8lRV5y-2OfDmXzwpQ9hOJlq9vsQjp-1024.npz
eval_Episode has 500 steps and return 201.7.
train_Episode has 500 steps and return 164.7.
Saved chunk: 20230921T231430F218601-2FFRm0A6JHxHgXMwL1XJ31-0Y1XkEdADjTcbSmWGERwUj-1024.npz
Starting evaluation at step 82000 Counter(82000) 81937
eval_Episode has 500 steps and return 211.1.
train_Episode has 500 steps and return 166.3.
Starting evaluation at step 82500 Counter(82500) 82437
Saved chunk: 20230921T231518F474242-2OfDmXzwpQ9hOJlq9vsQjp-2bO3CYvCMJw8DVAP2S8l09-1024.npz
eval_Episode has 500 steps and return 170.0.
train_Episode has 500 steps and return 151.7.
Saved chunk: 20230921T231551F179236-0Y1XkEdADjTcbSmWGERwUj-44Toth2dzL255jWPPFtHvY-1024.npz
Starting evaluation at step 83000 Counter(83000) 82937
eval_Episode has 500 steps and return 189.3.
train_Episode has 500 steps and return 193.8.
Starting evaluation at step 83500 Counter(83500) 83437
Saved chunk: 20230921T231637F663686-2bO3CYvCMJw8DVAP2S8l09-5xHAjtq8lzAYQPUkzPEyQi-1024.npz
eval_Episode has 500 steps and return 189.7.
train_Episode has 500 steps and return 192.8.
Saved chunk: 20230921T231711F809351-44Toth2dzL255jWPPFtHvY-49IKEFqWhJIj49w3YIpIo5-1024.npz
Starting evaluation at step 84000 Counter(84000) 83937
eval_Episode has 500 steps and return 200.2.
train_Episode has 500 steps and return 172.4.
Starting evaluation at step 84500 Counter(84500) 84437
Saved chunk: 20230921T231756F557308-5xHAjtq8lzAYQPUkzPEyQi-4Cye9MbFDEObCX2AP2eszc-1024.npz
eval_Episode has 500 steps and return 180.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 169190 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 180.4 / eval_episode/reward_rate 0.37 / episode/length 500 / episode/score 172.36 / episode/reward_rate 0.37 / train/action_mag 3.32 / train/action_max 3.09 / train/action_mean -5.2e-3 / train/action_min -2.92 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 4.1e4 / train/actor_opt_loss -104.85 / train/adv_mag 1.33 / train/adv_max 1.32 / train/adv_mean 
0.01 / train/adv_min -0.3 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.1e-10 / train/cont_loss_std 1.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-10 / train/cont_pred 1 / train/cont_rate 1 
/ train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 4.1e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 127.12 / train/extr_critic_max 127.12 / train/extr_critic_mean 118.08 / train/extr_critic_min 63.5 / train/extr_critic_std 9.13 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 128.71 / train/extr_return_raw_max 128.71 / train/extr_return_raw_mean 118.44 / train/extr_return_raw_min 
86.16 / train/extr_return_raw_std 9.11 / train/extr_reward_mag 1.83 / train/extr_reward_max 1.83 / train/extr_reward_mean 0.14 / train/extr_reward_min 0 / train/extr_reward_std 0.34 / train/image_loss_mean 1.54 / train/image_loss_std 1.29 / train/model_loss_mean 3.97 / 
train/model_loss_std 4.77 / train/model_opt_grad_norm 9.85 / train/model_opt_grad_steps 4.1e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8058.51 / train/policy_entropy_mag 3.81 / 
train/policy_entropy_max 3.03 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.06 / train/policy_logprob_mag 9.54 / train/policy_logprob_max 5.42 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -9.54 / 
train/policy_logprob_std 1.79 / train/policy_randomness_mag 0.71 / train/policy_randomness_max 0.71 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 1.9e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 44.54 / train/post_ent_max 44.54 / 
train/post_ent_mean 32.81 / train/post_ent_min 19.02 / train/post_ent_std 4.27 / train/prior_ent_mag 73.46 / train/prior_ent_max 73.46 / train/prior_ent_mean 36.71 / train/prior_ent_min 22.97 / train/prior_ent_std 6.43 / train/rep_loss_mean 3.89 / train/rep_loss_std 
6.36 / train/reward_avg 0.13 / train/reward_loss_mean 0.1 / train/reward_loss_std 0.26 / train/reward_max_data 1.62 / train/reward_max_pred 1.59 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.64 / 
train/reward_pred 0.13 / train/reward_rate 0.15 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.34 / report/cont_avg 1 / report/cont_loss_mean 1.4e-10 / report/cont_loss_std 3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.25 / report/dyn_loss_std 5.38 / report/image_loss_mean 1.21 / report/image_loss_std 1.11 / report/model_loss_mean 3.24 / report/model_loss_std 4.04 / 
report/post_ent_mag 46.02 / report/post_ent_max 46.02 / report/post_ent_mean 33.55 / report/post_ent_min 19.68 / report/post_ent_std 4.11 / report/prior_ent_mag 73.5 / report/prior_ent_max 73.5 / report/prior_ent_mean 36.91 / report/prior_ent_min 25.75 / 
report/prior_ent_std 6.18 / report/rep_loss_mean 3.25 / report/rep_loss_std 5.38 / report/reward_avg 0.11 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.24 / report/reward_max_data 1.88 / report/reward_max_pred 1.51 / report/reward_neg_acc 1 / 
report/reward_neg_loss 1.4e-4 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.64 / report/reward_pred 0.11 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.97 / eval/dyn_loss_std 6.89 / eval/image_loss_mean 1.65 / eval/image_loss_std 2.09 / eval/model_loss_mean 4.74 / eval/model_loss_std 5.69 / eval/post_ent_mag 
46.12 / eval/post_ent_max 46.12 / eval/post_ent_mean 33.58 / eval/post_ent_min 23.29 / eval/post_ent_std 3.53 / eval/prior_ent_mag 73.5 / eval/prior_ent_max 73.5 / eval/prior_ent_mean 37.29 / eval/prior_ent_min 29.13 / eval/prior_ent_std 5.93 / eval/rep_loss_mean 4.97 /
eval/rep_loss_std 6.89 / eval/reward_avg 0.13 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.5 / eval/reward_max_pred 1.43 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.8e-4 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.7 / 
eval/reward_pred 0.13 / eval/reward_rate 0.15 / replay/size 8.5e4 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.5e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3776 / timer/env.step_total 19.68
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.58 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
4.5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 / 
timer/agent.train_count 1888 / timer/agent.train_total 242.12 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / 
timer/dataset_eval_max 3.7e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 157.3.
Saved chunk: 20230921T231832F192568-49IKEFqWhJIj49w3YIpIo5-4TlcelaO0zoDd4U4T1MRbj-1024.npz
Starting evaluation at step 85000 Counter(85000) 84937
eval_Episode has 500 steps and return 199.3.
train_Episode has 500 steps and return 146.3.
Starting evaluation at step 85500 Counter(85500) 85437
Saved chunk: 20230921T231915F357397-4Cye9MbFDEObCX2AP2eszc-5S1lxn1V1E9JuZwotSspRt-1024.npz
eval_Episode has 500 steps and return 208.4.
train_Episode has 500 steps and return 164.5.
Starting evaluation at step 86000 Counter(86000) 85937
eval_Episode has 500 steps and return 178.2.
Saved chunk: 20230921T231953F513566-4TlcelaO0zoDd4U4T1MRbj-3yAkBBSS2aINFGDy0SAaJn-1024.npz
train_Episode has 500 steps and return 147.2.
Starting evaluation at step 86500 Counter(86500) 86437
Saved chunk: 20230921T232035F442722-5S1lxn1V1E9JuZwotSspRt-7EfU4aDZ73DweEEhT4lZtg-1024.npz
eval_Episode has 500 steps and return 214.8.
train_Episode has 500 steps and return 197.9.
Starting evaluation at step 87000 Counter(87000) 86937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232117F935250-3yAkBBSS2aINFGDy0SAaJn-3qV3pZNtwClxGtF5Drs1Fl-1024.npz
train_Episode has 500 steps and return 207.1.
Starting evaluation at step 87500 Counter(87500) 87437
Saved chunk: 20230921T232154F600871-7EfU4aDZ73DweEEhT4lZtg-7CJOMOpCaSW4v39ZMxpo54-1024.npz
eval_Episode has 500 steps and return 167.0.
train_Episode has 500 steps and return 181.9.
Starting evaluation at step 88000 Counter(88000) 87937
eval_Episode has 500 steps and return 190.5.
Saved chunk: 20230921T232238F515509-3qV3pZNtwClxGtF5Drs1Fl-400XNUwjLBXpo4ShKzGO0x-1024.npz
train_Episode has 500 steps and return 158.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 176830 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 158.1 / episode/reward_rate 0.31 / eval_episode/length 500 / eval_episode/score 190.49 / eval_episode/reward_rate 0.37 / train/action_mag 3.6 / train/action_max 3.42 / train/action_mean -0.03 / train/action_min -3.09 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 4.3e4 / train/actor_opt_loss -60.44 / train/adv_mag 0.96 / train/adv_max 0.96 / train/adv_mean 6.8e-3 / 
train/adv_min -0.29 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.8e-10 / train/cont_loss_std 9.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.95 / train/dyn_loss_std 6.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 4.3e4 / 
train/extr_critic_critic_opt_loss 8863.61 / train/extr_critic_mag 133.04 / train/extr_critic_max 133.04 / train/extr_critic_mean 124.19 / train/extr_critic_min 77 / train/extr_critic_std 9.47 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 134.75 / train/extr_return_raw_max 134.75 / train/extr_return_raw_mean 124.42 / train/extr_return_raw_min 
89.65 / train/extr_return_raw_std 9.55 / train/extr_reward_mag 1.82 / train/extr_reward_max 1.82 / train/extr_reward_mean 0.15 / train/extr_reward_min 0 / train/extr_reward_std 0.36 / train/image_loss_mean 1.52 / train/image_loss_std 1.26 / train/model_loss_mean 3.99 / 
train/model_loss_std 4.78 / train/model_opt_grad_norm 9.73 / train/model_opt_grad_steps 4.3e4 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6780.1 / train/policy_entropy_mag 3.89 / 
train/policy_entropy_max 3.33 / train/policy_entropy_mean -2.13 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.86 / train/policy_logprob_max 5.41 / train/policy_logprob_mean 2.13 / train/policy_logprob_min -9.86 / 
train/policy_logprob_std 1.83 / train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.4e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 45.18 / train/post_ent_max 45.18 / 
train/post_ent_mean 33.45 / train/post_ent_min 19.28 / train/post_ent_std 4.44 / train/prior_ent_mag 74.28 / train/prior_ent_max 74.28 / train/prior_ent_mean 37.39 / train/prior_ent_min 23.28 / train/prior_ent_std 6.54 / train/rep_loss_mean 3.95 / train/rep_loss_std 
6.43 / train/reward_avg 0.14 / train/reward_loss_mean 0.1 / train/reward_loss_std 0.27 / train/reward_max_data 1.64 / train/reward_max_pred 1.61 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.64 / 
train/reward_pred 0.14 / train/reward_rate 0.16 / train_stats/mean_log_entropy -2.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-10 / report/cont_loss_std 4.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.14 / report/dyn_loss_std 7.21 / report/image_loss_mean 1.43 / report/image_loss_std 1.42 / report/model_loss_mean 4.02 / report/model_loss_std 5.4 / 
report/post_ent_mag 44.12 / report/post_ent_max 44.12 / report/post_ent_mean 34.33 / report/post_ent_min 19.41 / report/post_ent_std 5.06 / report/prior_ent_mag 74.46 / report/prior_ent_max 74.46 / report/prior_ent_mean 38.37 / report/prior_ent_min 21.01 / 
report/prior_ent_std 6.88 / report/rep_loss_mean 4.14 / report/rep_loss_std 7.21 / report/reward_avg 0.14 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.26 / report/reward_max_data 1.57 / report/reward_max_pred 1.6 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4.6e-4 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.65 / report/reward_pred 0.14 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-10 / eval/cont_loss_std 1.3e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.7 / eval/dyn_loss_std 8.76 / eval/image_loss_mean 3.04 / eval/image_loss_std 3.43 / eval/model_loss_mean 7.81 / eval/model_loss_std 8.1 / eval/post_ent_mag 
43.25 / eval/post_ent_max 43.25 / eval/post_ent_mean 33.05 / eval/post_ent_min 14.35 / eval/post_ent_std 4.84 / eval/prior_ent_mag 74.46 / eval/prior_ent_max 74.46 / eval/prior_ent_mean 38.76 / eval/prior_ent_min 25.18 / eval/prior_ent_std 5.95 / eval/rep_loss_mean 7.7 
/ eval/rep_loss_std 8.76 / eval/reward_avg 0.12 / eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.48 / eval/reward_max_data 1.28 / eval/reward_max_pred 1.31 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.1e-3 / eval/reward_pos_acc 0.97 / eval/reward_pos_loss 0.85 
/ eval/reward_pred 0.12 / eval/reward_rate 0.17 / replay/size 8.8e4 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.9e4 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3820 / timer/env.step_total 19.89
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.39 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 7.7e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 16.23 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1910 / timer/agent.train_total 245.05 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / 
timer/dataset_eval_max 3.1e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 88500 Counter(88500) 88437
Saved chunk: 20230921T232313F489762-7CJOMOpCaSW4v39ZMxpo54-0yrBEg0IDYAviTgR3MN2un-1024.npz
eval_Episode has 500 steps and return 195.3.
train_Episode has 500 steps and return 166.0.
Starting evaluation at step 89000 Counter(89000) 88937
eval_Episode has 500 steps and return 217.7.
Saved chunk: 20230921T232359F007794-400XNUwjLBXpo4ShKzGO0x-4UXjaIxGqXB3NlTVWMr8jB-1024.npz
train_Episode has 500 steps and return 196.8.
Starting evaluation at step 89500 Counter(89500) 89437
Saved chunk: 20230921T232433F217500-0yrBEg0IDYAviTgR3MN2un-2gbhYEKl9wL0gJSLIkvpJ9-1024.npz
eval_Episode has 500 steps and return 222.8.
train_Episode has 500 steps and return 203.7.
Starting evaluation at step 90000 Counter(90000) 89937
eval_Episode has 500 steps and return 198.5.
Saved chunk: 20230921T232520F605525-4UXjaIxGqXB3NlTVWMr8jB-1zemL4iN3XN0rPc6Q1dSW4-1024.npz
train_Episode has 500 steps and return 195.0.
Starting evaluation at step 90500 Counter(90500) 90437
Saved chunk: 20230921T232552F653044-2gbhYEKl9wL0gJSLIkvpJ9-0C8grmDYcpWhzSczZp8ZZi-1024.npz
eval_Episode has 500 steps and return 211.8.
train_Episode has 500 steps and return 201.0.
Starting evaluation at step 91000 Counter(91000) 90937
eval_Episode has 500 steps and return 209.6.
Saved chunk: 20230921T232641F288787-1zemL4iN3XN0rPc6Q1dSW4-6hrLxajf3BiKvXL8F43QI2-1024.npz
train_Episode has 500 steps and return 163.2.
Starting evaluation at step 91500 Counter(91500) 91437
Saved chunk: 20230921T232711F600911-0C8grmDYcpWhzSczZp8ZZi-2sONdEizPeOdUHrvLiehFF-1024.npz
eval_Episode has 500 steps and return 209.4.
train_Episode has 500 steps and return 204.4.
Starting evaluation at step 92000 Counter(92000) 91937
eval_Episode has 500 steps and return 217.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T232830F422525-2sONdEizPeOdUHrvLiehFF-0000000000000000000000-623.npz
Saved chunk: 20230921T232801F727928-6hrLxajf3BiKvXL8F43QI2-0000000000000000000000-964.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T232801F727928-6hrLxajf3BiKvXL8F43QI2-1P3gIvaKhn40fHwBwuuHAl-1024.npz
train_Episode has 500 steps and return 190.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 184370 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 217.65 / eval_episode/reward_rate 0.41 / episode/length 500 / episode/score 190 / episode/reward_rate 0.36 / train/action_mag 3.43 / train/action_max 3.28 / train/action_mean -0.01 / train/action_min -2.84 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 4.5e4 / train/actor_opt_loss -86.14 / train/adv_mag 0.69 / train/adv_max 0.68 / train/adv_mean 9.5e-3 / 
train/adv_min -0.28 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 7.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 4.5e4 / 
train/extr_critic_critic_opt_loss 9783.67 / train/extr_critic_mag 140.23 / train/extr_critic_max 140.23 / train/extr_critic_mean 130.43 / train/extr_critic_min 89.17 / train/extr_critic_std 9.89 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 141.17 / train/extr_return_raw_max 141.17 / train/extr_return_raw_mean 130.74 / train/extr_return_raw_min 
95.41 / train/extr_return_raw_std 9.96 / train/extr_reward_mag 1.85 / train/extr_reward_max 1.85 / train/extr_reward_mean 0.16 / train/extr_reward_min 0 / train/extr_reward_std 0.37 / train/image_loss_mean 1.48 / train/image_loss_std 1.23 / train/model_loss_mean 3.92 / 
train/model_loss_std 4.73 / train/model_opt_grad_norm 9.67 / train/model_opt_grad_steps 4.5e4 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7248.68 / train/policy_entropy_mag 3.85 / 
train/policy_entropy_max 2.79 / train/policy_entropy_mean -2.32 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.01 / train/policy_logprob_mag 9.38 / train/policy_logprob_max 5.41 / train/policy_logprob_mean 2.32 / train/policy_logprob_min -9.38 / 
train/policy_logprob_std 1.77 / train/policy_randomness_mag 0.69 / train/policy_randomness_max 0.69 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.2e-3 / train/policy_randomness_std 0.11 / train/post_ent_mag 45.66 / train/post_ent_max 45.66 / 
train/post_ent_mean 33.91 / train/post_ent_min 19.52 / train/post_ent_std 4.52 / train/prior_ent_mag 74.92 / train/prior_ent_max 74.92 / train/prior_ent_mean 37.84 / train/prior_ent_min 23.4 / train/prior_ent_std 6.6 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.37 /
train/reward_avg 0.14 / train/reward_loss_mean 0.1 / train/reward_loss_std 0.27 / train/reward_max_data 1.68 / train/reward_max_pred 1.64 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred 
0.14 / train/reward_rate 0.16 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.41 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 3.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.03 / report/dyn_loss_std 6.36 / report/image_loss_mean 1.66 / report/image_loss_std 1.38 / report/model_loss_mean 4.17 / report/model_loss_std 4.92 / report/post_ent_mag 
45.44 / report/post_ent_max 45.44 / report/post_ent_mean 33.53 / report/post_ent_min 19.48 / report/post_ent_std 5.02 / report/prior_ent_mag 74.88 / report/prior_ent_max 74.88 / report/prior_ent_mean 37.83 / report/prior_ent_min 20.81 / report/prior_ent_std 6.75 / 
report/rep_loss_mean 4.03 / report/rep_loss_std 6.36 / report/reward_avg 0.13 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.23 / report/reward_max_data 1.45 / report/reward_max_pred 1.54 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.13 / report/reward_rate 0.15 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 4.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 11.64 / eval/dyn_loss_std 12.54 / eval/image_loss_mean 5.07 / eval/image_loss_std 5.86 / eval/model_loss_mean 12.12 / eval/model_loss_std 12.67 / eval/post_ent_mag 44.6 / 
eval/post_ent_max 44.6 / eval/post_ent_mean 31.92 / eval/post_ent_min 14.49 / eval/post_ent_std 5.09 / eval/prior_ent_mag 74.88 / eval/prior_ent_max 74.88 / eval/prior_ent_mean 38.85 / eval/prior_ent_min 24.58 / eval/prior_ent_std 6.42 / eval/rep_loss_mean 11.64 / 
eval/rep_loss_std 12.54 / eval/reward_avg 0.08 / eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.26 / eval/reward_max_data 1.47 / eval/reward_max_pred 1.51 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.71 / 
eval/reward_pred 0.08 / eval/reward_rate 0.1 / replay/size 9.2e4 / replay/inserts 3770 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.3e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3770 / timer/env.step_total 19.64
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.55 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
2.5e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7778 / timer/agent.policy_total 
17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1885 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1885 / timer/agent.train_total 241.79 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 
1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 92500 Counter(92500) 92437
Saved chunk: 20230921T232830F422525-2sONdEizPeOdUHrvLiehFF-4UfhmBkJtJrEFaCX5SEfh1-1024.npz
eval_Episode has 500 steps and return 216.2.
train_Episode has 500 steps and return 192.2.
Starting evaluation at step 93000 Counter(93000) 92937
eval_Episode has 500 steps and return 224.9.
train_Episode has 500 steps and return 209.8.
Saved chunk: 20230921T232922F384776-1P3gIvaKhn40fHwBwuuHAl-3r8RuTo0YdiPGsMB4p5wbK-1024.npz
Starting evaluation at step 93500 Counter(93500) 93437
Saved chunk: 20230921T232950F356642-4UfhmBkJtJrEFaCX5SEfh1-0E932GGcv1SK0zIYOMz80O-1024.npz
eval_Episode has 500 steps and return 212.4.
train_Episode has 500 steps and return 174.8.
Starting evaluation at step 94000 Counter(94000) 93937
eval_Episode has 500 steps and return 219.5.
train_Episode has 500 steps and return 188.5.
Saved chunk: 20230921T233043F927785-3r8RuTo0YdiPGsMB4p5wbK-2ilcaoFm7wkkLGfmUcYv0T-1024.npz
Starting evaluation at step 94500 Counter(94500) 94437
eval_Episode has 500 steps and return 175.7.
Saved chunk: 20230921T233109F625591-0E932GGcv1SK0zIYOMz80O-42b0cXwkCRUovxvTJO1pxe-1024.npz
train_Episode has 500 steps and return 190.8.
Starting evaluation at step 95000 Counter(95000) 94937
eval_Episode has 500 steps and return 228.2.
train_Episode has 500 steps and return 193.5.
Saved chunk: 20230921T233204F550308-2ilcaoFm7wkkLGfmUcYv0T-24iNjOyAd2hG14GyvOkjw1-1024.npz
Starting evaluation at step 95500 Counter(95500) 95437
eval_Episode has 500 steps and return 217.6.
Saved chunk: 20230921T233228F553514-42b0cXwkCRUovxvTJO1pxe-1x1aL5j7rAm8P28MVatQ0d-1024.npz
train_Episode has 500 steps and return 193.6.
Starting evaluation at step 96000 Counter(96000) 95937
eval_Episode has 500 steps and return 207.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 192002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 207.93 / eval_episode/reward_rate 0.33 / episode/length 500 / episode/score 193.6 / episode/reward_rate 0.38 / train/action_mag 3.37 / train/action_max 3.25 / train/action_mean -0.02 / train/action_min -2.66 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 4.6e4 / train/actor_opt_loss -72.02 / train/adv_mag 0.69 / train/adv_max 0.68 / train/adv_mean 8e-3
/ train/adv_min -0.28 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.4e-10 / train/cont_loss_std 5.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 4.6e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 148.64 / train/extr_critic_max 148.64 / train/extr_critic_mean 138.9 / train/extr_critic_min 92.67 / train/extr_critic_std 9.86 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 149.78 / train/extr_return_raw_max 149.78 / train/extr_return_raw_mean 139.18 / 
train/extr_return_raw_min 103.7 / train/extr_return_raw_std 9.88 / train/extr_reward_mag 1.86 / train/extr_reward_max 1.86 / train/extr_reward_mean 0.17 / train/extr_reward_min 0 / train/extr_reward_std 0.39 / train/image_loss_mean 1.46 / train/image_loss_std 1.22 / 
train/model_loss_mean 3.91 / train/model_loss_std 4.76 / train/model_opt_grad_norm 9.51 / train/model_opt_grad_steps 4.6e4 / train/model_opt_loss 2.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 
3.78 / train/policy_entropy_max 2.72 / train/policy_entropy_mean -2.3 / train/policy_entropy_min -3.51 / train/policy_entropy_std 0.98 / train/policy_logprob_mag 9.43 / train/policy_logprob_max 5.4 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -9.43 / 
train/policy_logprob_std 1.74 / train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.7e-3 / train/policy_randomness_std 0.11 / train/post_ent_mag 46.15 / train/post_ent_max 46.15 / 
train/post_ent_mean 34.4 / train/post_ent_min 19.46 / train/post_ent_std 4.62 / train/prior_ent_mag 75.46 / train/prior_ent_max 75.46 / train/prior_ent_mean 38.31 / train/prior_ent_min 23.76 / train/prior_ent_std 6.65 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.43 
/ train/reward_avg 0.15 / train/reward_loss_mean 0.11 / train/reward_loss_std 0.27 / train/reward_max_data 1.67 / train/reward_max_pred 1.65 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred
0.15 / train/reward_rate 0.17 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.3 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.56 / report/image_loss_mean 1.55 / report/image_loss_std 1.1 / report/model_loss_mean 4.02 / report/model_loss_std 4.79 / report/post_ent_mag 45.19 /
report/post_ent_max 45.19 / report/post_ent_mean 33.96 / report/post_ent_min 19.18 / report/post_ent_std 5.53 / report/prior_ent_mag 75.16 / report/prior_ent_max 75.16 / report/prior_ent_mean 38.01 / report/prior_ent_min 22.54 / report/prior_ent_std 7.37 / 
report/rep_loss_mean 3.95 / report/rep_loss_std 6.56 / report/reward_avg 0.15 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.25 / report/reward_max_data 1.65 / report/reward_max_pred 1.59 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.63 / report/reward_pred 0.15 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 9.6e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 9.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.64 / eval/dyn_loss_std 7.65 / eval/image_loss_mean 1.87 / eval/image_loss_std 2.38 / eval/model_loss_mean 5.37 / eval/model_loss_std 6.47 / eval/post_ent_mag 47.03 / 
eval/post_ent_max 47.03 / eval/post_ent_mean 34.86 / eval/post_ent_min 19.06 / eval/post_ent_std 4.28 / eval/prior_ent_mag 75.16 / eval/prior_ent_max 75.16 / eval/prior_ent_mean 38.99 / eval/prior_ent_min 25.5 / eval/prior_ent_std 6.03 / eval/rep_loss_mean 5.64 / 
eval/rep_loss_std 7.65 / eval/reward_avg 0.14 / eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.7 / eval/reward_max_pred 1.69 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.1e-3 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.68 / 
eval/reward_pred 0.14 / eval/reward_rate 0.17 / replay/size 9.6e4 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.7e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.77 / timer/env.step_count 3816 / timer/env.step_total 19.73
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 457.92 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7824 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.8e-3 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.1e-4 
/ timer/agent.train_count 1908 / timer/agent.train_total 244.59 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / 
timer/dataset_eval_max 3.2e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 195.1.
Saved chunk: 20230921T233324F892241-24iNjOyAd2hG14GyvOkjw1-4HTJcZ4JdmAd9em7wci5p8-1024.npz
Starting evaluation at step 96500 Counter(96500) 96437
eval_Episode has 500 steps and return 215.5.
Saved chunk: 20230921T233347F282206-1x1aL5j7rAm8P28MVatQ0d-1WrNIFMJnqoxURUFVttEjM-1024.npz
train_Episode has 500 steps and return 198.5.
Starting evaluation at step 97000 Counter(97000) 96937
eval_Episode has 500 steps and return 193.7.
train_Episode has 500 steps and return 184.0.
Saved chunk: 20230921T233446F011808-4HTJcZ4JdmAd9em7wci5p8-7LF4p3b0jbFlA3tdjEOMZk-1024.npz
Starting evaluation at step 97500 Counter(97500) 97437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 185.5.
Starting evaluation at step 98000 Counter(98000) 97937
Saved chunk: 20230921T233507F042696-1WrNIFMJnqoxURUFVttEjM-7sPXTBzEGDJ2AgegjHuVAp-1024.npz
eval_Episode has 500 steps and return 212.3.
train_Episode has 500 steps and return 206.2.
Saved chunk: 20230921T233606F907506-7LF4p3b0jbFlA3tdjEOMZk-6PZMh5VscTRMCWolqEjKFm-1024.npz
Starting evaluation at step 98500 Counter(98500) 98437
eval_Episode has 500 steps and return 174.0.
train_Episode has 500 steps and return 170.2.
Starting evaluation at step 99000 Counter(99000) 98937
Saved chunk: 20230921T233702F308780-7sPXTBzEGDJ2AgegjHuVAp-4zCnc8RWDYoeu7jFYJdJR5-1024.npz
eval_Episode has 500 steps and return 227.5.
train_Episode has 500 steps and return 219.1.
Saved chunk: 20230921T233727F541949-6PZMh5VscTRMCWolqEjKFm-27BFJFUe00fmMRgVdqWzRq-1024.npz
Starting evaluation at step 99500 Counter(99500) 99437
eval_Episode has 500 steps and return 249.8.
train_Episode has 500 steps and return 216.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 199646 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 216.18 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 249.8 / eval_episode/reward_rate 0.44 / train/action_mag 3.54 / train/action_max 3.36 / train/action_mean -0.04 / train/action_min -2.95 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 4.8e4 / train/actor_opt_loss -30.31 / train/adv_mag 0.48 / train/adv_max 0.47 / train/adv_mean 
3.7e-3 / train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 7.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.45 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 4.8e4 / train/extr_critic_critic_opt_loss 9287.27 / train/extr_critic_mag 153.32 / train/extr_critic_max 153.32 / train/extr_critic_mean 143.48 / train/extr_critic_min 95.44 / train/extr_critic_std 11.76 / 
train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 155.1 / 
train/extr_return_raw_max 155.1 / train/extr_return_raw_mean 143.63 / train/extr_return_raw_min 100.59 / train/extr_return_raw_std 11.8 / train/extr_reward_mag 1.86 / train/extr_reward_max 1.86 / train/extr_reward_mean 0.17 / train/extr_reward_min 0 / 
train/extr_reward_std 0.4 / train/image_loss_mean 1.43 / train/image_loss_std 1.2 / train/model_loss_mean 3.89 / train/model_loss_std 4.76 / train/model_opt_grad_norm 9.8 / train/model_opt_grad_steps 4.8e4 / train/model_opt_loss 2.9e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 3.87 / train/policy_entropy_max 3.42 / train/policy_entropy_mean -1.9 / train/policy_entropy_min -3.48 / train/policy_entropy_std 1.09 / 
train/policy_logprob_mag 10.14 / train/policy_logprob_max 5.32 / train/policy_logprob_mean 1.9 / train/policy_logprob_min -10.14 / train/policy_logprob_std 1.81 / train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.18 / 
train/policy_randomness_min 6.4e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 46.79 / train/post_ent_max 46.79 / train/post_ent_mean 34.91 / train/post_ent_min 19.78 / train/post_ent_std 4.73 / train/prior_ent_mag 76.08 / train/prior_ent_max 76.08 / 
train/prior_ent_mean 38.8 / train/prior_ent_min 24.27 / train/prior_ent_std 6.72 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.45 / train/reward_avg 0.16 / train/reward_loss_mean 0.11 / train/reward_loss_std 0.27 / train/reward_max_data 1.69 / train/reward_max_pred 
1.67 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred 0.16 / train/reward_rate 0.17 / train_stats/mean_log_entropy -2.06 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.2e-10 / report/cont_loss_std 4.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 5.95 / 
report/image_loss_mean 1.39 / report/image_loss_std 1.04 / report/model_loss_mean 3.79 / report/model_loss_std 4.34 / report/post_ent_mag 47.98 / report/post_ent_max 47.98 / report/post_ent_mean 35.49 / report/post_ent_min 20.47 / report/post_ent_std 4.29 / 
report/prior_ent_mag 76.04 / report/prior_ent_max 76.04 / report/prior_ent_mean 39.21 / report/prior_ent_min 26.7 / report/prior_ent_std 6.24 / report/rep_loss_mean 3.78 / report/rep_loss_std 5.95 / report/reward_avg 0.17 / report/reward_loss_mean 0.12 / 
report/reward_loss_std 0.32 / report/reward_max_data 1.76 / report/reward_max_pred 1.65 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.71 / report/reward_pred 0.17 / report/reward_rate 0.17 / 
eval/cont_avg 1 / eval/cont_loss_mean 7.6e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.26 / eval/dyn_loss_std 7.36 / 
eval/image_loss_mean 1.85 / eval/image_loss_std 2.92 / eval/model_loss_mean 5.11 / eval/model_loss_std 6.69 / eval/post_ent_mag 46.77 / eval/post_ent_max 46.77 / eval/post_ent_mean 34.8 / eval/post_ent_min 20.77 / eval/post_ent_std 3.89 / eval/prior_ent_mag 76.04 / 
eval/prior_ent_max 76.04 / eval/prior_ent_mean 38.9 / eval/prior_ent_min 25.66 / eval/prior_ent_std 6.09 / eval/rep_loss_mean 5.26 / eval/rep_loss_std 7.36 / eval/reward_avg 0.09 / eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.51 / 
eval/reward_max_pred 1.27 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.78 / eval/reward_pred 0.09 / eval/reward_rate 0.13 / replay/size 1e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 
3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 
1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3822 / timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 456.08 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / 
timer/agent.policy_count 7329 / timer/agent.policy_total 16.14 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1911 / timer/agent.train_total 245.3 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.48

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 100000 Counter(100000) 99937
Saved chunk: 20230921T233821F234046-4zCnc8RWDYoeu7jFYJdJR5-7yIUgl0CiAIeQkWyKIjELi-1024.npz
eval_Episode has 500 steps and return 195.4.
train_Episode has 500 steps and return 198.3.
Saved chunk: 20230921T233848F015050-27BFJFUe00fmMRgVdqWzRq-2QaiPpc2NM6dxQ8FZiuLaN-1024.npz
Starting evaluation at step 100500 Counter(100500) 100437
eval_Episode has 500 steps and return 254.8.
train_Episode has 500 steps and return 208.3.
Starting evaluation at step 101000 Counter(101000) 100937
Saved chunk: 20230921T233940F880494-7yIUgl0CiAIeQkWyKIjELi-3HbWlEwQySY3ZNrnv53ObM-1024.npz
eval_Episode has 500 steps and return 240.7.
train_Episode has 500 steps and return 204.1.
Saved chunk: 20230921T234009F516897-2QaiPpc2NM6dxQ8FZiuLaN-583eKwUDAKcPeUcXI9uuAK-1024.npz
Starting evaluation at step 101500 Counter(101500) 101437
eval_Episode has 500 steps and return 219.6.
train_Episode has 500 steps and return 193.7.
Starting evaluation at step 102000 Counter(102000) 101937
Saved chunk: 20230921T234100F391273-3HbWlEwQySY3ZNrnv53ObM-6OQS8ogeJ0PKZ0RbT4vKsP-1024.npz
eval_Episode has 500 steps and return 219.0.
train_Episode has 500 steps and return 196.2.
Saved chunk: 20230921T234130F579121-583eKwUDAKcPeUcXI9uuAK-026auRkTlYjR5oe2ZDeTKJ-1024.npz
Starting evaluation at step 102500 Counter(102500) 102437
eval_Episode has 500 steps and return 216.1.
train_Episode has 500 steps and return 206.6.
Starting evaluation at step 103000 Counter(103000) 102937
Saved chunk: 20230921T234219F734677-6OQS8ogeJ0PKZ0RbT4vKsP-5mqXI0JEoEbCnqZEyQ4HxE-1024.npz
eval_Episode has 500 steps and return 231.2.
train_Episode has 500 steps and return 214.1.
Saved chunk: 20230921T234251F363144-026auRkTlYjR5oe2ZDeTKJ-2uOwP5Awon4DemA14yW83p-1024.npz
Starting evaluation at step 103500 Counter(103500) 103437
eval_Episode has 500 steps and return 235.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 207166 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 235.28 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 214.14 / episode/reward_rate 0.39 / train/action_mag 3.43 / train/action_max 3.26 / train/action_mean -0.04 / train/action_min -3.01 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 5e4 / train/actor_opt_loss -39.41 / train/adv_mag 0.41 / train/adv_max 0.37 / train/adv_mean 4.6e-3
/ train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.95 / train/dyn_loss_std 6.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 5e4 / 
train/extr_critic_critic_opt_loss 7848.97 / train/extr_critic_mag 157.6 / train/extr_critic_max 157.6 / train/extr_critic_mean 146.79 / train/extr_critic_min 101.89 / train/extr_critic_std 11.2 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 158.25 / train/extr_return_raw_max 158.25 / train/extr_return_raw_mean 146.98 / train/extr_return_raw_min
106.28 / train/extr_return_raw_std 11.29 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.19 / train/extr_reward_min 0 / train/extr_reward_std 0.41 / train/image_loss_mean 1.42 / train/image_loss_std 1.18 / train/model_loss_mean 3.91 
/ train/model_loss_std 4.76 / train/model_opt_grad_norm 9.68 / train/model_opt_grad_steps 5e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8085.11 / train/policy_entropy_mag 3.79 / 
train/policy_entropy_max 3.25 / train/policy_entropy_mean -1.97 / train/policy_entropy_min -3.48 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.88 / train/policy_logprob_max 5.32 / train/policy_logprob_mean 1.97 / train/policy_logprob_min -9.88 / 
train/policy_logprob_std 1.8 / train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 6e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 47.41 / train/post_ent_max 47.41 / 
train/post_ent_mean 35.44 / train/post_ent_min 19.91 / train/post_ent_std 4.8 / train/prior_ent_mag 76.43 / train/prior_ent_max 76.43 / train/prior_ent_mean 39.41 / train/prior_ent_min 24.53 / train/prior_ent_std 6.71 / train/rep_loss_mean 3.95 / train/rep_loss_std 6.47
/ train/reward_avg 0.18 / train/reward_loss_mean 0.12 / train/reward_loss_std 0.28 / train/reward_max_data 1.72 / train/reward_max_pred 1.69 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred 
0.18 / train/reward_rate 0.19 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.17 / report/cont_avg 1 / report/cont_loss_mean 8.7e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 8.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.96 / report/dyn_loss_std 6.43 / report/image_loss_mean 1.45 / report/image_loss_std 1.44 / report/model_loss_mean 3.91 / report/model_loss_std 4.95 / report/post_ent_mag 
48.93 / report/post_ent_max 48.93 / report/post_ent_mean 35.01 / report/post_ent_min 21.54 / report/post_ent_std 4.8 / report/prior_ent_mag 76.7 / report/prior_ent_max 76.7 / report/prior_ent_mean 39.06 / report/prior_ent_min 24.18 / report/prior_ent_std 6.62 / 
report/rep_loss_mean 3.96 / report/rep_loss_std 6.43 / report/reward_avg 0.13 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.24 / report/reward_max_data 1.85 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.64 / report/reward_pred 0.13 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 5.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.25 / eval/dyn_loss_std 8.8 / eval/image_loss_mean 2.63 / eval/image_loss_std 3.03 / eval/model_loss_mean 7.1 / eval/model_loss_std 7.63 / eval/post_ent_mag 46.1 / eval/post_ent_max 
46.1 / eval/post_ent_mean 34.01 / eval/post_ent_min 17.98 / eval/post_ent_std 5.76 / eval/prior_ent_mag 76.7 / eval/prior_ent_max 76.7 / eval/prior_ent_mean 39.38 / eval/prior_ent_min 26.6 / eval/prior_ent_std 6.46 / eval/rep_loss_mean 7.25 / eval/rep_loss_std 8.8 / 
eval/reward_avg 0.15 / eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.51 / eval/reward_max_pred 1.48 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-3 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.15 / 
eval/reward_rate 0.18 / replay/size 1e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3760 / timer/env.step_total 19.45 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.3 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-4 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.24 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.7e-3 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1880 / 
timer/agent.train_total 241.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T234412F116433-2uOwP5Awon4DemA14yW83p-0000000000000000000000-176.npz
Saved chunk: 20230921T234338F924212-5mqXI0JEoEbCnqZEyQ4HxE-0000000000000000000000-882.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 222.8.
Starting evaluation at step 104000 Counter(104000) 103937
Saved chunk: 20230921T234338F924212-5mqXI0JEoEbCnqZEyQ4HxE-3RGKenyZvYztCiKw4uXnU1-1024.npz
eval_Episode has 500 steps and return 250.1.
train_Episode has 500 steps and return 208.0.
Saved chunk: 20230921T234412F116433-2uOwP5Awon4DemA14yW83p-0T8DznNVSuEV2GgtrxQugq-1024.npz
Starting evaluation at step 104500 Counter(104500) 104437
eval_Episode has 500 steps and return 234.0.
train_Episode has 500 steps and return 216.6.
Starting evaluation at step 105000 Counter(105000) 104937
Saved chunk: 20230921T234459F174898-3RGKenyZvYztCiKw4uXnU1-6ncbrSCRMzLXdGIDGIuaJZ-1024.npz
eval_Episode has 500 steps and return 208.7.
train_Episode has 500 steps and return 109.8.
Saved chunk: 20230921T234534F129301-0T8DznNVSuEV2GgtrxQugq-6ZYRJUziQDr8N1gwh5o6dU-1024.npz
Starting evaluation at step 105500 Counter(105500) 105437
eval_Episode has 500 steps and return 232.0.
train_Episode has 500 steps and return 195.1.
Starting evaluation at step 106000 Counter(106000) 105937
Saved chunk: 20230921T234618F683795-6ncbrSCRMzLXdGIDGIuaJZ-4d8PnfzPdjzT9eJ5oby8yp-1024.npz
eval_Episode has 500 steps and return 233.5.
train_Episode has 500 steps and return 188.2.
Saved chunk: 20230921T234655F131701-6ZYRJUziQDr8N1gwh5o6dU-5VxybtMbqQTvTnIMhc08XL-1024.npz
Starting evaluation at step 106500 Counter(106500) 106437
eval_Episode has 500 steps and return 236.1.
train_Episode has 500 steps and return 207.5.
Starting evaluation at step 107000 Counter(107000) 106937
Saved chunk: 20230921T234738F020549-4d8PnfzPdjzT9eJ5oby8yp-3rvi2RGPUgNaFYEflK88aO-1024.npz
eval_Episode has 500 steps and return 251.7.
train_Episode has 500 steps and return 169.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 214774 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 169.83 / episode/reward_rate 0.34 / eval_episode/length 500 / eval_episode/score 251.69 / eval_episode/reward_rate 0.44 / train/action_mag 3.43 / train/action_max 3.14 / train/action_mean -0.02 / train/action_min -3.28 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 5.2e4 / train/actor_opt_loss -52.11 / train/adv_mag 0.42 / train/adv_max 0.39 / train/adv_mean 
5.9e-3 / train/adv_min -0.29 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 8.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / 
train/extr_critic_critic_opt_grad_steps 5.2e4 / train/extr_critic_critic_opt_loss 8823.17 / train/extr_critic_mag 162.23 / train/extr_critic_max 162.23 / train/extr_critic_mean 151.84 / train/extr_critic_min 114.05 / train/extr_critic_std 9.85 / 
train/extr_return_normed_mag 1.28 / train/extr_return_normed_max 1.06 / train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 162.75 / 
train/extr_return_raw_max 162.75 / train/extr_return_raw_mean 152.06 / train/extr_return_raw_min 117.45 / train/extr_return_raw_std 9.91 / train/extr_reward_mag 1.89 / train/extr_reward_max 1.89 / train/extr_reward_mean 0.19 / train/extr_reward_min 0 / 
train/extr_reward_std 0.42 / train/image_loss_mean 1.41 / train/image_loss_std 1.15 / train/model_loss_mean 3.91 / train/model_loss_std 4.76 / train/model_opt_grad_norm 9.44 / train/model_opt_grad_steps 5.2e4 / train/model_opt_loss 3.6e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9263.16 / train/policy_entropy_mag 3.87 / train/policy_entropy_max 3.7 / train/policy_entropy_mean -2.08 / train/policy_entropy_min -3.49 / train/policy_entropy_std 1.13 / 
train/policy_logprob_mag 10.1 / train/policy_logprob_max 5.34 / train/policy_logprob_mean 2.08 / train/policy_logprob_min -10.1 / train/policy_logprob_std 1.83 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.16 / 
train/policy_randomness_min 4.9e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 47.58 / train/post_ent_max 47.58 / train/post_ent_mean 35.8 / train/post_ent_min 20.01 / train/post_ent_std 4.91 / train/prior_ent_mag 76.81 / train/prior_ent_max 76.81 / 
train/prior_ent_mean 39.79 / train/prior_ent_min 24.92 / train/prior_ent_std 6.76 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.51 / train/reward_avg 0.18 / train/reward_loss_mean 0.12 / train/reward_loss_std 0.28 / train/reward_max_data 1.72 / train/reward_max_pred
1.71 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred 0.18 / train/reward_rate 0.19 / train_stats/mean_log_entropy -2.31 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1e-10 / report/cont_loss_std 3.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.17 / report/dyn_loss_std 7.12 / 
report/image_loss_mean 1.37 / report/image_loss_std 1.14 / report/model_loss_mean 4 / report/model_loss_std 5.16 / report/post_ent_mag 49.35 / report/post_ent_max 49.35 / report/post_ent_mean 36.56 / report/post_ent_min 19.19 / report/post_ent_std 4.93 / 
report/prior_ent_mag 76.84 / report/prior_ent_max 76.84 / report/prior_ent_mean 40.54 / report/prior_ent_min 26.67 / report/prior_ent_std 6.72 / report/rep_loss_mean 4.17 / report/rep_loss_std 7.12 / report/reward_avg 0.18 / report/reward_loss_mean 0.12 / 
report/reward_loss_std 0.3 / report/reward_max_data 1.56 / report/reward_max_pred 1.53 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.62 / report/reward_pred 0.18 / report/reward_rate 0.19 / 
eval/cont_avg 1 / eval/cont_loss_mean 8.7e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.34 / eval/dyn_loss_std 7.65 / 
eval/image_loss_mean 1.83 / eval/image_loss_std 2.6 / eval/model_loss_mean 5.16 / eval/model_loss_std 6.63 / eval/post_ent_mag 46.75 / eval/post_ent_max 46.75 / eval/post_ent_mean 35.63 / eval/post_ent_min 19.71 / eval/post_ent_std 4.44 / eval/prior_ent_mag 76.84 / 
eval/prior_ent_max 76.84 / eval/prior_ent_mean 40.08 / eval/prior_ent_min 25.82 / eval/prior_ent_std 6.35 / eval/rep_loss_mean 5.34 / eval/rep_loss_std 7.65 / eval/reward_avg 0.13 / eval/reward_loss_mean 0.13 / eval/reward_loss_std 0.5 / eval/reward_max_data 1.63 / 
eval/reward_max_pred 1.65 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-3 / eval/reward_pos_acc 0.96 / eval/reward_pos_loss 0.83 / eval/reward_pred 0.13 / eval/reward_rate 0.16 / replay/size 1.1e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg
3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 
1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3804 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 455.7 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / 
timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.4 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11
/ timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.96 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 107500 Counter(107500) 107437
eval_Episode has 500 steps and return 229.3.
Saved chunk: 20230921T234815F957989-5VxybtMbqQTvTnIMhc08XL-3Uxl3TrAKGlaXBMEmg2tQU-1024.npz
train_Episode has 500 steps and return 218.0.
Starting evaluation at step 108000 Counter(108000) 107937
Saved chunk: 20230921T234857F173658-3rvi2RGPUgNaFYEflK88aO-2gOegs4qvjKE7sGpfVoTz6-1024.npz
eval_Episode has 500 steps and return 260.8.
train_Episode has 500 steps and return 219.9.
Starting evaluation at step 108500 Counter(108500) 108437
eval_Episode has 500 steps and return 266.9.
Saved chunk: 20230921T234940F989322-3Uxl3TrAKGlaXBMEmg2tQU-7FuLSQ2YEhDJ98cZt8Jhwo-1024.npz
train_Episode has 500 steps and return 231.9.
Starting evaluation at step 109000 Counter(109000) 108937
Saved chunk: 20230921T235018F236860-2gOegs4qvjKE7sGpfVoTz6-52cEVQiXaZz0lqqWYigtgo-1024.npz
eval_Episode has 500 steps and return 221.3.
train_Episode has 500 steps and return 192.3.
Starting evaluation at step 109500 Counter(109500) 109437
eval_Episode has 500 steps and return 218.6.
Saved chunk: 20230921T235103F048591-7FuLSQ2YEhDJ98cZt8Jhwo-7KnexbGyVC4QQeTYWE8pJ3-1024.npz
train_Episode has 500 steps and return 228.3.
Starting evaluation at step 110000 Counter(110000) 109937
Saved chunk: 20230921T235137F735088-52cEVQiXaZz0lqqWYigtgo-2CslkZSrq2bVRBKPTBpn3O-1024.npz
eval_Episode has 500 steps and return 241.6.
train_Episode has 500 steps and return 202.2.
Starting evaluation at step 110500 Counter(110500) 110437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235224F054670-7KnexbGyVC4QQeTYWE8pJ3-3JYomsn1E5twkIUJNbkpnA-1024.npz
train_Episode has 500 steps and return 232.6.
Starting evaluation at step 111000 Counter(111000) 110937
Saved chunk: 20230921T235257F118023-2CslkZSrq2bVRBKPTBpn3O-3Xo04r9jAxgDR1PvuoDPYU-1024.npz
eval_Episode has 500 steps and return 238.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 222262 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 238.89 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 232.59 / episode/reward_rate 0.42 / train/action_mag 3.6 / train/action_max 3.25 / train/action_mean -9.5e-3 / train/action_min -3.44 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 5.4e4 / train/actor_opt_loss -48.08 / train/adv_mag 0.46 / train/adv_max 0.43 / train/adv_mean 
5.5e-3 / train/adv_min -0.25 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 4.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 / train/cont_rate 1 
/ train/dyn_loss_mean 3.92 / train/dyn_loss_std 6.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 5.4e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 167.79 / train/extr_critic_max 167.79 / train/extr_critic_mean 156.48 / train/extr_critic_min 107.81 / train/extr_critic_std 12.42 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 168.23 / train/extr_return_raw_max 168.23 / train/extr_return_raw_mean 156.7 / train/extr_return_raw_min 
113.81 / train/extr_return_raw_std 12.47 / train/extr_reward_mag 1.89 / train/extr_reward_max 1.89 / train/extr_reward_mean 0.19 / train/extr_reward_min 0 / train/extr_reward_std 0.42 / train/image_loss_mean 1.38 / train/image_loss_std 1.15 / train/model_loss_mean 3.86 
/ train/model_loss_std 4.77 / train/model_opt_grad_norm 9.31 / train/model_opt_grad_steps 5.4e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.34 / train/policy_entropy_max
4.27 / train/policy_entropy_mean -1.9 / train/policy_entropy_min -3.49 / train/policy_entropy_std 1.33 / train/policy_logprob_mag 10.54 / train/policy_logprob_max 5.35 / train/policy_logprob_mean 1.9 / train/policy_logprob_min -10.54 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 4.7e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 48.1 / train/post_ent_max 48.1 / train/post_ent_mean 36.16 / 
train/post_ent_min 20.24 / train/post_ent_std 5.08 / train/prior_ent_mag 77.1 / train/prior_ent_max 77.1 / train/prior_ent_mean 40.09 / train/prior_ent_min 25.11 / train/prior_ent_std 6.88 / train/rep_loss_mean 3.92 / train/rep_loss_std 6.52 / train/reward_avg 0.19 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.28 / train/reward_max_data 1.74 / train/reward_max_pred 1.72 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred 0.19 / train/reward_rate 
0.2 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.34 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.44 / report/dyn_loss_std 6.11 / report/image_loss_mean 1.11 / report/image_loss_std 0.77 / report/model_loss_mean 3.3 / report/model_loss_std 4.24 / report/post_ent_mag 49.35 / report/post_ent_max 49.35 / 
report/post_ent_mean 37.01 / report/post_ent_min 20.74 / report/post_ent_std 4.82 / report/prior_ent_mag 77.24 / report/prior_ent_max 77.24 / report/prior_ent_mean 40.4 / report/prior_ent_min 27.06 / report/prior_ent_std 6.76 / report/rep_loss_mean 3.44 / 
report/rep_loss_std 6.11 / report/reward_avg 0.21 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.31 / report/reward_max_data 1.74 / report/reward_max_pred 1.74 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.64 / report/reward_pred 0.21 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 7.7e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.77 / eval/dyn_loss_std 9.16 / eval/image_loss_mean 2.33 / eval/image_loss_std 3.11 / eval/model_loss_mean 6.52 / eval/model_loss_std 8.18 / eval/post_ent_mag 49.36 / eval/post_ent_max 49.36 / eval/post_ent_mean 
36.01 / eval/post_ent_min 19.62 / eval/post_ent_std 4.72 / eval/prior_ent_mag 77.24 / eval/prior_ent_max 77.24 / eval/prior_ent_mean 40.69 / eval/prior_ent_min 28.06 / eval/prior_ent_std 6.55 / eval/rep_loss_mean 6.77 / eval/rep_loss_std 9.16 / eval/reward_avg 0.14 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.49 / eval/reward_max_pred 1.54 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.71 / eval/reward_pred 0.14 / eval/reward_rate 0.17 / 
replay/size 1.1e5 / replay/inserts 3744 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3744 / timer/env.step_total 19.33 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 7.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 446.28 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7752 / timer/agent.policy_total 17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1872 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1872 / timer/agent.train_total 242.06 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.01 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 24.95

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 208.4.
Starting evaluation at step 111500 Counter(111500) 111437
eval_Episode has 500 steps and return 177.6.
Saved chunk: 20230921T235344F927007-3JYomsn1E5twkIUJNbkpnA-43UgfMK0m77YHgoZnCosBp-1024.npz
train_Episode has 500 steps and return 212.3.
Starting evaluation at step 112000 Counter(112000) 111937
Saved chunk: 20230921T235416F318077-3Xo04r9jAxgDR1PvuoDPYU-3FhYP8iHZuBlunj9FLE7q0-1024.npz
eval_Episode has 500 steps and return 254.7.
train_Episode has 500 steps and return 226.2.
Starting evaluation at step 112500 Counter(112500) 112437
eval_Episode has 500 steps and return 227.3.
Saved chunk: 20230921T235506F608937-43UgfMK0m77YHgoZnCosBp-5yw77ynH6nncnzGjHhVm7C-1024.npz
train_Episode has 500 steps and return 126.1.
Starting evaluation at step 113000 Counter(113000) 112937
Saved chunk: 20230921T235536F656650-3FhYP8iHZuBlunj9FLE7q0-5fv119trEgq0MKN5DUfa3L-1024.npz
eval_Episode has 500 steps and return 251.3.
train_Episode has 500 steps and return 229.2.
Starting evaluation at step 113500 Counter(113500) 113437
eval_Episode has 500 steps and return 228.4.
Saved chunk: 20230921T235627F786190-5yw77ynH6nncnzGjHhVm7C-56Mh3ROCKVByR5O7I2gnXr-1024.npz
train_Episode has 500 steps and return 183.7.
Starting evaluation at step 114000 Counter(114000) 113937
Saved chunk: 20230921T235656F194544-5fv119trEgq0MKN5DUfa3L-0ksmpSLOgdoWyFDqQzRkWn-1024.npz
eval_Episode has 500 steps and return 255.9.
train_Episode has 500 steps and return 230.7.
Starting evaluation at step 114500 Counter(114500) 114437
eval_Episode has 500 steps and return 242.4.
Saved chunk: 20230921T235748F834926-56Mh3ROCKVByR5O7I2gnXr-5Vtzm5KCiAOZXOA9VCHBfh-1024.npz
train_Episode has 500 steps and return 207.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 229870 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 207.1 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 242.43 / eval_episode/reward_rate 0.41 / train/action_mag 3.32 / train/action_max 3.1 / train/action_mean 0.01 / train/action_min -3.12 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 5.6e4 / train/actor_opt_loss -48.3 / train/adv_mag 0.61 / train/adv_max 0.59 / train/adv_mean 5.6e-3 / train/adv_min
-0.27 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.98 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 5.6e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 173.82 / train/extr_critic_max 173.82 / train/extr_critic_mean 163.36 / train/extr_critic_min 112.39 / train/extr_critic_std 11.27 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 174.56 / train/extr_return_raw_max 174.56 / train/extr_return_raw_mean 163.56 / 
train/extr_return_raw_min 123.87 / train/extr_return_raw_std 11.29 / train/extr_reward_mag 1.89 / train/extr_reward_max 1.89 / train/extr_reward_mean 0.2 / train/extr_reward_min 0 / train/extr_reward_std 0.43 / train/image_loss_mean 1.39 / train/image_loss_std 1.16 / 
train/model_loss_mean 3.91 / train/model_loss_std 4.82 / train/model_opt_grad_norm 9.59 / train/model_opt_grad_steps 5.6e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.98
/ train/policy_entropy_max 3.79 / train/policy_entropy_mean -2.17 / train/policy_entropy_min -3.5 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.92 / train/policy_logprob_max 5.35 / train/policy_logprob_mean 2.17 / train/policy_logprob_min -9.92 / 
train/policy_logprob_std 1.8 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 4.2e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 48.42 / train/post_ent_max 48.42 / 
train/post_ent_mean 36.62 / train/post_ent_min 20.24 / train/post_ent_std 5.12 / train/prior_ent_mag 77.47 / train/prior_ent_max 77.47 / train/prior_ent_mean 40.61 / train/prior_ent_min 25.38 / train/prior_ent_std 6.84 / train/rep_loss_mean 3.98 / train/rep_loss_std 
6.57 / train/reward_avg 0.2 / train/reward_loss_mean 0.13 / train/reward_loss_std 0.29 / train/reward_max_data 1.75 / train/reward_max_pred 1.74 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / 
train/reward_pred 0.2 / train/reward_rate 0.2 / train_stats/mean_log_entropy -2.4 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.3e-11 / report/cont_loss_std 2.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 7.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 6.16 / report/image_loss_mean 1.25 / report/image_loss_std 1.41 / report/model_loss_mean 3.55 / report/model_loss_std 4.84 / 
report/post_ent_mag 50.23 / report/post_ent_max 50.23 / report/post_ent_mean 36.12 / report/post_ent_min 19.96 / report/post_ent_std 5.17 / report/prior_ent_mag 77.71 / report/prior_ent_max 77.71 / report/prior_ent_mean 39.6 / report/prior_ent_min 23.15 / 
report/prior_ent_std 7.17 / report/rep_loss_mean 3.66 / report/rep_loss_std 6.16 / report/reward_avg 0.15 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.25 / report/reward_max_data 1.76 / report/reward_max_pred 1.78 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.64 / report/reward_pred 0.15 / report/reward_rate 0.15 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.8 / eval/dyn_loss_std 8.72 / eval/image_loss_mean 2.43 / eval/image_loss_std 2.91 / eval/model_loss_mean 6.68 / eval/model_loss_std 7.63 / eval/post_ent_mag 
50.06 / eval/post_ent_max 50.06 / eval/post_ent_mean 36.43 / eval/post_ent_min 17.45 / eval/post_ent_std 5.84 / eval/prior_ent_mag 77.71 / eval/prior_ent_max 77.71 / eval/prior_ent_mean 41.19 / eval/prior_ent_min 27.61 / eval/prior_ent_std 6.68 / eval/rep_loss_mean 6.8 
/ eval/rep_loss_std 8.72 / eval/reward_avg 0.19 / eval/reward_loss_mean 0.16 / eval/reward_loss_std 0.55 / eval/reward_max_data 1.79 / eval/reward_max_pred 1.75 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.71
/ eval/reward_pred 0.19 / eval/reward_rate 0.21 / replay/size 1.1e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3804 / timer/env.step_total 19.67
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.12 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 1.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.39 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.7e-4 / 
timer/agent.train_count 1902 / timer/agent.train_total 244.96 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / 
timer/dataset_eval_max 3.9e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 115000 Counter(115000) 114937
Saved chunk: 20230921T235909F582625-5Vtzm5KCiAOZXOA9VCHBfh-0000000000000000000000-312.npz
Saved chunk: 20230921T235815F544697-0ksmpSLOgdoWyFDqQzRkWn-0000000000000000000000-640.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230921T235815F544697-0ksmpSLOgdoWyFDqQzRkWn-3zVAhxDDQU6yN8RmYkXSmK-1024.npz
eval_Episode has 500 steps and return 225.9.
train_Episode has 500 steps and return 216.2.
Starting evaluation at step 115500 Counter(115500) 115437
eval_Episode has 500 steps and return 244.3.
Saved chunk: 20230921T235909F582625-5Vtzm5KCiAOZXOA9VCHBfh-48fLiUFTiYUX2uOWGCMvGf-1024.npz
train_Episode has 500 steps and return 241.0.
Starting evaluation at step 116000 Counter(116000) 115937
Saved chunk: 20230921T235935F836245-3zVAhxDDQU6yN8RmYkXSmK-2y7mrLXJ11D5meUGWetw3W-1024.npz
eval_Episode has 500 steps and return 258.0.
train_Episode has 500 steps and return 248.0.
Starting evaluation at step 116500 Counter(116500) 116437
eval_Episode has 500 steps and return 246.3.
train_Episode has 500 steps and return 226.9.
Saved chunk: 20230922T000031F702747-48fLiUFTiYUX2uOWGCMvGf-4MjPKo0OIpTfFjZ8NqbqJj-1024.npz
Starting evaluation at step 117000 Counter(117000) 116937
Saved chunk: 20230922T000055F330456-2y7mrLXJ11D5meUGWetw3W-2iUcEmnmuomYX3A5Y0NFR5-1024.npz
eval_Episode has 500 steps and return 240.5.
train_Episode has 500 steps and return 221.0.
Starting evaluation at step 117500 Counter(117500) 117437
eval_Episode has 500 steps and return 241.5.
train_Episode has 500 steps and return 232.4.
Saved chunk: 20230922T000152F611353-4MjPKo0OIpTfFjZ8NqbqJj-5SC8fDBO3bBqsp79RuL9rR-1024.npz
Starting evaluation at step 118000 Counter(118000) 117937
Saved chunk: 20230922T000214F644443-2iUcEmnmuomYX3A5Y0NFR5-1cnaslogxvjTlLdWlrsa3P-1024.npz
eval_Episode has 500 steps and return 251.7.
train_Episode has 500 steps and return 223.6.
Starting evaluation at step 118500 Counter(118500) 118437
eval_Episode has 500 steps and return 268.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 237386 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 268.84 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 223.56 / episode/reward_rate 0.39 / train/action_mag 3.49 / train/action_max 3.18 / train/action_mean 9.3e-3 / train/action_min -3.31 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 5.8e4 / train/actor_opt_loss -29.05 / train/adv_mag 0.6 / train/adv_max 0.57 / train/adv_mean 
3.6e-3 / train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 9.4e-11 / train/cont_loss_std 4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.4e-11 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.54 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 5.8e4 / 
train/extr_critic_critic_opt_loss 9801.67 / train/extr_critic_mag 178.4 / train/extr_critic_max 178.4 / train/extr_critic_mean 168.51 / train/extr_critic_min 118.15 / train/extr_critic_std 11.2 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 179.64 / train/extr_return_raw_max 179.64 / train/extr_return_raw_mean 168.66 / 
train/extr_return_raw_min 127.85 / train/extr_return_raw_std 11.22 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.21 / train/extr_reward_min 0 / train/extr_reward_std 0.45 / train/image_loss_mean 1.36 / train/image_loss_std 1.15 / 
train/model_loss_mean 3.86 / train/model_loss_std 4.79 / train/model_opt_grad_norm 9.32 / train/model_opt_grad_steps 5.8e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.94
/ train/policy_entropy_max 3.79 / train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.5 / train/policy_entropy_std 1.15 / train/policy_logprob_mag 10 / train/policy_logprob_max 5.35 / train/policy_logprob_mean 2.04 / train/policy_logprob_min -10 / 
train/policy_logprob_std 1.84 / train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 4.2e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 48.75 / train/post_ent_max 48.75 / 
train/post_ent_mean 36.84 / train/post_ent_min 20.42 / train/post_ent_std 5.22 / train/prior_ent_mag 77.68 / train/prior_ent_max 77.68 / train/prior_ent_mean 40.79 / train/prior_ent_min 25.32 / train/prior_ent_std 6.93 / train/rep_loss_mean 3.94 / train/rep_loss_std 
6.54 / train/reward_avg 0.2 / train/reward_loss_mean 0.13 / train/reward_loss_std 0.28 / train/reward_max_data 1.77 / train/reward_max_pred 1.76 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / 
train/reward_pred 0.2 / train/reward_rate 0.2 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.35 / report/cont_avg 1 / report/cont_loss_mean 7.2e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 7.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.91 / report/dyn_loss_std 6.63 / report/image_loss_mean 1.41 / report/image_loss_std 1.22 / report/model_loss_mean 3.89 / report/model_loss_std 4.82 / 
report/post_ent_mag 48.89 / report/post_ent_max 48.89 / report/post_ent_mean 36.63 / report/post_ent_min 21.01 / report/post_ent_std 5.5 / report/prior_ent_mag 77.61 / report/prior_ent_max 77.61 / report/prior_ent_mean 40.44 / report/prior_ent_min 24.46 / 
report/prior_ent_std 7.15 / report/rep_loss_mean 3.91 / report/rep_loss_std 6.63 / report/reward_avg 0.21 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.31 / report/reward_max_data 1.79 / report/reward_max_pred 1.76 / report/reward_neg_acc 1 / 
report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.21 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 7.5e-11 / eval/cont_loss_std 3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 7.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.75 / eval/dyn_loss_std 8.9 / eval/image_loss_mean 2.52 / eval/image_loss_std 2.94 / eval/model_loss_mean 7.29 / eval/model_loss_std 7.7 / eval/post_ent_mag 
48.47 / eval/post_ent_max 48.47 / eval/post_ent_mean 35.69 / eval/post_ent_min 18.91 / eval/post_ent_std 5.43 / eval/prior_ent_mag 77.61 / eval/prior_ent_max 77.61 / eval/prior_ent_mean 41.12 / eval/prior_ent_min 27.66 / eval/prior_ent_std 6.11 / eval/rep_loss_mean 7.75
/ eval/rep_loss_std 8.9 / eval/reward_avg 0.14 / eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.52 / eval/reward_max_pred 1.52 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.69 / 
eval/reward_pred 0.14 / eval/reward_rate 0.16 / replay/size 1.2e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3758 / timer/env.step_total 19.39
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.73 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
4.3e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.3e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / timer/agent.policy_count 7766 / timer/agent.policy_total 
17.63 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1879 / timer/agent.train_total 241.61 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac
1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 224.8.
Saved chunk: 20230922T000313F340083-5SC8fDBO3bBqsp79RuL9rR-5AVk5fWzSKnOv9XUlTM55g-1024.npz
Starting evaluation at step 119000 Counter(119000) 118937
eval_Episode has 500 steps and return 252.8.
Saved chunk: 20230922T000333F720822-1cnaslogxvjTlLdWlrsa3P-3o96o7lLKIL6y9KumsNIjR-1024.npz
train_Episode has 500 steps and return 231.4.
Starting evaluation at step 119500 Counter(119500) 119437
eval_Episode has 500 steps and return 237.5.
train_Episode has 500 steps and return 226.3.
Saved chunk: 20230922T000434F704466-5AVk5fWzSKnOv9XUlTM55g-22GilrEpzcxU7X3ZV7Sixj-1024.npz
Starting evaluation at step 120000 Counter(120000) 119937
eval_Episode has 500 steps and return 259.1.
Saved chunk: 20230922T000453F693079-3o96o7lLKIL6y9KumsNIjR-2hQ0UdfBVRBFN6qZ1ctJ3g-1024.npz
train_Episode has 500 steps and return 224.2.
Starting evaluation at step 120500 Counter(120500) 120437
eval_Episode has 500 steps and return 263.7.
train_Episode has 500 steps and return 224.8.
Saved chunk: 20230922T000555F836376-22GilrEpzcxU7X3ZV7Sixj-3NpqXtOeUEcCG8CD5FPVsv-1024.npz
Starting evaluation at step 121000 Counter(121000) 120937
eval_Episode has 500 steps and return 264.5.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 121500 Counter(121500) 121437
Saved chunk: 20230922T000613F166004-2hQ0UdfBVRBFN6qZ1ctJ3g-4uUcaooCqVAU4maSxBpEz3-1024.npz
eval_Episode has 500 steps and return 234.5.
train_Episode has 500 steps and return 243.4.
Saved chunk: 20230922T000716F781549-3NpqXtOeUEcCG8CD5FPVsv-0Y6VK4gC7DTEDIqpXUSYq0-1024.npz
Starting evaluation at step 122000 Counter(122000) 121937
eval_Episode has 500 steps and return 261.8.
train_Episode has 500 steps and return 222.6.
Starting evaluation at step 122500 Counter(122500) 122437
Saved chunk: 20230922T000808F497040-4uUcaooCqVAU4maSxBpEz3-5WY1U3qd0W7u0lpPYntrIg-1024.npz
eval_Episode has 500 steps and return 281.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 245002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 222.64 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 281.01 / eval_episode/reward_rate 0.45 / train/action_mag 3.72 / train/action_max 3.17 / train/action_mean 9.1e-3 / train/action_min -3.68 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 6e4 / train/actor_opt_loss -20.9 / train/adv_mag 0.48 / train/adv_max 0.4 / train/adv_mean 2.7e-3 /
train/adv_min -0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 9.6e-11 / train/cont_loss_std 5.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.98 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 6e4 / 
train/extr_critic_critic_opt_loss 8534.84 / train/extr_critic_mag 180.34 / train/extr_critic_max 180.34 / train/extr_critic_mean 170.53 / train/extr_critic_min 126.26 / train/extr_critic_std 11.31 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.05 /
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 181.83 / train/extr_return_raw_max 181.83 / train/extr_return_raw_mean 170.64 / 
train/extr_return_raw_min 129.14 / train/extr_return_raw_std 11.37 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.22 / train/extr_reward_min 0 / train/extr_reward_std 0.46 / train/image_loss_mean 1.36 / train/image_loss_std 1.13 / 
train/model_loss_mean 3.88 / train/model_loss_std 4.79 / train/model_opt_grad_norm 9.3 / train/model_opt_grad_steps 6e4 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8376.96 / train/policy_entropy_mag 
4.16 / train/policy_entropy_max 4.1 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.5 / train/policy_entropy_std 1.29 / train/policy_logprob_mag 10.22 / train/policy_logprob_max 5.37 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.22 / 
train/policy_logprob_std 1.93 / train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.6e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 49 / train/post_ent_max 49 / 
train/post_ent_mean 37.15 / train/post_ent_min 20.37 / train/post_ent_std 5.29 / train/prior_ent_mag 77.95 / train/prior_ent_max 77.95 / train/prior_ent_mean 41.13 / train/prior_ent_min 25.47 / train/prior_ent_std 6.96 / train/rep_loss_mean 3.98 / train/rep_loss_std 
6.57 / train/reward_avg 0.21 / train/reward_loss_mean 0.13 / train/reward_loss_std 0.29 / train/reward_max_data 1.8 / train/reward_max_pred 1.8 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / 
train/reward_pred 0.21 / train/reward_rate 0.21 / train_stats/mean_log_entropy -1.48 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.5e-11 / report/cont_loss_std 7.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 9.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 6.62 / report/image_loss_mean 1.27 / report/image_loss_std 1.2 / report/model_loss_mean 3.57 / report/model_loss_std 4.91 / 
report/post_ent_mag 49.73 / report/post_ent_max 49.73 / report/post_ent_mean 36.7 / report/post_ent_min 21.03 / report/post_ent_std 5.04 / report/prior_ent_mag 78.13 / report/prior_ent_max 78.13 / report/prior_ent_mean 40.4 / report/prior_ent_min 27.32 / 
report/prior_ent_std 7 / report/rep_loss_mean 3.64 / report/rep_loss_std 6.62 / report/reward_avg 0.17 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.27 / report/reward_max_data 1.77 / report/reward_max_pred 1.76 / report/reward_neg_acc 1 / 
report/reward_neg_loss 3.8e-4 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.64 / report/reward_pred 0.17 / report/reward_rate 0.18 / eval/cont_avg 1 / eval/cont_loss_mean 8.5e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 8.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.99 / eval/dyn_loss_std 7.99 / eval/image_loss_mean 1.91 / eval/image_loss_std 2.58 / eval/model_loss_mean 5.65 / eval/model_loss_std 6.9 / eval/post_ent_mag 
48.76 / eval/post_ent_max 48.76 / eval/post_ent_mean 37.08 / eval/post_ent_min 19.76 / eval/post_ent_std 4.97 / eval/prior_ent_mag 78.13 / eval/prior_ent_max 78.13 / eval/prior_ent_mean 42.1 / eval/prior_ent_min 28.88 / eval/prior_ent_std 6.39 / eval/rep_loss_mean 5.99 
/ eval/rep_loss_std 7.99 / eval/reward_avg 0.23 / eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 
/ eval/reward_pred 0.23 / eval/reward_rate 0.23 / replay/size 1.2e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.41 / timer/env.step_count 3808 / timer/env.step_total 19.7 
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.09 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
5.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7816 / timer/agent.policy_total 17.35 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / 
timer/agent.train_count 1904 / timer/agent.train_total 244.99 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / 
timer/dataset_eval_max 3.7e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 202.3.
Saved chunk: 20230922T000837F517221-0Y6VK4gC7DTEDIqpXUSYq0-46xZdpzUeNU4gi44kTpkWI-1024.npz
Starting evaluation at step 123000 Counter(123000) 122937
eval_Episode has 500 steps and return 210.7.
train_Episode has 500 steps and return 248.0.
Starting evaluation at step 123500 Counter(123500) 123437
Saved chunk: 20230922T000927F494280-5WY1U3qd0W7u0lpPYntrIg-4P9BKVjQR993PuzrJ2uC2D-1024.npz
eval_Episode has 500 steps and return 252.0.
train_Episode has 500 steps and return 219.0.
Saved chunk: 20230922T000958F955083-46xZdpzUeNU4gi44kTpkWI-6PuTctnKHqVkAi8XSAXKcn-1024.npz
Starting evaluation at step 124000 Counter(124000) 123937
eval_Episode has 500 steps and return 215.4.
train_Episode has 500 steps and return 211.6.
Starting evaluation at step 124500 Counter(124500) 124437
Saved chunk: 20230922T001047F769713-4P9BKVjQR993PuzrJ2uC2D-7GwBQlDIArsCxyz9mrxdBg-1024.npz
eval_Episode has 500 steps and return 264.0.
train_Episode has 500 steps and return 222.1.
Saved chunk: 20230922T001120F034553-6PuTctnKHqVkAi8XSAXKcn-6lI4DzIeLYhRo5yl9ri2Uv-1024.npz
Starting evaluation at step 125000 Counter(125000) 124937
eval_Episode has 500 steps and return 257.7.
train_Episode has 500 steps and return 255.8.
Starting evaluation at step 125500 Counter(125500) 125437
Saved chunk: 20230922T001207F160405-7GwBQlDIArsCxyz9mrxdBg-6ZaR9iS0hxgousp4EHzzLs-1024.npz
eval_Episode has 500 steps and return 291.5.
train_Episode has 500 steps and return 248.5.
Saved chunk: 20230922T001240F967412-6lI4DzIeLYhRo5yl9ri2Uv-5izSvdYfPtP8jR8Oe8Ur3O-1024.npz
Starting evaluation at step 126000 Counter(126000) 125937
eval_Episode has 500 steps and return 263.3.
train_Episode has 500 steps and return 273.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 252622 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 273.19 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 263.26 / eval_episode/reward_rate 0.44 / train/action_mag 3.73 / train/action_max 3.28 / train/action_mean 0.03 / train/action_min -3.64 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 6.2e4 / train/actor_opt_loss -25.57 / train/adv_mag 0.46 / train/adv_max 0.43 / train/adv_mean 
3.2e-3 / train/adv_min -0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.6e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.6e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 4.02 / train/dyn_loss_std 6.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / 
train/extr_critic_critic_opt_grad_steps 6.2e4 / train/extr_critic_critic_opt_loss 7634.35 / train/extr_critic_mag 183.51 / train/extr_critic_max 183.51 / train/extr_critic_mean 172.25 / train/extr_critic_min 120.6 / train/extr_critic_std 12.49 / 
train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 184.06 / 
train/extr_return_raw_max 184.06 / train/extr_return_raw_mean 172.4 / train/extr_return_raw_min 127.87 / train/extr_return_raw_std 12.58 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.24 / train/extr_reward_min 0 / 
train/extr_reward_std 0.48 / train/image_loss_mean 1.36 / train/image_loss_std 1.14 / train/model_loss_mean 3.91 / train/model_loss_std 4.81 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 6.2e4 / train/model_opt_loss 2.5e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6368.42 / train/policy_entropy_mag 4.33 / train/policy_entropy_max 4.26 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.5 / train/policy_entropy_std 1.34 / 
train/policy_logprob_mag 10.33 / train/policy_logprob_max 5.38 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.33 / train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.17 / 
train/policy_randomness_min 3.4e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 49.4 / train/post_ent_max 49.4 / train/post_ent_mean 37.54 / train/post_ent_min 20.44 / train/post_ent_std 5.39 / train/prior_ent_mag 78.2 / train/prior_ent_max 78.2 / 
train/prior_ent_mean 41.56 / train/prior_ent_min 25.54 / train/prior_ent_std 6.97 / train/rep_loss_mean 4.02 / train/rep_loss_std 6.59 / train/reward_avg 0.22 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.82 / train/reward_max_pred
1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.22 / train/reward_rate 0.22 / train_stats/mean_log_entropy -2.44 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 6.8e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.32 / report/dyn_loss_std 6.74 / 
report/image_loss_mean 1.46 / report/image_loss_std 1.35 / report/model_loss_mean 4.2 / report/model_loss_std 5.21 / report/post_ent_mag 50.51 / report/post_ent_max 50.51 / report/post_ent_mean 38.12 / report/post_ent_min 18.21 / report/post_ent_std 4.86 / 
report/prior_ent_mag 78.9 / report/prior_ent_max 78.9 / report/prior_ent_mean 42.46 / report/prior_ent_min 28.23 / report/prior_ent_std 6.23 / report/rep_loss_mean 4.32 / report/rep_loss_std 6.74 / report/reward_avg 0.23 / report/reward_loss_mean 0.15 / 
report/reward_loss_std 0.32 / report/reward_max_data 1.88 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 7.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.64 / report/reward_pred 0.23 / report/reward_rate 0.22 / eval/cont_avg 
1 / eval/cont_loss_mean 7.6e-11 / eval/cont_loss_std 7.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.28 / eval/dyn_loss_std 8.53 / 
eval/image_loss_mean 2.48 / eval/image_loss_std 3.66 / eval/model_loss_mean 7 / eval/model_loss_std 8.09 / eval/post_ent_mag 49.94 / eval/post_ent_max 49.94 / eval/post_ent_mean 37.56 / eval/post_ent_min 16.99 / eval/post_ent_std 5.89 / eval/prior_ent_mag 78.9 / 
eval/prior_ent_max 78.9 / eval/prior_ent_mean 43.24 / eval/prior_ent_min 27.76 / eval/prior_ent_std 5.91 / eval/rep_loss_mean 7.28 / eval/rep_loss_std 8.53 / eval/reward_avg 0.2 / eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.59 / 
eval/reward_max_pred 1.58 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.66 / eval/reward_pred 0.2 / eval/reward_rate 0.22 / replay/size 1.3e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 
3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 
1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3810 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 458.15 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-4 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / 
timer/agent.policy_count 7317 / timer/agent.policy_total 16.33 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.5e-3 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1905 / timer/agent.train_total 245.18 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T001401F595469-5izSvdYfPtP8jR8Oe8Ur3O-0000000000000000000000-448.npz
Saved chunk: 20230922T001326F347955-6ZaR9iS0hxgousp4EHzzLs-0000000000000000000000-899.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 126500 Counter(126500) 126437
Saved chunk: 20230922T001326F347955-6ZaR9iS0hxgousp4EHzzLs-0xQZBpb5bDRIca0670qRTw-1024.npz
eval_Episode has 500 steps and return 271.1.
train_Episode has 500 steps and return 250.2.
Saved chunk: 20230922T001401F595469-5izSvdYfPtP8jR8Oe8Ur3O-1mrZaSnrGgzYGvxzJZG3TM-1024.npz
Starting evaluation at step 127000 Counter(127000) 126937
eval_Episode has 500 steps and return 247.2.
train_Episode has 500 steps and return 225.6.
Starting evaluation at step 127500 Counter(127500) 127437
Saved chunk: 20230922T001446F516945-0xQZBpb5bDRIca0670qRTw-3wsRXEcdM2q3yVyGjItE29-1024.npz
eval_Episode has 500 steps and return 273.8.
train_Episode has 500 steps and return 237.1.
Starting evaluation at step 128000 Counter(128000) 127937
Saved chunk: 20230922T001523F670540-1mrZaSnrGgzYGvxzJZG3TM-4jEkIBGPjkiPal5duubJzN-1024.npz
eval_Episode has 500 steps and return 279.9.
train_Episode has 500 steps and return 206.8.
Starting evaluation at step 128500 Counter(128500) 128437
Saved chunk: 20230922T001606F093145-3wsRXEcdM2q3yVyGjItE29-0qcLbh2JF7ZMYF2dqkhWNR-1024.npz
eval_Episode has 500 steps and return 255.9.
train_Episode has 500 steps and return 257.1.
Starting evaluation at step 129000 Counter(129000) 128937
eval_Episode has 500 steps and return 267.5.
Saved chunk: 20230922T001644F691973-4jEkIBGPjkiPal5duubJzN-2w9mVmyecF2qJXSncUaj5v-1024.npz
train_Episode has 500 steps and return 241.5.
Starting evaluation at step 129500 Counter(129500) 129437
Saved chunk: 20230922T001725F450943-0qcLbh2JF7ZMYF2dqkhWNR-7BFf2JSczTtY5ZuCtn6HoT-1024.npz
eval_Episode has 500 steps and return 260.8.
train_Episode has 500 steps and return 241.9.
Starting evaluation at step 130000 Counter(130000) 129937
eval_Episode has 500 steps and return 263.0.
Saved chunk: 20230922T001809F072466-2w9mVmyecF2qJXSncUaj5v-5a0ENwv48yBtx9MawE7fQa-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 260130 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 262.95 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 241.94 / episode/reward_rate 0.4 / train/action_mag 3.75 / train/action_max 3.38 / train/action_mean 0.02 / train/action_min -3.65 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 6.4e4 / train/actor_opt_loss -29.49 / train/adv_mag 0.47 / train/adv_max 0.43 / train/adv_mean 3.6e-3 / 
train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.9e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 6.4e4 / 
train/extr_critic_critic_opt_loss 7539.67 / train/extr_critic_mag 186.72 / train/extr_critic_max 186.72 / train/extr_critic_mean 174.97 / train/extr_critic_min 114.08 / train/extr_critic_std 14.43 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 187.36 / train/extr_return_raw_max 187.36 / train/extr_return_raw_mean 175.14 / train/extr_return_raw_min
120.57 / train/extr_return_raw_std 14.49 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.24 / train/extr_reward_min 0 / train/extr_reward_std 0.48 / train/image_loss_mean 1.31 / train/image_loss_std 1.12 / train/model_loss_mean 3.81 
/ train/model_loss_std 4.78 / train/model_opt_grad_norm 9.46 / train/model_opt_grad_steps 6.4e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.46 / train/policy_entropy_max
4.42 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.5 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.7 / train/policy_logprob_max 5.38 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.7 / train/policy_logprob_std 2.01 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.5e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 49.79 / train/post_ent_max 49.79 / train/post_ent_mean 37.76 / 
train/post_ent_min 20.54 / train/post_ent_std 5.46 / train/prior_ent_mag 78.34 / train/prior_ent_max 78.34 / train/prior_ent_mean 41.68 / train/prior_ent_min 25.49 / train/prior_ent_std 7.07 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.55 / train/reward_avg 0.22 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.83 / train/reward_max_pred 1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.22 / train/reward_rate 
0.22 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.46 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 6.13 / report/image_loss_mean 1.34 / report/image_loss_std 0.9 / report/model_loss_mean 3.72 / report/model_loss_std 4.25 / report/post_ent_mag 50.25 / report/post_ent_max 50.25 / 
report/post_ent_mean 37.26 / report/post_ent_min 21.56 / report/post_ent_std 5.73 / report/prior_ent_mag 78.27 / report/prior_ent_max 78.27 / report/prior_ent_mean 41.02 / report/prior_ent_min 26.22 / report/prior_ent_std 7.48 / report/rep_loss_mean 3.75 / 
report/rep_loss_std 6.13 / report/reward_avg 0.21 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.29 / report/reward_max_data 1.65 / report/reward_max_pred 1.62 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.62 / report/reward_pred 0.21 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.53 / eval/dyn_loss_std 6.91 / eval/image_loss_mean 1.21 / eval/image_loss_std 1.51 / eval/model_loss_mean 4.08 / eval/model_loss_std 5.3 / eval/post_ent_mag 50.81 / eval/post_ent_max 50.81 / eval/post_ent_mean 
36.63 / eval/post_ent_min 20.45 / eval/post_ent_std 6.33 / eval/prior_ent_mag 78.27 / eval/prior_ent_max 78.27 / eval/prior_ent_mean 40.57 / eval/prior_ent_min 26.36 / eval/prior_ent_std 8.08 / eval/rep_loss_mean 4.53 / eval/rep_loss_std 6.91 / eval/reward_avg 0.24 / 
eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.73 / eval/reward_max_pred 1.76 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.24 / eval/reward_rate 0.23 / 
replay/size 1.3e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3754 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.88 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.37 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.63 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / 
timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 259.7.
Starting evaluation at step 130500 Counter(130500) 130437
Saved chunk: 20230922T001844F592349-7BFf2JSczTtY5ZuCtn6HoT-6znsWlmu7qdUqTAHhll0Mr-1024.npz
eval_Episode has 500 steps and return 242.3.
train_Episode has 500 steps and return 241.2.
Starting evaluation at step 131000 Counter(131000) 130937
eval_Episode has 500 steps and return 277.6.
Saved chunk: 20230922T001929F748341-5a0ENwv48yBtx9MawE7fQa-69WXxv2AzqncTlgwER3Dmb-1024.npz
train_Episode has 500 steps and return 246.4.
Starting evaluation at step 131500 Counter(131500) 131437
Saved chunk: 20230922T002004F698230-6znsWlmu7qdUqTAHhll0Mr-3Sm4F1sI1gEKgMpH86XywK-1024.npz
eval_Episode has 500 steps and return 277.8.
train_Episode has 500 steps and return 226.6.
Starting evaluation at step 132000 Counter(132000) 131937
eval_Episode has 500 steps and return 249.3.
Saved chunk: 20230922T002051F711871-69WXxv2AzqncTlgwER3Dmb-5nnk8sIc98J8tH0F3UL05k-1024.npz
train_Episode has 500 steps and return 262.9.
Starting evaluation at step 132500 Counter(132500) 132437
Saved chunk: 20230922T002124F266384-3Sm4F1sI1gEKgMpH86XywK-1JQ3bKXAmTBUmsQCtMy61h-1024.npz
eval_Episode has 500 steps and return 269.5.
train_Episode has 500 steps and return 256.8.
Starting evaluation at step 133000 Counter(133000) 132937
eval_Episode has 500 steps and return 247.1.
Saved chunk: 20230922T002212F776035-5nnk8sIc98J8tH0F3UL05k-122oqMQZ3OjQyN4UezulR0-1024.npz
train_Episode has 500 steps and return 230.0.
Starting evaluation at step 133500 Counter(133500) 133437
Saved chunk: 20230922T002243F675939-1JQ3bKXAmTBUmsQCtMy61h-0DDwkprA7PLEBU0uCuj7Qm-1024.npz
eval_Episode has 500 steps and return 292.9.
train_Episode has 500 steps and return 223.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 267742 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 223.33 / episode/reward_rate 0.38 / eval_episode/length 500 / eval_episode/score 292.86 / eval_episode/reward_rate 0.48 / train/action_mag 3.68 / train/action_max 3.35 / train/action_mean 0.04 / train/action_min -3.56 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 6.5e4 / train/actor_opt_loss -34.5 / train/adv_mag 0.59 / train/adv_max 0.57 / train/adv_mean 
4.1e-3 / train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.9e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.9e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.99 / train/dyn_loss_std 6.61 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 6.5e4 / train/extr_critic_critic_opt_loss 9377.08 / train/extr_critic_mag 191.14 / train/extr_critic_max 191.14 / train/extr_critic_mean 179.84 / train/extr_critic_min 121.15 / train/extr_critic_std 12.73 / 
train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 191.61 / 
train/extr_return_raw_max 191.61 / train/extr_return_raw_mean 180.04 / train/extr_return_raw_min 132.78 / train/extr_return_raw_std 12.78 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.24 / train/extr_reward_min 0 / 
train/extr_reward_std 0.49 / train/image_loss_mean 1.32 / train/image_loss_std 1.15 / train/model_loss_mean 3.85 / train/model_loss_std 4.83 / train/model_opt_grad_norm 9.31 / train/model_opt_grad_steps 6.5e4 / train/model_opt_loss 2.8e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7368.42 / train/policy_entropy_mag 4.76 / train/policy_entropy_max 4.74 / train/policy_entropy_mean -2.06 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.34 / 
train/policy_logprob_mag 10.9 / train/policy_logprob_max 5.39 / train/policy_logprob_mean 2.06 / train/policy_logprob_min -10.9 / train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.16 / 
train/policy_randomness_min 3e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 49.88 / train/post_ent_max 49.88 / train/post_ent_mean 38.12 / train/post_ent_min 20.6 / train/post_ent_std 5.5 / train/prior_ent_mag 78.55 / train/prior_ent_max 78.55 / 
train/prior_ent_mean 42.11 / train/prior_ent_min 25.98 / train/prior_ent_std 7.02 / train/rep_loss_mean 3.99 / train/rep_loss_std 6.61 / train/reward_avg 0.23 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.85 / train/reward_max_pred
1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.23 / train/reward_rate 0.23 / train_stats/mean_log_entropy -2.44 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 7.8e-11 / report/cont_loss_std 2.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 6.51 / 
report/image_loss_mean 1.2 / report/image_loss_std 1.07 / report/model_loss_mean 3.66 / report/model_loss_std 4.76 / report/post_ent_mag 50.29 / report/post_ent_max 50.29 / report/post_ent_mean 38.11 / report/post_ent_min 21.09 / report/post_ent_std 5.45 / 
report/prior_ent_mag 78.67 / report/prior_ent_max 78.67 / report/prior_ent_mean 41.98 / report/prior_ent_min 27.03 / report/prior_ent_std 7.19 / report/rep_loss_mean 3.85 / report/rep_loss_std 6.51 / report/reward_avg 0.28 / report/reward_loss_mean 0.15 / 
report/reward_loss_std 0.3 / report/reward_max_data 1.82 / report/reward_max_pred 1.85 / report/reward_neg_acc 1 / report/reward_neg_loss 3.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.28 / report/reward_rate 0.25 / eval/cont_avg 1
/ eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.34 / eval/dyn_loss_std 7.51 / eval/image_loss_mean
1.89 / eval/image_loss_std 3.03 / eval/model_loss_mean 5.24 / eval/model_loss_std 7.06 / eval/post_ent_mag 50.1 / eval/post_ent_max 50.1 / eval/post_ent_mean 38.85 / eval/post_ent_min 25.02 / eval/post_ent_std 4.88 / eval/prior_ent_mag 78.67 / eval/prior_ent_max 78.67 /
eval/prior_ent_mean 43.29 / eval/prior_ent_min 30.23 / eval/prior_ent_std 6.22 / eval/rep_loss_mean 5.34 / eval/rep_loss_std 7.51 / eval/reward_avg 0.21 / eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.67 / eval/reward_max_pred 1.64 / 
eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.21 / eval/reward_rate 0.23 / replay/size 1.3e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3806 / timer/env.step_total 19.64 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 452.93 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7313 / timer/agent.policy_total 16.33 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / 
timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1903 / timer/agent.train_total 245.15 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 134000 Counter(134000) 133937
eval_Episode has 500 steps and return 238.6.
Saved chunk: 20230922T002333F472582-122oqMQZ3OjQyN4UezulR0-6zG7fynPYLE8WpoNnINbn7-1024.npz
train_Episode has 500 steps and return 256.0.
Starting evaluation at step 134500 Counter(134500) 134437
Saved chunk: 20230922T002402F747524-0DDwkprA7PLEBU0uCuj7Qm-4woKxSVZQdzTuYdxry36Cm-1024.npz
eval_Episode has 500 steps and return 287.6.
train_Episode has 500 steps and return 265.7.
Starting evaluation at step 135000 Counter(135000) 134937
eval_Episode has 500 steps and return 290.4.
Saved chunk: 20230922T002455F096151-6zG7fynPYLE8WpoNnINbn7-0T5CR1SEKJ5s7eWgVcY4ud-1024.npz
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 135500 Counter(135500) 135437
Saved chunk: 20230922T002522F967211-4woKxSVZQdzTuYdxry36Cm-50tqCHhQJIy0eYnFGC99Fc-1024.npz
eval_Episode has 500 steps and return 273.9.
train_Episode has 500 steps and return 269.3.
Starting evaluation at step 136000 Counter(136000) 135937
eval_Episode has 500 steps and return 276.8.
Saved chunk: 20230922T002616F152272-0T5CR1SEKJ5s7eWgVcY4ud-0HCrYYINiN7U0fVYrYNGbS-1024.npz
train_Episode has 500 steps and return 240.6.
Starting evaluation at step 136500 Counter(136500) 136437
Saved chunk: 20230922T002642F343143-50tqCHhQJIy0eYnFGC99Fc-1nNjemlk66Lm6NCQ247dKL-1024.npz
eval_Episode has 500 steps and return 283.5.
train_Episode has 500 steps and return 209.8.
Starting evaluation at step 137000 Counter(137000) 136937
eval_Episode has 500 steps and return 266.4.
Saved chunk: 20230922T002736F969777-0HCrYYINiN7U0fVYrYNGbS-5Lv2QEbSjJosssXFPzHCAj-1024.npz
train_Episode has 500 steps and return 240.5.
Starting evaluation at step 137500 Counter(137500) 137437
Saved chunk: 20230922T002801F540769-1nNjemlk66Lm6NCQ247dKL-6iK0IATHS2bgYC0nIJkZuF-1024.npz
eval_Episode has 500 steps and return 266.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 275266 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 266.86 / eval_episode/reward_rate 0.41 / episode/length 500 / episode/score 240.51 / episode/reward_rate 0.42 / train/action_mag 3.48 / train/action_max 3.31 / train/action_mean 0.05 / train/action_min -3.25 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 6.7e4 / train/actor_opt_loss -32.12 / train/adv_mag 0.53 / train/adv_max 0.51 / train/adv_mean 
3.9e-3 / train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.3e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 6.7e4 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 196.59 / train/extr_critic_max 196.59 / train/extr_critic_mean 185.18 / train/extr_critic_min 129.82 / train/extr_critic_std 12.78 / 
train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.19 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 196.98 / 
train/extr_return_raw_max 196.98 / train/extr_return_raw_mean 185.37 / train/extr_return_raw_min 137.99 / train/extr_return_raw_std 12.8 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.25 / train/extr_reward_min 0 / 
train/extr_reward_std 0.5 / train/image_loss_mean 1.29 / train/image_loss_std 1.09 / train/model_loss_mean 3.79 / train/model_loss_std 4.75 / train/model_opt_grad_norm 9.33 / train/model_opt_grad_steps 6.7e4 / train/model_opt_loss 3.8e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.41 / train/policy_entropy_max 4.32 / train/policy_entropy_mean -2.21 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.14 / 
train/policy_logprob_mag 10.17 / train/policy_logprob_max 5.39 / train/policy_logprob_mean 2.22 / train/policy_logprob_min -10.17 / train/policy_logprob_std 1.84 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.14 / 
train/policy_randomness_min 2.8e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 50.03 / train/post_ent_max 50.03 / train/post_ent_mean 38.33 / train/post_ent_min 21.06 / train/post_ent_std 5.5 / train/prior_ent_mag 78.69 / train/prior_ent_max 78.69 / 
train/prior_ent_mean 42.27 / train/prior_ent_min 26.27 / train/prior_ent_std 7.03 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.55 / train/reward_avg 0.23 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.86 / train/reward_max_pred
1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.23 / train/reward_rate 0.23 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.48 / report/cont_avg 1 / 
report/cont_loss_mean 5.3e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.01 / report/dyn_loss_std 5.37 / 
report/image_loss_mean 0.85 / report/image_loss_std 0.86 / report/model_loss_mean 2.75 / report/model_loss_std 3.94 / report/post_ent_mag 50.68 / report/post_ent_max 50.68 / report/post_ent_mean 36.07 / report/post_ent_min 20.06 / report/post_ent_std 6.28 / 
report/prior_ent_mag 78.55 / report/prior_ent_max 78.55 / report/prior_ent_mean 39.12 / report/prior_ent_min 25.42 / report/prior_ent_std 8.21 / report/rep_loss_mean 3.01 / report/rep_loss_std 5.37 / report/reward_avg 0.16 / report/reward_loss_mean 0.09 / 
report/reward_loss_std 0.24 / report/reward_max_data 2 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.16 / report/reward_rate 0.15 / eval/cont_avg 1 / 
eval/cont_loss_mean 7.5e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.8 / eval/dyn_loss_std 7.8 / eval/image_loss_mean 1.75 
/ eval/image_loss_std 2.43 / eval/model_loss_mean 5.41 / eval/model_loss_std 6.48 / eval/post_ent_mag 51.43 / eval/post_ent_max 51.43 / eval/post_ent_mean 39.28 / eval/post_ent_min 19.47 / eval/post_ent_std 5.21 / eval/prior_ent_mag 78.55 / eval/prior_ent_max 78.55 / 
eval/prior_ent_mean 43.93 / eval/prior_ent_min 27.44 / eval/prior_ent_std 5.99 / eval/rep_loss_mean 5.8 / eval/rep_loss_std 7.8 / eval/reward_avg 0.23 / eval/reward_loss_mean 0.18 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.74 / eval/reward_max_pred 1.75 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.68 / eval/reward_pred 0.23 / eval/reward_rate 0.26 / replay/size 1.4e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3762 / timer/env.step_total 19.75 / timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 449.86 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count
7770 / timer/agent.policy_total 17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.7e-3 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / 
timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.71 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 262.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T002857F664177-5Lv2QEbSjJosssXFPzHCAj-0000000000000000000000-584.npz
Saved chunk: 20230922T002920F623928-6iK0IATHS2bgYC0nIJkZuF-0000000000000000000000-134.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 138000 Counter(138000) 137937
eval_Episode has 500 steps and return 263.8.
Saved chunk: 20230922T002857F664177-5Lv2QEbSjJosssXFPzHCAj-0SZUth8Tek6aXDooCIBZb1-1024.npz
train_Episode has 500 steps and return 254.2.
Starting evaluation at step 138500 Counter(138500) 138437
Saved chunk: 20230922T002920F623928-6iK0IATHS2bgYC0nIJkZuF-49jssTkYNeY453vSrImS5w-1024.npz
eval_Episode has 500 steps and return 271.4.
train_Episode has 500 steps and return 287.0.
Starting evaluation at step 139000 Counter(139000) 138937
eval_Episode has 500 steps and return 258.6.
Saved chunk: 20230922T003019F597775-0SZUth8Tek6aXDooCIBZb1-0pgMsVVZHEURauAL3lURHU-1024.npz
train_Episode has 500 steps and return 265.8.
Starting evaluation at step 139500 Counter(139500) 139437
Saved chunk: 20230922T003041F104710-49jssTkYNeY453vSrImS5w-2lR2LkVPWMMErcsEIeKGWc-1024.npz
eval_Episode has 500 steps and return 285.3.
train_Episode has 500 steps and return 266.6.
Starting evaluation at step 140000 Counter(140000) 139937
eval_Episode has 500 steps and return 202.7.
train_Episode has 500 steps and return 226.4.
Saved chunk: 20230922T003140F531215-0pgMsVVZHEURauAL3lURHU-00bHGR6nmgxND7smKKQSGP-1024.npz
Starting evaluation at step 140500 Counter(140500) 140437
Saved chunk: 20230922T003200F404952-2lR2LkVPWMMErcsEIeKGWc-0QOMPjKdcmeTlfNR7Rk9uc-1024.npz
eval_Episode has 500 steps and return 262.3.
train_Episode has 500 steps and return 245.2.
Starting evaluation at step 141000 Counter(141000) 140937
eval_Episode has 500 steps and return 265.3.
train_Episode has 500 steps and return 250.8.
Saved chunk: 20230922T003301F244873-00bHGR6nmgxND7smKKQSGP-5XbY2xdyx2iVsKhKKlBY4L-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 282886 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 250.82 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 265.3 / eval_episode/reward_rate 0.45 / train/action_mag 3.54 / train/action_max 3.3 / train/action_mean 0.04 / train/action_min -3.33 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 6.9e4 / train/actor_opt_loss -21.41 / train/adv_mag 0.54 / train/adv_max 0.51 / train/adv_mean 2.8e-3 / 
train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.5e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.98 / train/dyn_loss_std 6.56 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 6.9e4 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 200.84 / train/extr_critic_max 200.84 / train/extr_critic_mean 189.57 / train/extr_critic_min 128.3 / train/extr_critic_std 13.39 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 201.26 / train/extr_return_raw_max 201.26 / train/extr_return_raw_mean 189.7 / train/extr_return_raw_min 
137.99 / train/extr_return_raw_std 13.4 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.51 / train/image_loss_mean 1.29 / train/image_loss_std 1.1 / train/model_loss_mean 3.82 / 
train/model_loss_std 4.77 / train/model_opt_grad_norm 9.11 / train/model_opt_grad_steps 6.9e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.2 / train/policy_entropy_max 4 
/ train/policy_entropy_mean -2.16 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 10.11 / train/policy_logprob_max 5.39 / train/policy_logprob_mean 2.16 / train/policy_logprob_min -10.11 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 3e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 50.34 / train/post_ent_max 50.34 / train/post_ent_mean 38.71 / 
train/post_ent_min 20.88 / train/post_ent_std 5.6 / train/prior_ent_mag 78.85 / train/prior_ent_max 78.85 / train/prior_ent_mean 42.68 / train/prior_ent_min 26.24 / train/prior_ent_std 7.02 / train/rep_loss_mean 3.98 / train/rep_loss_std 6.56 / train/reward_avg 0.25 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.3 / train/reward_max_data 1.89 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.25 / train/reward_rate 
0.24 / train_stats/mean_log_entropy -2.47 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.9e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.94 / report/dyn_loss_std 6.87 / report/image_loss_mean 1.3 / report/image_loss_std 1.39 / report/model_loss_mean 3.8 / report/model_loss_std 5.2 / report/post_ent_mag 50.51 / report/post_ent_max 50.51 / 
report/post_ent_mean 38.89 / report/post_ent_min 17.84 / report/post_ent_std 5.72 / report/prior_ent_mag 78.66 / report/prior_ent_max 78.66 / report/prior_ent_mean 42.9 / report/prior_ent_min 26.98 / report/prior_ent_std 6.96 / report/rep_loss_mean 3.94 / 
report/rep_loss_std 6.87 / report/reward_avg 0.23 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.28 / report/reward_max_data 1.91 / report/reward_max_pred 1.87 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.23 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 8.6e-11 / eval/cont_loss_std 8.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.81 / eval/dyn_loss_std 9.79 / eval/image_loss_mean 2.33 / eval/image_loss_std 3.67 / eval/model_loss_mean 6.56 / eval/model_loss_std 8.97 / eval/post_ent_mag 50.37 / eval/post_ent_max 50.37 / eval/post_ent_mean 
37.98 / eval/post_ent_min 18.37 / eval/post_ent_std 6.33 / eval/prior_ent_mag 78.66 / eval/prior_ent_max 78.66 / eval/prior_ent_mean 43.3 / eval/prior_ent_min 25.81 / eval/prior_ent_std 7.33 / eval/rep_loss_mean 6.81 / eval/rep_loss_std 9.79 / eval/reward_avg 0.25 / 
eval/reward_loss_mean 0.15 / eval/reward_loss_std 0.29 / eval/reward_max_data 1.79 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.25 / eval/reward_rate 0.24 / 
replay/size 1.4e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3810 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.32 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7317 / timer/agent.policy_total 16.45 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1905 / timer/agent.train_total 244.97 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 141500 Counter(141500) 141437
Saved chunk: 20230922T003319F492764-0QOMPjKdcmeTlfNR7Rk9uc-5lvAVjEc3Fndy7F0hWRhvV-1024.npz
eval_Episode has 500 steps and return 256.1.
train_Episode has 500 steps and return 255.7.
Starting evaluation at step 142000 Counter(142000) 141937
eval_Episode has 500 steps and return 270.7.
train_Episode has 500 steps and return 278.1.
Saved chunk: 20230922T003421F775669-5XbY2xdyx2iVsKhKKlBY4L-11oZyVQE6BktWd30WhFP7E-1024.npz
Starting evaluation at step 142500 Counter(142500) 142437
eval_Episode has 500 steps and return 264.9.
Saved chunk: 20230922T003439F301852-5lvAVjEc3Fndy7F0hWRhvV-5NHEik1z3ynxYxHUZD6wnJ-1024.npz
train_Episode has 500 steps and return 263.6.
Starting evaluation at step 143000 Counter(143000) 142937
eval_Episode has 500 steps and return 241.0.
train_Episode has 500 steps and return 243.9.
Saved chunk: 20230922T003543F580492-11oZyVQE6BktWd30WhFP7E-70DsAruwzuOISHhvtFcpFB-1024.npz
Starting evaluation at step 143500 Counter(143500) 143437
eval_Episode has 500 steps and return 238.5.
Saved chunk: 20230922T003558F761891-5NHEik1z3ynxYxHUZD6wnJ-6tQOKkSQRJHaJLELKoi3H0-1024.npz
train_Episode has 500 steps and return 267.8.
Starting evaluation at step 144000 Counter(144000) 143937
eval_Episode has 500 steps and return 289.6.
train_Episode has 500 steps and return 263.1.
Saved chunk: 20230922T003704F526588-70DsAruwzuOISHhvtFcpFB-5Kp1QcowlPvbmpY9J09ioO-1024.npz
Starting evaluation at step 144500 Counter(144500) 144437
eval_Episode has 500 steps and return 292.3.
train_Episode has 500 steps and return 272.8.
Starting evaluation at step 145000 Counter(145000) 144937
Saved chunk: 20230922T003718F090886-6tQOKkSQRJHaJLELKoi3H0-1f8llijI239HkUw7xD5c8i-1024.npz
eval_Episode has 500 steps and return 282.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 290410 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 282.03 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 272.82 / episode/reward_rate 0.43 / train/action_mag 3.62 / train/action_max 3.36 / train/action_mean 0.04 / train/action_min -3.41 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 7.1e4 / train/actor_opt_loss -21.32 / train/adv_mag 0.5 / train/adv_max 0.47 / train/adv_mean 
2.8e-3 / train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.2e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 7.1e4 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 204.08 / train/extr_critic_max 204.08 / train/extr_critic_mean 192.93 / train/extr_critic_min 136.3 / train/extr_critic_std 13 / train/extr_return_normed_mag 
1.4 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 204.54 / train/extr_return_raw_max 204.54 / 
train/extr_return_raw_mean 193.06 / train/extr_return_raw_min 142.45 / train/extr_return_raw_std 12.98 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.51 / train/image_loss_mean 
1.26 / train/image_loss_std 1.07 / train/model_loss_mean 3.77 / train/model_loss_std 4.76 / train/model_opt_grad_norm 9.22 / train/model_opt_grad_steps 7.1e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 4.48 / train/policy_entropy_max 4.43 / train/policy_entropy_mean -2.13 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 10.28 / train/policy_logprob_max 5.39 / train/policy_logprob_mean 2.13 / 
train/policy_logprob_min -10.28 / train/policy_logprob_std 1.91 / train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 3e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 50.47 / 
train/post_ent_max 50.47 / train/post_ent_mean 38.94 / train/post_ent_min 20.91 / train/post_ent_std 5.52 / train/prior_ent_mag 79 / train/prior_ent_max 79 / train/prior_ent_mean 42.88 / train/prior_ent_min 26.5 / train/prior_ent_std 6.97 / train/rep_loss_mean 3.94 / 
train/rep_loss_std 6.57 / train/reward_avg 0.25 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.3 / train/reward_max_data 1.89 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 
0.61 / train/reward_pred 0.25 / train/reward_rate 0.24 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.45 / report/cont_avg 1 / report/cont_loss_mean 5.6e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 5.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 6.4 / report/image_loss_mean 1.27 / report/image_loss_std 0.98 / report/model_loss_mean 3.6 / report/model_loss_std 4.57 / 
report/post_ent_mag 49.73 / report/post_ent_max 49.73 / report/post_ent_mean 38.35 / report/post_ent_min 16.7 / report/post_ent_std 5.78 / report/prior_ent_mag 79.02 / report/prior_ent_max 79.02 / report/prior_ent_mean 42.19 / report/prior_ent_min 26.28 / 
report/prior_ent_std 7.09 / report/rep_loss_mean 3.66 / report/rep_loss_std 6.4 / report/reward_avg 0.22 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.28 / report/reward_max_data 1.95 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / 
report/reward_neg_loss 5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.22 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.12 / eval/dyn_loss_std 8.16 / eval/image_loss_mean 1.64 / eval/image_loss_std 2.79 / eval/model_loss_mean 4.88 / eval/model_loss_std 7.21 / eval/post_ent_mag 
51.38 / eval/post_ent_max 51.38 / eval/post_ent_mean 38.9 / eval/post_ent_min 19.46 / eval/post_ent_std 5.47 / eval/prior_ent_mag 79.02 / eval/prior_ent_max 79.02 / eval/prior_ent_mean 43.3 / eval/prior_ent_min 26.39 / eval/prior_ent_std 6.53 / eval/rep_loss_mean 5.12 /
eval/rep_loss_std 8.16 / eval/reward_avg 0.26 / eval/reward_loss_mean 0.16 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.71 / eval/reward_max_pred 1.81 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.64 /
eval/reward_pred 0.26 / eval/reward_rate 0.25 / replay/size 1.5e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3762 / timer/env.step_total 19.43
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.13 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
6e-3 / timer/replay._sample_max 0.05 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.29 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1881 / 
timer/agent.train_total 241.94 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 260.2.
Saved chunk: 20230922T003825F227998-5Kp1QcowlPvbmpY9J09ioO-53LkMC38MJrPGJSxAv59ij-1024.npz
Starting evaluation at step 145500 Counter(145500) 145437
eval_Episode has 500 steps and return 276.9.
train_Episode has 500 steps and return 263.1.
Starting evaluation at step 146000 Counter(146000) 145937
Saved chunk: 20230922T003913F132176-1f8llijI239HkUw7xD5c8i-2FBgeNwuYFprHA2Risi1Tr-1024.npz
eval_Episode has 500 steps and return 288.5.
train_Episode has 500 steps and return 238.8.
Saved chunk: 20230922T003946F651957-53LkMC38MJrPGJSxAv59ij-3BcpI3JC1TzSTBF7H26MAf-1024.npz
Starting evaluation at step 146500 Counter(146500) 146437
eval_Episode has 500 steps and return 282.0.
train_Episode has 500 steps and return 263.4.
Starting evaluation at step 147000 Counter(147000) 146937
Saved chunk: 20230922T004033F229544-2FBgeNwuYFprHA2Risi1Tr-4QFwpD4fiYXe6XZ8lnkI0v-1024.npz
eval_Episode has 500 steps and return 257.1.
train_Episode has 500 steps and return 268.2.
Saved chunk: 20230922T004107F588672-3BcpI3JC1TzSTBF7H26MAf-5rWmq24WGTFHDqrqsgos4n-1024.npz
Starting evaluation at step 147500 Counter(147500) 147437
eval_Episode has 500 steps and return 275.2.
train_Episode has 500 steps and return 202.1.
Starting evaluation at step 148000 Counter(148000) 147937
Saved chunk: 20230922T004152F516916-4QFwpD4fiYXe6XZ8lnkI0v-02lZ88LyOPKrpV19qXsfKU-1024.npz
eval_Episode has 500 steps and return 266.8.
train_Episode has 500 steps and return 231.7.
Saved chunk: 20230922T004228F412110-5rWmq24WGTFHDqrqsgos4n-0cSsVR18JUCU20ip54RUBP-1024.npz
Starting evaluation at step 148500 Counter(148500) 148437
eval_Episode has 500 steps and return 273.9.
train_Episode has 500 steps and return 279.9.
Starting evaluation at step 149000 Counter(149000) 148937
Saved chunk: 20230922T004311F715365-02lZ88LyOPKrpV19qXsfKU-7omufWQacgELw7fq905AER-1024.npz
eval_Episode has 500 steps and return 225.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 298002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 279.89 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 225.19 / eval_episode/reward_rate 0.36 / train/action_mag 3.52 / train/action_max 3.38 / train/action_mean 0.04 / train/action_min -3.14 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 7.3e4 / train/actor_opt_loss -12.68 / train/adv_mag 0.37 / train/adv_max 0.31 / train/adv_mean 2e-3
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.6e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.97 / train/dyn_loss_std 6.61 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 7.3e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 206.81 / train/extr_critic_max 206.81 / train/extr_critic_mean 195.99 / train/extr_critic_min 140.77 / train/extr_critic_std 13.28 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 207.39 / train/extr_return_raw_max 207.39 / train/extr_return_raw_mean 196.08 / 
train/extr_return_raw_min 142.71 / train/extr_return_raw_std 13.3 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.25 / train/image_loss_std 1.07 / 
train/model_loss_mean 3.79 / train/model_loss_std 4.78 / train/model_opt_grad_norm 9.22 / train/model_opt_grad_steps 7.3e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 5.3e-3 / train/model_opt_model_opt_grad_scale 8342.11 / 
train/policy_entropy_mag 3.96 / train/policy_entropy_max 3.71 / train/policy_entropy_mean -2.25 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.78 / train/policy_logprob_max 5.41 / train/policy_logprob_mean 2.26 / 
train/policy_logprob_min -9.78 / train/policy_logprob_std 1.82 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.7e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 50.5 / 
train/post_ent_max 50.5 / train/post_ent_mean 39.34 / train/post_ent_min 20.93 / train/post_ent_std 5.54 / train/prior_ent_mag 79.17 / train/prior_ent_max 79.17 / train/prior_ent_mean 43.3 / train/prior_ent_min 26.59 / train/prior_ent_std 6.91 / train/rep_loss_mean 3.97
/ train/rep_loss_std 6.61 / train/reward_avg 0.27 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.31 / train/reward_max_data 1.9 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss
0.6 / train/reward_pred 0.27 / train/reward_rate 0.25 / train_stats/mean_log_entropy -2.51 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.6e-11 / report/cont_loss_std 2.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 6.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.07 / report/dyn_loss_std 6.8 / report/image_loss_mean 1.35 / report/image_loss_std 1.11 / report/model_loss_mean 3.94 / report/model_loss_std 4.85 / 
report/post_ent_mag 51.75 / report/post_ent_max 51.75 / report/post_ent_mean 39.01 / report/post_ent_min 20.47 / report/post_ent_std 6.04 / report/prior_ent_mag 79.31 / report/prior_ent_max 79.31 / report/prior_ent_mean 43.08 / report/prior_ent_min 26.37 / 
report/prior_ent_std 7.37 / report/rep_loss_mean 4.07 / report/rep_loss_std 6.8 / report/reward_avg 0.25 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.29 / report/reward_max_data 1.92 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4.3e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.6 / report/reward_pred 0.24 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.22 / eval/dyn_loss_std 7.74 / eval/image_loss_mean 1.65 / eval/image_loss_std 2.58 / eval/model_loss_mean 4.95 / eval/model_loss_std 6.68 / eval/post_ent_mag 
51.3 / eval/post_ent_max 51.3 / eval/post_ent_mean 39.09 / eval/post_ent_min 17.66 / eval/post_ent_std 6.48 / eval/prior_ent_mag 79.31 / eval/prior_ent_max 79.31 / eval/prior_ent_mean 43.39 / eval/prior_ent_min 24.28 / eval/prior_ent_std 7.49 / eval/rep_loss_mean 5.22 /
eval/rep_loss_std 7.74 / eval/reward_avg 0.27 / eval/reward_loss_mean 0.16 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.1e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.27 / eval/reward_rate 0.27 / replay/size 1.5e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.4 / timer/env.step_count 3796 / timer/env.step_total 19.6 /
timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.64 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
5.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 17.32 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1898 / timer/agent.train_total 244.08 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T004430F748450-7omufWQacgELw7fq905AER-0000000000000000000000-393.npz
Saved chunk: 20230922T004349F105896-0cSsVR18JUCU20ip54RUBP-0000000000000000000000-720.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 239.8.
Starting evaluation at step 149500 Counter(149500) 149437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004349F105896-0cSsVR18JUCU20ip54RUBP-5YIOwdn3WcUrAfJrXR8JK7-1024.npz
train_Episode has 500 steps and return 251.7.
Starting evaluation at step 150000 Counter(150000) 149937
Saved chunk: 20230922T004430F748450-7omufWQacgELw7fq905AER-4wCjsv1bTAFgbohVWZgtkV-1024.npz
eval_Episode has 500 steps and return 285.5.
train_Episode has 500 steps and return 267.1.
Starting evaluation at step 150500 Counter(150500) 150437
eval_Episode has 500 steps and return 231.2.
Saved chunk: 20230922T004514F550278-5YIOwdn3WcUrAfJrXR8JK7-1j2NciNyIf6unMruGA5xis-1024.npz
train_Episode has 500 steps and return 271.7.
Starting evaluation at step 151000 Counter(151000) 150937
Saved chunk: 20230922T004551F307921-4wCjsv1bTAFgbohVWZgtkV-4O8Q54la2aGxtcTZKnOghu-1024.npz
eval_Episode has 500 steps and return 285.0.
train_Episode has 500 steps and return 256.9.
Starting evaluation at step 151500 Counter(151500) 151437
eval_Episode has 500 steps and return 278.3.
Saved chunk: 20230922T004635F548568-1j2NciNyIf6unMruGA5xis-6pmX9mNWdTiD5qcjXrm7k3-1024.npz
train_Episode has 500 steps and return 255.5.
Starting evaluation at step 152000 Counter(152000) 151937
Saved chunk: 20230922T004710F626581-4O8Q54la2aGxtcTZKnOghu-1dTQysNf2SalZE2CT7qLqX-1024.npz
eval_Episode has 500 steps and return 280.3.
train_Episode has 500 steps and return 270.0.
Starting evaluation at step 152500 Counter(152500) 152437
eval_Episode has 500 steps and return 296.0.
Saved chunk: 20230922T004756F335332-6pmX9mNWdTiD5qcjXrm7k3-3vXMgoRJwHr2qV9A4qB1ws-1024.npz
train_Episode has 500 steps and return 264.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 305618 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 264.13 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 295.98 / eval_episode/reward_rate 0.5 / train/action_mag 3.56 / train/action_max 3.38 / train/action_mean 0.03 / train/action_min -3.15 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 7.5e4 / train/actor_opt_loss -6.52 / train/adv_mag 0.42 / train/adv_max 0.37 / train/adv_mean 1.3e-3 / train/adv_min
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.3e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 7.5e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 208.85 / train/extr_critic_max 208.85 / train/extr_critic_mean 197.99 / train/extr_critic_min 140.57 / train/extr_critic_std 13.3 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 209.52 / train/extr_return_raw_max 209.52 / train/extr_return_raw_mean 198.05 / train/extr_return_raw_min
146.53 / train/extr_return_raw_std 13.32 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.25 / train/image_loss_std 1.08 / train/model_loss_mean 3.78 
/ train/model_loss_std 4.78 / train/model_opt_grad_norm 9.02 / train/model_opt_grad_steps 7.5e4 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9000 / train/policy_entropy_mag 3.96 / 
train/policy_entropy_max 3.78 / train/policy_entropy_mean -2.18 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.16 / train/policy_logprob_mag 9.84 / train/policy_logprob_max 5.41 / train/policy_logprob_mean 2.18 / train/policy_logprob_min -9.84 / 
train/policy_logprob_std 1.85 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.6e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 50.63 / train/post_ent_max 50.63 / 
train/post_ent_mean 39.37 / train/post_ent_min 20.89 / train/post_ent_std 5.61 / train/prior_ent_mag 79.31 / train/prior_ent_max 79.31 / train/prior_ent_mean 43.32 / train/prior_ent_min 26.43 / train/prior_ent_std 6.99 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.6
/ train/reward_avg 0.26 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.3 / train/reward_max_data 1.89 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 
0.26 / train/reward_rate 0.25 / train_stats/mean_log_entropy -2.47 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8e-11 / report/cont_loss_std 7.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.93 / report/dyn_loss_std 6.84 / report/image_loss_mean 1.39 / report/image_loss_std 1.35 / report/model_loss_mean 3.85 / report/model_loss_std 5.1 / report/post_ent_mag 50.84 /
report/post_ent_max 50.84 / report/post_ent_mean 37.76 / report/post_ent_min 21.26 / report/post_ent_std 5.86 / report/prior_ent_mag 79.59 / report/prior_ent_max 79.59 / report/prior_ent_mean 41.65 / report/prior_ent_min 25.31 / report/prior_ent_std 7.26 / 
report/rep_loss_mean 3.93 / report/rep_loss_std 6.84 / report/reward_avg 0.19 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.26 / report/reward_max_data 1.97 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 9.4e-4 / 
report/reward_pos_acc 0.98 / report/reward_pos_loss 0.58 / report/reward_pred 0.18 / report/reward_rate 0.18 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.04 / eval/dyn_loss_std 7.01 / eval/image_loss_mean 1.46 / eval/image_loss_std 1.95 / eval/model_loss_mean 4.68 / eval/model_loss_std 5.65 / eval/post_ent_mag 51.92 / 
eval/post_ent_max 51.92 / eval/post_ent_mean 40.35 / eval/post_ent_min 23.41 / eval/post_ent_std 5.05 / eval/prior_ent_mag 79.59 / eval/prior_ent_max 79.59 / eval/prior_ent_mean 44.8 / eval/prior_ent_min 30.49 / eval/prior_ent_std 6.06 / eval/rep_loss_mean 5.04 / 
eval/rep_loss_std 7.01 / eval/reward_avg 0.35 / eval/reward_loss_mean 0.2 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.82 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.61 / 
eval/reward_pred 0.35 / eval/reward_rate 0.32 / replay/size 1.5e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3808 / timer/env.step_total 19.77
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.51 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
1.3e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7315 / timer/agent.policy_total 
16.57 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.73 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 153000 Counter(153000) 152937
Saved chunk: 20230922T004829F763382-1dTQysNf2SalZE2CT7qLqX-6LiXWM2iFNbYEW0cEt1hRN-1024.npz
eval_Episode has 500 steps and return 273.5.
train_Episode has 500 steps and return 232.2.
Starting evaluation at step 153500 Counter(153500) 153437
eval_Episode has 500 steps and return 278.5.
Saved chunk: 20230922T004916F972527-3vXMgoRJwHr2qV9A4qB1ws-6NHgInZXqGj6lqjbwQlI4F-1024.npz
train_Episode has 500 steps and return 226.7.
Starting evaluation at step 154000 Counter(154000) 153937
Saved chunk: 20230922T004949F640041-6LiXWM2iFNbYEW0cEt1hRN-0AfQ7Rm9dbJG2DOOBevasR-1024.npz
eval_Episode has 500 steps and return 292.6.
train_Episode has 500 steps and return 267.7.
Starting evaluation at step 154500 Counter(154500) 154437
eval_Episode has 500 steps and return 270.6.
Saved chunk: 20230922T005038F699136-6NHgInZXqGj6lqjbwQlI4F-1w8UTurYLXIviI8HXNJiYa-1024.npz
train_Episode has 500 steps and return 236.3.
Starting evaluation at step 155000 Counter(155000) 154937
Saved chunk: 20230922T005109F073039-0AfQ7Rm9dbJG2DOOBevasR-7JGfVnM9Q6heF8KHBgPyVk-1024.npz
eval_Episode has 500 steps and return 290.8.
train_Episode has 500 steps and return 253.4.
Starting evaluation at step 155500 Counter(155500) 155437
eval_Episode has 500 steps and return 274.9.
Saved chunk: 20230922T005159F671449-1w8UTurYLXIviI8HXNJiYa-4lO4Z0ZePXy6IlGMFuTDDr-1024.npz
train_Episode has 500 steps and return 274.3.
Starting evaluation at step 156000 Counter(156000) 155937
Saved chunk: 20230922T005228F402619-7JGfVnM9Q6heF8KHBgPyVk-2FA0umTJlxSC0GRgq0ngL3-1024.npz
eval_Episode has 500 steps and return 299.3.
train_Episode has 500 steps and return 269.3.
Starting evaluation at step 156500 Counter(156500) 156437
eval_Episode has 500 steps and return 250.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 313142 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 250.49 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 269.34 / episode/reward_rate 0.43 / train/action_mag 3.53 / train/action_max 3.39 / train/action_mean 0.04 / train/action_min -3.13 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 7.7e4 / train/actor_opt_loss -3.38 / train/adv_mag 0.35 / train/adv_max 0.3 / train/adv_mean 1e-3 /
train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.6e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 7.7e4 / 
train/extr_critic_critic_opt_loss 9152.44 / train/extr_critic_mag 209.97 / train/extr_critic_max 209.97 / train/extr_critic_mean 199.39 / train/extr_critic_min 146.41 / train/extr_critic_std 13.65 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 211.01 / train/extr_return_raw_max 211.01 / train/extr_return_raw_mean 199.43 / 
train/extr_return_raw_min 148.32 / train/extr_return_raw_std 13.68 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.29 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.23 / train/image_loss_std 1.06 / 
train/model_loss_mean 3.76 / train/model_loss_std 4.74 / train/model_opt_grad_norm 9.21 / train/model_opt_grad_steps 7.7e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.97
/ train/policy_entropy_max 3.75 / train/policy_entropy_mean -2.19 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.15 / train/policy_logprob_mag 9.82 / train/policy_logprob_max 5.42 / train/policy_logprob_mean 2.19 / train/policy_logprob_min -9.82 / 
train/policy_logprob_std 1.85 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.5e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 50.7 / train/post_ent_max 50.7 / 
train/post_ent_mean 39.6 / train/post_ent_min 21.07 / train/post_ent_std 5.63 / train/prior_ent_mag 79.4 / train/prior_ent_max 79.4 / train/prior_ent_mean 43.53 / train/prior_ent_min 26.61 / train/prior_ent_std 6.99 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.57 /
train/reward_avg 0.27 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 
0.27 / train/reward_rate 0.25 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.49 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 6.11 / report/image_loss_mean 1.2 / report/image_loss_std 1.02 / report/model_loss_mean 3.54 / report/model_loss_std 4.45 / report/post_ent_mag 50.08 /
report/post_ent_max 50.08 / report/post_ent_mean 39.18 / report/post_ent_min 22.76 / report/post_ent_std 5.72 / report/prior_ent_mag 79.55 / report/prior_ent_max 79.55 / report/prior_ent_mean 42.81 / report/prior_ent_min 25.69 / report/prior_ent_std 7.13 / 
report/rep_loss_mean 3.66 / report/rep_loss_std 6.11 / report/reward_avg 0.23 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.33 / report/reward_max_data 1.8 / report/reward_max_pred 1.79 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / 
report/reward_pos_acc 0.99 / report/reward_pos_loss 0.62 / report/reward_pred 0.23 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 8.1e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.26 / eval/dyn_loss_std 9.29 / eval/image_loss_mean 2.66 / eval/image_loss_std 3.94 / eval/model_loss_mean 7.23 / eval/model_loss_std 8.85 / eval/post_ent_mag 51.05 / 
eval/post_ent_max 51.05 / eval/post_ent_mean 39.58 / eval/post_ent_min 19.9 / eval/post_ent_std 6.52 / eval/prior_ent_mag 79.55 / eval/prior_ent_max 79.55 / eval/prior_ent_mean 45.02 / eval/prior_ent_min 27.37 / eval/prior_ent_std 6 / eval/rep_loss_mean 7.26 / 
eval/rep_loss_std 9.29 / eval/reward_avg 0.34 / eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.43 / eval/reward_max_data 2 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.66 / 
eval/reward_pred 0.33 / eval/reward_rate 0.31 / replay/size 1.6e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3762 / timer/env.step_total 19.41
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.67 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.56 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.8e-4 / 
timer/agent.train_count 1881 / timer/agent.train_total 241.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T005320F400626-4lO4Z0ZePXy6IlGMFuTDDr-6gFaJOkdunA0rK9fRBHruH-1024.npz
train_Episode has 500 steps and return 255.0.
Starting evaluation at step 157000 Counter(157000) 156937
Saved chunk: 20230922T005347F496401-2FA0umTJlxSC0GRgq0ngL3-6P1hsU4cqpZW568V5YXzmP-1024.npz
eval_Episode has 500 steps and return 306.0.
train_Episode has 500 steps and return 259.5.
Starting evaluation at step 157500 Counter(157500) 157437
eval_Episode has 500 steps and return 286.1.
Saved chunk: 20230922T005441F821187-6gFaJOkdunA0rK9fRBHruH-4gQTGM5Ekez9yULO0SfE7y-1024.npz
train_Episode has 500 steps and return 264.0.
Starting evaluation at step 158000 Counter(158000) 157937
Saved chunk: 20230922T005507F551958-6P1hsU4cqpZW568V5YXzmP-5heieoLTvAgCZ4JioN7moR-1024.npz
eval_Episode has 500 steps and return 279.4.
train_Episode has 500 steps and return 260.3.
Starting evaluation at step 158500 Counter(158500) 158437
eval_Episode has 500 steps and return 254.0.
Saved chunk: 20230922T005602F892625-4gQTGM5Ekez9yULO0SfE7y-3ycYXH0PzKlXHb54nJqYcZ-1024.npz
train_Episode has 500 steps and return 281.6.
Starting evaluation at step 159000 Counter(159000) 158937
Saved chunk: 20230922T005626F955653-5heieoLTvAgCZ4JioN7moR-4Ybpn70A3gGqpPvdmVeUXw-1024.npz
eval_Episode has 500 steps and return 295.9.
train_Episode has 500 steps and return 285.2.
Starting evaluation at step 159500 Counter(159500) 159437
eval_Episode has 500 steps and return 283.8.
Saved chunk: 20230922T005723F779058-3ycYXH0PzKlXHb54nJqYcZ-04YvDdfgr6cgq9nex5PsXl-1024.npz
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 160000 Counter(160000) 159937
Saved chunk: 20230922T005746F177006-4Ybpn70A3gGqpPvdmVeUXw-2zoNJq3UfUfxJjuNUEuuz7-1024.npz
eval_Episode has 500 steps and return 298.6.
train_Episode has 500 steps and return 263.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 320766 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 263.55 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 298.58 / eval_episode/reward_rate 0.49 / train/action_mag 3.58 / train/action_max 3.36 / train/action_mean 0.04 / train/action_min -3.14 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 7.9e4 / train/actor_opt_loss -1.41 / train/adv_mag 0.44 / train/adv_max 0.39 / train/adv_mean 8e-4 
/ train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.4e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.96 / train/dyn_loss_std 6.58 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 7.9e4 / 
train/extr_critic_critic_opt_loss 8822.37 / train/extr_critic_mag 210.25 / train/extr_critic_max 210.25 / train/extr_critic_mean 200.27 / train/extr_critic_min 147.56 / train/extr_critic_std 12.6 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 211.46 / train/extr_return_raw_max 211.46 / train/extr_return_raw_mean 200.3 / train/extr_return_raw_min
151.8 / train/extr_return_raw_std 12.64 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.29 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.23 / train/image_loss_std 1.08 / train/model_loss_mean 3.76 /
train/model_loss_std 4.76 / train/model_opt_grad_norm 9.08 / train/model_opt_grad_steps 7.9e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.03 / train/policy_entropy_max 
3.83 / train/policy_entropy_mean -2.19 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 10.05 / train/policy_logprob_max 5.42 / train/policy_logprob_mean 2.19 / train/policy_logprob_min -10.05 / train/policy_logprob_std 1.83 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.3e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 50.76 / train/post_ent_max 50.76 / train/post_ent_mean 39.85 / 
train/post_ent_min 21.1 / train/post_ent_std 5.6 / train/prior_ent_mag 79.46 / train/prior_ent_max 79.46 / train/prior_ent_mean 43.81 / train/prior_ent_min 27.04 / train/prior_ent_std 6.91 / train/rep_loss_mean 3.96 / train/rep_loss_std 6.58 / train/reward_avg 0.27 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.27 / train/reward_rate 
0.26 / train_stats/mean_log_entropy -2.49 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.6e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.73 / report/dyn_loss_std 6.37 / report/image_loss_mean 1.2 / report/image_loss_std 1.11 / report/model_loss_mean 3.59 / report/model_loss_std 4.64 / report/post_ent_mag 51.35 / report/post_ent_max 51.35 / 
report/post_ent_mean 39.55 / report/post_ent_min 23.8 / report/post_ent_std 5.42 / report/prior_ent_mag 79.72 / report/prior_ent_max 79.72 / report/prior_ent_mean 43.23 / report/prior_ent_min 28.83 / report/prior_ent_std 6.88 / report/rep_loss_mean 3.73 / 
report/rep_loss_std 6.37 / report/reward_avg 0.23 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.29 / report/reward_max_data 1.93 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 3.6e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.24 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 8.7e-11 / eval/cont_loss_std 2.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.93 / eval/dyn_loss_std 7.82 / eval/image_loss_mean 1.75 / eval/image_loss_std 2.12 / eval/model_loss_mean 5.52 / eval/model_loss_std 6.32 / eval/post_ent_mag 51.15 / eval/post_ent_max 51.15 / eval/post_ent_mean 
40.94 / eval/post_ent_min 21.38 / eval/post_ent_std 5.35 / eval/prior_ent_mag 79.72 / eval/prior_ent_max 79.72 / eval/prior_ent_mean 45.89 / eval/prior_ent_min 28.69 / eval/prior_ent_std 5.63 / eval/rep_loss_mean 5.93 / eval/rep_loss_std 7.82 / eval/reward_avg 0.34 / 
eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.79 / eval/reward_max_pred 1.81 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.35 / eval/reward_rate 0.33 / 
replay/size 1.6e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3812 / timer/env.step_total 19.88 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.69 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.29 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.6e-3 
/ timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1906 / timer/agent.train_total 245 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 160500 Counter(160500) 160437
eval_Episode has 500 steps and return 273.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T005844F405047-04YvDdfgr6cgq9nex5PsXl-0000000000000000000000-856.npz
Saved chunk: 20230922T005905F219172-2zoNJq3UfUfxJjuNUEuuz7-0000000000000000000000-652.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T005844F405047-04YvDdfgr6cgq9nex5PsXl-09pZsD9Nx8GgkzdS9YICgP-1024.npz
train_Episode has 500 steps and return 255.1.
Starting evaluation at step 161000 Counter(161000) 160937
Saved chunk: 20230922T005905F219172-2zoNJq3UfUfxJjuNUEuuz7-12CeI4qo95eWhOpKE6rkPq-1024.npz
eval_Episode has 500 steps and return 297.1.
train_Episode has 500 steps and return 268.1.
Starting evaluation at step 161500 Counter(161500) 161437
eval_Episode has 500 steps and return 296.9.
Saved chunk: 20230922T010006F346178-09pZsD9Nx8GgkzdS9YICgP-7KV4IqsDiAGVZtPJMUWsIa-1024.npz
train_Episode has 500 steps and return 278.0.
Starting evaluation at step 162000 Counter(162000) 161937
Saved chunk: 20230922T010025F742638-12CeI4qo95eWhOpKE6rkPq-5RQ46vdo9mgoJ5qBJKMEzF-1024.npz
eval_Episode has 500 steps and return 264.2.
train_Episode has 500 steps and return 261.7.
Starting evaluation at step 162500 Counter(162500) 162437
eval_Episode has 500 steps and return 280.2.
Saved chunk: 20230922T010128F350537-7KV4IqsDiAGVZtPJMUWsIa-0TFOioyZKW3kt8opF5OJCf-1024.npz
train_Episode has 500 steps and return 269.3.
Starting evaluation at step 163000 Counter(163000) 162937
eval_Episode has 500 steps and return 292.2.
Saved chunk: 20230922T010146F124548-5RQ46vdo9mgoJ5qBJKMEzF-2DTrstJv4ujrik32Fou6V7-1024.npz
train_Episode has 500 steps and return 251.8.
Starting evaluation at step 163500 Counter(163500) 163437
eval_Episode has 500 steps and return 277.7.
train_Episode has 500 steps and return 271.0.
Saved chunk: 20230922T010249F175902-0TFOioyZKW3kt8opF5OJCf-05GIiWHMnp4eXJjv5D89Ua-1024.npz
Starting evaluation at step 164000 Counter(164000) 163937
eval_Episode has 500 steps and return 292.7.
Saved chunk: 20230922T010305F310877-2DTrstJv4ujrik32Fou6V7-1HYbm63p7P3vCC85jMq9fV-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 328254 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 292.67 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 271.03 / episode/reward_rate 0.43 / train/action_mag 3.6 / train/action_max 3.43 / train/action_mean 0.04 / train/action_min -3.24 / train/action_std
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 8.1e4 / train/actor_opt_loss -1.14 / train/adv_mag 0.36 / train/adv_max 0.29 / train/adv_mean 7.5e-4 / train/adv_min
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.2e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.95 / train/dyn_loss_std 6.58 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 8.1e4 / 
train/extr_critic_critic_opt_loss 8359.29 / train/extr_critic_mag 210.92 / train/extr_critic_max 210.92 / train/extr_critic_mean 201.01 / train/extr_critic_min 151.57 / train/extr_critic_std 12.14 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.03 /
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.25 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 211.92 / train/extr_return_raw_max 211.92 / train/extr_return_raw_mean 201.05 / train/extr_return_raw_min
154 / train/extr_return_raw_std 12.18 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.21 / train/image_loss_std 1.06 / train/model_loss_mean 3.75 / 
train/model_loss_std 4.75 / train/model_opt_grad_norm 9.03 / train/model_opt_grad_steps 8.1e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.51 / train/policy_entropy_max 
4.43 / train/policy_entropy_mean -2.11 / train/policy_entropy_min -3.51 / train/policy_entropy_std 1.23 / train/policy_logprob_mag 10.29 / train/policy_logprob_max 5.42 / train/policy_logprob_mean 2.11 / train/policy_logprob_min -10.29 / train/policy_logprob_std 1.89 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.2e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 50.87 / train/post_ent_max 50.87 / train/post_ent_mean 40.04 / 
train/post_ent_min 20.95 / train/post_ent_std 5.65 / train/prior_ent_mag 79.55 / train/prior_ent_max 79.55 / train/prior_ent_mean 43.98 / train/prior_ent_min 26.87 / train/prior_ent_std 6.93 / train/rep_loss_mean 3.95 / train/rep_loss_std 6.58 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.31 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.29 / train/reward_rate 
0.27 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.41 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 4.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 5.95 / report/image_loss_mean 0.99 / report/image_loss_std 0.91 / report/model_loss_mean 3.25 / report/model_loss_std 4.23 / report/post_ent_mag 52.36 / report/post_ent_max 52.36 /
report/post_ent_mean 39.76 / report/post_ent_min 20.75 / report/post_ent_std 6.22 / report/prior_ent_mag 79.56 / report/prior_ent_max 79.56 / report/prior_ent_mean 43.45 / report/prior_ent_min 26.65 / report/prior_ent_std 7.52 / report/rep_loss_mean 3.49 / 
report/rep_loss_std 5.95 / report/reward_avg 0.32 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.29 / report/reward_max_data 1.9 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 4.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.32 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 3.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.06 / eval/dyn_loss_std 7.02 / eval/image_loss_mean 1.31 / eval/image_loss_std 1.21 / eval/model_loss_mean 4.61 / eval/model_loss_std 5.11 / eval/post_ent_mag 51.23 / eval/post_ent_max 51.23 / eval/post_ent_mean 
41.71 / eval/post_ent_min 16.82 / eval/post_ent_std 5.06 / eval/prior_ent_mag 79.56 / eval/prior_ent_max 79.56 / eval/prior_ent_mean 46.41 / eval/prior_ent_min 29.82 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 5.06 / eval/rep_loss_std 7.02 / eval/reward_avg 0.41 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.42 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.41 / eval/reward_rate 0.41 / 
replay/size 1.6e5 / replay/inserts 3744 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3744 / timer/env.step_total 19.37 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.45 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.7e-4 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7752 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1872 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1872 / timer/agent.train_total 241.87 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.16 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 24.95

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 253.5.
Starting evaluation at step 164500 Counter(164500) 164437
eval_Episode has 500 steps and return 301.0.
train_Episode has 500 steps and return 278.1.
Saved chunk: 20230922T010409F806301-05GIiWHMnp4eXJjv5D89Ua-7AVXVcbEhVMjPn7YHqz0h7-1024.npz
Starting evaluation at step 165000 Counter(165000) 164937
eval_Episode has 500 steps and return 290.0.
Saved chunk: 20230922T010424F337916-1HYbm63p7P3vCC85jMq9fV-4N0C1YekH0L06F8OdVZkuI-1024.npz
train_Episode has 500 steps and return 293.0.
Starting evaluation at step 165500 Counter(165500) 165437
eval_Episode has 500 steps and return 277.1.
train_Episode has 500 steps and return 280.2.
Saved chunk: 20230922T010531F503432-7AVXVcbEhVMjPn7YHqz0h7-6gRtWcIbg4rougHAVVbik2-1024.npz
Starting evaluation at step 166000 Counter(166000) 165937
eval_Episode has 500 steps and return 263.5.
Saved chunk: 20230922T010544F526873-4N0C1YekH0L06F8OdVZkuI-1i9WdtOpBW7QeFjvLhAndK-1024.npz
train_Episode has 500 steps and return 270.1.
Starting evaluation at step 166500 Counter(166500) 166437
eval_Episode has 500 steps and return 275.6.
train_Episode has 500 steps and return 280.6.
Saved chunk: 20230922T010652F431025-6gRtWcIbg4rougHAVVbik2-5Dqyr7IuISeYudTWGwM5RG-1024.npz
Starting evaluation at step 167000 Counter(167000) 166937
eval_Episode has 500 steps and return 275.2.
train_Episode has 500 steps and return 238.2.
Starting evaluation at step 167500 Counter(167500) 167437
Saved chunk: 20230922T010703F889321-1i9WdtOpBW7QeFjvLhAndK-265S4EDfi2q4wdG6dk3gol-1024.npz
eval_Episode has 500 steps and return 282.7.
train_Episode has 500 steps and return 243.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 335878 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 243.89 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 282.73 / eval_episode/reward_rate 0.48 / train/action_mag 3.76 / train/action_max 3.45 / train/action_mean 0.04 / train/action_min -3.54 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 8.2e4 / train/actor_opt_loss -3.41 / train/adv_mag 0.3 / train/adv_max 0.25 / train/adv_mean 9.8e-4 
/ train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.2e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.98 / train/dyn_loss_std 6.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 8.2e4 / 
train/extr_critic_critic_opt_loss 8007.65 / train/extr_critic_mag 212.23 / train/extr_critic_max 212.23 / train/extr_critic_mean 201.95 / train/extr_critic_min 158.82 / train/extr_critic_std 10.75 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.25 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 212.49 / train/extr_return_raw_max 212.49 / train/extr_return_raw_mean 202 / train/extr_return_raw_min 
159.49 / train/extr_return_raw_std 10.81 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.22 / train/image_loss_std 1.05 / train/model_loss_mean 3.77 
/ train/model_loss_std 4.75 / train/model_opt_grad_norm 9.36 / train/model_opt_grad_steps 8.2e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.87 / train/policy_entropy_max
4.85 / train/policy_entropy_mean -2.11 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 10.82 / train/policy_logprob_max 5.43 / train/policy_logprob_mean 2.11 / train/policy_logprob_min -10.82 / train/policy_logprob_std 1.98 / 
train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 1.9e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 50.98 / train/post_ent_max 50.98 / train/post_ent_mean 40.23 / 
train/post_ent_min 21.17 / train/post_ent_std 5.6 / train/prior_ent_mag 79.63 / train/prior_ent_max 79.63 / train/prior_ent_mean 44.21 / train/prior_ent_min 27.19 / train/prior_ent_std 6.87 / train/rep_loss_mean 3.98 / train/rep_loss_std 6.6 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.29 / train/reward_rate 
0.27 / train_stats/mean_log_entropy -2.45 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.6e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 6.27 / report/image_loss_mean 1.16 / report/image_loss_std 0.82 / report/model_loss_mean 3.73 / report/model_loss_std 4.35 / report/post_ent_mag 50.67 / report/post_ent_max 50.67 /
report/post_ent_mean 41.14 / report/post_ent_min 21.81 / report/post_ent_std 5.04 / report/prior_ent_mag 79.79 / report/prior_ent_max 79.79 / report/prior_ent_mean 45.32 / report/prior_ent_min 27.21 / report/prior_ent_std 5.94 / report/rep_loss_mean 3.99 / 
report/rep_loss_std 6.27 / report/reward_avg 0.34 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.31 / report/reward_max_data 1.94 / report/reward_max_pred 1.91 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.33 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 4.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.82 / eval/dyn_loss_std 6.75 / eval/image_loss_mean 1.26 / eval/image_loss_std 1.35 / eval/model_loss_mean 4.41 / eval/model_loss_std 4.95 / eval/post_ent_mag 50.78 / eval/post_ent_max 50.78 / eval/post_ent_mean 
42.02 / eval/post_ent_min 22.88 / eval/post_ent_std 4.45 / eval/prior_ent_mag 79.79 / eval/prior_ent_max 79.79 / eval/prior_ent_mean 46.66 / eval/prior_ent_min 32.98 / eval/prior_ent_std 5.16 / eval/rep_loss_mean 4.82 / eval/rep_loss_std 6.75 / eval/reward_avg 0.45 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.86 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.45 / eval/reward_rate 0.41 / 
replay/size 1.7e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3812 / timer/env.step_total 19.65 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.46 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.35 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1906 / timer/agent.train_total 245.1 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.41

Saved chunk: 20230922T010813F138575-5Dqyr7IuISeYudTWGwM5RG-3My9YHkkLC2jHY6UdJplSt-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 168000 Counter(168000) 167937
eval_Episode has 500 steps and return 289.0.
train_Episode has 500 steps and return 243.1.
Starting evaluation at step 168500 Counter(168500) 168437
Saved chunk: 20230922T010858F916514-265S4EDfi2q4wdG6dk3gol-171Um2wEGiwdUZ7D3jo0SC-1024.npz
eval_Episode has 500 steps and return 301.7.
train_Episode has 500 steps and return 242.8.
Saved chunk: 20230922T010933F748190-3My9YHkkLC2jHY6UdJplSt-3w7F4jh43RelvRLNkKqa7Q-1024.npz
Starting evaluation at step 169000 Counter(169000) 168937
eval_Episode has 500 steps and return 255.3.
train_Episode has 500 steps and return 264.1.
Starting evaluation at step 169500 Counter(169500) 169437
Saved chunk: 20230922T011018F929547-171Um2wEGiwdUZ7D3jo0SC-1O5MMrPp3CMUXdIjngpU8x-1024.npz
eval_Episode has 500 steps and return 278.9.
train_Episode has 500 steps and return 268.7.
Saved chunk: 20230922T011055F507179-3w7F4jh43RelvRLNkKqa7Q-4j9L3LAVwrLmaqc2q2Qtgp-1024.npz
Starting evaluation at step 170000 Counter(170000) 169937
eval_Episode has 500 steps and return 309.2.
train_Episode has 500 steps and return 276.6.
Starting evaluation at step 170500 Counter(170500) 170437
Saved chunk: 20230922T011138F278787-1O5MMrPp3CMUXdIjngpU8x-1i8cOAy2qYONvGg3giGDdQ-1024.npz
eval_Episode has 500 steps and return 291.5.
train_Episode has 500 steps and return 265.9.
Starting evaluation at step 171000 Counter(171000) 170937
eval_Episode has 500 steps and return 248.5.
Saved chunk: 20230922T011216F342252-4j9L3LAVwrLmaqc2q2Qtgp-5GkNzg2Lr6FEbsXRyhSa6g-1024.npz
train_Episode has 500 steps and return 250.0.
Starting evaluation at step 171500 Counter(171500) 171437
Saved chunk: 20230922T011257F427995-1i8cOAy2qYONvGg3giGDdQ-2bN3PwJlBTPcT33mdTEiWK-1024.npz
eval_Episode has 500 steps and return 285.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 343410 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 285.92 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 249.96 / episode/reward_rate 0.43 / train/action_mag 3.67 / train/action_max 3.47 / train/action_mean 0.04 / train/action_min -3.33 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 8.4e4 / train/actor_opt_loss -3.97 / train/adv_mag 0.34 / train/adv_max 0.25 / train/adv_mean 1.1e-3
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.9e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 8.4e4 / 
train/extr_critic_critic_opt_loss 7721.33 / train/extr_critic_mag 213.27 / train/extr_critic_max 213.27 / train/extr_critic_mean 201.87 / train/extr_critic_min 153.19 / train/extr_critic_std 12.48 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 213.16 / train/extr_return_raw_max 213.16 / train/extr_return_raw_mean 201.91 / 
train/extr_return_raw_min 153.1 / train/extr_return_raw_std 12.54 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.18 / train/image_loss_std 1.04 / 
train/model_loss_mean 3.71 / train/model_loss_std 4.72 / train/model_opt_grad_norm 9.12 / train/model_opt_grad_steps 8.4e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.88
/ train/policy_entropy_max 4.86 / train/policy_entropy_mean -2.17 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.29 / train/policy_logprob_mag 10.67 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.17 / train/policy_logprob_min -10.67 / 
train/policy_logprob_std 1.94 / train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 1.7e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 51 / train/post_ent_max 51 / 
train/post_ent_mean 40.36 / train/post_ent_min 21.29 / train/post_ent_std 5.62 / train/prior_ent_mag 79.69 / train/prior_ent_max 79.69 / train/prior_ent_mean 44.3 / train/prior_ent_min 27.14 / train/prior_ent_std 6.88 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.55
/ train/reward_avg 0.29 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 
0.29 / train/reward_rate 0.27 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.49 / report/cont_avg 1 / report/cont_loss_mean 7e-11 / report/cont_loss_std 2.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 6.22 / report/image_loss_mean 1.05 / report/image_loss_std 0.95 / report/model_loss_mean 3.52 / report/model_loss_std 4.48 / report/post_ent_mag 51.97 
/ report/post_ent_max 51.97 / report/post_ent_mean 40.55 / report/post_ent_min 23.24 / report/post_ent_std 5.27 / report/prior_ent_mag 79.64 / report/prior_ent_max 79.64 / report/prior_ent_mean 44.34 / report/prior_ent_min 31.01 / report/prior_ent_std 6.62 / 
report/rep_loss_mean 3.82 / report/rep_loss_std 6.22 / report/reward_avg 0.3 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.34 / report/reward_max_data 1.97 / report/reward_max_pred 1.94 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.3 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 8.6e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.21 / eval/dyn_loss_std 9.8 / eval/image_loss_mean 2.26 / eval/image_loss_std 3.26 / eval/model_loss_mean 6.83 / eval/model_loss_std 8.52 / eval/post_ent_mag 51.97 / eval/post_ent_max
51.97 / eval/post_ent_mean 40.41 / eval/post_ent_min 17.25 / eval/post_ent_std 6.38 / eval/prior_ent_mag 79.64 / eval/prior_ent_max 79.64 / eval/prior_ent_mean 45.73 / eval/prior_ent_min 26.64 / eval/prior_ent_std 6.27 / eval/rep_loss_mean 7.21 / eval/rep_loss_std 9.8 /
eval/reward_avg 0.38 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.54 / eval/reward_max_data 1.89 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.66 / eval/reward_pred 0.38 / 
eval/reward_rate 0.36 / replay/size 1.7e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3766 / timer/env.step_total 19.44 / timer/env.step_frac 0.06 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.94 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / 
timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1883 / 
timer/agent.train_total 242.04 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 261.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 172000 Counter(172000) 171937
Saved chunk: 20230922T011416F446368-2bN3PwJlBTPcT33mdTEiWK-0000000000000000000000-410.npz
Saved chunk: 20230922T011340F490132-5GkNzg2Lr6FEbsXRyhSa6g-0000000000000000000000-992.npz
eval_Episode has 500 steps and return 289.8.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T011340F490132-5GkNzg2Lr6FEbsXRyhSa6g-29saRGY0mlMJChHxJUF7js-1024.npz
train_Episode has 500 steps and return 257.2.
Starting evaluation at step 172500 Counter(172500) 172437
Saved chunk: 20230922T011416F446368-2bN3PwJlBTPcT33mdTEiWK-5ZlP00hYbTz1MLfmxMiJ0U-1024.npz
eval_Episode has 500 steps and return 271.4.
train_Episode has 500 steps and return 264.2.
Starting evaluation at step 173000 Counter(173000) 172937
eval_Episode has 500 steps and return 287.2.
Saved chunk: 20230922T011502F412682-29saRGY0mlMJChHxJUF7js-6N6Bsh1OlE8PgV9eR7DUcv-1024.npz
train_Episode has 500 steps and return 286.1.
Starting evaluation at step 173500 Counter(173500) 173437
Saved chunk: 20230922T011537F010300-5ZlP00hYbTz1MLfmxMiJ0U-1EfPTGXuoAbEOuyJHjGSZ2-1024.npz
eval_Episode has 500 steps and return 300.0.
train_Episode has 500 steps and return 245.1.
Starting evaluation at step 174000 Counter(174000) 173937
eval_Episode has 500 steps and return 312.9.
Saved chunk: 20230922T011623F402685-6N6Bsh1OlE8PgV9eR7DUcv-0xHxPJEDeV5gYkmeCDT82z-1024.npz
train_Episode has 500 steps and return 256.3.
Starting evaluation at step 174500 Counter(174500) 174437
Saved chunk: 20230922T011656F366027-1EfPTGXuoAbEOuyJHjGSZ2-65AE1FXmMSvW2DpRvA5QGX-1024.npz
eval_Episode has 500 steps and return 284.9.
train_Episode has 500 steps and return 257.6.
Starting evaluation at step 175000 Counter(175000) 174937
eval_Episode has 500 steps and return 289.0.
Saved chunk: 20230922T011744F230320-0xHxPJEDeV5gYkmeCDT82z-0k7UfBfh9BU5SskJwPMT0j-1024.npz
train_Episode has 500 steps and return 229.9.
Starting evaluation at step 175500 Counter(175500) 175437
Saved chunk: 20230922T011815F490485-65AE1FXmMSvW2DpRvA5QGX-6POKEBoQtRSsMba6HCnTFO-1024.npz
eval_Episode has 500 steps and return 296.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 351002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 229.9 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 296.23 / eval_episode/reward_rate 0.46 / train/action_mag 3.77 / train/action_max 3.55 / train/action_mean 0.04 / train/action_min -3.5 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 8.6e4 / train/actor_opt_loss -5.16 / train/adv_mag 0.32 / train/adv_max 0.25 / train/adv_mean 1.2e-3 / train/adv_min
-0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.1e-11 / train/cont_loss_std 4.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.94 / train/dyn_loss_std 6.54 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 8.6e4 / 
train/extr_critic_critic_opt_loss 7381.23 / train/extr_critic_mag 213.55 / train/extr_critic_max 213.55 / train/extr_critic_mean 202.75 / train/extr_critic_min 155.52 / train/extr_critic_std 11.97 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 213.77 / train/extr_return_raw_max 213.77 / train/extr_return_raw_mean 202.81 / train/extr_return_raw_min 
157 / train/extr_return_raw_std 12.04 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.18 / train/image_loss_std 1.05 / train/model_loss_mean 3.71 / 
train/model_loss_std 4.72 / train/model_opt_grad_norm 9.21 / train/model_opt_grad_steps 8.6e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.12 / train/policy_entropy_max 
5.09 / train/policy_entropy_mean -2.1 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 11.03 / train/policy_logprob_max 5.43 / train/policy_logprob_mean 2.1 / train/policy_logprob_min -11.03 / train/policy_logprob_std 2.01 / 
train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.9e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.06 / train/post_ent_max 51.06 / train/post_ent_mean 40.51 / 
train/post_ent_min 21.47 / train/post_ent_std 5.59 / train/prior_ent_mag 79.75 / train/prior_ent_max 79.75 / train/prior_ent_mean 44.43 / train/prior_ent_min 27.19 / train/prior_ent_std 6.86 / train/rep_loss_mean 3.94 / train/rep_loss_std 6.54 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.29 / train/reward_rate 
0.27 / train_stats/mean_log_entropy -2.43 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.01 / report/dyn_loss_std 6.83 / report/image_loss_mean 1.22 / report/image_loss_std 1.21 / report/model_loss_mean 3.8 / report/model_loss_std 5.02 / report/post_ent_mag 51.44 / report/post_ent_max 51.44 / 
report/post_ent_mean 40.66 / report/post_ent_min 20.26 / report/post_ent_std 6.11 / report/prior_ent_mag 79.76 / report/prior_ent_max 79.76 / report/prior_ent_mean 44.48 / report/prior_ent_min 25.85 / report/prior_ent_std 7 / report/rep_loss_mean 4.01 / 
report/rep_loss_std 6.83 / report/reward_avg 0.3 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.29 / report/reward_max_data 1.9 / report/reward_max_pred 1.89 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.3 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 9.6e-11 / eval/cont_loss_std 4.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.08 / eval/dyn_loss_std 8.69 / eval/image_loss_mean 1.88 / eval/image_loss_std 2.94 / eval/model_loss_mean 5.76 / eval/model_loss_std 7.5 / eval/post_ent_mag 49.86 / eval/post_ent_max 49.86 / eval/post_ent_mean 
41.38 / eval/post_ent_min 20.93 / eval/post_ent_std 5.68 / eval/prior_ent_mag 79.76 / eval/prior_ent_max 79.76 / eval/prior_ent_mean 46.38 / eval/prior_ent_min 29.96 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 6.08 / eval/rep_loss_std 8.69 / eval/reward_avg 0.4 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.91 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.39 / eval/reward_rate 0.38 / 
replay/size 1.8e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.86 / timer/env.step_count 3796 / timer/env.step_total 19.6 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.05 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.5e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7804 / timer/agent.policy_total 17.63 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1898 / timer/agent.train_total 244.16 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 275.3.
Starting evaluation at step 176000 Counter(176000) 175937
eval_Episode has 500 steps and return 293.2.
Saved chunk: 20230922T011904F885384-0k7UfBfh9BU5SskJwPMT0j-5qFVME5dfNtmC48XBuktJu-1024.npz
train_Episode has 500 steps and return 262.1.
Starting evaluation at step 176500 Counter(176500) 176437
Saved chunk: 20230922T011934F607580-6POKEBoQtRSsMba6HCnTFO-6j4gyd7PgnnR1JayFCVPbx-1024.npz
eval_Episode has 500 steps and return 294.3.
train_Episode has 500 steps and return 280.0.
Starting evaluation at step 177000 Counter(177000) 176937
eval_Episode has 500 steps and return 274.7.
Saved chunk: 20230922T012026F548326-5qFVME5dfNtmC48XBuktJu-5xAgT2mQI8bS8yfFj6suML-1024.npz
train_Episode has 500 steps and return 259.4.
Starting evaluation at step 177500 Counter(177500) 177437
Saved chunk: 20230922T012054F805223-6j4gyd7PgnnR1JayFCVPbx-5gEIFzsfaKPcv5JXFdNzJJ-1024.npz
eval_Episode has 500 steps and return 289.6.
train_Episode has 500 steps and return 262.4.
Starting evaluation at step 178000 Counter(178000) 177937
eval_Episode has 500 steps and return 303.2.
Saved chunk: 20230922T012147F541130-5xAgT2mQI8bS8yfFj6suML-551obNT5Uti5zO1dzObHbL-1024.npz
train_Episode has 500 steps and return 261.0.
Starting evaluation at step 178500 Counter(178500) 178437
Saved chunk: 20230922T012214F190834-5gEIFzsfaKPcv5JXFdNzJJ-3UyvF2L2twRTldJhdh6gqA-1024.npz
eval_Episode has 500 steps and return 293.8.
train_Episode has 500 steps and return 285.3.
Starting evaluation at step 179000 Counter(179000) 178937
eval_Episode has 500 steps and return 273.9.
Saved chunk: 20230922T012308F309254-551obNT5Uti5zO1dzObHbL-2w9oVYYLOoRvzpYZHtIm80-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 358626 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 285.32 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 273.88 / eval_episode/reward_rate 0.44 / train/action_mag 3.88 / train/action_max 3.66 / train/action_mean 0.05 / train/action_min -3.64 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.21 / train/actor_opt_grad_steps 8.8e4 / train/actor_opt_loss -5.79 / train/adv_mag 0.38 / train/adv_max 0.32 / train/adv_mean 
1.2e-3 / train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.6e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.6e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.95 / train/dyn_loss_std 6.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 8.8e4 / train/extr_critic_critic_opt_loss 7059.1 / train/extr_critic_mag 214.07 / train/extr_critic_max 214.07 / train/extr_critic_mean 203.57 / train/extr_critic_min 150.73 / train/extr_critic_std 12.47 / 
train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 214.51 / 
train/extr_return_raw_max 214.51 / train/extr_return_raw_mean 203.62 / train/extr_return_raw_min 153.96 / train/extr_return_raw_std 12.53 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / 
train/extr_reward_std 0.57 / train/image_loss_mean 1.17 / train/image_loss_std 1.03 / train/model_loss_mean 3.71 / train/model_loss_std 4.69 / train/model_opt_grad_norm 8.89 / train/model_opt_grad_steps 8.8e4 / train/model_opt_loss 3.7e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.31 / train/policy_entropy_max 5.28 / train/policy_entropy_mean -2.07 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.52 / 
train/policy_logprob_mag 11.48 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.07 / train/policy_logprob_min -11.48 / train/policy_logprob_std 2.1 / train/policy_randomness_mag 0.96 / train/policy_randomness_max 0.96 / train/policy_randomness_mean 0.16 / 
train/policy_randomness_min 1.7e-3 / train/policy_randomness_std 0.17 / train/post_ent_mag 51.13 / train/post_ent_max 51.13 / train/post_ent_mean 40.86 / train/post_ent_min 21.64 / train/post_ent_std 5.52 / train/prior_ent_mag 79.81 / train/prior_ent_max 79.81 / 
train/prior_ent_mean 44.81 / train/prior_ent_min 27.46 / train/prior_ent_std 6.72 / train/rep_loss_mean 3.95 / train/rep_loss_std 6.51 / train/reward_avg 0.31 / train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.93 / train/reward_max_pred
1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.31 / train/reward_rate 0.28 / train_stats/mean_log_entropy -2.46 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 6.1e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.14 / report/dyn_loss_std 6.83 / 
report/image_loss_mean 1.36 / report/image_loss_std 1.25 / report/model_loss_mean 4 / report/model_loss_std 5.05 / report/post_ent_mag 51.56 / report/post_ent_max 51.56 / report/post_ent_mean 40.35 / report/post_ent_min 16.52 / report/post_ent_std 6.12 / 
report/prior_ent_mag 79.88 / report/prior_ent_max 79.88 / report/prior_ent_mean 44.54 / report/prior_ent_min 25.4 / report/prior_ent_std 6.85 / report/rep_loss_mean 4.14 / report/rep_loss_std 6.83 / report/reward_avg 0.26 / report/reward_loss_mean 0.15 / 
report/reward_loss_std 0.3 / report/reward_max_data 1.96 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 7.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.26 / report/reward_rate 0.26 / eval/cont_avg 1
/ eval/cont_loss_mean 8e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.85 / eval/dyn_loss_std 6.73 / eval/image_loss_mean 
1.21 / eval/image_loss_std 1.18 / eval/model_loss_mean 4.37 / eval/model_loss_std 4.9 / eval/post_ent_mag 50.19 / eval/post_ent_max 50.19 / eval/post_ent_mean 42.46 / eval/post_ent_min 19.98 / eval/post_ent_std 4.66 / eval/prior_ent_mag 79.88 / eval/prior_ent_max 79.88 
/ eval/prior_ent_mean 47.07 / eval/prior_ent_min 32.74 / eval/prior_ent_std 5.01 / eval/rep_loss_mean 4.85 / eval/rep_loss_std 6.73 / eval/reward_avg 0.47 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.93 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.47 / eval/reward_rate 0.4 / replay/size 1.8e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 
1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3812 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 451.14 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count
7319 / timer/agent.policy_total 16.32 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / 
timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1906 / timer/agent.train_total 245.21 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 264.3.
Starting evaluation at step 179500 Counter(179500) 179437
Saved chunk: 20230922T012333F326368-3UyvF2L2twRTldJhdh6gqA-7m6LkLAVOB6U0ZtcLpk7gs-1024.npz
eval_Episode has 500 steps and return 255.7.
train_Episode has 500 steps and return 267.2.
Starting evaluation at step 180000 Counter(180000) 179937
eval_Episode has 500 steps and return 304.4.
Saved chunk: 20230922T012428F977855-2w9oVYYLOoRvzpYZHtIm80-3QzEm22JmHhJDwIiDbgoF1-1024.npz
train_Episode has 500 steps and return 287.0.
Starting evaluation at step 180500 Counter(180500) 180437
Saved chunk: 20230922T012453F288215-7m6LkLAVOB6U0ZtcLpk7gs-5cdMYkyFaUTPST1qDCqmwl-1024.npz
eval_Episode has 500 steps and return 310.9.
train_Episode has 500 steps and return 266.5.
Starting evaluation at step 181000 Counter(181000) 180937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012550F808980-3QzEm22JmHhJDwIiDbgoF1-3dAaEzqaBr7ZjmTdvBKk5V-1024.npz
train_Episode has 500 steps and return 269.1.
Starting evaluation at step 181500 Counter(181500) 181437
Saved chunk: 20230922T012612F749264-5cdMYkyFaUTPST1qDCqmwl-5jiO1rzmmlN4zpK9U72AbV-1024.npz
eval_Episode has 500 steps and return 290.8.
train_Episode has 500 steps and return 239.7.
Starting evaluation at step 182000 Counter(182000) 181937
eval_Episode has 500 steps and return 283.3.
Saved chunk: 20230922T012711F836368-3dAaEzqaBr7ZjmTdvBKk5V-4z84V5SiH3sZMXI3Oefyep-1024.npz
train_Episode has 500 steps and return 235.8.
Starting evaluation at step 182500 Counter(182500) 182437
Saved chunk: 20230922T012732F146844-5jiO1rzmmlN4zpK9U72AbV-3dS7CKS56DJGpPeAI35M6z-1024.npz
eval_Episode has 500 steps and return 287.3.
train_Episode has 500 steps and return 268.4.
Starting evaluation at step 183000 Counter(183000) 182937
eval_Episode has 500 steps and return 266.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 366150 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 268.41 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 266.9 / eval_episode/reward_rate 0.44 / train/action_mag 3.98 / train/action_max 3.75 / train/action_mean 0.04 / train/action_min -3.73 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 9e4 / train/actor_opt_loss -4.66 / train/adv_mag 0.37 / train/adv_max 0.29 / train/adv_mean 1.1e-3 / train/adv_min 
-0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.1e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.54 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 9e4 / 
train/extr_critic_critic_opt_loss 6977.83 / train/extr_critic_mag 214.9 / train/extr_critic_max 214.9 / train/extr_critic_mean 203.27 / train/extr_critic_min 141.67 / train/extr_critic_std 15.04 / train/extr_return_normed_mag 1.56 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.33 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 215.3 / train/extr_return_raw_max 215.3 / train/extr_return_raw_mean 203.32 / train/extr_return_raw_min 
143.72 / train/extr_return_raw_std 15.1 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 1.16 / train/image_loss_std 1.02 / train/model_loss_mean 3.67 /
train/model_loss_std 4.69 / train/model_opt_grad_norm 9 / train/model_opt_grad_steps 9e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.27 / train/policy_entropy_max 5.22 /
train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.6 / train/policy_logprob_mag 11.59 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.04 / train/policy_logprob_min -11.59 / train/policy_logprob_std 2.16 / 
train/policy_randomness_mag 0.95 / train/policy_randomness_max 0.95 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.5e-3 / train/policy_randomness_std 0.17 / train/post_ent_mag 51.17 / train/post_ent_max 51.17 / train/post_ent_mean 40.67 / 
train/post_ent_min 21.22 / train/post_ent_std 5.68 / train/prior_ent_mag 79.88 / train/prior_ent_max 79.88 / train/prior_ent_mean 44.57 / train/prior_ent_min 27.14 / train/prior_ent_std 6.94 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.54 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.3 / train/reward_rate 
0.27 / train_stats/mean_log_entropy -2.49 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.61 / report/dyn_loss_std 6.03 / report/image_loss_mean 1 / report/image_loss_std 0.83 / report/model_loss_mean 3.31 / report/model_loss_std 4.3 / report/post_ent_mag 51.25 / report/post_ent_max 51.25 / 
report/post_ent_mean 41.24 / report/post_ent_min 23.28 / report/post_ent_std 5.11 / report/prior_ent_mag 79.92 / report/prior_ent_max 79.92 / report/prior_ent_mean 44.78 / report/prior_ent_min 26.64 / report/prior_ent_std 6.42 / report/rep_loss_mean 3.61 / 
report/rep_loss_std 6.03 / report/reward_avg 0.28 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.3 / report/reward_max_data 1.91 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.27 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.75 / eval/dyn_loss_std 8 / eval/image_loss_mean 1.59 / eval/image_loss_std 2.03 / eval/model_loss_mean 5.27 / eval/model_loss_std 6.34 / eval/post_ent_mag 51.02 / eval/post_ent_max 51.02 / eval/post_ent_mean 
41.55 / eval/post_ent_min 21.4 / eval/post_ent_std 5.52 / eval/prior_ent_mag 79.92 / eval/prior_ent_max 79.92 / eval/prior_ent_mean 46.56 / eval/prior_ent_min 31.47 / eval/prior_ent_std 5.64 / eval/rep_loss_mean 5.75 / eval/rep_loss_std 8 / eval/reward_avg 0.38 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.43 / eval/reward_max_data 1.88 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.2e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.38 / eval/reward_rate 0.36 / 
replay/size 1.8e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3762 / timer/env.step_total 19.4 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.92 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.24 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1881 / timer/agent.train_total 242.09 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T012832F495160-4z84V5SiH3sZMXI3Oefyep-3HaDGcd5ey2rJQjU3HZtcg-1024.npz
train_Episode has 500 steps and return 262.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T012953F993189-3HaDGcd5ey2rJQjU3HZtcg-0000000000000000000000-104.npz
Saved chunk: 20230922T012851F203921-3dS7CKS56DJGpPeAI35M6z-0000000000000000000000-669.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 183500 Counter(183500) 183437
Saved chunk: 20230922T012851F203921-3dS7CKS56DJGpPeAI35M6z-4xV63FouamSEx8Oo8LTaSs-1024.npz
eval_Episode has 500 steps and return 301.7.
train_Episode has 500 steps and return 257.5.
Starting evaluation at step 184000 Counter(184000) 183937
eval_Episode has 500 steps and return 302.1.
Saved chunk: 20230922T012953F993189-3HaDGcd5ey2rJQjU3HZtcg-3u323ZVEkW1gMbhJzg0KuP-1024.npz
train_Episode has 500 steps and return 265.1.
Starting evaluation at step 184500 Counter(184500) 184437
Saved chunk: 20230922T013011F550425-4xV63FouamSEx8Oo8LTaSs-3NvfqSjfJADkegzEkZfoeV-1024.npz
eval_Episode has 500 steps and return 305.8.
train_Episode has 500 steps and return 252.5.
Starting evaluation at step 185000 Counter(185000) 184937
eval_Episode has 500 steps and return 292.4.
Saved chunk: 20230922T013115F410029-3u323ZVEkW1gMbhJzg0KuP-0EiIvfnx4MUex7wCDNZ0Ko-1024.npz
train_Episode has 500 steps and return 277.7.
Starting evaluation at step 185500 Counter(185500) 185437
Saved chunk: 20230922T013131F027348-3NvfqSjfJADkegzEkZfoeV-59mVx0vkF5LmsvaDKG7IS0-1024.npz
eval_Episode has 500 steps and return 299.5.
train_Episode has 500 steps and return 265.6.
Starting evaluation at step 186000 Counter(186000) 185937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 259.4.
Saved chunk: 20230922T013236F264275-0EiIvfnx4MUex7wCDNZ0Ko-5ZnDLK8E2q4eZeU8BgtU2a-1024.npz
Starting evaluation at step 186500 Counter(186500) 186437
Saved chunk: 20230922T013250F242661-59mVx0vkF5LmsvaDKG7IS0-1OKxacqWSzjDc6mLKaL7rx-1024.npz
eval_Episode has 500 steps and return 294.9.
train_Episode has 500 steps and return 239.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 373762 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 239.81 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 294.9 / eval_episode/reward_rate 0.49 / train/action_mag 3.92 / train/action_max 3.74 / train/action_mean 0.05 / train/action_min -3.58 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 9.2e4 / train/actor_opt_loss -6.88 / train/adv_mag 0.42 / train/adv_max 0.36 / train/adv_mean 1.3e-3 / train/adv_min
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.9e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.97 / train/dyn_loss_std 6.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 9.2e4 / 
train/extr_critic_critic_opt_loss 6712.93 / train/extr_critic_mag 215.82 / train/extr_critic_max 215.82 / train/extr_critic_mean 204.84 / train/extr_critic_min 142.55 / train/extr_critic_std 14.07 / train/extr_return_normed_mag 1.61 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.32 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 216.16 / train/extr_return_raw_max 216.16 / train/extr_return_raw_mean 204.9 / train/extr_return_raw_min
145.06 / train/extr_return_raw_std 14.11 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.16 / train/image_loss_std 1.03 / train/model_loss_mean 3.72 
/ train/model_loss_std 4.7 / train/model_opt_grad_norm 8.72 / train/model_opt_grad_steps 9.2e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.16 / train/policy_entropy_max 
5.12 / train/policy_entropy_mean -2.13 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.46 / train/policy_logprob_mag 11.19 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.13 / train/policy_logprob_min -11.19 / train/policy_logprob_std 2.05 / 
train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 1.4e-3 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.2 / train/post_ent_max 51.2 / train/post_ent_mean 40.95 / 
train/post_ent_min 21.33 / train/post_ent_std 5.62 / train/prior_ent_mag 79.93 / train/prior_ent_max 79.93 / train/prior_ent_mean 44.92 / train/prior_ent_min 27.03 / train/prior_ent_std 6.81 / train/rep_loss_mean 3.97 / train/rep_loss_std 6.53 / train/reward_avg 0.31 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.93 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.31 / train/reward_rate 
0.28 / train_stats/mean_log_entropy -2.47 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 7.02 / report/image_loss_mean 1.08 / report/image_loss_std 1.04 / report/model_loss_mean 3.52 / report/model_loss_std 5.06 / report/post_ent_mag 50.78 / report/post_ent_max 50.78 /
report/post_ent_mean 39.83 / report/post_ent_min 16.07 / report/post_ent_std 6.68 / report/prior_ent_mag 80.01 / report/prior_ent_max 80.01 / report/prior_ent_mean 43.74 / report/prior_ent_min 25.59 / report/prior_ent_std 7.88 / report/rep_loss_mean 3.84 / 
report/rep_loss_std 7.02 / report/reward_avg 0.24 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.27 / report/reward_max_data 1.88 / report/reward_max_pred 1.87 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.24 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.45 / eval/dyn_loss_std 7.35 / eval/image_loss_mean 1.42 / eval/image_loss_std 1.7 / eval/model_loss_mean 4.94 / eval/model_loss_std 5.62 / eval/post_ent_mag 50.77 / eval/post_ent_max 50.77 / eval/post_ent_mean 
42.04 / eval/post_ent_min 19.24 / eval/post_ent_std 5.36 / eval/prior_ent_mag 80.01 / eval/prior_ent_max 80.01 / eval/prior_ent_mean 46.81 / eval/prior_ent_min 28.18 / eval/prior_ent_std 5.37 / eval/rep_loss_mean 5.45 / eval/rep_loss_std 7.35 / eval/reward_avg 0.45 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.45 / eval/reward_rate 0.39 / 
replay/size 1.9e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3806 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.97 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.48 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.86 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.36

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 187000 Counter(187000) 186937
eval_Episode has 500 steps and return 263.5.
train_Episode has 500 steps and return 277.2.
Saved chunk: 20230922T013356F961355-5ZnDLK8E2q4eZeU8BgtU2a-0qIGBYydogmKICbswCvSrU-1024.npz
Starting evaluation at step 187500 Counter(187500) 187437
eval_Episode has 500 steps and return 285.0.
Saved chunk: 20230922T013409F375142-1OKxacqWSzjDc6mLKaL7rx-6RnIq4fJnXhV3m8JYd7rw6-1024.npz
train_Episode has 500 steps and return 291.1.
Starting evaluation at step 188000 Counter(188000) 187937
eval_Episode has 500 steps and return 287.7.
train_Episode has 500 steps and return 269.9.
Saved chunk: 20230922T013518F647080-0qIGBYydogmKICbswCvSrU-0SuewjmsVTAsKzPJYDwNVv-1024.npz
Starting evaluation at step 188500 Counter(188500) 188437
eval_Episode has 500 steps and return 282.7.
Saved chunk: 20230922T013529F572196-6RnIq4fJnXhV3m8JYd7rw6-6IqegE8F7NUX3UhyniREEf-1024.npz
train_Episode has 500 steps and return 272.4.
Starting evaluation at step 189000 Counter(189000) 188937
eval_Episode has 500 steps and return 314.1.
train_Episode has 500 steps and return 263.1.
Saved chunk: 20230922T013639F551040-0SuewjmsVTAsKzPJYDwNVv-1yLczja61lX7KWCvduV0pV-1024.npz
Starting evaluation at step 189500 Counter(189500) 189437
eval_Episode has 500 steps and return 309.5.
Saved chunk: 20230922T013648F876551-6IqegE8F7NUX3UhyniREEf-0E1mu5ZPtG17pZ82mceOu3-1024.npz
train_Episode has 500 steps and return 227.3.
Starting evaluation at step 190000 Counter(190000) 189937
eval_Episode has 500 steps and return 289.3.
train_Episode has 500 steps and return 242.0.
Saved chunk: 20230922T013800F448119-1yLczja61lX7KWCvduV0pV-2OBoolm38mG6cpTyQYw9aQ-1024.npz
Starting evaluation at step 190500 Counter(190500) 190437
eval_Episode has 500 steps and return 294.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 381282 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 294.72 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 241.99 / episode/reward_rate 0.41 / train/action_mag 3.9 / train/action_max 3.73 / train/action_mean 0.05 / train/action_min -3.46 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 9.4e4 / train/actor_opt_loss -7.73 / train/adv_mag 0.4 / train/adv_max 0.32 / train/adv_mean 1.4e-3 / train/adv_min 
-0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.92 / train/dyn_loss_std 6.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 9.4e4 / 
train/extr_critic_critic_opt_loss 6702.52 / train/extr_critic_mag 216.96 / train/extr_critic_max 216.96 / train/extr_critic_mean 206.05 / train/extr_critic_min 156.74 / train/extr_critic_std 12.59 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 217.27 / train/extr_return_raw_max 217.27 / train/extr_return_raw_mean 206.11 / 
train/extr_return_raw_min 156.61 / train/extr_return_raw_std 12.65 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.14 / train/image_loss_std 1.03 / 
train/model_loss_mean 3.66 / train/model_loss_std 4.72 / train/model_opt_grad_norm 8.86 / train/model_opt_grad_steps 9.4e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.1 
/ train/policy_entropy_max 5.06 / train/policy_entropy_mean -2.2 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.78 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.2 / train/policy_logprob_min -10.78 / 
train/policy_logprob_std 2.01 / train/policy_randomness_mag 0.93 / train/policy_randomness_max 0.93 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.18 / train/post_ent_max 51.18 / 
train/post_ent_mean 41.03 / train/post_ent_min 21.62 / train/post_ent_std 5.52 / train/prior_ent_mag 79.97 / train/prior_ent_max 79.97 / train/prior_ent_mean 44.93 / train/prior_ent_min 27.53 / train/prior_ent_std 6.78 / train/rep_loss_mean 3.92 / train/rep_loss_std 
6.55 / train/reward_avg 0.31 / train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.31 / train/reward_rate 0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.53 / report/cont_avg 1 / report/cont_loss_mean 5.3e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.4 / report/dyn_loss_std 6.98 / report/image_loss_mean 1.3 / report/image_loss_std 0.98 / report/model_loss_mean 4.1 / report/model_loss_std 4.84 / 
report/post_ent_mag 51.86 / report/post_ent_max 51.86 / report/post_ent_mean 41.4 / report/post_ent_min 22.76 / report/post_ent_std 5.51 / report/prior_ent_mag 80.11 / report/prior_ent_max 80.11 / report/prior_ent_mean 45.88 / report/prior_ent_min 26.45 / 
report/prior_ent_std 6.63 / report/rep_loss_mean 4.4 / report/rep_loss_std 6.98 / report/reward_avg 0.3 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.97 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.3 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 9.5e-11 / eval/cont_loss_std 8.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 9.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.99 / eval/dyn_loss_std 6.54 / eval/image_loss_mean 1.32 / eval/image_loss_std 1.64 / eval/model_loss_mean 4.57 / eval/model_loss_std 5.11 / eval/post_ent_mag 
49.88 / eval/post_ent_max 49.88 / eval/post_ent_mean 42.67 / eval/post_ent_min 24.8 / eval/post_ent_std 4.38 / eval/prior_ent_mag 80.11 / eval/prior_ent_max 80.11 / eval/prior_ent_mean 47.23 / eval/prior_ent_min 31.83 / eval/prior_ent_std 4.98 / eval/rep_loss_mean 4.99 
/ eval/rep_loss_std 6.54 / eval/reward_avg 0.46 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 / 
eval/reward_pred 0.46 / eval/reward_rate 0.41 / replay/size 1.9e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3760 / timer/env.step_total 19.54 / 
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.77 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
5.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.29 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.5e-4 / 
timer/agent.train_count 1880 / timer/agent.train_total 241.84 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / 
timer/dataset_eval_max 4e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 294.0.
Starting evaluation at step 191000 Counter(191000) 190937
Saved chunk: 20230922T013808F167321-0E1mu5ZPtG17pZ82mceOu3-6wxbW2eX9aN41HFwnMUlnP-1024.npz
eval_Episode has 500 steps and return 288.2.
train_Episode has 500 steps and return 275.0.
Saved chunk: 20230922T013921F075578-2OBoolm38mG6cpTyQYw9aQ-5HuojAIJl8TSwNDUo6uRbN-1024.npz
Starting evaluation at step 191500 Counter(191500) 191437
eval_Episode has 500 steps and return 294.5.
train_Episode has 500 steps and return 247.3.
Starting evaluation at step 192000 Counter(192000) 191937
Saved chunk: 20230922T014004F126258-6wxbW2eX9aN41HFwnMUlnP-4Eum4nlKodyv8AEGtc8dQq-1024.npz
eval_Episode has 500 steps and return 291.7.
train_Episode has 500 steps and return 243.4.
Starting evaluation at step 192500 Counter(192500) 192437
eval_Episode has 500 steps and return 291.4.
Saved chunk: 20230922T014042F878647-5HuojAIJl8TSwNDUo6uRbN-2DiM7x4ctwTCgjgsPqueY4-1024.npz
train_Episode has 500 steps and return 270.7.
Starting evaluation at step 193000 Counter(193000) 192937
Saved chunk: 20230922T014123F555608-4Eum4nlKodyv8AEGtc8dQq-6M7ACYqqN6AaNZpoSfXFQc-1024.npz
eval_Episode has 500 steps and return 297.6.
train_Episode has 500 steps and return 280.6.
Starting evaluation at step 193500 Counter(193500) 193437
eval_Episode has 500 steps and return 280.5.
Saved chunk: 20230922T014207F327938-2DiM7x4ctwTCgjgsPqueY4-30dxiWYVWAjVKQ0WrDPTpM-1024.npz
train_Episode has 500 steps and return 266.2.
Starting evaluation at step 194000 Counter(194000) 193937
Saved chunk: 20230922T014242F813908-6M7ACYqqN6AaNZpoSfXFQc-2zTzCwsof1pIFY8kgPZPyH-1024.npz
eval_Episode has 500 steps and return 284.8.
train_Episode has 500 steps and return 296.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 388910 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 296.8 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 284.79 / eval_episode/reward_rate 0.44 / train/action_mag 3.81 / train/action_max 3.69 / train/action_mean 0.05 / train/action_min -3.38 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 9.6e4 / train/actor_opt_loss -7.21 / train/adv_mag 0.34 / train/adv_max 0.27 / train/adv_mean 1.4e-3 / train/adv_min 
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.2e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.88 / train/dyn_loss_std 6.45 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 9.6e4 / 
train/extr_critic_critic_opt_loss 6803.29 / train/extr_critic_mag 218.22 / train/extr_critic_max 218.22 / train/extr_critic_mean 207.76 / train/extr_critic_min 160.11 / train/extr_critic_std 11.62 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 218.48 / train/extr_return_raw_max 218.48 / train/extr_return_raw_mean 207.82 / train/extr_return_raw_min
159.98 / train/extr_return_raw_std 11.67 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.33 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.13 / train/image_loss_std 1.01 / train/model_loss_mean 3.62 
/ train/model_loss_std 4.64 / train/model_opt_grad_norm 8.91 / train/model_opt_grad_steps 9.6e4 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.92 / train/policy_entropy_max
4.87 / train/policy_entropy_mean -2.22 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.33 / train/policy_logprob_mag 10.71 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.22 / train/policy_logprob_min -10.71 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.36 / train/post_ent_max 51.36 / train/post_ent_mean 41.18 / 
train/post_ent_min 21.52 / train/post_ent_std 5.49 / train/prior_ent_mag 80.01 / train/prior_ent_max 80.01 / train/prior_ent_mean 45.05 / train/prior_ent_min 27.75 / train/prior_ent_std 6.7 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.45 / train/reward_avg 0.32 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.32 / train/reward_rate 
0.28 / train_stats/mean_log_entropy -2.53 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.12 / report/image_loss_mean 1.07 / report/image_loss_std 0.8 / report/model_loss_mean 3.56 / report/model_loss_std 4.25 / report/post_ent_mag 51.47 / report/post_ent_max 51.47 / 
report/post_ent_mean 42.21 / report/post_ent_min 20.92 / report/post_ent_std 4.95 / report/prior_ent_mag 80.03 / report/prior_ent_max 80.03 / report/prior_ent_mean 46.09 / report/prior_ent_min 29.61 / report/prior_ent_std 5.99 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 6.12 / report/reward_avg 0.37 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.29 / report/reward_max_data 1.91 / report/reward_max_pred 1.89 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.38 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.29 / eval/dyn_loss_std 7.7 / eval/image_loss_mean 1.56 / eval/image_loss_std 2.06 / eval/model_loss_mean 4.97 / eval/model_loss_std 6.11 / eval/post_ent_mag 49.45 / eval/post_ent_max 49.45 / eval/post_ent_mean 
40.41 / eval/post_ent_min 18.93 / eval/post_ent_std 6.98 / eval/prior_ent_mag 80.03 / eval/prior_ent_max 80.03 / eval/prior_ent_mean 45.15 / eval/prior_ent_min 23.99 / eval/prior_ent_std 7.62 / eval/rep_loss_mean 5.29 / eval/rep_loss_std 7.7 / eval/reward_avg 0.44 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.44 / eval/reward_rate 0.39 / 
replay/size 1.9e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3814 / timer/env.step_total 19.64 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.1e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 458.95 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.34 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.5e-3 
/ timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1907 / timer/agent.train_total 245.17 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 194500 Counter(194500) 194437
eval_Episode has 500 steps and return 303.3.
Saved chunk: 20230922T014327F921987-30dxiWYVWAjVKQ0WrDPTpM-3Nn7TSAWNqBvBBHXAHz9z7-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T014401F711139-2zTzCwsof1pIFY8kgPZPyH-0000000000000000000000-928.npz
Saved chunk: 20230922T014449F323159-3Nn7TSAWNqBvBBHXAHz9z7-0000000000000000000000-240.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 280.4.
Starting evaluation at step 195000 Counter(195000) 194937
Saved chunk: 20230922T014401F711139-2zTzCwsof1pIFY8kgPZPyH-6NPYDlq5LV0KwMD8MdkUba-1024.npz
eval_Episode has 500 steps and return 293.7.
train_Episode has 500 steps and return 272.8.
Starting evaluation at step 195500 Counter(195500) 195437
eval_Episode has 500 steps and return 297.6.
Saved chunk: 20230922T014449F323159-3Nn7TSAWNqBvBBHXAHz9z7-1VcuYB7GMi17S2xf2LAb5r-1024.npz
train_Episode has 500 steps and return 274.7.
Starting evaluation at step 196000 Counter(196000) 195937
Saved chunk: 20230922T014522F090140-6NPYDlq5LV0KwMD8MdkUba-2kEFGDFLJs828pSoh9hbbv-1024.npz
eval_Episode has 500 steps and return 256.6.
train_Episode has 500 steps and return 268.6.
Starting evaluation at step 196500 Counter(196500) 196437
eval_Episode has 500 steps and return 310.0.
Saved chunk: 20230922T014610F557742-1VcuYB7GMi17S2xf2LAb5r-0RnzvslavWYh1GeP3mt77k-1024.npz
train_Episode has 500 steps and return 234.8.
Starting evaluation at step 197000 Counter(197000) 196937
Saved chunk: 20230922T014641F387757-2kEFGDFLJs828pSoh9hbbv-14Xm9bxovwLmF1VH0URYCj-1024.npz
eval_Episode has 500 steps and return 291.4.
train_Episode has 500 steps and return 267.0.
Starting evaluation at step 197500 Counter(197500) 197437
eval_Episode has 500 steps and return 282.2.
Saved chunk: 20230922T014731F250704-0RnzvslavWYh1GeP3mt77k-5IO14v2h2cr0xclzs7j9a2-1024.npz
train_Episode has 500 steps and return 256.0.
Starting evaluation at step 198000 Counter(198000) 197937
Saved chunk: 20230922T014800F408381-14Xm9bxovwLmF1VH0URYCj-0TQ0ef0EgC8VpYPLLh07vA-1024.npz
eval_Episode has 500 steps and return 277.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 396442 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 277.71 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 256 / episode/reward_rate 0.41 / train/action_mag 3.75 / train/action_max 3.61 / train/action_mean 0.05 / train/action_min -3.33 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 9.8e4 / train/actor_opt_loss -4.93 / train/adv_mag 0.35 / train/adv_max 0.29 / train/adv_mean 1.2e-3 / train/adv_min
-0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.92 / train/dyn_loss_std 6.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 9.8e4 / 
train/extr_critic_critic_opt_loss 7089.97 / train/extr_critic_mag 219.35 / train/extr_critic_max 219.35 / train/extr_critic_mean 209.18 / train/extr_critic_min 167.29 / train/extr_critic_std 10.79 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 219.57 / train/extr_return_raw_max 219.57 / train/extr_return_raw_mean 209.23 / 
train/extr_return_raw_min 168.41 / train/extr_return_raw_std 10.84 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.12 / train/image_loss_std 0.98 / 
train/model_loss_mean 3.64 / train/model_loss_std 4.63 / train/model_opt_grad_norm 8.85 / train/model_opt_grad_steps 9.8e4 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.94
/ train/policy_entropy_max 4.88 / train/policy_entropy_mean -2.3 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.21 / train/policy_logprob_mag 10.42 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -10.42 / 
train/policy_logprob_std 1.88 / train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 1e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.3 / train/post_ent_max 51.3 / 
train/post_ent_mean 41.3 / train/post_ent_min 21.65 / train/post_ent_std 5.41 / train/prior_ent_mag 80.03 / train/prior_ent_max 80.03 / train/prior_ent_mean 45.2 / train/prior_ent_min 27.66 / train/prior_ent_std 6.63 / train/rep_loss_mean 3.92 / train/rep_loss_std 6.47 
/ train/reward_avg 0.33 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.33 / train/reward_rate 0.29 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.51 / report/cont_avg 1 / report/cont_loss_mean 9.2e-11 / report/cont_loss_std 1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 9.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 7.29 / report/image_loss_mean 1.17 / report/image_loss_std 1.02 / report/model_loss_mean 3.74 / report/model_loss_std 5.16 / report/post_ent_mag 
51.78 / report/post_ent_max 51.78 / report/post_ent_mean 41.63 / report/post_ent_min 20.92 / report/post_ent_std 5.74 / report/prior_ent_mag 79.89 / report/prior_ent_max 79.89 / report/prior_ent_mean 45.74 / report/prior_ent_min 27.59 / report/prior_ent_std 6.87 / 
report/rep_loss_mean 3.99 / report/rep_loss_std 7.29 / report/reward_avg 0.32 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 1.99 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.32 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 9.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.54 / eval/dyn_loss_std 6.43 / eval/image_loss_mean 1.16 / eval/image_loss_std 1.48 / eval/model_loss_mean 4.13 / eval/model_loss_std 4.91 / eval/post_ent_mag 51.54 / eval/post_ent_max 
51.54 / eval/post_ent_mean 41.18 / eval/post_ent_min 20.02 / eval/post_ent_std 6.77 / eval/prior_ent_mag 79.89 / eval/prior_ent_max 79.89 / eval/prior_ent_mean 45.67 / eval/prior_ent_min 23.76 / eval/prior_ent_std 7.23 / eval/rep_loss_mean 4.54 / eval/rep_loss_std 6.43 
/ eval/reward_avg 0.48 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.47 / 
eval/reward_rate 0.39 / replay/size 2e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3766 / timer/env.step_total 19.48 / timer/env.step_frac 0.06 / 
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.33 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-4 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.33 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1883 / timer/agent.train_total 242.24 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / 
timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac
1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.11

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 266.4.
Starting evaluation at step 198500 Counter(198500) 198437
eval_Episode has 500 steps and return 288.1.
Saved chunk: 20230922T014851F715987-5IO14v2h2cr0xclzs7j9a2-1S8cUJvOJJzB8Dox4EWOJx-1024.npz
train_Episode has 500 steps and return 259.3.
Starting evaluation at step 199000 Counter(199000) 198937
Saved chunk: 20230922T014919F247159-0TQ0ef0EgC8VpYPLLh07vA-2aNkleCqv0Ne8Pgg40QsT6-1024.npz
eval_Episode has 500 steps and return 285.2.
train_Episode has 500 steps and return 286.3.
Starting evaluation at step 199500 Counter(199500) 199437
eval_Episode has 500 steps and return 297.0.
Saved chunk: 20230922T015013F270306-1S8cUJvOJJzB8Dox4EWOJx-7iIKTmFK5Wd5tulZtGhWvE-1024.npz
train_Episode has 500 steps and return 262.5.
Starting evaluation at step 200000 Counter(200000) 199937
Saved chunk: 20230922T015039F443649-2aNkleCqv0Ne8Pgg40QsT6-2Ku1GMgHYeDbiXsF6chNfJ-1024.npz
eval_Episode has 500 steps and return 308.3.
train_Episode has 500 steps and return 259.8.
Starting evaluation at step 200500 Counter(200500) 200437
eval_Episode has 500 steps and return 298.8.
Saved chunk: 20230922T015134F136779-7iIKTmFK5Wd5tulZtGhWvE-2kCLYPQIYmLgis6mXFN3EA-1024.npz
train_Episode has 500 steps and return 279.1.
Starting evaluation at step 201000 Counter(201000) 200937
Saved chunk: 20230922T015158F625594-2Ku1GMgHYeDbiXsF6chNfJ-0FRrp3dCe1BHn2zQBw7aGk-1024.npz
eval_Episode has 500 steps and return 305.6.
train_Episode has 500 steps and return 264.6.
Starting evaluation at step 201500 Counter(201500) 201437
eval_Episode has 500 steps and return 296.4.
Saved chunk: 20230922T015254F874562-2kCLYPQIYmLgis6mXFN3EA-59ZvfAuUyKJY3OBIIcDVv9-1024.npz
train_Episode has 500 steps and return 259.7.
Starting evaluation at step 202000 Counter(202000) 201937
Saved chunk: 20230922T015317F817279-0FRrp3dCe1BHn2zQBw7aGk-6J3Z1mveOFEXOKdw03Yz7S-1024.npz
eval_Episode has 500 steps and return 307.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 404002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 259.7 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 307.71 / eval_episode/reward_rate 0.49 / train/action_mag 3.89 / train/action_max 3.72 / train/action_mean 0.05 / train/action_min -3.49 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -4.8 / train/adv_mag 0.43 / train/adv_max 0.36 / train/adv_mean 1.2e-3 / train/adv_min 
-0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.4e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 7440.86 / train/extr_critic_mag 220.21 / train/extr_critic_max 220.21 / train/extr_critic_mean 209.94 / train/extr_critic_min 159.06 / train/extr_critic_std 11.88 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 220.45 / train/extr_return_raw_max 220.45 / train/extr_return_raw_mean 209.99 / 
train/extr_return_raw_min 162.16 / train/extr_return_raw_std 11.92 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.1 / train/image_loss_std 0.98 / 
train/model_loss_mean 3.61 / train/model_loss_std 4.59 / train/model_opt_grad_norm 8.65 / train/model_opt_grad_steps 9.9e4 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.14
/ train/policy_entropy_max 5.07 / train/policy_entropy_mean -2.28 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.37 / train/policy_logprob_mag 10.94 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.28 / train/policy_logprob_min -10.94 / 
train/policy_logprob_std 1.99 / train/policy_randomness_mag 0.93 / train/policy_randomness_max 0.93 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 7.8e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.28 / train/post_ent_max 51.28 / 
train/post_ent_mean 41.46 / train/post_ent_min 21.76 / train/post_ent_std 5.36 / train/prior_ent_mag 80.03 / train/prior_ent_max 80.03 / train/prior_ent_mean 45.33 / train/prior_ent_min 28.02 / train/prior_ent_std 6.54 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.4
/ train/reward_avg 0.33 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.33 / train/reward_rate 0.3 / train_stats/mean_log_entropy -2.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4 / report/dyn_loss_std 6.52 / report/image_loss_mean 1.27 / report/image_loss_std 1.09 / report/model_loss_mean 3.82 / report/model_loss_std 4.59 / report/post_ent_mag 51.05 /
report/post_ent_max 51.05 / report/post_ent_mean 41.16 / report/post_ent_min 20.88 / report/post_ent_std 5.76 / report/prior_ent_mag 80.01 / report/prior_ent_max 80.01 / report/prior_ent_mean 45.2 / report/prior_ent_min 27.59 / report/prior_ent_std 6.68 / 
report/rep_loss_mean 4 / report/rep_loss_std 6.52 / report/reward_avg 0.29 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.28 / report/reward_max_data 1.99 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.29 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 7.7e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 7.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.93 / eval/dyn_loss_std 7.07 / eval/image_loss_mean 1.47 / eval/image_loss_std 2.17 / eval/model_loss_mean 4.67 / eval/model_loss_std 5.74 / eval/post_ent_mag 50.11 / 
eval/post_ent_max 50.11 / eval/post_ent_mean 40.01 / eval/post_ent_min 20.63 / eval/post_ent_std 7.66 / eval/prior_ent_mag 80.01 / eval/prior_ent_max 80.01 / eval/prior_ent_mean 44.66 / eval/prior_ent_min 23.18 / eval/prior_ent_std 8.4 / eval/rep_loss_mean 4.93 / 
eval/rep_loss_std 7.07 / eval/reward_avg 0.44 / eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.43 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.63 / 
eval/reward_pred 0.44 / eval/reward_rate 0.37 / replay/size 2e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.31 / timer/env.step_count 3780 / timer/env.step_total 19.59
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.01 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
5.4e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7788 / timer/agent.policy_total 17.4 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min
1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1890 / 
timer/agent.train_total 243.51 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.14 / timer/agent.report_frac 4.5e-4 / timer/agent.report_avg 
0.07 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 258.4.
Starting evaluation at step 202500 Counter(202500) 202437
eval_Episode has 500 steps and return 300.6.
Saved chunk: 20230922T015415F440916-59ZvfAuUyKJY3OBIIcDVv9-3acaA0u9TZYFADMFhA112A-1024.npz
train_Episode has 500 steps and return 261.7.
Starting evaluation at step 203000 Counter(203000) 202937
Saved chunk: 20230922T015436F897370-6J3Z1mveOFEXOKdw03Yz7S-43MJwnqjlCygQO2lgFfzwJ-1024.npz
eval_Episode has 500 steps and return 300.2.
train_Episode has 500 steps and return 298.4.
Starting evaluation at step 203500 Counter(203500) 203437
eval_Episode has 500 steps and return 306.5.
Saved chunk: 20230922T015537F270639-3acaA0u9TZYFADMFhA112A-1HPMpNSMASyHzqpI8CaNyU-1024.npz
train_Episode has 500 steps and return 285.5.
Starting evaluation at step 204000 Counter(204000) 203937
Saved chunk: 20230922T015557F046747-43MJwnqjlCygQO2lgFfzwJ-6rek0PEeh5RumvwML9wiV8-1024.npz
eval_Episode has 500 steps and return 310.7.
train_Episode has 500 steps and return 268.5.
Starting evaluation at step 204500 Counter(204500) 204437
eval_Episode has 500 steps and return 312.5.
Saved chunk: 20230922T015657F961683-1HPMpNSMASyHzqpI8CaNyU-4NibG9yrCBrUIYgCcOES0U-1024.npz
train_Episode has 500 steps and return 299.7.
Starting evaluation at step 205000 Counter(205000) 204937
Saved chunk: 20230922T015716F114127-6rek0PEeh5RumvwML9wiV8-3HZjyANKmndsRqS2Fk9TVu-1024.npz
eval_Episode has 500 steps and return 309.6.
train_Episode has 500 steps and return 273.2.
Starting evaluation at step 205500 Counter(205500) 205437
eval_Episode has 500 steps and return 303.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 411646 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 273.18 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 303.43 / eval_episode/reward_rate 0.46 / train/action_mag 3.94 / train/action_max 3.8 / train/action_mean 0.05 / train/action_min -3.48 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.21 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -3.95 / train/adv_mag 0.47 / train/adv_max 0.39 / train/adv_mean 1.1e-3 / train/adv_min 
-0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.92 / train/dyn_loss_std 6.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 7940.87 / train/extr_critic_mag 221.07 / train/extr_critic_max 221.07 / train/extr_critic_mean 210.67 / train/extr_critic_min 160.52 / train/extr_critic_std 11.99 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 221.32 / train/extr_return_raw_max 221.32 / train/extr_return_raw_mean 210.71 / 
train/extr_return_raw_min 163.91 / train/extr_return_raw_std 12.03 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.11 / train/image_loss_std 1.01 / 
train/model_loss_mean 3.65 / train/model_loss_std 4.65 / train/model_opt_grad_norm 8.67 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.16 /
train/policy_entropy_max 5.1 / train/policy_entropy_mean -2.22 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.45 / train/policy_logprob_mag 11.16 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.22 / train/policy_logprob_min -11.16 / 
train/policy_logprob_std 2.05 / train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 6.4e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.19 / train/post_ent_max 51.19 / 
train/post_ent_mean 41.44 / train/post_ent_min 21.54 / train/post_ent_std 5.42 / train/prior_ent_mag 80.01 / train/prior_ent_max 80.01 / train/prior_ent_mean 45.35 / train/prior_ent_min 27.81 / train/prior_ent_std 6.58 / train/rep_loss_mean 3.92 / train/rep_loss_std 
6.47 / train/reward_avg 0.34 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.34 / train/reward_rate 0.3 / train_stats/mean_log_entropy -2.57 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.7e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 4.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.66 / report/image_loss_mean 1.11 / report/image_loss_std 1.1 / report/model_loss_mean 3.67 / report/model_loss_std 4.8 / 
report/post_ent_mag 50.39 / report/post_ent_max 50.39 / report/post_ent_mean 41.09 / report/post_ent_min 20.98 / report/post_ent_std 5.3 / report/prior_ent_mag 80.14 / report/prior_ent_max 80.14 / report/prior_ent_mean 45.22 / report/prior_ent_min 28.94 / 
report/prior_ent_std 6.63 / report/rep_loss_mean 3.95 / report/rep_loss_std 6.66 / report/reward_avg 0.35 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.33 / report/reward_max_data 1.94 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / 
report/reward_neg_loss 8.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.35 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 4.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.25 / eval/dyn_loss_std 5.87 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.09 / eval/model_loss_mean 3.92 / eval/model_loss_std 4.33 / eval/post_ent_mag 
49.55 / eval/post_ent_max 49.55 / eval/post_ent_mean 43.12 / eval/post_ent_min 24.43 / eval/post_ent_std 3.94 / eval/prior_ent_mag 80.14 / eval/prior_ent_max 80.14 / eval/prior_ent_mean 47.38 / eval/prior_ent_min 33.59 / eval/prior_ent_std 4.85 / eval/rep_loss_mean 4.25
/ eval/rep_loss_std 5.87 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / 
eval/reward_pred 0.61 / eval/reward_rate 0.51 / replay/size 2.1e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3822 / timer/env.step_total 19.67
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.1e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.02 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 7.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7329 / timer/agent.policy_total 16.29 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.6e-4 / 
timer/agent.train_count 1911 / timer/agent.train_total 245.9 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.47

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T015818F462193-4NibG9yrCBrUIYgCcOES0U-4cvAjyTZtOg4J1qQrw8rWh-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 283.8.
Starting evaluation at step 206000 Counter(206000) 205937
Saved chunk: 20230922T015834F985080-3HZjyANKmndsRqS2Fk9TVu-4Mm3rKOF3Gyq6JtlDsnIlg-1024.npz
eval_Episode has 500 steps and return 294.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T015954F691667-4Mm3rKOF3Gyq6JtlDsnIlg-0000000000000000000000-163.npz
Saved chunk: 20230922T015939F083444-4cvAjyTZtOg4J1qQrw8rWh-0000000000000000000000-376.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 300.8.
Starting evaluation at step 206500 Counter(206500) 206437
eval_Episode has 500 steps and return 323.1.
Saved chunk: 20230922T015939F083444-4cvAjyTZtOg4J1qQrw8rWh-31809vFuO4ViQehZ0TDsnI-1024.npz
train_Episode has 500 steps and return 265.2.
Starting evaluation at step 207000 Counter(207000) 206937
Saved chunk: 20230922T015954F691667-4Mm3rKOF3Gyq6JtlDsnIlg-0WwxhMcJfdcYTWziox7GGU-1024.npz
eval_Episode has 500 steps and return 284.9.
train_Episode has 500 steps and return 292.6.
Starting evaluation at step 207500 Counter(207500) 207437
eval_Episode has 500 steps and return 320.5.
Saved chunk: 20230922T020100F724400-31809vFuO4ViQehZ0TDsnI-1EpXIkPEYxgccnlCp0dUcr-1024.npz
train_Episode has 500 steps and return 299.8.
Starting evaluation at step 208000 Counter(208000) 207937
Saved chunk: 20230922T020114F133299-0WwxhMcJfdcYTWziox7GGU-1UT92Ym5ibkycWNxgN20gU-1024.npz
eval_Episode has 500 steps and return 306.3.
train_Episode has 500 steps and return 279.0.
Starting evaluation at step 208500 Counter(208500) 208437
eval_Episode has 500 steps and return 277.7.
Saved chunk: 20230922T020221F251953-1EpXIkPEYxgccnlCp0dUcr-626MFkuGpDRfBrBpBRnQ1g-1024.npz
train_Episode has 500 steps and return 290.1.
Starting evaluation at step 209000 Counter(209000) 208937
Saved chunk: 20230922T020233F079704-1UT92Ym5ibkycWNxgN20gU-3XaoquLcifaY41urBbS8Fl-1024.npz
eval_Episode has 500 steps and return 292.7.
train_Episode has 500 steps and return 271.4.
Starting evaluation at step 209500 Counter(209500) 209437
eval_Episode has 500 steps and return 315.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 419198 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 271.4 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 315.29 / eval_episode/reward_rate 0.47 / train/action_mag 4.02 / train/action_max 3.91 / train/action_mean 0.05 / train/action_min -3.46 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -3.16 / train/adv_mag 0.43 / train/adv_max 0.36 / train/adv_mean 9.9e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.44 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 8594.66 / train/extr_critic_mag 221.93 / train/extr_critic_max 221.93 / train/extr_critic_mean 211.48 / train/extr_critic_min 159.63 / train/extr_critic_std 12.2 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 222.17 / train/extr_return_raw_max 222.17 / train/extr_return_raw_mean 211.52 / 
train/extr_return_raw_min 161 / train/extr_return_raw_std 12.23 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.09 / train/image_loss_std 1 / 
train/model_loss_mean 3.6 / train/model_loss_std 4.62 / train/model_opt_grad_norm 9.02 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.07 / 
train/policy_entropy_max 5 / train/policy_entropy_mean -2.24 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.38 / train/policy_logprob_mag 10.68 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.24 / train/policy_logprob_min -10.68 / 
train/policy_logprob_std 1.99 / train/policy_randomness_mag 0.93 / train/policy_randomness_max 0.93 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 6.2e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.17 / train/post_ent_max 51.17 / 
train/post_ent_mean 41.41 / train/post_ent_min 21.68 / train/post_ent_std 5.42 / train/prior_ent_mag 80.02 / train/prior_ent_max 80.02 / train/prior_ent_mean 45.26 / train/prior_ent_min 27.58 / train/prior_ent_std 6.61 / train/rep_loss_mean 3.88 / train/rep_loss_std 
6.44 / train/reward_avg 0.33 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.33 / train/reward_rate 0.3 / train_stats/mean_log_entropy -2.54 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 8.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 6.04 / report/image_loss_mean 0.94 / report/image_loss_std 0.7 / report/model_loss_mean 3.29 / report/model_loss_std 4.22 / 
report/post_ent_mag 51.74 / report/post_ent_max 51.74 / report/post_ent_mean 41.99 / report/post_ent_min 23.3 / report/post_ent_std 4.79 / report/prior_ent_mag 80.12 / report/prior_ent_max 80.12 / report/prior_ent_mean 45.56 / report/prior_ent_min 23.7 / 
report/prior_ent_std 6.34 / report/rep_loss_mean 3.58 / report/rep_loss_std 6.04 / report/reward_avg 0.36 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.32 / report/reward_max_data 1.9 / report/reward_max_pred 1.93 / report/reward_neg_acc 0.99 / 
report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.36 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.55 / eval/dyn_loss_std 6.14 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.01 / eval/model_loss_mean 4.13 / eval/model_loss_std 4.45 / eval/post_ent_mag 
50.16 / eval/post_ent_max 50.16 / eval/post_ent_mean 42.91 / eval/post_ent_min 24.82 / eval/post_ent_std 4.04 / eval/prior_ent_mag 80.12 / eval/prior_ent_max 80.12 / eval/prior_ent_mean 47.25 / eval/prior_ent_min 32.89 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 4.55
/ eval/rep_loss_std 6.14 / eval/reward_avg 0.59 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.42 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / 
eval/reward_pred 0.59 / eval/reward_rate 0.47 / replay/size 2.1e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3776 / timer/env.step_total 19.47 
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 7.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.67 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 8.5e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7784 / 
timer/agent.policy_total 17.34 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / 
timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1888 / timer/agent.train_total 242.95 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 268.8.
Saved chunk: 20230922T020341F662930-626MFkuGpDRfBrBpBRnQ1g-1Vjp03gn2u9XAw3V9hfZxb-1024.npz
Starting evaluation at step 210000 Counter(210000) 209937
Saved chunk: 20230922T020351F840732-3XaoquLcifaY41urBbS8Fl-5TMAOv0Q85cVy5CkDmBG68-1024.npz
eval_Episode has 500 steps and return 296.3.
train_Episode has 500 steps and return 274.2.
Starting evaluation at step 210500 Counter(210500) 210437
eval_Episode has 500 steps and return 303.4.
train_Episode has 500 steps and return 305.2.
Saved chunk: 20230922T020502F946039-1Vjp03gn2u9XAw3V9hfZxb-6Ub2PNGhglGbN5DyV082B9-1024.npz
Starting evaluation at step 211000 Counter(211000) 210937
eval_Episode has 500 steps and return 288.6.
Saved chunk: 20230922T020511F584163-5TMAOv0Q85cVy5CkDmBG68-1rSQtwpZBgYIL0ekNout08-1024.npz
train_Episode has 500 steps and return 273.4.
Starting evaluation at step 211500 Counter(211500) 211437
eval_Episode has 500 steps and return 295.8.
train_Episode has 500 steps and return 282.3.
Saved chunk: 20230922T020623F653553-6Ub2PNGhglGbN5DyV082B9-0ICHZs0mRN7mR2cOg3j23f-1024.npz
Starting evaluation at step 212000 Counter(212000) 211937
eval_Episode has 500 steps and return 325.0.
Saved chunk: 20230922T020630F715693-1rSQtwpZBgYIL0ekNout08-7lSDFYLYVmX3hcQP2mspcD-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 212500 Counter(212500) 212437
eval_Episode has 500 steps and return 303.9.
train_Episode has 500 steps and return 268.0.
Saved chunk: 20230922T020744F457422-0ICHZs0mRN7mR2cOg3j23f-27Pq0Y0Wesv01Qo4IsQGWD-1024.npz
Starting evaluation at step 213000 Counter(213000) 212937
eval_Episode has 500 steps and return 304.6.
Saved chunk: 20230922T020749F901306-7lSDFYLYVmX3hcQP2mspcD-0lisoZsNsOdwM91CHPs43Z-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 426838 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 267.95 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 304.57 / eval_episode/reward_rate 0.49 / train/action_mag 3.98 / train/action_max 3.88 / train/action_mean 0.06 / train/action_min -3.45 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -2.26 / train/adv_mag 0.6 / train/adv_max 0.53 / train/adv_mean 9.1e-4
/ train/adv_min -0.33 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.8e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.45 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 8921.69 / train/extr_critic_mag 222.48 / train/extr_critic_max 222.48 / train/extr_critic_mean 212.11 / train/extr_critic_min 156.3 / train/extr_critic_std 12.01 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 222.72 / train/extr_return_raw_max 222.72 / train/extr_return_raw_mean 212.15 / 
train/extr_return_raw_min 164.19 / train/extr_return_raw_std 12.03 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.1 / train/image_loss_std 1.01 / 
train/model_loss_mean 3.62 / train/model_loss_std 4.64 / train/model_opt_grad_norm 8.84 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.95
/ train/policy_entropy_max 4.88 / train/policy_entropy_mean -2.25 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.54 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.25 / train/policy_logprob_min -10.54 / 
train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 5.3e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.18 / train/post_ent_max 51.18 / 
train/post_ent_mean 41.47 / train/post_ent_min 21.44 / train/post_ent_std 5.39 / train/prior_ent_mag 80.01 / train/prior_ent_max 80.01 / train/prior_ent_mean 45.35 / train/prior_ent_min 27.58 / train/prior_ent_std 6.57 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.45
/ train/reward_avg 0.34 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.34 / train/reward_rate 0.3 / train_stats/mean_log_entropy -2.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.1e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.51 / report/dyn_loss_std 6.89 / report/image_loss_mean 1.34 / report/image_loss_std 1.36 / report/model_loss_mean 4.24 / report/model_loss_std 5.28 / report/post_ent_mag 50.4
/ report/post_ent_max 50.4 / report/post_ent_mean 41.36 / report/post_ent_min 22.02 / report/post_ent_std 5.33 / report/prior_ent_mag 80.09 / report/prior_ent_max 80.09 / report/prior_ent_mean 45.86 / report/prior_ent_min 27.66 / report/prior_ent_std 6.31 / 
report/rep_loss_mean 4.51 / report/rep_loss_std 6.89 / report/reward_avg 0.33 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.66 / report/reward_pred 0.33 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 8e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.88 / eval/dyn_loss_std 7.05 / eval/image_loss_mean 1.27 / eval/image_loss_std 1.71 / eval/model_loss_mean 4.5 / eval/model_loss_std 5.54 / eval/post_ent_mag 49.32 / eval/post_ent_max 
49.32 / eval/post_ent_mean 42.67 / eval/post_ent_min 23.95 / eval/post_ent_std 4.47 / eval/prior_ent_mag 80.09 / eval/prior_ent_max 80.09 / eval/prior_ent_mean 47.12 / eval/prior_ent_min 29.18 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 4.88 / eval/rep_loss_std 7.05 
/ eval/reward_avg 0.56 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.47 / eval/reward_max_data 1.91 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.56 / 
eval/reward_rate 0.45 / replay/size 2.1e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3820 / timer/env.step_total 19.76 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.84 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / 
timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 16.32 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 3.3e-3 / timer/agent.train_count 1910 / 
timer/agent.train_total 245.76 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 293.1.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 213500 Counter(213500) 213437
eval_Episode has 500 steps and return 301.3.
train_Episode has 500 steps and return 260.0.
Starting evaluation at step 214000 Counter(214000) 213937
eval_Episode has 500 steps and return 294.9.
Saved chunk: 20230922T020904F795841-27Pq0Y0Wesv01Qo4IsQGWD-5028mmX5bhCEwUdp1ILKvv-1024.npz
train_Episode has 500 steps and return 261.3.
Starting evaluation at step 214500 Counter(214500) 214437
Saved chunk: 20230922T020908F819491-0lisoZsNsOdwM91CHPs43Z-0AJq7UXp65r4YCNzyr5tl9-1024.npz
eval_Episode has 500 steps and return 314.3.
train_Episode has 500 steps and return 244.1.
Starting evaluation at step 215000 Counter(215000) 214937
eval_Episode has 500 steps and return 301.1.
Saved chunk: 20230922T021030F069474-5028mmX5bhCEwUdp1ILKvv-6iZyLYOWyZxQgoLm3Sb4bb-1024.npz
train_Episode has 500 steps and return 294.6.
Starting evaluation at step 215500 Counter(215500) 215437
Saved chunk: 20230922T021105F161100-0AJq7UXp65r4YCNzyr5tl9-5bKB3GWjTqFA9LKAqnn6c4-1024.npz
eval_Episode has 500 steps and return 299.4.
train_Episode has 500 steps and return 279.7.
Starting evaluation at step 216000 Counter(216000) 215937
eval_Episode has 500 steps and return 288.2.
Saved chunk: 20230922T021151F042766-6iZyLYOWyZxQgoLm3Sb4bb-5PgXuN3WgIn0WiDI1cigyx-1024.npz
train_Episode has 500 steps and return 258.8.
Starting evaluation at step 216500 Counter(216500) 216437
Saved chunk: 20230922T021224F452968-5bKB3GWjTqFA9LKAqnn6c4-6d3fWTTP0mQJ0cGVx13hct-1024.npz
eval_Episode has 500 steps and return 289.7.
train_Episode has 500 steps and return 277.0.
Starting evaluation at step 217000 Counter(217000) 216937
eval_Episode has 500 steps and return 291.1.
Saved chunk: 20230922T021311F882592-5PgXuN3WgIn0WiDI1cigyx-5iqq9XVPs04a2hESjmWgni-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 434322 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 277 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 291.1 / eval_episode/reward_rate 0.46 / train_stats/mean_log_entropy -2.54 / train/action_mag 3.98 / train/action_max 3.88 / train/action_mean 0.06 / 
train/action_min -3.52 / train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -2.44 / train/adv_mag 0.34 / train/adv_max 
0.26 / train/adv_mean 9.4e-4 / train/adv_min -0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.85 / train/dyn_loss_std 6.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 9285.16 / train/extr_critic_mag 223.24 / train/extr_critic_max 223.24 / train/extr_critic_mean 212.98 / train/extr_critic_min 161.77 / train/extr_critic_std 12.44 / 
train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 223.49 / 
train/extr_return_raw_max 223.49 / train/extr_return_raw_mean 213.02 / train/extr_return_raw_min 162.05 / train/extr_return_raw_std 12.46 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / 
train/extr_reward_std 0.6 / train/image_loss_mean 1.06 / train/image_loss_std 0.96 / train/model_loss_mean 3.56 / train/model_loss_std 4.56 / train/model_opt_grad_norm 8.71 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.75 / train/policy_entropy_max 4.67 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / 
train/policy_logprob_mag 10.38 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -10.38 / train/policy_logprob_std 1.91 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.13 / 
train/policy_randomness_min 4.9e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.13 / train/post_ent_max 51.13 / train/post_ent_mean 41.67 / train/post_ent_min 21.66 / train/post_ent_std 5.32 / train/prior_ent_mag 80.04 / train/prior_ent_max 80.04 / 
train/prior_ent_mean 45.51 / train/prior_ent_min 27.61 / train/prior_ent_std 6.52 / train/rep_loss_mean 3.85 / train/rep_loss_std 6.37 / train/reward_avg 0.35 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred
1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.35 / train/reward_rate 0.31 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / 
report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.61 / report/dyn_loss_std 6.07 / report/image_loss_mean 0.97 / 
report/image_loss_std 1.1 / report/model_loss_mean 3.28 / report/model_loss_std 4.5 / report/post_ent_mag 51.41 / report/post_ent_max 51.41 / report/post_ent_mean 41.09 / report/post_ent_min 20.53 / report/post_ent_std 5.5 / report/prior_ent_mag 79.96 / 
report/prior_ent_max 79.96 / report/prior_ent_mean 44.63 / report/prior_ent_min 28.12 / report/prior_ent_std 6.86 / report/rep_loss_mean 3.61 / report/rep_loss_std 6.07 / report/reward_avg 0.3 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.27 / 
report/reward_max_data 1.99 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 8.7e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.3 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11
/ eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.61 / eval/dyn_loss_std 6.33 / eval/image_loss_mean 1.2 / eval/image_loss_std 
1.33 / eval/model_loss_mean 4.25 / eval/model_loss_std 4.74 / eval/post_ent_mag 50.62 / eval/post_ent_max 50.62 / eval/post_ent_mean 42.67 / eval/post_ent_min 23.27 / eval/post_ent_std 4.52 / eval/prior_ent_mag 79.96 / eval/prior_ent_max 79.96 / eval/prior_ent_mean 
47.08 / eval/prior_ent_min 30.35 / eval/prior_ent_std 5.25 / eval/rep_loss_mean 4.61 / eval/rep_loss_std 6.33 / eval/reward_avg 0.55 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 
0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.55 / eval/reward_rate 0.46 / replay/size 2.2e5 / replay/inserts 3742 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / 
replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac
1 / timer/duration 300.01 / timer/env.step_count 3742 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.4 / 
timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7750 / timer/agent.policy_total 
17.27 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1871 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.4e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1871 / timer/agent.train_total 242 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.29 / timer/agent.report_count 2
/ timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 24.94

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 262.7.
Starting evaluation at step 217500 Counter(217500) 217437
Saved chunk: 20230922T021343F630222-6d3fWTTP0mQJ0cGVx13hct-2yV2BfZb8aefLl0NT5tRqv-1024.npz
eval_Episode has 500 steps and return 309.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T021433F823986-5iqq9XVPs04a2hESjmWgni-0000000000000000000000-512.npz
Saved chunk: 20230922T021505F010299-2yV2BfZb8aefLl0NT5tRqv-0000000000000000000000-422.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 257.0.
Starting evaluation at step 218000 Counter(218000) 217937
eval_Episode has 500 steps and return 298.2.
Saved chunk: 20230922T021433F823986-5iqq9XVPs04a2hESjmWgni-0PxuJKl38dlu0ACYs9mGLV-1024.npz
train_Episode has 500 steps and return 285.0.
Starting evaluation at step 218500 Counter(218500) 218437
Saved chunk: 20230922T021505F010299-2yV2BfZb8aefLl0NT5tRqv-199L8pEXSkRbQhwu0e0BsV-1024.npz
eval_Episode has 500 steps and return 297.7.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 219000 Counter(219000) 218937
eval_Episode has 500 steps and return 299.3.
Saved chunk: 20230922T021556F068218-0PxuJKl38dlu0ACYs9mGLV-61YmbwlkR22n5RScXnWBiZ-1024.npz
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 219500 Counter(219500) 219437
Saved chunk: 20230922T021624F747225-199L8pEXSkRbQhwu0e0BsV-6ivLfUvF2pfmGOob0p6mcN-1024.npz
eval_Episode has 500 steps and return 315.1.
train_Episode has 500 steps and return 282.6.
Starting evaluation at step 220000 Counter(220000) 219937
eval_Episode has 500 steps and return 300.2.
Saved chunk: 20230922T021716F955193-61YmbwlkR22n5RScXnWBiZ-0F6WjRlSVtjZhPhDPtP8y1-1024.npz
train_Episode has 500 steps and return 298.6.
Starting evaluation at step 220500 Counter(220500) 220437
Saved chunk: 20230922T021743F978936-6ivLfUvF2pfmGOob0p6mcN-5iPHnNTfvWaRj9bigHIVz6-1024.npz
eval_Episode has 500 steps and return 290.9.
train_Episode has 500 steps and return 288.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 441934 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 288.27 / episode/reward_rate 0.48 / eval_episode/length 500 / eval_episode/score 290.94 / eval_episode/reward_rate 0.45 / train/action_mag 3.97 / train/action_max 3.89 / train/action_mean 0.06 / train/action_min -3.39 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -20.27 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean 
2.7e-3 / train/adv_min -0.33 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 9774.91 / train/extr_critic_mag 223.94 / train/extr_critic_max 223.94 / train/extr_critic_mean 213.83 / train/extr_critic_min 162.58 / train/extr_critic_std 11.76 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 224.2 / train/extr_return_raw_max 224.2 / train/extr_return_raw_mean 213.95 / train/extr_return_raw_min 
165.1 / train/extr_return_raw_std 11.59 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.08 / train/image_loss_std 0.99 / train/model_loss_mean 3.6 / 
train/model_loss_std 4.61 / train/model_opt_grad_norm 8.78 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.8 / train/policy_entropy_max 
4.66 / train/policy_entropy_mean -2.29 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 10.25 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -10.25 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 5e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.17 / train/post_ent_max 51.17 / train/post_ent_mean 41.6 / 
train/post_ent_min 21.72 / train/post_ent_std 5.39 / train/prior_ent_mag 80.03 / train/prior_ent_max 80.03 / train/prior_ent_mean 45.48 / train/prior_ent_min 27.58 / train/prior_ent_std 6.57 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.42 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.35 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -1.68 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.8e-11 / report/cont_loss_std 2.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 6.19 / report/image_loss_mean 0.99 / report/image_loss_std 1.14 / report/model_loss_mean 3.46 / report/model_loss_std 4.5 / report/post_ent_mag 51.73 / report/post_ent_max 51.73 / 
report/post_ent_mean 41.82 / report/post_ent_min 20.78 / report/post_ent_std 5.09 / report/prior_ent_mag 79.83 / report/prior_ent_max 79.83 / report/prior_ent_mean 45.75 / report/prior_ent_min 29.33 / report/prior_ent_std 6.35 / report/rep_loss_mean 3.78 / 
report/rep_loss_std 6.19 / report/reward_avg 0.4 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.4 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.69 / eval/dyn_loss_std 15.65 / eval/image_loss_mean 2.48 / eval/image_loss_std 6.04 / eval/model_loss_mean 7.36 / eval/model_loss_std 15.15 / eval/post_ent_mag 50.1 / eval/post_ent_max 50.1 / eval/post_ent_mean 
42.46 / eval/post_ent_min 22.64 / eval/post_ent_std 4.67 / eval/prior_ent_mag 79.83 / eval/prior_ent_max 79.83 / eval/prior_ent_mean 46.93 / eval/prior_ent_min 27.08 / eval/prior_ent_std 5.32 / eval/rep_loss_mean 7.69 / eval/rep_loss_std 15.65 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.88 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.56 / eval/reward_rate 0.46 / 
replay/size 2.2e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3806 / timer/env.step_total 19.71 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.21 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.2e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.76 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.7 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 221000 Counter(221000) 220937
eval_Episode has 500 steps and return 306.2.
Saved chunk: 20230922T021837F600009-0F6WjRlSVtjZhPhDPtP8y1-0EuhTlRvzS2UOUE0BaDkuX-1024.npz
train_Episode has 500 steps and return 286.7.
Starting evaluation at step 221500 Counter(221500) 221437
Saved chunk: 20230922T021903F055277-5iPHnNTfvWaRj9bigHIVz6-5qMZydj3gBTRFnEnng6KPL-1024.npz
eval_Episode has 500 steps and return 305.9.
train_Episode has 500 steps and return 305.1.
Starting evaluation at step 222000 Counter(222000) 221937
eval_Episode has 500 steps and return 291.3.
Saved chunk: 20230922T021959F230852-0EuhTlRvzS2UOUE0BaDkuX-0c4TvkoEhB24oKqXybgPdS-1024.npz
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 222500 Counter(222500) 222437
Saved chunk: 20230922T022023F253220-5qMZydj3gBTRFnEnng6KPL-4ThcIWOlvY3JuOqQwRVXIe-1024.npz
eval_Episode has 500 steps and return 304.7.
train_Episode has 500 steps and return 279.7.
Starting evaluation at step 223000 Counter(223000) 222937
eval_Episode has 500 steps and return 302.6.
Saved chunk: 20230922T022120F282524-0c4TvkoEhB24oKqXybgPdS-0owEu9jM5lo3Fuz1BL0AdF-1024.npz
train_Episode has 500 steps and return 283.5.
Starting evaluation at step 223500 Counter(223500) 223437
Saved chunk: 20230922T022142F684521-4ThcIWOlvY3JuOqQwRVXIe-1xVb9pYfA3PmQZe6BH4NnH-1024.npz
eval_Episode has 500 steps and return 308.0.
train_Episode has 500 steps and return 295.2.
Starting evaluation at step 224000 Counter(224000) 223937
eval_Episode has 500 steps and return 316.5.
Saved chunk: 20230922T022241F193273-0owEu9jM5lo3Fuz1BL0AdF-3fV5hzXYwG72mGgfQrKXpe-1024.npz
train_Episode has 500 steps and return 278.8.
Starting evaluation at step 224500 Counter(224500) 224437
Saved chunk: 20230922T022301F935688-1xVb9pYfA3PmQZe6BH4NnH-7obevFQBPIOa29wix1Cwd4-1024.npz
eval_Episode has 500 steps and return 286.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 449446 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 286.89 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 278.8 / episode/reward_rate 0.42 / train/action_mag 3.92 / train/action_max 3.86 / train/action_mean 0.05 / train/action_min -3.4 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.54 / train/adv_mag 0.36 / train/adv_max 0.28 / train/adv_mean 1.1e-3 / train/adv_min
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 224.5 / train/extr_critic_max 224.5 / train/extr_critic_mean 214.47 / train/extr_critic_min 168.82 / train/extr_critic_std 11.19 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 224.77 / train/extr_return_raw_max 224.77 / train/extr_return_raw_mean 214.51 / train/extr_return_raw_min 
169.89 / train/extr_return_raw_std 11.19 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.08 / train/image_loss_std 1 / train/model_loss_mean 3.6 / 
train/model_loss_std 4.6 / train/model_opt_grad_norm 8.64 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.94 / train/policy_entropy_max 
4.84 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.28 / train/policy_logprob_mag 10.48 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -10.48 / train/policy_logprob_std 1.93 / 
train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 4.5e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.13 / train/post_ent_max 51.13 / train/post_ent_mean 41.59 / 
train/post_ent_min 21.7 / train/post_ent_std 5.36 / train/prior_ent_mag 80.02 / train/prior_ent_max 80.02 / train/prior_ent_mean 45.45 / train/prior_ent_min 27.55 / train/prior_ent_std 6.54 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.41 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.35 / train/reward_rate 
0.31 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.56 / report/cont_avg 1 / report/cont_loss_mean 5.2e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.73 / report/dyn_loss_std 5.91 / report/image_loss_mean 0.93 / report/image_loss_std 0.64 / report/model_loss_mean 3.4 / report/model_loss_std 4.09 / report/post_ent_mag 50.04 / report/post_ent_max 50.04 / 
report/post_ent_mean 42.94 / report/post_ent_min 24.37 / report/post_ent_std 3.94 / report/prior_ent_mag 80.22 / report/prior_ent_max 80.22 / report/prior_ent_mean 46.76 / report/prior_ent_min 31.35 / report/prior_ent_std 5.26 / report/rep_loss_mean 3.73 / 
report/rep_loss_std 5.91 / report/reward_avg 0.46 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.35 / report/reward_max_data 1.97 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.46 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 6.3e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.89 / eval/dyn_loss_std 6.93 / eval/image_loss_mean 1.36 / eval/image_loss_std 2.04 / eval/model_loss_mean 4.55 / eval/model_loss_std 5.63 / eval/post_ent_mag 49.99 / eval/post_ent_max 49.99 / eval/post_ent_mean 
42.37 / eval/post_ent_min 17.6 / eval/post_ent_std 4.86 / eval/prior_ent_mag 80.22 / eval/prior_ent_max 80.22 / eval/prior_ent_mean 46.94 / eval/prior_ent_min 30.24 / eval/prior_ent_std 5.22 / eval/rep_loss_mean 4.89 / eval/rep_loss_std 6.93 / eval/reward_avg 0.53 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.52 / eval/reward_rate 0.41 / 
replay/size 2.2e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3756 / timer/env.step_total 19.38 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.76 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7764 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.89 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 267.5.
Starting evaluation at step 225000 Counter(225000) 224937
eval_Episode has 500 steps and return 292.2.
Saved chunk: 20230922T022401F958643-3fV5hzXYwG72mGgfQrKXpe-3tmd1izZKZqZrCgdMLtWx3-1024.npz
train_Episode has 500 steps and return 284.0.
Starting evaluation at step 225500 Counter(225500) 225437
Saved chunk: 20230922T022421F138270-7obevFQBPIOa29wix1Cwd4-0wuvE8KpfB8bCmVp1eqMYT-1024.npz
eval_Episode has 500 steps and return 301.9.
train_Episode has 500 steps and return 291.7.
Starting evaluation at step 226000 Counter(226000) 225937
eval_Episode has 500 steps and return 294.0.
Saved chunk: 20230922T022523F748396-3tmd1izZKZqZrCgdMLtWx3-3GXE655nvQMmxvcHYcdvOX-1024.npz
train_Episode has 500 steps and return 288.9.
Starting evaluation at step 226500 Counter(226500) 226437
Saved chunk: 20230922T022541F446754-0wuvE8KpfB8bCmVp1eqMYT-1PjcbsK0O8TXkcjPXxU9uz-1024.npz
eval_Episode has 500 steps and return 301.8.
train_Episode has 500 steps and return 261.5.
Starting evaluation at step 227000 Counter(227000) 226937
eval_Episode has 500 steps and return 317.4.
Saved chunk: 20230922T022644F690269-3GXE655nvQMmxvcHYcdvOX-0V2msEBLcFg2zAJfFRX0QP-1024.npz
train_Episode has 500 steps and return 276.0.
Starting evaluation at step 227500 Counter(227500) 227437
Saved chunk: 20230922T022700F701611-1PjcbsK0O8TXkcjPXxU9uz-0ZcMkcHh7gZqcXQHXBjYfE-1024.npz
eval_Episode has 500 steps and return 325.8.
train_Episode has 500 steps and return 282.2.
Starting evaluation at step 228000 Counter(228000) 227937
eval_Episode has 500 steps and return 304.6.
Saved chunk: 20230922T022805F368722-0V2msEBLcFg2zAJfFRX0QP-0hThKsGqdzd0kW0etWwuX5-1024.npz
train_Episode has 500 steps and return 271.6.
Starting evaluation at step 228500 Counter(228500) 228437
Saved chunk: 20230922T022819F784801-0ZcMkcHh7gZqcXQHXBjYfE-5XtyQiKpoKj28S0iHzm4ZH-1024.npz
eval_Episode has 500 steps and return 319.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 457002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 271.55 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 319.2 / eval_episode/reward_rate 0.5 / train/action_mag 4.02 / train/action_max 3.96 / train/action_mean 0.05 / train/action_min -3.34 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.24 / train/adv_mag 0.41 / train/adv_max 0.33 / train/adv_mean 1e-3 / train/adv_min 
-0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 225.06 / train/extr_critic_max 225.06 / train/extr_critic_mean 214.97 / train/extr_critic_min 165.36 / train/extr_critic_std 11.77 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 225.34 / train/extr_return_raw_max 225.34 / train/extr_return_raw_mean 215.01 / train/extr_return_raw_min
167.22 / train/extr_return_raw_std 11.76 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1.09 / train/image_loss_std 1 / train/model_loss_mean 3.61 / 
train/model_loss_std 4.64 / train/model_opt_grad_norm 8.8 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 4.71 / train/policy_entropy_max
4.64 / train/policy_entropy_mean -2.32 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.23 / train/policy_logprob_mag 10.22 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.32 / train/policy_logprob_min -10.22 / train/policy_logprob_std 1.9 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 4.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.19 / train/post_ent_max 51.19 / train/post_ent_mean 41.68 / 
train/post_ent_min 21.54 / train/post_ent_std 5.32 / train/prior_ent_mag 80.06 / train/prior_ent_max 80.06 / train/prior_ent_mean 45.57 / train/prior_ent_min 27.7 / train/prior_ent_std 6.5 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.47 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.35 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.1e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.98 / report/dyn_loss_std 6.01 / report/image_loss_mean 1.01 / report/image_loss_std 0.79 / report/model_loss_mean 3.61 / report/model_loss_std 4.17 / report/post_ent_mag 51.39 / report/post_ent_max 51.39 /
report/post_ent_mean 42.71 / report/post_ent_min 23.91 / report/post_ent_std 4.62 / report/prior_ent_mag 80.3 / report/prior_ent_max 80.3 / report/prior_ent_mean 46.73 / report/prior_ent_min 27.25 / report/prior_ent_std 5.76 / report/rep_loss_mean 3.98 / 
report/rep_loss_std 6.01 / report/reward_avg 0.43 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / report/reward_max_data 1.97 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.43 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 7.7e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.94 / eval/dyn_loss_std 5.64 / eval/image_loss_mean 0.93 / eval/image_loss_std 0.78 / eval/model_loss_mean 3.6 / eval/model_loss_std 3.96 / eval/post_ent_mag 50.11 / eval/post_ent_max 50.11 / eval/post_ent_mean 
41.49 / eval/post_ent_min 17.26 / eval/post_ent_std 7.01 / eval/prior_ent_mag 80.3 / eval/prior_ent_max 80.3 / eval/prior_ent_mean 45.69 / eval/prior_ent_min 22.33 / eval/prior_ent_std 7.6 / eval/rep_loss_mean 3.94 / eval/rep_loss_std 5.64 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.57 / eval/reward_rate 0.47 / 
replay/size 2.3e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.99 / timer/env.step_count 3778 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.51 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 17.4 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / 
timer/dataset_train_count 1889 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1889 / timer/agent.train_total 242.79 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 265.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 229000 Counter(229000) 228937
Saved chunk: 20230922T022938F732904-5XtyQiKpoKj28S0iHzm4ZH-0000000000000000000000-180.npz
Saved chunk: 20230922T022925F838526-0hThKsGqdzd0kW0etWwuX5-0000000000000000000000-648.npz
eval_Episode has 500 steps and return 317.4.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T022925F838526-0hThKsGqdzd0kW0etWwuX5-2q7vIUVVx2JRZdE4fPIm1z-1024.npz
train_Episode has 500 steps and return 302.7.
Starting evaluation at step 229500 Counter(229500) 229437
Saved chunk: 20230922T022938F732904-5XtyQiKpoKj28S0iHzm4ZH-674Ghyi74w7lXrkHCTgNlj-1024.npz
eval_Episode has 500 steps and return 309.3.
train_Episode has 500 steps and return 291.8.
Starting evaluation at step 230000 Counter(230000) 229937
eval_Episode has 500 steps and return 287.0.
Saved chunk: 20230922T023048F052917-2q7vIUVVx2JRZdE4fPIm1z-49uPMxZxU5o3wJITygLiV1-1024.npz
train_Episode has 500 steps and return 284.6.
Starting evaluation at step 230500 Counter(230500) 230437
Saved chunk: 20230922T023059F412078-674Ghyi74w7lXrkHCTgNlj-1jHYnO4Ix3TdV7Vn6IYjDn-1024.npz
eval_Episode has 500 steps and return 312.3.
train_Episode has 500 steps and return 264.7.
Starting evaluation at step 231000 Counter(231000) 230937
eval_Episode has 500 steps and return 315.2.
Saved chunk: 20230922T023208F985508-49uPMxZxU5o3wJITygLiV1-7JBLEUubIwVT9SUEhVhQeI-1024.npz
train_Episode has 500 steps and return 266.9.
Starting evaluation at step 231500 Counter(231500) 231437
Saved chunk: 20230922T023218F774398-1jHYnO4Ix3TdV7Vn6IYjDn-2RYI9tGFJt5Js4SomOIj7p-1024.npz
eval_Episode has 500 steps and return 309.2.
train_Episode has 500 steps and return 283.3.
Starting evaluation at step 232000 Counter(232000) 231937
eval_Episode has 500 steps and return 313.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 464614 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 283.29 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 313.4 / eval_episode/reward_rate 0.46 / train/action_mag 4 / train/action_max 3.97 / train/action_mean 0.05 / train/action_min -3.27 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss 1.08 / train/adv_mag 0.45 / train/adv_max 0.38 / train/adv_mean 5.9e-4 / train/adv_min 
-0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 225.67 / train/extr_critic_max 225.67 / train/extr_critic_mean 216.23 / train/extr_critic_min 170.01 / train/extr_critic_std 9.61 / train/extr_return_normed_mag 1.28 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.23 / train/extr_return_rate 1 / train/extr_return_raw_mag 225.92 / train/extr_return_raw_max 225.92 / train/extr_return_raw_mean 216.25 / train/extr_return_raw_min 
175.89 / train/extr_return_raw_std 9.63 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 1.06 / train/image_loss_std 0.99 / train/model_loss_mean 3.56 /
train/model_loss_std 4.58 / train/model_opt_grad_norm 8.61 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.57 / train/policy_entropy_max 
4.41 / train/policy_entropy_mean -2.32 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 10.2 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.32 / train/policy_logprob_min -10.2 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3.9e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.41 / train/post_ent_max 51.41 / train/post_ent_mean 41.74 / 
train/post_ent_min 21.88 / train/post_ent_std 5.19 / train/prior_ent_mag 80.06 / train/prior_ent_max 80.06 / train/prior_ent_mean 45.58 / train/prior_ent_min 27.84 / train/prior_ent_std 6.41 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.39 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.36 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.53 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 5.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.98 / report/dyn_loss_std 7.2 / report/image_loss_mean 1.33 / report/image_loss_std 1.11 / report/model_loss_mean 3.86 / report/model_loss_std 5.07 / report/post_ent_mag 50.31 / report/post_ent_max 50.31 / 
report/post_ent_mean 40.01 / report/post_ent_min 21.63 / report/post_ent_std 6.1 / report/prior_ent_mag 79.9 / report/prior_ent_max 79.9 / report/prior_ent_mean 43.94 / report/prior_ent_min 27.73 / report/prior_ent_std 7.4 / report/rep_loss_mean 3.98 / 
report/rep_loss_std 7.2 / report/reward_avg 0.29 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.26 / report/reward_max_data 1.9 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.29 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 9.8e-11 / eval/cont_loss_std 9.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.18 / eval/dyn_loss_std 7.52 / eval/image_loss_mean 1.4 / eval/image_loss_std 2.19 / eval/model_loss_mean 4.8 / eval/model_loss_std 6.22 / eval/post_ent_mag 49.62 / eval/post_ent_max 49.62 / eval/post_ent_mean 
42.52 / eval/post_ent_min 18.84 / eval/post_ent_std 4.68 / eval/prior_ent_mag 79.9 / eval/prior_ent_max 79.9 / eval/prior_ent_mean 47.06 / eval/prior_ent_min 28.78 / eval/prior_ent_std 5.12 / eval/rep_loss_mean 5.18 / eval/rep_loss_std 7.52 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.57 / eval/reward_rate 0.47 / 
replay/size 2.3e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3806 / timer/env.step_total 19.61 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 465.6 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.69 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.76 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T023329F743255-7JBLEUubIwVT9SUEhVhQeI-06foG0iWAd95POzRKWMQFL-1024.npz
train_Episode has 500 steps and return 292.9.
Starting evaluation at step 232500 Counter(232500) 232437
Saved chunk: 20230922T023337F915225-2RYI9tGFJt5Js4SomOIj7p-2jJpMW4oQIMEtYXpqtNEx6-1024.npz
eval_Episode has 500 steps and return 309.8.
train_Episode has 500 steps and return 287.7.
Starting evaluation at step 233000 Counter(233000) 232937
eval_Episode has 500 steps and return 315.0.
train_Episode has 500 steps and return 299.9.
Saved chunk: 20230922T023451F185999-06foG0iWAd95POzRKWMQFL-22sNRAXTiY46W2U286vqb5-1024.npz
Starting evaluation at step 233500 Counter(233500) 233437
Saved chunk: 20230922T023457F831836-2jJpMW4oQIMEtYXpqtNEx6-1BWXK9XsfeccXy40KJto3a-1024.npz
eval_Episode has 500 steps and return 320.0.
train_Episode has 500 steps and return 287.1.
Starting evaluation at step 234000 Counter(234000) 233937
eval_Episode has 500 steps and return 304.9.
train_Episode has 500 steps and return 298.1.
Starting evaluation at step 234500 Counter(234500) 234437
Saved chunk: 20230922T023612F209277-22sNRAXTiY46W2U286vqb5-2fdoChle33nvNAg1nPb3df-1024.npz
eval_Episode has 500 steps and return 324.2.
Saved chunk: 20230922T023617F253329-1BWXK9XsfeccXy40KJto3a-2osBPVxy9O3jmXtMsdNbsK-1024.npz
train_Episode has 500 steps and return 300.2.
Starting evaluation at step 235000 Counter(235000) 234937
eval_Episode has 500 steps and return 289.9.
train_Episode has 500 steps and return 284.7.
Starting evaluation at step 235500 Counter(235500) 235437
eval_Episode has 500 steps and return 310.5.
Saved chunk: 20230922T023736F459133-2osBPVxy9O3jmXtMsdNbsK-5u0BwmzVyizjN14MVWikJl-1024.npz
Saved chunk: 20230922T023733F005802-2fdoChle33nvNAg1nPb3df-5MXdpX0y59My1Oo22FWwNt-1024.npz
train_Episode has 500 steps and return 258.4.
Starting evaluation at step 236000 Counter(236000) 235937
eval_Episode has 500 steps and return 312.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 472138 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 258.41 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 312.8 / eval_episode/reward_rate 0.49 / train/action_mag 4.03 / train/action_max 4 / train/action_mean 0.04 / train/action_min -3.31 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -3.44 / train/adv_mag 0.52 / train/adv_max 0.41 / train/adv_mean 1e-3 / train/adv_min 
-0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.8e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 226.14 / train/extr_critic_max 226.14 / train/extr_critic_mean 215.68 / train/extr_critic_min 155.41 / train/extr_critic_std 13.34 / train/extr_return_normed_mag 1.6 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.59 / train/extr_return_normed_std 0.32 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 226.37 / train/extr_return_raw_max 226.37 / train/extr_return_raw_mean 215.73 / 
train/extr_return_raw_min 159.17 / train/extr_return_raw_std 13.27 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 1.07 / train/image_loss_std 1.01 / 
train/model_loss_mean 3.6 / train/model_loss_std 4.62 / train/model_opt_grad_norm 8.74 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.48 
/ train/policy_entropy_max 4.32 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 10.01 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -10.01 / 
train/policy_logprob_std 1.87 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3.7e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.35 / train/post_ent_max 51.35 / 
train/post_ent_mean 41.77 / train/post_ent_min 21.7 / train/post_ent_std 5.24 / train/prior_ent_mag 80.04 / train/prior_ent_max 80.04 / train/prior_ent_mean 45.64 / train/prior_ent_min 27.7 / train/prior_ent_std 6.42 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.43 /
train/reward_avg 0.36 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 
0.36 / train/reward_rate 0.31 / train_stats/mean_log_entropy -2.55 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.24 / report/dyn_loss_std 7.1 / report/image_loss_mean 1.3 / report/image_loss_std 1.16 / report/model_loss_mean 4.02 / report/model_loss_std 5.09 / report/post_ent_mag 51.61 
/ report/post_ent_max 51.61 / report/post_ent_mean 41.23 / report/post_ent_min 20.72 / report/post_ent_std 5.55 / report/prior_ent_mag 80.05 / report/prior_ent_max 80.05 / report/prior_ent_mean 45.55 / report/prior_ent_min 27.17 / report/prior_ent_std 6.73 / 
report/rep_loss_mean 4.24 / report/rep_loss_std 7.1 / report/reward_avg 0.33 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 1.94 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.33 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 7.3e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 7.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.22 / eval/dyn_loss_std 6.09 / eval/image_loss_mean 0.96 / eval/image_loss_std 0.9 / eval/model_loss_mean 3.8 / eval/model_loss_std 4.37 / eval/post_ent_mag 50.28 / eval/post_ent_max 
50.28 / eval/post_ent_mean 42.91 / eval/post_ent_min 22.45 / eval/post_ent_std 3.73 / eval/prior_ent_mag 80.05 / eval/prior_ent_max 80.05 / eval/prior_ent_mean 47.05 / eval/prior_ent_min 31.36 / eval/prior_ent_std 4.79 / eval/rep_loss_mean 4.22 / eval/rep_loss_std 6.09 
/ eval/reward_avg 0.58 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.47 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.57 
/ eval/reward_rate 0.46 / replay/size 2.4e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3762 / timer/env.step_total 19.54 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.45 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8.2e-3 / 
timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.02 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1881 / 
timer/agent.train_total 241.84 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 295.4.
Starting evaluation at step 236500 Counter(236500) 236437
eval_Episode has 500 steps and return 309.5.
Saved chunk: 20230922T023855F580108-5u0BwmzVyizjN14MVWikJl-1Q7WRn7mWv9igVho8R3jM2-1024.npz
Saved chunk: 20230922T023857F231854-5MXdpX0y59My1Oo22FWwNt-2QuHWFFf6qUxpV6HgR9dMJ-1024.npz
train_Episode has 500 steps and return 254.5.
Starting evaluation at step 237000 Counter(237000) 236937
eval_Episode has 500 steps and return 307.6.
train_Episode has 500 steps and return 292.2.
Starting evaluation at step 237500 Counter(237500) 237437
eval_Episode has 500 steps and return 301.5.
Saved chunk: 20230922T024019F039046-2QuHWFFf6qUxpV6HgR9dMJ-4LxxZ3xtLhyHBUXFlwfhLB-1024.npz
train_Episode has 500 steps and return 298.4.
Starting evaluation at step 238000 Counter(238000) 237937
Saved chunk: 20230922T024015F797995-1Q7WRn7mWv9igVho8R3jM2-1Xaxzkg7liwzJTHyUU2RUn-1024.npz
eval_Episode has 500 steps and return 316.4.
train_Episode has 500 steps and return 276.6.
Starting evaluation at step 238500 Counter(238500) 238437
eval_Episode has 500 steps and return 295.3.
Saved chunk: 20230922T024140F170586-4LxxZ3xtLhyHBUXFlwfhLB-6lj14bKUcBPtwiLvRwKZpE-1024.npz
train_Episode has 500 steps and return 289.3.
Starting evaluation at step 239000 Counter(239000) 238937
Saved chunk: 20230922T024211F423534-1Xaxzkg7liwzJTHyUU2RUn-09pL5wLAHwbYrXRMDHk9jy-1024.npz
eval_Episode has 500 steps and return 316.2.
train_Episode has 500 steps and return 273.1.
Starting evaluation at step 239500 Counter(239500) 239437
eval_Episode has 500 steps and return 308.9.
Saved chunk: 20230922T024300F954108-6lj14bKUcBPtwiLvRwKZpE-3jBPQWBg5Mo8qJZIdIe3gI-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 479750 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 273.08 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 308.91 / eval_episode/reward_rate 0.5 / train/action_mag 4.05 / train/action_max 3.98 / train/action_mean 0.05 / train/action_min -3.24 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -1.33 / train/adv_mag 0.49 / train/adv_max 0.43 / train/adv_mean 8.4e-4 / train/adv_min
-0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.87 / train/dyn_loss_std 6.38 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 226.49 / train/extr_critic_max 226.49 / train/extr_critic_mean 216.27 / train/extr_critic_min 162.32 / train/extr_critic_std 11.78 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 226.73 / train/extr_return_raw_max 226.73 / train/extr_return_raw_mean 216.31 / 
train/extr_return_raw_min 169.47 / train/extr_return_raw_std 11.79 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 1.05 / train/image_loss_std 0.98 / 
train/model_loss_mean 3.57 / train/model_loss_std 4.57 / train/model_opt_grad_norm 8.76 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.45
/ train/policy_entropy_max 4.28 / train/policy_entropy_mean -2.35 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.17 / train/policy_logprob_mag 10.08 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.35 / train/policy_logprob_min -10.08 / 
train/policy_logprob_std 1.86 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3.2e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.61 / train/post_ent_max 51.61 / 
train/post_ent_mean 41.71 / train/post_ent_min 21.85 / train/post_ent_std 5.18 / train/prior_ent_mag 80.01 / train/prior_ent_max 80.01 / train/prior_ent_mean 45.56 / train/prior_ent_min 28.02 / train/prior_ent_std 6.41 / train/rep_loss_mean 3.87 / train/rep_loss_std 
6.38 / train/reward_avg 0.36 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.36 / train/reward_rate 0.31 / train_stats/mean_log_entropy -2.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.33 / report/dyn_loss_std 7.02 / report/image_loss_mean 1.14 / report/image_loss_std 0.93 / report/model_loss_mean 3.93 / report/model_loss_std 4.92 / 
report/post_ent_mag 51.37 / report/post_ent_max 51.37 / report/post_ent_mean 41.46 / report/post_ent_min 22.42 / report/post_ent_std 5.17 / report/prior_ent_mag 80 / report/prior_ent_max 80 / report/prior_ent_mean 45.74 / report/prior_ent_min 31.53 / 
report/prior_ent_std 6.51 / report/rep_loss_mean 4.33 / report/rep_loss_std 7.02 / report/reward_avg 0.37 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / 
report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.36 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.92 / eval/dyn_loss_std 5.82 / eval/image_loss_mean 0.92 / eval/image_loss_std 1.02 / eval/model_loss_mean 3.53 / eval/model_loss_std 4.19 / eval/post_ent_mag 
49.99 / eval/post_ent_max 49.99 / eval/post_ent_mean 41.57 / eval/post_ent_min 16.74 / eval/post_ent_std 7.09 / eval/prior_ent_mag 80 / eval/prior_ent_max 80 / eval/prior_ent_mean 45.74 / eval/prior_ent_min 22.24 / eval/prior_ent_std 7.56 / eval/rep_loss_mean 3.92 / 
eval/rep_loss_std 5.82 / eval/reward_avg 0.55 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / 
eval/reward_pred 0.55 / eval/reward_rate 0.45 / replay/size 2.4e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3806 / timer/env.step_total 19.76 / 
timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.23 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
6.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.38 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / 
timer/agent.train_count 1903 / timer/agent.train_total 244.88 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / 
timer/dataset_eval_max 3.6e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 290.3.
Starting evaluation at step 240000 Counter(240000) 239937
Saved chunk: 20230922T024330F627515-09pL5wLAHwbYrXRMDHk9jy-0HARV2EiSUGK1JG3oTVq0I-1024.npz
eval_Episode has 500 steps and return 314.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T024450F643013-0HARV2EiSUGK1JG3oTVq0I-0000000000000000000000-439.npz
Saved chunk: 20230922T024421F649175-3jBPQWBg5Mo8qJZIdIe3gI-0000000000000000000000-784.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 281.3.
Starting evaluation at step 240500 Counter(240500) 240437
eval_Episode has 500 steps and return 300.2.
Saved chunk: 20230922T024421F649175-3jBPQWBg5Mo8qJZIdIe3gI-2TMsMfmKdbMUU2ssCF7bYr-1024.npz
train_Episode has 500 steps and return 282.2.
Starting evaluation at step 241000 Counter(241000) 240937
Saved chunk: 20230922T024450F643013-0HARV2EiSUGK1JG3oTVq0I-0Z0oCWSgN1ApP2RCZzevcu-1024.npz
eval_Episode has 500 steps and return 303.7.
train_Episode has 500 steps and return 260.0.
Starting evaluation at step 241500 Counter(241500) 241437
eval_Episode has 500 steps and return 263.3.
Saved chunk: 20230922T024543F865625-2TMsMfmKdbMUU2ssCF7bYr-1WKU21zdAKmHJAhB3ayV6j-1024.npz
train_Episode has 500 steps and return 268.2.
Starting evaluation at step 242000 Counter(242000) 241937
Saved chunk: 20230922T024610F453461-0Z0oCWSgN1ApP2RCZzevcu-4mRXvZM5P4EMCNkB7TQTfD-1024.npz
eval_Episode has 500 steps and return 297.6.
train_Episode has 500 steps and return 253.8.
Starting evaluation at step 242500 Counter(242500) 242437
eval_Episode has 500 steps and return 306.4.
Saved chunk: 20230922T024704F871538-1WKU21zdAKmHJAhB3ayV6j-7AMiNxmGtNKHXohfhtzOkw-1024.npz
train_Episode has 500 steps and return 277.3.
Starting evaluation at step 243000 Counter(243000) 242937
Saved chunk: 20230922T024729F814978-4mRXvZM5P4EMCNkB7TQTfD-3yKYVqTTZtphNne2saq3P0-1024.npz
eval_Episode has 500 steps and return 299.2.
train_Episode has 500 steps and return 265.7.
Starting evaluation at step 243500 Counter(243500) 243437
eval_Episode has 500 steps and return 302.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 487258 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 265.69 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 302.16 / eval_episode/reward_rate 0.51 / train/action_mag 4.06 / train/action_max 4.03 / train/action_mean 0.05 / train/action_min -3.24 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss 1 / train/adv_mag 0.57 / train/adv_max 0.48 / train/adv_mean 6.1e-4 / 
train/adv_min -0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 227.12 / train/extr_critic_max 227.12 / train/extr_critic_mean 217.25 / train/extr_critic_min 163.9 / train/extr_critic_std 10.95 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 227.38 / train/extr_return_raw_max 227.38 / train/extr_return_raw_mean 217.27 / train/extr_return_raw_min
171.15 / train/extr_return_raw_std 10.98 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.05 / train/image_loss_std 0.97 / train/model_loss_mean 3.57 
/ train/model_loss_std 4.56 / train/model_opt_grad_norm 8.72 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.57 / train/policy_entropy_max
4.4 / train/policy_entropy_mean -2.36 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 10.27 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.36 / train/policy_logprob_min -10.27 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.81 / train/post_ent_max 51.81 / train/post_ent_mean 41.81 / 
train/post_ent_min 22.13 / train/post_ent_std 5.1 / train/prior_ent_mag 80 / train/prior_ent_max 80 / train/prior_ent_mean 45.67 / train/prior_ent_min 28.36 / train/prior_ent_std 6.32 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.37 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.37 / train/reward_rate 
0.32 / train_stats/mean_log_entropy -2.59 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 9.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 6.35 / report/image_loss_mean 0.91 / report/image_loss_std 1.09 / report/model_loss_mean 3.19 / report/model_loss_std 4.61 / report/post_ent_mag 52.48 / report/post_ent_max 52.48 /
report/post_ent_mean 40.1 / report/post_ent_min 18.94 / report/post_ent_std 6.41 / report/prior_ent_mag 79.89 / report/prior_ent_max 79.89 / report/prior_ent_mean 43.61 / report/prior_ent_min 20.5 / report/prior_ent_std 8.05 / report/rep_loss_mean 3.54 / 
report/rep_loss_std 6.35 / report/reward_avg 0.3 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.29 / report/reward_max_data 1.91 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.3 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 8e-11 / eval/cont_loss_std 4.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8e-11 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 5.55 / eval/dyn_loss_std 8.66 / eval/image_loss_mean 1.53 / eval/image_loss_std 2.48 / eval/model_loss_mean 5.13 / eval/model_loss_std 7.53 / eval/post_ent_mag 50.19 / eval/post_ent_max 50.19 / eval/post_ent_mean 40.74 / 
eval/post_ent_min 18.76 / eval/post_ent_std 7.22 / eval/prior_ent_mag 79.89 / eval/prior_ent_max 79.89 / eval/prior_ent_mean 45.37 / eval/prior_ent_min 22.14 / eval/prior_ent_std 7.51 / eval/rep_loss_mean 5.55 / eval/rep_loss_std 8.66 / eval/reward_avg 0.5 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 1 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.68 / eval/reward_pred 0.49 / eval/reward_rate 0.4 / 
replay/size 2.4e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3754 / timer/env.step_total 19.46 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.54 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.05 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.5 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 6.5e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.61 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T024825F598798-7AMiNxmGtNKHXohfhtzOkw-7CBXToEKLCAtZ2bl0ip6nt-1024.npz
train_Episode has 500 steps and return 285.4.
Starting evaluation at step 244000 Counter(244000) 243937
Saved chunk: 20230922T024848F908840-3yKYVqTTZtphNne2saq3P0-1Swe6fluPrgeU6sB0mRc8E-1024.npz
eval_Episode has 500 steps and return 315.1.
train_Episode has 500 steps and return 276.7.
Starting evaluation at step 244500 Counter(244500) 244437
eval_Episode has 500 steps and return 262.5.
Saved chunk: 20230922T024947F111151-7CBXToEKLCAtZ2bl0ip6nt-1Xl6wizM4eC2vQhTEJKZm4-1024.npz
train_Episode has 500 steps and return 301.6.
Starting evaluation at step 245000 Counter(245000) 244937
Saved chunk: 20230922T025008F972827-1Swe6fluPrgeU6sB0mRc8E-64Gk3JCft38SnxEoM0thYV-1024.npz
eval_Episode has 500 steps and return 311.4.
train_Episode has 500 steps and return 245.4.
Starting evaluation at step 245500 Counter(245500) 245437
eval_Episode has 500 steps and return 316.6.
Saved chunk: 20230922T025108F164276-1Xl6wizM4eC2vQhTEJKZm4-3U9BVHuEpbuD4vIh8PjJYi-1024.npz
train_Episode has 500 steps and return 263.9.
Starting evaluation at step 246000 Counter(246000) 245937
Saved chunk: 20230922T025128F409581-64Gk3JCft38SnxEoM0thYV-0KFJhlAfsrlHZsCa1mxHN5-1024.npz
eval_Episode has 500 steps and return 318.1.
train_Episode has 500 steps and return 289.9.
Starting evaluation at step 246500 Counter(246500) 246437
eval_Episode has 500 steps and return 309.6.
Saved chunk: 20230922T025229F055712-3U9BVHuEpbuD4vIh8PjJYi-73kAgi35Lwuf5SVu3tAAnc-1024.npz
train_Episode has 500 steps and return 279.9.
Starting evaluation at step 247000 Counter(247000) 246937
Saved chunk: 20230922T025247F677571-0KFJhlAfsrlHZsCa1mxHN5-66fOSCy7Ij0YfkgnaHsLNC-1024.npz
eval_Episode has 500 steps and return 306.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 494882 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 279.9 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 306.13 / eval_episode/reward_rate 0.52 / train/action_mag 4.01 / train/action_max 3.96 / train/action_mean 0.05 / train/action_min -3.36 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss 2.91 / train/adv_mag 0.66 / train/adv_max 0.59 / train/adv_mean 4e-4 / train/adv_min 
-0.32 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.5e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 227.63 / train/extr_critic_max 227.63 / train/extr_critic_mean 217.73 / train/extr_critic_min 160.73 / train/extr_critic_std 10.93 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 227.86 / train/extr_return_raw_max 227.86 / train/extr_return_raw_mean 217.74 / 
train/extr_return_raw_min 172.23 / train/extr_return_raw_std 10.94 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.04 / train/image_loss_std 0.98 / 
train/model_loss_mean 3.55 / train/model_loss_std 4.57 / train/model_opt_grad_norm 8.7 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.78 
/ train/policy_entropy_max 4.65 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.28 / train/policy_logprob_mag 10.55 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -10.55 / 
train/policy_logprob_std 1.93 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3.3e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52 / train/post_ent_max 52 / 
train/post_ent_mean 41.83 / train/post_ent_min 21.82 / train/post_ent_std 5.06 / train/prior_ent_mag 79.95 / train/prior_ent_max 79.95 / train/prior_ent_mean 45.68 / train/prior_ent_min 28.15 / train/prior_ent_std 6.28 / train/rep_loss_mean 3.86 / train/rep_loss_std 
6.36 / train/reward_avg 0.37 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.37 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.62 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 4.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.46 / report/dyn_loss_std 6.91 / report/image_loss_mean 1.17 / report/image_loss_std 1.18 / report/model_loss_mean 3.34 / report/model_loss_std 5.05 / 
report/post_ent_mag 54.56 / report/post_ent_max 54.56 / report/post_ent_mean 39.62 / report/post_ent_min 21.74 / report/post_ent_std 5.76 / report/prior_ent_mag 80.15 / report/prior_ent_max 80.15 / report/prior_ent_mean 43.16 / report/prior_ent_min 27.27 / 
report/prior_ent_std 7.25 / report/rep_loss_mean 3.46 / report/rep_loss_std 6.91 / report/reward_avg 0.15 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.25 / report/reward_max_data 1.69 / report/reward_max_pred 1.69 / report/reward_neg_acc 1 / 
report/reward_neg_loss 3.2e-4 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.59 / report/reward_pred 0.15 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.57 / eval/dyn_loss_std 6.81 / eval/image_loss_mean 1.17 / eval/image_loss_std 1.41 / eval/model_loss_mean 4.19 / eval/model_loss_std 5.09 / eval/post_ent_mag 
51.12 / eval/post_ent_max 51.12 / eval/post_ent_mean 42.33 / eval/post_ent_min 20.34 / eval/post_ent_std 4.42 / eval/prior_ent_mag 80.15 / eval/prior_ent_max 80.15 / eval/prior_ent_mean 46.72 / eval/prior_ent_min 30.99 / eval/prior_ent_std 5.32 / eval/rep_loss_mean 4.57
/ eval/rep_loss_std 6.81 / eval/reward_avg 0.55 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.55 / eval/reward_rate 0.46 / replay/size 2.5e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3812 / timer/env.step_total 19.65
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.86 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 7.3e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.32 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.8e-4 / 
timer/agent.train_count 1906 / timer/agent.train_total 245.15 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 278.9.
Starting evaluation at step 247500 Counter(247500) 247437
eval_Episode has 500 steps and return 308.5.
Saved chunk: 20230922T025349F689752-73kAgi35Lwuf5SVu3tAAnc-49R8wR7FwHFwtetjDIr4Oi-1024.npz
train_Episode has 500 steps and return 304.9.
Starting evaluation at step 248000 Counter(248000) 247937
Saved chunk: 20230922T025406F699921-66fOSCy7Ij0YfkgnaHsLNC-22dYG4yeOUzOG6cxmjRqoi-1024.npz
eval_Episode has 500 steps and return 301.7.
train_Episode has 500 steps and return 294.1.
Starting evaluation at step 248500 Counter(248500) 248437
eval_Episode has 500 steps and return 312.0.
Saved chunk: 20230922T025511F322222-49R8wR7FwHFwtetjDIr4Oi-0PIzCTX8srKH4X1C03v0r2-1024.npz
train_Episode has 500 steps and return 288.1.
Starting evaluation at step 249000 Counter(249000) 248937
Saved chunk: 20230922T025526F888591-22dYG4yeOUzOG6cxmjRqoi-04UpaNJEvaLfcLaw0IOh9l-1024.npz
eval_Episode has 500 steps and return 329.9.
train_Episode has 500 steps and return 281.7.
Starting evaluation at step 249500 Counter(249500) 249437
eval_Episode has 500 steps and return 299.6.
Saved chunk: 20230922T025632F344162-0PIzCTX8srKH4X1C03v0r2-31VhqM0JhwOUpvdS57rIYi-1024.npz
train_Episode has 500 steps and return 306.0.
Starting evaluation at step 250000 Counter(250000) 249937
Saved chunk: 20230922T025646F283930-04UpaNJEvaLfcLaw0IOh9l-0sfFey0L6AwY7nQXAMd6KG-1024.npz
eval_Episode has 500 steps and return 292.1.
train_Episode has 500 steps and return 306.6.
Starting evaluation at step 250500 Counter(250500) 250437
eval_Episode has 500 steps and return 288.1.
Saved chunk: 20230922T025753F208838-31VhqM0JhwOUpvdS57rIYi-4sFvtR2DnrAqVLGZGsVUxu-1024.npz
Starting evaluation at step 251000 Counter(251000) 250937
Saved chunk: 20230922T025805F546883-0sfFey0L6AwY7nQXAMd6KG-2KoDVGZXNEuWbhhCmzoOrt-1024.npz
eval_Episode has 500 steps and return 328.4.
train_Episode has 500 steps and return 266.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 502402 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 266.86 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 328.42 / eval_episode/reward_rate 0.48 / train/action_mag 4.04 / train/action_max 3.99 / train/action_mean 0.05 / train/action_min -3.39 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss 1.32 / train/adv_mag 0.55 / train/adv_max 0.45 / train/adv_mean 5.6e-4
/ train/adv_min -0.35 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 228.08 / train/extr_critic_max 228.08 / train/extr_critic_mean 217.95 / train/extr_critic_min 166.48 / train/extr_critic_std 11.5 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 228.29 / train/extr_return_raw_max 228.29 / train/extr_return_raw_mean 217.97 / 
train/extr_return_raw_min 170.53 / train/extr_return_raw_std 11.5 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.04 / train/image_loss_std 1 / 
train/model_loss_mean 3.55 / train/model_loss_std 4.56 / train/model_opt_grad_norm 8.69 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.85
/ train/policy_entropy_max 4.8 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.3 / train/policy_logprob_mag 10.31 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -10.31 / 
train/policy_logprob_std 1.95 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3.2e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.26 / train/post_ent_max 52.26 / 
train/post_ent_mean 41.76 / train/post_ent_min 21.89 / train/post_ent_std 5.1 / train/prior_ent_mag 79.99 / train/prior_ent_max 79.99 / train/prior_ent_mean 45.59 / train/prior_ent_min 27.97 / train/prior_ent_std 6.35 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.32
/ train/reward_avg 0.37 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.37 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.6 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4 / report/dyn_loss_std 6.64 / report/image_loss_mean 0.97 / report/image_loss_std 0.73 / report/model_loss_mean 3.62 / report/model_loss_std 4.54 / report/post_ent_mag 51.21 /
report/post_ent_max 51.21 / report/post_ent_mean 43.09 / report/post_ent_min 21.4 / report/post_ent_std 4.52 / report/prior_ent_mag 79.95 / report/prior_ent_max 79.95 / report/prior_ent_mean 47.11 / report/prior_ent_min 23.45 / report/prior_ent_std 5.52 / 
report/rep_loss_mean 4 / report/rep_loss_std 6.64 / report/reward_avg 0.48 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.48 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.45 / eval/dyn_loss_std 6.69 / eval/image_loss_mean 1.1 / eval/image_loss_std 1.46 / eval/model_loss_mean 4.07 / eval/model_loss_std 5.11 / eval/post_ent_mag 50.01 / eval/post_ent_max
50.01 / eval/post_ent_mean 42.73 / eval/post_ent_min 18.26 / eval/post_ent_std 4.41 / eval/prior_ent_mag 79.95 / eval/prior_ent_max 79.95 / eval/prior_ent_mean 46.99 / eval/prior_ent_min 32.68 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 4.45 / eval/rep_loss_std 6.69 
/ eval/reward_avg 0.59 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.46 / eval/reward_max_data 1.91 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.59 / 
eval/reward_rate 0.47 / replay/size 2.5e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3760 / timer/env.step_total 19.43 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.55 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.2e-3 / 
timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.32 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1880 / 
timer/agent.train_total 241.93 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 251500 Counter(251500) 251437
eval_Episode has 500 steps and return 307.6.
train_Episode has 500 steps and return 288.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T025913F831434-4sFvtR2DnrAqVLGZGsVUxu-0000000000000000000000-920.npz
Saved chunk: 20230922T025924F556906-2KoDVGZXNEuWbhhCmzoOrt-0000000000000000000000-698.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T025913F831434-4sFvtR2DnrAqVLGZGsVUxu-2Qqn5RbfNsOS5m3Igeidg1-1024.npz
Starting evaluation at step 252000 Counter(252000) 251937
Saved chunk: 20230922T025924F556906-2KoDVGZXNEuWbhhCmzoOrt-1EEwO0ivzvt6YlHYT0NvQO-1024.npz
eval_Episode has 500 steps and return 331.4.
train_Episode has 500 steps and return 310.1.
Starting evaluation at step 252500 Counter(252500) 252437
eval_Episode has 500 steps and return 330.1.
train_Episode has 500 steps and return 283.2.
Saved chunk: 20230922T030035F839025-2Qqn5RbfNsOS5m3Igeidg1-697CPBLjDeSgSmObdrtXSd-1024.npz
Starting evaluation at step 253000 Counter(253000) 252937
Saved chunk: 20230922T030045F091670-1EEwO0ivzvt6YlHYT0NvQO-4B0ESeQPJOtAlHz3nEub0M-1024.npz
eval_Episode has 500 steps and return 315.5.
train_Episode has 500 steps and return 309.7.
Starting evaluation at step 253500 Counter(253500) 253437
eval_Episode has 500 steps and return 296.4.
train_Episode has 500 steps and return 266.0.
Saved chunk: 20230922T030156F792463-697CPBLjDeSgSmObdrtXSd-6EI058jEPFyoPewwNo41RG-1024.npz
Starting evaluation at step 254000 Counter(254000) 253937
Saved chunk: 20230922T030204F428498-4B0ESeQPJOtAlHz3nEub0M-4LZzabNJO3KzTmc79PUxtQ-1024.npz
eval_Episode has 500 steps and return 300.0.
train_Episode has 500 steps and return 287.1.
Starting evaluation at step 254500 Counter(254500) 254437
eval_Episode has 500 steps and return 319.5.
train_Episode has 500 steps and return 293.4.
Saved chunk: 20230922T030317F496125-6EI058jEPFyoPewwNo41RG-7jKqRYPXpzUXHkQUVmpkx3-1024.npz
Starting evaluation at step 255000 Counter(255000) 254937
Saved chunk: 20230922T030323F513202-4LZzabNJO3KzTmc79PUxtQ-1HaiONwcW8syTH5SREH6So-1024.npz
eval_Episode has 500 steps and return 315.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 510002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 315.36 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 293.39 / episode/reward_rate 0.45 / train/action_mag 3.96 / train/action_max 3.89 / train/action_mean 0.06 / train/action_min -3.24 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -1.51 / train/adv_mag 0.54 / train/adv_max 0.46 / train/adv_mean 9e-4 
/ train/adv_min -0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 6.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 228.46 / train/extr_critic_max 228.46 / train/extr_critic_mean 218.81 / train/extr_critic_min 169.75 / train/extr_critic_std 10.83 / train/extr_return_normed_mag 1.56 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 228.68 / train/extr_return_raw_max 228.68 / train/extr_return_raw_mean 218.84 / 
train/extr_return_raw_min 171.54 / train/extr_return_raw_std 10.83 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.03 / train/image_loss_std 0.96 / 
train/model_loss_mean 3.54 / train/model_loss_std 4.52 / train/model_opt_grad_norm 8.78 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 5.3e-3 / train/model_opt_model_opt_grad_scale 7342.11 / 
train/policy_entropy_mag 4.56 / train/policy_entropy_max 4.4 / train/policy_entropy_mean -2.49 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.14 / train/policy_logprob_mag 9.91 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.49 / 
train/policy_logprob_min -9.91 / train/policy_logprob_std 1.83 / train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.81 / 
train/post_ent_max 51.81 / train/post_ent_mean 41.84 / train/post_ent_min 21.71 / train/post_ent_std 5.04 / train/prior_ent_mag 79.89 / train/prior_ent_max 79.89 / train/prior_ent_mean 45.67 / train/prior_ent_min 28.34 / train/prior_ent_std 6.27 / train/rep_loss_mean 
3.85 / train/rep_loss_std 6.32 / train/reward_avg 0.37 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / 
train/reward_pos_loss 0.59 / train/reward_pred 0.37 / train/reward_rate 0.32 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.69 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 7.5e-11 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.32 / report/dyn_loss_std 5.13 / report/image_loss_mean 0.74 / report/image_loss_std 0.58 / report/model_loss_mean 2.95 / 
report/model_loss_std 3.57 / report/post_ent_mag 53.9 / report/post_ent_max 53.9 / report/post_ent_mean 41.06 / report/post_ent_min 19.42 / report/post_ent_std 6.5 / report/prior_ent_mag 79.98 / report/prior_ent_max 79.98 / report/prior_ent_mean 44.6 / 
report/prior_ent_min 22.93 / report/prior_ent_std 7.55 / report/rep_loss_mean 3.32 / report/rep_loss_std 5.13 / report/reward_avg 0.42 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.36 / report/reward_max_data 1.97 / report/reward_max_pred 1.96 / 
report/reward_neg_acc 1 / report/reward_neg_loss 7.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.63 / report/reward_pred 0.41 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 6.1e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.83 / eval/dyn_loss_std 5.8 / eval/image_loss_mean 0.84 / eval/image_loss_std 0.78 / eval/model_loss_mean 3.44 / eval/model_loss_std 
4.17 / eval/post_ent_mag 50.86 / eval/post_ent_max 50.86 / eval/post_ent_mean 41.71 / eval/post_ent_min 18.48 / eval/post_ent_std 6.64 / eval/prior_ent_mag 79.98 / eval/prior_ent_max 79.98 / eval/prior_ent_mean 45.57 / eval/prior_ent_min 23.09 / eval/prior_ent_std 7.26 
/ eval/rep_loss_mean 3.83 / eval/rep_loss_std 5.8 / eval/reward_avg 0.56 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.57 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.63 / eval/reward_pred 0.56 / eval/reward_rate 0.44 / replay/size 2.5e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.98 / timer/env.step_count 3800 / 
timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 464.5 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 /
timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7808 / 
timer/agent.policy_total 17.46 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / 
timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.38 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.08

train_Episode has 500 steps and return 285.1.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 255500 Counter(255500) 255437
eval_Episode has 500 steps and return 299.3.
train_Episode has 500 steps and return 307.2.
Starting evaluation at step 256000 Counter(256000) 255937
Saved chunk: 20230922T030438F092533-7jKqRYPXpzUXHkQUVmpkx3-4VmEeFmLEJlqYIzE8IBuyn-1024.npz
Saved chunk: 20230922T030442F588231-1HaiONwcW8syTH5SREH6So-2Awvcl0MKmjlLn2HDeJNFw-1024.npz
eval_Episode has 500 steps and return 303.0.
train_Episode has 500 steps and return 310.3.
Starting evaluation at step 256500 Counter(256500) 256437
eval_Episode has 500 steps and return 311.2.
train_Episode has 500 steps and return 303.1.
Starting evaluation at step 257000 Counter(257000) 256937
eval_Episode has 500 steps and return 320.5.
Saved chunk: 20230922T030602F899844-2Awvcl0MKmjlLn2HDeJNFw-4IjQnh9aGTrSzv0paCDyKY-1024.npz
train_Episode has 500 steps and return 288.6.
Saved chunk: 20230922T030600F002494-4VmEeFmLEJlqYIzE8IBuyn-1cizPUedkWuPY1kri59BfJ-1024.npz
Starting evaluation at step 257500 Counter(257500) 257437
eval_Episode has 500 steps and return 326.3.
train_Episode has 500 steps and return 289.4.
Starting evaluation at step 258000 Counter(258000) 257937
eval_Episode has 500 steps and return 296.4.
Saved chunk: 20230922T030722F142728-4IjQnh9aGTrSzv0paCDyKY-2nNrUqYtqu4jDeLmb18efc-1024.npz
train_Episode has 500 steps and return 307.8.
Saved chunk: 20230922T030724F372736-1cizPUedkWuPY1kri59BfJ-0sh5uZXcKJz7osDq0dl8xJ-1024.npz
Starting evaluation at step 258500 Counter(258500) 258437
eval_Episode has 500 steps and return 298.0.
train_Episode has 500 steps and return 306.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 517626 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 306.07 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 297.99 / eval_episode/reward_rate 0.45 / train_stats/mean_log_entropy -2.63 / train/action_mag 4 / train/action_max 3.99 / train/action_mean 0.06 / 
train/action_min -3.2 / train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -0.6 / train/adv_mag 0.46 / train/adv_max 0.34
/ train/adv_mean 7.8e-4 / train/adv_min -0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1
/ train/cont_rate 1 / train/dyn_loss_mean 3.85 / train/dyn_loss_std 6.3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.97 / train/extr_critic_max 228.97 / train/extr_critic_mean 219.86 / train/extr_critic_min 181.11 / train/extr_critic_std 8.7 / 
train/extr_return_normed_mag 1.27 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 229.18 / train/extr_return_raw_max 
229.18 / train/extr_return_raw_mean 219.89 / train/extr_return_raw_min 183.01 / train/extr_return_raw_std 8.75 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / 
train/image_loss_mean 1.03 / train/image_loss_std 0.96 / train/model_loss_mean 3.53 / train/model_loss_std 4.52 / train/model_opt_grad_norm 8.5 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.45 / train/policy_entropy_max 4.33 / train/policy_entropy_mean -2.39 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.9 / train/policy_logprob_max 5.49 / 
train/policy_logprob_mean 2.39 / train/policy_logprob_min -9.9 / train/policy_logprob_std 1.86 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 
0.13 / train/post_ent_mag 51.63 / train/post_ent_max 51.63 / train/post_ent_mean 41.98 / train/post_ent_min 21.93 / train/post_ent_std 4.89 / train/prior_ent_mag 79.9 / train/prior_ent_max 79.9 / train/prior_ent_mean 45.8 / train/prior_ent_min 28.48 / 
train/prior_ent_std 6.12 / train/rep_loss_mean 3.85 / train/rep_loss_std 6.3 / train/reward_avg 0.39 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.95 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 
5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.39 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 2.6e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 5.43 / report/image_loss_mean 0.88 / report/image_loss_std 0.76 / report/model_loss_mean 3.3 / 
report/model_loss_std 3.86 / report/post_ent_mag 53.25 / report/post_ent_max 53.25 / report/post_ent_mean 42.28 / report/post_ent_min 21.38 / report/post_ent_std 4.17 / report/prior_ent_mag 79.73 / report/prior_ent_max 79.73 / report/prior_ent_mean 45.86 / 
report/prior_ent_min 33.77 / report/prior_ent_std 5.69 / report/rep_loss_mean 3.72 / report/rep_loss_std 5.43 / report/reward_avg 0.37 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.32 / report/reward_max_data 1.9 / report/reward_max_pred 1.9 / 
report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.62 / report/reward_pred 0.37 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.81 / eval/dyn_loss_std 6.59 / eval/image_loss_mean 1.16 / eval/image_loss_std 1.39 / eval/model_loss_mean 4.32 / eval/model_loss_std 
4.92 / eval/post_ent_mag 50.32 / eval/post_ent_max 50.32 / eval/post_ent_mean 42.4 / eval/post_ent_min 22.05 / eval/post_ent_std 4.01 / eval/prior_ent_mag 79.73 / eval/prior_ent_max 79.73 / eval/prior_ent_mean 46.91 / eval/prior_ent_min 28.31 / eval/prior_ent_std 5.16 /
eval/rep_loss_mean 4.81 / eval/rep_loss_std 6.59 / eval/reward_avg 0.56 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.59 / eval/reward_pred 0.55 / eval/reward_rate 0.46 / replay/size 2.6e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3812 / 
timer/env.step_total 19.64 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.72 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 
0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.29 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1906 / timer/agent.train_total 245.2 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 259000 Counter(259000) 258937
eval_Episode has 500 steps and return 319.9.
Saved chunk: 20230922T030841F244039-2nNrUqYtqu4jDeLmb18efc-3ahluveuJfa7XMgrkxsBb7-1024.npz
train_Episode has 500 steps and return 286.2.
Saved chunk: 20230922T030845F056490-0sh5uZXcKJz7osDq0dl8xJ-5uJkVS4L8tcUnYy9VWTcp0-1024.npz
Starting evaluation at step 259500 Counter(259500) 259437
eval_Episode has 500 steps and return 308.4.
train_Episode has 500 steps and return 278.7.
Starting evaluation at step 260000 Counter(260000) 259937
eval_Episode has 500 steps and return 298.1.
train_Episode has 500 steps and return 298.5.
Saved chunk: 20230922T031006F616879-5uJkVS4L8tcUnYy9VWTcp0-3txQSwPSuyTL61zANlW4bP-1024.npz
Starting evaluation at step 260500 Counter(260500) 260437
Saved chunk: 20230922T031001F227658-3ahluveuJfa7XMgrkxsBb7-6llDMojHm3BVwcvctCOM1u-1024.npz
eval_Episode has 500 steps and return 295.6.
train_Episode has 500 steps and return 299.5.
Starting evaluation at step 261000 Counter(261000) 260937
eval_Episode has 500 steps and return 266.7.
train_Episode has 500 steps and return 273.8.
Saved chunk: 20230922T031127F562239-3txQSwPSuyTL61zANlW4bP-3CiZY5uAyEMTu9Iu7js55c-1024.npz
Starting evaluation at step 261500 Counter(261500) 261437
Saved chunk: 20230922T031156F659414-6llDMojHm3BVwcvctCOM1u-7IOJurAMSS74LIbXFgoXpm-1024.npz
eval_Episode has 500 steps and return 314.8.
train_Episode has 500 steps and return 296.2.
Starting evaluation at step 262000 Counter(262000) 261937
eval_Episode has 500 steps and return 321.8.
train_Episode has 500 steps and return 268.0.
Saved chunk: 20230922T031248F313550-3CiZY5uAyEMTu9Iu7js55c-6hFZPzf6mcTbYYTDZ7O7U4-1024.npz
Starting evaluation at step 262500 Counter(262500) 262437
Saved chunk: 20230922T031315F778080-7IOJurAMSS74LIbXFgoXpm-6Sjw3xoXEvB7Lui4r6Wy3h-1024.npz
eval_Episode has 500 steps and return 318.3.
train_Episode has 500 steps and return 305.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 525154 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 318.32 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 305.46 / episode/reward_rate 0.48 / train/action_mag 4.12 / train/action_max 4.05 / train/action_mean 0.06 / train/action_min -3.46 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 2.66 / train/adv_mag 0.46 / train/adv_max 0.38 / train/adv_mean 4.2e-4
/ train/adv_min -0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.82 / train/dyn_loss_std 6.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.38 / train/extr_critic_max 229.38 / train/extr_critic_mean 219.47 / train/extr_critic_min 170.22 / train/extr_critic_std 11.26 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.58 / train/extr_return_raw_max 229.58 / train/extr_return_raw_mean 219.49 / 
train/extr_return_raw_min 173.73 / train/extr_return_raw_std 11.3 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.01 / train/image_loss_std 0.95 / 
train/model_loss_mean 3.49 / train/model_loss_std 4.49 / train/model_opt_grad_norm 8.52 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.79
/ train/policy_entropy_max 4.76 / train/policy_entropy_mean -2.29 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.37 / train/policy_logprob_mag 10.62 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -10.62 / 
train/policy_logprob_std 1.99 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.83 / train/post_ent_max 51.83 / 
train/post_ent_mean 41.9 / train/post_ent_min 21.87 / train/post_ent_std 4.97 / train/prior_ent_mag 79.87 / train/prior_ent_max 79.87 / train/prior_ent_mean 45.69 / train/prior_ent_min 28.14 / train/prior_ent_std 6.26 / train/rep_loss_mean 3.82 / train/rep_loss_std 6.28
/ train/reward_avg 0.38 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.38 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.61 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.69 / report/dyn_loss_std 5.38 / report/image_loss_mean 0.91 / report/image_loss_std 0.67 / report/model_loss_mean 3.36 / report/model_loss_std 3.84 / report/post_ent_mag 51.32 
/ report/post_ent_max 51.32 / report/post_ent_mean 43.09 / report/post_ent_min 27.05 / report/post_ent_std 3.58 / report/prior_ent_mag 79.95 / report/prior_ent_max 79.95 / report/prior_ent_mean 46.9 / report/prior_ent_min 35.64 / report/prior_ent_std 5.01 / 
report/rep_loss_mean 3.69 / report/rep_loss_std 5.38 / report/reward_avg 0.45 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 8.6e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.45 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.22 / eval/dyn_loss_std 6.4 / eval/image_loss_mean 1.12 / eval/image_loss_std 1.86 / eval/model_loss_mean 3.95 / eval/model_loss_std 5.08 / eval/post_ent_mag 49.98 / eval/post_ent_max
49.98 / eval/post_ent_mean 42.61 / eval/post_ent_min 21.06 / eval/post_ent_std 4.17 / eval/prior_ent_mag 79.95 / eval/prior_ent_max 79.95 / eval/prior_ent_mean 46.6 / eval/prior_ent_min 32.19 / eval/prior_ent_std 5.25 / eval/rep_loss_mean 4.22 / eval/rep_loss_std 6.4 / 
eval/reward_avg 0.61 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.6 / 
eval/reward_rate 0.47 / replay/size 2.6e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3764 / timer/env.step_total 19.4 / timer/env.step_frac 0.06 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.99 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.9e-3 / 
timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.22 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1882 / 
timer/agent.train_total 242.08 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 263000 Counter(263000) 262937
eval_Episode has 500 steps and return 315.6.
train_Episode has 500 steps and return 306.3.
Saved chunk: 20230922T031408F964739-6hFZPzf6mcTbYYTDZ7O7U4-6RrdmDxbH6eTHfQsL8ifM2-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T031434F882771-6Sjw3xoXEvB7Lui4r6Wy3h-0000000000000000000000-957.npz
Saved chunk: 20230922T031530F737655-6RrdmDxbH6eTHfQsL8ifM2-0000000000000000000000-32.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 263500 Counter(263500) 263437
Saved chunk: 20230922T031434F882771-6Sjw3xoXEvB7Lui4r6Wy3h-4lTloSAJnaQ60uyCVKTGS0-1024.npz
eval_Episode has 500 steps and return 323.1.
train_Episode has 500 steps and return 273.3.
Starting evaluation at step 264000 Counter(264000) 263937
eval_Episode has 500 steps and return 295.3.
train_Episode has 500 steps and return 280.9.
Saved chunk: 20230922T031530F737655-6RrdmDxbH6eTHfQsL8ifM2-1Av2nClxcgwmxlmSStUFsZ-1024.npz
Starting evaluation at step 264500 Counter(264500) 264437
Saved chunk: 20230922T031555F575055-4lTloSAJnaQ60uyCVKTGS0-500Rs0NCkODzWaiLF2cUkM-1024.npz
eval_Episode has 500 steps and return 311.5.
train_Episode has 500 steps and return 251.2.
Starting evaluation at step 265000 Counter(265000) 264937
eval_Episode has 500 steps and return 305.5.
train_Episode has 500 steps and return 312.3.
Saved chunk: 20230922T031652F115097-1Av2nClxcgwmxlmSStUFsZ-2HpURN4dYDG1x3kahPBkNa-1024.npz
Starting evaluation at step 265500 Counter(265500) 265437
Saved chunk: 20230922T031714F934796-500Rs0NCkODzWaiLF2cUkM-4raiNclG9CXqUFQYzw5ORp-1024.npz
eval_Episode has 500 steps and return 296.9.
train_Episode has 500 steps and return 282.0.
Starting evaluation at step 266000 Counter(266000) 265937
eval_Episode has 500 steps and return 304.5.
train_Episode has 500 steps and return 276.3.
Saved chunk: 20230922T031812F852129-2HpURN4dYDG1x3kahPBkNa-5NeN8TymNjualmmTRwI7hb-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 532762 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 304.5 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 276.27 / episode/reward_rate 0.41 / train/action_mag 4.1 / train/action_max 4.02 / train/action_mean 0.05 / train/action_min -3.56 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 1.58 / train/adv_mag 0.43 / train/adv_max 0.36 / train/adv_mean 5.3e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.82 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.64 / train/extr_critic_max 229.64 / train/extr_critic_mean 219.26 / train/extr_critic_min 165.98 / train/extr_critic_std 12.62 / train/extr_return_normed_mag 1.52 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.32 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.82 / train/extr_return_raw_max 229.82 / train/extr_return_raw_mean 219.28 / 
train/extr_return_raw_min 169.39 / train/extr_return_raw_std 12.64 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 1.01 / train/image_loss_std 0.97 / 
train/model_loss_mean 3.49 / train/model_loss_std 4.52 / train/model_opt_grad_norm 8.92 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.72
/ train/policy_entropy_max 4.65 / train/policy_entropy_mean -2.3 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.37 / train/policy_logprob_mag 10.57 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.3 / train/policy_logprob_min -10.57 / 
train/policy_logprob_std 1.99 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.96 / train/post_ent_max 51.96 / 
train/post_ent_mean 41.79 / train/post_ent_min 22.19 / train/post_ent_std 5.05 / train/prior_ent_mag 79.81 / train/prior_ent_max 79.81 / train/prior_ent_mean 45.59 / train/prior_ent_min 28.24 / train/prior_ent_std 6.33 / train/rep_loss_mean 3.82 / train/rep_loss_std 
6.29 / train/reward_avg 0.38 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.38 / train/reward_rate 0.32 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.63 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.88 / report/dyn_loss_std 5.88 / report/image_loss_mean 0.97 / report/image_loss_std 0.78 / report/model_loss_mean 3.54 / report/model_loss_std 4.14 / 
report/post_ent_mag 51.26 / report/post_ent_max 51.26 / report/post_ent_mean 43.04 / report/post_ent_min 24.33 / report/post_ent_std 4.06 / report/prior_ent_mag 79.7 / report/prior_ent_max 79.7 / report/prior_ent_mean 46.89 / report/prior_ent_min 32.1 / 
report/prior_ent_std 5.29 / report/rep_loss_mean 3.88 / report/rep_loss_std 5.88 / report/reward_avg 0.5 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.35 / report/reward_max_data 1.95 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.2e-4 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.59 / report/reward_pred 0.49 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.11 / eval/dyn_loss_std 7.61 / eval/image_loss_mean 1.37 / eval/image_loss_std 2.07 / eval/model_loss_mean 4.72 / eval/model_loss_std 6.13 / eval/post_ent_mag 
49.99 / eval/post_ent_max 49.99 / eval/post_ent_mean 41.69 / eval/post_ent_min 21.17 / eval/post_ent_std 5.07 / eval/prior_ent_mag 79.7 / eval/prior_ent_max 79.7 / eval/prior_ent_mean 46.17 / eval/prior_ent_min 28.98 / eval/prior_ent_std 5.51 / eval/rep_loss_mean 5.11 /
eval/rep_loss_std 7.61 / eval/reward_avg 0.54 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / 
eval/reward_pred 0.54 / eval/reward_rate 0.43 / replay/size 2.7e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3804 / timer/env.step_total 19.79
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.7 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
2.3e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7311 / timer/agent.policy_total 
16.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.82 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac
1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 266500 Counter(266500) 266437
Saved chunk: 20230922T031834F110269-4raiNclG9CXqUFQYzw5ORp-0vIJghB8uGuSWfbGHkGN5Z-1024.npz
eval_Episode has 500 steps and return 311.2.
train_Episode has 500 steps and return 263.0.
Starting evaluation at step 267000 Counter(267000) 266937
eval_Episode has 500 steps and return 320.6.
train_Episode has 500 steps and return 276.6.
Saved chunk: 20230922T031933F527628-5NeN8TymNjualmmTRwI7hb-0Vk3S0EtrJlWThAMJinDom-1024.npz
Starting evaluation at step 267500 Counter(267500) 267437
Saved chunk: 20230922T031954F050266-0vIJghB8uGuSWfbGHkGN5Z-7GnVLx3ieXEaf38pNklg7K-1024.npz
eval_Episode has 500 steps and return 324.2.
train_Episode has 500 steps and return 271.8.
Starting evaluation at step 268000 Counter(268000) 267937
eval_Episode has 500 steps and return 305.7.
train_Episode has 500 steps and return 280.2.
Saved chunk: 20230922T032055F418838-0Vk3S0EtrJlWThAMJinDom-6sy9sppt4DIG9B7NXC53sf-1024.npz
Starting evaluation at step 268500 Counter(268500) 268437
Saved chunk: 20230922T032113F520483-7GnVLx3ieXEaf38pNklg7K-5yV0g84CyaXSkPtcsaWHvz-1024.npz
eval_Episode has 500 steps and return 293.5.
train_Episode has 500 steps and return 290.6.
Starting evaluation at step 269000 Counter(269000) 268937
eval_Episode has 500 steps and return 305.6.
train_Episode has 500 steps and return 286.6.
Saved chunk: 20230922T032216F337904-6sy9sppt4DIG9B7NXC53sf-5Qgv4tRnlI8aD2JI2KgHXk-1024.npz
Starting evaluation at step 269500 Counter(269500) 269437
Saved chunk: 20230922T032232F841726-5yV0g84CyaXSkPtcsaWHvz-2l9jIqkaqP18747qQi6Ii0-1024.npz
eval_Episode has 500 steps and return 314.2.
train_Episode has 500 steps and return 261.4.
Starting evaluation at step 270000 Counter(270000) 269937
eval_Episode has 500 steps and return 309.0.
train_Episode has 500 steps and return 309.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 540282 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 309.01 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 309.88 / episode/reward_rate 0.47 / train/action_mag 4.04 / train/action_max 3.98 / train/action_mean 0.06 / train/action_min -3.38 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 2.04 / train/adv_mag 0.44 / train/adv_max 0.37 / train/adv_mean 5.2e-4
/ train/adv_min -0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.1e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.93 / train/extr_critic_max 229.93 / train/extr_critic_mean 220.29 / train/extr_critic_min 178.43 / train/extr_critic_std 10.22 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.15 / train/extr_return_raw_max 230.15 / train/extr_return_raw_mean 220.31 / 
train/extr_return_raw_min 181.96 / train/extr_return_raw_std 10.26 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1 / train/image_loss_std 0.96 / 
train/model_loss_mean 3.51 / train/model_loss_std 4.51 / train/model_opt_grad_norm 8.51 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.42
/ train/policy_entropy_max 4.35 / train/policy_entropy_mean -2.42 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 9.94 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.42 / train/policy_logprob_min -9.94 / 
train/policy_logprob_std 1.86 / train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.82 / train/post_ent_max 51.82 / 
train/post_ent_mean 41.97 / train/post_ent_min 21.85 / train/post_ent_std 4.9 / train/prior_ent_mag 79.76 / train/prior_ent_max 79.76 / train/prior_ent_mean 45.79 / train/prior_ent_min 28.47 / train/prior_ent_std 6.14 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.29
/ train/reward_avg 0.39 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 
0.39 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.65 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.01 / report/dyn_loss_std 6.33 / report/image_loss_mean 0.98 / report/image_loss_std 0.96 / report/model_loss_mean 3.62 / report/model_loss_std 4.54 / report/post_ent_mag 
50.62 / report/post_ent_max 50.62 / report/post_ent_mean 42.28 / report/post_ent_min 23.35 / report/post_ent_std 4.2 / report/prior_ent_mag 79.8 / report/prior_ent_max 79.8 / report/prior_ent_mean 46.34 / report/prior_ent_min 28.96 / report/prior_ent_std 5.53 / 
report/rep_loss_mean 4.01 / report/rep_loss_std 6.33 / report/reward_avg 0.44 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.44 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.27 / eval/dyn_loss_std 6.1 / eval/image_loss_mean 1.07 / eval/image_loss_std 1.32 / eval/model_loss_mean 3.92 / eval/model_loss_std 4.67 / eval/post_ent_mag 50.66 / eval/post_ent_max
50.66 / eval/post_ent_mean 42.42 / eval/post_ent_min 25.73 / eval/post_ent_std 3.82 / eval/prior_ent_mag 79.8 / eval/prior_ent_max 79.8 / eval/prior_ent_mean 46.52 / eval/prior_ent_min 35.09 / eval/prior_ent_std 4.81 / eval/rep_loss_mean 4.27 / eval/rep_loss_std 6.1 / 
eval/reward_avg 0.59 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.59 / 
eval/reward_rate 0.46 / replay/size 2.7e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3760 / timer/env.step_total 19.38 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.43 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1880 / 
timer/agent.train_total 241.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T032337F027546-5Qgv4tRnlI8aD2JI2KgHXk-0UWH50Kt3HX48HET6xsk3K-1024.npz
Starting evaluation at step 270500 Counter(270500) 270437
Saved chunk: 20230922T032351F939276-2l9jIqkaqP18747qQi6Ii0-7qSAPMMv2eW1uAbzbLHJ1w-1024.npz
eval_Episode has 500 steps and return 314.2.
train_Episode has 500 steps and return 296.1.
Starting evaluation at step 271000 Counter(271000) 270937
eval_Episode has 500 steps and return 320.9.
train_Episode has 500 steps and return 298.8.
Saved chunk: 20230922T032458F659273-0UWH50Kt3HX48HET6xsk3K-7eEY1e5cw8hVu91ReczyNL-1024.npz
Starting evaluation at step 271500 Counter(271500) 271437
Saved chunk: 20230922T032512F083161-7qSAPMMv2eW1uAbzbLHJ1w-7cBi8Nf4JFvvAOlQwtnwNZ-1024.npz
eval_Episode has 500 steps and return 310.0.
train_Episode has 500 steps and return 276.5.
Starting evaluation at step 272000 Counter(272000) 271937
eval_Episode has 500 steps and return 332.4.
train_Episode has 500 steps and return 285.8.
Saved chunk: 20230922T032619F664135-7eEY1e5cw8hVu91ReczyNL-7yNUe6J7uzrQKYdfgNLLnk-1024.npz
Starting evaluation at step 272500 Counter(272500) 272437
Saved chunk: 20230922T032631F461287-7cBi8Nf4JFvvAOlQwtnwNZ-49vVxbinGI2KQcyFxqYO1C-1024.npz
eval_Episode has 500 steps and return 316.3.
train_Episode has 500 steps and return 265.4.
Starting evaluation at step 273000 Counter(273000) 272937
eval_Episode has 500 steps and return 301.3.
train_Episode has 500 steps and return 305.6.
Saved chunk: 20230922T032740F445757-7yNUe6J7uzrQKYdfgNLLnk-6QT3WqINF3s0Bo429562FR-1024.npz
Starting evaluation at step 273500 Counter(273500) 273437
Saved chunk: 20230922T032750F612389-49vVxbinGI2KQcyFxqYO1C-3Yn9VHrDc80jlZT9kkxoxr-1024.npz
eval_Episode has 500 steps and return 317.8.
train_Episode has 500 steps and return 252.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 547910 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 317.75 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 252.49 / episode/reward_rate 0.39 / train/action_mag 4.14 / train/action_max 4.06 / train/action_mean 0.06 / train/action_min -3.45 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 3.11 / train/adv_mag 0.42 / train/adv_max 0.34 / train/adv_mean 4.1e-4
/ train/adv_min -0.34 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.33 / train/extr_critic_max 230.33 / train/extr_critic_mean 220.19 / train/extr_critic_min 170.65 / train/extr_critic_std 12.09 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.32 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.5 / train/extr_return_raw_max 230.5 / train/extr_return_raw_mean 220.21 / train/extr_return_raw_min 
172.48 / train/extr_return_raw_std 12.14 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.99 / train/image_loss_std 0.94 / train/model_loss_mean 3.47 /
train/model_loss_std 4.45 / train/model_opt_grad_norm 8.45 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.71 / train/policy_entropy_max 
4.62 / train/policy_entropy_mean -2.41 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.32 / train/policy_logprob_mag 10.55 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.41 / train/policy_logprob_min -10.55 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.39 / train/post_ent_max 52.39 / train/post_ent_mean 41.96 / 
train/post_ent_min 21.8 / train/post_ent_std 4.86 / train/prior_ent_mag 79.7 / train/prior_ent_max 79.7 / train/prior_ent_mean 45.74 / train/prior_ent_min 28.55 / train/prior_ent_std 6.13 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.23 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.39 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.71 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.86 / report/dyn_loss_std 6.25 / report/image_loss_mean 0.91 / report/image_loss_std 0.89 / report/model_loss_mean 3.43 / report/model_loss_std 4.44 / report/post_ent_mag 52.6 / report/post_ent_max 52.6 / 
report/post_ent_mean 42.52 / report/post_ent_min 22.7 / report/post_ent_std 4.07 / report/prior_ent_mag 79.54 / report/prior_ent_max 79.54 / report/prior_ent_mean 46.38 / report/prior_ent_min 36.28 / report/prior_ent_std 5.38 / report/rep_loss_mean 3.86 / 
report/rep_loss_std 6.25 / report/reward_avg 0.41 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.29 / report/reward_max_data 1.95 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 3.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.41 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.96 / eval/dyn_loss_std 6.82 / eval/image_loss_mean 1.32 / eval/image_loss_std 1.8 / eval/model_loss_mean 4.57 / eval/model_loss_std 5.39 / eval/post_ent_mag 50.5 / eval/post_ent_max 50.5 / eval/post_ent_mean 
41.82 / eval/post_ent_min 22.11 / eval/post_ent_std 4.78 / eval/prior_ent_mag 79.54 / eval/prior_ent_max 79.54 / eval/prior_ent_mean 46.21 / eval/prior_ent_min 28.92 / eval/prior_ent_std 5.53 / eval/rep_loss_mean 4.96 / eval/rep_loss_std 6.82 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.57 / eval/reward_rate 0.44 / 
replay/size 2.7e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3814 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 460.25 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.35 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1907 / timer/agent.train_total 245.14 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 274000 Counter(274000) 273937
eval_Episode has 500 steps and return 280.8.
train_Episode has 500 steps and return 293.3.
Saved chunk: 20230922T032901F018296-6QT3WqINF3s0Bo429562FR-6IrozW9hjFXwy6Ms5L7LXE-1024.npz
Starting evaluation at step 274500 Counter(274500) 274437
Saved chunk: 20230922T032909F607627-3Yn9VHrDc80jlZT9kkxoxr-6kz11tkib3W5SHrMbCi2Tt-1024.npz
eval_Episode has 500 steps and return 323.7.
train_Episode has 500 steps and return 260.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T033022F789608-6IrozW9hjFXwy6Ms5L7LXE-0000000000000000000000-168.npz
Saved chunk: 20230922T033029F874838-6kz11tkib3W5SHrMbCi2Tt-0000000000000000000000-192.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 275000 Counter(275000) 274937
eval_Episode has 500 steps and return 312.1.
train_Episode has 500 steps and return 304.2.
Saved chunk: 20230922T033022F789608-6IrozW9hjFXwy6Ms5L7LXE-21bUcO2YVu2yozUlrCKaSy-1024.npz
Starting evaluation at step 275500 Counter(275500) 275437
Saved chunk: 20230922T033029F874838-6kz11tkib3W5SHrMbCi2Tt-26QESJIjoe196s7JaCk2uM-1024.npz
eval_Episode has 500 steps and return 319.1.
train_Episode has 500 steps and return 299.8.
Starting evaluation at step 276000 Counter(276000) 275937
eval_Episode has 500 steps and return 312.6.
train_Episode has 500 steps and return 298.8.
Saved chunk: 20230922T033144F106251-21bUcO2YVu2yozUlrCKaSy-3Oi3riZlEOD116E4eosjXb-1024.npz
Starting evaluation at step 276500 Counter(276500) 276437
Saved chunk: 20230922T033149F588955-26QESJIjoe196s7JaCk2uM-1i1bavZan99F1HEqAxJrcX-1024.npz
eval_Episode has 500 steps and return 305.9.
train_Episode has 500 steps and return 278.4.
Starting evaluation at step 277000 Counter(277000) 276937
eval_Episode has 500 steps and return 322.3.
train_Episode has 500 steps and return 300.8.
Starting evaluation at step 277500 Counter(277500) 277437
Saved chunk: 20230922T033308F725687-1i1bavZan99F1HEqAxJrcX-5Ek4fq2k3dGDJG21OesrV8-1024.npz
eval_Episode has 500 steps and return 316.7.
Saved chunk: 20230922T033304F841262-3Oi3riZlEOD116E4eosjXb-2yjPYzjZFdtKNXY5tlXC8x-1024.npz
train_Episode has 500 steps and return 295.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 555420 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 316.66 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 295.41 / episode/reward_rate 0.46 / train/action_mag 4.08 / train/action_max 4.04 / train/action_mean 0.06 / train/action_min -3.36 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 1.21 / train/adv_mag 0.44 / train/adv_max 0.35 / train/adv_mean 6.1e-4
/ train/adv_min -0.36 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.59 / train/extr_critic_max 230.59 / train/extr_critic_mean 221.07 / train/extr_critic_min 177.1 / train/extr_critic_std 9.98 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 230.78 / train/extr_return_raw_max 230.78 / train/extr_return_raw_mean 221.09 / train/extr_return_raw_min 
178.62 / train/extr_return_raw_std 10.01 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1 / train/image_loss_std 0.96 / train/model_loss_mean 3.48 / 
train/model_loss_std 4.49 / train/model_opt_grad_norm 8.56 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.39 / train/policy_entropy_max 
4.25 / train/policy_entropy_mean -2.43 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.21 / train/policy_logprob_mag 10.06 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.43 / train/policy_logprob_min -10.06 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.09 / train/post_ent_max 52.09 / train/post_ent_mean 41.97 / 
train/post_ent_min 21.93 / train/post_ent_std 4.9 / train/prior_ent_mag 79.71 / train/prior_ent_max 79.71 / train/prior_ent_mean 45.74 / train/prior_ent_min 28.22 / train/prior_ent_std 6.17 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.26 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.39 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.65 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.88 / report/dyn_loss_std 6.52 / report/image_loss_mean 1.02 / report/image_loss_std 0.91 / report/model_loss_mean 3.51 / report/model_loss_std 4.59 / report/post_ent_mag 51.93 / report/post_ent_max 51.93 /
report/post_ent_mean 40.69 / report/post_ent_min 19.44 / report/post_ent_std 7.24 / report/prior_ent_mag 79.67 / report/prior_ent_max 79.67 / report/prior_ent_mean 44.47 / report/prior_ent_min 21.36 / report/prior_ent_std 8.39 / report/rep_loss_mean 3.88 / 
report/rep_loss_std 6.52 / report/reward_avg 0.33 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 2 / report/reward_max_pred 1.95 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.33 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.78 / eval/dyn_loss_std 5.61 / eval/image_loss_mean 0.8 / eval/image_loss_std 0.67 / eval/model_loss_mean 3.37 / eval/model_loss_std 3.97 / eval/post_ent_mag 51.36 / eval/post_ent_max 51.36 / eval/post_ent_mean 42.96 / 
eval/post_ent_min 24.51 / eval/post_ent_std 3.31 / eval/prior_ent_mag 79.67 / eval/prior_ent_max 79.67 / eval/prior_ent_mean 46.74 / eval/prior_ent_min 35.02 / eval/prior_ent_std 4.81 / eval/rep_loss_mean 3.78 / eval/rep_loss_std 5.61 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.63 / eval/reward_rate 0.48 / 
replay/size 2.8e5 / replay/inserts 3755 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3755 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.9 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7763 / timer/agent.policy_total 17.6 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.45 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 278000 Counter(278000) 277937
eval_Episode has 500 steps and return 324.2.
train_Episode has 500 steps and return 279.8.
Starting evaluation at step 278500 Counter(278500) 278437
Saved chunk: 20230922T033427F811326-5Ek4fq2k3dGDJG21OesrV8-5OxEFjMw3w57QCZLwmei0s-1024.npz
eval_Episode has 500 steps and return 321.0.
Saved chunk: 20230922T033429F023699-2yjPYzjZFdtKNXY5tlXC8x-4cNpzQLGvsomDNaLOfb2Uo-1024.npz
train_Episode has 500 steps and return 280.2.
Starting evaluation at step 279000 Counter(279000) 278937
eval_Episode has 500 steps and return 300.1.
train_Episode has 500 steps and return 293.0.
Starting evaluation at step 279500 Counter(279500) 279437
Saved chunk: 20230922T033548F207995-5OxEFjMw3w57QCZLwmei0s-1RNSZrxwkrNRXUgcw6aNf3-1024.npz
eval_Episode has 500 steps and return 303.8.
train_Episode has 500 steps and return 298.4.
Saved chunk: 20230922T033550F988094-4cNpzQLGvsomDNaLOfb2Uo-5jJjf0IAKHwB1VomJwfWEO-1024.npz
Starting evaluation at step 280000 Counter(280000) 279937
eval_Episode has 500 steps and return 306.7.
train_Episode has 500 steps and return 283.6.
Starting evaluation at step 280500 Counter(280500) 280437
eval_Episode has 500 steps and return 306.4.
Saved chunk: 20230922T033708F938932-1RNSZrxwkrNRXUgcw6aNf3-1O2UFr1HqfkGdpvqCMdnvf-1024.npz
train_Episode has 500 steps and return 295.2.
Saved chunk: 20230922T033713F282373-5jJjf0IAKHwB1VomJwfWEO-0zPusl7clmzQqYu4aFCsC0-1024.npz
Starting evaluation at step 281000 Counter(281000) 280937
eval_Episode has 500 steps and return 320.7.
train_Episode has 500 steps and return 296.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 562998 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 320.66 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 296.28 / episode/reward_rate 0.44 / train/action_mag 4.05 / train/action_max 4.01 / train/action_mean 0.07 / train/action_min -3.24 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 1.15 / train/adv_mag 0.35 / train/adv_max 0.29 / train/adv_mean 6.3e-4
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.92 / train/extr_critic_max 230.92 / train/extr_critic_mean 221.57 / train/extr_critic_min 177.51 / train/extr_critic_std 10.11 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 231.14 / train/extr_return_raw_max 231.14 / train/extr_return_raw_mean 221.59 / train/extr_return_raw_min 
180.33 / train/extr_return_raw_std 10.14 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.99 / train/image_loss_std 0.95 / train/model_loss_mean 3.46 
/ train/model_loss_std 4.49 / train/model_opt_grad_norm 8.69 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.31 / train/policy_entropy_max
4.17 / train/policy_entropy_mean -2.47 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.15 / train/policy_logprob_mag 9.76 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.47 / train/policy_logprob_min -9.76 / train/policy_logprob_std 1.84 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2.2e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.32 / train/post_ent_max 52.32 / train/post_ent_mean 41.97 / 
train/post_ent_min 21.92 / train/post_ent_std 4.9 / train/prior_ent_mag 79.64 / train/prior_ent_max 79.64 / train/prior_ent_mean 45.72 / train/prior_ent_min 28.32 / train/prior_ent_std 6.17 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.26 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.39 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.66 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.15 / report/image_loss_mean 0.9 / report/image_loss_std 0.75 / report/model_loss_mean 3.36 / report/model_loss_std 4.32 / report/post_ent_mag 51.37 / report/post_ent_max 51.37 / 
report/post_ent_mean 42.39 / report/post_ent_min 25.06 / report/post_ent_std 4.27 / report/prior_ent_mag 79.82 / report/prior_ent_max 79.82 / report/prior_ent_mean 46.18 / report/prior_ent_min 31.05 / report/prior_ent_std 5.7 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.15 / report/reward_avg 0.46 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.34 / report/reward_max_data 1.88 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.45 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 6.5e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.67 / eval/dyn_loss_std 7.17 / eval/image_loss_mean 1.08 / eval/image_loss_std 1.43 / eval/model_loss_mean 4.16 / eval/model_loss_std 5.48 / eval/post_ent_mag 50.79 / eval/post_ent_max 50.79 / eval/post_ent_mean 
42.15 / eval/post_ent_min 22.42 / eval/post_ent_std 4.27 / eval/prior_ent_mag 79.82 / eval/prior_ent_max 79.82 / eval/prior_ent_mean 46.52 / eval/prior_ent_min 34.02 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 4.67 / eval/rep_loss_std 7.17 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.6 / eval/reward_rate 0.46 / 
replay/size 2.8e5 / replay/inserts 3789 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3789 / timer/env.step_total 19.71 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.43 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7296 / timer/agent.policy_total 16.31 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1895 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1895 / timer/agent.train_total 245.09 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.49 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.26

Starting evaluation at step 281500 Counter(281500) 281437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 315.7.
Saved chunk: 20230922T033828F042033-1O2UFr1HqfkGdpvqCMdnvf-3xmEzQSTzV2fMKYGikSmTD-1024.npz
train_Episode has 500 steps and return 302.2.
Saved chunk: 20230922T033833F972947-0zPusl7clmzQqYu4aFCsC0-0azgDNqkRhU4l0ZQKAuDGV-1024.npz
Starting evaluation at step 282000 Counter(282000) 281937
eval_Episode has 500 steps and return 334.7.
train_Episode has 500 steps and return 294.6.
Starting evaluation at step 282500 Counter(282500) 282437
eval_Episode has 500 steps and return 327.5.
Saved chunk: 20230922T033948F174457-3xmEzQSTzV2fMKYGikSmTD-5JZKRx6hETKCX4rJyZjRUB-1024.npz
train_Episode has 500 steps and return 301.3.
Saved chunk: 20230922T033955F766268-0azgDNqkRhU4l0ZQKAuDGV-7KbaQuhMxr7J588wzYRvQa-1024.npz
Starting evaluation at step 283000 Counter(283000) 282937
eval_Episode has 500 steps and return 324.6.
train_Episode has 500 steps and return 293.7.
Starting evaluation at step 283500 Counter(283500) 283437
eval_Episode has 500 steps and return 323.4.
train_Episode has 500 steps and return 259.7.
Saved chunk: 20230922T034116F767268-7KbaQuhMxr7J588wzYRvQa-1c6JBr89ZYToCZWb5OXPWc-1024.npz
Starting evaluation at step 284000 Counter(284000) 283937
Saved chunk: 20230922T034107F668431-5JZKRx6hETKCX4rJyZjRUB-5zXyhhrf8jDraBgHRLtgJp-1024.npz
eval_Episode has 500 steps and return 323.8.
train_Episode has 500 steps and return 277.5.
Starting evaluation at step 284500 Counter(284500) 284437
eval_Episode has 500 steps and return 293.3.
train_Episode has 500 steps and return 288.7.
Saved chunk: 20230922T034237F689455-1c6JBr89ZYToCZWb5OXPWc-5pBnFQUOsh3Jap7vOwkVEh-1024.npz
Starting evaluation at step 285000 Counter(285000) 284937
Saved chunk: 20230922T034303F061643-5zXyhhrf8jDraBgHRLtgJp-0ci85J6UMMCCjeQdNHoBoY-1024.npz
eval_Episode has 500 steps and return 307.6.
train_Episode has 500 steps and return 303.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 570510 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 307.64 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 302.99 / episode/reward_rate 0.46 / eval_stats/mean_log_entropy 0 / train/action_mag 4.01 / train/action_max 3.96 / train/action_mean 0.07 / 
train/action_min -3.33 / train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 3.81 / train/adv_mag 0.39 / train/adv_max 
0.31 / train/adv_mean 3.6e-4 / train/adv_min -0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.85 / train/dyn_loss_std 6.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / 
train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.33 / train/extr_critic_max 231.33 / train/extr_critic_mean 222.24 / train/extr_critic_min 179.38 / train/extr_critic_std 9.8 / 
train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 231.52 / train/extr_return_raw_max 
231.52 / train/extr_return_raw_mean 222.26 / train/extr_return_raw_min 180.82 / train/extr_return_raw_std 9.82 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / 
train/image_loss_mean 1.01 / train/image_loss_std 1 / train/model_loss_mean 3.52 / train/model_loss_std 4.54 / train/model_opt_grad_norm 8.57 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.22 / train/policy_entropy_max 3.89 / train/policy_entropy_mean -2.49 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.55 / train/policy_logprob_max 5.49 / 
train/policy_logprob_mean 2.49 / train/policy_logprob_min -9.55 / train/policy_logprob_std 1.8 / train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 
0.12 / train/post_ent_mag 51.76 / train/post_ent_max 51.76 / train/post_ent_mean 42.02 / train/post_ent_min 21.83 / train/post_ent_std 4.85 / train/prior_ent_mag 79.63 / train/prior_ent_max 79.63 / train/prior_ent_mean 45.84 / train/prior_ent_min 28.57 / 
train/prior_ent_std 6.08 / train/rep_loss_mean 3.85 / train/rep_loss_std 6.28 / train/reward_avg 0.41 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.94 / train/reward_neg_acc 1 / train/reward_neg_loss 
5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.41 / train/reward_rate 0.34 / train_stats/mean_log_entropy -2.61 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 6.04 / report/image_loss_mean 0.9 / report/image_loss_std 0.84 / report/model_loss_mean 3.44 / 
report/model_loss_std 4.31 / report/post_ent_mag 51.15 / report/post_ent_max 51.15 / report/post_ent_mean 43.23 / report/post_ent_min 25.29 / report/post_ent_std 3.9 / report/prior_ent_mag 79.59 / report/prior_ent_max 79.59 / report/prior_ent_mean 47.13 / 
report/prior_ent_min 33.83 / report/prior_ent_std 4.89 / report/rep_loss_mean 3.84 / report/rep_loss_std 6.04 / report/reward_avg 0.51 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 1.95 / 
report/reward_neg_acc 0.99 / report/reward_neg_loss 8.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.51 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.72 / eval/dyn_loss_std 7.55 / eval/image_loss_mean 1.26 / eval/image_loss_std 2.05 / eval/model_loss_mean 4.35 / eval/model_loss_std 
6.2 / eval/post_ent_mag 50.74 / eval/post_ent_max 50.74 / eval/post_ent_mean 42.12 / eval/post_ent_min 21.44 / eval/post_ent_std 4.54 / eval/prior_ent_mag 79.59 / eval/prior_ent_max 79.59 / eval/prior_ent_mean 46.23 / eval/prior_ent_min 29.61 / eval/prior_ent_std 5.41 /
eval/rep_loss_mean 4.72 / eval/rep_loss_std 7.55 / eval/reward_avg 0.56 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.58 / eval/reward_pred 0.56 / eval/reward_rate 0.45 / replay/size 2.9e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3756 / 
timer/env.step_total 19.4 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.46 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 
/ timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7764 / timer/agent.policy_total 17.69 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.15 / timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 2.4e-4 / 
timer/agent.train_count 1878 / timer/agent.train_total 241.12 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.16 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / 
timer/dataset_eval_max 3.1e-5 / fps 25.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 285500 Counter(285500) 285437
eval_Episode has 500 steps and return 310.0.
train_Episode has 500 steps and return 289.1.
Saved chunk: 20230922T034358F476288-5pBnFQUOsh3Jap7vOwkVEh-2dh24lc39SIbQmqlb0I53q-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 286000 Counter(286000) 285937
Saved chunk: 20230922T034520F208322-2dh24lc39SIbQmqlb0I53q-0000000000000000000000-304.npz
Saved chunk: 20230922T034422F260047-0ci85J6UMMCCjeQdNHoBoY-0000000000000000000000-974.npz
Saved chunk: 20230922T034422F260047-0ci85J6UMMCCjeQdNHoBoY-0LHXu8EPorscQACPk9etbg-1024.npz
eval_Episode has 500 steps and return 311.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 298.2.
Starting evaluation at step 286500 Counter(286500) 286437
eval_Episode has 500 steps and return 307.5.
train_Episode has 500 steps and return 289.1.
Saved chunk: 20230922T034520F208322-2dh24lc39SIbQmqlb0I53q-1CXDAomIKNKmnJomqEhw4A-1024.npz
Starting evaluation at step 287000 Counter(287000) 286937
Saved chunk: 20230922T034542F649778-0LHXu8EPorscQACPk9etbg-5CBOHStgNkBLThpnSVVboh-1024.npz
eval_Episode has 500 steps and return 327.2.
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 287500 Counter(287500) 287437
eval_Episode has 500 steps and return 317.4.
train_Episode has 500 steps and return 297.3.
Saved chunk: 20230922T034641F650727-1CXDAomIKNKmnJomqEhw4A-4TYreF013YPOnFwnhN1kKn-1024.npz
Starting evaluation at step 288000 Counter(288000) 287937
Saved chunk: 20230922T034702F376739-5CBOHStgNkBLThpnSVVboh-7LPRJxNNiTTegYHqEjcDER-1024.npz
eval_Episode has 500 steps and return 324.0.
train_Episode has 500 steps and return 318.6.
Starting evaluation at step 288500 Counter(288500) 288437
eval_Episode has 500 steps and return 301.7.
train_Episode has 500 steps and return 291.8.
Saved chunk: 20230922T034802F579355-4TYreF013YPOnFwnhN1kKn-1IF1arvtxPpec1csrJqXF1-1024.npz
Starting evaluation at step 289000 Counter(289000) 288937
Saved chunk: 20230922T034821F644190-7LPRJxNNiTTegYHqEjcDER-1FFjnYjAWsQ9Upgfeu0Aly-1024.npz
eval_Episode has 500 steps and return 315.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 578014 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 315.07 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 291.81 / episode/reward_rate 0.45 / train/action_mag 3.92 / train/action_max 3.86 / train/action_mean 0.07 / train/action_min -3.23 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 0.95 / train/adv_mag 0.49 / train/adv_max 0.37 / train/adv_mean 6.6e-4
/ train/adv_min -0.37 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.82 / train/dyn_loss_std 6.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.64 / train/extr_critic_max 231.64 / train/extr_critic_mean 222.23 / train/extr_critic_min 176.84 / train/extr_critic_std 9.86 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 231.84 / train/extr_return_raw_max 231.84 / train/extr_return_raw_mean 222.26 / train/extr_return_raw_min 
178.84 / train/extr_return_raw_std 9.86 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 1 / train/image_loss_std 0.98 / train/model_loss_mean 3.49 / 
train/model_loss_std 4.49 / train/model_opt_grad_norm 8.46 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.28 / train/policy_entropy_max 
4.04 / train/policy_entropy_mean -2.52 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.09 / train/policy_logprob_mag 9.63 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.52 / train/policy_logprob_min -9.63 / train/policy_logprob_std 1.8 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.9e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.08 / train/post_ent_max 52.08 / train/post_ent_mean 41.94 / 
train/post_ent_min 21.9 / train/post_ent_std 4.83 / train/prior_ent_mag 79.55 / train/prior_ent_max 79.55 / train/prior_ent_mean 45.73 / train/prior_ent_min 28.7 / train/prior_ent_std 6.1 / train/rep_loss_mean 3.82 / train/rep_loss_std 6.26 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.31 / train/reward_max_data 1.96 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.39 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.67 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.94 / report/dyn_loss_std 6.38 / report/image_loss_mean 0.94 / report/image_loss_std 0.95 / report/model_loss_mean 3.53 / report/model_loss_std 4.55 / report/post_ent_mag 51.06 / report/post_ent_max 51.06 /
report/post_ent_mean 42.35 / report/post_ent_min 22.96 / report/post_ent_std 4.21 / report/prior_ent_mag 79.33 / report/prior_ent_max 79.33 / report/prior_ent_mean 46.3 / report/prior_ent_min 30.25 / report/prior_ent_std 5.59 / report/rep_loss_mean 3.94 / 
report/rep_loss_std 6.38 / report/reward_avg 0.48 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.32 / report/reward_max_data 1.95 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.47 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.53 / eval/dyn_loss_std 6.81 / eval/image_loss_mean 1.31 / eval/image_loss_std 2.18 / eval/model_loss_mean 4.29 / eval/model_loss_std 5.77 / eval/post_ent_mag 50.58 / eval/post_ent_max 50.58 / eval/post_ent_mean 
40.6 / eval/post_ent_min 18.95 / eval/post_ent_std 7 / eval/prior_ent_mag 79.33 / eval/prior_ent_max 79.33 / eval/prior_ent_mean 44.84 / eval/prior_ent_min 22.35 / eval/prior_ent_std 7.54 / eval/rep_loss_mean 4.53 / eval/rep_loss_std 6.81 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.54 / eval/reward_rate 0.42 / 
replay/size 2.9e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3752 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.53 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.2e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.5 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241.49 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 297.6.
Starting evaluation at step 289500 Counter(289500) 289437
eval_Episode has 500 steps and return 289.9.
train_Episode has 500 steps and return 306.6.
Saved chunk: 20230922T034923F250350-1IF1arvtxPpec1csrJqXF1-1BzUy27O22BiwBxMKojEiS-1024.npz
Starting evaluation at step 290000 Counter(290000) 289937
Saved chunk: 20230922T034940F742369-1FFjnYjAWsQ9Upgfeu0Aly-3LFBMHuBqswmNVIb9O7HvA-1024.npz
eval_Episode has 500 steps and return 330.2.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 290500 Counter(290500) 290437
eval_Episode has 500 steps and return 311.6.
train_Episode has 500 steps and return 300.1.
Saved chunk: 20230922T035045F139146-1BzUy27O22BiwBxMKojEiS-3fmmhL92M7J5NlcVhL5NwB-1024.npz
Starting evaluation at step 291000 Counter(291000) 290937
Saved chunk: 20230922T035101F115684-3LFBMHuBqswmNVIb9O7HvA-07JpZUJranIQmXGSmPDWAP-1024.npz
eval_Episode has 500 steps and return 321.5.
train_Episode has 500 steps and return 288.0.
Starting evaluation at step 291500 Counter(291500) 291437
eval_Episode has 500 steps and return 298.9.
train_Episode has 500 steps and return 303.7.
Saved chunk: 20230922T035206F076687-3fmmhL92M7J5NlcVhL5NwB-10aOVkgEBIcKuAiCkLBqu7-1024.npz
Starting evaluation at step 292000 Counter(292000) 291937
Saved chunk: 20230922T035220F449885-07JpZUJranIQmXGSmPDWAP-6kvCeFIbDS5CfqJyIjSis2-1024.npz
eval_Episode has 500 steps and return 326.7.
train_Episode has 500 steps and return 302.1.
Starting evaluation at step 292500 Counter(292500) 292437
eval_Episode has 500 steps and return 311.0.
train_Episode has 500 steps and return 309.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 585630 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 309.37 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 311.02 / eval_episode/reward_rate 0.45 / train/action_mag 3.96 / train/action_max 3.93 / train/action_mean 0.07 / train/action_min -3.25 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 4.31 / train/adv_mag 0.45 / train/adv_max 0.36 / train/adv_mean 3.2e-4
/ train/adv_min -0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.91 / train/extr_critic_max 231.91 / train/extr_critic_mean 222.89 / train/extr_critic_min 181.11 / train/extr_critic_std 9.19 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 232.1 / train/extr_return_raw_max 232.1 / train/extr_return_raw_mean 222.9 / train/extr_return_raw_min 
184.77 / train/extr_return_raw_std 9.23 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.98 / train/image_loss_std 0.96 / train/model_loss_mean 3.47 /
train/model_loss_std 4.46 / train/model_opt_grad_norm 8.16 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.19 / train/policy_entropy_max 
3.92 / train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.04 / train/policy_logprob_mag 9.58 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -9.58 / train/policy_logprob_std 1.77 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.9e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.01 / train/post_ent_max 52.01 / train/post_ent_mean 42.08 / 
train/post_ent_min 22.43 / train/post_ent_std 4.73 / train/prior_ent_mag 79.49 / train/prior_ent_max 79.49 / train/prior_ent_mean 45.85 / train/prior_ent_min 29.07 / train/prior_ent_std 5.98 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.21 / train/reward_avg 0.4 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.4 / train/reward_rate 
0.34 / train_stats/mean_log_entropy -2.67 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.41 / report/image_loss_mean 1.03 / report/image_loss_std 1 / report/model_loss_mean 3.5 / report/model_loss_std 4.57 / report/post_ent_mag 52.62 / report/post_ent_max 52.62 / 
report/post_ent_mean 41.54 / report/post_ent_min 21.61 / report/post_ent_std 4.92 / report/prior_ent_mag 79.53 / report/prior_ent_max 79.53 / report/prior_ent_mean 45.28 / report/prior_ent_min 28.94 / report/prior_ent_std 6.43 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 6.41 / report/reward_avg 0.32 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.32 / report/reward_max_data 1.96 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.32 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 8.5e-11 / eval/cont_loss_std 3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.5e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.93 / eval/dyn_loss_std 5.68 / eval/image_loss_mean 0.87 / eval/image_loss_std 0.95 / eval/model_loss_mean 3.54 / eval/model_loss_std 4.09 / eval/post_ent_mag 50.77 / eval/post_ent_max 50.77 / eval/post_ent_mean 42.6 / 
eval/post_ent_min 27.4 / eval/post_ent_std 3.46 / eval/prior_ent_mag 79.53 / eval/prior_ent_max 79.53 / eval/prior_ent_mean 46.49 / eval/prior_ent_min 32.86 / eval/prior_ent_std 5.02 / eval/rep_loss_mean 3.93 / eval/rep_loss_std 5.68 / eval/reward_avg 0.67 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.66 / eval/reward_rate 0.51 / 
replay/size 2.9e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3808 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.77 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.38 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1904 / timer/agent.train_total 245.06 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T035326F833129-10aOVkgEBIcKuAiCkLBqu7-7HTv0dCWiR2UM2rxrBNBEi-1024.npz
Starting evaluation at step 293000 Counter(293000) 292937
Saved chunk: 20230922T035339F628684-6kvCeFIbDS5CfqJyIjSis2-48oKdyJbLyImwosdLCQfDD-1024.npz
eval_Episode has 500 steps and return 295.2.
train_Episode has 500 steps and return 301.8.
Starting evaluation at step 293500 Counter(293500) 293437
eval_Episode has 500 steps and return 307.7.
train_Episode has 500 steps and return 291.1.
Saved chunk: 20230922T035448F483309-7HTv0dCWiR2UM2rxrBNBEi-1ob9mhqjCrRbTGHvwPZ1hY-1024.npz
Starting evaluation at step 294000 Counter(294000) 293937
Saved chunk: 20230922T035459F743910-48oKdyJbLyImwosdLCQfDD-7Bov7pF9RwZMvYFPwDRQmf-1024.npz
eval_Episode has 500 steps and return 320.3.
train_Episode has 500 steps and return 310.0.
Starting evaluation at step 294500 Counter(294500) 294437
eval_Episode has 500 steps and return 306.2.
train_Episode has 500 steps and return 286.9.
Saved chunk: 20230922T035609F563460-1ob9mhqjCrRbTGHvwPZ1hY-6VpnUIu1Ng1l8mBMEjZBoD-1024.npz
Starting evaluation at step 295000 Counter(295000) 294937
Saved chunk: 20230922T035619F243195-7Bov7pF9RwZMvYFPwDRQmf-7n3BVAYP6LQedn0V9SZ58j-1024.npz
eval_Episode has 500 steps and return 326.5.
train_Episode has 500 steps and return 275.0.
Starting evaluation at step 295500 Counter(295500) 295437
eval_Episode has 500 steps and return 304.2.
train_Episode has 500 steps and return 277.1.
Saved chunk: 20230922T035730F493263-6VpnUIu1Ng1l8mBMEjZBoD-0M6BqdqE2Z8jIJu4gWnvou-1024.npz
Starting evaluation at step 296000 Counter(296000) 295937
Saved chunk: 20230922T035738F585816-7n3BVAYP6LQedn0V9SZ58j-3TSIHF87E73JQdnCMLOP1a-1024.npz
eval_Episode has 500 steps and return 307.3.
train_Episode has 500 steps and return 289.6.
Starting evaluation at step 296500 Counter(296500) 296437
eval_Episode has 500 steps and return 303.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 593146 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 303.59 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 289.59 / episode/reward_rate 0.43 / train/action_mag 4.01 / train/action_max 3.89 / train/action_mean 0.07 / train/action_min -3.46 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 3.93 / train/adv_mag 0.38 / train/adv_max 0.3 / train/adv_mean 3.5e-4 
/ train/adv_min -0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 232.07 / train/extr_critic_max 232.07 / train/extr_critic_mean 222.68 / train/extr_critic_min 178.08 / train/extr_critic_std 10.41 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 232.27 / train/extr_return_raw_max 232.27 / train/extr_return_raw_mean 222.69 / 
train/extr_return_raw_min 179.07 / train/extr_return_raw_std 10.45 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.97 / train/image_loss_std 0.93 / 
train/model_loss_mean 3.45 / train/model_loss_std 4.42 / train/model_opt_grad_norm 8.22 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.26
/ train/policy_entropy_max 4.12 / train/policy_entropy_mean -2.49 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.09 / train/policy_logprob_mag 9.57 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.49 / train/policy_logprob_min -9.57 / 
train/policy_logprob_std 1.81 / train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.02 / train/post_ent_max 52.02 / 
train/post_ent_mean 42.07 / train/post_ent_min 22.22 / train/post_ent_std 4.71 / train/prior_ent_mag 79.48 / train/prior_ent_max 79.48 / train/prior_ent_mean 45.83 / train/prior_ent_min 29.13 / train/prior_ent_std 5.98 / train/rep_loss_mean 3.79 / train/rep_loss_std 
6.18 / train/reward_avg 0.41 / train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / 
train/reward_pred 0.41 / train/reward_rate 0.34 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.66 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.89 / report/dyn_loss_std 6.72 / report/image_loss_mean 1.01 / report/image_loss_std 0.86 / report/model_loss_mean 3.54 / report/model_loss_std 4.65 / 
report/post_ent_mag 52.17 / report/post_ent_max 52.17 / report/post_ent_mean 42.75 / report/post_ent_min 22.21 / report/post_ent_std 4.56 / report/prior_ent_mag 79.32 / report/prior_ent_max 79.32 / report/prior_ent_mean 46.6 / report/prior_ent_min 28.87 / 
report/prior_ent_std 5.69 / report/rep_loss_mean 3.89 / report/rep_loss_std 6.72 / report/reward_avg 0.4 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / 
report/reward_neg_loss 5.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.4 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.37 / eval/dyn_loss_std 6.06 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.32 / eval/model_loss_mean 3.95 / eval/model_loss_std 4.56 / eval/post_ent_mag 
50.44 / eval/post_ent_max 50.44 / eval/post_ent_mean 42.39 / eval/post_ent_min 20.92 / eval/post_ent_std 4.03 / eval/prior_ent_mag 79.32 / eval/prior_ent_max 79.32 / eval/prior_ent_mean 46.35 / eval/prior_ent_min 31.53 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 4.37
/ eval/rep_loss_std 6.06 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.62 / eval/reward_rate 0.48 / replay/size 3e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3758 / timer/env.step_total 19.38
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 464.38 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7766 / timer/agent.policy_total 17.33 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 
/ timer/agent.train_count 1879 / timer/agent.train_total 241.71 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / 
timer/dataset_eval_max 3.4e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 305.2.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T035851F224293-0M6BqdqE2Z8jIJu4gWnvou-2QxHTX5Q6p007ye1XuqGgS-1024.npz
Starting evaluation at step 297000 Counter(297000) 296937
Saved chunk: 20230922T035857F719312-3TSIHF87E73JQdnCMLOP1a-4GUMVFK66fB1MZn9FPPogY-1024.npz
eval_Episode has 500 steps and return 335.5.
train_Episode has 500 steps and return 307.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T040013F090056-2QxHTX5Q6p007ye1XuqGgS-0000000000000000000000-440.npz
Saved chunk: 20230922T040018F061991-4GUMVFK66fB1MZn9FPPogY-0000000000000000000000-209.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 297500 Counter(297500) 297437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 312.9.
Saved chunk: 20230922T040013F090056-2QxHTX5Q6p007ye1XuqGgS-25avpbAxcAPWIL4fyPC4tm-1024.npz
Starting evaluation at step 298000 Counter(298000) 297937
Saved chunk: 20230922T040018F061991-4GUMVFK66fB1MZn9FPPogY-3MqhEqTRxzxQDj8Er6Ht65-1024.npz
eval_Episode has 500 steps and return 280.2.
train_Episode has 500 steps and return 292.6.
Starting evaluation at step 298500 Counter(298500) 298437
eval_Episode has 500 steps and return 325.0.
train_Episode has 500 steps and return 295.3.
Starting evaluation at step 299000 Counter(299000) 298937
Saved chunk: 20230922T040137F828048-3MqhEqTRxzxQDj8Er6Ht65-2ES5NXfyedfbcrMtdjiSxp-1024.npz
eval_Episode has 500 steps and return 312.1.
Saved chunk: 20230922T040134F458761-25avpbAxcAPWIL4fyPC4tm-64uDqzbjSMjry4tbwG5vU7-1024.npz
train_Episode has 500 steps and return 273.9.
Starting evaluation at step 299500 Counter(299500) 299437
eval_Episode has 500 steps and return 319.1.
train_Episode has 500 steps and return 308.5.
Starting evaluation at step 300000 Counter(300000) 299937
Saved chunk: 20230922T040257F038121-2ES5NXfyedfbcrMtdjiSxp-4X8ghdNG3qurXfEkjnItFX-1024.npz
eval_Episode has 500 steps and return 308.9.
Saved chunk: 20230922T040258F815160-64uDqzbjSMjry4tbwG5vU7-0eZdCyMzJaQEUZjVphc6Lo-1024.npz
train_Episode has 500 steps and return 281.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 600754 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 281.54 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 308.88 / eval_episode/reward_rate 0.47 / train/action_mag 4.05 / train/action_max 3.94 / train/action_mean 0.07 / train/action_min -3.48 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 2.41 / train/adv_mag 0.47 / train/adv_max 0.4 / train/adv_mean 4.9e-4 
/ train/adv_min -0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 232.18 / train/extr_critic_max 232.18 / train/extr_critic_mean 222.29 / train/extr_critic_min 168.75 / train/extr_critic_std 11.9 / train/extr_return_normed_mag 1.63 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.67 / train/extr_return_normed_std 0.33 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 232.39 / train/extr_return_raw_max 232.39 / train/extr_return_raw_mean 222.3 / train/extr_return_raw_min
171.46 / train/extr_return_raw_std 11.92 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.98 / train/image_loss_std 0.95 / train/model_loss_mean 3.45 
/ train/model_loss_std 4.45 / train/model_opt_grad_norm 8.6 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.34 / train/policy_entropy_max 
4.2 / train/policy_entropy_mean -2.45 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.14 / train/policy_logprob_mag 9.8 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.44 / train/policy_logprob_min -9.8 / train/policy_logprob_std 1.84 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.98 / train/post_ent_max 51.98 / train/post_ent_mean 41.93 / 
train/post_ent_min 21.99 / train/post_ent_std 4.85 / train/prior_ent_mag 79.41 / train/prior_ent_max 79.41 / train/prior_ent_mean 45.69 / train/prior_ent_min 28.37 / train/prior_ent_std 6.12 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.22 / train/reward_avg 0.4 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.4 / train/reward_rate 
0.33 / train_stats/mean_log_entropy -2.63 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 6.17 / report/image_loss_mean 0.96 / report/image_loss_std 0.76 / report/model_loss_mean 3.4 / report/model_loss_std 4.32 / report/post_ent_mag 52.43 / report/post_ent_max 52.43 / 
report/post_ent_mean 41.87 / report/post_ent_min 22.84 / report/post_ent_std 4.4 / report/prior_ent_mag 79.42 / report/prior_ent_max 79.42 / report/prior_ent_mean 45.53 / report/prior_ent_min 29.01 / report/prior_ent_std 6.17 / report/rep_loss_mean 3.74 / 
report/rep_loss_std 6.17 / report/reward_avg 0.4 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.31 / report/reward_max_data 1.93 / report/reward_max_pred 1.93 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.39 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 7.6e-11 / eval/cont_loss_std 3.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.25 / eval/dyn_loss_std 6.19 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.49 / eval/model_loss_mean 3.94 / eval/model_loss_std 4.82 / eval/post_ent_mag 50.35 / eval/post_ent_max 50.35 / eval/post_ent_mean 
42.25 / eval/post_ent_min 23.49 / eval/post_ent_std 4.01 / eval/prior_ent_mag 79.42 / eval/prior_ent_max 79.42 / eval/prior_ent_mean 46.46 / eval/prior_ent_min 32.05 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 4.25 / eval/rep_loss_std 6.19 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.6 / eval/reward_rate 0.47 / 
replay/size 3e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3804 / timer/env.step_total 19.9 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.85 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.54 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 6e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.61 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 300500 Counter(300500) 300437
eval_Episode has 500 steps and return 326.9.
train_Episode has 500 steps and return 268.0.
Starting evaluation at step 301000 Counter(301000) 300937
Saved chunk: 20230922T040416F097030-4X8ghdNG3qurXfEkjnItFX-5V0So4Xx11jtAHbZjf7YUE-1024.npz
eval_Episode has 500 steps and return 325.1.
Saved chunk: 20230922T040419F419015-0eZdCyMzJaQEUZjVphc6Lo-4YveB3BnL0Flir2pqK0fUL-1024.npz
train_Episode has 500 steps and return 308.6.
Starting evaluation at step 301500 Counter(301500) 301437
eval_Episode has 500 steps and return 276.4.
train_Episode has 500 steps and return 297.5.
Starting evaluation at step 302000 Counter(302000) 301937
eval_Episode has 500 steps and return 329.3.
Saved chunk: 20230922T040536F374236-5V0So4Xx11jtAHbZjf7YUE-59JolPM67gH3ocYdKZZcw8-1024.npz
Saved chunk: 20230922T040541F280188-4YveB3BnL0Flir2pqK0fUL-6PiOcTgFB7ypG7K0ARss3R-1024.npz
train_Episode has 500 steps and return 300.7.
Starting evaluation at step 302500 Counter(302500) 302437
eval_Episode has 500 steps and return 329.0.
train_Episode has 500 steps and return 288.6.
Starting evaluation at step 303000 Counter(303000) 302937
Saved chunk: 20230922T040655F700971-59JolPM67gH3ocYdKZZcw8-2xAKSCDF51a18h3P3fnWoe-1024.npz
eval_Episode has 500 steps and return 308.1.
train_Episode has 500 steps and return 295.0.
Saved chunk: 20230922T040702F186778-6PiOcTgFB7ypG7K0ARss3R-5E0HqcBkJRFPrVUsBKL9XO-1024.npz
Starting evaluation at step 303500 Counter(303500) 303437
eval_Episode has 500 steps and return 313.0.
train_Episode has 500 steps and return 291.7.
Starting evaluation at step 304000 Counter(304000) 303937
eval_Episode has 500 steps and return 276.6.
Saved chunk: 20230922T040814F878004-2xAKSCDF51a18h3P3fnWoe-4AKQbKuyoKkZ5zJt5yyYN3-1024.npz
train_Episode has 500 steps and return 277.7.
Saved chunk: 20230922T040822F913762-5E0HqcBkJRFPrVUsBKL9XO-1grCI89xqNwc7WgJjtOntj-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 608274 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 276.64 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 277.68 / episode/reward_rate 0.43 / train/action_mag 3.99 / train/action_max 3.92 / train/action_mean 0.07 / train/action_min -3.39 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 3.95 / train/adv_mag 0.54 / train/adv_max 0.47 / train/adv_mean 3.5e-4
/ train/adv_min -0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 6.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 232.43 / train/extr_critic_max 232.43 / train/extr_critic_mean 223.42 / train/extr_critic_min 178.6 / train/extr_critic_std 9.46 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 232.64 / train/extr_return_raw_max 232.64 / train/extr_return_raw_mean 223.44 / train/extr_return_raw_min 
180.88 / train/extr_return_raw_std 9.48 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.97 / train/image_loss_std 0.93 / train/model_loss_mean 3.44 /
train/model_loss_std 4.41 / train/model_opt_grad_norm 8.37 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.25 / train/policy_entropy_max 
4.04 / train/policy_entropy_mean -2.51 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.61 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.52 / train/policy_logprob_min -9.61 / train/policy_logprob_std 1.79 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.75 / train/post_ent_max 51.75 / train/post_ent_mean 42.05 / 
train/post_ent_min 22.56 / train/post_ent_std 4.66 / train/prior_ent_mag 79.35 / train/prior_ent_max 79.35 / train/prior_ent_mean 45.8 / train/prior_ent_min 29.34 / train/prior_ent_std 5.96 / train/rep_loss_mean 3.78 / train/rep_loss_std 6.15 / train/reward_avg 0.41 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.41 / train/reward_rate 
0.34 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.65 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 5.91 / report/image_loss_mean 0.95 / report/image_loss_std 0.78 / report/model_loss_mean 3.38 / report/model_loss_std 4.1 / report/post_ent_mag 51.62 / report/post_ent_max 51.62 / 
report/post_ent_mean 41.5 / report/post_ent_min 22.5 / report/post_ent_std 4.97 / report/prior_ent_mag 79.17 / report/prior_ent_max 79.17 / report/prior_ent_mean 45.29 / report/prior_ent_min 25.49 / report/prior_ent_std 6.21 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 5.91 / report/reward_avg 0.43 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 1.91 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.42 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.12 / eval/dyn_loss_std 7.08 / eval/image_loss_mean 1.46 / eval/image_loss_std 2.28 / eval/model_loss_mean 4.81 / eval/model_loss_std 6.08 / eval/post_ent_mag 49.99 / eval/post_ent_max 49.99 / eval/post_ent_mean 41.52 / 
eval/post_ent_min 19.26 / eval/post_ent_std 4.46 / eval/prior_ent_mag 79.17 / eval/prior_ent_max 79.17 / eval/prior_ent_mean 46.11 / eval/prior_ent_min 33.86 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 5.12 / eval/rep_loss_std 7.08 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.54 / eval/reward_rate 0.43 / 
replay/size 3e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3760 / timer/env.step_total 19.39 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.56 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.7 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 304500 Counter(304500) 304437
eval_Episode has 500 steps and return 337.5.
train_Episode has 500 steps and return 311.8.
Starting evaluation at step 305000 Counter(305000) 304937
eval_Episode has 500 steps and return 304.3.
Saved chunk: 20230922T040933F956345-4AKQbKuyoKkZ5zJt5yyYN3-1hYJ5ztHjyBnosYARGUXF4-1024.npz
train_Episode has 500 steps and return 289.7.
Saved chunk: 20230922T040943F587999-1grCI89xqNwc7WgJjtOntj-12ZShHhPmS5Oq3jmwi9muu-1024.npz
Starting evaluation at step 305500 Counter(305500) 305437
eval_Episode has 500 steps and return 324.7.
train_Episode has 500 steps and return 282.5.
Starting evaluation at step 306000 Counter(306000) 305937
eval_Episode has 500 steps and return 314.8.
Saved chunk: 20230922T041054F394236-1hYJ5ztHjyBnosYARGUXF4-3W5CVBrtcAtFWmyn3Ms8iq-1024.npz
train_Episode has 500 steps and return 308.1.
Saved chunk: 20230922T041105F648177-12ZShHhPmS5Oq3jmwi9muu-1Dn3eU7051YDwGEhvCtRw6-1024.npz
Starting evaluation at step 306500 Counter(306500) 306437
eval_Episode has 500 steps and return 318.7.
train_Episode has 500 steps and return 284.5.
Starting evaluation at step 307000 Counter(307000) 306937
eval_Episode has 500 steps and return 325.7.
train_Episode has 500 steps and return 314.6.
Saved chunk: 20230922T041226F508960-1Dn3eU7051YDwGEhvCtRw6-6DQDtacLsnpwnetZNMHLsb-1024.npz
Starting evaluation at step 307500 Counter(307500) 307437
Saved chunk: 20230922T041213F744317-3W5CVBrtcAtFWmyn3Ms8iq-6Nf8NjCCxZ7GZoeo2QBVBv-1024.npz
eval_Episode has 500 steps and return 317.2.
train_Episode has 500 steps and return 293.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 615890 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 317.21 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 292.96 / episode/reward_rate 0.45 / train/action_mag 4.01 / train/action_max 3.95 / train/action_mean 0.07 / train/action_min -3.38 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 5.61 / train/adv_mag 0.6 / train/adv_max 0.53 / train/adv_mean 1.9e-4 
/ train/adv_min -0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.77 / train/dyn_loss_std 6.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 232.63 / train/extr_critic_max 232.63 / train/extr_critic_mean 223.48 / train/extr_critic_min 176.95 / train/extr_critic_std 9.9 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 232.83 / train/extr_return_raw_max 232.83 / train/extr_return_raw_mean 223.49 / 
train/extr_return_raw_min 182.71 / train/extr_return_raw_std 9.93 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.91 / 
train/model_loss_mean 3.43 / train/model_loss_std 4.4 / train/model_opt_grad_norm 8.26 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.34 
/ train/policy_entropy_max 4.19 / train/policy_entropy_mean -2.51 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.1 / train/policy_logprob_mag 9.66 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.51 / train/policy_logprob_min -9.66 / 
train/policy_logprob_std 1.81 / train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.85 / train/post_ent_max 51.85 / 
train/post_ent_mean 42.07 / train/post_ent_min 22.47 / train/post_ent_std 4.65 / train/prior_ent_mag 79.3 / train/prior_ent_max 79.3 / train/prior_ent_mean 45.82 / train/prior_ent_min 29.34 / train/prior_ent_std 5.95 / train/rep_loss_mean 3.77 / train/rep_loss_std 6.17 
/ train/reward_avg 0.42 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.42 / train/reward_rate 0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.7 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.77 / report/dyn_loss_std 5.96 / report/image_loss_mean 0.99 / report/image_loss_std 1.17 / report/model_loss_mean 3.47 / report/model_loss_std 4.38 / report/post_ent_mag 
52.43 / report/post_ent_max 52.43 / report/post_ent_mean 42.61 / report/post_ent_min 21.2 / report/post_ent_std 4.14 / report/prior_ent_mag 79.32 / report/prior_ent_max 79.32 / report/prior_ent_mean 46.25 / report/prior_ent_min 28.7 / report/prior_ent_std 5.3 / 
report/rep_loss_mean 3.77 / report/rep_loss_std 5.96 / report/reward_avg 0.42 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.34 / report/reward_max_data 1.91 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.42 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.21 / eval/dyn_loss_std 5.75 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.36 / eval/model_loss_mean 3.81 / eval/model_loss_std 4.5 / eval/post_ent_mag 50.81 / eval/post_ent_max
50.81 / eval/post_ent_mean 42.44 / eval/post_ent_min 25.36 / eval/post_ent_std 3.56 / eval/prior_ent_mag 79.32 / eval/prior_ent_max 79.32 / eval/prior_ent_mean 46.41 / eval/prior_ent_min 37.69 / eval/prior_ent_std 4.98 / eval/rep_loss_mean 4.21 / eval/rep_loss_std 5.75 
/ eval/reward_avg 0.62 / eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.63 / 
eval/reward_rate 0.49 / replay/size 3.1e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3808 / timer/env.step_total 19.62 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.57 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.7e-3 / 
timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.42 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1904 / 
timer/agent.train_total 245 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 308000 Counter(308000) 307937
eval_Episode has 500 steps and return 299.2.
train_Episode has 500 steps and return 275.1.
Saved chunk: 20230922T041347F179022-6DQDtacLsnpwnetZNMHLsb-14TqDPXwIpM6Ccxybrdsg9-1024.npz
Starting evaluation at step 308500 Counter(308500) 308437
Saved chunk: 20230922T041408F836215-6Nf8NjCCxZ7GZoeo2QBVBv-03oyOes9duroYusEPjYt5J-1024.npz
eval_Episode has 500 steps and return 322.5.
train_Episode has 500 steps and return 281.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T041508F822431-14TqDPXwIpM6Ccxybrdsg9-0000000000000000000000-576.npz
Saved chunk: 20230922T041528F989117-03oyOes9duroYusEPjYt5J-0000000000000000000000-468.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 309000 Counter(309000) 308937
eval_Episode has 500 steps and return 321.2.
train_Episode has 500 steps and return 295.7.
Saved chunk: 20230922T041508F822431-14TqDPXwIpM6Ccxybrdsg9-3Wr4L0SPBwqVIfiDRQON7J-1024.npz
Starting evaluation at step 309500 Counter(309500) 309437
Saved chunk: 20230922T041528F989117-03oyOes9duroYusEPjYt5J-3DzcCxuD39BdqLlR6hw423-1024.npz
eval_Episode has 500 steps and return 324.4.
train_Episode has 500 steps and return 306.6.
Starting evaluation at step 310000 Counter(310000) 309937
eval_Episode has 500 steps and return 323.6.
train_Episode has 500 steps and return 301.1.
Saved chunk: 20230922T041630F207707-3Wr4L0SPBwqVIfiDRQON7J-4OYGBxbr6HmJ3eVZToHKSu-1024.npz
Starting evaluation at step 310500 Counter(310500) 310437
Saved chunk: 20230922T041648F771283-3DzcCxuD39BdqLlR6hw423-7pbHa6CHNUcc9JJFRsavQz-1024.npz
eval_Episode has 500 steps and return 274.3.
train_Episode has 500 steps and return 307.5.
Starting evaluation at step 311000 Counter(311000) 310937
eval_Episode has 500 steps and return 309.2.
train_Episode has 500 steps and return 290.4.
Saved chunk: 20230922T041751F089537-4OYGBxbr6HmJ3eVZToHKSu-31Kzgfzvzxap7xeLg2Ecyf-1024.npz
Starting evaluation at step 311500 Counter(311500) 311437
Saved chunk: 20230922T041808F040726-7pbHa6CHNUcc9JJFRsavQz-306NtcTWD7BVhkle7arpby-1024.npz
eval_Episode has 500 steps and return 327.9.
train_Episode has 500 steps and return 286.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 623398 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 327.88 / eval_episode/reward_rate 0.5 / episode/length 500 / episode/score 286.85 / episode/reward_rate 0.42 / train/action_mag 3.99 / train/action_max 3.94 / train/action_mean 0.07 / train/action_min -3.33 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 3.9 / train/adv_mag 0.48 / train/adv_max 0.41 / train/adv_mean 3.6e-4 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.79 / train/dyn_loss_std 6.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 232.91 / train/extr_critic_max 232.91 / train/extr_critic_mean 223.63 / train/extr_critic_min 181.62 / train/extr_critic_std 9.7 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 233.11 / train/extr_return_raw_max 233.11 / train/extr_return_raw_mean 223.64 / train/extr_return_raw_min 
184.41 / train/extr_return_raw_std 9.74 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.94 / train/model_loss_mean 3.44 /
train/model_loss_std 4.42 / train/model_opt_grad_norm 8.46 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.46 / train/policy_entropy_max 
4.33 / train/policy_entropy_mean -2.51 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.86 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.51 / train/policy_logprob_min -9.86 / train/policy_logprob_std 1.83 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.13 / train/post_ent_max 52.13 / train/post_ent_mean 41.93 / 
train/post_ent_min 22.49 / train/post_ent_std 4.65 / train/prior_ent_mag 79.22 / train/prior_ent_max 79.22 / train/prior_ent_mean 45.68 / train/prior_ent_min 29.34 / train/prior_ent_std 5.96 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.17 / train/reward_avg 0.41 / 
train/reward_loss_mean 0.2 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.41 / train/reward_rate 
0.34 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 5.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 6.05 / report/image_loss_mean 0.84 / report/image_loss_std 0.91 / report/model_loss_mean 3.17 / report/model_loss_std 4.37 / report/post_ent_mag 53.27 / report/post_ent_max 53.27 /
report/post_ent_mean 42.67 / report/post_ent_min 21.15 / report/post_ent_std 4.09 / report/prior_ent_mag 79.33 / report/prior_ent_max 79.33 / report/prior_ent_mean 46.18 / report/prior_ent_min 32.4 / report/prior_ent_std 5.61 / report/rep_loss_mean 3.54 / 
report/rep_loss_std 6.05 / report/reward_avg 0.42 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 1.93 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.41 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.4 / eval/dyn_loss_std 7.69 / eval/image_loss_mean 1.44 / eval/image_loss_std 2.31 / eval/model_loss_mean 4.99 / eval/model_loss_std 6.45 / eval/post_ent_mag 50.68 / eval/post_ent_max 50.68 / eval/post_ent_mean 
41.65 / eval/post_ent_min 22.07 / eval/post_ent_std 4.54 / eval/prior_ent_mag 79.33 / eval/prior_ent_max 79.33 / eval/prior_ent_mean 46.51 / eval/prior_ent_min 26.22 / eval/prior_ent_std 5.6 / eval/rep_loss_mean 5.4 / eval/rep_loss_std 7.69 / eval/reward_avg 0.54 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.51 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.67 / eval/reward_pred 0.54 / eval/reward_rate 0.46 / 
replay/size 3.1e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3754 / timer/env.step_total 19.56 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.28 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.45 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.68 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 312000 Counter(312000) 311937
eval_Episode has 500 steps and return 319.8.
train_Episode has 500 steps and return 300.0.
Saved chunk: 20230922T041911F807976-31Kzgfzvzxap7xeLg2Ecyf-73wPu9F6Eg01aP15GtYCxd-1024.npz
Starting evaluation at step 312500 Counter(312500) 312437
Saved chunk: 20230922T041927F149704-306NtcTWD7BVhkle7arpby-5HAR64V4CvGDFAnSWYKpeJ-1024.npz
eval_Episode has 500 steps and return 328.3.
train_Episode has 500 steps and return 291.9.
Starting evaluation at step 313000 Counter(313000) 312937
eval_Episode has 500 steps and return 317.7.
train_Episode has 500 steps and return 302.5.
Saved chunk: 20230922T042033F797411-73wPu9F6Eg01aP15GtYCxd-5mbJ0rdunFivxLVTMsu84J-1024.npz
Starting evaluation at step 313500 Counter(313500) 313437
Saved chunk: 20230922T042047F667411-5HAR64V4CvGDFAnSWYKpeJ-03krd7ObCQHYRo0BWQmcj8-1024.npz
eval_Episode has 500 steps and return 310.1.
train_Episode has 500 steps and return 301.5.
Starting evaluation at step 314000 Counter(314000) 313937
eval_Episode has 500 steps and return 324.8.
train_Episode has 500 steps and return 291.4.
Saved chunk: 20230922T042154F838350-5mbJ0rdunFivxLVTMsu84J-2sSUzsSJMFBoDUfcZgIOVB-1024.npz
Starting evaluation at step 314500 Counter(314500) 314437
Saved chunk: 20230922T042207F082160-03krd7ObCQHYRo0BWQmcj8-3h8BATK5rpNQunhyU4XvrC-1024.npz
eval_Episode has 500 steps and return 326.9.
train_Episode has 500 steps and return 278.4.
Starting evaluation at step 315000 Counter(315000) 314937
eval_Episode has 500 steps and return 300.8.
train_Episode has 500 steps and return 264.6.
Saved chunk: 20230922T042315F722668-2sSUzsSJMFBoDUfcZgIOVB-1uiGGLscykxyqUQh6mn6yC-1024.npz
Starting evaluation at step 315500 Counter(315500) 315437
Saved chunk: 20230922T042326F380975-3h8BATK5rpNQunhyU4XvrC-2XLJdueMLH0uzhHL3AopgT-1024.npz
eval_Episode has 500 steps and return 320.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 631002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 320.22 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 264.64 / episode/reward_rate 0.4 / train/action_mag 4.06 / train/action_max 3.99 / train/action_mean 0.07 / train/action_min -3.5 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 5.51 / train/adv_mag 0.36 / train/adv_max 0.28 / train/adv_mean 1.8e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.77 / train/dyn_loss_std 6.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.09 / train/extr_critic_max 233.09 / train/extr_critic_mean 223.65 / train/extr_critic_min 178.98 / train/extr_critic_std 10.76 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 233.29 / train/extr_return_raw_max 233.29 / train/extr_return_raw_mean 223.66 / train/extr_return_raw_min
179.36 / train/extr_return_raw_std 10.8 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.95 / train/model_loss_mean 3.42 /
train/model_loss_std 4.41 / train/model_opt_grad_norm 8.68 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.45 / train/policy_entropy_max 
4.24 / train/policy_entropy_mean -2.45 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 10 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.45 / train/policy_logprob_min -10 / train/policy_logprob_std 1.89 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.86 / train/post_ent_max 51.86 / train/post_ent_mean 41.93 / 
train/post_ent_min 22.18 / train/post_ent_std 4.72 / train/prior_ent_mag 79.18 / train/prior_ent_max 79.18 / train/prior_ent_mean 45.67 / train/prior_ent_min 28.67 / train/prior_ent_std 6.02 / train/rep_loss_mean 3.77 / train/rep_loss_std 6.14 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.42 / train/reward_rate 
0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.65 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.94 / report/dyn_loss_std 6.52 / report/image_loss_mean 0.92 / report/image_loss_std 0.89 / report/model_loss_mean 3.52 / report/model_loss_std 4.64 / report/post_ent_mag 52.59 / report/post_ent_max 52.59 /
report/post_ent_mean 42.41 / report/post_ent_min 21.44 / report/post_ent_std 4.12 / report/prior_ent_mag 78.81 / report/prior_ent_max 78.81 / report/prior_ent_mean 46.32 / report/prior_ent_min 31.15 / report/prior_ent_std 5.49 / report/rep_loss_mean 3.94 / 
report/rep_loss_std 6.52 / report/reward_avg 0.45 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.33 / report/reward_max_data 1.98 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.45 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.23 / eval/dyn_loss_std 6.14 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.47 / eval/model_loss_mean 3.88 / eval/model_loss_std 4.74 / eval/post_ent_mag 51 / eval/post_ent_max 51 / eval/post_ent_mean 42.09 
/ eval/post_ent_min 24.05 / eval/post_ent_std 4.29 / eval/prior_ent_mag 78.81 / eval/prior_ent_max 78.81 / eval/prior_ent_mean 46.24 / eval/prior_ent_min 28.63 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 4.23 / eval/rep_loss_std 6.14 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.6 / eval/reward_rate 0.45 / 
replay/size 3.2e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.4 / timer/env.step_count 3802 / timer/env.step_total 19.65 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.49 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7810 / timer/agent.policy_total 17.63 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / 
timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.7 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 316000 Counter(316000) 315937
eval_Episode has 500 steps and return 298.7.
train_Episode has 500 steps and return 273.9.
Saved chunk: 20230922T042436F381521-1uiGGLscykxyqUQh6mn6yC-1gXivz5lmtJO97YvnTbx7p-1024.npz
Starting evaluation at step 316500 Counter(316500) 316437
Saved chunk: 20230922T042445F453940-2XLJdueMLH0uzhHL3AopgT-3xgfSauID2O29vKMyRipeE-1024.npz
eval_Episode has 500 steps and return 310.2.
train_Episode has 500 steps and return 305.4.
Starting evaluation at step 317000 Counter(317000) 316937
eval_Episode has 500 steps and return 329.1.
train_Episode has 500 steps and return 289.5.
Saved chunk: 20230922T042558F400228-1gXivz5lmtJO97YvnTbx7p-6EfMttYayN9Grg2aoi1h78-1024.npz
Starting evaluation at step 317500 Counter(317500) 317437
Saved chunk: 20230922T042605F947214-3xgfSauID2O29vKMyRipeE-1a2TCJnkwIJcr1pLef2kke-1024.npz
eval_Episode has 500 steps and return 319.2.
train_Episode has 500 steps and return 294.8.
Starting evaluation at step 318000 Counter(318000) 317937
eval_Episode has 500 steps and return 330.1.
train_Episode has 500 steps and return 306.6.
Saved chunk: 20230922T042719F374550-6EfMttYayN9Grg2aoi1h78-34wHMmuruuabEWG0QnHvHY-1024.npz
Starting evaluation at step 318500 Counter(318500) 318437
Saved chunk: 20230922T042725F307825-1a2TCJnkwIJcr1pLef2kke-5t1kNQpRd4IcCc9SZCpiaj-1024.npz
eval_Episode has 500 steps and return 307.1.
train_Episode has 500 steps and return 291.9.
Starting evaluation at step 319000 Counter(319000) 318937
eval_Episode has 500 steps and return 301.5.
train_Episode has 500 steps and return 290.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 638614 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 290.75 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 301.52 / eval_episode/reward_rate 0.43 / train/action_mag 4.06 / train/action_max 3.98 / train/action_mean 0.07 / train/action_min -3.52 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 4.87 / train/adv_mag 0.39 / train/adv_max 0.3 / train/adv_mean 2.4e-4 
/ train/adv_min -0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.26 / train/extr_critic_max 233.26 / train/extr_critic_mean 224.27 / train/extr_critic_min 181.56 / train/extr_critic_std 9.33 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 233.46 / train/extr_return_raw_max 233.46 / train/extr_return_raw_mean 224.28 / train/extr_return_raw_min 
183.15 / train/extr_return_raw_std 9.37 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.97 / train/image_loss_std 0.96 / train/model_loss_mean 3.45 /
train/model_loss_std 4.45 / train/model_opt_grad_norm 8.26 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.57 / train/policy_entropy_max 
4.4 / train/policy_entropy_mean -2.43 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 10.11 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.43 / train/policy_logprob_min -10.11 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 1.9e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.89 / train/post_ent_max 51.89 / train/post_ent_mean 41.93 / 
train/post_ent_min 22.39 / train/post_ent_std 4.69 / train/prior_ent_mag 79.19 / train/prior_ent_max 79.19 / train/prior_ent_mean 45.7 / train/prior_ent_min 28.91 / train/prior_ent_std 5.97 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.2 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.96 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.41 / train/reward_rate 
0.34 / train_stats/mean_log_entropy -2.64 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 5.5 / report/image_loss_mean 0.93 / report/image_loss_std 0.89 / report/model_loss_mean 3.33 / report/model_loss_std 3.93 / report/post_ent_mag 53.5 / report/post_ent_max 53.5 / 
report/post_ent_mean 42.06 / report/post_ent_min 24.53 / report/post_ent_std 4.5 / report/prior_ent_mag 79.23 / report/prior_ent_max 79.23 / report/prior_ent_mean 45.79 / report/prior_ent_min 29.26 / report/prior_ent_std 5.75 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 5.5 / report/reward_avg 0.43 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 1.96 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.43 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.38 / eval/dyn_loss_std 6.31 / eval/image_loss_mean 1.08 / eval/image_loss_std 1.43 / eval/model_loss_mean 4 / eval/model_loss_std 4.8 / eval/post_ent_mag 49.92 / eval/post_ent_max 49.92 / eval/post_ent_mean 
41.74 / eval/post_ent_min 22.14 / eval/post_ent_std 4.21 / eval/prior_ent_mag 79.23 / eval/prior_ent_max 79.23 / eval/prior_ent_mean 45.96 / eval/prior_ent_min 24.12 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 4.38 / eval/rep_loss_std 6.31 / eval/reward_avg 0.59 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.58 / eval/reward_rate 0.46 / 
replay/size 3.2e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3806 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.53 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.57 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.89 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T042840F132240-34wHMmuruuabEWG0QnHvHY-4XwjlvnNSQPg3Su77mp2Xq-1024.npz
Starting evaluation at step 319500 Counter(319500) 319437
Saved chunk: 20230922T042844F476722-5t1kNQpRd4IcCc9SZCpiaj-4NNKir6pGfdBefhPxlIglD-1024.npz
eval_Episode has 500 steps and return 321.1.
train_Episode has 500 steps and return 288.0.
Starting evaluation at step 320000 Counter(320000) 319937
eval_Episode has 500 steps and return 338.3.
train_Episode has 500 steps and return 306.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T043001F813527-4XwjlvnNSQPg3Su77mp2Xq-0000000000000000000000-712.npz
Saved chunk: 20230922T043004F604894-4NNKir6pGfdBefhPxlIglD-0000000000000000000000-727.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 320500 Counter(320500) 320437
Saved chunk: 20230922T043004F604894-4NNKir6pGfdBefhPxlIglD-2D8JgoEIjBEJBNKnCKl8Ce-1024.npz
eval_Episode has 500 steps and return 328.2.
Saved chunk: 20230922T043001F813527-4XwjlvnNSQPg3Su77mp2Xq-0NpDlhQbKUl2mUZOiQP8vD-1024.npz
train_Episode has 500 steps and return 295.4.
Starting evaluation at step 321000 Counter(321000) 320937
eval_Episode has 500 steps and return 323.9.
train_Episode has 500 steps and return 250.9.
Starting evaluation at step 321500 Counter(321500) 321437
Saved chunk: 20230922T043124F362654-2D8JgoEIjBEJBNKnCKl8Ce-6StBZ8THziPxhcJYPuumzK-1024.npz
eval_Episode has 500 steps and return 316.0.
Saved chunk: 20230922T043126F700499-0NpDlhQbKUl2mUZOiQP8vD-2YA5JzH2DhIzqovybSIBfx-1024.npz
train_Episode has 500 steps and return 302.9.
Starting evaluation at step 322000 Counter(322000) 321937
eval_Episode has 500 steps and return 310.5.
train_Episode has 500 steps and return 284.9.
Starting evaluation at step 322500 Counter(322500) 322437
Saved chunk: 20230922T043243F649973-6StBZ8THziPxhcJYPuumzK-43keu2WcNYDsJXtIMfRe2k-1024.npz
eval_Episode has 500 steps and return 312.6.
Saved chunk: 20230922T043247F560456-2YA5JzH2DhIzqovybSIBfx-06YE1iilqk0UuSDRSSWvB4-1024.npz
train_Episode has 500 steps and return 272.9.
Starting evaluation at step 323000 Counter(323000) 322937
eval_Episode has 500 steps and return 310.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 646130 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 310.1 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 272.87 / episode/reward_rate 0.42 / train/action_mag 4.02 / train/action_max 3.95 / train/action_mean 0.07 / train/action_min -3.5 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 6.39 / train/adv_mag 0.35 / train/adv_max 0.25 / train/adv_mean 9.9e-5 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.77 / train/dyn_loss_std 6.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.35 / train/extr_critic_max 233.35 / train/extr_critic_mean 224.4 / train/extr_critic_min 185.89 / train/extr_critic_std 9.22 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 233.57 / train/extr_return_raw_max 233.57 / train/extr_return_raw_mean 224.4 / train/extr_return_raw_min 
185.99 / train/extr_return_raw_std 9.27 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.95 / train/image_loss_std 0.92 / train/model_loss_mean 3.43 /
train/model_loss_std 4.39 / train/model_opt_grad_norm 8.46 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.62 / train/policy_entropy_max 
4.44 / train/policy_entropy_mean -2.49 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 9.91 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.49 / train/policy_logprob_min -9.91 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.85 / train/post_ent_max 51.85 / train/post_ent_mean 41.95 / 
train/post_ent_min 22.52 / train/post_ent_std 4.63 / train/prior_ent_mag 79.12 / train/prior_ent_max 79.12 / train/prior_ent_mean 45.7 / train/prior_ent_min 29.22 / train/prior_ent_std 5.95 / train/rep_loss_mean 3.77 / train/rep_loss_std 6.15 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.42 / train/reward_rate 
0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.66 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.68 / report/dyn_loss_std 7.07 / report/image_loss_mean 0.98 / report/image_loss_std 1.07 / report/model_loss_mean 3.35 / report/model_loss_std 5.04 / report/post_ent_mag 51.23 / report/post_ent_max 51.23 /
report/post_ent_mean 40.58 / report/post_ent_min 22.3 / report/post_ent_std 4.78 / report/prior_ent_mag 79.02 / report/prior_ent_max 79.02 / report/prior_ent_mean 44.32 / report/prior_ent_min 28.47 / report/prior_ent_std 6.73 / report/rep_loss_mean 3.68 / 
report/rep_loss_std 7.07 / report/reward_avg 0.35 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.99 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.35 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.75 / eval/dyn_loss_std 5.74 / eval/image_loss_mean 0.88 / eval/image_loss_std 1.09 / eval/model_loss_mean 3.44 / eval/model_loss_std 4.24 / eval/post_ent_mag 50.7 / eval/post_ent_max 50.7 / eval/post_ent_mean 
42.25 / eval/post_ent_min 24.38 / eval/post_ent_std 3.62 / eval/prior_ent_mag 79.02 / eval/prior_ent_max 79.02 / eval/prior_ent_mean 45.94 / eval/prior_ent_min 27.46 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 3.75 / eval/rep_loss_std 5.74 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.66 / eval/reward_rate 0.52 / 
replay/size 3.2e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3758 / timer/env.step_total 19.63 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.25 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7766 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1879 / timer/agent.train_total 241.58 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 310.7.
Starting evaluation at step 323500 Counter(323500) 323437
Saved chunk: 20230922T043402F671920-43keu2WcNYDsJXtIMfRe2k-3KJPAd13pKQv2Jj2vnCXZS-1024.npz
eval_Episode has 500 steps and return 309.2.
Saved chunk: 20230922T043408F137294-06YE1iilqk0UuSDRSSWvB4-1y7wMFBhyWCfPxVfWKYDaW-1024.npz
train_Episode has 500 steps and return 295.8.
Starting evaluation at step 324000 Counter(324000) 323937
eval_Episode has 500 steps and return 321.1.
train_Episode has 500 steps and return 302.2.
Starting evaluation at step 324500 Counter(324500) 324437
Saved chunk: 20230922T043522F793735-3KJPAd13pKQv2Jj2vnCXZS-2N4nILdy4d3pMfE6NcgJZL-1024.npz
eval_Episode has 500 steps and return 337.1.
Saved chunk: 20230922T043529F885047-1y7wMFBhyWCfPxVfWKYDaW-3CARLwsndy1tvj2XiDDnQV-1024.npz
train_Episode has 500 steps and return 270.3.
Starting evaluation at step 325000 Counter(325000) 324937
eval_Episode has 500 steps and return 327.5.
train_Episode has 500 steps and return 275.1.
Starting evaluation at step 325500 Counter(325500) 325437
Saved chunk: 20230922T043642F193846-2N4nILdy4d3pMfE6NcgJZL-5qh55bDVdcChKplD2jfGLZ-1024.npz
eval_Episode has 500 steps and return 317.9.
Saved chunk: 20230922T043650F820810-3CARLwsndy1tvj2XiDDnQV-0jDzfM3ZQXeTqG2Rpffk1W-1024.npz
train_Episode has 500 steps and return 271.8.
Starting evaluation at step 326000 Counter(326000) 325937
eval_Episode has 500 steps and return 295.6.
train_Episode has 500 steps and return 310.1.
Starting evaluation at step 326500 Counter(326500) 326437
Saved chunk: 20230922T043801F391935-5qh55bDVdcChKplD2jfGLZ-6o2Xw9wzvh1lGyH7tll481-1024.npz
eval_Episode has 500 steps and return 306.2.
train_Episode has 500 steps and return 315.2.
Saved chunk: 20230922T043811F569880-0jDzfM3ZQXeTqG2Rpffk1W-4rcQfJk2BoEt5OUeuRKo3Y-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 653750 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 315.17 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 306.18 / eval_episode/reward_rate 0.47 / train/action_mag 4.06 / train/action_max 4.02 / train/action_mean 0.07 / train/action_min -3.38 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 4.66 / train/adv_mag 0.37 / train/adv_max 0.3 / train/adv_mean 2.8e-4 
/ train/adv_min -0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 6.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.51 / train/extr_critic_max 233.51 / train/extr_critic_mean 224.62 / train/extr_critic_min 186.13 / train/extr_critic_std 8.95 / train/extr_return_normed_mag 1.29 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 233.71 / train/extr_return_raw_max 233.71 / train/extr_return_raw_mean 224.63 / train/extr_return_raw_min 
187.64 / train/extr_return_raw_std 8.98 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.96 / train/image_loss_std 0.95 / train/model_loss_mean 3.44 /
train/model_loss_std 4.41 / train/model_opt_grad_norm 8.35 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.29 / train/policy_entropy_max 
4.09 / train/policy_entropy_mean -2.52 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.4 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.52 / train/policy_logprob_min -9.4 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.06 / train/post_ent_max 52.06 / train/post_ent_mean 41.95 / 
train/post_ent_min 22.24 / train/post_ent_std 4.66 / train/prior_ent_mag 79.04 / train/prior_ent_max 79.04 / train/prior_ent_mean 45.7 / train/prior_ent_min 28.92 / train/prior_ent_std 5.96 / train/rep_loss_mean 3.78 / train/rep_loss_std 6.16 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.42 / train/reward_rate 
0.35 / train_stats/mean_log_entropy -2.69 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.69 / report/dyn_loss_std 6.14 / report/image_loss_mean 0.93 / report/image_loss_std 0.82 / report/model_loss_mean 3.38 / report/model_loss_std 4.34 / report/post_ent_mag 51.1 / report/post_ent_max 51.1 / 
report/post_ent_mean 42.57 / report/post_ent_min 19.58 / report/post_ent_std 4.29 / report/prior_ent_mag 79.24 / report/prior_ent_max 79.24 / report/prior_ent_mean 46.27 / report/prior_ent_min 28.52 / report/prior_ent_std 5.63 / report/rep_loss_mean 3.69 / 
report/rep_loss_std 6.14 / report/reward_avg 0.48 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.33 / report/reward_max_data 1.94 / report/reward_max_pred 1.94 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.47 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 4.33 / eval/dyn_loss_std 6.63 / eval/image_loss_mean 1.01 / eval/image_loss_std 1.53 / eval/model_loss_mean 3.9 / eval/model_loss_std 5.14 / eval/post_ent_mag 50.49 / eval/post_ent_max 50.49 / eval/post_ent_mean 42.19 / 
eval/post_ent_min 25.55 / eval/post_ent_std 3.67 / eval/prior_ent_mag 79.24 / eval/prior_ent_max 79.24 / eval/prior_ent_mean 46.39 / eval/prior_ent_min 37.87 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 4.33 / eval/rep_loss_std 6.63 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.59 / eval/reward_rate 0.46 / 
replay/size 3.3e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3810 / timer/env.step_total 19.7 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.36 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7317 / timer/agent.policy_total 16.44 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 
/ timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1905 / timer/agent.train_total 244.92 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 327000 Counter(327000) 326937
eval_Episode has 500 steps and return 332.4.
train_Episode has 500 steps and return 297.9.
Starting evaluation at step 327500 Counter(327500) 327437
eval_Episode has 500 steps and return 307.8.
Saved chunk: 20230922T043920F441219-6o2Xw9wzvh1lGyH7tll481-1NDvd2d7DnSUjeeYvEFxdK-1024.npz
train_Episode has 500 steps and return 303.5.
Saved chunk: 20230922T043932F218900-4rcQfJk2BoEt5OUeuRKo3Y-4qMRCVUfcZNnHVdcLI27Ld-1024.npz
Starting evaluation at step 328000 Counter(328000) 327937
eval_Episode has 500 steps and return 319.1.
train_Episode has 500 steps and return 293.4.
Starting evaluation at step 328500 Counter(328500) 328437
eval_Episode has 500 steps and return 316.6.
Saved chunk: 20230922T044040F871923-1NDvd2d7DnSUjeeYvEFxdK-41g70spUhNrcnAHxWJtd76-1024.npz
train_Episode has 500 steps and return 276.2.
Saved chunk: 20230922T044054F288784-4qMRCVUfcZNnHVdcLI27Ld-4EfbyQ68KL6WmkNdnoCyZR-1024.npz
Starting evaluation at step 329000 Counter(329000) 328937
eval_Episode has 500 steps and return 327.5.
train_Episode has 500 steps and return 312.2.
Starting evaluation at step 329500 Counter(329500) 329437
eval_Episode has 500 steps and return 300.6.
Saved chunk: 20230922T044200F495451-41g70spUhNrcnAHxWJtd76-6UafZA8vr5M1BJrIbbVGFV-1024.npz
train_Episode has 500 steps and return 267.2.
Saved chunk: 20230922T044215F490330-4EfbyQ68KL6WmkNdnoCyZR-6zP0VlXRyL9ywvuRH4mKza-1024.npz
Starting evaluation at step 330000 Counter(330000) 329937
eval_Episode has 500 steps and return 285.3.
train_Episode has 500 steps and return 294.3.
Starting evaluation at step 330500 Counter(330500) 330437
eval_Episode has 500 steps and return 307.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 661252 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 307.05 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 294.28 / episode/reward_rate 0.44 / train/action_mag 4.04 / train/action_max 4 / train/action_mean 0.08 / train/action_min -3.42 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 4 / train/adv_mag 0.38 / train/adv_max 0.29 / train/adv_mean 3.5e-4 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.76 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.57 / train/extr_critic_max 233.57 / train/extr_critic_mean 224.94 / train/extr_critic_min 188.57 / train/extr_critic_std 8.7 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 233.76 / train/extr_return_raw_max 233.76 / train/extr_return_raw_mean 224.96 / train/extr_return_raw_min 
188.65 / train/extr_return_raw_std 8.74 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.94 / train/image_loss_std 0.92 / train/model_loss_mean 3.41 /
train/model_loss_std 4.39 / train/model_opt_grad_norm 8.37 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.12 / train/policy_entropy_max 
3.88 / train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.57 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -9.57 / train/policy_logprob_std 1.79 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.12 / train/post_ent_max 52.12 / train/post_ent_mean 42.06 / 
train/post_ent_min 22.18 / train/post_ent_std 4.59 / train/prior_ent_mag 79.04 / train/prior_ent_max 79.04 / train/prior_ent_mean 45.8 / train/prior_ent_min 29.45 / train/prior_ent_std 5.89 / train/rep_loss_mean 3.76 / train/rep_loss_std 6.12 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.43 / train/reward_rate 
0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.66 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 6.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.69 / report/dyn_loss_std 6.14 / report/image_loss_mean 0.96 / report/image_loss_std 1.04 / report/model_loss_mean 3.37 / report/model_loss_std 4.51 / report/post_ent_mag 50.98 / report/post_ent_max 50.98 /
report/post_ent_mean 41.8 / report/post_ent_min 24.66 / report/post_ent_std 4.44 / report/prior_ent_mag 78.95 / report/prior_ent_max 78.95 / report/prior_ent_mean 45.41 / report/prior_ent_min 27.5 / report/prior_ent_std 5.89 / report/rep_loss_mean 3.69 / 
report/rep_loss_std 6.14 / report/reward_avg 0.44 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 1.96 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.44 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.06 / eval/dyn_loss_std 12.32 / eval/image_loss_mean 2.11 / eval/image_loss_std 4.27 / eval/model_loss_mean 6.63 / eval/model_loss_std 11.31 / eval/post_ent_mag 50.09 / eval/post_ent_max 50.09 / 
eval/post_ent_mean 41.81 / eval/post_ent_min 22.34 / eval/post_ent_std 4.04 / eval/prior_ent_mag 78.95 / eval/prior_ent_max 78.95 / eval/prior_ent_mean 46.23 / eval/prior_ent_min 34.76 / eval/prior_ent_std 5.39 / eval/rep_loss_mean 7.06 / eval/rep_loss_std 12.32 / 
eval/reward_avg 0.55 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.46 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.55 / 
eval/reward_rate 0.43 / replay/size 3.3e5 / replay/inserts 3751 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3751 / timer/env.step_total 19.39 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.16 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.7e-3 / 
timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7759 / timer/agent.policy_total 17.35 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.02 / timer/dataset_train_count 1875 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1875 / 
timer/agent.train_total 241.86 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 293.5.
Saved chunk: 20230922T044336F306641-6zP0VlXRyL9ywvuRH4mKza-2uVUSzLREqZ7UHLl9O6oGt-1024.npz
Starting evaluation at step 331000 Counter(331000) 330937
Saved chunk: 20230922T044319F825463-6UafZA8vr5M1BJrIbbVGFV-3C2hx8NtxJWP5UrBNeztU7-1024.npz
eval_Episode has 500 steps and return 328.0.
train_Episode has 500 steps and return 295.8.
Starting evaluation at step 331500 Counter(331500) 331437
eval_Episode has 500 steps and return 308.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T044458F072309-2uVUSzLREqZ7UHLl9O6oGt-0000000000000000000000-848.npz
Saved chunk: 20230922T044516F150965-3C2hx8NtxJWP5UrBNeztU7-0000000000000000000000-986.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 301.5.
Saved chunk: 20230922T044458F072309-2uVUSzLREqZ7UHLl9O6oGt-5ozbrLyLXfpG9FahvaSQNw-1024.npz
Starting evaluation at step 332000 Counter(332000) 331937
Saved chunk: 20230922T044516F150965-3C2hx8NtxJWP5UrBNeztU7-22Gi2fLpJcacdZltGhFu7D-1024.npz
eval_Episode has 500 steps and return 305.3.
train_Episode has 500 steps and return 313.7.
Starting evaluation at step 332500 Counter(332500) 332437
eval_Episode has 500 steps and return 327.2.
train_Episode has 500 steps and return 310.3.
Saved chunk: 20230922T044619F428319-5ozbrLyLXfpG9FahvaSQNw-7Fpij64LVNfsZfIINlqzJl-1024.npz
Starting evaluation at step 333000 Counter(333000) 332937
Saved chunk: 20230922T044635F896813-22Gi2fLpJcacdZltGhFu7D-5DjGdk5H0IIltq6ybKUiEC-1024.npz
eval_Episode has 500 steps and return 314.5.
train_Episode has 500 steps and return 294.7.
Starting evaluation at step 333500 Counter(333500) 333437
eval_Episode has 500 steps and return 324.2.
train_Episode has 500 steps and return 292.9.
Saved chunk: 20230922T044740F461446-7Fpij64LVNfsZfIINlqzJl-6CSjp7ChdptgWBP3qi73B8-1024.npz
Starting evaluation at step 334000 Counter(334000) 333937
Saved chunk: 20230922T044755F316657-5DjGdk5H0IIltq6ybKUiEC-3o0eSxE5A7Q1QOIiYPnzig-1024.npz
eval_Episode has 500 steps and return 327.1.
train_Episode has 500 steps and return 289.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 668850 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 289.66 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 327.11 / eval_episode/reward_rate 0.5 / train/action_mag 4.04 / train/action_max 3.97 / train/action_mean 0.07 / train/action_min -3.47 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 4.39 / train/adv_mag 0.51 / train/adv_max 0.41 / train/adv_mean 3.2e-4 / train/adv_min 
-0.4 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.76 / train/dyn_loss_std 6.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 233.88 / train/extr_critic_max 233.88 / train/extr_critic_mean 224.74 / train/extr_critic_min 179.88 / train/extr_critic_std 10.44 / train/extr_return_normed_mag 1.6 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.62 / train/extr_return_normed_std 0.32 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 234.09 / train/extr_return_raw_max 234.09 / train/extr_return_raw_mean 224.76 / 
train/extr_return_raw_min 180.01 / train/extr_return_raw_std 10.46 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.94 / train/image_loss_std 0.92 / 
train/model_loss_mean 3.41 / train/model_loss_std 4.37 / train/model_opt_grad_norm 8.32 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.14
/ train/policy_entropy_max 3.93 / train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.77 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -9.77 / 
train/policy_logprob_std 1.82 / train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.04 / train/post_ent_max 52.04 / 
train/post_ent_mean 42 / train/post_ent_min 22.37 / train/post_ent_std 4.6 / train/prior_ent_mag 78.94 / train/prior_ent_max 78.94 / train/prior_ent_mean 45.74 / train/prior_ent_min 29.31 / train/prior_ent_std 5.89 / train/rep_loss_mean 3.76 / train/rep_loss_std 6.11 / 
train/reward_avg 0.42 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 
0.42 / train/reward_rate 0.35 / train_stats/mean_log_entropy -2.69 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 6.61 / report/image_loss_mean 1.02 / report/image_loss_std 1.06 / report/model_loss_mean 3.51 / report/model_loss_std 4.79 / report/post_ent_mag 
51.58 / report/post_ent_max 51.58 / report/post_ent_mean 41.77 / report/post_ent_min 23.16 / report/post_ent_std 4.8 / report/prior_ent_mag 79.13 / report/prior_ent_max 79.13 / report/prior_ent_mean 45.55 / report/prior_ent_min 28.84 / report/prior_ent_std 6.16 / 
report/rep_loss_mean 3.84 / report/rep_loss_std 6.61 / report/reward_avg 0.39 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 1.98 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.39 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.65 / eval/dyn_loss_std 6.77 / eval/image_loss_mean 1.2 / eval/image_loss_std 2.01 / eval/model_loss_mean 4.27 / eval/model_loss_std 5.72 / eval/post_ent_mag 50.55 / eval/post_ent_max
50.55 / eval/post_ent_mean 42 / eval/post_ent_min 20.83 / eval/post_ent_std 4.28 / eval/prior_ent_mag 79.13 / eval/prior_ent_max 79.13 / eval/prior_ent_mean 46.03 / eval/prior_ent_min 29.54 / eval/prior_ent_std 5.28 / eval/rep_loss_mean 4.65 / eval/rep_loss_std 6.77 / 
eval/reward_avg 0.59 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.59 / 
eval/reward_rate 0.45 / replay/size 3.3e5 / replay/inserts 3799 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3799 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.85 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8.1e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7306 / timer/agent.policy_total 16.5 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.69 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac
1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.32

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 334500 Counter(334500) 334437
eval_Episode has 500 steps and return 337.9.
train_Episode has 500 steps and return 274.4.
Saved chunk: 20230922T044901F245702-6CSjp7ChdptgWBP3qi73B8-4mFtqCntBWeVTdj37kAWIF-1024.npz
Starting evaluation at step 335000 Counter(335000) 334937
Saved chunk: 20230922T044914F495651-3o0eSxE5A7Q1QOIiYPnzig-5cEOYqKW7uQOWilr0cH4Nr-1024.npz
eval_Episode has 500 steps and return 311.2.
train_Episode has 500 steps and return 283.4.
Starting evaluation at step 335500 Counter(335500) 335437
eval_Episode has 500 steps and return 315.0.
train_Episode has 500 steps and return 294.5.
Saved chunk: 20230922T045023F178105-4mFtqCntBWeVTdj37kAWIF-1rynIYAPgGpb00jBVaNNhk-1024.npz
Starting evaluation at step 336000 Counter(336000) 335937
Saved chunk: 20230922T045034F923741-5cEOYqKW7uQOWilr0cH4Nr-05JMTm14be1CS2D2V2MU7G-1024.npz
eval_Episode has 500 steps and return 313.5.
train_Episode has 500 steps and return 316.6.
Starting evaluation at step 336500 Counter(336500) 336437
eval_Episode has 500 steps and return 301.6.
train_Episode has 500 steps and return 273.0.
Saved chunk: 20230922T045144F390659-1rynIYAPgGpb00jBVaNNhk-4DXn8dHwgCpBaVr5japWie-1024.npz
Starting evaluation at step 337000 Counter(337000) 336937
Saved chunk: 20230922T045154F499862-05JMTm14be1CS2D2V2MU7G-2qxDjkHMdaBsfJ4sC3jY7t-1024.npz
eval_Episode has 500 steps and return 331.9.
train_Episode has 500 steps and return 279.3.
Starting evaluation at step 337500 Counter(337500) 337437
eval_Episode has 500 steps and return 319.8.
train_Episode has 500 steps and return 290.0.
Saved chunk: 20230922T045305F253635-4DXn8dHwgCpBaVr5japWie-3gOOhSjVRd4B6IAoPJcO3e-1024.npz
Starting evaluation at step 338000 Counter(338000) 337937
Saved chunk: 20230922T045313F788261-2qxDjkHMdaBsfJ4sC3jY7t-4SSu846JhettC8B2yEUzue-1024.npz
eval_Episode has 500 steps and return 307.2.
train_Episode has 500 steps and return 282.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 676358 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 307.23 / eval_episode/reward_rate 0.5 / episode/length 500 / episode/score 282.41 / episode/reward_rate 0.42 / train/action_mag 4.07 / train/action_max 4.05 / train/action_mean 0.08 / train/action_min -3.3 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 3.43 / train/adv_mag 0.42 / train/adv_max 0.33 / train/adv_mean 4.4e-4 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 6.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.05 / train/extr_critic_max 234.05 / train/extr_critic_mean 225.67 / train/extr_critic_min 190.02 / train/extr_critic_std 7.94 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 234.26 / train/extr_return_raw_max 234.26 / train/extr_return_raw_mean 225.69 / train/extr_return_raw_min 
190.14 / train/extr_return_raw_std 7.96 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.95 / train/image_loss_std 0.94 / train/model_loss_mean 3.43 /
train/model_loss_std 4.39 / train/model_opt_grad_norm 8.24 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.1 / train/policy_entropy_max 
3.85 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1 / train/policy_logprob_mag 9.06 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -9.06 / train/policy_logprob_std 1.74 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 51.95 / train/post_ent_max 51.95 / train/post_ent_mean 42.03 / 
train/post_ent_min 22.43 / train/post_ent_std 4.52 / train/prior_ent_mag 78.89 / train/prior_ent_max 78.89 / train/prior_ent_mean 45.78 / train/prior_ent_min 29.53 / train/prior_ent_std 5.81 / train/rep_loss_mean 3.78 / train/rep_loss_std 6.12 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.95 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.43 / train/reward_rate 
0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.73 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 9.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.57 / report/dyn_loss_std 5.55 / report/image_loss_mean 0.89 / report/image_loss_std 1.02 / report/model_loss_mean 3.3 / report/model_loss_std 4.11 / report/post_ent_mag 52.38 / report/post_ent_max 52.38 / 
report/post_ent_mean 42.64 / report/post_ent_min 21.92 / report/post_ent_std 4.04 / report/prior_ent_mag 78.84 / report/prior_ent_max 78.84 / report/prior_ent_mean 46.14 / report/prior_ent_min 33.59 / report/prior_ent_std 5.15 / report/rep_loss_mean 3.57 / 
report/rep_loss_std 5.55 / report/reward_avg 0.54 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.34 / report/reward_max_data 1.97 / report/reward_max_pred 1.94 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.53 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.17 / eval/dyn_loss_std 6.46 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.58 / eval/model_loss_mean 3.83 / eval/model_loss_std 5.03 / eval/post_ent_mag 50.68 / eval/post_ent_max 50.68 / eval/post_ent_mean 
41.91 / eval/post_ent_min 23.22 / eval/post_ent_std 4.25 / eval/prior_ent_mag 78.84 / eval/prior_ent_max 78.84 / eval/prior_ent_mean 45.82 / eval/prior_ent_min 29.06 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 4.17 / eval/rep_loss_std 6.46 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.58 / eval/reward_rate 0.45 / 
replay/size 3.4e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3754 / timer/env.step_total 19.42 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.06 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.37 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.9 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 338500 Counter(338500) 338437
eval_Episode has 500 steps and return 316.2.
train_Episode has 500 steps and return 282.1.
Saved chunk: 20230922T045425F949985-3gOOhSjVRd4B6IAoPJcO3e-7jflBopEjXZXnjfXT1Sgfp-1024.npz
Starting evaluation at step 339000 Counter(339000) 338937
Saved chunk: 20230922T045432F917776-4SSu846JhettC8B2yEUzue-79uiXfp7M71kCDKz2eXsuG-1024.npz
eval_Episode has 500 steps and return 316.5.
train_Episode has 500 steps and return 288.9.
Starting evaluation at step 339500 Counter(339500) 339437
eval_Episode has 500 steps and return 320.8.
train_Episode has 500 steps and return 290.2.
Saved chunk: 20230922T045548F105242-7jflBopEjXZXnjfXT1Sgfp-0ZrLLgNd8ybdb6wCmBw9rg-1024.npz
Starting evaluation at step 340000 Counter(340000) 339937
Saved chunk: 20230922T045553F486975-79uiXfp7M71kCDKz2eXsuG-77Uy4TDSQT95Ue33hulQlm-1024.npz
eval_Episode has 500 steps and return 321.9.
train_Episode has 500 steps and return 297.9.
Starting evaluation at step 340500 Counter(340500) 340437
eval_Episode has 500 steps and return 325.6.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 341000 Counter(341000) 340937
Saved chunk: 20230922T045709F138081-0ZrLLgNd8ybdb6wCmBw9rg-2rzcXceARveaLvWlyrictm-1024.npz
Saved chunk: 20230922T045712F950406-77Uy4TDSQT95Ue33hulQlm-7AFlDK4BM0XRUZKHHE15ug-1024.npz
eval_Episode has 500 steps and return 318.3.
train_Episode has 500 steps and return 296.9.
Starting evaluation at step 341500 Counter(341500) 341437
eval_Episode has 500 steps and return 322.5.
train_Episode has 500 steps and return 310.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 683962 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 322.5 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 310.72 / episode/reward_rate 0.49 / train/action_mag 4 / train/action_max 3.95 / train/action_mean 0.08 / train/action_min -3.41 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 4.77 / train/adv_mag 0.38 / train/adv_max 0.29 / train/adv_mean 2.9e-4 / train/adv_min 
-0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.75 / train/dyn_loss_std 6.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.18 / train/extr_critic_max 234.18 / train/extr_critic_mean 225.5 / train/extr_critic_min 185.46 / train/extr_critic_std 9.29 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 234.38 / train/extr_return_raw_max 234.38 / train/extr_return_raw_mean 225.51 / train/extr_return_raw_min 
185.83 / train/extr_return_raw_std 9.32 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.94 / train/image_loss_std 0.94 / train/model_loss_mean 3.4 / 
train/model_loss_std 4.38 / train/model_opt_grad_norm 8.18 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.94 / train/policy_entropy_max 
3.62 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.04 / train/policy_logprob_mag 9.26 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.26 / train/policy_logprob_std 1.77 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 42.07 / 
train/post_ent_min 22.48 / train/post_ent_std 4.56 / train/prior_ent_mag 78.83 / train/prior_ent_max 78.83 / train/prior_ent_mean 45.79 / train/prior_ent_min 29.45 / train/prior_ent_std 5.85 / train/rep_loss_mean 3.75 / train/rep_loss_std 6.1 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.33 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.43 / train/reward_rate 
0.36 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.67 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.22 / report/dyn_loss_std 6.86 / report/image_loss_mean 1.08 / report/image_loss_std 1.22 / report/model_loss_mean 3.8 / report/model_loss_std 5.05 / report/post_ent_mag 50.85 / report/post_ent_max 50.85 / 
report/post_ent_mean 40.79 / report/post_ent_min 16.36 / report/post_ent_std 5.7 / report/prior_ent_mag 78.79 / report/prior_ent_max 78.79 / report/prior_ent_mean 45 / report/prior_ent_min 26.46 / report/prior_ent_std 6.97 / report/rep_loss_mean 4.22 / 
report/rep_loss_std 6.86 / report/reward_avg 0.39 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 5.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.39 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.4 / eval/dyn_loss_std 6.67 / eval/image_loss_mean 1.18 / eval/image_loss_std 2.37 / eval/model_loss_mean 4.09 / eval/model_loss_std 5.93 / eval/post_ent_mag 50.98 / eval/post_ent_max 50.98 / eval/post_ent_mean 
41.84 / eval/post_ent_min 25.39 / eval/post_ent_std 3.93 / eval/prior_ent_mag 78.79 / eval/prior_ent_max 78.79 / eval/prior_ent_mean 46.01 / eval/prior_ent_min 35.89 / eval/prior_ent_std 4.99 / eval/rep_loss_mean 4.4 / eval/rep_loss_std 6.67 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.61 / eval/reward_rate 0.45 / 
replay/size 3.4e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3802 / timer/env.step_total 19.63 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.49 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.2e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.42 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1901 / timer/agent.train_total 245.02 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 342000 Counter(342000) 341937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T045832F155539-7AFlDK4BM0XRUZKHHE15ug-7l1HUC77WI9Xb37oSe94Mh-1024.npz
eval_Episode has 500 steps and return 323.9.
Saved chunk: 20230922T045829F935733-2rzcXceARveaLvWlyrictm-11P3TsOHlJIKov8zunN0Ag-1024.npz
train_Episode has 500 steps and return 250.2.
Starting evaluation at step 342500 Counter(342500) 342437
eval_Episode has 500 steps and return 319.4.
train_Episode has 500 steps and return 301.4.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 343000 Counter(343000) 342937
Saved chunk: 20230922T045952F371436-7l1HUC77WI9Xb37oSe94Mh-0000000000000000000000-744.npz
Saved chunk: 20230922T045955F293401-11P3TsOHlJIKov8zunN0Ag-0000000000000000000000-984.npz
Saved chunk: 20230922T045952F371436-7l1HUC77WI9Xb37oSe94Mh-2DXCSlwzwu9iDDxCQBTyos-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
eval_Episode has 500 steps and return 312.9.
Saved chunk: 20230922T045955F293401-11P3TsOHlJIKov8zunN0Ag-0EV0Fq7FD7QFBr0JWVdN3G-1024.npz
train_Episode has 500 steps and return 317.1.
Starting evaluation at step 343500 Counter(343500) 343437
eval_Episode has 500 steps and return 309.5.
train_Episode has 500 steps and return 298.6.
Starting evaluation at step 344000 Counter(344000) 343937
Saved chunk: 20230922T050112F284619-2DXCSlwzwu9iDDxCQBTyos-6NnfGmEaXTrwdhsScSZ6jk-1024.npz
eval_Episode has 500 steps and return 303.9.
Saved chunk: 20230922T050116F806181-0EV0Fq7FD7QFBr0JWVdN3G-1BHS5AgFKZNIEbQh3jEZNe-1024.npz
train_Episode has 500 steps and return 285.9.
Starting evaluation at step 344500 Counter(344500) 344437
eval_Episode has 500 steps and return 319.4.
train_Episode has 500 steps and return 307.6.
Starting evaluation at step 345000 Counter(345000) 344937
Saved chunk: 20230922T050233F238042-6NnfGmEaXTrwdhsScSZ6jk-1XigkSBPlAu16jElyQSM9a-1024.npz
eval_Episode has 500 steps and return 328.4.
Saved chunk: 20230922T050239F283718-1BHS5AgFKZNIEbQh3jEZNe-04nRu9EaxJ9thWrEAjdrFF-1024.npz
train_Episode has 500 steps and return 319.7.
Starting evaluation at step 345500 Counter(345500) 345437
eval_Episode has 500 steps and return 321.1.
train_Episode has 500 steps and return 290.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 691422 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 321.12 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 290.36 / episode/reward_rate 0.45 / train/action_mag 4.05 / train/action_max 3.97 / train/action_mean 0.08 / train/action_min -3.48 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 3.75 / train/adv_mag 0.47 / train/adv_max 0.39 / train/adv_mean 4e-4 /
train/adv_min -0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.37 / train/extr_critic_max 234.37 / train/extr_critic_mean 225.33 / train/extr_critic_min 181.85 / train/extr_critic_std 9.99 / train/extr_return_normed_mag 1.51 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 234.57 / train/extr_return_raw_max 234.57 / train/extr_return_raw_mean 225.34 / 
train/extr_return_raw_min 183.73 / train/extr_return_raw_std 10 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.93 / train/image_loss_std 0.91 / 
train/model_loss_mean 3.38 / train/model_loss_std 4.34 / train/model_opt_grad_norm 8.54 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.9 
/ train/policy_entropy_max 3.58 / train/policy_entropy_mean -2.59 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.03 / train/policy_logprob_mag 9.1 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.59 / train/policy_logprob_min -9.1 / 
train/policy_logprob_std 1.76 / train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.09 / train/post_ent_max 52.09 / 
train/post_ent_mean 42.02 / train/post_ent_min 22.66 / train/post_ent_std 4.6 / train/prior_ent_mag 78.77 / train/prior_ent_max 78.77 / train/prior_ent_mean 45.73 / train/prior_ent_min 29.54 / train/prior_ent_std 5.89 / train/rep_loss_mean 3.73 / train/rep_loss_std 6.08
/ train/reward_avg 0.43 / train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred
0.43 / train/reward_rate 0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.6 / report/dyn_loss_std 6.13 / report/image_loss_mean 0.86 / report/image_loss_std 0.72 / report/model_loss_mean 3.24 / report/model_loss_std 4.25 / report/post_ent_mag 53.91
/ report/post_ent_max 53.91 / report/post_ent_mean 42.08 / report/post_ent_min 16.93 / report/post_ent_std 4.11 / report/prior_ent_mag 78.71 / report/prior_ent_max 78.71 / report/prior_ent_mean 45.58 / report/prior_ent_min 28.08 / report/prior_ent_std 5.61 / 
report/rep_loss_mean 3.6 / report/rep_loss_std 6.13 / report/reward_avg 0.43 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 4.4e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.43 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.43 / eval/dyn_loss_std 6.67 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.47 / eval/model_loss_mean 3.99 / eval/model_loss_std 5.06 / eval/post_ent_mag 51.24 / 
eval/post_ent_max 51.24 / eval/post_ent_mean 41.97 / eval/post_ent_min 21.6 / eval/post_ent_std 4.09 / eval/prior_ent_mag 78.71 / eval/prior_ent_max 78.71 / eval/prior_ent_mean 46.06 / eval/prior_ent_min 34.68 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 4.43 / 
eval/rep_loss_std 6.67 / eval/reward_avg 0.61 / eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.61 / eval/reward_rate 0.48 / replay/size 3.5e5 / replay/inserts 3730 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3730 / timer/env.step_total 19.24 
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.3 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min
6.5e-4 / timer/replay._sample_max 0.19 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7738 / timer/agent.policy_total 
17.65 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1865 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1865 / timer/agent.train_total 241.63 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.65 / 
timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac
1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 24.86

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 346000 Counter(346000) 345937
Saved chunk: 20230922T050352F371635-1XigkSBPlAu16jElyQSM9a-7l1A0mArSlzamIiA7TyzEp-1024.npz
eval_Episode has 500 steps and return 332.4.
Saved chunk: 20230922T050359F974947-04nRu9EaxJ9thWrEAjdrFF-3UBusTWZdeWIc3CJ9gVwuM-1024.npz
train_Episode has 500 steps and return 244.0.
Starting evaluation at step 346500 Counter(346500) 346437
eval_Episode has 500 steps and return 322.4.
train_Episode has 500 steps and return 303.8.
Starting evaluation at step 347000 Counter(347000) 346937
Saved chunk: 20230922T050512F529173-7l1A0mArSlzamIiA7TyzEp-6L2m0bfd1HAlEJmRvQ1NCY-1024.npz
eval_Episode has 500 steps and return 311.4.
Saved chunk: 20230922T050521F745693-3UBusTWZdeWIc3CJ9gVwuM-4q1nPQeojg63PkOeaEsezb-1024.npz
train_Episode has 500 steps and return 317.3.
Starting evaluation at step 347500 Counter(347500) 347437
eval_Episode has 500 steps and return 320.6.
train_Episode has 500 steps and return 315.2.
Starting evaluation at step 348000 Counter(348000) 347937
Saved chunk: 20230922T050632F082062-6L2m0bfd1HAlEJmRvQ1NCY-4qKlbbfswywbuUwyBiBVrE-1024.npz
eval_Episode has 500 steps and return 318.0.
Saved chunk: 20230922T050642F850666-4q1nPQeojg63PkOeaEsezb-1lu6ciKTMndaPMlo3CeHlM-1024.npz
train_Episode has 500 steps and return 291.4.
Starting evaluation at step 348500 Counter(348500) 348437
eval_Episode has 500 steps and return 327.5.
train_Episode has 500 steps and return 281.3.
Starting evaluation at step 349000 Counter(349000) 348937
Saved chunk: 20230922T050751F390426-4qKlbbfswywbuUwyBiBVrE-3i2jFkPcHaGiPTm1Wv2f0f-1024.npz
eval_Episode has 500 steps and return 324.6.
Saved chunk: 20230922T050803F713846-1lu6ciKTMndaPMlo3CeHlM-67On4iOEM8yfQtRwtmaYGI-1024.npz
train_Episode has 500 steps and return 306.3.
Starting evaluation at step 349500 Counter(349500) 349437
eval_Episode has 500 steps and return 312.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 699002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 312.57 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 306.27 / episode/reward_rate 0.47 / train/action_mag 4.05 / train/action_max 4 / train/action_mean 0.08 / train/action_min -3.41 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 2.33 / train/adv_mag 0.48 / train/adv_max 0.39 / train/adv_mean 5.4e-4 / train/adv_min 
-0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.48 / train/extr_critic_max 234.48 / train/extr_critic_mean 225.52 / train/extr_critic_min 177.12 / train/extr_critic_std 9.92 / train/extr_return_normed_mag 1.55 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.61 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 234.68 / train/extr_return_raw_max 234.68 / train/extr_return_raw_mean 225.53 / train/extr_return_raw_min 
180.19 / train/extr_return_raw_std 9.9 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.93 / train/image_loss_std 0.92 / train/model_loss_mean 3.38 / 
train/model_loss_std 4.33 / train/model_opt_grad_norm 8.27 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.9 / train/policy_entropy_max 
3.56 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.05 / train/policy_logprob_mag 9.24 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.24 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.14 / train/post_ent_max 52.14 / train/post_ent_mean 42.01 / 
train/post_ent_min 22.39 / train/post_ent_std 4.57 / train/prior_ent_mag 78.75 / train/prior_ent_max 78.75 / train/prior_ent_mean 45.71 / train/prior_ent_min 29.53 / train/prior_ent_std 5.87 / train/rep_loss_mean 3.73 / train/rep_loss_std 6.05 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.43 / train/reward_rate 
0.35 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.67 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 6.46 / report/image_loss_mean 1.03 / report/image_loss_std 0.96 / report/model_loss_mean 3.54 / report/model_loss_std 4.59 / report/post_ent_mag 50.86 / report/post_ent_max 50.86 /
report/post_ent_mean 41.45 / report/post_ent_min 19.22 / report/post_ent_std 5.05 / report/prior_ent_mag 78.99 / report/prior_ent_max 78.99 / report/prior_ent_mean 45.2 / report/prior_ent_min 29.01 / report/prior_ent_std 6.21 / report/rep_loss_mean 3.85 / 
report/rep_loss_std 6.46 / report/reward_avg 0.42 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.42 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 4.32 / eval/dyn_loss_std 6.53 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.37 / eval/model_loss_mean 3.89 / eval/model_loss_std 4.98 / eval/post_ent_mag 50.88 / eval/post_ent_max 50.88 / eval/post_ent_mean 41.94 / 
eval/post_ent_min 24.25 / eval/post_ent_std 4.02 / eval/prior_ent_mag 78.99 / eval/prior_ent_max 78.99 / eval/prior_ent_mean 45.97 / eval/prior_ent_min 31.75 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 4.32 / eval/rep_loss_std 6.53 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.57 / eval/reward_rate 0.43 / 
replay/size 3.5e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.45 / timer/env.step_count 3790 / timer/env.step_total 19.57 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 1e-2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.46 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 
/ timer/dataset_train_count 1895 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1895 / timer/agent.train_total 244.09 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 318.5.
Starting evaluation at step 350000 Counter(350000) 349937
Saved chunk: 20230922T050910F509046-3i2jFkPcHaGiPTm1Wv2f0f-5QNkystgaM3tGegP07bmqK-1024.npz
eval_Episode has 500 steps and return 321.0.
train_Episode has 500 steps and return 290.8.
Saved chunk: 20230922T050924F387243-67On4iOEM8yfQtRwtmaYGI-6aQnSM6QiluH13o0wvL6iM-1024.npz
Starting evaluation at step 350500 Counter(350500) 350437
eval_Episode has 500 steps and return 325.3.
train_Episode has 500 steps and return 316.6.
Starting evaluation at step 351000 Counter(351000) 350937
eval_Episode has 500 steps and return 310.2.
Saved chunk: 20230922T051030F880159-5QNkystgaM3tGegP07bmqK-5cf4CCjIfQlBEINNlOmyn1-1024.npz
train_Episode has 500 steps and return 251.6.
Saved chunk: 20230922T051046F431746-6aQnSM6QiluH13o0wvL6iM-6zK17prFP91ELKzxZ65ljT-1024.npz
Starting evaluation at step 351500 Counter(351500) 351437
eval_Episode has 500 steps and return 324.9.
train_Episode has 500 steps and return 303.1.
Starting evaluation at step 352000 Counter(352000) 351937
eval_Episode has 500 steps and return 314.5.
Saved chunk: 20230922T051150F420992-5cf4CCjIfQlBEINNlOmyn1-0MVxCc0oMhSmD7ejvaTjd7-1024.npz
train_Episode has 500 steps and return 299.8.
Saved chunk: 20230922T051207F502176-6zK17prFP91ELKzxZ65ljT-3RHiJdlFK6kOJ4SGjE3wKK-1024.npz
Starting evaluation at step 352500 Counter(352500) 352437
eval_Episode has 500 steps and return 320.2.
train_Episode has 500 steps and return 310.3.
Starting evaluation at step 353000 Counter(353000) 352937
eval_Episode has 500 steps and return 332.0.
Saved chunk: 20230922T051309F793040-0MVxCc0oMhSmD7ejvaTjd7-5GWkwGWD6CR5WnOmouUo5P-1024.npz
train_Episode has 500 steps and return 318.0.
Saved chunk: 20230922T051328F451021-3RHiJdlFK6kOJ4SGjE3wKK-6yBWWyCGdrfQHJCrAd2V3b-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 706602 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 318.02 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 331.98 / eval_episode/reward_rate 0.48 / train/action_mag 3.97 / train/action_max 3.94 / train/action_mean 0.08 / train/action_min -3.36 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 3.89 / train/adv_mag 0.39 / train/adv_max 0.29 / train/adv_mean 3.9e-4
/ train/adv_min -0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.74 / train/dyn_loss_std 6.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.76 / train/extr_critic_max 234.76 / train/extr_critic_mean 226.4 / train/extr_critic_min 191.11 / train/extr_critic_std 7.91 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 234.97 / train/extr_return_raw_max 234.97 / train/extr_return_raw_mean 226.41 / train/extr_return_raw_min 
192.82 / train/extr_return_raw_std 7.91 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.92 / train/image_loss_std 0.93 / train/model_loss_mean 3.38 /
train/model_loss_std 4.35 / train/model_opt_grad_norm 8.45 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.76 / train/policy_entropy_max 
3.29 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.98 / train/policy_logprob_mag 9.11 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.62 / train/policy_logprob_min -9.11 / train/policy_logprob_std 1.73 / 
train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 42.04 / 
train/post_ent_min 22.59 / train/post_ent_std 4.47 / train/prior_ent_mag 78.72 / train/prior_ent_max 78.72 / train/prior_ent_mean 45.74 / train/prior_ent_min 29.84 / train/prior_ent_std 5.81 / train/rep_loss_mean 3.74 / train/rep_loss_std 6.06 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.65 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.97 / report/dyn_loss_std 6.02 / report/image_loss_mean 0.99 / report/image_loss_std 1.03 / report/model_loss_mean 3.58 / report/model_loss_std 4.42 / report/post_ent_mag 52.39 / report/post_ent_max 52.39 /
report/post_ent_mean 43.11 / report/post_ent_min 22.98 / report/post_ent_std 4.19 / report/prior_ent_mag 78.51 / report/prior_ent_max 78.51 / report/prior_ent_mean 47 / report/prior_ent_min 32.27 / report/prior_ent_std 5.2 / report/rep_loss_mean 3.97 / 
report/rep_loss_std 6.02 / report/reward_avg 0.41 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.31 / report/reward_max_data 1.95 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.41 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 9.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.8 / eval/dyn_loss_std 5.44 / eval/image_loss_mean 0.86 / eval/image_loss_std 0.98 / eval/model_loss_mean 3.45 / eval/model_loss_std 3.98 / eval/post_ent_mag 50.31 / eval/post_ent_max 50.31 / eval/post_ent_mean 
42.22 / eval/post_ent_min 24.18 / eval/post_ent_std 3.81 / eval/prior_ent_mag 78.51 / eval/prior_ent_max 78.51 / eval/prior_ent_mean 45.89 / eval/prior_ent_min 35.07 / eval/prior_ent_std 5.1 / eval/rep_loss_mean 3.8 / eval/rep_loss_std 5.44 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.64 / eval/reward_rate 0.5 / 
replay/size 3.5e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3800 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.97 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.3e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7307 / timer/agent.policy_total 16.44 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1900 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.83 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.33

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 353500 Counter(353500) 353437
eval_Episode has 500 steps and return 329.4.
train_Episode has 500 steps and return 244.5.
Starting evaluation at step 354000 Counter(354000) 353937
eval_Episode has 500 steps and return 332.0.
train_Episode has 500 steps and return 295.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T051429F057225-5GWkwGWD6CR5WnOmouUo5P-0000000000000000000000-1003.npz
Saved chunk: 20230922T051449F275006-6yBWWyCGdrfQHJCrAd2V3b-0000000000000000000000-1020.npz
Saved chunk: 20230922T051449F275006-6yBWWyCGdrfQHJCrAd2V3b-3t6dJVRTZT5Y24DY7vyQDK-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 354500 Counter(354500) 354437
Saved chunk: 20230922T051429F057225-5GWkwGWD6CR5WnOmouUo5P-2GdctHxQtCn46AB81ModUZ-1024.npz
eval_Episode has 500 steps and return 338.7.
train_Episode has 500 steps and return 309.3.
Starting evaluation at step 355000 Counter(355000) 354937
eval_Episode has 500 steps and return 326.0.
train_Episode has 500 steps and return 304.6.
Saved chunk: 20230922T051611F568618-3t6dJVRTZT5Y24DY7vyQDK-1qeDVqQ6U3ayRUB6CVeGPC-1024.npz
Starting evaluation at step 355500 Counter(355500) 355437
Saved chunk: 20230922T051626F082524-2GdctHxQtCn46AB81ModUZ-6qo4ATrz1GcrnuOUJ9w26d-1024.npz
eval_Episode has 500 steps and return 332.9.
train_Episode has 500 steps and return 283.0.
Starting evaluation at step 356000 Counter(356000) 355937
eval_Episode has 500 steps and return 301.1.
train_Episode has 500 steps and return 293.6.
Saved chunk: 20230922T051732F797142-1qeDVqQ6U3ayRUB6CVeGPC-4IVmCG7gSiFQM0jPXgbpBd-1024.npz
Starting evaluation at step 356500 Counter(356500) 356437
Saved chunk: 20230922T051745F500668-6qo4ATrz1GcrnuOUJ9w26d-3m92136Q3xbLijJmAz4PZ0-1024.npz
eval_Episode has 500 steps and return 318.9.
train_Episode has 500 steps and return 302.1.
Starting evaluation at step 357000 Counter(357000) 356937
eval_Episode has 500 steps and return 309.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 714098 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 309.53 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 302.13 / episode/reward_rate 0.44 / train/action_mag 4 / train/action_max 3.95 / train/action_mean 0.08 / train/action_min -3.33 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 5.44 / train/adv_mag 0.54 / train/adv_max 0.42 / train/adv_mean 2.4e-4 / train/adv_min 
-0.41 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.72 / train/dyn_loss_std 6.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 234.93 / train/extr_critic_max 234.93 / train/extr_critic_mean 226.17 / train/extr_critic_min 185.22 / train/extr_critic_std 9.07 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.13 / train/extr_return_raw_max 235.13 / train/extr_return_raw_mean 226.18 / train/extr_return_raw_min 
187.05 / train/extr_return_raw_std 9.1 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.92 / train/image_loss_std 0.91 / train/model_loss_mean 3.37 / 
train/model_loss_std 4.31 / train/model_opt_grad_norm 8.04 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.79 / train/policy_entropy_max 
3.19 / train/policy_entropy_mean -2.65 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.97 / train/policy_logprob_mag 9.24 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.65 / train/policy_logprob_min -9.24 / train/policy_logprob_std 1.73 / 
train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 51.93 / train/post_ent_max 51.93 / train/post_ent_mean 42.03 / 
train/post_ent_min 22.62 / train/post_ent_std 4.49 / train/prior_ent_mag 78.73 / train/prior_ent_max 78.73 / train/prior_ent_mean 45.73 / train/prior_ent_min 29.94 / train/prior_ent_std 5.81 / train/rep_loss_mean 3.72 / train/rep_loss_std 6.03 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.72 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 5.45 / report/image_loss_mean 0.79 / report/image_loss_std 0.71 / report/model_loss_mean 3.13 / report/model_loss_std 3.9 / report/post_ent_mag 52.13 / report/post_ent_max 52.13 / 
report/post_ent_mean 42.61 / report/post_ent_min 25.07 / report/post_ent_std 3.72 / report/prior_ent_mag 78.82 / report/prior_ent_max 78.82 / report/prior_ent_mean 46.08 / report/prior_ent_min 30.78 / report/prior_ent_std 5.29 / report/rep_loss_mean 3.49 / 
report/rep_loss_std 5.45 / report/reward_avg 0.53 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.53 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 6.5e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.5 / eval/dyn_loss_std 5.14 / eval/image_loss_mean 0.74 / eval/image_loss_std 0.69 / eval/model_loss_mean 3.16 / eval/model_loss_std 3.65 / eval/post_ent_mag 50.63 / eval/post_ent_max 50.63 / eval/post_ent_mean 
42.45 / eval/post_ent_min 26.38 / eval/post_ent_std 3.18 / eval/prior_ent_mag 78.82 / eval/prior_ent_max 78.82 / eval/prior_ent_mean 45.97 / eval/prior_ent_min 40 / eval/prior_ent_std 4.99 / eval/rep_loss_mean 3.5 / eval/rep_loss_std 5.14 / eval/reward_avg 0.7 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.7 / eval/reward_rate 0.51 / 
replay/size 3.6e5 / replay/inserts 3748 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3748 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.77 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7756 / timer/agent.policy_total 17.46 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1874 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1874 / timer/agent.train_total 241.44 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 24.99

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 322.8.
Saved chunk: 20230922T051853F574588-4IVmCG7gSiFQM0jPXgbpBd-7o2Jup6dACH0bM8yAMvZ5J-1024.npz
Starting evaluation at step 357500 Counter(357500) 357437
Saved chunk: 20230922T051904F672388-3m92136Q3xbLijJmAz4PZ0-3J3LMN47AO4PbQSYDtJDle-1024.npz
eval_Episode has 500 steps and return 332.8.
train_Episode has 500 steps and return 283.3.
Starting evaluation at step 358000 Counter(358000) 357937
eval_Episode has 500 steps and return 335.2.
train_Episode has 500 steps and return 302.7.
Starting evaluation at step 358500 Counter(358500) 358437
eval_Episode has 500 steps and return 322.8.
Saved chunk: 20230922T052015F355535-7o2Jup6dACH0bM8yAMvZ5J-5pYkXC8ePekFcIOFMmv2QJ-1024.npz
train_Episode has 500 steps and return 285.3.
Starting evaluation at step 359000 Counter(359000) 358937
eval_Episode has 500 steps and return 307.9.
Saved chunk: 20230922T052024F953816-3J3LMN47AO4PbQSYDtJDle-5rLvYUbqISEej4QLjwbWxb-1024.npz
train_Episode has 500 steps and return 315.4.
Saved chunk: 20230922T052136F500681-5pYkXC8ePekFcIOFMmv2QJ-4JVTIWSEJ8qBF9gF7qoGmd-1024.npz
Starting evaluation at step 359500 Counter(359500) 359437
Saved chunk: 20230922T052144F489072-5rLvYUbqISEej4QLjwbWxb-1SjiAw9rCT5olY4GqosDti-1024.npz
eval_Episode has 500 steps and return 333.3.
train_Episode has 500 steps and return 309.3.
Starting evaluation at step 360000 Counter(360000) 359937
eval_Episode has 500 steps and return 315.6.
train_Episode has 500 steps and return 301.5.
Saved chunk: 20230922T052314F732401-4JVTIWSEJ8qBF9gF7qoGmd-0ArMnJ7eR9d1s5doTlBSXq-1024.npz
Starting evaluation at step 360500 Counter(360500) 360437
Saved chunk: 20230922T052321F059524-1SjiAw9rCT5olY4GqosDti-5DzZ8coD5BaIjjPBkwGV3a-1024.npz
eval_Episode has 500 steps and return 323.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 721242 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 301.53 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 323.71 / eval_episode/reward_rate 0.48 / train/action_mag 3.95 / train/action_max 3.9 / train/action_mean 0.09 / train/action_min -3.4 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 5.32 / train/adv_mag 0.62 / train/adv_max 0.51 / train/adv_mean 2.4e-4 / train/adv_min 
-0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.72 / train/dyn_loss_std 6.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.05 / train/extr_critic_max 235.05 / train/extr_critic_mean 226.66 / train/extr_critic_min 183.58 / train/extr_critic_std 8.46 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.25 / train/extr_return_raw_max 235.25 / train/extr_return_raw_mean 226.67 / train/extr_return_raw_min 
188.44 / train/extr_return_raw_std 8.47 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.92 / train/image_loss_std 0.92 / train/model_loss_mean 3.37 /
train/model_loss_std 4.31 / train/model_opt_grad_norm 8.51 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.9 / train/policy_entropy_max 
3.44 / train/policy_entropy_mean -2.62 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1 / train/policy_logprob_mag 8.96 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -8.96 / train/policy_logprob_std 1.74 / 
train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.17 / train/post_ent_max 52.17 / train/post_ent_mean 42.04 / 
train/post_ent_min 22.6 / train/post_ent_std 4.45 / train/prior_ent_mag 78.61 / train/prior_ent_max 78.61 / train/prior_ent_mean 45.73 / train/prior_ent_min 29.81 / train/prior_ent_std 5.77 / train/rep_loss_mean 3.72 / train/rep_loss_std 6.01 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.64 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.55 / report/dyn_loss_std 6.03 / report/image_loss_mean 0.98 / report/image_loss_std 1.09 / report/model_loss_mean 3.27 / report/model_loss_std 4.43 / report/post_ent_mag 51.26 / report/post_ent_max 51.26 /
report/post_ent_mean 41 / report/post_ent_min 23.19 / report/post_ent_std 4.53 / report/prior_ent_mag 78.35 / report/prior_ent_max 78.35 / report/prior_ent_mean 44.51 / report/prior_ent_min 25.83 / report/prior_ent_std 5.89 / report/rep_loss_mean 3.55 / 
report/rep_loss_std 6.03 / report/reward_avg 0.33 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.3 / report/reward_max_data 1.96 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.33 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.53 / eval/dyn_loss_std 6.53 / eval/image_loss_mean 1.09 / eval/image_loss_std 1.48 / eval/model_loss_mean 4.09 / eval/model_loss_std 5.03 / eval/post_ent_mag 50.62 / eval/post_ent_max 50.62 / eval/post_ent_mean 
41.6 / eval/post_ent_min 23.52 / eval/post_ent_std 4.17 / eval/prior_ent_mag 78.35 / eval/prior_ent_max 78.35 / eval/prior_ent_mean 45.94 / eval/prior_ent_min 33.55 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 4.53 / eval/rep_loss_std 6.53 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.61 / eval/reward_rate 0.45 / 
replay/size 3.6e5 / replay/inserts 3572 / replay/samples 2.9e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3572 / timer/env.step_total 18.39 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.1e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 2.9e4 / timer/replay._sample_total 427.35 / timer/replay._sample_frac 1.42 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7079 / timer/agent.policy_total 15.91 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / 
timer/dataset_train_count 1786 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1786 / timer/agent.train_total 229.45 / 
timer/agent.train_frac 0.76 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 23.8

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 295.3.
Starting evaluation at step 361000 Counter(361000) 360937
eval_Episode has 500 steps and return 328.5.
train_Episode has 500 steps and return 306.7.
Saved chunk: 20230922T052434F951986-0ArMnJ7eR9d1s5doTlBSXq-2nAqWMNSmOLmrUYxhRccOs-1024.npz
Starting evaluation at step 361500 Counter(361500) 361437
Saved chunk: 20230922T052439F779095-5DzZ8coD5BaIjjPBkwGV3a-7jrbyeN6N2CvKHkrKWoPy4-1024.npz
eval_Episode has 500 steps and return 327.6.
train_Episode has 500 steps and return 307.0.
Starting evaluation at step 362000 Counter(362000) 361937
eval_Episode has 500 steps and return 344.4.
train_Episode has 500 steps and return 298.8.
Starting evaluation at step 362500 Counter(362500) 362437
Saved chunk: 20230922T052556F919513-2nAqWMNSmOLmrUYxhRccOs-53CAcNEauQOimieuJ0iQ3e-1024.npz
Saved chunk: 20230922T052600F147265-7jrbyeN6N2CvKHkrKWoPy4-6D5IyO82XsHdk9QS604elJ-1024.npz
eval_Episode has 500 steps and return 319.8.
train_Episode has 500 steps and return 300.8.
Starting evaluation at step 363000 Counter(363000) 362937
eval_Episode has 500 steps and return 322.4.
train_Episode has 500 steps and return 326.5.
Starting evaluation at step 363500 Counter(363500) 363437
Saved chunk: 20230922T052719F238015-6D5IyO82XsHdk9QS604elJ-7BqUZgpQvOO6qjabRYt40l-1024.npz
eval_Episode has 500 steps and return 322.3.
Saved chunk: 20230922T052717F607280-53CAcNEauQOimieuJ0iQ3e-59PDCMiVf9yVyBR9qp9vMH-1024.npz
train_Episode has 500 steps and return 274.2.
Starting evaluation at step 364000 Counter(364000) 363937
eval_Episode has 500 steps and return 320.6.
train_Episode has 500 steps and return 310.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 728878 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 310.25 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 320.63 / eval_episode/reward_rate 0.47 / train/action_mag 4.04 / train/action_max 4 / train/action_mean 0.08 / train/action_min -3.37 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 5.03 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean 2.9e-4 / train/adv_min 
-0.36 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.74 / train/dyn_loss_std 6.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.02 / train/extr_critic_max 235.02 / train/extr_critic_mean 226.86 / train/extr_critic_min 194.17 / train/extr_critic_std 7.3 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.22 / train/extr_return_raw_max 235.22 / train/extr_return_raw_mean 226.87 / train/extr_return_raw_min 
194.74 / train/extr_return_raw_std 7.33 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.93 / train/image_loss_std 0.92 / train/model_loss_mean 3.38 /
train/model_loss_std 4.33 / train/model_opt_grad_norm 8.21 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.81 / train/policy_entropy_max 
3.22 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.98 / train/policy_logprob_mag 8.97 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -8.97 / train/policy_logprob_std 1.72 / 
train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 1e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.06 / train/post_ent_max 52.06 / train/post_ent_mean 42.09 / 
train/post_ent_min 22.88 / train/post_ent_std 4.37 / train/prior_ent_mag 78.55 / train/prior_ent_max 78.55 / train/prior_ent_mean 45.8 / train/prior_ent_min 30.15 / train/prior_ent_std 5.7 / train/rep_loss_mean 3.74 / train/rep_loss_std 6.04 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.77 / report/dyn_loss_std 6.28 / report/image_loss_mean 0.92 / report/image_loss_std 0.97 / report/model_loss_mean 3.39 / report/model_loss_std 4.51 / report/post_ent_mag 53.57 / report/post_ent_max 53.57 /
report/post_ent_mean 42.36 / report/post_ent_min 20.05 / report/post_ent_std 4.36 / report/prior_ent_mag 78.67 / report/prior_ent_max 78.67 / report/prior_ent_mean 46.05 / report/prior_ent_min 29.35 / report/prior_ent_std 5.68 / report/rep_loss_mean 3.77 / 
report/rep_loss_std 6.28 / report/reward_avg 0.42 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 1.94 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 3.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.43 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.19 / eval/dyn_loss_std 8.64 / eval/image_loss_mean 1.54 / eval/image_loss_std 3 / eval/model_loss_mean 4.95 / eval/model_loss_std 7.6 / eval/post_ent_mag 50.49 / eval/post_ent_max 50.49 / eval/post_ent_mean 
41.43 / eval/post_ent_min 17.12 / eval/post_ent_std 5 / eval/prior_ent_mag 78.67 / eval/prior_ent_max 78.67 / eval/prior_ent_mean 45.87 / eval/prior_ent_min 30.12 / eval/prior_ent_std 5.72 / eval/rep_loss_mean 5.19 / eval/rep_loss_std 8.64 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.57 / eval/reward_rate 0.44 / 
replay/size 3.6e5 / replay/inserts 3818 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.13 / timer/env.step_count 3818 / timer/env.step_total 19.69 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 466.64 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8.7e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7325 / timer/agent.policy_total 16.37 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1909 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1909 / timer/agent.train_total 245.93 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.44

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 364500 Counter(364500) 364437
Saved chunk: 20230922T052838F215481-7BqUZgpQvOO6qjabRYt40l-7nptHlJAFxvQYRQnPgYJ2t-1024.npz
eval_Episode has 500 steps and return 330.1.
Saved chunk: 20230922T052841F575875-59PDCMiVf9yVyBR9qp9vMH-3v8wlakxkP4UpGTap0OWNY-1024.npz
train_Episode has 500 steps and return 316.1.
Starting evaluation at step 365000 Counter(365000) 364937
eval_Episode has 500 steps and return 316.0.
train_Episode has 500 steps and return 315.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 365500 Counter(365500) 365437
Saved chunk: 20230922T053003F060899-3v8wlakxkP4UpGTap0OWNY-0000000000000000000000-956.npz
Saved chunk: 20230922T052958F063878-7nptHlJAFxvQYRQnPgYJ2t-0000000000000000000000-761.npz
Saved chunk: 20230922T052958F063878-7nptHlJAFxvQYRQnPgYJ2t-1MLgyABOb9ExSm7ehGVWXJ-1024.npz
eval_Episode has 500 steps and return 329.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T053003F060899-3v8wlakxkP4UpGTap0OWNY-2S5A932M3fF6RNQqGf2Aa7-1024.npz
train_Episode has 500 steps and return 292.2.
Starting evaluation at step 366000 Counter(366000) 365937
eval_Episode has 500 steps and return 320.9.
train_Episode has 500 steps and return 299.3.
Starting evaluation at step 366500 Counter(366500) 366437
Saved chunk: 20230922T053117F531421-1MLgyABOb9ExSm7ehGVWXJ-5UQlB2T50cxJigc6nkJjoO-1024.npz
eval_Episode has 500 steps and return 326.6.
Saved chunk: 20230922T053124F203088-2S5A932M3fF6RNQqGf2Aa7-7IpXzssMuieKUkoTcjHDiB-1024.npz
train_Episode has 500 steps and return 290.3.
Starting evaluation at step 367000 Counter(367000) 366937
eval_Episode has 500 steps and return 313.1.
train_Episode has 500 steps and return 282.4.
Starting evaluation at step 367500 Counter(367500) 367437
Saved chunk: 20230922T053236F727915-5UQlB2T50cxJigc6nkJjoO-0jqpezEIEmaVKGe42fZ71S-1024.npz
eval_Episode has 500 steps and return 317.1.
Saved chunk: 20230922T053244F833186-7IpXzssMuieKUkoTcjHDiB-4vjedlqgN7xqNklwZLpLgM-1024.npz
train_Episode has 500 steps and return 293.0.
Starting evaluation at step 368000 Counter(368000) 367937
eval_Episode has 500 steps and return 291.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 736410 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 291 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 293.02 / episode/reward_rate 0.43 / train/action_mag 3.98 / train/action_max 3.96 / train/action_mean 0.08 / train/action_min -3.39 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 3.81 / train/adv_mag 0.41 / train/adv_max 0.3 / train/adv_mean 4.1e-4 / train/adv_min 
-0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.1e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.71 / train/dyn_loss_std 6.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 235.14 / train/extr_critic_max 235.14 / train/extr_critic_mean 226.55 / train/extr_critic_min 187.65 / train/extr_critic_std 9.02 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.35 / train/extr_return_raw_max 235.35 / train/extr_return_raw_mean 226.57 / train/extr_return_raw_min 
187.3 / train/extr_return_raw_std 9.04 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.91 / train/image_loss_std 0.91 / train/model_loss_mean 3.35 / 
train/model_loss_std 4.31 / train/model_opt_grad_norm 8.13 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.76 / train/policy_entropy_max 
3.06 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.98 / train/policy_logprob_mag 9.17 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.65 / train/policy_logprob_min -9.17 / train/policy_logprob_std 1.73 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 9.9e-5 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.26 / train/post_ent_max 52.26 / train/post_ent_mean 42.03 / 
train/post_ent_min 22.54 / train/post_ent_std 4.44 / train/prior_ent_mag 78.55 / train/prior_ent_max 78.55 / train/prior_ent_mean 45.72 / train/prior_ent_min 29.88 / train/prior_ent_std 5.76 / train/rep_loss_mean 3.71 / train/rep_loss_std 6.02 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.73 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.73 / report/dyn_loss_std 6.14 / report/image_loss_mean 0.92 / report/image_loss_std 0.71 / report/model_loss_mean 3.37 / report/model_loss_std 4.2 / report/post_ent_mag 52.39 / report/post_ent_max 52.39 / 
report/post_ent_mean 42.23 / report/post_ent_min 17.86 / report/post_ent_std 4.17 / report/prior_ent_mag 78.47 / report/prior_ent_max 78.47 / report/prior_ent_mean 46.01 / report/prior_ent_min 29.9 / report/prior_ent_std 5.55 / report/rep_loss_mean 3.73 / 
report/rep_loss_std 6.14 / report/reward_avg 0.47 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.48 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.05 / eval/dyn_loss_std 7.78 / eval/image_loss_mean 1.35 / eval/image_loss_std 2.46 / eval/model_loss_mean 4.65 / eval/model_loss_std 6.54 / eval/post_ent_mag 50.13 / eval/post_ent_max 50.13 / eval/post_ent_mean 
41.34 / eval/post_ent_min 19.14 / eval/post_ent_std 4.5 / eval/prior_ent_mag 78.47 / eval/prior_ent_max 78.47 / eval/prior_ent_mean 45.8 / eval/prior_ent_min 30.91 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 5.05 / eval/rep_loss_std 7.78 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.57 / eval/reward_rate 0.44 / 
replay/size 3.7e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3766 / timer/env.step_total 19.43 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.68 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-4 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.51 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1883 / timer/agent.train_total 242.76 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 305.8.
Starting evaluation at step 368500 Counter(368500) 368437
Saved chunk: 20230922T053355F608891-0jqpezEIEmaVKGe42fZ71S-1TERl8FoHkb0HwRBq5SRdV-1024.npz
eval_Episode has 500 steps and return 321.7.
Saved chunk: 20230922T053405F285887-4vjedlqgN7xqNklwZLpLgM-4B0aJovlugieRpWjTnDIPb-1024.npz
train_Episode has 500 steps and return 300.4.
Starting evaluation at step 369000 Counter(369000) 368937
eval_Episode has 500 steps and return 324.4.
train_Episode has 500 steps and return 317.3.
Starting evaluation at step 369500 Counter(369500) 369437
Saved chunk: 20230922T053515F691604-1TERl8FoHkb0HwRBq5SRdV-6pgaEhdkRfFO0wrXl1Hoxw-1024.npz
eval_Episode has 500 steps and return 317.5.
Saved chunk: 20230922T053527F038497-4B0aJovlugieRpWjTnDIPb-0S0yMZDMw4TqDWkuVHfCgI-1024.npz
train_Episode has 500 steps and return 294.2.
Starting evaluation at step 370000 Counter(370000) 369937
eval_Episode has 500 steps and return 304.1.
train_Episode has 500 steps and return 284.0.
Starting evaluation at step 370500 Counter(370500) 370437
Saved chunk: 20230922T053635F048895-6pgaEhdkRfFO0wrXl1Hoxw-2eKMoUL1CshsRpC8vsCWyx-1024.npz
eval_Episode has 500 steps and return 313.0.
Saved chunk: 20230922T053647F979961-0S0yMZDMw4TqDWkuVHfCgI-6p41dTTBCMTMRa73jcRSgv-1024.npz
train_Episode has 500 steps and return 289.6.
Starting evaluation at step 371000 Counter(371000) 370937
eval_Episode has 500 steps and return 318.6.
train_Episode has 500 steps and return 318.7.
Starting evaluation at step 371500 Counter(371500) 371437
Saved chunk: 20230922T053754F383649-2eKMoUL1CshsRpC8vsCWyx-0cinGOArZnA8ZvI5VOSFg0-1024.npz
eval_Episode has 500 steps and return 321.8.
Saved chunk: 20230922T053808F836343-6p41dTTBCMTMRa73jcRSgv-5yNDXVRCUafTLAl9pfCsi8-1024.npz
train_Episode has 500 steps and return 294.6.
Starting evaluation at step 372000 Counter(372000) 371937
eval_Episode has 500 steps and return 310.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 744002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 294.56 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 310.51 / eval_episode/reward_rate 0.44 / train/action_mag 3.96 / train/action_max 3.93 / train/action_mean 0.08 / train/action_min -3.4 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 5.13 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean 2.7e-4 / train/adv_min 
-0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.74 / train/dyn_loss_std 6.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 235.36 / train/extr_critic_max 235.36 / train/extr_critic_mean 226.78 / train/extr_critic_min 188.86 / train/extr_critic_std 8.41 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.57 / train/extr_return_raw_max 235.57 / train/extr_return_raw_mean 226.79 / train/extr_return_raw_min 
190.12 / train/extr_return_raw_std 8.43 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.46 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.93 / train/image_loss_std 0.94 / train/model_loss_mean 3.38 /
train/model_loss_std 4.33 / train/model_opt_grad_norm 8.19 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.71 / train/policy_entropy_max 
3.12 / train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.99 / train/policy_logprob_mag 8.89 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.62 / train/policy_logprob_min -8.89 / train/policy_logprob_std 1.73 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 9.5e-5 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.42 / train/post_ent_max 52.42 / train/post_ent_mean 42 / 
train/post_ent_min 22.52 / train/post_ent_std 4.48 / train/prior_ent_mag 78.46 / train/prior_ent_max 78.46 / train/prior_ent_mean 45.7 / train/prior_ent_min 29.87 / train/prior_ent_std 5.77 / train/rep_loss_mean 3.74 / train/rep_loss_std 6.03 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.21 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.08 / report/image_loss_mean 1.02 / report/image_loss_std 1.04 / report/model_loss_mean 3.44 / report/model_loss_std 4.4 / report/post_ent_mag 54.51 / report/post_ent_max 54.51 / 
report/post_ent_mean 42.04 / report/post_ent_min 26.26 / report/post_ent_std 4.33 / report/prior_ent_mag 78.42 / report/prior_ent_max 78.42 / report/prior_ent_mean 45.7 / report/prior_ent_min 29.58 / report/prior_ent_std 5.75 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.08 / report/reward_avg 0.38 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 1.96 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 2.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.38 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.19 / eval/dyn_loss_std 6.08 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.41 / eval/model_loss_mean 3.79 / eval/model_loss_std 4.7 / eval/post_ent_mag 50.21 / eval/post_ent_max 50.21 / eval/post_ent_mean 
41.84 / eval/post_ent_min 21.19 / eval/post_ent_std 4.02 / eval/prior_ent_mag 78.42 / eval/prior_ent_max 78.42 / eval/prior_ent_mean 45.78 / eval/prior_ent_min 31.96 / eval/prior_ent_std 5.16 / eval/rep_loss_mean 4.19 / eval/rep_loss_std 6.08 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 3.7e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.81 / timer/env.step_count 3796 / timer/env.step_total 19.61 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.01 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.9e-4 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 17.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / 
timer/dataset_train_count 1898 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1898 / timer/agent.train_total 244.5 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 312.8.
Starting evaluation at step 372500 Counter(372500) 372437
eval_Episode has 500 steps and return 290.1.
Saved chunk: 20230922T053913F533053-0cinGOArZnA8ZvI5VOSFg0-6TKGdFkt2DCK2QbPQpwJ2w-1024.npz
Saved chunk: 20230922T053929F578259-5yNDXVRCUafTLAl9pfCsi8-5Xt0mfT9re6Tv311yA8sp4-1024.npz
train_Episode has 500 steps and return 277.8.
Starting evaluation at step 373000 Counter(373000) 372937
eval_Episode has 500 steps and return 320.7.
train_Episode has 500 steps and return 309.1.
Starting evaluation at step 373500 Counter(373500) 373437
eval_Episode has 500 steps and return 310.8.
Saved chunk: 20230922T054034F008106-6TKGdFkt2DCK2QbPQpwJ2w-6cy2q6b2XyistF9vgZdZOO-1024.npz
train_Episode has 500 steps and return 309.0.
Saved chunk: 20230922T054051F709356-5Xt0mfT9re6Tv311yA8sp4-5waOQOVVbqrKSg6zAvN5BG-1024.npz
Starting evaluation at step 374000 Counter(374000) 373937
eval_Episode has 500 steps and return 288.4.
train_Episode has 500 steps and return 318.5.
Starting evaluation at step 374500 Counter(374500) 374437
eval_Episode has 500 steps and return 334.1.
Saved chunk: 20230922T054153F414325-6cy2q6b2XyistF9vgZdZOO-78mra5zC1tnvCnflAcc3Gi-1024.npz
train_Episode has 500 steps and return 300.5.
Saved chunk: 20230922T054212F649569-5waOQOVVbqrKSg6zAvN5BG-1p4Xa8AJksjBavmzWap42x-1024.npz
Starting evaluation at step 375000 Counter(375000) 374937
eval_Episode has 500 steps and return 322.1.
train_Episode has 500 steps and return 285.7.
Starting evaluation at step 375500 Counter(375500) 375437
eval_Episode has 500 steps and return 308.0.
Saved chunk: 20230922T054312F717609-78mra5zC1tnvCnflAcc3Gi-3jxtw1ecTSqWBa6uGCniOT-1024.npz
train_Episode has 500 steps and return 293.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 751610 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.19 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 307.98 / eval_episode/reward_rate 0.48 / train/action_mag 4.04 / train/action_max 3.99 / train/action_mean 0.09 / train/action_min -3.46 / 
train/action_std 0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 6.16 / train/adv_mag 0.41 / train/adv_max 0.31 / train/adv_mean 1.6e-4
/ train/adv_min -0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.45 / train/extr_critic_max 235.45 / train/extr_critic_mean 227.05 / train/extr_critic_min 190.37 / train/extr_critic_std 8.33 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.63 / train/extr_return_raw_max 235.63 / train/extr_return_raw_mean 227.06 / train/extr_return_raw_min 
190.31 / train/extr_return_raw_std 8.35 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.91 / train/image_loss_std 0.91 / train/model_loss_mean 3.34 /
train/model_loss_std 4.27 / train/model_opt_grad_norm 8.08 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.72 / train/policy_entropy_max 
3.06 / train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.98 / train/policy_logprob_mag 9.07 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.63 / train/policy_logprob_min -9.07 / train/policy_logprob_std 1.73 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 8.7e-5 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.23 / train/post_ent_max 52.23 / train/post_ent_mean 42.08 / 
train/post_ent_min 22.6 / train/post_ent_std 4.36 / train/prior_ent_mag 78.41 / train/prior_ent_max 78.41 / train/prior_ent_mean 45.75 / train/prior_ent_min 30.08 / train/prior_ent_std 5.66 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.96 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.8 / report/dyn_loss_std 6.41 / report/image_loss_mean 1 / report/image_loss_std 1.01 / report/model_loss_mean 3.49 / report/model_loss_std 4.63 / report/post_ent_mag 51.58 / report/post_ent_max 51.58 / 
report/post_ent_mean 41.87 / report/post_ent_min 23.74 / report/post_ent_std 4.72 / report/prior_ent_mag 78.11 / report/prior_ent_max 78.11 / report/prior_ent_mean 45.51 / report/prior_ent_min 29.01 / report/prior_ent_std 5.81 / report/rep_loss_mean 3.8 / 
report/rep_loss_std 6.41 / report/reward_avg 0.43 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.43 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 9.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.25 / eval/dyn_loss_std 6.56 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.75 / eval/model_loss_mean 3.89 / eval/model_loss_std 5.15 / eval/post_ent_mag 51.17 / eval/post_ent_max 51.17 / eval/post_ent_mean 
41.95 / eval/post_ent_min 22.83 / eval/post_ent_std 3.92 / eval/prior_ent_mag 78.11 / eval/prior_ent_max 78.11 / eval/prior_ent_mean 45.94 / eval/prior_ent_min 34.22 / eval/prior_ent_std 5.37 / eval/rep_loss_mean 4.25 / eval/rep_loss_std 6.56 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.39 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 3.8e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3804 / timer/env.step_total 19.78 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.4 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.41 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9e-3 / 
timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1902 / timer/agent.train_total 245 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T054333F488309-1p4Xa8AJksjBavmzWap42x-1cPQRxZh6QXGuuIKV6cxyw-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 376000 Counter(376000) 375937
eval_Episode has 500 steps and return 326.5.
train_Episode has 500 steps and return 310.9.
Starting evaluation at step 376500 Counter(376500) 376437
eval_Episode has 500 steps and return 329.1.
train_Episode has 500 steps and return 309.3.
Saved chunk: 20230922T054454F633654-1cPQRxZh6QXGuuIKV6cxyw-6cZtQXfALc68iaBITtCUs8-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T054616F479536-6cZtQXfALc68iaBITtCUs8-0000000000000000000000-68.npz
Saved chunk: 20230922T054431F857583-3jxtw1ecTSqWBa6uGCniOT-0000000000000000000000-1020.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 377000 Counter(377000) 376937
Saved chunk: 20230922T054431F857583-3jxtw1ecTSqWBa6uGCniOT-0NWgIoMQLaxxdVbOXmCH1H-1024.npz
eval_Episode has 500 steps and return 286.4.
train_Episode has 500 steps and return 295.5.
Starting evaluation at step 377500 Counter(377500) 377437
eval_Episode has 500 steps and return 319.6.
train_Episode has 500 steps and return 265.0.
Saved chunk: 20230922T054616F479536-6cZtQXfALc68iaBITtCUs8-1x6ZzzahlA22XQ43tJLdTo-1024.npz
Starting evaluation at step 378000 Counter(378000) 377937
Saved chunk: 20230922T054628F888801-0NWgIoMQLaxxdVbOXmCH1H-6U6PQt58HNmWEiFyFngO3z-1024.npz
eval_Episode has 500 steps and return 326.0.
train_Episode has 500 steps and return 312.5.
Starting evaluation at step 378500 Counter(378500) 378437
eval_Episode has 500 steps and return 304.9.
train_Episode has 500 steps and return 307.6.
Saved chunk: 20230922T054737F927906-1x6ZzzahlA22XQ43tJLdTo-0DL4Dps3z4JeMgz9jo29hv-1024.npz
Starting evaluation at step 379000 Counter(379000) 378937
Saved chunk: 20230922T054748F502414-6U6PQt58HNmWEiFyFngO3z-7LA8tV9ZVRbgQtP9il34np-1024.npz
eval_Episode has 500 steps and return 315.2.
train_Episode has 500 steps and return 298.9.
Starting evaluation at step 379500 Counter(379500) 379437
eval_Episode has 500 steps and return 326.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 759102 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 326.79 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 298.85 / episode/reward_rate 0.44 / train/action_mag 4.06 / train/action_max 4.01 / train/action_mean 0.08 / train/action_min -3.48 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 3.13 / train/adv_mag 0.41 / train/adv_max 0.32 / train/adv_mean 4.5e-4
/ train/adv_min -0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.48 / train/extr_critic_max 235.48 / train/extr_critic_mean 226.95 / train/extr_critic_min 189.23 / train/extr_critic_std 8.74 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.48 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.68 / train/extr_return_raw_max 235.68 / train/extr_return_raw_mean 226.96 / train/extr_return_raw_min 
189.76 / train/extr_return_raw_std 8.77 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.91 / train/image_loss_std 0.9 / train/model_loss_mean 3.34 / 
train/model_loss_std 4.29 / train/model_opt_grad_norm 8.23 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.15 / train/policy_entropy_max 
3.78 / train/policy_entropy_mean -2.55 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.55 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.55 / train/policy_logprob_min -9.55 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 7.5e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.31 / train/post_ent_max 52.31 / train/post_ent_mean 41.97 / 
train/post_ent_min 22.51 / train/post_ent_std 4.5 / train/prior_ent_mag 78.43 / train/prior_ent_max 78.43 / train/prior_ent_mean 45.63 / train/prior_ent_min 29.69 / train/prior_ent_std 5.83 / train/rep_loss_mean 3.7 / train/rep_loss_std 6 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.36 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.67 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 6.45 / report/image_loss_mean 0.91 / report/image_loss_std 0.88 / report/model_loss_mean 3.43 / report/model_loss_std 4.55 / report/post_ent_mag 54.6 / report/post_ent_max 54.6 / 
report/post_ent_mean 42.33 / report/post_ent_min 25.12 / report/post_ent_std 4.19 / report/prior_ent_mag 78.62 / report/prior_ent_max 78.62 / report/prior_ent_mean 46.24 / report/prior_ent_min 30.52 / report/prior_ent_std 5.54 / report/rep_loss_mean 3.84 / 
report/rep_loss_std 6.45 / report/reward_avg 0.42 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.32 / report/reward_max_data 1.95 / report/reward_max_pred 1.92 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.42 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.98 / eval/dyn_loss_std 7.08 / eval/image_loss_mean 1.45 / eval/image_loss_std 2.58 / eval/model_loss_mean 4.75 / eval/model_loss_std 6.34 / eval/post_ent_mag 51.06 / eval/post_ent_max 51.06 / eval/post_ent_mean 
41.78 / eval/post_ent_min 24.59 / eval/post_ent_std 3.66 / eval/prior_ent_mag 78.62 / eval/prior_ent_max 78.62 / eval/prior_ent_mean 45.78 / eval/prior_ent_min 34.54 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 4.98 / eval/rep_loss_std 7.08 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.47 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.63 / eval/reward_rate 0.48 / 
replay/size 3.8e5 / replay/inserts 3746 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3746 / timer/env.step_total 19.64 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.71 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7754 / timer/agent.policy_total 17.59 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1873 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1873 / timer/agent.train_total 241.42 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / 
timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 24.97

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 311.6.
Saved chunk: 20230922T054858F764571-0DL4Dps3z4JeMgz9jo29hv-05prV0F9LrjZ8tGh9A9O3n-1024.npz
Starting evaluation at step 380000 Counter(380000) 379937
Saved chunk: 20230922T054907F730786-7LA8tV9ZVRbgQtP9il34np-2vB3FYhEYd8Po1BloojEvo-1024.npz
eval_Episode has 500 steps and return 328.1.
train_Episode has 500 steps and return 269.8.
Starting evaluation at step 380500 Counter(380500) 380437
eval_Episode has 500 steps and return 319.0.
train_Episode has 500 steps and return 325.2.
Saved chunk: 20230922T055020F583259-05prV0F9LrjZ8tGh9A9O3n-7KI3WjZ8MeayZ5sQJPyiTq-1024.npz
Starting evaluation at step 381000 Counter(381000) 380937
Saved chunk: 20230922T055028F035087-2vB3FYhEYd8Po1BloojEvo-4zXxqZLaYAd9DS7iPDFEKB-1024.npz
eval_Episode has 500 steps and return 339.0.
train_Episode has 500 steps and return 299.9.
Starting evaluation at step 381500 Counter(381500) 381437
eval_Episode has 500 steps and return 319.5.
train_Episode has 500 steps and return 305.2.
Saved chunk: 20230922T055141F673307-7KI3WjZ8MeayZ5sQJPyiTq-6TCC9clBNxmFAWX85JhYjO-1024.npz
Starting evaluation at step 382000 Counter(382000) 381937
Saved chunk: 20230922T055147F528596-4zXxqZLaYAd9DS7iPDFEKB-7I8DB5qB9luDN2KOYVSHDA-1024.npz
eval_Episode has 500 steps and return 336.9.
train_Episode has 500 steps and return 301.5.
Starting evaluation at step 382500 Counter(382500) 382437
eval_Episode has 500 steps and return 331.5.
train_Episode has 500 steps and return 290.2.
Saved chunk: 20230922T055302F511397-6TCC9clBNxmFAWX85JhYjO-3ZmcG2mpXnxNuRX40QJKnL-1024.npz
Starting evaluation at step 383000 Counter(383000) 382937
Saved chunk: 20230922T055306F761862-7I8DB5qB9luDN2KOYVSHDA-6ToqQe2ZsJRkLmVIZH5oEN-1024.npz
eval_Episode has 500 steps and return 305.9.
train_Episode has 500 steps and return 288.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 766714 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 288.39 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 305.94 / eval_episode/reward_rate 0.45 / train/action_mag 4.03 / train/action_max 3.95 / train/action_mean 0.09 / train/action_min -3.5 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 5.21 / train/adv_mag 0.53 / train/adv_max 0.43 / train/adv_mean 2.5e-4 / train/adv_min 
-0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.67 / train/extr_critic_max 235.67 / train/extr_critic_mean 227.29 / train/extr_critic_min 186.52 / train/extr_critic_std 8.64 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.87 / train/extr_return_raw_max 235.87 / train/extr_return_raw_mean 227.29 / train/extr_return_raw_min 
188.45 / train/extr_return_raw_std 8.66 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.92 / train/image_loss_std 0.93 / train/model_loss_mean 3.38 /
train/model_loss_std 4.33 / train/model_opt_grad_norm 8.46 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.44 / train/policy_entropy_max 
4.2 / train/policy_entropy_mean -2.59 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.77 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.59 / train/policy_logprob_min -9.77 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 7.1e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.36 / train/post_ent_max 52.36 / train/post_ent_mean 42.06 / 
train/post_ent_min 22.82 / train/post_ent_std 4.41 / train/prior_ent_mag 78.33 / train/prior_ent_max 78.33 / train/prior_ent_mean 45.75 / train/prior_ent_min 30.05 / train/prior_ent_std 5.7 / train/rep_loss_mean 3.73 / train/rep_loss_std 6.02 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.68 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 6.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 6.49 / report/image_loss_mean 1.01 / report/image_loss_std 1.1 / report/model_loss_mean 3.46 / report/model_loss_std 4.77 / report/post_ent_mag 54.22 / report/post_ent_max 54.22 / 
report/post_ent_mean 42.38 / report/post_ent_min 19.34 / report/post_ent_std 4.45 / report/prior_ent_mag 78.38 / report/prior_ent_max 78.38 / report/prior_ent_mean 46.14 / report/prior_ent_min 27.71 / report/prior_ent_std 5.51 / report/rep_loss_mean 3.78 / 
report/rep_loss_std 6.49 / report/reward_avg 0.36 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.32 / report/reward_max_data 1.93 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 8.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.36 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 9.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.49 / eval/dyn_loss_std 6.83 / eval/image_loss_mean 1.21 / eval/image_loss_std 2.26 / eval/model_loss_mean 4.18 / eval/model_loss_std 5.84 / eval/post_ent_mag 50.81 / eval/post_ent_max 50.81 / eval/post_ent_mean 
41.58 / eval/post_ent_min 17.28 / eval/post_ent_std 4.4 / eval/prior_ent_mag 78.38 / eval/prior_ent_max 78.38 / eval/prior_ent_mean 45.7 / eval/prior_ent_min 31.2 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 4.49 / eval/rep_loss_std 6.83 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.63 / eval/reward_rate 0.47 / 
replay/size 3.8e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3806 / timer/env.step_total 19.84 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.8 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.46 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1903 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.84 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 383500 Counter(383500) 383437
eval_Episode has 500 steps and return 328.3.
train_Episode has 500 steps and return 290.4.
Starting evaluation at step 384000 Counter(384000) 383937
Saved chunk: 20230922T055423F144476-3ZmcG2mpXnxNuRX40QJKnL-0FMIZkpdYeeVPKQVUg67GV-1024.npz
Saved chunk: 20230922T055425F832031-6ToqQe2ZsJRkLmVIZH5oEN-50DJKaQdjz3giFNqmngzfx-1024.npz
eval_Episode has 500 steps and return 316.1.
train_Episode has 500 steps and return 319.8.
Starting evaluation at step 384500 Counter(384500) 384437
eval_Episode has 500 steps and return 316.0.
train_Episode has 500 steps and return 315.0.
Starting evaluation at step 385000 Counter(385000) 384937
Saved chunk: 20230922T055546F297921-50DJKaQdjz3giFNqmngzfx-6MDG5fY4rfiaYSotc24KIi-1024.npz
eval_Episode has 500 steps and return 333.4.
Saved chunk: 20230922T055545F182129-0FMIZkpdYeeVPKQVUg67GV-1ke75LKCjoJTUko3eQwewN-1024.npz
train_Episode has 500 steps and return 319.3.
Starting evaluation at step 385500 Counter(385500) 385437
eval_Episode has 500 steps and return 316.6.
train_Episode has 500 steps and return 320.7.
Starting evaluation at step 386000 Counter(386000) 385937
Saved chunk: 20230922T055705F762332-6MDG5fY4rfiaYSotc24KIi-48DAq3DiQ4kzVNuLOR21bl-1024.npz
eval_Episode has 500 steps and return 331.1.
Saved chunk: 20230922T055709F774801-1ke75LKCjoJTUko3eQwewN-5N5a01wHyiHXceWpqx6fne-1024.npz
train_Episode has 500 steps and return 311.6.
Starting evaluation at step 386500 Counter(386500) 386437
eval_Episode has 500 steps and return 320.1.
train_Episode has 500 steps and return 303.7.
Starting evaluation at step 387000 Counter(387000) 386937
Saved chunk: 20230922T055824F944651-48DAq3DiQ4kzVNuLOR21bl-6gpVEfJKKp1hV1aQThqOGn-1024.npz
eval_Episode has 500 steps and return 326.8.
Saved chunk: 20230922T055830F534781-5N5a01wHyiHXceWpqx6fne-4Z6Sm8AnMU7YJg57KuvCiG-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 774224 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 326.8 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 303.71 / episode/reward_rate 0.44 / train/action_mag 4.02 / train/action_max 3.96 / train/action_mean 0.09 / train/action_min -3.53 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 4.77 / train/adv_mag 0.49 / train/adv_max 0.36 / train/adv_mean 3e-4 / train/adv_min 
-0.43 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.97 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.71 / train/extr_critic_max 235.71 / train/extr_critic_mean 227.37 / train/extr_critic_min 187.97 / train/extr_critic_std 8.33 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 235.9 / train/extr_return_raw_max 235.9 / train/extr_return_raw_mean 227.37 / train/extr_return_raw_min 
189.53 / train/extr_return_raw_std 8.35 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.9 / train/image_loss_std 0.9 / train/model_loss_mean 3.34 / 
train/model_loss_std 4.28 / train/model_opt_grad_norm 8.01 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.33 / train/policy_entropy_max 
3.97 / train/policy_entropy_mean -2.6 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.85 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.6 / train/policy_logprob_min -9.85 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 7e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.12 / train/post_ent_max 52.12 / train/post_ent_mean 42.06 / 
train/post_ent_min 22.89 / train/post_ent_std 4.32 / train/prior_ent_mag 78.33 / train/prior_ent_max 78.33 / train/prior_ent_mean 45.72 / train/prior_ent_min 30.47 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.97 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.69 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 5.88 / report/image_loss_mean 0.84 / report/image_loss_std 0.81 / report/model_loss_mean 3.33 / report/model_loss_std 4.16 / report/post_ent_mag 51.35 / report/post_ent_max 51.35 /
report/post_ent_mean 42.35 / report/post_ent_min 21.2 / report/post_ent_std 3.87 / report/prior_ent_mag 78.2 / report/prior_ent_max 78.2 / report/prior_ent_mean 46.16 / report/prior_ent_min 31.27 / report/prior_ent_std 5.29 / report/rep_loss_mean 3.76 / 
report/rep_loss_std 5.88 / report/reward_avg 0.51 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.34 / report/reward_max_data 1.95 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 3.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.51 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.22 / eval/dyn_loss_std 6.51 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.35 / eval/model_loss_mean 3.78 / eval/model_loss_std 4.9 / eval/post_ent_mag 50.81 / eval/post_ent_max 50.81 / eval/post_ent_mean 
41.72 / eval/post_ent_min 20.69 / eval/post_ent_std 4 / eval/prior_ent_mag 78.2 / eval/prior_ent_max 78.2 / eval/prior_ent_mean 45.79 / eval/prior_ent_min 29.28 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 4.22 / eval/rep_loss_std 6.51 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.6 / eval/reward_rate 0.46 / 
replay/size 3.9e5 / replay/inserts 3755 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3755 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.38 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7763 / timer/agent.policy_total 17.34 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 
/ timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.86 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 310.9.
Starting evaluation at step 387500 Counter(387500) 387437
eval_Episode has 500 steps and return 333.9.
train_Episode has 500 steps and return 319.0.
Starting evaluation at step 388000 Counter(388000) 387937
Saved chunk: 20230922T055944F099417-6gpVEfJKKp1hV1aQThqOGn-3VHiArXWYehwiBmln4iy07-1024.npz
eval_Episode has 500 steps and return 329.6.
Saved chunk: 20230922T055951F306163-4Z6Sm8AnMU7YJg57KuvCiG-15yYaFeJtnI9dwDMRVNIAI-1024.npz
train_Episode has 500 steps and return 295.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T060104F671987-3VHiArXWYehwiBmln4iy07-0000000000000000000000-255.npz
Saved chunk: 20230922T060113F446107-15yYaFeJtnI9dwDMRVNIAI-0000000000000000000000-204.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 388500 Counter(388500) 388437
eval_Episode has 500 steps and return 320.0.
train_Episode has 500 steps and return 287.6.
Starting evaluation at step 389000 Counter(389000) 388937
Saved chunk: 20230922T060104F671987-3VHiArXWYehwiBmln4iy07-1MlVlGqQCADYbqjLTEeXVA-1024.npz
eval_Episode has 500 steps and return 328.0.
Saved chunk: 20230922T060113F446107-15yYaFeJtnI9dwDMRVNIAI-3vVFBH1rMADkoy4Pgv1doH-1024.npz
train_Episode has 500 steps and return 311.7.
Starting evaluation at step 389500 Counter(389500) 389437
eval_Episode has 500 steps and return 333.2.
train_Episode has 500 steps and return 298.5.
Starting evaluation at step 390000 Counter(390000) 389937
Saved chunk: 20230922T060224F265503-1MlVlGqQCADYbqjLTEeXVA-3oVJveymxNxYOPTO6XUmv0-1024.npz
eval_Episode has 500 steps and return 321.6.
Saved chunk: 20230922T060234F585824-3vVFBH1rMADkoy4Pgv1doH-2IWxEaAH02w8UUapor4Enh-1024.npz
train_Episode has 500 steps and return 298.0.
Starting evaluation at step 390500 Counter(390500) 390437
eval_Episode has 500 steps and return 330.0.
train_Episode has 500 steps and return 255.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 781830 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 255.81 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 330.02 / eval_episode/reward_rate 0.47 / train/action_mag 4.06 / train/action_max 3.99 / train/action_mean 0.09 / train/action_min -3.52 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss 4.78 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean 2.8e-4 
/ train/adv_min -0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.69 / train/dyn_loss_std 5.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 235.93 / train/extr_critic_max 235.93 / train/extr_critic_mean 227.22 / train/extr_critic_min 185.21 / train/extr_critic_std 8.94 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.12 / train/extr_return_raw_max 236.12 / train/extr_return_raw_mean 227.23 / train/extr_return_raw_min 
188.99 / train/extr_return_raw_std 8.95 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.91 / train/image_loss_std 0.92 / train/model_loss_mean 3.34 /
train/model_loss_std 4.29 / train/model_opt_grad_norm 8.07 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.48 / train/policy_entropy_max 
4.18 / train/policy_entropy_mean -2.55 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 9.69 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.55 / train/policy_logprob_min -9.69 / train/policy_logprob_std 1.85 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 7.2e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.25 / train/post_ent_max 52.25 / train/post_ent_mean 42.01 / 
train/post_ent_min 22.65 / train/post_ent_std 4.4 / train/prior_ent_mag 78.25 / train/prior_ent_max 78.25 / train/prior_ent_mean 45.66 / train/prior_ent_min 30.06 / train/prior_ent_std 5.74 / train/rep_loss_mean 3.69 / train/rep_loss_std 5.98 / train/reward_avg 0.44 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.44 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.67 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.01 / report/image_loss_mean 0.83 / report/image_loss_std 0.7 / report/model_loss_mean 3.3 / report/model_loss_std 4.19 / report/post_ent_mag 51.57 / report/post_ent_max 51.57 / 
report/post_ent_mean 42.56 / report/post_ent_min 25.88 / report/post_ent_std 3.93 / report/prior_ent_mag 78.26 / report/prior_ent_max 78.26 / report/prior_ent_mean 46.32 / report/prior_ent_min 35.85 / report/prior_ent_std 5.23 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.01 / report/reward_avg 0.51 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.32 / report/reward_max_data 1.96 / report/reward_max_pred 1.93 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.52 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.02 / eval/dyn_loss_std 6.14 / eval/image_loss_mean 0.87 / eval/image_loss_std 1.01 / eval/model_loss_mean 3.58 / eval/model_loss_std 4.5 / eval/post_ent_mag 51.83 / eval/post_ent_max 51.83 / eval/post_ent_mean 
42.07 / eval/post_ent_min 25.96 / eval/post_ent_std 3.52 / eval/prior_ent_mag 78.26 / eval/prior_ent_max 78.26 / eval/prior_ent_mean 45.92 / eval/prior_ent_min 35.89 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 4.02 / eval/rep_loss_std 6.14 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.65 / eval/reward_rate 0.5 / 
replay/size 3.9e5 / replay/inserts 3803 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3803 / timer/env.step_total 19.92 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.29 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7310 / timer/agent.policy_total 16.55 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1902 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.7 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 391000 Counter(391000) 390937
Saved chunk: 20230922T060343F443215-3oVJveymxNxYOPTO6XUmv0-30vu550MB9Nh34jSLC0Vi7-1024.npz
eval_Episode has 500 steps and return 296.2.
Saved chunk: 20230922T060355F334238-2IWxEaAH02w8UUapor4Enh-6toY0HJzThRv8nEUhdRB5T-1024.npz
train_Episode has 500 steps and return 311.4.
Starting evaluation at step 391500 Counter(391500) 391437
eval_Episode has 500 steps and return 319.4.
train_Episode has 500 steps and return 317.6.
Starting evaluation at step 392000 Counter(392000) 391937
Saved chunk: 20230922T060503F588822-30vu550MB9Nh34jSLC0Vi7-4fzOF2R5ONIlz3ujzqmlJX-1024.npz
eval_Episode has 500 steps and return 314.8.
Saved chunk: 20230922T060517F083515-6toY0HJzThRv8nEUhdRB5T-0QG0Ox7JZiLM9Rv8zCBere-1024.npz
train_Episode has 500 steps and return 299.6.
Starting evaluation at step 392500 Counter(392500) 392437
eval_Episode has 500 steps and return 331.5.
train_Episode has 500 steps and return 308.1.
Starting evaluation at step 393000 Counter(393000) 392937
Saved chunk: 20230922T060623F052090-4fzOF2R5ONIlz3ujzqmlJX-2Y6MSVjmbJ5kybIRNSf11l-1024.npz
eval_Episode has 500 steps and return 327.2.
Saved chunk: 20230922T060638F107617-0QG0Ox7JZiLM9Rv8zCBere-6t0PKa73e8mErMO1Qpl5tn-1024.npz
train_Episode has 500 steps and return 291.0.
Starting evaluation at step 393500 Counter(393500) 393437
eval_Episode has 500 steps and return 309.7.
train_Episode has 500 steps and return 294.3.
Starting evaluation at step 394000 Counter(394000) 393937
Saved chunk: 20230922T060742F411385-2Y6MSVjmbJ5kybIRNSf11l-1kw7xVdywbL0vZpXPMfHZO-1024.npz
eval_Episode has 500 steps and return 335.2.
Saved chunk: 20230922T060759F027454-6t0PKa73e8mErMO1Qpl5tn-0KdPVrIhtwYugY4rkIW2mt-1024.npz
train_Episode has 500 steps and return 292.6.
Starting evaluation at step 394500 Counter(394500) 394437
eval_Episode has 500 steps and return 334.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 789346 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 334.4 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 292.6 / episode/reward_rate 0.43 / train/action_mag 4.03 / train/action_max 3.95 / train/action_mean 0.09 / train/action_min -3.48 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.32 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 4.75 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 3.1e-4 / train/adv_min 
-0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.69 / train/dyn_loss_std 5.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.15 / train/extr_critic_max 236.15 / train/extr_critic_mean 227.97 / train/extr_critic_min 193.73 / train/extr_critic_std 7.38 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.33 / train/extr_return_raw_max 236.33 / train/extr_return_raw_mean 227.98 / train/extr_return_raw_min 
195.21 / train/extr_return_raw_std 7.4 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.9 / train/image_loss_std 0.92 / train/model_loss_mean 3.33 / 
train/model_loss_std 4.28 / train/model_opt_grad_norm 7.84 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.19 / train/policy_entropy_max 
3.76 / train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.06 / train/policy_logprob_mag 9.3 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.63 / train/policy_logprob_min -9.3 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6.2e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.23 / train/post_ent_max 52.23 / train/post_ent_mean 42.03 / 
train/post_ent_min 22.9 / train/post_ent_std 4.33 / train/prior_ent_mag 78.13 / train/prior_ent_max 78.13 / train/prior_ent_mean 45.68 / train/prior_ent_min 30.32 / train/prior_ent_std 5.65 / train/rep_loss_mean 3.69 / train/rep_loss_std 5.95 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.36 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.71 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 5.8 / report/image_loss_mean 0.86 / report/image_loss_std 0.77 / report/model_loss_mean 3.13 / report/model_loss_std 4.08 / report/post_ent_mag 52.1 / report/post_ent_max 52.1 / 
report/post_ent_mean 42.5 / report/post_ent_min 25.38 / report/post_ent_std 4.15 / report/prior_ent_mag 78.28 / report/prior_ent_max 78.28 / report/prior_ent_mean 45.91 / report/prior_ent_min 32.74 / report/prior_ent_std 5.53 / report/rep_loss_mean 3.51 / 
report/rep_loss_std 5.8 / report/reward_avg 0.32 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.29 / report/reward_max_data 1.94 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.32 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.66 / eval/dyn_loss_std 5.29 / eval/image_loss_mean 0.75 / eval/image_loss_std 0.59 / eval/model_loss_mean 3.24 / eval/model_loss_std 3.67 / eval/post_ent_mag 50.13 / eval/post_ent_max 50.13 / eval/post_ent_mean 
42.17 / eval/post_ent_min 25.82 / eval/post_ent_std 3.28 / eval/prior_ent_mag 78.28 / eval/prior_ent_max 78.28 / eval/prior_ent_mean 45.74 / eval/prior_ent_min 38.63 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 3.66 / eval/rep_loss_std 5.29 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.66 / eval/reward_rate 0.49 / 
replay/size 3.9e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3758 / timer/env.step_total 19.39 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.39 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7766 / timer/agent.policy_total 17.32 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1879 / timer/agent.train_total 241.99 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 306.2.
Starting evaluation at step 395000 Counter(395000) 394937
Saved chunk: 20230922T060901F515149-1kw7xVdywbL0vZpXPMfHZO-5yQWzioMEY5QHJLwuLpfPv-1024.npz
eval_Episode has 500 steps and return 320.8.
Saved chunk: 20230922T060919F625849-0KdPVrIhtwYugY4rkIW2mt-3dyhKNtGCMlmOKw1OYrmlr-1024.npz
train_Episode has 500 steps and return 302.8.
Starting evaluation at step 395500 Counter(395500) 395437
eval_Episode has 500 steps and return 310.7.
train_Episode has 500 steps and return 296.3.
Starting evaluation at step 396000 Counter(396000) 395937
Saved chunk: 20230922T061021F682413-5yQWzioMEY5QHJLwuLpfPv-2XXPyYT0XkHZakHkyoH4n4-1024.npz
eval_Episode has 500 steps and return 316.0.
train_Episode has 500 steps and return 300.8.
Saved chunk: 20230922T061041F511372-3dyhKNtGCMlmOKw1OYrmlr-03bMfDTlMPMGHBXUoQv9Uv-1024.npz
Starting evaluation at step 396500 Counter(396500) 396437
eval_Episode has 500 steps and return 349.9.
train_Episode has 500 steps and return 289.3.
Starting evaluation at step 397000 Counter(397000) 396937
eval_Episode has 500 steps and return 328.9.
Saved chunk: 20230922T061141F168280-2XXPyYT0XkHZakHkyoH4n4-0pSRKViNz5JPBQxD6lZGyo-1024.npz
train_Episode has 500 steps and return 310.4.
Saved chunk: 20230922T061202F548561-03bMfDTlMPMGHBXUoQv9Uv-5U1x70fJPXDFOfBTUcFkOM-1024.npz
Starting evaluation at step 397500 Counter(397500) 397437
eval_Episode has 500 steps and return 314.8.
train_Episode has 500 steps and return 308.8.
Starting evaluation at step 398000 Counter(398000) 397937
eval_Episode has 500 steps and return 319.3.
Saved chunk: 20230922T061300F501976-0pSRKViNz5JPBQxD6lZGyo-1zmyZC1dnOuPTPGSB8CqKQ-1024.npz
train_Episode has 500 steps and return 293.9.
Saved chunk: 20230922T061323F406887-5U1x70fJPXDFOfBTUcFkOM-1VM8Yza5QrG1OwNBWOjYue-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 796962 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.94 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 319.28 / eval_episode/reward_rate 0.46 / train/action_mag 4.01 / train/action_max 3.98 / train/action_mean 0.09 / train/action_min -3.46 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 8.06 / train/adv_mag 0.39 / train/adv_max 0.29 / train/adv_mean -3.4e-5 /
train/adv_min -0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.72 / train/dyn_loss_std 6.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.27 / train/extr_critic_max 236.27 / train/extr_critic_mean 227.98 / train/extr_critic_min 194.28 / train/extr_critic_std 7.69 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.46 / train/extr_return_raw_max 236.46 / train/extr_return_raw_mean 227.98 / train/extr_return_raw_min 
195.25 / train/extr_return_raw_std 7.72 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.91 / train/image_loss_std 0.92 / train/model_loss_mean 3.36 /
train/model_loss_std 4.31 / train/model_opt_grad_norm 8.14 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.04 / train/policy_entropy_max 
3.55 / train/policy_entropy_mean -2.62 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.06 / train/policy_logprob_mag 9.14 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.62 / train/policy_logprob_min -9.14 / train/policy_logprob_std 1.77 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6.5e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.04 / train/post_ent_max 52.04 / train/post_ent_mean 42.03 / 
train/post_ent_min 22.91 / train/post_ent_std 4.35 / train/prior_ent_mag 78.18 / train/prior_ent_max 78.18 / train/prior_ent_mean 45.71 / train/prior_ent_min 30.39 / train/prior_ent_std 5.68 / train/rep_loss_mean 3.72 / train/rep_loss_std 6.02 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.34 / report/dyn_loss_std 4.97 / report/image_loss_mean 0.77 / report/image_loss_std 0.71 / report/model_loss_mean 3.07 / report/model_loss_std 3.62 / report/post_ent_mag 53.54 / report/post_ent_max 53.54 /
report/post_ent_mean 43.06 / report/post_ent_min 29.73 / report/post_ent_std 3.19 / report/prior_ent_mag 78.21 / report/prior_ent_max 78.21 / report/prior_ent_mean 46.43 / report/prior_ent_min 40.1 / report/prior_ent_std 4.92 / report/rep_loss_mean 3.34 / 
report/rep_loss_std 4.97 / report/reward_avg 0.59 / report/reward_loss_mean 0.29 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.59 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.67 / eval/dyn_loss_std 5.63 / eval/image_loss_mean 0.89 / eval/image_loss_std 1.37 / eval/model_loss_mean 3.4 / eval/model_loss_std 4.34 / eval/post_ent_mag 50.64 / eval/post_ent_max 50.64 / eval/post_ent_mean 
42.01 / eval/post_ent_min 22.09 / eval/post_ent_std 3.81 / eval/prior_ent_mag 78.21 / eval/prior_ent_max 78.21 / eval/prior_ent_mean 45.58 / eval/prior_ent_min 32.47 / eval/prior_ent_std 5.13 / eval/rep_loss_mean 3.67 / eval/rep_loss_std 5.63 / eval/reward_avg 0.68 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.68 / eval/reward_rate 0.5 / 
replay/size 4e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3808 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.77 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.35 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.95 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 398500 Counter(398500) 398437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 331.8.
train_Episode has 500 steps and return 284.9.
Starting evaluation at step 399000 Counter(399000) 398937
eval_Episode has 500 steps and return 337.9.
Saved chunk: 20230922T061419F519338-1zmyZC1dnOuPTPGSB8CqKQ-2diycfwHFeiYdgQHFYyytg-1024.npz
train_Episode has 500 steps and return 288.8.
Saved chunk: 20230922T061443F917912-1VM8Yza5QrG1OwNBWOjYue-15TubC2Z3ld9PdkIoeLrrQ-1024.npz
Starting evaluation at step 399500 Counter(399500) 399437
eval_Episode has 500 steps and return 342.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T061606F165709-15TubC2Z3ld9PdkIoeLrrQ-0000000000000000000000-340.npz
Saved chunk: 20230922T061540F011136-2diycfwHFeiYdgQHFYyytg-0000000000000000000000-514.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 307.7.
Starting evaluation at step 400000 Counter(400000) 399937
eval_Episode has 500 steps and return 313.5.
train_Episode has 500 steps and return 299.6.
Saved chunk: 20230922T061606F165709-15TubC2Z3ld9PdkIoeLrrQ-1Hn8O3tdzQFVHfaHlkHcNp-1024.npz
Starting evaluation at step 400500 Counter(400500) 400437
Saved chunk: 20230922T061540F011136-2diycfwHFeiYdgQHFYyytg-3LypfnAZpAVvsGuLmZhNKJ-1024.npz
eval_Episode has 500 steps and return 318.7.
train_Episode has 500 steps and return 310.2.
Starting evaluation at step 401000 Counter(401000) 400937
eval_Episode has 500 steps and return 325.8.
train_Episode has 500 steps and return 279.8.
Saved chunk: 20230922T061727F406590-1Hn8O3tdzQFVHfaHlkHcNp-16lIIKG1E1faFwB4p1l6HY-1024.npz
Starting evaluation at step 401500 Counter(401500) 401437
Saved chunk: 20230922T061735F836457-3LypfnAZpAVvsGuLmZhNKJ-3f0i4ucpXplZvKjvlUCwzr-1024.npz
eval_Episode has 500 steps and return 325.6.
train_Episode has 500 steps and return 281.7.
Starting evaluation at step 402000 Counter(402000) 401937
eval_Episode has 500 steps and return 302.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 804458 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 302.05 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 281.68 / episode/reward_rate 0.43 / train/action_mag 4 / train/action_max 3.95 / train/action_mean 0.09 / train/action_min -3.46 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 7.81 / train/adv_mag 0.38 / train/adv_max 0.28 / train/adv_mean -4.2e-6 / train/adv_min 
-0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.17 / train/extr_critic_max 236.17 / train/extr_critic_mean 228.11 / train/extr_critic_min 197.92 / train/extr_critic_std 6.75 / train/extr_return_normed_mag 1.23 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.23 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.35 / train/extr_return_raw_max 236.35 / train/extr_return_raw_mean 228.11 / train/extr_return_raw_min 
197.82 / train/extr_return_raw_std 6.78 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.9 / train/image_loss_std 0.9 / train/model_loss_mean 3.32 / 
train/model_loss_std 4.23 / train/model_opt_grad_norm 8.1 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.89 / train/policy_entropy_max 3.36
/ train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.03 / train/policy_logprob_mag 9.22 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.63 / train/policy_logprob_min -9.22 / train/policy_logprob_std 1.75 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6.8e-5 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.09 / train/post_ent_max 52.09 / train/post_ent_mean 42.1 / 
train/post_ent_min 22.95 / train/post_ent_std 4.26 / train/prior_ent_mag 78.16 / train/prior_ent_max 78.16 / train/prior_ent_mean 45.73 / train/prior_ent_min 30.56 / train/prior_ent_std 5.63 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.92 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.69 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.89 / report/dyn_loss_std 6.56 / report/image_loss_mean 0.99 / report/image_loss_std 1.05 / report/model_loss_mean 3.5 / report/model_loss_std 4.7 / report/post_ent_mag 53.94 / report/post_ent_max 53.94 / 
report/post_ent_mean 42.32 / report/post_ent_min 18.5 / report/post_ent_std 4.72 / report/prior_ent_mag 78.03 / report/prior_ent_max 78.03 / report/prior_ent_mean 46.09 / report/prior_ent_min 28.06 / report/prior_ent_std 5.61 / report/rep_loss_mean 3.89 / 
report/rep_loss_std 6.56 / report/reward_avg 0.38 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 3.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.38 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.21 / eval/dyn_loss_std 6.31 / eval/image_loss_mean 1.05 / eval/image_loss_std 1.78 / eval/model_loss_mean 4.01 / eval/model_loss_std 5.53 / eval/post_ent_mag 49.92 / eval/post_ent_max 49.92 / eval/post_ent_mean 
41.56 / eval/post_ent_min 21.64 / eval/post_ent_std 4.24 / eval/prior_ent_mag 78.03 / eval/prior_ent_max 78.03 / eval/prior_ent_mean 45.47 / eval/prior_ent_min 34.83 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 4.21 / eval/rep_loss_std 6.31 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.44 / eval/reward_loss_std 1.18 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 0.97 / eval/reward_pos_loss 0.87 / eval/reward_pred 0.62 / eval/reward_rate 0.49 /
replay/size 4e5 / replay/inserts 3748 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3748 / timer/env.step_total 19.39 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.89 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7756 / timer/agent.policy_total 17.53 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1874 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1874 / timer/agent.train_total 241.48 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 24.99

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 301.8.
Saved chunk: 20230922T061848F151974-16lIIKG1E1faFwB4p1l6HY-336PJigxrzKhQmjJ7UzPiM-1024.npz
Starting evaluation at step 402500 Counter(402500) 402437
Saved chunk: 20230922T061854F998563-3f0i4ucpXplZvKjvlUCwzr-0NObXDBgcQ3Cd6jRiTzuR6-1024.npz
eval_Episode has 500 steps and return 322.8.
train_Episode has 500 steps and return 281.9.
Starting evaluation at step 403000 Counter(403000) 402937
eval_Episode has 500 steps and return 319.7.
train_Episode has 500 steps and return 314.7.
Saved chunk: 20230922T062010F096926-336PJigxrzKhQmjJ7UzPiM-4EYEXECf2ELhZtZteQnQSz-1024.npz
Starting evaluation at step 403500 Counter(403500) 403437
Saved chunk: 20230922T062015F405795-0NObXDBgcQ3Cd6jRiTzuR6-6Mu1NiHqI6KTPa6IjxEDEm-1024.npz
eval_Episode has 500 steps and return 332.3.
train_Episode has 500 steps and return 305.0.
Starting evaluation at step 404000 Counter(404000) 403937
eval_Episode has 500 steps and return 324.3.
train_Episode has 500 steps and return 271.7.
Saved chunk: 20230922T062131F258583-4EYEXECf2ELhZtZteQnQSz-0i9Nxaq19RYE8gKgiY3hE6-1024.npz
Starting evaluation at step 404500 Counter(404500) 404437
Saved chunk: 20230922T062134F963351-6Mu1NiHqI6KTPa6IjxEDEm-5zRzyj2quygbDAooecT9Fy-1024.npz
eval_Episode has 500 steps and return 331.1.
train_Episode has 500 steps and return 306.5.
Starting evaluation at step 405000 Counter(405000) 404937
eval_Episode has 500 steps and return 331.6.
train_Episode has 500 steps and return 296.7.
Starting evaluation at step 405500 Counter(405500) 405437
Saved chunk: 20230922T062254F312900-5zRzyj2quygbDAooecT9Fy-3meATinPYrum0GZYrzc1NH-1024.npz
eval_Episode has 500 steps and return 307.3.
Saved chunk: 20230922T062252F193667-0i9Nxaq19RYE8gKgiY3hE6-7BaxkMrBRyqJ2Rdrs3FD99-1024.npz
train_Episode has 500 steps and return 296.1.
Starting evaluation at step 406000 Counter(406000) 405937
eval_Episode has 500 steps and return 328.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 812002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 296.12 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 328.26 / eval_episode/reward_rate 0.47 / train/action_mag 4.05 / train/action_max 4 / train/action_mean 0.09 / train/action_min -3.5 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 6.63 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 1.1e-4 / train/adv_min -0.35
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.71 / train/dyn_loss_std 5.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.14 / train/extr_critic_max 236.14 / train/extr_critic_mean 228.12 / train/extr_critic_min 193.33 / train/extr_critic_std 6.97 / train/extr_return_normed_mag 1.25 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.23 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.33 / train/extr_return_raw_max 236.33 / train/extr_return_raw_mean 228.12 / train/extr_return_raw_min 
196.18 / train/extr_return_raw_std 7 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.9 / train/image_loss_std 0.92 / train/model_loss_mean 3.34 / 
train/model_loss_std 4.28 / train/model_opt_grad_norm 8.09 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.98 / train/policy_entropy_max 
3.55 / train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.04 / train/policy_logprob_mag 9.08 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.63 / train/policy_logprob_min -9.08 / train/policy_logprob_std 1.76 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6.6e-5 / train/policy_randomness_std 0.11 / train/post_ent_mag 52.18 / train/post_ent_max 52.18 / train/post_ent_mean 42.04 / 
train/post_ent_min 22.47 / train/post_ent_std 4.34 / train/prior_ent_mag 78.1 / train/prior_ent_max 78.1 / train/prior_ent_mean 45.72 / train/prior_ent_min 30.37 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.71 / train/rep_loss_std 5.98 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.72 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.47 / report/dyn_loss_std 5.57 / report/image_loss_mean 0.8 / report/image_loss_std 0.63 / report/model_loss_mean 3.11 / report/model_loss_std 3.79 / report/post_ent_mag 51.83 / report/post_ent_max 51.83 / 
report/post_ent_mean 41.9 / report/post_ent_min 27.09 / report/post_ent_std 4.04 / report/prior_ent_mag 77.93 / report/prior_ent_max 77.93 / report/prior_ent_mean 45.32 / report/prior_ent_min 32.86 / report/prior_ent_std 5.47 / report/rep_loss_mean 3.47 / 
report/rep_loss_std 5.57 / report/reward_avg 0.5 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.32 / report/reward_max_data 2 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 6.9e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.5 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.98 / eval/dyn_loss_std 6.19 / eval/image_loss_mean 0.88 / eval/image_loss_std 1.1 / eval/model_loss_mean 3.54 / eval/model_loss_std 4.55 / eval/post_ent_mag 51.14 / eval/post_ent_max 51.14 / eval/post_ent_mean 
42.04 / eval/post_ent_min 25.14 / eval/post_ent_std 3.6 / eval/prior_ent_mag 77.93 / eval/prior_ent_max 77.93 / eval/prior_ent_mean 45.84 / eval/prior_ent_min 38.73 / eval/prior_ent_std 5.06 / eval/rep_loss_mean 3.98 / eval/rep_loss_std 6.19 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.5e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 4.1e5 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.32 / timer/env.step_count 3772 / timer/env.step_total 19.47 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.91 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.4e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7780 / timer/agent.policy_total 17.36 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 
/ timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1886 / timer/agent.train_total 243.09 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 297.4.
Starting evaluation at step 406500 Counter(406500) 406437
Saved chunk: 20230922T062413F484718-3meATinPYrum0GZYrzc1NH-2u2fylQAwe56wISPHGyo9d-1024.npz
eval_Episode has 500 steps and return 344.1.
Saved chunk: 20230922T062416F469130-7BaxkMrBRyqJ2Rdrs3FD99-36Gy5HpBXzPkzoQwmpKC3K-1024.npz
train_Episode has 500 steps and return 308.3.
Starting evaluation at step 407000 Counter(407000) 406937
eval_Episode has 500 steps and return 318.3.
train_Episode has 500 steps and return 300.1.
Starting evaluation at step 407500 Counter(407500) 407437
Saved chunk: 20230922T062533F874655-2u2fylQAwe56wISPHGyo9d-3W7kUZiMlPxSlWo31Vmgcu-1024.npz
eval_Episode has 500 steps and return 325.9.
Saved chunk: 20230922T062538F453719-36Gy5HpBXzPkzoQwmpKC3K-2nXgq5fHJ66p004bor4Mzx-1024.npz
train_Episode has 500 steps and return 289.5.
Starting evaluation at step 408000 Counter(408000) 407937
eval_Episode has 500 steps and return 338.1.
train_Episode has 500 steps and return 274.1.
Starting evaluation at step 408500 Counter(408500) 408437
Saved chunk: 20230922T062653F339542-3W7kUZiMlPxSlWo31Vmgcu-5VF5mubOFhPt5D1K0OhTLA-1024.npz
eval_Episode has 500 steps and return 305.5.
Saved chunk: 20230922T062659F507660-2nXgq5fHJ66p004bor4Mzx-1U3DK2bKTTHrlaFTN3LP0y-1024.npz
train_Episode has 500 steps and return 302.4.
Starting evaluation at step 409000 Counter(409000) 408937
eval_Episode has 500 steps and return 325.2.
train_Episode has 500 steps and return 305.6.
Starting evaluation at step 409500 Counter(409500) 409437
Saved chunk: 20230922T062812F590920-5VF5mubOFhPt5D1K0OhTLA-6Ery5Cc7tWQGzSzVm0esVt-1024.npz
eval_Episode has 500 steps and return 314.0.
Saved chunk: 20230922T062820F309581-1U3DK2bKTTHrlaFTN3LP0y-7sKcCB46N5qAvyALO3qgKj-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 819610 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 305.62 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 313.99 / eval_episode/reward_rate 0.48 / train/action_mag 4.09 / train/action_max 4.05 / train/action_mean 0.09 / train/action_min -3.55 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 4.83 / train/adv_mag 0.39 / train/adv_max 0.3 / train/adv_mean 3e-4 / 
train/adv_min -0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.22 / train/extr_critic_max 236.22 / train/extr_critic_mean 227.81 / train/extr_critic_min 192.12 / train/extr_critic_std 8.11 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.43 / train/extr_return_raw_max 236.43 / train/extr_return_raw_mean 227.82 / train/extr_return_raw_min 
193.18 / train/extr_return_raw_std 8.13 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.89 / train/image_loss_std 0.88 / train/model_loss_mean 3.31 /
train/model_loss_std 4.23 / train/model_opt_grad_norm 8.12 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.95 / train/policy_entropy_max 
3.52 / train/policy_entropy_mean -2.62 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.06 / train/policy_logprob_mag 9.3 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.62 / train/policy_logprob_min -9.3 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6.4e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.1 / train/post_ent_max 52.1 / train/post_ent_mean 42.09 / 
train/post_ent_min 22.9 / train/post_ent_std 4.33 / train/prior_ent_mag 78.02 / train/prior_ent_max 78.02 / train/prior_ent_mean 45.72 / train/prior_ent_min 30.45 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.93 / train/reward_avg 0.45 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.45 / train/reward_rate 
0.36 / train_stats/mean_log_entropy -2.69 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 8.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.34 / report/dyn_loss_std 5.12 / report/image_loss_mean 0.74 / report/image_loss_std 0.57 / report/model_loss_mean 3.01 / report/model_loss_std 3.6 / report/post_ent_mag 51.99 / report/post_ent_max 51.99 / 
report/post_ent_mean 43.32 / report/post_ent_min 29.16 / report/post_ent_std 3.26 / report/prior_ent_mag 77.96 / report/prior_ent_max 77.96 / report/prior_ent_mean 46.64 / report/prior_ent_min 39.24 / report/prior_ent_std 4.77 / report/rep_loss_mean 3.34 / 
report/rep_loss_std 5.12 / report/reward_avg 0.6 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.6 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.89 / eval/dyn_loss_std 5.97 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.5 / eval/model_loss_mean 3.62 / eval/model_loss_std 4.59 / eval/post_ent_mag 51.62 / eval/post_ent_max 51.62 / eval/post_ent_mean 
41.91 / eval/post_ent_min 22.05 / eval/post_ent_std 4.08 / eval/prior_ent_mag 77.96 / eval/prior_ent_max 77.96 / eval/prior_ent_mean 45.58 / eval/prior_ent_min 29.04 / eval/prior_ent_std 5.42 / eval/rep_loss_mean 3.89 / eval/rep_loss_std 5.97 / eval/reward_avg 0.68 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.67 / eval/reward_rate 0.5 / 
replay/size 4.1e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3804 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 468.04 / timer/replay._sample_frac 1.56 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.43 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.83 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.36

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 301.4.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 410000 Counter(410000) 409937
eval_Episode has 500 steps and return 306.7.
train_Episode has 500 steps and return 276.7.
Starting evaluation at step 410500 Counter(410500) 410437
Saved chunk: 20230922T062931F726390-6Ery5Cc7tWQGzSzVm0esVt-0j1lD0n8pqPOWzbGt4NLab-1024.npz
eval_Episode has 500 steps and return 320.3.
Saved chunk: 20230922T062941F010591-7sKcCB46N5qAvyALO3qgKj-58G9tdk3TsQ0VzvT7A3tHz-1024.npz
train_Episode has 500 steps and return 285.9.
Starting evaluation at step 411000 Counter(411000) 410937
eval_Episode has 500 steps and return 322.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T063052F207677-0j1lD0n8pqPOWzbGt4NLab-0000000000000000000000-773.npz
Saved chunk: 20230922T063103F101702-58G9tdk3TsQ0VzvT7A3tHz-0000000000000000000000-476.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 312.1.
Starting evaluation at step 411500 Counter(411500) 411437
Saved chunk: 20230922T063052F207677-0j1lD0n8pqPOWzbGt4NLab-3qZZEBCN7h1vQtqg4jSaIL-1024.npz
eval_Episode has 500 steps and return 316.0.
Saved chunk: 20230922T063103F101702-58G9tdk3TsQ0VzvT7A3tHz-27c5vzu7Vj0yZELndcw6SC-1024.npz
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 412000 Counter(412000) 411937
eval_Episode has 500 steps and return 334.9.
train_Episode has 500 steps and return 297.0.
Starting evaluation at step 412500 Counter(412500) 412437
Saved chunk: 20230922T063211F858793-3qZZEBCN7h1vQtqg4jSaIL-3TSJcnx3G91sfH92H5NIUu-1024.npz
eval_Episode has 500 steps and return 327.8.
Saved chunk: 20230922T063224F296537-27c5vzu7Vj0yZELndcw6SC-5h5wgbXhzsvkXlYhBIvPZ8-1024.npz
train_Episode has 500 steps and return 308.2.
Starting evaluation at step 413000 Counter(413000) 412937
eval_Episode has 500 steps and return 327.6.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 413500 Counter(413500) 413437
Saved chunk: 20230922T063331F010917-3TSJcnx3G91sfH92H5NIUu-23yVFcSE43pVCOsSqvXS7P-1024.npz
eval_Episode has 500 steps and return 333.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 827118 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.48 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 333.09 / eval_episode/reward_rate 0.48 / train_stats/mean_log_entropy -2.75 / train/action_mag 4.03 / train/action_max 3.98 / train/action_mean 0.09 / 
train/action_min -3.4 / train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 5.57 / train/adv_mag 0.55 / train/adv_max 0.45 
/ train/adv_mean 2.3e-4 / train/adv_min -0.41 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1
/ train/cont_rate 1 / train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / 
train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.11 / train/extr_critic_max 236.11 / train/extr_critic_mean 227.29 / train/extr_critic_min 179.57 / train/extr_critic_std 9.99 / 
train/extr_return_normed_mag 1.7 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.82 / train/extr_return_normed_std 0.34 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 236.32 / 
train/extr_return_raw_max 236.32 / train/extr_return_raw_mean 227.3 / train/extr_return_raw_min 181.7 / train/extr_return_raw_std 10.01 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / 
train/extr_reward_std 0.68 / train/image_loss_mean 0.88 / train/image_loss_std 0.9 / train/model_loss_mean 3.32 / train/model_loss_std 4.25 / train/model_opt_grad_norm 8.05 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.98 / train/policy_entropy_max 3.49 / train/policy_entropy_mean -2.64 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.06 / 
train/policy_logprob_mag 9.14 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.64 / train/policy_logprob_min -9.14 / train/policy_logprob_std 1.78 / train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.1 / 
train/policy_randomness_min 6e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.04 / train/post_ent_max 52.04 / train/post_ent_mean 42.13 / train/post_ent_min 22.7 / train/post_ent_std 4.39 / train/prior_ent_mag 77.95 / train/prior_ent_max 77.95 / 
train/prior_ent_mean 45.79 / train/prior_ent_min 30.3 / train/prior_ent_std 5.7 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.93 / train/reward_avg 0.46 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 
1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / 
report/cont_loss_std 8.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 5.47 / report/image_loss_mean 0.77 / 
report/image_loss_std 0.63 / report/model_loss_mean 3.21 / report/model_loss_std 3.81 / report/post_ent_mag 51.53 / report/post_ent_max 51.53 / report/post_ent_mean 42.54 / report/post_ent_min 26.43 / report/post_ent_std 3.44 / report/prior_ent_mag 77.87 / 
report/prior_ent_max 77.87 / report/prior_ent_mean 46.11 / report/prior_ent_min 36.78 / report/prior_ent_std 4.99 / report/rep_loss_mean 3.64 / report/rep_loss_std 5.47 / report/reward_avg 0.53 / report/reward_loss_mean 0.26 / report/reward_loss_std 0.35 / 
report/reward_max_data 1.98 / report/reward_max_pred 1.95 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.53 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 
4.8e-11 / eval/cont_loss_std 9.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.04 / eval/dyn_loss_std 5.95 / eval/image_loss_mean 0.98 / 
eval/image_loss_std 1.31 / eval/model_loss_mean 3.7 / eval/model_loss_std 4.42 / eval/post_ent_mag 50.18 / eval/post_ent_max 50.18 / eval/post_ent_mean 41.77 / eval/post_ent_min 24.58 / eval/post_ent_std 3.8 / eval/prior_ent_mag 77.87 / eval/prior_ent_max 77.87 / 
eval/prior_ent_mean 45.66 / eval/prior_ent_min 28.95 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 4.04 / eval/rep_loss_std 5.95 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.92 / 
eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.62 / eval/reward_rate 0.46 / replay/size 4.1e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3754 / timer/env.step_total 19.48 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 460.23 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.1e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / 
timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.64 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 
0.18 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.58 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T063344F976098-5h5wgbXhzsvkXlYhBIvPZ8-7qf5sMRSYsrI5RDhpGvwN2-1024.npz
train_Episode has 500 steps and return 317.9.
Starting evaluation at step 414000 Counter(414000) 413937
eval_Episode has 500 steps and return 302.3.
train_Episode has 500 steps and return 282.0.
Starting evaluation at step 414500 Counter(414500) 414437
Saved chunk: 20230922T063450F154963-23yVFcSE43pVCOsSqvXS7P-1fTudjbxsMMQaBnNg60JBY-1024.npz
eval_Episode has 500 steps and return 315.6.
Saved chunk: 20230922T063506F802669-7qf5sMRSYsrI5RDhpGvwN2-4pogE6H9GYjkJrJNIjzrV0-1024.npz
train_Episode has 500 steps and return 274.2.
Starting evaluation at step 415000 Counter(415000) 414937
eval_Episode has 500 steps and return 310.6.
train_Episode has 500 steps and return 297.0.
Starting evaluation at step 415500 Counter(415500) 415437
Saved chunk: 20230922T063610F672746-1fTudjbxsMMQaBnNg60JBY-3AC2qBQTSyEtpIaTfLdfqR-1024.npz
eval_Episode has 500 steps and return 326.0.
Saved chunk: 20230922T063627F837455-4pogE6H9GYjkJrJNIjzrV0-715NLlC8DEk9QXABw2qV2p-1024.npz
train_Episode has 500 steps and return 316.7.
Starting evaluation at step 416000 Counter(416000) 415937
eval_Episode has 500 steps and return 315.2.
train_Episode has 500 steps and return 282.2.
Starting evaluation at step 416500 Counter(416500) 416437
Saved chunk: 20230922T063729F968345-3AC2qBQTSyEtpIaTfLdfqR-6WWM6vwj90jr3Ea490I6rn-1024.npz
eval_Episode has 500 steps and return 332.1.
Saved chunk: 20230922T063748F737128-715NLlC8DEk9QXABw2qV2p-4MA4Xu9NatVHyoJbOLZ0JR-1024.npz
train_Episode has 500 steps and return 287.8.
Starting evaluation at step 417000 Counter(417000) 416937
eval_Episode has 500 steps and return 307.2.
train_Episode has 500 steps and return 285.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 834682 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 285.64 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 307.16 / eval_episode/reward_rate 0.46 / train/action_mag 4.03 / train/action_max 3.97 / train/action_mean 0.08 / train/action_min -3.45 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 9.03 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean -1.3e-4 /
train/adv_min -0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.97 / train/extr_critic_max 235.97 / train/extr_critic_mean 227.33 / train/extr_critic_min 185.99 / train/extr_critic_std 8.92 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.18 / train/extr_return_raw_max 236.18 / train/extr_return_raw_mean 227.33 / train/extr_return_raw_min 
188.79 / train/extr_return_raw_std 8.93 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.67 / train/image_loss_mean 0.89 / train/image_loss_std 0.9 / train/model_loss_mean 3.31 / 
train/model_loss_std 4.24 / train/model_opt_grad_norm 8.01 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.08 / train/policy_entropy_max 
3.77 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.48 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -9.48 / train/policy_logprob_std 1.82 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6.7e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.16 / train/post_ent_max 52.16 / train/post_ent_mean 42.14 / 
train/post_ent_min 23.03 / train/post_ent_std 4.34 / train/prior_ent_mag 77.99 / train/prior_ent_max 77.99 / train/prior_ent_mean 45.79 / train/prior_ent_min 30.28 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.91 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.72 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.02 / report/dyn_loss_std 6.77 / report/image_loss_mean 0.99 / report/image_loss_std 1.12 / report/model_loss_mean 3.63 / report/model_loss_std 4.83 / report/post_ent_mag 52.59 / report/post_ent_max 52.59 /
report/post_ent_mean 41.6 / report/post_ent_min 20.84 / report/post_ent_std 4.88 / report/prior_ent_mag 77.96 / report/prior_ent_max 77.96 / report/prior_ent_mean 45.57 / report/prior_ent_min 30.42 / report/prior_ent_std 6.09 / report/rep_loss_mean 4.02 / 
report/rep_loss_std 6.77 / report/reward_avg 0.49 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.33 / report/reward_max_data 1.99 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 5.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.49 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 8.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.15 / eval/dyn_loss_std 6.06 / eval/image_loss_mean 0.95 / eval/image_loss_std 1.38 / eval/model_loss_mean 3.71 / eval/model_loss_std 4.64 / eval/post_ent_mag 50.05 / eval/post_ent_max 50.05 / eval/post_ent_mean 
41.84 / eval/post_ent_min 25.26 / eval/post_ent_std 3.79 / eval/prior_ent_mag 77.96 / eval/prior_ent_max 77.96 / eval/prior_ent_mean 45.78 / eval/prior_ent_min 34.39 / eval/prior_ent_std 5.1 / eval/rep_loss_mean 4.15 / eval/rep_loss_std 6.06 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.62 / eval/reward_rate 0.44 / 
replay/size 4.2e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3782 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.21 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.7e-4 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7289 / timer/agent.policy_total 16.33 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1891 / timer/agent.train_total 245.29 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.82 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 417500 Counter(417500) 417437
Saved chunk: 20230922T063849F263101-6WWM6vwj90jr3Ea490I6rn-3sNWta5z6h9bQ6JLgnH1UA-1024.npz
eval_Episode has 500 steps and return 312.2.
Saved chunk: 20230922T063909F546188-4MA4Xu9NatVHyoJbOLZ0JR-2s9UC6zifwNF4o2d2XMYeC-1024.npz
train_Episode has 500 steps and return 297.9.
Starting evaluation at step 418000 Counter(418000) 417937
eval_Episode has 500 steps and return 328.4.
train_Episode has 500 steps and return 281.5.
Starting evaluation at step 418500 Counter(418500) 418437
Saved chunk: 20230922T064011F126116-3sNWta5z6h9bQ6JLgnH1UA-1twycgiWifgTIOuGUN1wvt-1024.npz
eval_Episode has 500 steps and return 320.1.
Saved chunk: 20230922T064033F086999-2s9UC6zifwNF4o2d2XMYeC-3eh3kl0ZNMq6N1kl9VFBG6-1024.npz
train_Episode has 500 steps and return 298.4.
Starting evaluation at step 419000 Counter(419000) 418937
eval_Episode has 500 steps and return 316.3.
train_Episode has 500 steps and return 310.1.
Starting evaluation at step 419500 Counter(419500) 419437
eval_Episode has 500 steps and return 318.4.
Saved chunk: 20230922T064130F633649-1twycgiWifgTIOuGUN1wvt-5JKKyTPZjBd7YI6sLIwj26-1024.npz
train_Episode has 500 steps and return 318.0.
Saved chunk: 20230922T064154F204757-3eh3kl0ZNMq6N1kl9VFBG6-6pbc2oqAPFz9sQULr0nz78-1024.npz
Starting evaluation at step 420000 Counter(420000) 419937
eval_Episode has 500 steps and return 318.5.
train_Episode has 500 steps and return 291.2.
Starting evaluation at step 420500 Counter(420500) 420437
Saved chunk: 20230922T064250F119434-5JKKyTPZjBd7YI6sLIwj26-5f4pNF3MKVckdvnXpRZ02X-1024.npz
eval_Episode has 500 steps and return 331.5.
train_Episode has 500 steps and return 290.6.
Saved chunk: 20230922T064315F184496-6pbc2oqAPFz9sQULr0nz78-44faH5Bgn24J8bj2chnaSr-1024.npz
Starting evaluation at step 421000 Counter(421000) 420937
eval_Episode has 500 steps and return 318.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 842186 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 318.31 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 290.58 / episode/reward_rate 0.43 / train/action_mag 4.1 / train/action_max 4.04 / train/action_mean 0.08 / train/action_min -3.51 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 5.53 / train/adv_mag 0.49 / train/adv_max 0.39 / train/adv_mean 2e-4 / train/adv_min 
-0.37 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.69 / train/dyn_loss_std 5.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.93 / train/extr_critic_max 235.93 / train/extr_critic_mean 226.93 / train/extr_critic_min 181.22 / train/extr_critic_std 10.2 / train/extr_return_normed_mag 1.52 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.68 / train/extr_return_normed_std 0.33 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 236.16 / train/extr_return_raw_max 236.16 / train/extr_return_raw_mean 226.94 / 
train/extr_return_raw_min 182.23 / train/extr_return_raw_std 10.23 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.89 / train/image_loss_std 0.91 / 
train/model_loss_mean 3.32 / train/model_loss_std 4.26 / train/model_opt_grad_norm 7.93 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.65
/ train/policy_entropy_max 4.44 / train/policy_entropy_mean -2.56 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 9.75 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.56 / train/policy_logprob_min -9.75 / 
train/policy_logprob_std 1.89 / train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 6.6e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.1 / train/post_ent_max 52.1 / 
train/post_ent_mean 42.12 / train/post_ent_min 22.75 / train/post_ent_std 4.42 / train/prior_ent_mag 77.93 / train/prior_ent_max 77.93 / train/prior_ent_mean 45.77 / train/prior_ent_min 29.99 / train/prior_ent_std 5.73 / train/rep_loss_mean 3.69 / train/rep_loss_std 
5.93 / train/reward_avg 0.46 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / 
train/reward_pred 0.46 / train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.72 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 6.22 / report/image_loss_mean 0.89 / report/image_loss_std 0.82 / report/model_loss_mean 3.39 / report/model_loss_std 4.32 / 
report/post_ent_mag 51.86 / report/post_ent_max 51.86 / report/post_ent_mean 42.37 / report/post_ent_min 24.05 / report/post_ent_std 4.32 / report/prior_ent_mag 77.81 / report/prior_ent_max 77.81 / report/prior_ent_mean 46.19 / report/prior_ent_min 31.28 / 
report/prior_ent_std 5.59 / report/rep_loss_mean 3.78 / report/rep_loss_std 6.22 / report/reward_avg 0.5 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.5 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.54 / eval/dyn_loss_std 6.77 / eval/image_loss_mean 1.18 / eval/image_loss_std 2.1 / eval/model_loss_mean 4.19 / eval/model_loss_std 5.6 / eval/post_ent_mag 
52.74 / eval/post_ent_max 52.74 / eval/post_ent_mean 41.64 / eval/post_ent_min 23.75 / eval/post_ent_std 4.35 / eval/prior_ent_mag 77.81 / eval/prior_ent_max 77.81 / eval/prior_ent_mean 45.79 / eval/prior_ent_min 32.1 / eval/prior_ent_std 5.28 / eval/rep_loss_mean 4.54 
/ eval/rep_loss_std 6.77 / eval/reward_avg 0.61 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.61 / eval/reward_rate 0.46 / replay/size 4.2e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3752 / timer/env.step_total 19.36
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.72 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.35 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.8e-3 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1876 / timer/agent.train_total 241.98 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 
4e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 293.8.
Starting evaluation at step 421500 Counter(421500) 421437
eval_Episode has 500 steps and return 326.4.
Saved chunk: 20230922T064409F404942-5f4pNF3MKVckdvnXpRZ02X-28Hbu6toIquhge0qcBXEea-1024.npz
train_Episode has 500 steps and return 306.7.
Saved chunk: 20230922T064435F985275-44faH5Bgn24J8bj2chnaSr-0MLspbvPSkaKy17Zxeqg0d-1024.npz
Starting evaluation at step 422000 Counter(422000) 421937
eval_Episode has 500 steps and return 326.1.
train_Episode has 500 steps and return 313.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 422500 Counter(422500) 422437
Saved chunk: 20230922T064529F883315-28Hbu6toIquhge0qcBXEea-0000000000000000000000-531.npz
Saved chunk: 20230922T064558F254204-0MLspbvPSkaKy17Zxeqg0d-0000000000000000000000-612.npz
eval_Episode has 500 steps and return 319.3.
Saved chunk: 20230922T064529F883315-28Hbu6toIquhge0qcBXEea-7ucoKgveDPFxO6NQPnVWdS-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 301.6.
Saved chunk: 20230922T064558F254204-0MLspbvPSkaKy17Zxeqg0d-2JVG4nreZYs4xn4hOrY5IR-1024.npz
Starting evaluation at step 423000 Counter(423000) 422937
eval_Episode has 500 steps and return 311.7.
train_Episode has 500 steps and return 302.8.
Starting evaluation at step 423500 Counter(423500) 423437
eval_Episode has 500 steps and return 295.7.
train_Episode has 500 steps and return 296.9.
Saved chunk: 20230922T064719F701316-2JVG4nreZYs4xn4hOrY5IR-0cX8oM04k5RlBXojO3mvwU-1024.npz
Starting evaluation at step 424000 Counter(424000) 423937
Saved chunk: 20230922T064649F831008-7ucoKgveDPFxO6NQPnVWdS-4eCHOEHrWDiw7NXK6tCcqM-1024.npz
eval_Episode has 500 steps and return 328.1.
train_Episode has 500 steps and return 306.2.
Starting evaluation at step 424500 Counter(424500) 424437
eval_Episode has 500 steps and return 277.4.
train_Episode has 500 steps and return 278.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 849774 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 278.47 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 277.36 / eval_episode/reward_rate 0.43 / train/action_mag 4.08 / train/action_max 4.03 / train/action_mean 0.08 / train/action_min -3.45 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 5.25 / train/adv_mag 0.48 / train/adv_max 0.37 / train/adv_mean 2.6e-4
/ train/adv_min -0.38 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.86 / train/extr_critic_max 235.86 / train/extr_critic_mean 227.18 / train/extr_critic_min 182.93 / train/extr_critic_std 9.12 / train/extr_return_normed_mag 1.5 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.66 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.07 / train/extr_return_raw_max 236.07 / train/extr_return_raw_mean 227.19 / train/extr_return_raw_min 
184.88 / train/extr_return_raw_std 9.15 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.47 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.89 / train/image_loss_std 0.89 / train/model_loss_mean 3.31 /
train/model_loss_std 4.2 / train/model_opt_grad_norm 8.04 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.38 / train/policy_entropy_max 4 
/ train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.14 / train/policy_logprob_mag 9.52 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.63 / train/policy_logprob_min -9.52 / train/policy_logprob_std 1.83 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.08 / train/post_ent_max 52.08 / train/post_ent_mean 42.15 / 
train/post_ent_min 22.89 / train/post_ent_std 4.38 / train/prior_ent_mag 77.86 / train/prior_ent_max 77.86 / train/prior_ent_mean 45.8 / train/prior_ent_min 30.13 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.89 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.97 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.74 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.26 / report/dyn_loss_std 5.1 / report/image_loss_mean 0.71 / report/image_loss_std 0.62 / report/model_loss_mean 2.88 / report/model_loss_std 3.56 / report/post_ent_mag 50.49 / report/post_ent_max 50.49 / 
report/post_ent_mean 41.93 / report/post_ent_min 22.82 / report/post_ent_std 3.7 / report/prior_ent_mag 77.82 / report/prior_ent_max 77.82 / report/prior_ent_mean 44.97 / report/prior_ent_min 30 / report/prior_ent_std 5.59 / report/rep_loss_mean 3.26 / 
report/rep_loss_std 5.1 / report/reward_avg 0.45 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / report/reward_max_data 1.94 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 5.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.45 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.53 / eval/dyn_loss_std 5.33 / eval/image_loss_mean 0.79 / eval/image_loss_std 0.97 / eval/model_loss_mean 3.22 / eval/model_loss_std 3.91 / eval/post_ent_mag 51.04 / eval/post_ent_max 51.04 / eval/post_ent_mean 
42.08 / eval/post_ent_min 23.05 / eval/post_ent_std 3.54 / eval/prior_ent_mag 77.82 / eval/prior_ent_max 77.82 / eval/prior_ent_mean 45.68 / eval/prior_ent_min 28.16 / eval/prior_ent_std 5.22 / eval/rep_loss_mean 3.53 / eval/rep_loss_std 5.33 / eval/reward_avg 0.67 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.67 / eval/reward_rate 0.51 / 
replay/size 4.2e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3794 / timer/env.step_total 19.59 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.3e-3 / timer/env.step_max 8.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 468.3 / timer/replay._sample_frac 1.56 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7301 / timer/agent.policy_total 16.7 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1897 / timer/agent.train_total 244.56 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T064840F537696-0cX8oM04k5RlBXojO3mvwU-76EmZxwHF8ANSsBZYngyBa-1024.npz
Starting evaluation at step 425000 Counter(425000) 424937
Saved chunk: 20230922T064845F239495-4eCHOEHrWDiw7NXK6tCcqM-68OH84WRToEx2EbBbFx6GF-1024.npz
eval_Episode has 500 steps and return 322.4.
train_Episode has 500 steps and return 306.1.
Starting evaluation at step 425500 Counter(425500) 425437
eval_Episode has 500 steps and return 339.6.
train_Episode has 500 steps and return 283.5.
Saved chunk: 20230922T065002F368135-76EmZxwHF8ANSsBZYngyBa-3Vv7ehGQWCK6gkbBqMrrah-1024.npz
Starting evaluation at step 426000 Counter(426000) 425937
Saved chunk: 20230922T065005F523933-68OH84WRToEx2EbBbFx6GF-4R0t9eglJkTSUuU1jvXIpQ-1024.npz
eval_Episode has 500 steps and return 315.8.
train_Episode has 500 steps and return 304.6.
Starting evaluation at step 426500 Counter(426500) 426437
eval_Episode has 500 steps and return 311.6.
train_Episode has 500 steps and return 283.0.
Starting evaluation at step 427000 Counter(427000) 426937
Saved chunk: 20230922T065125F121054-4R0t9eglJkTSUuU1jvXIpQ-16QpvXsUYzTi8fKQlZXX0f-1024.npz
eval_Episode has 500 steps and return 331.9.
Saved chunk: 20230922T065123F547816-3Vv7ehGQWCK6gkbBqMrrah-5mHrDEDMgGG9vjn3RqSZHU-1024.npz
train_Episode has 500 steps and return 305.1.
Starting evaluation at step 427500 Counter(427500) 427437
eval_Episode has 500 steps and return 302.1.
train_Episode has 500 steps and return 298.4.
Starting evaluation at step 428000 Counter(428000) 427937
Saved chunk: 20230922T065244F508339-16QpvXsUYzTi8fKQlZXX0f-53fgrnGLI96MjuQYe5c3FX-1024.npz
eval_Episode has 500 steps and return 308.2.
Saved chunk: 20230922T065248F061786-5mHrDEDMgGG9vjn3RqSZHU-72Su4NdKdDTH7wvcrTcHBR-1024.npz
train_Episode has 500 steps and return 315.6.
Starting evaluation at step 428500 Counter(428500) 428437
eval_Episode has 500 steps and return 314.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 857282 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 313.96 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 315.59 / episode/reward_rate 0.46 / train/action_mag 4.08 / train/action_max 4.03 / train/action_mean 0.09 / train/action_min -3.37 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.32 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 3.48 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 4.4e-4
/ train/adv_min -0.38 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.97 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 235.97 / train/extr_critic_max 235.97 / train/extr_critic_mean 227.55 / train/extr_critic_min 188.17 / train/extr_critic_std 8.37 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.17 / train/extr_return_raw_max 236.17 / train/extr_return_raw_mean 227.57 / train/extr_return_raw_min 
189.58 / train/extr_return_raw_std 8.39 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.9 / train/image_loss_std 0.93 / train/model_loss_mean 3.34 / 
train/model_loss_std 4.29 / train/model_opt_grad_norm 8.19 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.37 / train/policy_entropy_max 
3.99 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.1 / train/policy_logprob_mag 9.51 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -9.51 / train/policy_logprob_std 1.8 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 6e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.04 / train/post_ent_max 52.04 / train/post_ent_mean 42.12 / 
train/post_ent_min 22.87 / train/post_ent_std 4.41 / train/prior_ent_mag 77.75 / train/prior_ent_max 77.75 / train/prior_ent_mean 45.78 / train/prior_ent_min 29.87 / train/prior_ent_std 5.69 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.97 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 
0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.75 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 5.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.9 / report/dyn_loss_std 6.58 / report/image_loss_mean 1.02 / report/image_loss_std 1.14 / report/model_loss_mean 3.56 / report/model_loss_std 4.91 / report/post_ent_mag 51.53 / report/post_ent_max 51.53 / 
report/post_ent_mean 43.06 / report/post_ent_min 22.8 / report/post_ent_std 4.27 / report/prior_ent_mag 78 / report/prior_ent_max 78 / report/prior_ent_mean 46.8 / report/prior_ent_min 32.63 / report/prior_ent_std 5.45 / report/rep_loss_mean 3.9 / report/rep_loss_std 
6.58 / report/reward_avg 0.41 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 1.98 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / 
report/reward_pred 0.4 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 6.5e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.62 / eval/dyn_loss_std 5.23 / eval/image_loss_mean 0.76 / eval/image_loss_std 0.72 / eval/model_loss_mean 3.25 / eval/model_loss_std 3.76 / eval/post_ent_mag 51.08 / eval/post_ent_max 51.08 / eval/post_ent_mean 42.31 / eval/post_ent_min 28.52 / 
eval/post_ent_std 3.31 / eval/prior_ent_mag 78 / eval/prior_ent_max 78 / eval/prior_ent_mean 45.86 / eval/prior_ent_min 38.48 / eval/prior_ent_std 4.96 / eval/rep_loss_mean 3.62 / eval/rep_loss_std 5.23 / eval/reward_avg 0.67 / eval/reward_loss_mean 0.32 / 
eval/reward_loss_std 0.43 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.66 / eval/reward_rate 0.5 / replay/size 4.3e5 / replay/inserts 
3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3754 / timer/env.step_total 19.56 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 3.9e-3 / 
timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.46 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.8e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.39 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9e-3 / timer/dataset_train_count 
1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.73 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 291.5.
Starting evaluation at step 429000 Counter(429000) 428937
Saved chunk: 20230922T065403F697251-53fgrnGLI96MjuQYe5c3FX-4mXgnwHtOe4rdgiNDBNYL2-1024.npz
eval_Episode has 500 steps and return 347.9.
Saved chunk: 20230922T065408F810195-72Su4NdKdDTH7wvcrTcHBR-4uGAAgzJ5brGJeK3yvdiHu-1024.npz
train_Episode has 500 steps and return 311.1.
Starting evaluation at step 429500 Counter(429500) 429437
eval_Episode has 500 steps and return 332.6.
train_Episode has 500 steps and return 297.7.
Starting evaluation at step 430000 Counter(430000) 429937
Saved chunk: 20230922T065524F022675-4mXgnwHtOe4rdgiNDBNYL2-2yrP96V4cqCyV7M6FWd6YI-1024.npz
eval_Episode has 500 steps and return 312.2.
Saved chunk: 20230922T065530F799709-4uGAAgzJ5brGJeK3yvdiHu-1cieVAeJNI1pp5H4sj2DQG-1024.npz
train_Episode has 500 steps and return 307.5.
Starting evaluation at step 430500 Counter(430500) 430437
eval_Episode has 500 steps and return 334.7.
train_Episode has 500 steps and return 304.5.
Starting evaluation at step 431000 Counter(431000) 430937
Saved chunk: 20230922T065643F623224-2yrP96V4cqCyV7M6FWd6YI-3E1NHlmY89H9rzmn6jn07U-1024.npz
eval_Episode has 500 steps and return 305.2.
Saved chunk: 20230922T065651F914127-1cieVAeJNI1pp5H4sj2DQG-0ORAqRwhGBa6RfuZ51EEqL-1024.npz
train_Episode has 500 steps and return 305.3.
Starting evaluation at step 431500 Counter(431500) 431437
eval_Episode has 500 steps and return 316.0.
train_Episode has 500 steps and return 276.1.
Starting evaluation at step 432000 Counter(432000) 431937
Saved chunk: 20230922T065802F885565-3E1NHlmY89H9rzmn6jn07U-5NQiEDe4cmPJKeGA2L0nR2-1024.npz
eval_Episode has 500 steps and return 330.2.
Saved chunk: 20230922T065812F731198-0ORAqRwhGBa6RfuZ51EEqL-2g1uP5BrgapNMU3RHLZbEs-1024.npz
train_Episode has 500 steps and return 305.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 864894 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 305.45 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 330.19 / eval_episode/reward_rate 0.47 / train/action_mag 4.04 / train/action_max 4.01 / train/action_mean 0.09 / train/action_min -3.38 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 6.26 / train/adv_mag 0.39 / train/adv_max 0.27 / train/adv_mean 1.7e-4
/ train/adv_min -0.37 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.02 / train/extr_critic_max 236.02 / train/extr_critic_mean 227.64 / train/extr_critic_min 192.49 / train/extr_critic_std 7.9 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.21 / train/extr_return_raw_max 236.21 / train/extr_return_raw_mean 227.65 / train/extr_return_raw_min 
192.06 / train/extr_return_raw_std 7.93 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.89 / train/image_loss_std 0.91 / train/model_loss_mean 3.33 /
train/model_loss_std 4.26 / train/model_opt_grad_norm 7.91 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.34 / train/policy_entropy_max 
3.92 / train/policy_entropy_mean -2.68 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.32 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.68 / train/policy_logprob_min -9.32 / train/policy_logprob_std 1.79 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 5.5e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.12 / train/post_ent_max 52.12 / train/post_ent_mean 42.15 / 
train/post_ent_min 22.96 / train/post_ent_std 4.34 / train/prior_ent_mag 77.76 / train/prior_ent_max 77.76 / train/prior_ent_mean 45.81 / train/prior_ent_min 30.63 / train/prior_ent_std 5.65 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.92 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.77 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.27 / report/dyn_loss_std 5.36 / report/image_loss_mean 0.77 / report/image_loss_std 0.78 / report/model_loss_mean 2.95 / report/model_loss_std 3.84 / report/post_ent_mag 52.56 / report/post_ent_max 52.56 /
report/post_ent_mean 41.73 / report/post_ent_min 25.27 / report/post_ent_std 4.21 / report/prior_ent_mag 78.01 / report/prior_ent_max 78.01 / report/prior_ent_mean 44.83 / report/prior_ent_min 29.01 / report/prior_ent_std 5.97 / report/rep_loss_mean 3.27 / 
report/rep_loss_std 5.36 / report/reward_avg 0.49 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 1.95 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.49 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.69 / eval/dyn_loss_std 5.24 / eval/image_loss_mean 0.8 / eval/image_loss_std 1.03 / eval/model_loss_mean 3.32 / eval/model_loss_std 3.81 / eval/post_ent_mag 49.82 / eval/post_ent_max 49.82 / eval/post_ent_mean 
41.98 / eval/post_ent_min 25.96 / eval/post_ent_std 3.42 / eval/prior_ent_mag 78.01 / eval/prior_ent_max 78.01 / eval/prior_ent_mean 45.61 / eval/prior_ent_min 32.34 / eval/prior_ent_std 5.04 / eval/rep_loss_mean 3.69 / eval/rep_loss_std 5.24 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.4 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.66 / eval/reward_rate 0.49 / 
replay/size 4.3e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3806 / timer/env.step_total 19.63 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.5 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.56 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / 
timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.96 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.36

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 432500 Counter(432500) 432437
eval_Episode has 500 steps and return 321.7.
train_Episode has 500 steps and return 298.0.
Starting evaluation at step 433000 Counter(433000) 432937
Saved chunk: 20230922T065921F911185-5NQiEDe4cmPJKeGA2L0nR2-4a9X7cjbj0qz7vxPDpeesB-1024.npz
eval_Episode has 500 steps and return 323.4.
Saved chunk: 20230922T065933F316350-2g1uP5BrgapNMU3RHLZbEs-2Rm3ykpFsrYwVPiLAbhLjz-1024.npz
train_Episode has 500 steps and return 307.2.
Starting evaluation at step 433500 Counter(433500) 433437
eval_Episode has 500 steps and return 324.8.
train_Episode has 500 steps and return 320.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T070055F459743-2Rm3ykpFsrYwVPiLAbhLjz-0000000000000000000000-748.npz
Saved chunk: 20230922T070042F389996-4a9X7cjbj0qz7vxPDpeesB-0000000000000000000000-790.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 434000 Counter(434000) 433937
Saved chunk: 20230922T070042F389996-4a9X7cjbj0qz7vxPDpeesB-6OGtENdRvkgrjCnVeWAMcp-1024.npz
eval_Episode has 500 steps and return 304.1.
Saved chunk: 20230922T070055F459743-2Rm3ykpFsrYwVPiLAbhLjz-1Qk52KZgCGLQqB5WlS0igF-1024.npz
train_Episode has 500 steps and return 305.2.
Starting evaluation at step 434500 Counter(434500) 434437
eval_Episode has 500 steps and return 324.3.
train_Episode has 500 steps and return 258.2.
Starting evaluation at step 435000 Counter(435000) 434937
Saved chunk: 20230922T070202F027717-6OGtENdRvkgrjCnVeWAMcp-5Zfcx0cq0hEa6oC9ZCnoJL-1024.npz
eval_Episode has 500 steps and return 323.2.
Saved chunk: 20230922T070216F632390-1Qk52KZgCGLQqB5WlS0igF-5AWnZrnJ2OlONNkZznCn69-1024.npz
train_Episode has 500 steps and return 283.9.
Starting evaluation at step 435500 Counter(435500) 435437
eval_Episode has 500 steps and return 311.0.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 436000 Counter(436000) 435937
Saved chunk: 20230922T070321F320200-5Zfcx0cq0hEa6oC9ZCnoJL-2g5rg1aLKo1rrK2NVfgEgM-1024.npz
eval_Episode has 500 steps and return 325.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 872398 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 325.27 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 293.47 / episode/reward_rate 0.46 / train/action_mag 4 / train/action_max 3.99 / train/action_mean 0.09 / train/action_min -3.23 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.34 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 8.21 / train/adv_mag 0.41 / train/adv_max 0.28 / train/adv_mean -2.1e-5 / train/adv_min
-0.38 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.13 / train/extr_critic_max 236.13 / train/extr_critic_mean 228.39 / train/extr_critic_min 202.48 / train/extr_critic_std 5.88 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.23 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.31 / train/extr_return_raw_max 236.31 / train/extr_return_raw_mean 228.39 / train/extr_return_raw_min 
201.98 / train/extr_return_raw_std 5.91 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.89 / train/image_loss_std 0.91 / train/model_loss_mean 3.33 /
train/model_loss_std 4.24 / train/model_opt_grad_norm 7.85 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.1 / train/policy_entropy_max 
3.7 / train/policy_entropy_mean -2.71 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.01 / train/policy_logprob_mag 9.07 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.71 / train/policy_logprob_min -9.07 / train/policy_logprob_std 1.74 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4.9e-5 / train/policy_randomness_std 0.11 / train/post_ent_mag 51.96 / train/post_ent_max 51.96 / train/post_ent_mean 42.16 / 
train/post_ent_min 23.25 / train/post_ent_std 4.26 / train/prior_ent_mag 77.71 / train/prior_ent_max 77.71 / train/prior_ent_mean 45.83 / train/prior_ent_min 30.79 / train/prior_ent_std 5.56 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.9 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.47 / train/reward_rate 
0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.73 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 9.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.25 / report/image_loss_mean 0.88 / report/image_loss_std 0.91 / report/model_loss_mean 3.39 / report/model_loss_std 4.45 / report/post_ent_mag 51.37 / report/post_ent_max 51.37 /
report/post_ent_mean 42.25 / report/post_ent_min 20.09 / report/post_ent_std 4.05 / report/prior_ent_mag 77.74 / report/prior_ent_max 77.74 / report/prior_ent_mean 46.12 / report/prior_ent_min 32.98 / report/prior_ent_std 5.38 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 6.25 / report/reward_avg 0.47 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 1.98 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.47 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4 / eval/dyn_loss_std 6 / eval/image_loss_mean 0.91 / eval/image_loss_std 1.2 / eval/model_loss_mean 3.59 / eval/model_loss_std 4.43 / eval/post_ent_mag 52.76 / eval/post_ent_max 52.76 / eval/post_ent_mean 41.99 /
eval/post_ent_min 21.3 / eval/post_ent_std 3.66 / eval/prior_ent_mag 77.74 / eval/prior_ent_max 77.74 / eval/prior_ent_mean 45.81 / eval/prior_ent_min 28.93 / eval/prior_ent_std 5.28 / eval/rep_loss_mean 4 / eval/rep_loss_std 6 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 4.4e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3752 / timer/env.step_total 19.55 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.18 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.56 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241.59 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T070337F493356-5AWnZrnJ2OlONNkZznCn69-2XTZU6FCSRRwgbT86Jln8K-1024.npz
train_Episode has 500 steps and return 275.4.
Starting evaluation at step 436500 Counter(436500) 436437
eval_Episode has 500 steps and return 331.1.
train_Episode has 500 steps and return 318.3.
Starting evaluation at step 437000 Counter(437000) 436937
Saved chunk: 20230922T070440F373981-2g5rg1aLKo1rrK2NVfgEgM-3OaGorYd6owuOb2UzRJ9Bf-1024.npz
eval_Episode has 500 steps and return 331.4.
Saved chunk: 20230922T070459F201016-2XTZU6FCSRRwgbT86Jln8K-73uaAmEpVGfhg3SGzFCJAo-1024.npz
train_Episode has 500 steps and return 299.6.
Starting evaluation at step 437500 Counter(437500) 437437
eval_Episode has 500 steps and return 325.3.
train_Episode has 500 steps and return 303.6.
Starting evaluation at step 438000 Counter(438000) 437937
Saved chunk: 20230922T070600F974681-3OaGorYd6owuOb2UzRJ9Bf-0rWe45qs0RgcRqlJv3EaAC-1024.npz
eval_Episode has 500 steps and return 317.2.
Saved chunk: 20230922T070620F314184-73uaAmEpVGfhg3SGzFCJAo-180o5HJAhHa5jviODfpoVc-1024.npz
train_Episode has 500 steps and return 309.5.
Starting evaluation at step 438500 Counter(438500) 438437
eval_Episode has 500 steps and return 314.9.
train_Episode has 500 steps and return 317.5.
Starting evaluation at step 439000 Counter(439000) 438937
Saved chunk: 20230922T070720F257324-0rWe45qs0RgcRqlJv3EaAC-1E7ObH8LfCmoxDMY5TWDGo-1024.npz
eval_Episode has 500 steps and return 327.2.
Saved chunk: 20230922T070741F117332-180o5HJAhHa5jviODfpoVc-4NUU116RxadcFkQfS9twdh-1024.npz
train_Episode has 500 steps and return 293.8.
Starting evaluation at step 439500 Counter(439500) 439437
eval_Episode has 500 steps and return 339.8.
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 440000 Counter(440000) 439937
Saved chunk: 20230922T070839F402921-1E7ObH8LfCmoxDMY5TWDGo-1cWtsMZLVopwJympM4Ni12-1024.npz
eval_Episode has 500 steps and return 327.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 880002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 280.83 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 327.16 / eval_episode/reward_rate 0.48 / train/action_mag 4.06 / train/action_max 4.02 / train/action_mean 0.09 / train/action_min -3.33 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 4.32 / train/adv_mag 0.52 / train/adv_max 0.42 / train/adv_mean 3.7e-4
/ train/adv_min -0.38 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.69 / train/dyn_loss_std 5.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.04 / train/extr_critic_max 236.04 / train/extr_critic_mean 227.61 / train/extr_critic_min 186.58 / train/extr_critic_std 8.73 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.25 / train/extr_return_raw_max 236.25 / train/extr_return_raw_mean 227.62 / train/extr_return_raw_min 
188.27 / train/extr_return_raw_std 8.76 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.89 / train/image_loss_std 0.9 / train/model_loss_mean 3.32 / 
train/model_loss_std 4.24 / train/model_opt_grad_norm 7.93 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.28 / train/policy_entropy_max 
3.83 / train/policy_entropy_mean -2.7 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.37 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.7 / train/policy_logprob_min -9.37 / train/policy_logprob_std 1.79 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4.6e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.01 / train/post_ent_max 52.01 / train/post_ent_mean 42.06 / 
train/post_ent_min 22.63 / train/post_ent_std 4.34 / train/prior_ent_mag 77.72 / train/prior_ent_max 77.72 / train/prior_ent_mean 45.72 / train/prior_ent_min 30.58 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.69 / train/rep_loss_std 5.92 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.47 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.79 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 9.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.61 / report/dyn_loss_std 6.11 / report/image_loss_mean 0.89 / report/image_loss_std 0.98 / report/model_loss_mean 3.28 / report/model_loss_std 4.46 / report/post_ent_mag 52.55 / report/post_ent_max 52.55 /
report/post_ent_mean 43.11 / report/post_ent_min 22.64 / report/post_ent_std 4 / report/prior_ent_mag 77.64 / report/prior_ent_max 77.64 / report/prior_ent_mean 46.57 / report/prior_ent_min 33.49 / report/prior_ent_std 5.2 / report/rep_loss_mean 3.61 / 
report/rep_loss_std 6.11 / report/reward_avg 0.44 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 1.98 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 3.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.44 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.73 / eval/dyn_loss_std 6.98 / eval/image_loss_mean 1.28 / eval/image_loss_std 2.01 / eval/model_loss_mean 4.39 / eval/model_loss_std 5.65 / eval/post_ent_mag 50.67 / eval/post_ent_max 50.67 / eval/post_ent_mean 
40.99 / eval/post_ent_min 22.94 / eval/post_ent_std 4.63 / eval/prior_ent_mag 77.64 / eval/prior_ent_max 77.64 / eval/prior_ent_mean 45.24 / eval/prior_ent_min 31.12 / eval/prior_ent_std 5.9 / eval/rep_loss_mean 4.73 / eval/rep_loss_std 6.98 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.6 / eval/reward_rate 0.44 / 
replay/size 4.4e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.11 / timer/env.step_count 3802 / timer/env.step_total 19.63 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.68 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.9e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7810 / timer/agent.policy_total 17.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / 
timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.47 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T070901F790213-4NUU116RxadcFkQfS9twdh-19jQZeixOmNf1DbrfNkmWw-1024.npz
train_Episode has 500 steps and return 322.7.
Starting evaluation at step 440500 Counter(440500) 440437
eval_Episode has 500 steps and return 319.6.
train_Episode has 500 steps and return 294.2.
Starting evaluation at step 441000 Counter(441000) 440937
Saved chunk: 20230922T070958F430998-1cWtsMZLVopwJympM4Ni12-1Jllx9MVJkXRWLpWbLJWJV-1024.npz
eval_Episode has 500 steps and return 329.1.
Saved chunk: 20230922T071023F496520-19jQZeixOmNf1DbrfNkmWw-5i9whHjjUn18Wfx6Z9Gc9s-1024.npz
train_Episode has 500 steps and return 287.6.
Starting evaluation at step 441500 Counter(441500) 441437
eval_Episode has 500 steps and return 322.5.
train_Episode has 500 steps and return 318.5.
Starting evaluation at step 442000 Counter(442000) 441937
eval_Episode has 500 steps and return 330.4.
Saved chunk: 20230922T071118F964750-1Jllx9MVJkXRWLpWbLJWJV-3KBKNWlOaxn5i9SASDep2J-1024.npz
Saved chunk: 20230922T071144F612048-5i9whHjjUn18Wfx6Z9Gc9s-00ygmQr9obetWj4rV4apEs-1024.npz
train_Episode has 500 steps and return 294.9.
Starting evaluation at step 442500 Counter(442500) 442437
eval_Episode has 500 steps and return 336.6.
train_Episode has 500 steps and return 308.6.
Starting evaluation at step 443000 Counter(443000) 442937
eval_Episode has 500 steps and return 323.8.
Saved chunk: 20230922T071238F388019-3KBKNWlOaxn5i9SASDep2J-08QQWtKFBjFsE5SpsWYPIX-1024.npz
train_Episode has 500 steps and return 310.6.
Saved chunk: 20230922T071305F535827-00ygmQr9obetWj4rV4apEs-3dsAsI87sGAFDwR0bn3ENA-1024.npz
Starting evaluation at step 443500 Counter(443500) 443437
eval_Episode has 500 steps and return 340.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 887614 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 310.56 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 340.89 / eval_episode/reward_rate 0.52 / train/action_mag 4.06 / train/action_max 4.03 / train/action_mean 0.09 / train/action_min -3.36 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.35 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 5.61 / train/adv_mag 0.42 / train/adv_max 0.31 / train/adv_mean 2.3e-4
/ train/adv_min -0.37 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 5.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.26 / train/extr_critic_max 236.26 / train/extr_critic_mean 228.07 / train/extr_critic_min 193.25 / train/extr_critic_std 7.68 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.45 / train/extr_return_raw_max 236.45 / train/extr_return_raw_mean 228.08 / train/extr_return_raw_min 
192.27 / train/extr_return_raw_std 7.7 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.87 / train/image_loss_std 0.87 / train/model_loss_mean 3.28 / 
train/model_loss_std 4.16 / train/model_opt_grad_norm 8.09 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.22 / train/policy_entropy_max 
3.68 / train/policy_entropy_mean -2.68 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.18 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.68 / train/policy_logprob_min -9.18 / train/policy_logprob_std 1.79 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.96 / train/post_ent_max 51.96 / train/post_ent_mean 42.11 / 
train/post_ent_min 23.21 / train/post_ent_std 4.22 / train/prior_ent_mag 77.61 / train/prior_ent_max 77.61 / train/prior_ent_mean 45.73 / train/prior_ent_min 30.85 / train/prior_ent_std 5.55 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.8 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.47 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.78 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 9.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.88 / report/dyn_loss_std 6.12 / report/image_loss_mean 1.02 / report/image_loss_std 1.07 / report/model_loss_mean 3.54 / report/model_loss_std 4.39 / report/post_ent_mag 51.46 / report/post_ent_max 51.46 /
report/post_ent_mean 42.19 / report/post_ent_min 20.74 / report/post_ent_std 4.77 / report/prior_ent_mag 77.72 / report/prior_ent_max 77.72 / report/prior_ent_mean 46.13 / report/prior_ent_min 28.72 / report/prior_ent_std 5.75 / report/rep_loss_mean 3.88 / 
report/rep_loss_std 6.12 / report/reward_avg 0.42 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.42 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 9.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.67 / eval/dyn_loss_std 5.78 / eval/image_loss_mean 0.78 / eval/image_loss_std 0.83 / eval/model_loss_mean 3.28 / eval/model_loss_std 4.08 / eval/post_ent_mag 49.74 / eval/post_ent_max 49.74 / eval/post_ent_mean 
41.99 / eval/post_ent_min 24.69 / eval/post_ent_std 3.45 / eval/prior_ent_mag 77.72 / eval/prior_ent_max 77.72 / eval/prior_ent_mean 45.74 / eval/prior_ent_min 38.49 / eval/prior_ent_std 5.1 / eval/rep_loss_mean 3.67 / eval/rep_loss_std 5.78 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.9e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.65 / eval/reward_rate 0.5 / 
replay/size 4.4e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3806 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 464.23 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.5 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 /
timer/dataset_train_count 1903 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.92 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 294.7.
Starting evaluation at step 444000 Counter(444000) 443937
eval_Episode has 500 steps and return 344.0.
Saved chunk: 20230922T071357F475022-08QQWtKFBjFsE5SpsWYPIX-7qkfOq3uBp2HnQoXspLbDo-1024.npz
train_Episode has 500 steps and return 281.9.
Saved chunk: 20230922T071426F136407-3dsAsI87sGAFDwR0bn3ENA-65gdQ2zjUfOQ2NRGGeTIb6-1024.npz
Starting evaluation at step 444500 Counter(444500) 444437
eval_Episode has 500 steps and return 330.4.
train_Episode has 500 steps and return 311.1.
Starting evaluation at step 445000 Counter(445000) 444937
eval_Episode has 500 steps and return 308.1.
Saved chunk: 20230922T071517F715251-7qkfOq3uBp2HnQoXspLbDo-1gdNq5wHM2iFzDxvx8hI2t-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T071637F179892-1gdNq5wHM2iFzDxvx8hI2t-0000000000000000000000-25.npz
Saved chunk: 20230922T071548F102904-65gdQ2zjUfOQ2NRGGeTIb6-0000000000000000000000-884.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 307.4.
Saved chunk: 20230922T071548F102904-65gdQ2zjUfOQ2NRGGeTIb6-5e8EH84qsiuOOUEG3F7MKf-1024.npz
Starting evaluation at step 445500 Counter(445500) 445437
eval_Episode has 500 steps and return 326.6.
train_Episode has 500 steps and return 267.2.
Starting evaluation at step 446000 Counter(446000) 445937
eval_Episode has 500 steps and return 328.5.
Saved chunk: 20230922T071637F179892-1gdNq5wHM2iFzDxvx8hI2t-6ZrnuzYWTCxxJdpCuYBBFa-1024.npz
train_Episode has 500 steps and return 302.9.
Saved chunk: 20230922T071709F327520-5e8EH84qsiuOOUEG3F7MKf-3prUrvYQr0xA5IExPdmurL-1024.npz
Starting evaluation at step 446500 Counter(446500) 446437
eval_Episode has 500 steps and return 323.5.
train_Episode has 500 steps and return 301.5.
Starting evaluation at step 447000 Counter(447000) 446937
eval_Episode has 500 steps and return 322.4.
train_Episode has 500 steps and return 285.4.
Saved chunk: 20230922T071830F145480-3prUrvYQr0xA5IExPdmurL-20hum9Dgz9hNjCgUrMr8XN-1024.npz
Starting evaluation at step 447500 Counter(447500) 447437
Saved chunk: 20230922T071756F749912-6ZrnuzYWTCxxJdpCuYBBFa-5OWBaPZ3jMc5eR6qYyGJwR-1024.npz
eval_Episode has 500 steps and return 345.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 895122 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 285.42 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 345 / eval_episode/reward_rate 0.52 / train/action_mag 4.12 / train/action_max 4.07 / train/action_mean 0.09 / train/action_min -3.4 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.33 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 3.51 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean 4.4e-4 / train/adv_min 
-0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.43 / train/extr_critic_max 236.43 / train/extr_critic_mean 228.14 / train/extr_critic_min 192.91 / train/extr_critic_std 7.74 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.62 / train/extr_return_raw_max 236.62 / train/extr_return_raw_mean 228.16 / train/extr_return_raw_min 
193.88 / train/extr_return_raw_std 7.76 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.88 / train/image_loss_std 0.9 / train/model_loss_mean 3.31 / 
train/model_loss_std 4.23 / train/model_opt_grad_norm 7.94 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.3 / train/policy_entropy_max 
3.84 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.1 / train/policy_logprob_mag 9.61 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -9.61 / train/policy_logprob_std 1.8 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.09 / train/post_ent_max 52.09 / train/post_ent_mean 42.07 / 
train/post_ent_min 23.01 / train/post_ent_std 4.28 / train/prior_ent_mag 77.68 / train/prior_ent_max 77.68 / train/prior_ent_mean 45.72 / train/prior_ent_min 30.72 / train/prior_ent_std 5.62 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.9 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.76 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.29 / report/dyn_loss_std 5.14 / report/image_loss_mean 0.74 / report/image_loss_std 0.63 / report/model_loss_mean 2.93 / report/model_loss_std 3.65 / report/post_ent_mag 52.88 / report/post_ent_max 52.88 /
report/post_ent_mean 41.32 / report/post_ent_min 21.29 / report/post_ent_std 6 / report/prior_ent_mag 77.67 / report/prior_ent_max 77.67 / report/prior_ent_mean 44.73 / report/prior_ent_min 23.75 / report/prior_ent_std 7.1 / report/rep_loss_mean 3.29 / 
report/rep_loss_std 5.14 / report/reward_avg 0.45 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.32 / report/reward_max_data 1.98 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.44 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.72 / eval/dyn_loss_std 5.54 / eval/image_loss_mean 0.79 / eval/image_loss_std 0.87 / eval/model_loss_mean 3.31 / eval/model_loss_std 4 / eval/post_ent_mag 51.97 / eval/post_ent_max 51.97 / eval/post_ent_mean 
41.96 / eval/post_ent_min 25.22 / eval/post_ent_std 3.49 / eval/prior_ent_mag 77.67 / eval/prior_ent_max 77.67 / eval/prior_ent_mean 45.61 / eval/prior_ent_min 38.2 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 3.72 / eval/rep_loss_std 5.54 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.64 / eval/reward_rate 0.48 / 
replay/size 4.5e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3754 / timer/env.step_total 19.48 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.51 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8.1e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.46 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 293.8.
Starting evaluation at step 448000 Counter(448000) 447937
eval_Episode has 500 steps and return 316.5.
train_Episode has 500 steps and return 310.0.
Starting evaluation at step 448500 Counter(448500) 448437
Saved chunk: 20230922T071951F770005-5OWBaPZ3jMc5eR6qYyGJwR-5fdFZbYkGFWv6tWOmvYeFW-1024.npz
eval_Episode has 500 steps and return 312.3.
Saved chunk: 20230922T071950F768442-20hum9Dgz9hNjCgUrMr8XN-56Jw5WZOGDvQgu6nNyPlvo-1024.npz
train_Episode has 500 steps and return 300.4.
Starting evaluation at step 449000 Counter(449000) 448937
eval_Episode has 500 steps and return 320.2.
train_Episode has 500 steps and return 308.5.
Starting evaluation at step 449500 Counter(449500) 449437
Saved chunk: 20230922T072112F390406-5fdFZbYkGFWv6tWOmvYeFW-1deX2WScpwMzXe20UBndCU-1024.npz
eval_Episode has 500 steps and return 329.3.
Saved chunk: 20230922T072116F509605-56Jw5WZOGDvQgu6nNyPlvo-7oN1QmSESOBM3XgeP1YmPc-1024.npz
train_Episode has 500 steps and return 298.5.
Starting evaluation at step 450000 Counter(450000) 449937
eval_Episode has 500 steps and return 316.6.
train_Episode has 500 steps and return 283.6.
Starting evaluation at step 450500 Counter(450500) 450437
Saved chunk: 20230922T072231F733631-1deX2WScpwMzXe20UBndCU-6hnTXX9Vp4mU8mZs9QjITQ-1024.npz
eval_Episode has 500 steps and return 337.7.
Saved chunk: 20230922T072237F437837-7oN1QmSESOBM3XgeP1YmPc-4RHZGRpujdPd2F3vYnAlBt-1024.npz
train_Episode has 500 steps and return 306.4.
Starting evaluation at step 451000 Counter(451000) 450937
eval_Episode has 500 steps and return 337.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 902726 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 306.44 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 336.96 / eval_episode/reward_rate 0.5 / train/action_mag 4.04 / train/action_max 4.01 / train/action_mean 0.1 / train/action_min -3.36 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.32 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 4.64 / train/adv_mag 0.43 / train/adv_max 0.33 / train/adv_mean 3.3e-4 / train/adv_min 
-0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.61 / train/extr_critic_max 236.61 / train/extr_critic_mean 228.46 / train/extr_critic_min 193.76 / train/extr_critic_std 7.64 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.82 / train/extr_return_raw_max 236.82 / train/extr_return_raw_mean 228.47 / train/extr_return_raw_min 
193.75 / train/extr_return_raw_std 7.66 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.87 / train/image_loss_std 0.88 / train/model_loss_mean 3.28 /
train/model_loss_std 4.16 / train/model_opt_grad_norm 7.72 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.33 / train/policy_entropy_max 
3.82 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.1 / train/policy_logprob_mag 9.32 / train/policy_logprob_max 5.5 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -9.32 / train/policy_logprob_std 1.8 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4.5e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.07 / train/post_ent_max 52.07 / train/post_ent_mean 42.05 / 
train/post_ent_min 22.94 / train/post_ent_std 4.27 / train/prior_ent_mag 77.59 / train/prior_ent_max 77.59 / train/prior_ent_mean 45.68 / train/prior_ent_min 30.53 / train/prior_ent_std 5.61 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.82 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.9 / report/dyn_loss_std 6.38 / report/image_loss_mean 0.96 / report/image_loss_std 1.14 / report/model_loss_mean 3.55 / report/model_loss_std 4.73 / report/post_ent_mag 52.06 / report/post_ent_max 52.06 / 
report/post_ent_mean 41.84 / report/post_ent_min 25.05 / report/post_ent_std 4.4 / report/prior_ent_mag 77.42 / report/prior_ent_max 77.42 / report/prior_ent_mean 45.65 / report/prior_ent_min 29.84 / report/prior_ent_std 5.5 / report/rep_loss_mean 3.9 / 
report/rep_loss_std 6.38 / report/reward_avg 0.52 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.35 / report/reward_max_data 1.97 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.51 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.19 / eval/dyn_loss_std 6.64 / eval/image_loss_mean 1.02 / eval/image_loss_std 1.79 / eval/model_loss_mean 3.82 / eval/model_loss_std 5.39 / eval/post_ent_mag 50.46 / eval/post_ent_max 50.46 / eval/post_ent_mean 
41.66 / eval/post_ent_min 22.73 / eval/post_ent_std 3.7 / eval/prior_ent_mag 77.42 / eval/prior_ent_max 77.42 / eval/prior_ent_mean 45.45 / eval/prior_ent_min 35.03 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 4.19 / eval/rep_loss_std 6.64 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.62 / eval/reward_rate 0.46 / 
replay/size 4.5e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3802 / timer/env.step_total 19.85 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 466.1 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.48 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.2e-3 
/ timer/dataset_train_count 1901 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.8e-5 / timer/dataset_train_max 6.9e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.72 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 277.5.
Starting evaluation at step 451500 Counter(451500) 451437
Saved chunk: 20230922T072351F002965-6hnTXX9Vp4mU8mZs9QjITQ-0tALa8Y5fOGF10oW8W5n7a-1024.npz
eval_Episode has 500 steps and return 310.0.
Saved chunk: 20230922T072358F265912-4RHZGRpujdPd2F3vYnAlBt-06EaPjDQKHoytWoPWMV06V-1024.npz
train_Episode has 500 steps and return 264.0.
Starting evaluation at step 452000 Counter(452000) 451937
eval_Episode has 500 steps and return 337.6.
train_Episode has 500 steps and return 284.8.
Starting evaluation at step 452500 Counter(452500) 452437
eval_Episode has 500 steps and return 317.2.
Saved chunk: 20230922T072511F310741-0tALa8Y5fOGF10oW8W5n7a-4OU8zS1k9CCfTquty8Q3R7-1024.npz
Saved chunk: 20230922T072520F212230-06EaPjDQKHoytWoPWMV06V-6xGynRAg4LRQMFRMeT2Rpr-1024.npz
train_Episode has 500 steps and return 305.3.
Starting evaluation at step 453000 Counter(453000) 452937
eval_Episode has 500 steps and return 308.2.
train_Episode has 500 steps and return 278.0.
Starting evaluation at step 453500 Counter(453500) 453437
Saved chunk: 20230922T072630F953892-4OU8zS1k9CCfTquty8Q3R7-5pvY9zGtQqNTvCeiFlKprP-1024.npz
eval_Episode has 500 steps and return 322.9.
Saved chunk: 20230922T072641F438267-6xGynRAg4LRQMFRMeT2Rpr-1rMiVAfYCK6dkihio7JWjI-1024.npz
train_Episode has 500 steps and return 283.2.
Starting evaluation at step 454000 Counter(454000) 453937
eval_Episode has 500 steps and return 317.1.
train_Episode has 500 steps and return 303.1.
Starting evaluation at step 454500 Counter(454500) 454437
Saved chunk: 20230922T072750F428704-5pvY9zGtQqNTvCeiFlKprP-48MIx3GJtLlFPv42rxxf7l-1024.npz
eval_Episode has 500 steps and return 327.1.
Saved chunk: 20230922T072802F482492-1rMiVAfYCK6dkihio7JWjI-2zZZoMopE0q7gcjmwllRJq-1024.npz
train_Episode has 500 steps and return 307.6.
Starting evaluation at step 455000 Counter(455000) 454937
eval_Episode has 500 steps and return 335.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 910222 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 307.59 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 335.17 / eval_episode/reward_rate 0.47 / train/action_mag 4.06 / train/action_max 4.02 / train/action_mean 0.09 / train/action_min -3.36 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.35 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 10.59 / train/adv_mag 0.45 / train/adv_max 0.34 / train/adv_mean 
-2.7e-4 / train/adv_min -0.4 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.88 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / 
train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.54 / train/extr_critic_max 236.54 / train/extr_critic_mean 228.39 / train/extr_critic_min 195.28 / train/extr_critic_std 7.43 / 
train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.06 / train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.74 / train/extr_return_raw_max 
236.74 / train/extr_return_raw_mean 228.38 / train/extr_return_raw_min 193.95 / train/extr_return_raw_std 7.47 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / 
train/image_loss_mean 0.88 / train/image_loss_std 0.9 / train/model_loss_mean 3.31 / train/model_loss_std 4.22 / train/model_opt_grad_norm 8.08 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.21 / train/policy_entropy_max 3.65 / train/policy_entropy_mean -2.69 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.37 / train/policy_logprob_max 5.5 / 
train/policy_logprob_mean 2.69 / train/policy_logprob_min -9.37 / train/policy_logprob_std 1.78 / train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4.3e-5 / train/policy_randomness_std 
0.12 / train/post_ent_mag 52.1 / train/post_ent_max 52.1 / train/post_ent_mean 42.02 / train/post_ent_min 23.13 / train/post_ent_std 4.27 / train/prior_ent_mag 77.68 / train/prior_ent_max 77.68 / train/prior_ent_mean 45.68 / train/prior_ent_min 30.94 / 
train/prior_ent_std 5.61 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.88 / train/reward_avg 0.47 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.96 / train/reward_neg_acc 1 / train/reward_neg_loss 
5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.47 / train/reward_rate 0.37 / train_stats/mean_log_entropy -2.77 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.2e-11 / report/cont_loss_std 3.8e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.59 / report/dyn_loss_std 5.19 / report/image_loss_mean 0.7 / report/image_loss_std 0.53 / 
report/model_loss_mean 3.15 / report/model_loss_std 3.58 / report/post_ent_mag 51.08 / report/post_ent_max 51.08 / report/post_ent_mean 42.31 / report/post_ent_min 28.17 / report/post_ent_std 3.45 / report/prior_ent_mag 77.82 / report/prior_ent_max 77.82 / 
report/prior_ent_mean 46.04 / report/prior_ent_min 36.87 / report/prior_ent_std 5.09 / report/rep_loss_mean 3.59 / report/rep_loss_std 5.19 / report/reward_avg 0.6 / report/reward_loss_mean 0.29 / report/reward_loss_std 0.39 / report/reward_max_data 2 / 
report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.6 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 8.8e-11 
/ eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.08 / eval/dyn_loss_std 6.17 / eval/image_loss_mean 0.92 / eval/image_loss_std 1.24 / eval/model_loss_mean 3.64 
/ eval/model_loss_std 4.67 / eval/post_ent_mag 49.79 / eval/post_ent_max 49.79 / eval/post_ent_mean 41.84 / eval/post_ent_min 19.53 / eval/post_ent_std 3.68 / eval/prior_ent_mag 77.82 / eval/prior_ent_max 77.82 / eval/prior_ent_mean 45.6 / eval/prior_ent_min 34.92 / 
eval/prior_ent_std 5.12 / eval/rep_loss_mean 4.08 / eval/rep_loss_std 6.17 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.7e-3 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.62 / eval/reward_rate 0.46 / replay/size 4.6e5 / replay/inserts 3748 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3748 / timer/env.step_total 19.38 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.37 / timer/replay._sample_frac 1.51 / 
timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7756 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1874 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1874 / timer/agent.train_total 241.61 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 24.98

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 328.9.
Starting evaluation at step 455500 Counter(455500) 455437
Saved chunk: 20230922T072909F665813-48MIx3GJtLlFPv42rxxf7l-34euX5ODdzke9kSY9axnKt-1024.npz
eval_Episode has 500 steps and return 332.9.
Saved chunk: 20230922T072923F216219-2zZZoMopE0q7gcjmwllRJq-4jmAnNWk2giWT9UkOE1Ehl-1024.npz
train_Episode has 500 steps and return 313.8.
Starting evaluation at step 456000 Counter(456000) 455937
eval_Episode has 500 steps and return 299.2.
train_Episode has 500 steps and return 308.4.
Starting evaluation at step 456500 Counter(456500) 456437
Saved chunk: 20230922T073030F166667-34euX5ODdzke9kSY9axnKt-2avwxNPeoeLhRJfVP2iYA1-1024.npz
eval_Episode has 500 steps and return 319.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T073149F746611-2avwxNPeoeLhRJfVP2iYA1-0000000000000000000000-284.npz
Saved chunk: 20230922T073045F394853-4jmAnNWk2giWT9UkOE1Ehl-0000000000000000000000-1020.npz
Saved chunk: 20230922T073045F394853-4jmAnNWk2giWT9UkOE1Ehl-5gaWrYvwvYsslrTnBNJH6Y-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 305.1.
Starting evaluation at step 457000 Counter(457000) 456937
eval_Episode has 500 steps and return 308.1.
train_Episode has 500 steps and return 291.5.
Starting evaluation at step 457500 Counter(457500) 457437
Saved chunk: 20230922T073149F746611-2avwxNPeoeLhRJfVP2iYA1-1WUuGpjE2DUVOTuPZUMpSz-1024.npz
eval_Episode has 500 steps and return 306.2.
Saved chunk: 20230922T073206F574376-5gaWrYvwvYsslrTnBNJH6Y-5gn7xuKc4NHbIqNxJTllR8-1024.npz
train_Episode has 500 steps and return 309.8.
Starting evaluation at step 458000 Counter(458000) 457937
eval_Episode has 500 steps and return 330.3.
train_Episode has 500 steps and return 272.7.
Starting evaluation at step 458500 Counter(458500) 458437
Saved chunk: 20230922T073309F247023-1WUuGpjE2DUVOTuPZUMpSz-6KZvhmCCfncXbj8MBMoSGs-1024.npz
eval_Episode has 500 steps and return 324.6.
Saved chunk: 20230922T073327F526010-5gn7xuKc4NHbIqNxJTllR8-6ntfAkl1CIk94duM4pZ154-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 917826 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 272.71 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 324.62 / eval_episode/reward_rate 0.48 / train/action_mag 4.05 / train/action_max 4 / train/action_mean 0.09 / train/action_min -3.39 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.33 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 5.15 / train/adv_mag 0.38 / train/adv_max 0.27 / train/adv_mean 2.7e-4 / train/adv_min 
-0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.94 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.55 / train/extr_critic_max 236.55 / train/extr_critic_mean 228.06 / train/extr_critic_min 189.91 / train/extr_critic_std 8.7 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 236.76 / train/extr_return_raw_max 236.76 / train/extr_return_raw_mean 228.07 / train/extr_return_raw_min 
188.99 / train/extr_return_raw_std 8.73 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.88 / train/image_loss_std 0.91 / train/model_loss_mean 3.32 /
train/model_loss_std 4.27 / train/model_opt_grad_norm 7.95 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.52 / train/policy_entropy_max 
4.09 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.14 / train/policy_logprob_mag 9.85 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -9.85 / train/policy_logprob_std 1.83 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4.3e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.19 / train/post_ent_max 52.19 / train/post_ent_mean 41.96 / 
train/post_ent_min 22.65 / train/post_ent_std 4.4 / train/prior_ent_mag 77.62 / train/prior_ent_max 77.62 / train/prior_ent_mean 45.6 / train/prior_ent_min 30.12 / train/prior_ent_std 5.73 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.94 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.46 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.08 / report/dyn_loss_std 6.97 / report/image_loss_mean 1.09 / report/image_loss_std 1.3 / report/model_loss_mean 3.72 / report/model_loss_std 5.2 / report/post_ent_mag 52.48 / report/post_ent_max 52.48 / 
report/post_ent_mean 41.63 / report/post_ent_min 23.86 / report/post_ent_std 4.77 / report/prior_ent_mag 77.7 / report/prior_ent_max 77.7 / report/prior_ent_mean 45.55 / report/prior_ent_min 29.14 / report/prior_ent_std 5.96 / report/rep_loss_mean 4.08 / 
report/rep_loss_std 6.97 / report/reward_avg 0.39 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.39 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 2.7e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.66 / eval/dyn_loss_std 5.52 / eval/image_loss_mean 0.86 / eval/image_loss_std 1.33 / eval/model_loss_mean 3.37 / eval/model_loss_std 4.26 / eval/post_ent_mag 52.42 / eval/post_ent_max 52.42 / eval/post_ent_mean 
41.84 / eval/post_ent_min 24.94 / eval/post_ent_std 3.78 / eval/prior_ent_mag 77.7 / eval/prior_ent_max 77.7 / eval/prior_ent_mean 45.4 / eval/prior_ent_min 34.09 / eval/prior_ent_std 5.27 / eval/rep_loss_mean 3.66 / eval/rep_loss_std 5.52 / eval/reward_avg 0.67 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.67 / eval/reward_rate 0.49 / 
replay/size 4.6e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3802 / timer/env.step_total 19.72 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.05 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.9e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.52 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1901 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.72 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / 
timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.34

train_Episode has 500 steps and return 299.2.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 459000 Counter(459000) 458937
eval_Episode has 500 steps and return 335.7.
train_Episode has 500 steps and return 325.0.
Starting evaluation at step 459500 Counter(459500) 459437
Saved chunk: 20230922T073428F294500-6KZvhmCCfncXbj8MBMoSGs-2uARbaacDKkABjqMYnf2I6-1024.npz
eval_Episode has 500 steps and return 323.0.
Saved chunk: 20230922T073448F150409-6ntfAkl1CIk94duM4pZ154-2RxCRrXwabOScEfiVWFvOo-1024.npz
train_Episode has 500 steps and return 272.5.
Starting evaluation at step 460000 Counter(460000) 459937
eval_Episode has 500 steps and return 327.7.
train_Episode has 500 steps and return 272.8.
Starting evaluation at step 460500 Counter(460500) 460437
Saved chunk: 20230922T073548F834947-2uARbaacDKkABjqMYnf2I6-2FNFUQr9RkCVYWw6o1c63H-1024.npz
eval_Episode has 500 steps and return 317.3.
Saved chunk: 20230922T073610F377655-2RxCRrXwabOScEfiVWFvOo-77bX3g9jZhZQl1PVNWhxau-1024.npz
train_Episode has 500 steps and return 314.8.
Starting evaluation at step 461000 Counter(461000) 460937
eval_Episode has 500 steps and return 332.2.
train_Episode has 500 steps and return 288.0.
Starting evaluation at step 461500 Counter(461500) 461437
Saved chunk: 20230922T073708F372161-2FNFUQr9RkCVYWw6o1c63H-4YXjvyexyMVuBNuKj2cWCD-1024.npz
eval_Episode has 500 steps and return 343.8.
Saved chunk: 20230922T073731F422971-77bX3g9jZhZQl1PVNWhxau-7Dpa4dLqC0znh5vR9ujVGR-1024.npz
train_Episode has 500 steps and return 303.7.
Starting evaluation at step 462000 Counter(462000) 461937
eval_Episode has 500 steps and return 320.7.
train_Episode has 500 steps and return 313.3.
Starting evaluation at step 462500 Counter(462500) 462437
Saved chunk: 20230922T073827F568797-4YXjvyexyMVuBNuKj2cWCD-49SEsemHhRDHjpJsU5HH08-1024.npz
eval_Episode has 500 steps and return 319.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 925330 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 313.31 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 319.03 / eval_episode/reward_rate 0.49 / train_stats/mean_log_entropy -2.77 / train/action_mag 4.09 / train/action_max 4.04 / train/action_mean 0.09 / 
train/action_min -3.44 / train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.33 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 5.68 / train/adv_mag 0.42 / train/adv_max 
0.29 / train/adv_mean 2.3e-4 / train/adv_min -0.4 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.66 / train/dyn_loss_std 5.86 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / 
train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 236.8 / train/extr_critic_max 236.8 / train/extr_critic_mean 228.72 / train/extr_critic_min 196.98 / train/extr_critic_std 7.05 / train/extr_return_normed_mag
1.26 / train/extr_return_normed_max 1.06 / train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.01 / train/extr_return_raw_max 237.01 / 
train/extr_return_raw_mean 228.73 / train/extr_return_raw_min 196 / train/extr_return_raw_std 7.08 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.48 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.87
/ train/image_loss_std 0.89 / train/model_loss_mean 3.28 / train/model_loss_std 4.2 / train/model_opt_grad_norm 7.81 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / 
train/policy_entropy_mag 4.47 / train/policy_entropy_max 3.99 / train/policy_entropy_mean -2.67 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.58 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.67 / 
train/policy_logprob_min -9.58 / train/policy_logprob_std 1.82 / train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4.2e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.1 / 
train/post_ent_max 52.1 / train/post_ent_mean 42.04 / train/post_ent_min 23.38 / train/post_ent_std 4.25 / train/prior_ent_mag 77.58 / train/prior_ent_max 77.58 / train/prior_ent_mean 45.66 / train/prior_ent_min 30.83 / train/prior_ent_std 5.61 / train/rep_loss_mean 
3.66 / train/rep_loss_std 5.86 / train/reward_avg 0.46 / train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / 
train/reward_pos_loss 0.58 / train/reward_pred 0.46 / train/reward_rate 0.37 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 /
report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.62 / report/dyn_loss_std 5.9 / report/image_loss_mean 0.79 / report/image_loss_std 0.71 / report/model_loss_mean 3.19 / report/model_loss_std 4.03 / report/post_ent_mag 52.21
/ report/post_ent_max 52.21 / report/post_ent_mean 42.53 / report/post_ent_min 20.81 / report/post_ent_std 3.95 / report/prior_ent_mag 77.59 / report/prior_ent_max 77.59 / report/prior_ent_mean 46.18 / report/prior_ent_min 31.15 / report/prior_ent_std 5.19 / 
report/rep_loss_mean 3.62 / report/rep_loss_std 5.9 / report/reward_avg 0.5 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.33 / report/reward_max_data 1.94 / report/reward_max_pred 1.96 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.3e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / report/reward_pred 0.5 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.86 / eval/dyn_loss_std 5.49 / eval/image_loss_mean 0.92 / eval/image_loss_std 1.17 / eval/model_loss_mean 3.5 / eval/model_loss_std 4.06 / eval/post_ent_mag 50.34 / eval/post_ent_max
50.34 / eval/post_ent_mean 41.61 / eval/post_ent_min 22.67 / eval/post_ent_std 3.91 / eval/prior_ent_mag 77.59 / eval/prior_ent_max 77.59 / eval/prior_ent_mean 45.51 / eval/prior_ent_min 28.53 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 3.86 / eval/rep_loss_std 5.49 
/ eval/reward_avg 0.61 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.61 / 
eval/reward_rate 0.46 / replay/size 4.6e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3752 / timer/env.step_total 19.4 / timer/env.step_frac 0.06 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.34 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.2e-3 / 
timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.65 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.19 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1876 / 
timer/agent.train_total 241.57 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T073852F112135-7Dpa4dLqC0znh5vR9ujVGR-4L3YWUfFt8dOTkEPwAN9mN-1024.npz
train_Episode has 500 steps and return 303.0.
Starting evaluation at step 463000 Counter(463000) 462937
eval_Episode has 500 steps and return 321.0.
train_Episode has 500 steps and return 293.1.
Starting evaluation at step 463500 Counter(463500) 463437
Saved chunk: 20230922T073946F749356-49SEsemHhRDHjpJsU5HH08-4g21YXKy3VKyqutIqmpUr4-1024.npz
eval_Episode has 500 steps and return 329.1.
Saved chunk: 20230922T074014F009201-4L3YWUfFt8dOTkEPwAN9mN-2XWyaqG8YcgPAwnQWRNKiX-1024.npz
train_Episode has 500 steps and return 289.6.
Starting evaluation at step 464000 Counter(464000) 463937
eval_Episode has 500 steps and return 335.4.
train_Episode has 500 steps and return 285.4.
Starting evaluation at step 464500 Counter(464500) 464437
Saved chunk: 20230922T074107F204686-4g21YXKy3VKyqutIqmpUr4-26tz4TlAUlMRZa4pyL7Xu7-1024.npz
eval_Episode has 500 steps and return 335.7.
Saved chunk: 20230922T074134F972896-2XWyaqG8YcgPAwnQWRNKiX-2qVwkBbw0FAGfj2wcq0JRm-1024.npz
train_Episode has 500 steps and return 325.0.
Starting evaluation at step 465000 Counter(465000) 464937
eval_Episode has 500 steps and return 331.8.
train_Episode has 500 steps and return 282.9.
Starting evaluation at step 465500 Counter(465500) 465437
Saved chunk: 20230922T074226F574657-26tz4TlAUlMRZa4pyL7Xu7-3yVihgiiQhu9Nud7V1kS5U-1024.npz
eval_Episode has 500 steps and return 330.8.
Saved chunk: 20230922T074255F877053-2qVwkBbw0FAGfj2wcq0JRm-320U3ov4PZaysXb0gLRNcd-1024.npz
train_Episode has 500 steps and return 303.2.
Starting evaluation at step 466000 Counter(466000) 465937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 269.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 932942 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 269.82 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.07 / train/action_max 4.01 / train/action_mean 0.09 / train/action_min -3.43 / train/action_std 0.89 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 5.99 / train/adv_mag 0.44 / train/adv_max 0.29 / train/adv_mean 1.9e-4 / train/adv_min -0.41 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.69 
/ train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss
1.2e4 / train/extr_critic_mag 236.92 / train/extr_critic_max 236.92 / train/extr_critic_mean 228.52 / train/extr_critic_min 189.62 / train/extr_critic_std 8.19 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.75 /
train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.12 / train/extr_return_raw_max 237.12 / train/extr_return_raw_mean 228.53 / train/extr_return_raw_min 188.92 / train/extr_return_raw_std 8.23
/ train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.88 / train/image_loss_std 0.91 / train/model_loss_mean 3.31 / train/model_loss_std 4.23 / 
train/model_opt_grad_norm 7.74 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 2.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7368.42 / train/policy_entropy_mag 4.38 / train/policy_entropy_max 3.83 / 
train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.64 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -9.64 / train/policy_logprob_std 1.82 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 4e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 52 / train/post_ent_max 52 / train/post_ent_mean 41.91 / train/post_ent_min 
22.99 / train/post_ent_std 4.32 / train/prior_ent_mag 77.51 / train/prior_ent_max 77.51 / train/prior_ent_mean 45.56 / train/prior_ent_min 30.59 / train/prior_ent_std 5.68 / train/rep_loss_mean 3.69 / train/rep_loss_std 5.89 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.47 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.8 / report/dyn_loss_std 6.2 / report/image_loss_mean 0.93 / report/image_loss_std 1.1 / report/model_loss_mean 3.43 / report/model_loss_std 4.57 / report/post_ent_mag 52.36 / report/post_ent_max 52.36 / 
report/post_ent_mean 41.59 / report/post_ent_min 17.3 / report/post_ent_std 4.71 / report/prior_ent_mag 77.77 / report/prior_ent_max 77.77 / report/prior_ent_mean 45.29 / report/prior_ent_min 26.65 / report/prior_ent_std 5.98 / report/rep_loss_mean 3.8 / 
report/rep_loss_std 6.2 / report/reward_avg 0.43 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.36 / report/reward_max_data 1.93 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.62 / report/reward_pred 0.43 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.53 / eval/dyn_loss_std 6.63 / eval/image_loss_mean 1.11 / eval/image_loss_std 1.51 / eval/model_loss_mean 4.12 / eval/model_loss_std 5.15 / eval/post_ent_mag 51.05 / eval/post_ent_max 51.05 / eval/post_ent_mean 
41.65 / eval/post_ent_min 22.73 / eval/post_ent_std 4.08 / eval/prior_ent_mag 77.77 / eval/prior_ent_max 77.77 / eval/prior_ent_mean 45.85 / eval/prior_ent_min 33.26 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 4.53 / eval/rep_loss_std 6.63 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.45 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.6 / eval/reward_rate 0.45 / 
replay/size 4.7e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3806 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.01 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.44 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1903 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.8e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.81 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 466500 Counter(466500) 466437
eval_Episode has 500 steps and return 308.8.
Saved chunk: 20230922T074345F776892-3yVihgiiQhu9Nud7V1kS5U-1tN6JZPwi2sqlqWpsMU01W-1024.npz
train_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T074416F605661-320U3ov4PZaysXb0gLRNcd-45JlkQUqzCR7LLBxYOaQyZ-1024.npz
Starting evaluation at step 467000 Counter(467000) 466937
eval_Episode has 500 steps and return 345.7.
train_Episode has 500 steps and return 294.5.
Starting evaluation at step 467500 Counter(467500) 467437
eval_Episode has 500 steps and return 344.0.
Saved chunk: 20230922T074506F023846-1tN6JZPwi2sqlqWpsMU01W-1CiTqXoJlpabLbQGlXRF2Y-1024.npz
train_Episode has 500 steps and return 301.8.
Saved chunk: 20230922T074538F658589-45JlkQUqzCR7LLBxYOaQyZ-5i3ByP5QYKM5uILw2GuAio-1024.npz
Starting evaluation at step 468000 Counter(468000) 467937
eval_Episode has 500 steps and return 323.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T074625F612194-1CiTqXoJlpabLbQGlXRF2Y-0000000000000000000000-543.npz
Saved chunk: 20230922T074659F730914-5i3ByP5QYKM5uILw2GuAio-0000000000000000000000-132.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 320.4.
Starting evaluation at step 468500 Counter(468500) 468437
eval_Episode has 500 steps and return 318.4.
Saved chunk: 20230922T074625F612194-1CiTqXoJlpabLbQGlXRF2Y-6QENYRoHsso6E5NkxnZNpm-1024.npz
train_Episode has 500 steps and return 275.3.
Saved chunk: 20230922T074659F730914-5i3ByP5QYKM5uILw2GuAio-06u7rUalijMDyaiFwbnVA2-1024.npz
Starting evaluation at step 469000 Counter(469000) 468937
eval_Episode has 500 steps and return 314.2.
train_Episode has 500 steps and return 294.9.
Starting evaluation at step 469500 Counter(469500) 469437
eval_Episode has 500 steps and return 332.2.
train_Episode has 500 steps and return 315.7.
Starting evaluation at step 470000 Counter(470000) 469937
Saved chunk: 20230922T074745F187266-6QENYRoHsso6E5NkxnZNpm-2336gGT2awTJ4295Nb9scX-1024.npz
eval_Episode has 500 steps and return 320.9.
Saved chunk: 20230922T074820F787300-06u7rUalijMDyaiFwbnVA2-4pyC1GJc3XB16y0MFZoBCJ-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 940446 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 320.86 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 315.66 / episode/reward_rate 0.45 / train/action_mag 4.08 / train/action_max 4.03 / train/action_mean 0.09 / train/action_min -3.43 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.32 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 8.65 / train/adv_mag 0.55 / train/adv_max 0.41 / train/adv_mean 
-9.3e-5 / train/adv_min -0.47 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.68 / train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / 
train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 236.94 / train/extr_critic_max 236.94 / train/extr_critic_mean 228.4 / train/extr_critic_min 187.15 / train/extr_critic_std 8.84 / 
train/extr_return_normed_mag 1.57 / train/extr_return_normed_max 1.06 / train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.78 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.16 / train/extr_return_raw_max 
237.16 / train/extr_return_raw_mean 228.4 / train/extr_return_raw_min 186.94 / train/extr_return_raw_std 8.88 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / 
train/image_loss_mean 0.86 / train/image_loss_std 0.89 / train/model_loss_mean 3.3 / train/model_loss_std 4.19 / train/model_opt_grad_norm 7.76 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.32 / train/policy_entropy_max 3.94 / train/policy_entropy_mean -2.62 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.15 / train/policy_logprob_mag 9.54 / train/policy_logprob_max 5.51 / 
train/policy_logprob_mean 2.62 / train/policy_logprob_min -9.54 / train/policy_logprob_std 1.84 / train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4.4e-5 / train/policy_randomness_std 
0.13 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 41.91 / train/post_ent_min 23.13 / train/post_ent_std 4.36 / train/prior_ent_mag 77.43 / train/prior_ent_max 77.43 / train/prior_ent_mean 45.54 / train/prior_ent_min 30.65 / 
train/prior_ent_std 5.7 / train/rep_loss_mean 3.68 / train/rep_loss_std 5.84 / train/reward_avg 0.48 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 
5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.48 / train/reward_rate 0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.72 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 1e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.84 / report/dyn_loss_std 6.22 / report/image_loss_mean 0.94 / report/image_loss_std 1.19 / 
report/model_loss_mean 3.47 / report/model_loss_std 4.64 / report/post_ent_mag 52.64 / report/post_ent_max 52.64 / report/post_ent_mean 41.91 / report/post_ent_min 22.46 / report/post_ent_std 4.37 / report/prior_ent_mag 77.27 / report/prior_ent_max 77.27 / 
report/prior_ent_mean 45.76 / report/prior_ent_min 33.84 / report/prior_ent_std 5.56 / report/rep_loss_mean 3.84 / report/rep_loss_std 6.22 / report/reward_avg 0.48 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.35 / report/reward_max_data 2 / 
report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.59 / report/reward_pred 0.48 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 
1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.37 / eval/dyn_loss_std 6.47 / eval/image_loss_mean 1.25 / eval/image_loss_std 2.24 / 
eval/model_loss_mean 4.15 / eval/model_loss_std 5.56 / eval/post_ent_mag 50.68 / eval/post_ent_max 50.68 / eval/post_ent_mean 41.47 / eval/post_ent_min 19.58 / eval/post_ent_std 4.23 / eval/prior_ent_mag 77.27 / eval/prior_ent_max 77.27 / eval/prior_ent_mean 45.56 / 
eval/prior_ent_min 31.31 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 4.37 / eval/rep_loss_std 6.47 / eval/reward_avg 0.59 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.43 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / 
eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.59 / eval/reward_rate 0.44 / replay/size 4.7e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / 
replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac
1 / timer/duration 300.11 / timer/env.step_count 3752 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.19 / 
timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.7e-4 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 
0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.54 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1876 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241.58 / timer/agent.train_frac 0.8 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 298.5.
Starting evaluation at step 470500 Counter(470500) 470437
eval_Episode has 500 steps and return 333.5.
train_Episode has 500 steps and return 309.7.
Starting evaluation at step 471000 Counter(471000) 470937
Saved chunk: 20230922T074940F329016-2336gGT2awTJ4295Nb9scX-73F8RrPjrZzy4wC0hypeAF-1024.npz
eval_Episode has 500 steps and return 319.5.
Saved chunk: 20230922T074944F981317-4pyC1GJc3XB16y0MFZoBCJ-6S5R6m59WFF6lh19jnFloY-1024.npz
train_Episode has 500 steps and return 302.4.
Starting evaluation at step 471500 Counter(471500) 471437
eval_Episode has 500 steps and return 317.8.
train_Episode has 500 steps and return 314.6.
Starting evaluation at step 472000 Counter(472000) 471937
Saved chunk: 20230922T075100F911819-73F8RrPjrZzy4wC0hypeAF-22RrjBG2ABKH4QI87AVYv0-1024.npz
eval_Episode has 500 steps and return 338.4.
Saved chunk: 20230922T075107F179707-6S5R6m59WFF6lh19jnFloY-5S6rWXF9lpyIqzCy0Uf1Xp-1024.npz
train_Episode has 500 steps and return 317.7.
Starting evaluation at step 472500 Counter(472500) 472437
eval_Episode has 500 steps and return 319.1.
train_Episode has 500 steps and return 324.2.
Starting evaluation at step 473000 Counter(473000) 472937
Saved chunk: 20230922T075220F350047-22RrjBG2ABKH4QI87AVYv0-5DROWt4h5wnpvr6prIPYZV-1024.npz
eval_Episode has 500 steps and return 332.2.
Saved chunk: 20230922T075228F182585-5S6rWXF9lpyIqzCy0Uf1Xp-3Ixb3OOmTj7vDZOXEHpooN-1024.npz
train_Episode has 500 steps and return 308.1.
Starting evaluation at step 473500 Counter(473500) 473437
eval_Episode has 500 steps and return 303.6.
train_Episode has 500 steps and return 327.0.
Starting evaluation at step 474000 Counter(474000) 473937
Saved chunk: 20230922T075339F560358-5DROWt4h5wnpvr6prIPYZV-46YWYEYYL5f8zoD81rKJRn-1024.npz
eval_Episode has 500 steps and return 332.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 948002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 327.02 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 332.46 / eval_episode/reward_rate 0.46 / train/action_mag 4.05 / train/action_max 3.99 / train/action_mean 0.09 / train/action_min -3.37 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 3.65 / train/adv_mag 0.45 / train/adv_max 0.35 / train/adv_mean 4.3e-4
/ train/adv_min -0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.63 / train/dyn_loss_std 5.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.3e4 / train/extr_critic_mag 237.11 / train/extr_critic_max 237.11 / train/extr_critic_mean 228.78 / train/extr_critic_min 188.81 / train/extr_critic_std 8.47 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.31 / train/extr_return_raw_max 237.31 / train/extr_return_raw_mean 228.79 / train/extr_return_raw_min 
190.55 / train/extr_return_raw_std 8.5 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.86 / train/image_loss_std 0.87 / train/model_loss_mean 3.26 / 
train/model_loss_std 4.15 / train/model_opt_grad_norm 7.82 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.29 / train/policy_entropy_max 
3.7 / train/policy_entropy_mean -2.66 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.51 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.66 / train/policy_logprob_min -9.51 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 3.8e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.88 / train/post_ent_max 51.88 / train/post_ent_mean 42.05 / 
train/post_ent_min 23.37 / train/post_ent_std 4.31 / train/prior_ent_mag 77.45 / train/prior_ent_max 77.45 / train/prior_ent_mean 45.65 / train/prior_ent_min 30.71 / train/prior_ent_std 5.65 / train/rep_loss_mean 3.63 / train/rep_loss_std 5.8 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.74 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 5.9 / report/image_loss_mean 0.88 / report/image_loss_std 0.85 / report/model_loss_mean 3.32 / report/model_loss_std 4.16 / report/post_ent_mag 52.29 / report/post_ent_max 52.29 / 
report/post_ent_mean 42.24 / report/post_ent_min 22.65 / report/post_ent_std 4.31 / report/prior_ent_mag 77.66 / report/prior_ent_max 77.66 / report/prior_ent_mean 45.93 / report/prior_ent_min 28.21 / report/prior_ent_std 5.6 / report/rep_loss_mean 3.7 / 
report/rep_loss_std 5.9 / report/reward_avg 0.47 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.34 / report/reward_max_data 1.99 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.47 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.3 / eval/dyn_loss_std 4.65 / eval/image_loss_mean 0.68 / eval/image_loss_std 0.42 / eval/model_loss_mean 2.98 / eval/model_loss_std 3.15 / eval/post_ent_mag 51.8 / eval/post_ent_max 51.8 / eval/post_ent_mean 
42.01 / eval/post_ent_min 31.48 / eval/post_ent_std 3.33 / eval/prior_ent_mag 77.66 / eval/prior_ent_max 77.66 / eval/prior_ent_mean 45.33 / eval/prior_ent_min 38.62 / eval/prior_ent_std 5.03 / eval/rep_loss_mean 3.3 / eval/rep_loss_std 4.65 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.69 / eval/reward_rate 0.52 / 
replay/size 4.7e5 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.71 / timer/env.step_count 3778 / timer/env.step_total 19.52 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.43 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7786 / timer/agent.policy_total 17.65 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / 
timer/dataset_train_count 1889 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1889 / timer/agent.train_total 243.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T075348F943866-3Ixb3OOmTj7vDZOXEHpooN-1NbAYu39LkR5zkqQlr9Z8j-1024.npz
train_Episode has 500 steps and return 311.9.
Starting evaluation at step 474500 Counter(474500) 474437
eval_Episode has 500 steps and return 326.3.
train_Episode has 500 steps and return 319.1.
Starting evaluation at step 475000 Counter(475000) 474937
Saved chunk: 20230922T075458F650045-46YWYEYYL5f8zoD81rKJRn-0d40jUXAm79H6r3lCge4GX-1024.npz
eval_Episode has 500 steps and return 322.3.
Saved chunk: 20230922T075510F767489-1NbAYu39LkR5zkqQlr9Z8j-4x2ah32w1u2GtDUtC2p9Kh-1024.npz
train_Episode has 500 steps and return 298.3.
Starting evaluation at step 475500 Counter(475500) 475437
eval_Episode has 500 steps and return 337.6.
train_Episode has 500 steps and return 309.6.
Starting evaluation at step 476000 Counter(476000) 475937
Saved chunk: 20230922T075619F281439-0d40jUXAm79H6r3lCge4GX-2Q1IRo58l1U0uYi3RoGz0g-1024.npz
eval_Episode has 500 steps and return 323.1.
Saved chunk: 20230922T075631F843070-4x2ah32w1u2GtDUtC2p9Kh-19SRu8su1UQXIeOH5m5PZ0-1024.npz
train_Episode has 500 steps and return 304.4.
Starting evaluation at step 476500 Counter(476500) 476437
eval_Episode has 500 steps and return 320.7.
train_Episode has 500 steps and return 304.1.
Starting evaluation at step 477000 Counter(477000) 476937
Saved chunk: 20230922T075738F627482-2Q1IRo58l1U0uYi3RoGz0g-2Vxc6Ftg4ReCN9hLffmyYS-1024.npz
eval_Episode has 500 steps and return 316.8.
Saved chunk: 20230922T075752F736374-19SRu8su1UQXIeOH5m5PZ0-2D2RZKmhC28JYEvblK7Xbo-1024.npz
train_Episode has 500 steps and return 277.8.
Starting evaluation at step 477500 Counter(477500) 477437
eval_Episode has 500 steps and return 330.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 955612 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 277.82 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 330.23 / eval_episode/reward_rate 0.47 / train/action_mag 4.07 / train/action_max 4.04 / train/action_mean 0.09 / train/action_min -3.44 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 5.35 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean 2.5e-4 
/ train/adv_min -0.36 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.26 / train/extr_critic_max 237.26 / train/extr_critic_mean 228.97 / train/extr_critic_min 194.05 / train/extr_critic_std 7.76 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.48 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.46 / train/extr_return_raw_max 237.46 / train/extr_return_raw_mean 228.98 / train/extr_return_raw_min 
193.23 / train/extr_return_raw_std 7.78 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.87 / train/image_loss_std 0.91 / train/model_loss_mean 3.29 /
train/model_loss_std 4.24 / train/model_opt_grad_norm 7.82 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.35 / train/policy_entropy_max 
3.95 / train/policy_entropy_mean -2.64 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.53 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.64 / train/policy_logprob_min -9.53 / train/policy_logprob_std 1.82 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.7e-5 / train/policy_randomness_std 0.12 / train/post_ent_mag 51.95 / train/post_ent_max 51.95 / train/post_ent_mean 41.99 / 
train/post_ent_min 23.41 / train/post_ent_std 4.29 / train/prior_ent_mag 77.44 / train/prior_ent_max 77.44 / train/prior_ent_mean 45.61 / train/prior_ent_min 30.88 / train/prior_ent_std 5.63 / train/rep_loss_mean 3.66 / train/rep_loss_std 5.89 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.47 / train/reward_rate 
0.37 / train_stats/mean_log_entropy -2.71 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 8.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 6.38 / report/image_loss_mean 0.92 / report/image_loss_std 0.86 / report/model_loss_mean 3.31 / report/model_loss_std 4.42 / report/post_ent_mag 51.94 / report/post_ent_max 51.94 / 
report/post_ent_mean 40.49 / report/post_ent_min 21.03 / report/post_ent_std 6.13 / report/prior_ent_mag 77.37 / report/prior_ent_max 77.37 / report/prior_ent_mean 44.16 / report/prior_ent_min 22.27 / report/prior_ent_std 7.54 / report/rep_loss_mean 3.7 / 
report/rep_loss_std 6.38 / report/reward_avg 0.38 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.29 / report/reward_max_data 1.91 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.38 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 7e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7e-11 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 3.61 / eval/dyn_loss_std 5.43 / eval/image_loss_mean 0.76 / eval/image_loss_std 0.72 / eval/model_loss_mean 3.25 / eval/model_loss_std 3.83 / eval/post_ent_mag 50.2 / eval/post_ent_max 50.2 / eval/post_ent_mean 41.88 / 
eval/post_ent_min 26.08 / eval/post_ent_std 3.51 / eval/prior_ent_mag 77.37 / eval/prior_ent_max 77.37 / eval/prior_ent_mean 45.43 / eval/prior_ent_min 38.53 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 3.61 / eval/rep_loss_std 5.43 / eval/reward_avg 0.67 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.4 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.66 / eval/reward_rate 0.5 / 
replay/size 4.8e5 / replay/inserts 3805 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3805 / timer/env.step_total 19.83 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.5 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7312 / timer/agent.policy_total 16.42 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1902 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.83 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 275.7.
Starting evaluation at step 478000 Counter(478000) 477937
Saved chunk: 20230922T075857F741791-2Vxc6Ftg4ReCN9hLffmyYS-2DhnJ2eQMebaBOLMdfOvks-1024.npz
eval_Episode has 500 steps and return 318.4.
Saved chunk: 20230922T075913F408119-2D2RZKmhC28JYEvblK7Xbo-2cov8lAxmG2DHjSrcDca7B-1024.npz
train_Episode has 500 steps and return 323.8.
Starting evaluation at step 478500 Counter(478500) 478437
eval_Episode has 500 steps and return 318.6.
train_Episode has 500 steps and return 319.2.
Starting evaluation at step 479000 Counter(479000) 478937
Saved chunk: 20230922T080018F033392-2DhnJ2eQMebaBOLMdfOvks-4m434wJuKMLdchXxe7ICcT-1024.npz
eval_Episode has 500 steps and return 309.5.
Saved chunk: 20230922T080035F441827-2cov8lAxmG2DHjSrcDca7B-7Kxq61Qg0UslgXMYCMZFhj-1024.npz
train_Episode has 500 steps and return 313.4.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 479500 Counter(479500) 479437
Saved chunk: 20230922T080137F661364-4m434wJuKMLdchXxe7ICcT-0000000000000000000000-301.npz
Saved chunk: 20230922T080156F561580-7Kxq61Qg0UslgXMYCMZFhj-0000000000000000000000-268.npz
eval_Episode has 500 steps and return 328.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 300.0.
Starting evaluation at step 480000 Counter(480000) 479937
Saved chunk: 20230922T080137F661364-4m434wJuKMLdchXxe7ICcT-2JgcApTAv604v3zDToYqOk-1024.npz
eval_Episode has 500 steps and return 311.7.
Saved chunk: 20230922T080156F561580-7Kxq61Qg0UslgXMYCMZFhj-3Aldh2SrWonBYV6GQIOyVj-1024.npz
train_Episode has 500 steps and return 278.4.
Starting evaluation at step 480500 Counter(480500) 480437
eval_Episode has 500 steps and return 297.8.
train_Episode has 500 steps and return 307.3.
Starting evaluation at step 481000 Counter(481000) 480937
Saved chunk: 20230922T080257F382144-2JgcApTAv604v3zDToYqOk-1VHItPYHY3xqVhzIT9ksVy-1024.npz
eval_Episode has 500 steps and return 332.1.
Saved chunk: 20230922T080317F839469-3Aldh2SrWonBYV6GQIOyVj-0vcU55j2CUKm7NMyF7duUt-1024.npz
train_Episode has 500 steps and return 307.0.
Starting evaluation at step 481500 Counter(481500) 481437
eval_Episode has 500 steps and return 336.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 963106 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 307 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 336.68 / eval_episode/reward_rate 0.48 / train/action_mag 4.09 / train/action_max 4.03 / train/action_mean 0.09 / train/action_min -3.45 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 4.61 / train/adv_mag 0.47 / train/adv_max 0.36 / train/adv_mean 3.2e-4 / train/adv_min 
-0.38 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 5.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.4 / train/extr_critic_max 237.4 / train/extr_critic_mean 228.81 / train/extr_critic_min 187.85 / train/extr_critic_std 9.12 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.68 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.62 / train/extr_return_raw_max 237.62 / train/extr_return_raw_mean 228.82 / train/extr_return_raw_min 
188.25 / train/extr_return_raw_std 9.14 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.86 / train/image_loss_std 0.89 / train/model_loss_mean 3.28 /
train/model_loss_std 4.19 / train/model_opt_grad_norm 7.9 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.48 / train/policy_entropy_max 
3.98 / train/policy_entropy_mean -2.63 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.88 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.63 / train/policy_logprob_min -9.88 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.96 / train/post_ent_max 51.96 / train/post_ent_mean 41.97 / 
train/post_ent_min 23.06 / train/post_ent_std 4.34 / train/prior_ent_mag 77.35 / train/prior_ent_max 77.35 / train/prior_ent_mean 45.6 / train/prior_ent_min 30.73 / train/prior_ent_std 5.67 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.83 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 6.41 / report/image_loss_mean 1.04 / report/image_loss_std 1.03 / report/model_loss_mean 3.52 / report/model_loss_std 4.61 / report/post_ent_mag 52.57 / report/post_ent_max 52.57 /
report/post_ent_mean 41.99 / report/post_ent_min 21.13 / report/post_ent_std 4.87 / report/prior_ent_mag 77.35 / report/prior_ent_max 77.35 / report/prior_ent_mean 45.72 / report/prior_ent_min 31.56 / report/prior_ent_std 5.9 / report/rep_loss_mean 3.78 / 
report/rep_loss_std 6.41 / report/reward_avg 0.43 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.43 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 8.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.78 / eval/dyn_loss_std 7.06 / eval/image_loss_mean 1.18 / eval/image_loss_std 1.73 / eval/model_loss_mean 4.33 / eval/model_loss_std 5.65 / eval/post_ent_mag 51.39 / eval/post_ent_max 51.39 / eval/post_ent_mean 
41 / eval/post_ent_min 22.1 / eval/post_ent_std 4.46 / eval/prior_ent_mag 77.35 / eval/prior_ent_max 77.35 / eval/prior_ent_mean 45.29 / eval/prior_ent_min 33.8 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 4.78 / eval/rep_loss_std 7.06 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.58 / eval/reward_rate 0.45 / 
replay/size 4.8e5 / replay/inserts 3747 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3747 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.07 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.9e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7755 / timer/agent.policy_total 17.63 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1874 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1874 / timer/agent.train_total 241.48 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 24.98

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 482000 Counter(482000) 481937
Saved chunk: 20230922T080416F552661-1VHItPYHY3xqVhzIT9ksVy-0sdkrkSXM9v2i0dgwk5I3l-1024.npz
eval_Episode has 500 steps and return 338.3.
Saved chunk: 20230922T080438F507621-0vcU55j2CUKm7NMyF7duUt-06hPKm6T2Wggjh8rOyeqhW-1024.npz
train_Episode has 500 steps and return 302.0.
Starting evaluation at step 482500 Counter(482500) 482437
eval_Episode has 500 steps and return 339.6.
train_Episode has 500 steps and return 321.3.
Starting evaluation at step 483000 Counter(483000) 482937
Saved chunk: 20230922T080537F027737-0sdkrkSXM9v2i0dgwk5I3l-5Z0055kPxrWTQNOcUr74IE-1024.npz
eval_Episode has 500 steps and return 329.6.
Saved chunk: 20230922T080600F707920-06hPKm6T2Wggjh8rOyeqhW-5o8qZR97VUc6b1uH8yzWYe-1024.npz
train_Episode has 500 steps and return 282.0.
Starting evaluation at step 483500 Counter(483500) 483437
eval_Episode has 500 steps and return 347.7.
train_Episode has 500 steps and return 311.5.
Starting evaluation at step 484000 Counter(484000) 483937
Saved chunk: 20230922T080656F539111-5Z0055kPxrWTQNOcUr74IE-5WO30DgZlRyMNnUY7OIUtZ-1024.npz
eval_Episode has 500 steps and return 344.4.
Saved chunk: 20230922T080721F707373-5o8qZR97VUc6b1uH8yzWYe-6Ur8SwidCAG5WAOJORTRzI-1024.npz
train_Episode has 500 steps and return 284.0.
Starting evaluation at step 484500 Counter(484500) 484437
eval_Episode has 500 steps and return 322.8.
train_Episode has 500 steps and return 274.7.
Starting evaluation at step 485000 Counter(485000) 484937
Saved chunk: 20230922T080815F847735-5WO30DgZlRyMNnUY7OIUtZ-5dd5OYpSNtI9Tan0ybKMKI-1024.npz
eval_Episode has 500 steps and return 335.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 970710 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 274.7 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 335.45 / eval_episode/reward_rate 0.49 / train/action_mag 4.11 / train/action_max 4.02 / train/action_mean 0.09 / train/action_min -3.53 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 3.78 / train/adv_mag 0.62 / train/adv_max 0.54 / train/adv_mean 3.8e-4 / train/adv_min 
-0.35 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 5.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.61 / train/extr_critic_max 237.61 / train/extr_critic_mean 228.7 / train/extr_critic_min 179.3 / train/extr_critic_std 9.82 / train/extr_return_normed_mag 1.51 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.66 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.79 / train/extr_return_raw_max 237.79 / train/extr_return_raw_mean 228.71 / train/extr_return_raw_min 
185.7 / train/extr_return_raw_std 9.83 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.86 / train/image_loss_std 0.88 / train/model_loss_mean 3.27 / 
train/model_loss_std 4.16 / train/model_opt_grad_norm 8.03 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.52 / train/policy_entropy_max 
4.16 / train/policy_entropy_mean -2.56 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.25 / train/policy_logprob_mag 9.98 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.56 / train/policy_logprob_min -9.98 / train/policy_logprob_std 1.9 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.7e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.1 / train/post_ent_max 52.1 / train/post_ent_mean 41.93 / 
train/post_ent_min 23.09 / train/post_ent_std 4.38 / train/prior_ent_mag 77.31 / train/prior_ent_max 77.31 / train/prior_ent_mean 45.54 / train/prior_ent_min 30.65 / train/prior_ent_std 5.71 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.81 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.47 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.2 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 5.07 / report/image_loss_mean 0.74 / report/image_loss_std 0.7 / report/model_loss_mean 3.11 / report/model_loss_std 3.7 / report/post_ent_mag 51.03 / report/post_ent_max 51.03 / 
report/post_ent_mean 42.63 / report/post_ent_min 26.33 / report/post_ent_std 3.63 / report/prior_ent_mag 77.4 / report/prior_ent_max 77.4 / report/prior_ent_mean 46.22 / report/prior_ent_min 29.84 / report/prior_ent_std 5.11 / report/rep_loss_mean 3.51 / 
report/rep_loss_std 5.07 / report/reward_avg 0.56 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.37 / report/reward_max_data 1.96 / report/reward_max_pred 1.93 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.56 / report/reward_rate 0.45 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.77 / eval/dyn_loss_std 5.5 / eval/image_loss_mean 0.83 / eval/image_loss_std 1.03 / eval/model_loss_mean 3.39 / eval/model_loss_std 4.06 / eval/post_ent_mag 50.26 / eval/post_ent_max 50.26 / eval/post_ent_mean 
41.53 / eval/post_ent_min 24.27 / eval/post_ent_std 3.73 / eval/prior_ent_mag 77.4 / eval/prior_ent_max 77.4 / eval/prior_ent_mean 45.39 / eval/prior_ent_min 31.32 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 3.77 / eval/rep_loss_std 5.5 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.42 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.65 / eval/reward_rate 0.47 / replay/size 
4.9e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3802 / timer/env.step_total 19.66 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.26 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.8e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.7 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.2 / 
timer/dataset_train_count 1901 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.76 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T080842F539032-6Ur8SwidCAG5WAOJORTRzI-1wNqzH6X1qMub9J3hg6yxQ-1024.npz
train_Episode has 500 steps and return 298.5.
Starting evaluation at step 485500 Counter(485500) 485437
eval_Episode has 500 steps and return 317.1.
train_Episode has 500 steps and return 314.3.
Starting evaluation at step 486000 Counter(486000) 485937
Saved chunk: 20230922T080934F971196-5dd5OYpSNtI9Tan0ybKMKI-14I34wtHlG9mmY9WagRAFp-1024.npz
eval_Episode has 500 steps and return 326.3.
Saved chunk: 20230922T081004F301964-1wNqzH6X1qMub9J3hg6yxQ-0vW7C8au76R2XlYcuqeYn5-1024.npz
train_Episode has 500 steps and return 301.0.
Starting evaluation at step 486500 Counter(486500) 486437
eval_Episode has 500 steps and return 342.5.
train_Episode has 500 steps and return 303.0.
Starting evaluation at step 487000 Counter(487000) 486937
Saved chunk: 20230922T081055F582041-14I34wtHlG9mmY9WagRAFp-0g5KRclq6LsTlHctS3uIDs-1024.npz
eval_Episode has 500 steps and return 314.9.
Saved chunk: 20230922T081125F592119-0vW7C8au76R2XlYcuqeYn5-6Q16JnYCjxPzukH7XllV9I-1024.npz
train_Episode has 500 steps and return 313.9.
Starting evaluation at step 487500 Counter(487500) 487437
eval_Episode has 500 steps and return 314.0.
train_Episode has 500 steps and return 296.8.
Starting evaluation at step 488000 Counter(488000) 487937
Saved chunk: 20230922T081215F089083-0g5KRclq6LsTlHctS3uIDs-6bleK5eXhUfSHH2dkHU1Z7-1024.npz
eval_Episode has 500 steps and return 320.5.
Saved chunk: 20230922T081246F571580-6Q16JnYCjxPzukH7XllV9I-6B8bFAyhrxSKhNq7gcL0uD-1024.npz
train_Episode has 500 steps and return 309.1.
Starting evaluation at step 488500 Counter(488500) 488437
eval_Episode has 500 steps and return 321.1.
train_Episode has 500 steps and return 310.5.
Starting evaluation at step 489000 Counter(489000) 488937
Saved chunk: 20230922T081334F370074-6bleK5eXhUfSHH2dkHU1Z7-1zDhc8TGneeksRkTcvDAAm-1024.npz
eval_Episode has 500 steps and return 301.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 978214 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 310.46 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 301.28 / eval_episode/reward_rate 0.43 / train/action_mag 4.05 / train/action_max 4.01 / train/action_mean 0.09 / train/action_min -3.42 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 4.59 / train/adv_mag 0.57 / train/adv_max 0.47 / train/adv_mean 3.2e-4 
/ train/adv_min -0.38 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.67 / train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.73 / train/extr_critic_max 237.73 / train/extr_critic_mean 229.43 / train/extr_critic_min 186.2 / train/extr_critic_std 8 / train/extr_return_normed_mag 1.27 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.95 / train/extr_return_raw_max 237.95 / train/extr_return_raw_mean 229.44 / train/extr_return_raw_min 
190.26 / train/extr_return_raw_std 8.01 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.86 / train/image_loss_std 0.9 / train/model_loss_mean 3.29 / 
train/model_loss_std 4.2 / train/model_opt_grad_norm 7.78 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.67 / train/policy_entropy_max 
4.34 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.87 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -9.87 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.93 / train/post_ent_max 51.93 / train/post_ent_mean 41.96 / 
train/post_ent_min 23.09 / train/post_ent_std 4.25 / train/prior_ent_mag 77.32 / train/prior_ent_max 77.32 / train/prior_ent_mean 45.59 / train/prior_ent_min 30.9 / train/prior_ent_std 5.57 / train/rep_loss_mean 3.67 / train/rep_loss_std 5.84 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.71 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 9.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.73 / report/dyn_loss_std 5.91 / report/image_loss_mean 0.89 / report/image_loss_std 1.01 / report/model_loss_mean 3.34 / report/model_loss_std 4.32 / report/post_ent_mag 52.11 / report/post_ent_max 52.11 /
report/post_ent_mean 42.77 / report/post_ent_min 25.48 / report/post_ent_std 3.96 / report/prior_ent_mag 77.51 / report/prior_ent_max 77.51 / report/prior_ent_mean 46.36 / report/prior_ent_min 29.55 / report/prior_ent_std 5.32 / report/rep_loss_mean 3.73 / 
report/rep_loss_std 5.91 / report/reward_avg 0.45 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 1.96 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 4.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.45 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.51 / eval/dyn_loss_std 5.11 / eval/image_loss_mean 0.75 / eval/image_loss_std 0.88 / eval/model_loss_mean 3.18 / eval/model_loss_std 3.7 / eval/post_ent_mag 50.38 / eval/post_ent_max 50.38 / eval/post_ent_mean 
41.71 / eval/post_ent_min 26.96 / eval/post_ent_std 3.33 / eval/prior_ent_mag 77.51 / eval/prior_ent_max 77.51 / eval/prior_ent_mean 45.24 / eval/prior_ent_min 34.76 / eval/prior_ent_std 5.13 / eval/rep_loss_mean 3.51 / eval/rep_loss_std 5.11 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.69 / eval/reward_rate 0.51 / 
replay/size 4.9e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3752 / timer/env.step_total 19.41 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.64 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.7e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241.82 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 299.5.
Saved chunk: 20230922T081407F336733-6B8bFAyhrxSKhNq7gcL0uD-28gQ27egQ2j6IKlSyDwWiJ-1024.npz
Starting evaluation at step 489500 Counter(489500) 489437
eval_Episode has 500 steps and return 317.3.
train_Episode has 500 steps and return 310.6.
Starting evaluation at step 490000 Counter(490000) 489937
eval_Episode has 500 steps and return 325.9.
Saved chunk: 20230922T081453F512300-1zDhc8TGneeksRkTcvDAAm-5lL6qu4Q1mTMktZW1FD8Jg-1024.npz
train_Episode has 500 steps and return 286.2.
Starting evaluation at step 490500 Counter(490500) 490437
Saved chunk: 20230922T081529F335275-28gQ27egQ2j6IKlSyDwWiJ-1l6aHM5koYbNjs0j2De8TA-1024.npz
eval_Episode has 500 steps and return 302.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T081650F500279-1l6aHM5koYbNjs0j2De8TA-0000000000000000000000-304.npz
Saved chunk: 20230922T081614F228356-5lL6qu4Q1mTMktZW1FD8Jg-0000000000000000000000-560.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
train_Episode has 500 steps and return 301.9.
Starting evaluation at step 491000 Counter(491000) 490937
eval_Episode has 500 steps and return 306.7.
Saved chunk: 20230922T081614F228356-5lL6qu4Q1mTMktZW1FD8Jg-4Vnmig2NYiPJlcq5vFN09p-1024.npz
train_Episode has 500 steps and return 283.8.
Starting evaluation at step 491500 Counter(491500) 491437
eval_Episode has 500 steps and return 335.8.
Saved chunk: 20230922T081650F500279-1l6aHM5koYbNjs0j2De8TA-1HPdW3JQzgxmRP9RXNXCyc-1024.npz
train_Episode has 500 steps and return 291.4.
Starting evaluation at step 492000 Counter(492000) 491937
eval_Episode has 500 steps and return 335.1.
Saved chunk: 20230922T081733F892925-4Vnmig2NYiPJlcq5vFN09p-7oFMIPfh4N6JzakUtnh5Wm-1024.npz
train_Episode has 500 steps and return 291.3.
Starting evaluation at step 492500 Counter(492500) 492437
eval_Episode has 500 steps and return 328.6.
Saved chunk: 20230922T081815F167513-1HPdW3JQzgxmRP9RXNXCyc-0qCt88pJV5oKsojNQ8Vxvp-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 985814 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 291.26 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 328.64 / eval_episode/reward_rate 0.47 / train/action_mag 4.1 / train/action_max 4.05 / train/action_mean 0.09 / train/action_min -3.45 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 1 / train/adv_mag 0.45 / train/adv_max 0.38 / train/adv_mean 6.7e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.65 / train/dyn_loss_std 5.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.85 / train/extr_critic_max 237.85 / train/extr_critic_mean 229.11 / train/extr_critic_min 180.23 / train/extr_critic_std 9.79 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.04 / train/extr_return_raw_max 238.04 / train/extr_return_raw_mean 229.14 / train/extr_return_raw_min 
184.5 / train/extr_return_raw_std 9.78 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.85 / train/image_loss_std 0.88 / train/model_loss_mean 3.27 / 
train/model_loss_std 4.16 / train/model_opt_grad_norm 7.95 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.53 / train/policy_entropy_max 
4.14 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 10.01 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -10.01 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.95 / train/post_ent_max 51.95 / train/post_ent_mean 41.89 / 
train/post_ent_min 23.05 / train/post_ent_std 4.33 / train/prior_ent_mag 77.28 / train/prior_ent_max 77.28 / train/prior_ent_mean 45.49 / train/prior_ent_min 30.61 / train/prior_ent_std 5.68 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.8 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.68 / report/dyn_loss_std 5.98 / report/image_loss_mean 0.77 / report/image_loss_std 0.82 / report/model_loss_mean 3.19 / report/model_loss_std 4.24 / report/post_ent_mag 52.91 / report/post_ent_max 52.91 /
report/post_ent_mean 42.42 / report/post_ent_min 21.92 / report/post_ent_std 3.81 / report/prior_ent_mag 77.17 / report/prior_ent_max 77.17 / report/prior_ent_mean 46 / report/prior_ent_min 33.75 / report/prior_ent_std 5.22 / report/rep_loss_mean 3.68 / 
report/rep_loss_std 5.98 / report/reward_avg 0.48 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.47 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.2 / eval/dyn_loss_std 6.37 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.14 / eval/model_loss_mean 3.77 / eval/model_loss_std 4.67 / eval/post_ent_mag 51.14 / eval/post_ent_max 51.14 / eval/post_ent_mean 41.45 / 
eval/post_ent_min 21.53 / eval/post_ent_std 3.95 / eval/prior_ent_mag 77.17 / eval/prior_ent_max 77.17 / eval/prior_ent_mean 45.52 / eval/prior_ent_min 32.63 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 4.2 / eval/rep_loss_std 6.37 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.33 / eval/reward_max_data 2 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.66 / eval/reward_rate 0.47 / 
replay/size 4.9e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3800 / timer/env.step_total 19.99 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.89 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 8.2e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7307 / timer/agent.policy_total 16.6 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.52 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.32

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 312.4.
Starting evaluation at step 493000 Counter(493000) 492937
eval_Episode has 500 steps and return 325.6.
train_Episode has 500 steps and return 294.9.
Starting evaluation at step 493500 Counter(493500) 493437
Saved chunk: 20230922T081853F065076-7oFMIPfh4N6JzakUtnh5Wm-2BfxzW1PDPpQptnoAWGVMR-1024.npz
eval_Episode has 500 steps and return 329.1.
Saved chunk: 20230922T081935F831227-0qCt88pJV5oKsojNQ8Vxvp-3iytPUK2oh220ok1yqidoq-1024.npz
train_Episode has 500 steps and return 300.2.
Starting evaluation at step 494000 Counter(494000) 493937
eval_Episode has 500 steps and return 327.9.
train_Episode has 500 steps and return 290.5.
Starting evaluation at step 494500 Counter(494500) 494437
Saved chunk: 20230922T082049F514152-2BfxzW1PDPpQptnoAWGVMR-3K28lVdfpfIBg8cCi3b4zo-1024.npz
eval_Episode has 500 steps and return 328.5.
Saved chunk: 20230922T082057F995240-3iytPUK2oh220ok1yqidoq-3Zo6cO0atigEW2AB9eI7gr-1024.npz
train_Episode has 500 steps and return 274.6.
Starting evaluation at step 495000 Counter(495000) 494937
eval_Episode has 500 steps and return 300.7.
train_Episode has 500 steps and return 299.1.
Starting evaluation at step 495500 Counter(495500) 495437
Saved chunk: 20230922T082209F080899-3K28lVdfpfIBg8cCi3b4zo-4NdCCre5ztjHCfCjIDkSeS-1024.npz
eval_Episode has 500 steps and return 327.0.
Saved chunk: 20230922T082219F059906-3Zo6cO0atigEW2AB9eI7gr-2DDwqdBv2qiCZRUX74yYpf-1024.npz
train_Episode has 500 steps and return 276.1.
Starting evaluation at step 496000 Counter(496000) 495937
eval_Episode has 500 steps and return 331.3.
train_Episode has 500 steps and return 311.6.
Starting evaluation at step 496500 Counter(496500) 496437
Saved chunk: 20230922T082328F396522-4NdCCre5ztjHCfCjIDkSeS-0XALl8o3RW0NlMkGQlyB80-1024.npz
eval_Episode has 500 steps and return 315.4.
Saved chunk: 20230922T082339F924516-2DDwqdBv2qiCZRUX74yYpf-1AZ3fkUFisoazsnnUBKaEM-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 993314 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 311.63 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 315.43 / eval_episode/reward_rate 0.47 / train/action_mag 4.07 / train/action_max 4.03 / train/action_mean 0.09 / train/action_min -3.44 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 6.87 / train/adv_mag 0.56 / train/adv_max 0.48 / train/adv_mean 8.2e-5
/ train/adv_min -0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 5.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.04 / train/extr_critic_max 238.04 / train/extr_critic_mean 229.43 / train/extr_critic_min 183.42 / train/extr_critic_std 8.72 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.24 / train/extr_return_raw_max 238.24 / train/extr_return_raw_mean 229.43 / train/extr_return_raw_min 
189.81 / train/extr_return_raw_std 8.73 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.87 / train/image_loss_std 0.91 / train/model_loss_mean 3.32 /
train/model_loss_std 4.24 / train/model_opt_grad_norm 7.94 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.46 / train/policy_entropy_max 
4.15 / train/policy_entropy_mean -2.6 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.7 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.6 / train/policy_logprob_min -9.7 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.95 / train/post_ent_max 51.95 / train/post_ent_mean 41.87 / 
train/post_ent_min 22.95 / train/post_ent_std 4.33 / train/prior_ent_mag 77.18 / train/prior_ent_max 77.18 / train/prior_ent_mean 45.53 / train/prior_ent_min 30.59 / train/prior_ent_std 5.64 / train/rep_loss_mean 3.7 / train/rep_loss_std 5.9 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.1 / report/dyn_loss_std 4.79 / report/image_loss_mean 0.68 / report/image_loss_std 0.51 / report/model_loss_mean 2.76 / report/model_loss_std 3.3 / report/post_ent_mag 51.76 / report/post_ent_max 51.76 / 
report/post_ent_mean 42.06 / report/post_ent_min 29.03 / report/post_ent_std 3.38 / report/prior_ent_mag 77.29 / report/prior_ent_max 77.29 / report/prior_ent_mean 45.02 / report/prior_ent_min 32.61 / report/prior_ent_std 5.19 / report/rep_loss_mean 3.1 / 
report/rep_loss_std 4.79 / report/reward_avg 0.48 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 1.96 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.48 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.7 / eval/dyn_loss_std 5.78 / eval/image_loss_mean 0.87 / eval/image_loss_std 1.22 / eval/model_loss_mean 3.38 / eval/model_loss_std 4.31 / eval/post_ent_mag 50.64 / eval/post_ent_max 50.64 / eval/post_ent_mean 
41.6 / eval/post_ent_min 23.79 / eval/post_ent_std 3.52 / eval/prior_ent_mag 77.29 / eval/prior_ent_max 77.29 / eval/prior_ent_mean 45.15 / eval/prior_ent_min 33.59 / eval/prior_ent_std 5.22 / eval/rep_loss_mean 3.7 / eval/rep_loss_std 5.78 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.63 / eval/reward_rate 0.49 / 
replay/size 5e5 / replay/inserts 3750 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3750 / timer/env.step_total 19.59 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.15 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.8e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7758 / timer/agent.policy_total 17.43 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1875 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1875 / timer/agent.train_total 241.54 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 303.7.
Starting evaluation at step 497000 Counter(497000) 496937
eval_Episode has 500 steps and return 320.9.
train_Episode has 500 steps and return 295.3.
Starting evaluation at step 497500 Counter(497500) 497437
Saved chunk: 20230922T082447F530949-0XALl8o3RW0NlMkGQlyB80-63tniBij68X21LMAaLxaUK-1024.npz
eval_Episode has 500 steps and return 317.8.
Saved chunk: 20230922T082500F753586-1AZ3fkUFisoazsnnUBKaEM-1IAD9xD1QNqnpInRfh8vE3-1024.npz
train_Episode has 500 steps and return 297.5.
Starting evaluation at step 498000 Counter(498000) 497937
eval_Episode has 500 steps and return 341.5.
train_Episode has 500 steps and return 287.5.
Starting evaluation at step 498500 Counter(498500) 498437
Saved chunk: 20230922T082610F190600-63tniBij68X21LMAaLxaUK-0wzELbo6geAFZX5vLczPHk-1024.npz
eval_Episode has 500 steps and return 321.5.
Saved chunk: 20230922T082624F902335-1IAD9xD1QNqnpInRfh8vE3-1Q430gJZp56bFgSzdHlIu4-1024.npz
train_Episode has 500 steps and return 291.9.
Starting evaluation at step 499000 Counter(499000) 498937
eval_Episode has 500 steps and return 344.1.
train_Episode has 500 steps and return 283.8.
Starting evaluation at step 499500 Counter(499500) 499437
Saved chunk: 20230922T082729F448998-0wzELbo6geAFZX5vLczPHk-0gnjImhIUyMLJ4jIX54rxX-1024.npz
eval_Episode has 500 steps and return 323.2.
Saved chunk: 20230922T082745F701861-1Q430gJZp56bFgSzdHlIu4-6YRghvsJXwPyXy0jJus2mi-1024.npz
train_Episode has 500 steps and return 313.6.
Starting evaluation at step 500000 Counter(500000) 499937
eval_Episode has 500 steps and return 311.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1000874 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 313.6 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 311.58 / eval_episode/reward_rate 0.47 / train/action_mag 4.04 / train/action_max 3.97 / train/action_mean 0.09 / train/action_min -3.45 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 3.58 / train/adv_mag 0.49 / train/adv_max 0.4 / train/adv_mean 4.1e-4 / train/adv_min 
-0.39 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 5.79 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.79 / train/extr_critic_max 237.79 / train/extr_critic_mean 229.2 / train/extr_critic_min 186.01 / train/extr_critic_std 9.32 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 237.99 / train/extr_return_raw_max 237.99 / train/extr_return_raw_mean 229.21 / train/extr_return_raw_min 
187.11 / train/extr_return_raw_std 9.33 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.85 / train/image_loss_std 0.89 / train/model_loss_mean 3.27 / 
train/model_loss_std 4.16 / train/model_opt_grad_norm 7.95 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.39 / train/policy_entropy_max 4
/ train/policy_entropy_mean -2.59 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.87 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.59 / train/policy_logprob_min -9.87 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4.1e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 41.9 / 
train/post_ent_min 23 / train/post_ent_std 4.26 / train/prior_ent_mag 77.15 / train/prior_ent_max 77.15 / train/prior_ent_mean 45.51 / train/prior_ent_min 31.24 / train/prior_ent_std 5.6 / train/rep_loss_mean 3.66 / train/rep_loss_std 5.79 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.68 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 5.91 / report/image_loss_mean 0.78 / report/image_loss_std 0.74 / report/model_loss_mean 3.18 / report/model_loss_std 4.15 / report/post_ent_mag 51.29 / report/post_ent_max 51.29 /
report/post_ent_mean 42.11 / report/post_ent_min 20.78 / report/post_ent_std 4.11 / report/prior_ent_mag 76.92 / report/prior_ent_max 76.92 / report/prior_ent_mean 45.73 / report/prior_ent_min 31.23 / report/prior_ent_std 5.49 / report/rep_loss_mean 3.64 / 
report/rep_loss_std 5.91 / report/reward_avg 0.49 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 6.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.49 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-11 / eval/cont_loss_std 9.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.47 / eval/dyn_loss_std 4.92 / eval/image_loss_mean 0.69 / eval/image_loss_std 0.53 / eval/model_loss_mean 3.06 / eval/model_loss_std 3.42 / eval/post_ent_mag 50.09 / eval/post_ent_max 50.09 / eval/post_ent_mean 
41.78 / eval/post_ent_min 30.92 / eval/post_ent_std 3.29 / eval/prior_ent_mag 76.92 / eval/prior_ent_max 76.92 / eval/prior_ent_mean 45.28 / eval/prior_ent_min 39.47 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 3.47 / eval/rep_loss_std 4.92 / eval/reward_avg 0.68 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.67 / eval/reward_rate 0.49 / 
replay/size 5e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3780 / timer/env.step_total 19.51 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7287 / timer/agent.policy_total 16.37 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1890 / timer/agent.train_total 245.27 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 2.01 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 308.1.
Starting evaluation at step 500500 Counter(500500) 500437
Saved chunk: 20230922T082848F626170-0gnjImhIUyMLJ4jIX54rxX-3mANKFBip2jCborC3uO5TB-1024.npz
eval_Episode has 500 steps and return 334.0.
Saved chunk: 20230922T082906F425696-6YRghvsJXwPyXy0jJus2mi-7l6a9VyK6fNdXLglKXMBVg-1024.npz
train_Episode has 500 steps and return 303.2.
Starting evaluation at step 501000 Counter(501000) 500937
eval_Episode has 500 steps and return 338.7.
Starting evaluation at step 501500 Counter(501500) 501437
Saved chunk: 20230922T083008F850512-3mANKFBip2jCborC3uO5TB-7v7cSH47uhShuYucg8EYHE-1024.npz
eval_Episode has 500 steps and return 324.5.
train_Episode has 500 steps and return 322.7.
Saved chunk: 20230922T083028F323868-7l6a9VyK6fNdXLglKXMBVg-44pjeENstKTGd4ppzYvmsZ-1024.npz
Starting evaluation at step 502000 Counter(502000) 501937
eval_Episode has 500 steps and return 306.6.
train_Episode has 500 steps and return 314.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T083149F459448-44pjeENstKTGd4ppzYvmsZ-0000000000000000000000-340.npz
Saved chunk: 20230922T083128F406271-7v7cSH47uhShuYucg8EYHE-0000000000000000000000-819.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 502500 Counter(502500) 502437
Saved chunk: 20230922T083128F406271-7v7cSH47uhShuYucg8EYHE-0orrq2X9BkoVJPTtxeyFKJ-1024.npz
eval_Episode has 500 steps and return 309.6.
train_Episode has 500 steps and return 320.6.
Saved chunk: 20230922T083149F459448-44pjeENstKTGd4ppzYvmsZ-1dzpjyk4XTKBfjuCAYYiBv-1024.npz
Starting evaluation at step 503000 Counter(503000) 502937
eval_Episode has 500 steps and return 329.4.
train_Episode has 500 steps and return 302.2.
Starting evaluation at step 503500 Counter(503500) 503437
Saved chunk: 20230922T083248F045650-0orrq2X9BkoVJPTtxeyFKJ-2L5iLTj8WrsdIH3Ok1M1G1-1024.npz
eval_Episode has 500 steps and return 332.8.
train_Episode has 500 steps and return 306.2.
Saved chunk: 20230922T083310F618959-1dzpjyk4XTKBfjuCAYYiBv-47uhOBUxxDs3o6jAYtew6m-1024.npz
Starting evaluation at step 504000 Counter(504000) 503937
eval_Episode has 500 steps and return 311.5.
train_Episode has 500 steps and return 305.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1008374 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 305.41 / episode/reward_rate 0.46 / eval_episode/length 500 / eval_episode/score 311.49 / eval_episode/reward_rate 0.46 / train/action_mag 4.06 / train/action_max 4 / train/action_mean 0.1 / train/action_min -3.47 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 2.91 / train/adv_mag 0.44 / train/adv_max 0.37 / train/adv_mean 4.8e-4 / train/adv_min 
-0.33 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.95 / train/extr_critic_max 237.95 / train/extr_critic_mean 229.54 / train/extr_critic_min 187.22 / train/extr_critic_std 8.49 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.15 / train/extr_return_raw_max 238.15 / train/extr_return_raw_mean 229.56 / train/extr_return_raw_min 
189.34 / train/extr_return_raw_std 8.51 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.86 / train/model_loss_mean 3.24 / 
train/model_loss_std 4.12 / train/model_opt_grad_norm 8.05 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.31 / train/policy_entropy_max 
3.87 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.53 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.53 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4.1e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.04 / train/post_ent_max 52.04 / train/post_ent_mean 41.86 / 
train/post_ent_min 23.27 / train/post_ent_std 4.24 / train/prior_ent_mag 77.16 / train/prior_ent_max 77.16 / train/prior_ent_mean 45.46 / train/prior_ent_min 31.32 / train/prior_ent_std 5.61 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.76 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.66 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 5.1 / report/image_loss_mean 0.76 / report/image_loss_std 0.67 / report/model_loss_mean 3.15 / report/model_loss_std 3.65 / report/post_ent_mag 52.11 / report/post_ent_max 52.11 / 
report/post_ent_mean 42.66 / report/post_ent_min 23.54 / report/post_ent_std 3.8 / report/prior_ent_mag 77.13 / report/prior_ent_max 77.13 / report/prior_ent_mean 46.14 / report/prior_ent_min 35.7 / report/prior_ent_std 5.16 / report/rep_loss_mean 3.54 / 
report/rep_loss_std 5.1 / report/reward_avg 0.57 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.34 / report/reward_max_data 1.95 / report/reward_max_pred 1.95 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.57 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.49 / eval/dyn_loss_std 7.11 / eval/image_loss_mean 1.1 / eval/image_loss_std 1.73 / eval/model_loss_mean 4.09 / eval/model_loss_std 5.63 / eval/post_ent_mag 51.43 / eval/post_ent_max 51.43 / eval/post_ent_mean 
41.32 / eval/post_ent_min 21.96 / eval/post_ent_std 4.21 / eval/prior_ent_mag 77.13 / eval/prior_ent_max 77.13 / eval/prior_ent_mean 45.35 / eval/prior_ent_min 33.53 / eval/prior_ent_std 5.46 / eval/rep_loss_mean 4.49 / eval/rep_loss_std 7.11 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.63 / eval/reward_rate 0.48 / 
replay/size 5e5 / replay/inserts 3750 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3750 / timer/env.step_total 19.65 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.93 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.2e-4 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7758 / timer/agent.policy_total 17.52 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1875 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1875 / timer/agent.train_total 241.48 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / 
timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 24.99

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 504500 Counter(504500) 504437
Saved chunk: 20230922T083407F282125-2L5iLTj8WrsdIH3Ok1M1G1-4CfsuLKdf9RITE20wfuCRs-1024.npz
eval_Episode has 500 steps and return 313.1.
train_Episode has 500 steps and return 276.9.
Saved chunk: 20230922T083431F376171-47uhOBUxxDs3o6jAYtew6m-5f1XQIKB4fKFwm4W1zWv80-1024.npz
Starting evaluation at step 505000 Counter(505000) 504937
eval_Episode has 500 steps and return 336.5.
train_Episode has 500 steps and return 304.3.
Starting evaluation at step 505500 Counter(505500) 505437
Saved chunk: 20230922T083527F679958-4CfsuLKdf9RITE20wfuCRs-18bqRyP9Z3NBR1OGLo89Nk-1024.npz
eval_Episode has 500 steps and return 327.5.
train_Episode has 500 steps and return 323.3.
Saved chunk: 20230922T083553F488997-5f1XQIKB4fKFwm4W1zWv80-2gvgrEZDhQ4Aj5njofDFsK-1024.npz
Starting evaluation at step 506000 Counter(506000) 505937
eval_Episode has 500 steps and return 327.4.
train_Episode has 500 steps and return 304.7.
Starting evaluation at step 506500 Counter(506500) 506437
Saved chunk: 20230922T083647F214595-18bqRyP9Z3NBR1OGLo89Nk-55maDeB64npVttR8vPkCfw-1024.npz
eval_Episode has 500 steps and return 311.9.
train_Episode has 500 steps and return 299.1.
Saved chunk: 20230922T083714F566490-2gvgrEZDhQ4Aj5njofDFsK-31NnDeuwNzUp4zbGtABE0a-1024.npz
Starting evaluation at step 507000 Counter(507000) 506937
eval_Episode has 500 steps and return 297.6.
train_Episode has 500 steps and return 302.9.
Starting evaluation at step 507500 Counter(507500) 507437
Saved chunk: 20230922T083806F542969-55maDeB64npVttR8vPkCfw-0rSuy8YqKgpKWFqOTiu7Mx-1024.npz
eval_Episode has 500 steps and return 321.6.
train_Episode has 500 steps and return 308.7.
Saved chunk: 20230922T083835F383743-31NnDeuwNzUp4zbGtABE0a-4XaH4DYMb0OtE5DEmhY1Z8-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1015978 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 321.62 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 308.7 / episode/reward_rate 0.47 / train/action_mag 4.12 / train/action_max 4.07 / train/action_mean 0.09 / train/action_min -3.4 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 6.87 / train/adv_mag 0.49 / train/adv_max 0.38 / train/adv_mean 7.3e-5 / train/adv_min 
-0.37 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 5.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.04 / train/extr_critic_max 238.04 / train/extr_critic_mean 228.63 / train/extr_critic_min 178.03 / train/extr_critic_std 11.3 / train/extr_return_normed_mag 1.6 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.7 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.25 / train/extr_return_raw_max 238.25 / train/extr_return_raw_mean 228.63 / train/extr_return_raw_min 
179.79 / train/extr_return_raw_std 11.33 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.68 / train/image_loss_mean 0.86 / train/image_loss_std 0.89 / train/model_loss_mean 3.28 
/ train/model_loss_std 4.18 / train/model_opt_grad_norm 7.92 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.48 / train/policy_entropy_max
3.96 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.25 / train/policy_logprob_mag 9.71 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.71 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.8e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.02 / train/post_ent_max 52.02 / train/post_ent_mean 41.83 / 
train/post_ent_min 23 / train/post_ent_std 4.37 / train/prior_ent_mag 77.1 / train/prior_ent_max 77.1 / train/prior_ent_mean 45.44 / train/prior_ent_min 30.75 / train/prior_ent_std 5.71 / train/rep_loss_mean 3.66 / train/rep_loss_std 5.82 / train/reward_avg 0.47 / 
train/reward_loss_mean 0.22 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.47 / train/reward_rate 
0.37 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.41 / report/dyn_loss_std 5.37 / report/image_loss_mean 0.88 / report/image_loss_std 0.84 / report/model_loss_mean 3.13 / report/model_loss_std 3.82 / report/post_ent_mag 52.92 / report/post_ent_max 52.92 /
report/post_ent_mean 41.29 / report/post_ent_min 20.76 / report/post_ent_std 4.76 / report/prior_ent_mag 77.24 / report/prior_ent_max 77.24 / report/prior_ent_mean 44.62 / report/prior_ent_min 29.59 / report/prior_ent_std 5.95 / report/rep_loss_mean 3.41 / 
report/rep_loss_std 5.37 / report/reward_avg 0.44 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 1.95 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 4.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.44 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.46 / eval/dyn_loss_std 4.6 / eval/image_loss_mean 0.7 / eval/image_loss_std 0.48 / eval/model_loss_mean 3.1 / eval/model_loss_std 3.18 / eval/post_ent_mag 51.17 / eval/post_ent_max 51.17 / eval/post_ent_mean 
41.51 / eval/post_ent_min 31.01 / eval/post_ent_std 3.37 / eval/prior_ent_mag 77.24 / eval/prior_ent_max 77.24 / eval/prior_ent_mean 45.07 / eval/prior_ent_min 38.65 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 3.46 / eval/rep_loss_std 4.6 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.7 / eval/reward_rate 0.52 / 
replay/size 5.1e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3802 / timer/env.step_total 19.65 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.1 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.3e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.55 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1901 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.82 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 508000 Counter(508000) 507937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 323.3.
train_Episode has 500 steps and return 301.2.
Starting evaluation at step 508500 Counter(508500) 508437
Saved chunk: 20230922T083925F673689-0rSuy8YqKgpKWFqOTiu7Mx-1aQpha5BwmEDOsjwszJMcx-1024.npz
eval_Episode has 500 steps and return 331.0.
train_Episode has 500 steps and return 303.1.
Saved chunk: 20230922T083956F066528-4XaH4DYMb0OtE5DEmhY1Z8-229mqSRLIYrAZcNVWoIl7R-1024.npz
Starting evaluation at step 509000 Counter(509000) 508937
eval_Episode has 500 steps and return 319.7.
train_Episode has 500 steps and return 306.0.
Starting evaluation at step 509500 Counter(509500) 509437
Saved chunk: 20230922T084046F330388-1aQpha5BwmEDOsjwszJMcx-4oijz2PsDtdb7ycWulbx9Y-1024.npz
eval_Episode has 500 steps and return 302.3.
train_Episode has 500 steps and return 295.2.
Saved chunk: 20230922T084118F413223-229mqSRLIYrAZcNVWoIl7R-5meStb6MZKZhMwdCA1ysZY-1024.npz
Starting evaluation at step 510000 Counter(510000) 509937
eval_Episode has 500 steps and return 333.5.
train_Episode has 500 steps and return 293.0.
Starting evaluation at step 510500 Counter(510500) 510437
Saved chunk: 20230922T084205F703903-4oijz2PsDtdb7ycWulbx9Y-6TFw9htrfEvmplbNSfsML0-1024.npz
eval_Episode has 500 steps and return 324.9.
train_Episode has 500 steps and return 303.8.
Saved chunk: 20230922T084239F310150-5meStb6MZKZhMwdCA1ysZY-7BZv1t93pcZYJKmOouO9oK-1024.npz
Starting evaluation at step 511000 Counter(511000) 510937
eval_Episode has 500 steps and return 318.4.
train_Episode has 500 steps and return 287.8.
Starting evaluation at step 511500 Counter(511500) 511437
Saved chunk: 20230922T084324F886907-6TFw9htrfEvmplbNSfsML0-2GH5zNFJsYRlMDc6hMWVR2-1024.npz
eval_Episode has 500 steps and return 312.4.
train_Episode has 500 steps and return 306.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1023490 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 312.37 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 306.15 / episode/reward_rate 0.44 / train/action_mag 4.05 / train/action_max 4.01 / train/action_mean 0.09 / train/action_min -3.37 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 2.79 / train/adv_mag 0.65 / train/adv_max 0.58 / train/adv_mean 4.9e-4 
/ train/adv_min -0.36 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.08 / train/extr_critic_max 238.08 / train/extr_critic_mean 229.55 / train/extr_critic_min 180.37 / train/extr_critic_std 9.1 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.6 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.27 / train/extr_return_raw_max 238.27 / train/extr_return_raw_mean 229.57 / train/extr_return_raw_min 
186.33 / train/extr_return_raw_std 9.08 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.83 / train/image_loss_std 0.85 / train/model_loss_mean 3.23 / 
train/model_loss_std 4.09 / train/model_opt_grad_norm 7.81 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.39 / train/policy_entropy_max 
4.03 / train/policy_entropy_mean -2.59 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.86 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.59 / train/policy_logprob_min -9.86 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.02 / train/post_ent_max 52.02 / train/post_ent_mean 41.89 / 
train/post_ent_min 23.31 / train/post_ent_std 4.25 / train/prior_ent_mag 77.09 / train/prior_ent_max 77.09 / train/prior_ent_mean 45.47 / train/prior_ent_min 31.3 / train/prior_ent_std 5.59 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.73 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.74 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 5.74 / report/image_loss_mean 0.83 / report/image_loss_std 1.08 / report/model_loss_mean 3.18 / report/model_loss_std 4.32 / report/post_ent_mag 51.88 / report/post_ent_max 51.88 /
report/post_ent_mean 42.49 / report/post_ent_min 24.53 / report/post_ent_std 3.99 / report/prior_ent_mag 77.07 / report/prior_ent_max 77.07 / report/prior_ent_mean 45.89 / report/prior_ent_min 30.14 / report/prior_ent_std 5.37 / report/rep_loss_mean 3.54 / 
report/rep_loss_std 5.74 / report/reward_avg 0.5 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.5 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.07 / eval/dyn_loss_std 5.89 / eval/image_loss_mean 0.93 / eval/image_loss_std 1.48 / eval/model_loss_mean 3.7 / eval/model_loss_std 4.8 / eval/post_ent_mag 52.79 / eval/post_ent_max 52.79 / eval/post_ent_mean 
41.33 / eval/post_ent_min 24.32 / eval/post_ent_std 3.71 / eval/prior_ent_mag 77.07 / eval/prior_ent_max 77.07 / eval/prior_ent_mean 45.37 / eval/prior_ent_min 37.74 / eval/prior_ent_std 5.07 / eval/rep_loss_mean 4.07 / eval/rep_loss_std 5.89 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.58 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.06 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.64 / eval/reward_rate 0.46 / 
replay/size 5.1e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3756 / timer/env.step_total 19.37 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.75 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-4 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7764 / timer/agent.policy_total 17.69 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.21 / 
timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.34 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 512000 Counter(512000) 511937
Saved chunk: 20230922T084359F978991-7BZv1t93pcZYJKmOouO9oK-6xCMxENoRlP31n0cNl5q98-1024.npz
eval_Episode has 500 steps and return 331.7.
train_Episode has 500 steps and return 328.2.
Starting evaluation at step 512500 Counter(512500) 512437
Saved chunk: 20230922T084443F904038-2GH5zNFJsYRlMDc6hMWVR2-6yI2ni8m0SWB3pnfmlMk8m-1024.npz
eval_Episode has 500 steps and return 327.5.
train_Episode has 500 steps and return 305.1.
Starting evaluation at step 513000 Counter(513000) 512937
eval_Episode has 500 steps and return 328.3.
train_Episode has 500 steps and return 293.6.
Saved chunk: 20230922T084521F806183-6xCMxENoRlP31n0cNl5q98-1jsImgkScpT62dQg6WsGay-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 513500 Counter(513500) 513437
Saved chunk: 20230922T084646F445020-1jsImgkScpT62dQg6WsGay-0000000000000000000000-476.npz
Saved chunk: 20230922T084604F506193-6yI2ni8m0SWB3pnfmlMk8m-0000000000000000000000-577.npz
eval_Episode has 500 steps and return 342.1.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T084604F506193-6yI2ni8m0SWB3pnfmlMk8m-5ppzQIVkBlxxV13mLDo6Fv-1024.npz
train_Episode has 500 steps and return 286.6.
Starting evaluation at step 514000 Counter(514000) 513937
eval_Episode has 500 steps and return 344.8.
train_Episode has 500 steps and return 298.7.
Saved chunk: 20230922T084646F445020-1jsImgkScpT62dQg6WsGay-4CXUGv2rONvsuTo7I6cL12-1024.npz
Starting evaluation at step 514500 Counter(514500) 514437
eval_Episode has 500 steps and return 345.5.
Saved chunk: 20230922T084724F298528-5ppzQIVkBlxxV13mLDo6Fv-1sA2oCPYtgETJERSlfkToe-1024.npz
train_Episode has 500 steps and return 303.9.
Starting evaluation at step 515000 Counter(515000) 514937
eval_Episode has 500 steps and return 340.4.
train_Episode has 500 steps and return 304.6.
Saved chunk: 20230922T084807F747121-4CXUGv2rONvsuTo7I6cL12-1S9LPBoIhPWMUT7XzRNL4T-1024.npz
Starting evaluation at step 515500 Counter(515500) 515437
eval_Episode has 500 steps and return 287.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1031002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 287.24 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 304.56 / episode/reward_rate 0.47 / train/action_mag 4.06 / train/action_max 3.99 / train/action_mean 0.09 / train/action_min -3.4 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 5.89 / train/adv_mag 0.48 / train/adv_max 0.37 / train/adv_mean 1.7e-4 / train/adv_min 
-0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.14 / train/extr_critic_max 238.14 / train/extr_critic_mean 229.29 / train/extr_critic_min 177.83 / train/extr_critic_std 10.28 / train/extr_return_normed_mag 1.56 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.32 / train/extr_return_raw_max 238.32 / train/extr_return_raw_mean 229.29 / train/extr_return_raw_min 
180.55 / train/extr_return_raw_std 10.3 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.87 / train/model_loss_mean 3.24 / 
train/model_loss_std 4.13 / train/model_opt_grad_norm 7.74 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.37 / train/policy_entropy_max 
3.96 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 9.76 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.76 / train/policy_logprob_std 1.89 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52 / train/post_ent_max 52 / train/post_ent_mean 41.9 / train/post_ent_min
23.22 / train/post_ent_std 4.34 / train/prior_ent_mag 77.06 / train/prior_ent_max 77.06 / train/prior_ent_mean 45.48 / train/prior_ent_min 30.92 / train/prior_ent_std 5.65 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.76 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.41 / report/dyn_loss_std 4.92 / report/image_loss_mean 0.72 / report/image_loss_std 0.79 / report/model_loss_mean 2.99 / report/model_loss_std 3.63 / report/post_ent_mag 54.27 / report/post_ent_max 54.27 /
report/post_ent_mean 42.55 / report/post_ent_min 25.92 / report/post_ent_std 3.69 / report/prior_ent_mag 76.93 / report/prior_ent_max 76.93 / report/prior_ent_mean 46.05 / report/prior_ent_min 35.99 / report/prior_ent_std 5.05 / report/rep_loss_mean 3.41 / 
report/rep_loss_std 4.92 / report/reward_avg 0.47 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.47 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 8.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.65 / eval/dyn_loss_std 5.32 / eval/image_loss_mean 0.79 / eval/image_loss_std 0.89 / eval/model_loss_mean 3.29 / eval/model_loss_std 3.94 / eval/post_ent_mag 49.92 / eval/post_ent_max 49.92 / eval/post_ent_mean 
41.56 / eval/post_ent_min 27.73 / eval/post_ent_std 3.53 / eval/prior_ent_mag 76.93 / eval/prior_ent_max 76.93 / eval/prior_ent_mean 45.09 / eval/prior_ent_min 32.65 / eval/prior_ent_std 5.29 / eval/rep_loss_mean 3.65 / eval/rep_loss_std 5.32 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.68 / eval/reward_rate 0.5 / 
replay/size 5.2e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.44 / timer/env.step_count 3756 / timer/env.step_total 19.41 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.44 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7764 / timer/agent.policy_total 17.69 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1878 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.9 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25

Saved chunk: 20230922T084843F524009-1sA2oCPYtgETJERSlfkToe-5imgo8rTFZYy1WMmGXSPIg-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 276.4.
Starting evaluation at step 516000 Counter(516000) 515937
eval_Episode has 500 steps and return 304.2.
train_Episode has 500 steps and return 295.2.
Saved chunk: 20230922T084928F312865-1S9LPBoIhPWMUT7XzRNL4T-6ExYmMon3KhXRN2eW9IX88-1024.npz
Starting evaluation at step 516500 Counter(516500) 516437
eval_Episode has 500 steps and return 323.0.
train_Episode has 500 steps and return 325.3.
Starting evaluation at step 517000 Counter(517000) 516937
Saved chunk: 20230922T085002F525812-5imgo8rTFZYy1WMmGXSPIg-3UeVse06WYvfLrVKZibQMo-1024.npz
eval_Episode has 500 steps and return 321.8.
train_Episode has 500 steps and return 317.6.
Saved chunk: 20230922T085050F422489-6ExYmMon3KhXRN2eW9IX88-3Vu2QM2M018bKzg6iFspWI-1024.npz
Starting evaluation at step 517500 Counter(517500) 517437
eval_Episode has 500 steps and return 314.1.
train_Episode has 500 steps and return 300.8.
Starting evaluation at step 518000 Counter(518000) 517937
Saved chunk: 20230922T085159F385783-3UeVse06WYvfLrVKZibQMo-6DpLpnGmr6jfFWgSI3I2NE-1024.npz
eval_Episode has 500 steps and return 327.7.
train_Episode has 500 steps and return 284.9.
Saved chunk: 20230922T085211F519076-3Vu2QM2M018bKzg6iFspWI-4ycbxsW1huCJkybruFrEYU-1024.npz
Starting evaluation at step 518500 Counter(518500) 518437
eval_Episode has 500 steps and return 318.5.
train_Episode has 500 steps and return 306.5.
Starting evaluation at step 519000 Counter(519000) 518937
Saved chunk: 20230922T085318F675096-6DpLpnGmr6jfFWgSI3I2NE-3Ri2kFmCdtV8bt2rusIM1W-1024.npz
eval_Episode has 500 steps and return 329.5.
train_Episode has 500 steps and return 303.6.
Saved chunk: 20230922T085332F362025-4ycbxsW1huCJkybruFrEYU-7HMZZHyFy5DrGQ4VINo5nS-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1038606 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 303.59 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 329.45 / eval_episode/reward_rate 0.47 / train/action_mag 4.03 / train/action_max 3.97 / train/action_mean 0.09 / train/action_min -3.38 / 
train/action_std 0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 5.02 / train/adv_mag 0.51 / train/adv_max 0.42 / train/adv_mean 2.7e-4
/ train/adv_min -0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 5.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 237.94 / train/extr_critic_max 237.94 / train/extr_critic_mean 229.19 / train/extr_critic_min 180.76 / train/extr_critic_std 9.78 / train/extr_return_normed_mag 1.55 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.15 / train/extr_return_raw_max 238.15 / train/extr_return_raw_mean 229.2 / train/extr_return_raw_min 
184.62 / train/extr_return_raw_std 9.78 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.85 / train/image_loss_std 0.88 / train/model_loss_mean 3.26 / 
train/model_loss_std 4.14 / train/model_opt_grad_norm 7.87 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.04 / train/policy_entropy_max 
3.59 / train/policy_entropy_mean -2.6 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.16 / train/policy_logprob_mag 9.32 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.6 / train/policy_logprob_min -9.32 / train/policy_logprob_std 1.84 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.09 / train/post_ent_max 52.09 / train/post_ent_mean 41.9 / 
train/post_ent_min 23.19 / train/post_ent_std 4.3 / train/prior_ent_mag 77.01 / train/prior_ent_max 77.01 / train/prior_ent_mean 45.5 / train/prior_ent_min 30.98 / train/prior_ent_std 5.63 / train/rep_loss_mean 3.64 / train/rep_loss_std 5.78 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.48 / train/reward_rate 
0.38 / train_stats/mean_log_entropy -2.72 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 6.04 / report/image_loss_mean 0.82 / report/image_loss_std 0.71 / report/model_loss_mean 3.23 / report/model_loss_std 4.18 / report/post_ent_mag 51.91 / report/post_ent_max 51.91 /
report/post_ent_mean 42.27 / report/post_ent_min 22.43 / report/post_ent_std 4.2 / report/prior_ent_mag 76.98 / report/prior_ent_max 76.98 / report/prior_ent_mean 45.89 / report/prior_ent_min 27.77 / report/prior_ent_std 5.34 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 6.04 / report/reward_avg 0.49 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / report/reward_max_data 1.96 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.48 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 9.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.9 / eval/dyn_loss_std 5.72 / eval/image_loss_mean 0.84 / eval/image_loss_std 0.99 / eval/model_loss_mean 3.49 / eval/model_loss_std 4.22 / eval/post_ent_mag 51.29 / eval/post_ent_max 51.29 / eval/post_ent_mean 
41.58 / eval/post_ent_min 26.72 / eval/post_ent_std 3.5 / eval/prior_ent_mag 76.98 / eval/prior_ent_max 76.98 / eval/prior_ent_mean 45.46 / eval/prior_ent_min 34.42 / eval/prior_ent_std 5.25 / eval/rep_loss_mean 3.9 / eval/rep_loss_std 5.72 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.65 / eval/reward_rate 0.5 / 
replay/size 5.2e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3802 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.45 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1901 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1901 / timer/agent.train_total 244.85 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 519500 Counter(519500) 519437
eval_Episode has 500 steps and return 324.9.
train_Episode has 500 steps and return 288.3.
Starting evaluation at step 520000 Counter(520000) 519937
Saved chunk: 20230922T085437F761764-3Ri2kFmCdtV8bt2rusIM1W-1pQHSJZGZX1rZ0iZ00k6LV-1024.npz
eval_Episode has 500 steps and return 306.1.
train_Episode has 500 steps and return 299.5.
Saved chunk: 20230922T085452F989924-7HMZZHyFy5DrGQ4VINo5nS-05LfyVqjDNRUXowiAY5DxF-1024.npz
Starting evaluation at step 520500 Counter(520500) 520437
eval_Episode has 500 steps and return 324.5.
train_Episode has 500 steps and return 245.9.
Starting evaluation at step 521000 Counter(521000) 520937
Saved chunk: 20230922T085558F370270-1pQHSJZGZX1rZ0iZ00k6LV-4Y4DojzYVfCjxXUukOmLR4-1024.npz
eval_Episode has 500 steps and return 342.1.
train_Episode has 500 steps and return 313.5.
Saved chunk: 20230922T085615F285108-05LfyVqjDNRUXowiAY5DxF-4GdVL6DT0j006uyIoSAwFT-1024.npz
Starting evaluation at step 521500 Counter(521500) 521437
eval_Episode has 500 steps and return 325.0.
train_Episode has 500 steps and return 311.8.
Starting evaluation at step 522000 Counter(522000) 521937
Saved chunk: 20230922T085717F792148-4Y4DojzYVfCjxXUukOmLR4-7b7gNBWS5lGvhN8wkwdsbk-1024.npz
eval_Episode has 500 steps and return 332.4.
train_Episode has 500 steps and return 312.4.
Saved chunk: 20230922T085736F190538-4GdVL6DT0j006uyIoSAwFT-1sREvCQ2OvxqZ1KYb0mq3O-1024.npz
Starting evaluation at step 522500 Counter(522500) 522437
eval_Episode has 500 steps and return 338.6.
train_Episode has 500 steps and return 298.9.
Starting evaluation at step 523000 Counter(523000) 522937
Saved chunk: 20230922T085837F045042-7b7gNBWS5lGvhN8wkwdsbk-0HLWlzc8zi9WvKEsPjquPq-1024.npz
eval_Episode has 500 steps and return 346.3.
train_Episode has 500 steps and return 284.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1046114 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 346.34 / eval_episode/reward_rate 0.5 / episode/length 500 / episode/score 284.57 / episode/reward_rate 0.46 / train/action_mag 4.05 / train/action_max 3.97 / train/action_mean 0.09 / train/action_min -3.47 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 5.4 / train/adv_mag 0.43 / train/adv_max 0.35 / train/adv_mean 2.1e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 5.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.02 / train/extr_critic_max 238.02 / train/extr_critic_mean 229.28 / train/extr_critic_min 188.14 / train/extr_critic_std 9.33 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.18 / train/extr_return_raw_max 238.18 / train/extr_return_raw_mean 229.29 / train/extr_return_raw_min 
188.71 / train/extr_return_raw_std 9.35 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.87 / train/model_loss_mean 3.26 /
train/model_loss_std 4.15 / train/model_opt_grad_norm 7.64 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.53 / train/policy_entropy_max 
4.23 / train/policy_entropy_mean -2.54 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 10 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.54 / train/policy_logprob_min -10 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.05 / train/post_ent_max 52.05 / train/post_ent_mean 41.82 / 
train/post_ent_min 23.09 / train/post_ent_std 4.29 / train/prior_ent_mag 76.93 / train/prior_ent_max 76.93 / train/prior_ent_mean 45.42 / train/prior_ent_min 30.89 / train/prior_ent_std 5.63 / train/rep_loss_mean 3.64 / train/rep_loss_std 5.8 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.48 / train/reward_rate 
0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 2.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.28 / report/image_loss_mean 0.89 / report/image_loss_std 1.06 / report/model_loss_mean 3.44 / report/model_loss_std 4.52 / report/post_ent_mag 51.71 / report/post_ent_max 51.71 /
report/post_ent_mean 42.04 / report/post_ent_min 22.06 / report/post_ent_std 4.18 / report/prior_ent_mag 77.28 / report/prior_ent_max 77.28 / report/prior_ent_mean 45.86 / report/prior_ent_min 33.97 / report/prior_ent_std 5.57 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 6.28 / report/reward_avg 0.52 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.52 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.63 / eval/dyn_loss_std 7.02 / eval/image_loss_mean 1.26 / eval/image_loss_std 2.21 / eval/model_loss_mean 4.37 / eval/model_loss_std 6.06 / eval/post_ent_mag 50.5 / eval/post_ent_max 50.5 / eval/post_ent_mean 
41.21 / eval/post_ent_min 20.12 / eval/post_ent_std 4.07 / eval/prior_ent_mag 77.28 / eval/prior_ent_max 77.28 / eval/prior_ent_mean 45.45 / eval/prior_ent_min 29.94 / eval/prior_ent_std 5.67 / eval/rep_loss_mean 4.63 / eval/rep_loss_std 7.02 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.33 / eval/reward_loss_std 0.65 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.72 / eval/reward_pred 0.6 / eval/reward_rate 0.45 / 
replay/size 5.2e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3754 / timer/env.step_total 19.42 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 9.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.85 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.4 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.85 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T085857F016813-1sREvCQ2OvxqZ1KYb0mq3O-31H1aaN5V1cBd34tiYgThr-1024.npz
Starting evaluation at step 523500 Counter(523500) 523437
eval_Episode has 500 steps and return 325.4.
train_Episode has 500 steps and return 301.1.
Starting evaluation at step 524000 Counter(524000) 523937
Saved chunk: 20230922T085956F192735-0HLWlzc8zi9WvKEsPjquPq-2plc1ccsSXUXSPsqQGTqIU-1024.npz
eval_Episode has 500 steps and return 337.5.
train_Episode has 500 steps and return 302.5.
Saved chunk: 20230922T090018F905273-31H1aaN5V1cBd34tiYgThr-6dqnejaXDwmS2lYP4NKS5M-1024.npz
Starting evaluation at step 524500 Counter(524500) 524437
eval_Episode has 500 steps and return 339.5.
train_Episode has 500 steps and return 300.9.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T090116F963263-2plc1ccsSXUXSPsqQGTqIU-0000000000000000000000-836.npz
Saved chunk: 20230922T090140F104213-6dqnejaXDwmS2lYP4NKS5M-0000000000000000000000-612.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 525000 Counter(525000) 524937
Saved chunk: 20230922T090116F963263-2plc1ccsSXUXSPsqQGTqIU-2MFsxOoAwNvP3WOQz8dPDG-1024.npz
eval_Episode has 500 steps and return 325.5.
train_Episode has 500 steps and return 296.8.
Saved chunk: 20230922T090140F104213-6dqnejaXDwmS2lYP4NKS5M-3LzQYWGx6p1UMUs0y9kyNT-1024.npz
Starting evaluation at step 525500 Counter(525500) 525437
eval_Episode has 500 steps and return 319.5.
train_Episode has 500 steps and return 307.9.
Starting evaluation at step 526000 Counter(526000) 525937
Saved chunk: 20230922T090236F486761-2MFsxOoAwNvP3WOQz8dPDG-4o10f8Ws4929qt4TDDrjWM-1024.npz
eval_Episode has 500 steps and return 316.8.
train_Episode has 500 steps and return 296.4.
Saved chunk: 20230922T090301F177486-3LzQYWGx6p1UMUs0y9kyNT-1LC2Cu8Iy4MMVgWEXfM0eD-1024.npz
Starting evaluation at step 526500 Counter(526500) 526437
eval_Episode has 500 steps and return 318.7.
train_Episode has 500 steps and return 312.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1053714 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 318.73 / eval_episode/reward_rate 0.49 / episode/length 500 / episode/score 312 / episode/reward_rate 0.47 / train/action_mag 4.07 / train/action_max 4.04 / train/action_mean 0.1 / train/action_min -3.4 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 2.88 / train/adv_mag 0.62 / train/adv_max 0.54 / train/adv_mean 4.9e-4 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.1 / train/extr_critic_max 238.1 / train/extr_critic_mean 229.94 / train/extr_critic_min 182.9 / train/extr_critic_std 8.15 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.32 / train/extr_return_raw_max 238.32 / train/extr_return_raw_mean 229.95 / train/extr_return_raw_min 
190.54 / train/extr_return_raw_std 8.14 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.83 / train/image_loss_std 0.86 / train/model_loss_mean 3.23 /
train/model_loss_std 4.09 / train/model_opt_grad_norm 7.83 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.38 / train/policy_entropy_max 
3.93 / train/policy_entropy_mean -2.6 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 9.55 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.6 / train/policy_logprob_min -9.55 / train/policy_logprob_std 1.85 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 41.88 / 
train/post_ent_min 23.33 / train/post_ent_std 4.19 / train/prior_ent_mag 76.91 / train/prior_ent_max 76.91 / train/prior_ent_mean 45.45 / train/prior_ent_min 31.53 / train/prior_ent_std 5.54 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.71 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.5 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.3 / report/image_loss_mean 0.87 / report/image_loss_std 0.85 / report/model_loss_mean 3.31 / report/model_loss_std 4.47 / report/post_ent_mag 52.43 / report/post_ent_max 52.43 / 
report/post_ent_mean 42.48 / report/post_ent_min 25.37 / report/post_ent_std 4.24 / report/prior_ent_mag 76.84 / report/prior_ent_max 76.84 / report/prior_ent_mean 46.11 / report/prior_ent_min 32.8 / report/prior_ent_std 5.52 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.3 / report/reward_avg 0.44 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.45 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.94 / eval/dyn_loss_std 6.08 / eval/image_loss_mean 0.87 / eval/image_loss_std 1.18 / eval/model_loss_mean 3.55 / eval/model_loss_std 4.48 / eval/post_ent_mag 50.77 / eval/post_ent_max 50.77 / eval/post_ent_mean 
41.43 / eval/post_ent_min 23.54 / eval/post_ent_std 3.57 / eval/prior_ent_mag 76.84 / eval/prior_ent_max 76.84 / eval/prior_ent_mean 45.24 / eval/prior_ent_min 32.72 / eval/prior_ent_std 5.25 / eval/rep_loss_mean 3.94 / eval/rep_loss_std 6.08 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.65 / eval/reward_rate 0.48 / 
replay/size 5.3e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3800 / timer/env.step_total 20.1 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.21 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.82 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7307 / timer/agent.policy_total 16.56 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.4 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / 
timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.33

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 527000 Counter(527000) 526937
Saved chunk: 20230922T090355F632379-4o10f8Ws4929qt4TDDrjWM-6fi71dlWfIRViVqfmDeGa8-1024.npz
eval_Episode has 500 steps and return 322.2.
train_Episode has 500 steps and return 287.2.
Saved chunk: 20230922T090421F801836-1LC2Cu8Iy4MMVgWEXfM0eD-6AmXXm4KOn1VcrPAIwuUGU-1024.npz
Starting evaluation at step 527500 Counter(527500) 527437
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 297.9.
Starting evaluation at step 528000 Counter(528000) 527937
Saved chunk: 20230922T090515F942398-6fi71dlWfIRViVqfmDeGa8-4YEFt79Tc3XoYjK02UZMv2-1024.npz
eval_Episode has 500 steps and return 331.2.
train_Episode has 500 steps and return 297.1.
Saved chunk: 20230922T090543F911513-6AmXXm4KOn1VcrPAIwuUGU-1S8e28mGYVcuR7NXIU8EOu-1024.npz
Starting evaluation at step 528500 Counter(528500) 528437
eval_Episode has 500 steps and return 325.8.
train_Episode has 500 steps and return 271.3.
Starting evaluation at step 529000 Counter(529000) 528937
Saved chunk: 20230922T090635F516137-4YEFt79Tc3XoYjK02UZMv2-5d5Q6D0K0v9PVw65p0wFxk-1024.npz
eval_Episode has 500 steps and return 334.3.
train_Episode has 500 steps and return 331.5.
Saved chunk: 20230922T090704F981387-1S8e28mGYVcuR7NXIU8EOu-5DBJpHnhrmXB0lAMua93j8-1024.npz
Starting evaluation at step 529500 Counter(529500) 529437
eval_Episode has 500 steps and return 313.8.
train_Episode has 500 steps and return 280.5.
Starting evaluation at step 530000 Counter(530000) 529937
Saved chunk: 20230922T090754F831549-5d5Q6D0K0v9PVw65p0wFxk-6Wi8IYtBcCh6YUJ9EMIcvO-1024.npz
eval_Episode has 500 steps and return 334.3.
train_Episode has 500 steps and return 285.9.
Saved chunk: 20230922T090825F797165-5DBJpHnhrmXB0lAMua93j8-5uUTg37igyzQNbEK35fHP6-1024.npz
Starting evaluation at step 530500 Counter(530500) 530437
eval_Episode has 500 steps and return 344.9.
train_Episode has 500 steps and return 308.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1061222 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 344.86 / eval_episode/reward_rate 0.5 / episode/length 500 / episode/score 308.45 / episode/reward_rate 0.45 / train/action_mag 4.1 / train/action_max 4.06 / train/action_mean 0.09 / train/action_min -3.45 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 2.86 / train/adv_mag 0.52 / train/adv_max 0.4 / train/adv_mean 4.9e-4 / train/adv_min 
-0.39 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.63 / train/dyn_loss_std 5.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.4 / train/extr_critic_max 238.4 / train/extr_critic_mean 230.22 / train/extr_critic_min 189.55 / train/extr_critic_std 8.12 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.61 / train/extr_return_raw_max 238.61 / train/extr_return_raw_mean 230.24 / train/extr_return_raw_min 
190.98 / train/extr_return_raw_std 8.13 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.87 / train/model_loss_mean 3.25 /
train/model_loss_std 4.12 / train/model_opt_grad_norm 7.88 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.49 / train/policy_entropy_max 4
/ train/policy_entropy_mean -2.6 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.96 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.6 / train/policy_logprob_min -9.96 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 51.92 / train/post_ent_max 51.92 / train/post_ent_mean 41.9 / 
train/post_ent_min 23.4 / train/post_ent_std 4.2 / train/prior_ent_mag 76.83 / train/prior_ent_max 76.83 / train/prior_ent_mean 45.49 / train/prior_ent_min 31.42 / train/prior_ent_std 5.53 / train/rep_loss_mean 3.63 / train/rep_loss_std 5.74 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.72 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 5.61 / report/image_loss_mean 0.91 / report/image_loss_std 0.87 / report/model_loss_mean 3.27 / report/model_loss_std 4.01 / report/post_ent_mag 52.53 / report/post_ent_max 52.53 /
report/post_ent_mean 41.92 / report/post_ent_min 25.93 / report/post_ent_std 4.05 / report/prior_ent_mag 76.96 / report/prior_ent_max 76.96 / report/prior_ent_mean 45.47 / report/prior_ent_min 32.23 / report/prior_ent_std 5.32 / report/rep_loss_mean 3.58 / 
report/rep_loss_std 5.61 / report/reward_avg 0.46 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.32 / report/reward_max_data 1.91 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.46 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.98 / eval/dyn_loss_std 6.19 / eval/image_loss_mean 1.04 / eval/image_loss_std 1.52 / eval/model_loss_mean 3.71 / eval/model_loss_std 4.77 / eval/post_ent_mag 52.13 / eval/post_ent_max 52.13 / eval/post_ent_mean 
41.15 / eval/post_ent_min 21.72 / eval/post_ent_std 4.14 / eval/prior_ent_mag 76.96 / eval/prior_ent_max 76.96 / eval/prior_ent_mean 44.87 / eval/prior_ent_min 29.04 / eval/prior_ent_std 5.62 / eval/rep_loss_mean 3.98 / eval/rep_loss_std 6.19 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.64 / eval/reward_rate 0.47 / 
replay/size 5.3e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3754 / timer/env.step_total 19.4 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.37 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-4 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.43 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.76 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 531000 Counter(531000) 530937
Saved chunk: 20230922T090913F955404-6Wi8IYtBcCh6YUJ9EMIcvO-0C5D7wHDwCBgmuj1pJsP1n-1024.npz
eval_Episode has 500 steps and return 318.9.
train_Episode has 500 steps and return 291.1.
Saved chunk: 20230922T090946F396017-5uUTg37igyzQNbEK35fHP6-1lZhZfbjntYTzq6tlVhLsq-1024.npz
Starting evaluation at step 531500 Counter(531500) 531437
eval_Episode has 500 steps and return 343.2.
train_Episode has 500 steps and return 292.4.
Starting evaluation at step 532000 Counter(532000) 531937
Saved chunk: 20230922T091034F340221-0C5D7wHDwCBgmuj1pJsP1n-6gLFVgVcbufgDMh8es4yM4-1024.npz
eval_Episode has 500 steps and return 317.7.
train_Episode has 500 steps and return 321.9.
Saved chunk: 20230922T091108F583162-1lZhZfbjntYTzq6tlVhLsq-2sJWyua7tRTiGWhzl7xTjM-1024.npz
Starting evaluation at step 532500 Counter(532500) 532437
eval_Episode has 500 steps and return 336.4.
train_Episode has 500 steps and return 308.9.
Starting evaluation at step 533000 Counter(533000) 532937
Saved chunk: 20230922T091153F832893-6gLFVgVcbufgDMh8es4yM4-2SWMlUFdDAglqKUSVP2Dde-1024.npz
eval_Episode has 500 steps and return 327.6.
train_Episode has 500 steps and return 300.5.
Starting evaluation at step 533500 Counter(533500) 533437
eval_Episode has 500 steps and return 339.2.
Saved chunk: 20230922T091229F552645-2sJWyua7tRTiGWhzl7xTjM-3av5kJV4bdMDvWi0X2NMwb-1024.npz
train_Episode has 500 steps and return 303.0.
Starting evaluation at step 534000 Counter(534000) 533937
Saved chunk: 20230922T091313F074516-2SWMlUFdDAglqKUSVP2Dde-4grg48l2lMhA2dthpqiuEF-1024.npz
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 286.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1068834 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 318.22 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 286.59 / episode/reward_rate 0.45 / train/action_mag 4.05 / train/action_max 4.01 / train/action_mean 0.09 / train/action_min -3.52 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 6.19 / train/adv_mag 0.5 / train/adv_max 0.37 / train/adv_mean 1.4e-4 /
train/adv_min -0.4 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 5.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.38 / train/extr_critic_max 238.38 / train/extr_critic_mean 229.85 / train/extr_critic_min 185.31 / train/extr_critic_std 9.1 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.58 / train/extr_return_raw_max 238.58 / train/extr_return_raw_mean 229.85 / train/extr_return_raw_min 
186.83 / train/extr_return_raw_std 9.13 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.88 / train/model_loss_mean 3.25 / 
train/model_loss_std 4.17 / train/model_opt_grad_norm 8.03 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.46 / train/policy_entropy_max 
4.11 / train/policy_entropy_mean -2.56 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.25 / train/policy_logprob_mag 9.87 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.56 / train/policy_logprob_min -9.87 / train/policy_logprob_std 1.9 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.02 / train/post_ent_max 52.02 / train/post_ent_mean 41.86 / 
train/post_ent_min 23.09 / train/post_ent_std 4.26 / train/prior_ent_mag 76.89 / train/prior_ent_max 76.89 / train/prior_ent_mean 45.46 / train/prior_ent_min 31.25 / train/prior_ent_std 5.6 / train/rep_loss_mean 3.64 / train/rep_loss_std 5.83 / train/reward_avg 0.48 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.32 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.48 / train/reward_rate 
0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.66 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.81 / report/dyn_loss_std 5.69 / report/image_loss_mean 0.91 / report/image_loss_std 1.2 / report/model_loss_mean 3.42 / report/model_loss_std 4.37 / report/post_ent_mag 53.94 / report/post_ent_max 53.94 / 
report/post_ent_mean 42.4 / report/post_ent_min 23.09 / report/post_ent_std 4.03 / report/prior_ent_mag 76.55 / report/prior_ent_max 76.55 / report/prior_ent_mean 46.15 / report/prior_ent_min 35.53 / report/prior_ent_std 5.11 / report/rep_loss_mean 3.81 / 
report/rep_loss_std 5.69 / report/reward_avg 0.49 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.33 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 6.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.49 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.66 / eval/dyn_loss_std 5.35 / eval/image_loss_mean 0.79 / eval/image_loss_std 0.89 / eval/model_loss_mean 3.29 / eval/model_loss_std 3.9 / eval/post_ent_mag 50.46 / eval/post_ent_max 50.46 / eval/post_ent_mean 
41.39 / eval/post_ent_min 24.8 / eval/post_ent_std 3.62 / eval/prior_ent_mag 76.55 / eval/prior_ent_max 76.55 / eval/prior_ent_mean 45.17 / eval/prior_ent_min 33.03 / eval/prior_ent_std 5.2 / eval/rep_loss_mean 3.66 / eval/rep_loss_std 5.35 / eval/reward_avg 0.68 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.68 / eval/reward_rate 0.5 / replay/size 
5.3e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3806 / timer/env.step_total 19.7 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 466.4 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-4 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.47 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1903 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.93 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 534500 Counter(534500) 534437
eval_Episode has 500 steps and return 324.2.
Saved chunk: 20230922T091353F825604-3av5kJV4bdMDvWi0X2NMwb-6Ysx0UJOPo758vdbFGDOCF-1024.npz
train_Episode has 500 steps and return 302.4.
Starting evaluation at step 535000 Counter(535000) 534937
Saved chunk: 20230922T091432F141036-4grg48l2lMhA2dthpqiuEF-1anZSXL2457yng8jxS0hCA-1024.npz
eval_Episode has 500 steps and return 315.1.
train_Episode has 500 steps and return 301.7.
Starting evaluation at step 535500 Counter(535500) 535437
eval_Episode has 500 steps and return 333.7.
Saved chunk: 20230922T091515F627485-6Ysx0UJOPo758vdbFGDOCF-1hoU1cgJtQ06PB4DwZC5tb-1024.npz
train_Episode has 500 steps and return 305.2.
Starting evaluation at step 536000 Counter(536000) 535937
Saved chunk: 20230922T091552F635101-1anZSXL2457yng8jxS0hCA-1CNFgQeKeprTUZrADqjfZt-1024.npz
eval_Episode has 500 steps and return 324.8.
train_Episode has 500 steps and return 313.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T091636F793110-1hoU1cgJtQ06PB4DwZC5tb-0000000000000000000000-748.npz
Saved chunk: 20230922T091712F078903-1CNFgQeKeprTUZrADqjfZt-0000000000000000000000-71.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 536500 Counter(536500) 536437
eval_Episode has 500 steps and return 345.1.
train_Episode has 500 steps and return 301.0.
Saved chunk: 20230922T091636F793110-1hoU1cgJtQ06PB4DwZC5tb-5iVVYfjaMdtVh5lwJvxuzN-1024.npz
Starting evaluation at step 537000 Counter(537000) 536937
eval_Episode has 500 steps and return 326.0.
Saved chunk: 20230922T091712F078903-1CNFgQeKeprTUZrADqjfZt-12yFlHsdPhJATTKCoSJ4Qn-1024.npz
train_Episode has 500 steps and return 293.6.
Starting evaluation at step 537500 Counter(537500) 537437
eval_Episode has 500 steps and return 342.3.
train_Episode has 500 steps and return 308.1.
Saved chunk: 20230922T091757F933159-5iVVYfjaMdtVh5lwJvxuzN-0ygdn8gq77sXxszLfdpofP-1024.npz
Starting evaluation at step 538000 Counter(538000) 537937
eval_Episode has 500 steps and return 304.9.
Saved chunk: 20230922T091831F548240-12yFlHsdPhJATTKCoSJ4Qn-0uWl130bwJOSYfAGkFvYkZ-1024.npz
train_Episode has 500 steps and return 303.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1076338 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 304.94 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 303.4 / episode/reward_rate 0.45 / train/action_mag 4.08 / train/action_max 4.01 / train/action_mean 0.09 / train/action_min -3.56 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 5.51 / train/adv_mag 0.55 / train/adv_max 0.45 / train/adv_mean 2.2e-4 / train/adv_min 
-0.37 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.46 / train/extr_critic_max 238.46 / train/extr_critic_mean 229.93 / train/extr_critic_min 185.77 / train/extr_critic_std 9.1 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.67 / train/extr_return_raw_max 238.67 / train/extr_return_raw_mean 229.94 / train/extr_return_raw_min 
188.52 / train/extr_return_raw_std 9.12 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.83 / train/image_loss_std 0.85 / train/model_loss_mean 3.23 / 
train/model_loss_std 4.09 / train/model_opt_grad_norm 7.85 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.54 / train/policy_entropy_max 
4.1 / train/policy_entropy_mean -2.58 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 9.93 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.58 / train/policy_logprob_min -9.93 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 2.8e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.1 / train/post_ent_max 52.1 / train/post_ent_mean 41.93 / 
train/post_ent_min 23.71 / train/post_ent_std 4.19 / train/prior_ent_mag 76.78 / train/prior_ent_max 76.78 / train/prior_ent_mean 45.5 / train/prior_ent_min 31.68 / train/prior_ent_std 5.54 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.71 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.98 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.5 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.7 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 6.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.43 / report/dyn_loss_std 5.13 / report/image_loss_mean 0.73 / report/image_loss_std 0.65 / report/model_loss_mean 3.05 / report/model_loss_std 3.63 / report/post_ent_mag 53.18 / report/post_ent_max 53.18 /
report/post_ent_mean 42.76 / report/post_ent_min 28.29 / report/post_ent_std 3.57 / report/prior_ent_mag 76.81 / report/prior_ent_max 76.81 / report/prior_ent_mean 46.19 / report/prior_ent_min 33.23 / report/prior_ent_std 4.98 / report/rep_loss_mean 3.43 / 
report/rep_loss_std 5.13 / report/reward_avg 0.54 / report/reward_loss_mean 0.27 / report/reward_loss_std 0.34 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.54 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.66 / eval/dyn_loss_std 5.55 / eval/image_loss_mean 0.77 / eval/image_loss_std 1.03 / eval/model_loss_mean 3.25 / eval/model_loss_std 4.11 / eval/post_ent_mag 51.19 / eval/post_ent_max 51.19 / eval/post_ent_mean 
41.69 / eval/post_ent_min 22.37 / eval/post_ent_std 3.42 / eval/prior_ent_mag 76.81 / eval/prior_ent_max 76.81 / eval/prior_ent_mean 45.19 / eval/prior_ent_min 36.77 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 3.66 / eval/rep_loss_std 5.55 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.62 / eval/reward_rate 0.48 / 
replay/size 5.4e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3752 / timer/env.step_total 19.44 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.99 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.53 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.8e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241.71 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 538500 Counter(538500) 538437
eval_Episode has 500 steps and return 320.9.
train_Episode has 500 steps and return 301.0.
Saved chunk: 20230922T091918F589815-0ygdn8gq77sXxszLfdpofP-6GMHESXNgjHOTcZjhg9VWe-1024.npz
Starting evaluation at step 539000 Counter(539000) 538937
eval_Episode has 500 steps and return 330.5.
Saved chunk: 20230922T091950F606737-0uWl130bwJOSYfAGkFvYkZ-0oaegoabVQEAVHRsg18X0H-1024.npz
train_Episode has 500 steps and return 300.8.
Starting evaluation at step 539500 Counter(539500) 539437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 296.6.
Saved chunk: 20230922T092040F673676-6GMHESXNgjHOTcZjhg9VWe-18Ux1dE18PMtfi1fkWBi1I-1024.npz
Starting evaluation at step 540000 Counter(540000) 539937
eval_Episode has 500 steps and return 328.0.
train_Episode has 500 steps and return 308.0.
Starting evaluation at step 540500 Counter(540500) 540437
Saved chunk: 20230922T092111F355631-0oaegoabVQEAVHRsg18X0H-5Dv3dngd5zqI2o2QASI2ch-1024.npz
eval_Episode has 500 steps and return 340.8.
train_Episode has 500 steps and return 293.6.
Saved chunk: 20230922T092201F809550-18Ux1dE18PMtfi1fkWBi1I-3RKQZ3MLLuelZIKssB1ZF0-1024.npz
Starting evaluation at step 541000 Counter(541000) 540937
eval_Episode has 500 steps and return 324.7.
train_Episode has 500 steps and return 302.8.
Starting evaluation at step 541500 Counter(541500) 541437
Saved chunk: 20230922T092306F816125-5Dv3dngd5zqI2o2QASI2ch-4N23IkTNRrumxFBtMSnXo7-1024.npz
eval_Episode has 500 steps and return 336.7.
train_Episode has 500 steps and return 281.1.
Saved chunk: 20230922T092322F648073-3RKQZ3MLLuelZIKssB1ZF0-1wHHaSA7hqvoZ2OUrXv1Mi-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1083940 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 336.67 / eval_episode/reward_rate 0.5 / episode/length 500 / episode/score 281.14 / episode/reward_rate 0.42 / train/action_mag 4.05 / train/action_max 3.97 / train/action_mean 0.09 / train/action_min -3.62 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 5.29 / train/adv_mag 0.53 / train/adv_max 0.45 / train/adv_mean 2.2e-4 / train/adv_min 
-0.35 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.67 / train/extr_critic_max 238.67 / train/extr_critic_mean 230.05 / train/extr_critic_min 186.42 / train/extr_critic_std 9.07 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.52 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.87 / train/extr_return_raw_max 238.87 / train/extr_return_raw_mean 230.06 / train/extr_return_raw_min 
188.23 / train/extr_return_raw_std 9.08 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.88 / train/model_loss_mean 3.26 / 
train/model_loss_std 4.13 / train/model_opt_grad_norm 7.72 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.81 / train/policy_entropy_max 
4.52 / train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.32 / train/policy_logprob_mag 10.28 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -10.28 / train/policy_logprob_std 1.95 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.7e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.95 / train/post_ent_max 51.95 / train/post_ent_mean 41.81 / 
train/post_ent_min 23.3 / train/post_ent_std 4.21 / train/prior_ent_mag 76.79 / train/prior_ent_max 76.79 / train/prior_ent_mean 45.41 / train/prior_ent_min 31.57 / train/prior_ent_std 5.56 / train/rep_loss_mean 3.64 / train/rep_loss_std 5.76 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.68 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 4.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 5.71 / report/image_loss_mean 0.84 / report/image_loss_std 0.76 / report/model_loss_mean 3.28 / report/model_loss_std 3.98 / report/post_ent_mag 51.91 / report/post_ent_max 51.91 /
report/post_ent_mean 41.66 / report/post_ent_min 24.79 / report/post_ent_std 4.08 / report/prior_ent_mag 76.62 / report/prior_ent_max 76.62 / report/prior_ent_mean 45.3 / report/prior_ent_min 30.71 / report/prior_ent_std 5.62 / report/rep_loss_mean 3.66 / 
report/rep_loss_std 5.71 / report/reward_avg 0.51 / report/reward_loss_mean 0.25 / report/reward_loss_std 0.35 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.5 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.45 / eval/dyn_loss_std 4.65 / eval/image_loss_mean 0.71 / eval/image_loss_std 0.64 / eval/model_loss_mean 3.12 / eval/model_loss_std 3.35 / eval/post_ent_mag 50.88 / eval/post_ent_max 50.88 / eval/post_ent_mean 41.64 / 
eval/post_ent_min 30.23 / eval/post_ent_std 3.39 / eval/prior_ent_mag 76.62 / eval/prior_ent_max 76.62 / eval/prior_ent_mean 45.09 / eval/prior_ent_min 39.12 / eval/prior_ent_std 4.94 / eval/rep_loss_mean 3.45 / eval/rep_loss_std 4.65 / eval/reward_avg 0.69 / 
eval/reward_loss_mean 0.34 / eval/reward_loss_std 0.43 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.68 / eval/reward_rate 0.52 / 
replay/size 5.4e5 / replay/inserts 3801 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3801 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 465.69 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7308 / timer/agent.policy_total 16.5 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1900 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.64 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.34

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 542000 Counter(542000) 541937
eval_Episode has 500 steps and return 333.1.
train_Episode has 500 steps and return 286.3.
Starting evaluation at step 542500 Counter(542500) 542437
Saved chunk: 20230922T092426F012784-4N23IkTNRrumxFBtMSnXo7-7n5oD9SVzXAQHzScWcr9LG-1024.npz
eval_Episode has 500 steps and return 345.4.
train_Episode has 500 steps and return 331.5.
Saved chunk: 20230922T092443F376025-1wHHaSA7hqvoZ2OUrXv1Mi-5nPMXCkQpvcV0mT70qIK76-1024.npz
Starting evaluation at step 543000 Counter(543000) 542937
eval_Episode has 500 steps and return 330.1.
train_Episode has 500 steps and return 289.3.
Starting evaluation at step 543500 Counter(543500) 543437
Saved chunk: 20230922T092546F544924-7n5oD9SVzXAQHzScWcr9LG-2kDg466tWuVoQTXOoOSjLf-1024.npz
eval_Episode has 500 steps and return 308.0.
train_Episode has 500 steps and return 291.1.
Saved chunk: 20230922T092605F588518-5nPMXCkQpvcV0mT70qIK76-5TNMxqj1IvhKupGay35RKE-1024.npz
Starting evaluation at step 544000 Counter(544000) 543937
eval_Episode has 500 steps and return 307.4.
train_Episode has 500 steps and return 302.4.
Starting evaluation at step 544500 Counter(544500) 544437
Saved chunk: 20230922T092706F000400-2kDg466tWuVoQTXOoOSjLf-07xLZWtJy70L5YGtisYjUi-1024.npz
eval_Episode has 500 steps and return 322.6.
train_Episode has 500 steps and return 297.9.
Saved chunk: 20230922T092726F549371-5TNMxqj1IvhKupGay35RKE-6sPpbqt2pWy1iuNKVhPfos-1024.npz
Starting evaluation at step 545000 Counter(545000) 544937
eval_Episode has 500 steps and return 328.8.
train_Episode has 500 steps and return 298.1.
Starting evaluation at step 545500 Counter(545500) 545437
Saved chunk: 20230922T092825F283343-07xLZWtJy70L5YGtisYjUi-47VnYoZ8s1mL7sdZtZ8HWm-1024.npz
eval_Episode has 500 steps and return 326.4.
train_Episode has 500 steps and return 315.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1091450 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 326.4 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 315.56 / episode/reward_rate 0.48 / train/action_mag 4.06 / train/action_max 4 / train/action_mean 0.1 / train/action_min -3.52 / train/action_std 0.9
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 5.89 / train/adv_mag 0.54 / train/adv_max 0.43 / train/adv_mean 1.6e-4 / train/adv_min -0.41
/ train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.63 
/ train/dyn_loss_std 5.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss
1.2e4 / train/extr_critic_mag 238.5 / train/extr_critic_max 238.5 / train/extr_critic_mean 229.6 / train/extr_critic_min 183.6 / train/extr_critic_std 9.77 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.64 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.72 / train/extr_return_raw_max 238.72 / train/extr_return_raw_mean 229.6 / train/extr_return_raw_min 185.37 / train/extr_return_raw_std 9.82
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.84 / train/image_loss_std 0.88 / train/model_loss_mean 3.24 / train/model_loss_std 4.13 / 
train/model_opt_grad_norm 7.67 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.59 / train/policy_entropy_max 4.25 / 
train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.32 / train/policy_logprob_mag 10.07 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -10.07 / train/policy_logprob_std 1.95 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.8e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.03 / train/post_ent_max 52.03 / train/post_ent_mean 41.75 / 
train/post_ent_min 23.41 / train/post_ent_std 4.26 / train/prior_ent_mag 76.66 / train/prior_ent_max 76.66 / train/prior_ent_mean 45.34 / train/prior_ent_min 31.27 / train/prior_ent_std 5.61 / train/rep_loss_mean 3.63 / train/rep_loss_std 5.75 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.67 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 5.85 / report/image_loss_mean 0.84 / report/image_loss_std 0.7 / report/model_loss_mean 3.23 / report/model_loss_std 4.08 / report/post_ent_mag 51.94 / report/post_ent_max 51.94 / 
report/post_ent_mean 42.32 / report/post_ent_min 21.85 / report/post_ent_std 4.15 / report/prior_ent_mag 76.68 / report/prior_ent_max 76.68 / report/prior_ent_mean 45.99 / report/prior_ent_min 30.64 / report/prior_ent_std 5.39 / report/rep_loss_mean 3.64 / 
report/rep_loss_std 5.85 / report/reward_avg 0.43 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.43 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.88 / eval/dyn_loss_std 5.72 / eval/image_loss_mean 0.82 / eval/image_loss_std 0.99 / eval/model_loss_mean 3.45 / eval/model_loss_std 4.19 / eval/post_ent_mag 53.42 / eval/post_ent_max 53.42 / eval/post_ent_mean 
41.42 / eval/post_ent_min 22.33 / eval/post_ent_std 3.55 / eval/prior_ent_mag 76.68 / eval/prior_ent_max 76.68 / eval/prior_ent_mean 45.28 / eval/prior_ent_min 30.98 / eval/prior_ent_std 5.28 / eval/rep_loss_mean 3.88 / eval/rep_loss_std 5.72 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.5 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 5.5e5 / replay/inserts 3755 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3755 / timer/env.step_total 19.4 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.1 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7763 / timer/agent.policy_total 17.39 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1878 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.73 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T092847F359909-6sPpbqt2pWy1iuNKVhPfos-2p6RZadl3JtPQoF67mrSZ4-1024.npz
Starting evaluation at step 546000 Counter(546000) 545937
eval_Episode has 500 steps and return 305.2.
train_Episode has 500 steps and return 309.6.
Starting evaluation at step 546500 Counter(546500) 546437
Saved chunk: 20230922T092944F280489-47VnYoZ8s1mL7sdZtZ8HWm-7yYbV4JJkjScOAdK3WPa2o-1024.npz
eval_Episode has 500 steps and return 320.5.
train_Episode has 500 steps and return 296.8.
Saved chunk: 20230922T093009F108351-2p6RZadl3JtPQoF67mrSZ4-50hYtUOYFqhAUUefpHh6O1-1024.npz
Starting evaluation at step 547000 Counter(547000) 546937
eval_Episode has 500 steps and return 335.6.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 547500 Counter(547500) 547437
Saved chunk: 20230922T093104F984354-7yYbV4JJkjScOAdK3WPa2o-3jFlShsYhnFRlzt8y7vH5J-1024.npz
eval_Episode has 500 steps and return 327.5.
train_Episode has 500 steps and return 288.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T093130F336082-50hYtUOYFqhAUUefpHh6O1-0000000000000000000000-884.npz
Saved chunk: 20230922T093224F483940-3jFlShsYhnFRlzt8y7vH5J-0000000000000000000000-330.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T093130F336082-50hYtUOYFqhAUUefpHh6O1-28YS3CUNOonr1YSMF20Og8-1024.npz
Starting evaluation at step 548000 Counter(548000) 547937
eval_Episode has 500 steps and return 333.8.
train_Episode has 500 steps and return 291.6.
Starting evaluation at step 548500 Counter(548500) 548437
Saved chunk: 20230922T093224F483940-3jFlShsYhnFRlzt8y7vH5J-1HCSxkWRomHYCNCRqRrF9L-1024.npz
eval_Episode has 500 steps and return 314.0.
train_Episode has 500 steps and return 302.6.
Saved chunk: 20230922T093251F577979-28YS3CUNOonr1YSMF20Og8-4eysEFF5QXcoONRmWxAJEF-1024.npz
Starting evaluation at step 549000 Counter(549000) 548937
eval_Episode has 500 steps and return 331.3.
train_Episode has 500 steps and return 301.7.
Starting evaluation at step 549500 Counter(549500) 549437
Saved chunk: 20230922T093343F972099-1HCSxkWRomHYCNCRqRrF9L-49NLl70pdrbotzxPHdJR4r-1024.npz
eval_Episode has 500 steps and return 311.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1099002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 311.93 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 301.72 / episode/reward_rate 0.44 / train/action_mag 4.09 / train/action_max 4.03 / train/action_mean 0.09 / train/action_min -3.5 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 4.38 / train/adv_mag 0.4 / train/adv_max 0.31 / train/adv_mean 3.1e-4 / train/adv_min 
-0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.82 / train/extr_critic_max 238.82 / train/extr_critic_mean 230.23 / train/extr_critic_min 189.45 / train/extr_critic_std 8.72 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 239.01 / train/extr_return_raw_max 239.01 / train/extr_return_raw_mean 230.24 / train/extr_return_raw_min 
190.16 / train/extr_return_raw_std 8.75 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.85 / train/image_loss_std 0.88 / train/model_loss_mean 3.26 / 
train/model_loss_std 4.13 / train/model_opt_grad_norm 8.15 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.24 / train/policy_entropy_max 
3.87 / train/policy_entropy_mean -2.54 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.23 / train/policy_logprob_mag 9.63 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.54 / train/policy_logprob_min -9.63 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.1e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.08 / train/post_ent_max 52.08 / train/post_ent_mean 41.82 / 
train/post_ent_min 23.13 / train/post_ent_std 4.24 / train/prior_ent_mag 76.72 / train/prior_ent_max 76.72 / train/prior_ent_mean 45.43 / train/prior_ent_min 31.57 / train/prior_ent_std 5.56 / train/rep_loss_mean 3.65 / train/rep_loss_std 5.76 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.38 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -1.8 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 6.15 / report/image_loss_mean 0.88 / report/image_loss_std 0.99 / report/model_loss_mean 3.27 / report/model_loss_std 4.39 / report/post_ent_mag 53.13 / report/post_ent_max 53.13 /
report/post_ent_mean 42.04 / report/post_ent_min 19.3 / report/post_ent_std 4.15 / report/prior_ent_mag 76.69 / report/prior_ent_max 76.69 / report/prior_ent_mean 45.68 / report/prior_ent_min 30.38 / report/prior_ent_std 5.6 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 6.15 / report/reward_avg 0.47 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.32 / report/reward_max_data 1.98 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.46 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.71 / eval/dyn_loss_std 5.46 / eval/image_loss_mean 0.75 / eval/image_loss_std 0.75 / eval/model_loss_mean 3.28 / eval/model_loss_std 3.88 / eval/post_ent_mag 51.17 / eval/post_ent_max 51.17 / eval/post_ent_mean 
41.47 / eval/post_ent_min 26.76 / eval/post_ent_std 3.53 / eval/prior_ent_mag 76.69 / eval/prior_ent_max 76.69 / eval/prior_ent_mean 45.17 / eval/prior_ent_min 37.91 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 3.71 / eval/rep_loss_std 5.46 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.31 / eval/reward_loss_std 0.42 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.66 / eval/reward_rate 0.49 / 
replay/size 5.5e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.07 / timer/env.step_count 3776 / timer/env.step_total 19.63 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.09 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.09 / timer/agent.save_frac 2.9e-4 / timer/agent.save_avg 0.09 / timer/agent.save_min 0.09 / timer/agent.save_max 0.09 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.6 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.09 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1888 / timer/agent.train_total 243.18 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 310.1.
Saved chunk: 20230922T093412F319878-4eysEFF5QXcoONRmWxAJEF-7HaEonAg6vhIgBBNTYvZGH-1024.npz
Starting evaluation at step 550000 Counter(550000) 549937
eval_Episode has 500 steps and return 320.3.
train_Episode has 500 steps and return 295.9.
Starting evaluation at step 550500 Counter(550500) 550437
Saved chunk: 20230922T093503F100027-49NLl70pdrbotzxPHdJR4r-5BA65AGHSQS26rudu5OyRE-1024.npz
eval_Episode has 500 steps and return 340.0.
train_Episode has 500 steps and return 293.2.
Saved chunk: 20230922T093534F335399-7HaEonAg6vhIgBBNTYvZGH-5iA71bq5ylE4JH03PhaUd8-1024.npz
Starting evaluation at step 551000 Counter(551000) 550937
eval_Episode has 500 steps and return 344.5.
train_Episode has 500 steps and return 270.8.
Starting evaluation at step 551500 Counter(551500) 551437
Saved chunk: 20230922T093623F795534-5BA65AGHSQS26rudu5OyRE-7dSbHePkcq2bfK7XHnz8MY-1024.npz
eval_Episode has 500 steps and return 325.6.
train_Episode has 500 steps and return 298.9.
Saved chunk: 20230922T093655F376300-5iA71bq5ylE4JH03PhaUd8-5qRXco299BfNhmLLJbZMGR-1024.npz
Starting evaluation at step 552000 Counter(552000) 551937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 322.2.
Starting evaluation at step 552500 Counter(552500) 552437
Saved chunk: 20230922T093743F220252-7dSbHePkcq2bfK7XHnz8MY-3YQF1tJ0kjTuOzSYulutoG-1024.npz
eval_Episode has 500 steps and return 326.3.
train_Episode has 500 steps and return 304.7.
Saved chunk: 20230922T093816F304078-5qRXco299BfNhmLLJbZMGR-24D7BO9b3pi6TuNj881syn-1024.npz
Starting evaluation at step 553000 Counter(553000) 552937
eval_Episode has 500 steps and return 325.8.
train_Episode has 500 steps and return 313.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1106606 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 313.92 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 325.79 / eval_episode/reward_rate 0.48 / train/action_mag 4.11 / train/action_max 4.03 / train/action_mean 0.11 / train/action_min -3.57 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 14.94 / train/adv_mag 0.59 / train/adv_max 0.46 / train/adv_mean 
-7.7e-4 / train/adv_min -0.45 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 9.7e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.94 / train/extr_critic_max 238.94 / train/extr_critic_mean 230.09 / train/extr_critic_min 179.53 / train/extr_critic_std 9.57 / 
train/extr_return_normed_mag 1.26 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 239.16 / train/extr_return_raw_max 
239.16 / train/extr_return_raw_mean 230.06 / train/extr_return_raw_min 183.38 / train/extr_return_raw_std 9.72 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean
0.83 / train/image_loss_std 0.85 / train/model_loss_mean 3.23 / train/model_loss_std 4.08 / train/model_opt_grad_norm 7.45 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 4.16 / train/policy_entropy_max 3.83 / train/policy_entropy_mean -2.51 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.73 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.51 / 
train/policy_logprob_min -9.73 / train/policy_logprob_std 1.88 / train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.3e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.02 / 
train/post_ent_max 52.02 / train/post_ent_mean 41.87 / train/post_ent_min 23.31 / train/post_ent_std 4.18 / train/prior_ent_mag 76.71 / train/prior_ent_max 76.71 / train/prior_ent_mean 45.45 / train/prior_ent_min 31.33 / train/prior_ent_std 5.54 / train/rep_loss_mean 
3.62 / train/rep_loss_std 5.72 / train/reward_avg 0.49 / train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / 
train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 0.39 / train_stats/mean_log_entropy -2.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 4.3e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 5.55 / report/image_loss_mean 0.77 / report/image_loss_std 0.85 / report/model_loss_mean 3.09 / 
report/model_loss_std 4 / report/post_ent_mag 51.75 / report/post_ent_max 51.75 / report/post_ent_mean 41.59 / report/post_ent_min 24.66 / report/post_ent_std 4.16 / report/prior_ent_mag 76.59 / report/prior_ent_max 76.59 / report/prior_ent_mean 45.12 / 
report/prior_ent_min 31.2 / report/prior_ent_std 5.61 / report/rep_loss_mean 3.51 / report/rep_loss_std 5.55 / report/reward_avg 0.47 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / 
report/reward_neg_acc 1 / report/reward_neg_loss 3.8e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.47 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.71 / eval/dyn_loss_std 5.6 / eval/image_loss_mean 0.83 / eval/image_loss_std 1 / eval/model_loss_mean 3.35 / eval/model_loss_std 4.03 /
eval/post_ent_mag 50.14 / eval/post_ent_max 50.14 / eval/post_ent_mean 41.47 / eval/post_ent_min 23.77 / eval/post_ent_std 3.72 / eval/prior_ent_mag 76.59 / eval/prior_ent_max 76.59 / eval/prior_ent_mean 45.06 / eval/prior_ent_min 32.47 / eval/prior_ent_std 5.25 / 
eval/rep_loss_mean 3.71 / eval/rep_loss_std 5.6 / eval/reward_avg 0.64 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.59 / eval/reward_pred 0.64 / eval/reward_rate 0.47 / replay/size 5.5e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3802 / 
timer/env.step_total 19.88 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.21 / timer/replay._sample_count 3e4 / timer/replay._sample_total 461.61 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 
/ timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7309 / timer/agent.policy_total 16.5 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1901 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.5e-4 / 
timer/agent.train_count 1901 / timer/agent.train_total 244.48 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.35

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 553500 Counter(553500) 553437
Saved chunk: 20230922T093902F397589-3YQF1tJ0kjTuOzSYulutoG-5is8p4QzaO1OFQjCDMOBhb-1024.npz
eval_Episode has 500 steps and return 319.1.
train_Episode has 500 steps and return 287.4.
Saved chunk: 20230922T093937F046072-24D7BO9b3pi6TuNj881syn-3rT0gO6S3M0FNwp1mxqEK2-1024.npz
Starting evaluation at step 554000 Counter(554000) 553937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 329.1.
Starting evaluation at step 554500 Counter(554500) 554437
Saved chunk: 20230922T094022F759515-5is8p4QzaO1OFQjCDMOBhb-5BnHM2CzQZ6jO6sdhHpHMq-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 316.5.
Starting evaluation at step 555000 Counter(555000) 554937
eval_Episode has 500 steps and return 0.8.
Saved chunk: 20230922T094059F268370-3rT0gO6S3M0FNwp1mxqEK2-6dFm459VwTQp4x7KSL005f-1024.npz
train_Episode has 500 steps and return 289.8.
Starting evaluation at step 555500 Counter(555500) 555437
Saved chunk: 20230922T094142F361418-5BnHM2CzQZ6jO6sdhHpHMq-5PmGn6QS7ZUkktJ4fKIyMI-1024.npz
eval_Episode has 500 steps and return 325.4.
train_Episode has 500 steps and return 305.9.
Starting evaluation at step 556000 Counter(556000) 555937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094223F963108-6dFm459VwTQp4x7KSL005f-5SoCMrG1ByyuipjLYP3GB2-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 556500 Counter(556500) 556437
Saved chunk: 20230922T094301F860021-5PmGn6QS7ZUkktJ4fKIyMI-0GtnuFKJJjHSayxfFYK0kJ-1024.npz
eval_Episode has 500 steps and return 338.3.
train_Episode has 500 steps and return 292.4.
Starting evaluation at step 557000 Counter(557000) 556937
eval_Episode has 500 steps and return 288.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1114106 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 288.89 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 292.37 / episode/reward_rate 0.44 / train/action_mag 4.13 / train/action_max 4.08 / train/action_mean 0.11 / train/action_min -3.6 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -2.3 / train/adv_mag 0.61 / train/adv_max 0.53 / train/adv_mean 9.6e-4 / train/adv_min 
-0.5 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 239.03 / train/extr_critic_max 239.03 / train/extr_critic_mean 228.26 / train/extr_critic_min 150.45 / train/extr_critic_std 15.81 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.66 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 239.24 / train/extr_return_raw_max 239.24 / train/extr_return_raw_mean 228.3 / train/extr_return_raw_min
152.75 / train/extr_return_raw_std 15.79 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.83 / train/image_loss_std 0.88 / train/model_loss_mean 3.23 / 
train/model_loss_std 4.12 / train/model_opt_grad_norm 7.86 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.4 / train/policy_entropy_max 
4.28 / train/policy_entropy_mean -2.41 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.31 / train/policy_logprob_mag 9.83 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.41 / train/policy_logprob_min -9.83 / train/policy_logprob_std 1.94 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 3.6e-5 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.99 / train/post_ent_max 51.99 / train/post_ent_mean 41.8 / 
train/post_ent_min 23.2 / train/post_ent_std 4.25 / train/prior_ent_mag 76.64 / train/prior_ent_max 76.64 / train/prior_ent_mean 45.37 / train/prior_ent_min 31.1 / train/prior_ent_std 5.59 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.74 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.43 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 9.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 6.18 / report/image_loss_mean 1.01 / report/image_loss_std 1.23 / report/model_loss_mean 3.63 / report/model_loss_std 4.65 / report/post_ent_mag 53.16 / report/post_ent_max 53.16 /
report/post_ent_mean 42.02 / report/post_ent_min 23.3 / report/post_ent_std 4.58 / report/prior_ent_mag 76.33 / report/prior_ent_max 76.33 / report/prior_ent_mean 45.9 / report/prior_ent_min 33.89 / report/prior_ent_std 5.4 / report/rep_loss_mean 3.99 / 
report/rep_loss_std 6.18 / report/reward_avg 0.48 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 1.96 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.47 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.51 / eval/dyn_loss_std 5.16 / eval/image_loss_mean 0.73 / eval/image_loss_std 0.74 / eval/model_loss_mean 3.14 / eval/model_loss_std 3.67 / eval/post_ent_mag 50.11 / eval/post_ent_max 50.11 / eval/post_ent_mean 
41.44 / eval/post_ent_min 25.71 / eval/post_ent_std 3.46 / eval/prior_ent_mag 76.33 / eval/prior_ent_max 76.33 / eval/prior_ent_mean 44.94 / eval/prior_ent_min 37.96 / eval/prior_ent_std 4.94 / eval/rep_loss_mean 3.51 / eval/rep_loss_std 5.16 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.3 / eval/reward_loss_std 0.38 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.7 / eval/reward_rate 0.51 / 
replay/size 5.6e5 / replay/inserts 3750 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3750 / timer/env.step_total 19.44 / timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 9.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.78 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.25 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7758 / timer/agent.policy_total 17.37 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7e-3 / 
timer/dataset_train_count 1875 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1875 / timer/agent.train_total 241.65 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.36 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T094344F835011-5SoCMrG1ByyuipjLYP3GB2-411s5yLyMtp52DC0gU6SEk-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 311.1.
Starting evaluation at step 557500 Counter(557500) 557437
Saved chunk: 20230922T094421F009448-0GtnuFKJJjHSayxfFYK0kJ-1QJxLoqkFoHLRHCe95mnhf-1024.npz
eval_Episode has 500 steps and return 297.6.
train_Episode has 500 steps and return 298.1.
Starting evaluation at step 558000 Counter(558000) 557937
eval_Episode has 500 steps and return 316.2.
Saved chunk: 20230922T094505F883279-411s5yLyMtp52DC0gU6SEk-2UgI0SRe2MzRDwzzZyGCva-1024.npz
train_Episode has 500 steps and return 287.3.
Starting evaluation at step 558500 Counter(558500) 558437
Saved chunk: 20230922T094541F460366-1QJxLoqkFoHLRHCe95mnhf-0EwNSaKVyG0yg6khML2GI5-1024.npz
eval_Episode has 500 steps and return 324.7.
train_Episode has 500 steps and return 306.3.
Starting evaluation at step 559000 Counter(559000) 558937
eval_Episode has 500 steps and return 344.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Saved chunk: 20230922T094700F952122-0EwNSaKVyG0yg6khML2GI5-0000000000000000000000-589.npz
Saved chunk: 20230922T094627F697762-2UgI0SRe2MzRDwzzZyGCva-0000000000000000000000-1020.npz
Saved chunk: 20230922T094627F697762-2UgI0SRe2MzRDwzzZyGCva-5eWCmJu7n7tMnaU9Vsu9ZV-1024.npz
train_Episode has 500 steps and return 291.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/5/checkpoint.ckpt
Starting evaluation at step 559500 Counter(559500) 559437
eval_Episode has 500 steps and return 317.3.
Saved chunk: 20230922T094700F952122-0EwNSaKVyG0yg6khML2GI5-5L3PRkHjSRMEGODnS61BeZ-1024.npz
train_Episode has 500 steps and return 314.8.
Starting evaluation at step 560000 Counter(560000) 559937
eval_Episode has 500 steps and return 320.7.
train_Episode has 500 steps and return 280.9.
Saved chunk: 20230922T094748F826910-5eWCmJu7n7tMnaU9Vsu9ZV-2ShOM0JZgbLFQIZOCPQEfE-1024.npz
Starting evaluation at step 560500 Counter(560500) 560437
eval_Episode has 500 steps and return 326.7.
Saved chunk: 20230922T094820F472831-5L3PRkHjSRMEGODnS61BeZ-4dYlKQiXM9soUAv9OQBwyg-1024.npz
train_Episode has 500 steps and return 313.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1121706 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 313.94 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 326.69 / eval_episode/reward_rate 0.47 / train/action_mag 4.05 / train/action_max 4.01 / train/action_mean 0.1 / train/action_min -3.42 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 5.81 / train/adv_mag 0.4 / train/adv_max 0.29 / train/adv_mean 1.7e-4 / train/adv_min 
-0.38 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.63 / train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.93 / train/extr_critic_max 238.93 / train/extr_critic_mean 230.26 / train/extr_critic_min 186.39 / train/extr_critic_std 9.39 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 239.09 / train/extr_return_raw_max 239.09 / train/extr_return_raw_mean 230.26 / train/extr_return_raw_min 
186.65 / train/extr_return_raw_std 9.41 / train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.51 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.83 / train/image_loss_std 0.86 / train/model_loss_mean 3.24 /
train/model_loss_std 4.13 / train/model_opt_grad_norm 7.83 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.9 / train/policy_entropy_max 
3.34 / train/policy_entropy_mean -2.54 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.17 / train/policy_logprob_mag 9.37 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.54 / train/policy_logprob_min -9.37 / train/policy_logprob_std 1.84 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.11 / train/post_ent_max 52.11 / train/post_ent_mean 41.85 / 
train/post_ent_min 23.27 / train/post_ent_std 4.2 / train/prior_ent_mag 76.67 / train/prior_ent_max 76.67 / train/prior_ent_mean 45.44 / train/prior_ent_min 31.41 / train/prior_ent_std 5.55 / train/rep_loss_mean 3.63 / train/rep_loss_std 5.77 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.5 / train/reward_rate 
0.39 / train_stats/mean_log_entropy -2.57 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.71 / report/dyn_loss_std 6.54 / report/image_loss_mean 0.93 / report/image_loss_std 1.03 / report/model_loss_mean 3.37 / report/model_loss_std 4.77 / report/post_ent_mag 54.42 / report/post_ent_max 54.42 /
report/post_ent_mean 41.58 / report/post_ent_min 19.47 / report/post_ent_std 4.34 / report/prior_ent_mag 76.53 / report/prior_ent_max 76.53 / report/prior_ent_mean 45.36 / report/prior_ent_min 30.93 / report/prior_ent_std 5.69 / report/rep_loss_mean 3.71 / 
report/rep_loss_std 6.54 / report/reward_avg 0.44 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.36 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.44 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.69 / eval/dyn_loss_std 7.26 / eval/image_loss_mean 1.33 / eval/image_loss_std 2.88 / eval/model_loss_mean 4.43 / eval/model_loss_std 6.73 / eval/post_ent_mag 51.82 / eval/post_ent_max 51.82 / eval/post_ent_mean 
41.09 / eval/post_ent_min 23.6 / eval/post_ent_std 4.19 / eval/prior_ent_mag 76.53 / eval/prior_ent_max 76.53 / eval/prior_ent_mean 45.21 / eval/prior_ent_min 35.44 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 4.69 / eval/rep_loss_std 7.26 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.63 / eval/reward_rate 0.46 
/ replay/size 5.6e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3800 / timer/env.step_total 19.88 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.21 / timer/replay._sample_count 3e4 / timer/replay._sample_total 464.37 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7307 / timer/agent.policy_total 16.59 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.57 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.36 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.33

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 561000 Counter(561000) 560937
eval_Episode has 500 steps and return 343.5.
train_Episode has 500 steps and return 265.9.
Saved chunk: 20230922T094909F614818-2ShOM0JZgbLFQIZOCPQEfE-0gOtpVTsQpqFqro0jUrphz-1024.npz
Starting evaluation at step 561500 Counter(561500) 561437
eval_Episode has 500 steps and return 328.5.
Saved chunk: 20230922T094939F520266-4dYlKQiXM9soUAv9OQBwyg-02Opo0WtNuAsNNsE97Hkkf-1024.npz
train_Episode has 500 steps and return 294.7.
Starting evaluation at step 562000 Counter(562000) 561937
eval_Episode has 500 steps and return 336.9.
train_Episode has 500 steps and return 316.5.
Saved chunk: 20230922T095031F674209-0gOtpVTsQpqFqro0jUrphz-1xsvi1KCmA7gVHqMSOU6iK-1024.npz
Starting evaluation at step 562500 Counter(562500) 562437
eval_Episode has 500 steps and return 339.5.
Saved chunk: 20230922T095100F220973-02Opo0WtNuAsNNsE97Hkkf-5gDR0vEh3E1veR7GaIVool-1024.npz
train_Episode has 500 steps and return 310.5.
Starting evaluation at step 563000 Counter(563000) 562937
eval_Episode has 500 steps and return 332.0.
train_Episode has 500 steps and return 307.3.
Saved chunk: 20230922T095152F789208-1xsvi1KCmA7gVHqMSOU6iK-3qwbQW6RlYFtxTA6RwlCZE-1024.npz
Starting evaluation at step 563500 Counter(563500) 563437
eval_Episode has 500 steps and return 347.2.
train_Episode has 500 steps and return 311.8.
Starting evaluation at step 564000 Counter(564000) 563937
Saved chunk: 20230922T095219F763334-5gDR0vEh3E1veR7GaIVool-4nWi2CID34uPIIqzRmq5Ys-1024.npz
eval_Episode has 500 steps and return 335.6.
train_Episode has 500 steps and return 305.5.
Saved chunk: 20230922T095313F785934-3qwbQW6RlYFtxTA6RwlCZE-0G6kJOfO05QAOZwlGpY5zw-1024.npz
Starting evaluation at step 564500 Counter(564500) 564437
eval_Episode has 500 steps and return 340.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1129198 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 340.43 / eval_episode/reward_rate 0.5 / episode/length 500 / episode/score 305.47 / episode/reward_rate 0.44 / train/action_mag 4.04 / train/action_max 3.99 / train/action_mean 0.1 / train/action_min -3.43 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 5.19 / train/adv_mag 0.49 / train/adv_max 0.41 / train/adv_mean 2.4e-4 / train/adv_min 
-0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 5.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 238.62 / train/extr_critic_max 238.62 / train/extr_critic_mean 229.87 / train/extr_critic_min 182.69 / train/extr_critic_std 9.8 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 238.82 / train/extr_return_raw_max 238.82 / train/extr_return_raw_mean 229.88 / train/extr_return_raw_min 
184.36 / train/extr_return_raw_std 9.83 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.5 / train/extr_reward_min 0 / train/extr_reward_std 0.69 / train/image_loss_mean 0.83 / train/image_loss_std 0.87 / train/model_loss_mean 3.24 / 
train/model_loss_std 4.09 / train/model_opt_grad_norm 7.8 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.16 / train/policy_entropy_max 
3.62 / train/policy_entropy_mean -2.56 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.51 / train/policy_logprob_max 5.51 / train/policy_logprob_mean 2.56 / train/policy_logprob_min -9.51 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.8e-5 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.11 / train/post_ent_max 52.11 / train/post_ent_mean 41.81 / 
train/post_ent_min 23.45 / train/post_ent_std 4.21 / train/prior_ent_mag 76.59 / train/prior_ent_max 76.59 / train/prior_ent_mean 45.4 / train/prior_ent_min 31.37 / train/prior_ent_std 5.55 / train/rep_loss_mean 3.62 / train/rep_loss_std 5.71 / train/reward_avg 0.49 / 
train/reward_loss_mean 0.23 / train/reward_loss_std 0.33 / train/reward_max_data 1.99 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.49 / train/reward_rate 
0.39 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.64 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.21 / report/image_loss_mean 0.85 / report/image_loss_std 0.88 / report/model_loss_mean 3.31 / report/model_loss_std 4.47 / report/post_ent_mag 52.77 / report/post_ent_max 52.77 /
report/post_ent_mean 42.97 / report/post_ent_min 25.23 / report/post_ent_std 4.08 / report/prior_ent_mag 76.54 / report/prior_ent_max 76.54 / report/prior_ent_mean 46.61 / report/prior_ent_min 33.81 / report/prior_ent_std 5.07 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.21 / report/reward_avg 0.44 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.44 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 7.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.85 / eval/dyn_loss_std 5.81 / eval/image_loss_mean 0.84 / eval/image_loss_std 1.18 / eval/model_loss_mean 3.43 / eval/model_loss_std 4.37 / eval/post_ent_mag 50.82 / eval/post_ent_max 50.82 / eval/post_ent_mean 
41.39 / eval/post_ent_min 23.93 / eval/post_ent_std 3.91 / eval/prior_ent_mag 76.54 / eval/prior_ent_max 76.54 / eval/prior_ent_mean 45.04 / eval/prior_ent_min 35.22 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 3.85 / eval/rep_loss_std 5.81 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 5.6e5 / replay/inserts 3746 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3746 / timer/env.step_total 19.39 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.49 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7754 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1873 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1873 / timer/agent.train_total 241.81 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.53 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 24.96
