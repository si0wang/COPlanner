Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {}
JAX devices (1): [gpu(id=0)]
Policy devices: gpu:0
Train devices:  gpu:0
Tracing train function.
Optimizer model_opt has 15,686,787 variables.
{'action': Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>, 'deter': Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>, 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>, 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>}
{'action': Traced<ShapedArray(float32[15,1024,4])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,4])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,4]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f058c428a10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f058c4fa810; dead>, <weakref at 0x7f058c4fa6d0; dead>, <weakref at 0x7f058c4fa630; dead>, <weakref at 0x7f058c4fa3b0; dead>, <weakref at 0x7f058c4fac70; to 'JaxprTracer' at 0x7f058c4faef0>, <weakref at 0x7f058c4fa4a0; to 'JaxprTracer' at 0x7f058c4fa7c0>, <weakref at 0x7f058c4fa720; to 'JaxprTracer' at 0x7f058c4fac20>, <weakref at 0x7f058c4fae50; to 'JaxprTracer' at 0x7f058c4fa400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f058c375070>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f058c428a10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f058c4fa810; dead>, <weakref at 0x7f058c4fa6d0; dead>, <weakref at 0x7f058c4fa630; dead>, <weakref at 0x7f058c4fa3b0; dead>, <weakref at 0x7f058c4fac70; to 'JaxprTracer' at 0x7f058c4faef0>, <weakref at 0x7f058c4fa4a0; to 'JaxprTracer' at 0x7f058c4fa7c0>, <weakref at 0x7f058c4fa720; to 'JaxprTracer' at 0x7f058c4fac20>, <weakref at 0x7f058c4fae50; to 'JaxprTracer' at 0x7f058c4fa400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f058c375070>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f058c428a10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f058c4fa810; dead>, <weakref at 0x7f058c4fa6d0; dead>, <weakref at 0x7f058c4fa630; dead>, <weakref at 0x7f058c4fa3b0; dead>, <weakref at 0x7f058c4fac70; to 'JaxprTracer' at 0x7f058c4faef0>, <weakref at 0x7f058c4fa4a0; to 'JaxprTracer' at 0x7f058c4fa7c0>, <weakref at 0x7f058c4fa720; to 'JaxprTracer' at 0x7f058c4fac20>, <weakref at 0x7f058c4fae50; to 'JaxprTracer' at 0x7f058c4fa400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f058c375070>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f058c428a10>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f058c4fa810; dead>, <weakref at 0x7f058c4fa6d0; dead>, <weakref at 0x7f058c4fa630; dead>, <weakref at 0x7f058c4fa3b0; dead>, <weakref at 0x7f058c4fac70; to 'JaxprTracer' at 0x7f058c4faef0>, <weakref at 0x7f058c4fa4a0; to 'JaxprTracer' at 0x7f058c4fa7c0>, <weakref at 0x7f058c4fa720; to 'JaxprTracer' at 0x7f058c4fac20>, <weakref at 0x7f058c4fae50; to 'JaxprTracer' at 0x7f058c4fa400>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f058c375070>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Optimizer actor_opt has 1,054,728 variables.
Optimizer critic_opt has 1,181,439 variables.
Logdir /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp
Observation space:
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  position         Space(dtype=float64, shape=(6,), low=-inf, high=inf)
  velocity         Space(dtype=float64, shape=(7,), low=-inf, high=inf)
  touch            Space(dtype=float64, shape=(2,), low=-inf, high=inf)
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
Action space:
  reset            Space(dtype=bool, shape=(), low=False, high=True)
  action           Space(dtype=float32, shape=(4,), low=-1.0, high=1.0)
Prefill train dataset.
train_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212753F460041-25jWTFv4qub3cWYUxdoUm8-5ohlBp0ytv8yDuCQg6tuOq-1024.npz
Prefill eval dataset.
eval_Episode has 500 steps and return 0.0.
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212757F883929-6qEAvUpAcAB5YVtzy4COOY-7xIDvhpsXypzSBB3blKz46-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2200 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0
warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'


Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100 Counter(1100) 1037
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T212757F261342-5ohlBp0ytv8yDuCQg6tuOq-0000000000000000000000-76.npz
Saved chunk: 20230921T212801F608013-7xIDvhpsXypzSBB3blKz46-0000000000000000000000-76.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Tracing policy function.
Tracing policy function.
eval_Episode has 500 steps and return 0.0.
Tracing policy function.
Tracing train function.
{'action': Traced<ShapedArray(float32[15,1024,4])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,4])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,4])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,4]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f05ac7f0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f056f03a270; dead>, <weakref at 0x7f056f03a860; dead>, <weakref at 0x7f056f03a360; dead>, <weakref at 0x7f056f03a450; dead>, <weakref at 0x7f056f03ac70; to 'JaxprTracer' at 0x7f056f11ef90>, <weakref at 0x7f056f03a900; to 'JaxprTracer' at 0x7f056f11e310>, <weakref at 0x7f056f03a4f0; to 'JaxprTracer' at 0x7f056f11edb0>, <weakref at 0x7f056f03a3b0; to 'JaxprTracer' at 0x7f056f03a720>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f031c494870>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f05ac7f0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f056f03a270; dead>, <weakref at 0x7f056f03a860; dead>, <weakref at 0x7f056f03a360; dead>, <weakref at 0x7f056f03a450; dead>, <weakref at 0x7f056f03ac70; to 'JaxprTracer' at 0x7f056f11ef90>, <weakref at 0x7f056f03a900; to 'JaxprTracer' at 0x7f056f11e310>, <weakref at 0x7f056f03a4f0; to 'JaxprTracer' at 0x7f056f11edb0>, <weakref at 0x7f056f03a3b0; to 'JaxprTracer' at 0x7f056f03a720>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f031c494870>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f05ac7f0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f056f03a270; dead>, <weakref at 0x7f056f03a860; dead>, <weakref at 0x7f056f03a360; dead>, <weakref at 0x7f056f03a450; dead>, <weakref at 0x7f056f03ac70; to 'JaxprTracer' at 0x7f056f11ef90>, <weakref at 0x7f056f03a900; to 'JaxprTracer' at 0x7f056f11e310>, <weakref at 0x7f056f03a4f0; to 'JaxprTracer' at 0x7f056f11edb0>, <weakref at 0x7f056f03a3b0; to 'JaxprTracer' at 0x7f056f03a720>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f031c494870>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f05ac7f0680>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1028,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f056f03a270; dead>, <weakref at 0x7f056f03a860; dead>, <weakref at 0x7f056f03a360; dead>, <weakref at 0x7f056f03a450; dead>, <weakref at 0x7f056f03ac70; to 'JaxprTracer' at 0x7f056f11ef90>, <weakref at 0x7f056f03a900; to 'JaxprTracer' at 0x7f056f11e310>, <weakref at 0x7f056f03a4f0; to 'JaxprTracer' at 0x7f056f11edb0>, <weakref at 0x7f056f03a3b0; to 'JaxprTracer' at 0x7f056f03a720>], out_avals=[ShapedArray(float32[1024,4]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,4]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,4] e:f16[512,4] f:f16[1028,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,4] u:f32[4] v:f32[512,4] w:f32[4] x:f32[1024,4] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,4] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,4]
    by:f32[1024,4] bz:f32[1024,4] ca:f16[1024,4] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,4] = add_any fu fw
    fy:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] fy
    ga:f16[1024,4] = add fx fz
    gb:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,4] = pjit[
      jaxpr={ lambda ; gd:f32[1024,4] ge:f32[1024,4]. let
          gf:f32[1024,4] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,4] = mul 0.8999999761581421 gc
    gh:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gg
    gi:f32[1,1024,4] = mul bb gh
    gj:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,4] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,4] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,4] = add_any gj gl
    gn:f16[4] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,4] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 4)] gn
    gp:f16[1024,4] = add gm go
    gq:f32[1024,4] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,4] = mul gq by
    gs:f32[1024,4] = add gq gr
    gt:f32[1024,4] = mul gs bz
    gu:f32[1,1024,4] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 4)
    ] gt
    gv:f32[1,1024,4] = add gi gu
    gw:f32[1024,4] = reshape[dimensions=None new_sizes=(1024, 4)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,4] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,4] = mul gy ca
    ha:f16[1024,1028] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f031c494870>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Tracing report function.
Tracing report function.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2202 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.47 / train/action_max 4.47 / train/action_mean -0.01 / train/action_min -3.97 / train/action_std 1.02 / train/actor_opt_actor_opt_grad_overflow 0 / 
train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.9e-4 / train/actor_opt_grad_steps 1 / train/actor_opt_loss -10.99 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 
0.3 / train/cont_loss_std 0.19 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 0.95 / train/cont_pos_loss 0.3 / train/cont_pred 0.75 / train/cont_rate 1 / train/dyn_loss_mean 6.81 / train/dyn_loss_std 0.31 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 11.31 / train/extr_critic_critic_opt_grad_steps 1 / train/extr_critic_critic_opt_loss 8.1e4 / train/extr_critic_mag 0 
/ train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 0 / train/extr_return_normed_max -inf / train/extr_return_normed_mean 0 / train/extr_return_normed_min 0 / 
train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / 
train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2869.87 / train/image_loss_std 33.88 / train/model_loss_mean 2879.8 / train/model_loss_std 33.89 / train/model_opt_grad_norm nan / train/model_opt_grad_steps 0 / 
train/model_opt_loss 2.9e7 / train/model_opt_model_opt_grad_overflow 1 / train/model_opt_model_opt_grad_scale 5000 / train/policy_entropy_mag 5.54 / train/policy_entropy_max 5.54 / train/policy_entropy_mean 5.03 / train/policy_entropy_min 3.73 / train/policy_entropy_std 
0.21 / train/policy_logprob_mag 14.12 / train/policy_logprob_max -2.31 / train/policy_logprob_mean -5.04 / train/policy_logprob_min -14.12 / train/policy_logprob_std 1.46 / train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 
0.93 / train/policy_randomness_min 0.79 / train/policy_randomness_std 0.02 / train/post_ent_mag 107.76 / train/post_ent_max 107.76 / train/post_ent_mean 107.48 / train/post_ent_min 107.17 / train/post_ent_std 0.09 / train/prior_ent_mag 108.12 / train/prior_ent_max 108.12 
/ train/prior_ent_mean 107.52 / train/prior_ent_min 106.8 / train/prior_ent_std 0.23 / train/rep_loss_mean 6.81 / train/rep_loss_std 0.31 / train/reward_avg 3.6e-4 / train/reward_loss_mean 5.54 / train/reward_loss_std 9.5e-7 / train/reward_max_data 0.08 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 5.54 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train/params_agent/wm/model_opt 1.6e7 / train/params_agent/task_behavior/critic/critic_opt 
1.2e6 / train/params_agent/task_behavior/ac/actor_opt 1.1e6 / report/cont_avg 1 / report/cont_loss_mean 0.34 / report/cont_loss_std 0.22 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 0.92 / report/cont_pos_loss 0.34 / report/cont_pred 0.73 / 
report/cont_rate 1 / report/dyn_loss_mean 6.77 / report/dyn_loss_std 0.3 / report/image_loss_mean 2867.96 / report/image_loss_std 32.58 / report/model_loss_mean 2877.91 / report/model_loss_std 32.59 / report/post_ent_mag 107.76 / report/post_ent_max 107.76 / 
report/post_ent_mean 107.49 / report/post_ent_min 107.24 / report/post_ent_std 0.09 / report/prior_ent_mag 108.14 / report/prior_ent_max 108.14 / report/prior_ent_mean 107.51 / report/prior_ent_min 106.62 / report/prior_ent_std 0.24 / report/rep_loss_mean 6.77 / 
report/rep_loss_std 0.3 / report/reward_avg 3.6e-4 / report/reward_loss_mean 5.54 / report/reward_loss_std 9.5e-7 / report/reward_max_data 0.08 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 5.54 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 0.32 / eval/cont_loss_std 0.2 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 0.94 / eval/cont_pos_loss 0.32 / eval/cont_pred 0.74 / 
eval/cont_rate 1 / eval/dyn_loss_mean 6.83 / eval/dyn_loss_std 0.31 / eval/image_loss_mean 2869.4 / eval/image_loss_std 35.67 / eval/model_loss_mean 2879.36 / eval/model_loss_std 35.67 / eval/post_ent_mag 107.69 / eval/post_ent_max 107.69 / eval/post_ent_mean 107.47 / 
eval/post_ent_min 107.19 / eval/post_ent_std 0.08 / eval/prior_ent_mag 108.21 / eval/prior_ent_max 108.21 / eval/prior_ent_mean 107.51 / eval/prior_ent_min 106.67 / eval/prior_ent_std 0.24 / eval/rep_loss_mean 6.83 / eval/rep_loss_std 0.31 / eval/reward_avg 2.4e-8 / 
eval/reward_loss_mean 5.54 / eval/reward_loss_std 9.5e-7 / eval/reward_max_data 2.4e-5 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.54 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size
1038 / replay/inserts 1038 / replay/samples 112 / replay/insert_wait_avg 2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.5e-6 / replay/sample_wait_frac 1 / eval_replay/size 1538 / eval_replay/inserts 1538 / eval_replay/samples 112 / eval_replay/insert_wait_avg
2.2e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 103.27 / timer/env.step_count 1101 / timer/env.step_total 4.23 / timer/env.step_frac 0.04 / timer/env.step_avg 3.8e-3 / timer/env.step_min 3.3e-3
/ timer/env.step_max 0.39 / timer/replay._sample_count 112 / timer/replay._sample_total 32.06 / timer/replay._sample_frac 0.31 / timer/replay._sample_avg 0.29 / timer/replay._sample_min 8.8e-4 / timer/replay._sample_max 1.96 / timer/agent.save_count 1 / 
timer/agent.save_total 0.27 / timer/agent.save_frac 2.6e-3 / timer/agent.save_avg 0.27 / timer/agent.save_min 0.27 / timer/agent.save_max 0.27 / timer/agent.policy_count 502 / timer/agent.policy_total 23.59 / timer/agent.policy_frac 0.23 / timer/agent.policy_avg 0.05 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 21.44 / timer/dataset_train_count 1 / timer/dataset_train_total 2.2e-5 / timer/dataset_train_frac 2.1e-7 / timer/dataset_train_avg 2.2e-5 / timer/dataset_train_min 2.2e-5 / timer/dataset_train_max 2.2e-5 / 
timer/agent.train_count 1 / timer/agent.train_total 59.13 / timer/agent.train_frac 0.57 / timer/agent.train_avg 59.13 / timer/agent.train_min 59.13 / timer/agent.train_max 59.13 / timer/agent.report_count 2 / timer/agent.report_total 9.13 / timer/agent.report_frac 0.09 / 
timer/agent.report_avg 4.56 / timer/agent.report_min 0.07 / timer/agent.report_max 9.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 3e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 
3.1e-5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 1500 Counter(1500) 1437
Saved chunk: 20230921T212801F608013-7xIDvhpsXypzSBB3blKz46-6N2ActO9BC4zdAckB8E9Gl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.2.
Starting evaluation at step 2000 Counter(2000) 1937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T212757F261342-5ohlBp0ytv8yDuCQg6tuOq-0nVcF6yUW1WsNxvQhkKqYM-1024.npz
Starting evaluation at step 2500 Counter(2500) 2437
Saved chunk: 20230921T213007F823402-6N2ActO9BC4zdAckB8E9Gl-4Z5pBgtdqHXMJJYxQEYbmB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 3000 Counter(3000) 2937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213050F638724-0nVcF6yUW1WsNxvQhkKqYM-6a1DZHBmeje8VR3M5pHg2b-1024.npz
Starting evaluation at step 3500 Counter(3500) 3437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213126F120851-4Z5pBgtdqHXMJJYxQEYbmB-4oJRiHvddmZez64qx0VOBc-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 4000 Counter(4000) 3937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213210F684932-6a1DZHBmeje8VR3M5pHg2b-67Y9dcGTh0j3rvjhkDD0mB-1024.npz
Starting evaluation at step 4500 Counter(4500) 4437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.4.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 9666 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0.43 / episode/reward_rate 4e-3 / train/action_mag 4.98 / train/action_max 4.62 / train/action_mean -0.06 / train/action_min -4.82 / train/action_std 1.16 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.9e-4 / train/actor_opt_grad_steps 935 / train/actor_opt_loss -20.3 / train/adv_mag 0.02 / train/adv_max 0.02 / train/adv_mean 3.8e-4 / train/adv_min 1.3e-5 /
train/adv_std 6.7e-4 / train/cont_avg 1 / train/cont_loss_mean 1.7e-3 / train/cont_loss_std 1.1e-3 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-3 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.08 / 
train/dyn_loss_std 2.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.54 / train/extr_critic_critic_opt_grad_steps 935 / train/extr_critic_critic_opt_loss 1.2e4
/ train/extr_critic_mag 1.9e-3 / train/extr_critic_max 1.9e-3 / train/extr_critic_mean 1.8e-3 / train/extr_critic_min 1.8e-3 / train/extr_critic_std 1.1e-5 / train/extr_return_normed_mag 0.02 / train/extr_return_normed_max 0.02 / train/extr_return_normed_mean 6e-4 / 
train/extr_return_normed_min 2.5e-4 / train/extr_return_normed_std 6.8e-4 / train/extr_return_rate 3.5e-7 / train/extr_return_raw_mag 0.02 / train/extr_return_raw_max 0.02 / train/extr_return_raw_mean 2.2e-3 / train/extr_return_raw_min 1.9e-3 / train/extr_return_raw_std 
6.8e-4 / train/extr_reward_mag 8.4e-3 / train/extr_reward_max 8.4e-3 / train/extr_reward_mean 6.4e-5 / train/extr_reward_min 5e-5 / train/extr_reward_std 1.4e-4 / train/image_loss_mean 41.76 / train/image_loss_std 6.54 / train/model_loss_mean 43.8 / train/model_loss_std 
7.2 / train/model_opt_grad_norm 117.37 / train/model_opt_grad_steps 926 / train/model_opt_loss 956.43 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 28.56 / train/policy_entropy_mag 5.66 / train/policy_entropy_max 5.66 / 
train/policy_entropy_mean 5.64 / train/policy_entropy_min 5.48 / train/policy_entropy_std 0.01 / train/policy_logprob_mag 16.53 / train/policy_logprob_max -3.61 / train/policy_logprob_mean -5.64 / train/policy_logprob_min -16.53 / train/policy_logprob_std 1.41 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 1.5e-3 / train/post_ent_mag 55.46 / train/post_ent_max 55.46 / train/post_ent_mean 45.02 / train/post_ent_min 
39.14 / train/post_ent_std 2.9 / train/prior_ent_mag 62.25 / train/prior_ent_max 62.25 / train/prior_ent_mean 49.44 / train/prior_ent_min 44.5 / train/prior_ent_std 3.22 / train/rep_loss_mean 3.08 / train/rep_loss_std 2.34 / train/reward_avg 1.1e-4 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.06 / train/reward_max_data 0.04 / train/reward_max_pred 4e-3 / train/reward_neg_acc 1 / train/reward_neg_loss 0.19 / train/reward_pos_acc 0.19 / train/reward_pos_loss 3.68 / train/reward_pred 6.7e-5 / train/reward_rate
8.4e-5 / train_stats/mean_log_entropy 5.63 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-6 / report/cont_loss_std 2.5e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-6 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.86 / report/dyn_loss_std 3.61 / report/image_loss_mean 7.59 / report/image_loss_std 4.58 / report/model_loss_mean 9.9 / report/model_loss_std 5.73 / report/post_ent_mag 33.63 / report/post_ent_max 33.63 / 
report/post_ent_mean 22.56 / report/post_ent_min 16.69 / report/post_ent_std 2.91 / report/prior_ent_mag 47.02 / report/prior_ent_max 47.02 / report/prior_ent_mean 27.2 / report/prior_ent_min 19.58 / report/prior_ent_std 4.57 / report/rep_loss_mean 3.86 / 
report/rep_loss_std 3.61 / report/reward_avg 1.8e-4 / report/reward_loss_mean 3.7e-3 / report/reward_loss_std 0.04 / report/reward_max_data 0.08 / report/reward_max_pred 0.06 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 1.6e-4 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-6 / eval/cont_loss_std 2.3e-6 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-6 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 7.89 / eval/dyn_loss_std 4.23 / eval/image_loss_mean 16.49 / eval/image_loss_std 8.3 / eval/model_loss_mean 21.22 / eval/model_loss_std 9.74 / eval/post_ent_mag 46.2 / eval/post_ent_max 46.2 / eval/post_ent_mean 28.04 / 
eval/post_ent_min 17.86 / eval/post_ent_std 4.92 / eval/prior_ent_mag 47.02 / eval/prior_ent_max 47.02 / eval/prior_ent_mean 31.38 / eval/prior_ent_min 23.22 / eval/prior_ent_std 3.81 / eval/rep_loss_mean 7.89 / eval/rep_loss_std 4.23 / eval/reward_avg 2.4e-8 / 
eval/reward_loss_mean 2.5e-3 / eval/reward_loss_std 0.02 / eval/reward_max_data 2.4e-5 / eval/reward_max_pred 0.06 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.4e-4 / eval/reward_rate 0 / 
replay/size 4770 / replay/inserts 3732 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5045 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 291.1 / timer/env.step_count 3732 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 420.55 / timer/replay._sample_frac 1.44 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-3 / timer/replay._sample_max 0.08 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7239 / timer/agent.policy_total 15.91 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1866 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.5e-5 / timer/dataset_train_max 2.8e-3 / timer/agent.train_count 1866 / timer/agent.train_total 236.66 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.64

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 5000 Counter(5000) 4937
Saved chunk: 20230921T213244F665501-4oJRiHvddmZez64qx0VOBc-0Uj3cJTNreEw69QY6sOPyf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213330F914220-67Y9dcGTh0j3rvjhkDD0mB-3IVLrWquYt6tMn2nkyDbjD-1024.npz
Starting evaluation at step 5500 Counter(5500) 5437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 6000 Counter(6000) 5937
Saved chunk: 20230921T213439F739352-0Uj3cJTNreEw69QY6sOPyf-4ivw3DvO4tVsVJuExQhjhu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213451F851139-3IVLrWquYt6tMn2nkyDbjD-7q3ZrAhzeVYTRkPD447mP9-1024.npz
Starting evaluation at step 6500 Counter(6500) 6437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 7000 Counter(7000) 6937
Saved chunk: 20230921T213558F903560-4ivw3DvO4tVsVJuExQhjhu-3mKFGREiNVYRhzK9ulRuUa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213612F475070-7q3ZrAhzeVYTRkPD447mP9-35gIpNMFKv9mb15p4FLWQK-1024.npz
Starting evaluation at step 7500 Counter(7500) 7437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 8000 Counter(8000) 7937
Saved chunk: 20230921T213717F732219-3mKFGREiNVYRhzK9ulRuUa-1OnGMb1fwVcDUBlKIlmtAg-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213732F812754-35gIpNMFKv9mb15p4FLWQK-4lLBnllS5f01kagDB5ErJk-1024.npz
Starting evaluation at step 8500 Counter(8500) 8437
eval_Episode has 500 steps and return 4.5.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 17242 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 4.54 / eval_episode/reward_rate 1e-2 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.17 / train/action_max 5.07 / train/action_mean 0.16 / train/action_min -4.91 / train/action_std 1.3 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.7e-3 / train/actor_opt_grad_steps 2815 / train/actor_opt_loss -21.67 / train/adv_mag 0.2 / train/adv_max 0.19 / train/adv_mean 6.2e-4 / train/adv_min -0.01 /
train/adv_std 6.1e-3 / train/cont_avg 1 / train/cont_loss_mean 1.2e-6 / train/cont_loss_std 7.3e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-6 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.31 / 
train/dyn_loss_std 3.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 2815 / train/extr_critic_critic_opt_loss 
5883.34 / train/extr_critic_mag 0.03 / train/extr_critic_max 0.03 / train/extr_critic_mean 0.01 / train/extr_critic_min 0.01 / train/extr_critic_std 1.2e-3 / train/extr_return_normed_mag 0.21 / train/extr_return_normed_max 0.21 / train/extr_return_normed_mean 2.4e-3 / 
train/extr_return_normed_min 3.6e-4 / train/extr_return_normed_std 6.4e-3 / train/extr_return_rate 6.5e-5 / train/extr_return_raw_mag 0.22 / train/extr_return_raw_max 0.22 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.01 / train/extr_return_raw_std 
6.4e-3 / train/extr_reward_mag 0.08 / train/extr_reward_max 0.08 / train/extr_reward_mean 8.9e-5 / train/extr_reward_min 3.3e-6 / train/extr_reward_std 1.8e-3 / train/image_loss_mean 5.4 / train/image_loss_std 3.8 / train/model_loss_mean 7.39 / train/model_loss_std 5.11 /
train/model_opt_grad_norm 33.78 / train/model_opt_grad_steps 2806 / train/model_opt_loss 753.2 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 105.88 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.31 / train/policy_entropy_min 0.67 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 16.4 / train/policy_logprob_max 0.76 / train/policy_logprob_mean -5.31 / train/policy_logprob_min -16.4 / train/policy_logprob_std 1.66 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.96 / train/policy_randomness_min 0.46 / train/policy_randomness_std 0.08 / train/post_ent_mag 32.81 / train/post_ent_max 32.81 / train/post_ent_mean 20.17 / train/post_ent_min 
13.59 / train/post_ent_std 2.92 / train/prior_ent_mag 46.74 / train/prior_ent_max 46.74 / train/prior_ent_mean 24.18 / train/prior_ent_min 16.37 / train/prior_ent_std 4.66 / train/rep_loss_mean 3.31 / train/rep_loss_std 3.77 / train/reward_avg 1.1e-4 / 
train/reward_loss_mean 1.6e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.05 / train/reward_max_pred 0.04 / train/reward_neg_acc 1 / train/reward_neg_loss 1.4e-3 / train/reward_pos_acc 0.91 / train/reward_pos_loss 0.64 / train/reward_pred 1.1e-4 / 
train/reward_rate 3.9e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.51 / report/cont_avg 1 / report/cont_loss_mean 5.6e-7 / report/cont_loss_std 3e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
5.6e-7 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.08 / report/dyn_loss_std 3.98 / report/image_loss_mean 4.21 / report/image_loss_std 3.02 / report/model_loss_mean 6.06 / report/model_loss_std 4.62 / report/post_ent_mag 31.06 / report/post_ent_max 
31.06 / report/post_ent_mean 19.18 / report/post_ent_min 13.31 / report/post_ent_std 2.9 / report/prior_ent_mag 47.62 / report/prior_ent_max 47.62 / report/prior_ent_mean 22.86 / report/prior_ent_min 15.39 / report/prior_ent_std 4.73 / report/rep_loss_mean 3.08 / 
report/rep_loss_std 3.98 / report/reward_avg 0 / report/reward_loss_mean 2.8e-4 / report/reward_loss_std 1.3e-4 / report/reward_max_data 0 / report/reward_max_pred 3.6e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-4 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 3.3e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-7 / eval/cont_loss_std 3.3e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-7 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 10.37 / eval/dyn_loss_std 5.49 / eval/image_loss_mean 11.92 / eval/image_loss_std 5.33 / eval/model_loss_mean 18.14 / eval/model_loss_std 7.44 / eval/post_ent_mag 36.69 / eval/post_ent_max 36.69 / eval/post_ent_mean 24.76 / 
eval/post_ent_min 14.39 / eval/post_ent_std 4.25 / eval/prior_ent_mag 47.62 / eval/prior_ent_max 47.62 / eval/prior_ent_mean 29.38 / eval/prior_ent_min 19.08 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 10.37 / eval/rep_loss_std 5.49 / eval/reward_avg 0 / 
eval/reward_loss_mean 3e-4 / eval/reward_loss_std 3.7e-4 / eval/reward_max_data 0 / eval/reward_max_pred 1.1e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 5e-6 / eval/reward_rate 0 / 
replay/size 8558 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9053 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3788 / timer/env.step_total 19.91 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 435.34 / timer/replay._sample_frac 1.45 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.91 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1894 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 3.5e-4 / timer/agent.train_count 1894 / timer/agent.train_total 241.94 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 9000 Counter(9000) 8937
Saved chunk: 20230921T213836F398690-1OnGMb1fwVcDUBlKIlmtAg-0aga6nU9tpwQ83NSC40UKk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213853F069445-4lLBnllS5f01kagDB5ErJk-4G7jRinDnKBxyK6LFCWIhD-1024.npz
Starting evaluation at step 9500 Counter(9500) 9437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 10000 Counter(10000) 9937
Saved chunk: 20230921T213955F729163-0aga6nU9tpwQ83NSC40UKk-4KnHCWkmpd3J5vQELRqO0C-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214014F179499-4G7jRinDnKBxyK6LFCWIhD-4AL9tbppTVGaqi05MEtFYI-1024.npz
Starting evaluation at step 10500 Counter(10500) 10437
eval_Episode has 500 steps and return 2.2.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 11000 Counter(11000) 10937
Saved chunk: 20230921T214114F831585-4KnHCWkmpd3J5vQELRqO0C-5LXrg9LQTsFtYGbQXPD0HU-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214134F750102-4AL9tbppTVGaqi05MEtFYI-299EJFggJlifllKG5JGYgL-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T214255F169569-299EJFggJlifllKG5JGYgL-0000000000000000000000-136.npz
Saved chunk: 20230921T214233F722817-5LXrg9LQTsFtYGbQXPD0HU-0000000000000000000000-357.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 11500 Counter(11500) 11437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 12000 Counter(12000) 11937
Saved chunk: 20230921T214233F722817-5LXrg9LQTsFtYGbQXPD0HU-5rLXwgqYz1sdnuEhw3bwZo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214255F169569-299EJFggJlifllKG5JGYgL-52sJSuI5VMIiK37xeu89Ph-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 24898 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.21 / train/action_max 5.04 / train/action_mean -0.04 / train/action_min -5.06 / train/action_std 1.35 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.8e-4 / train/actor_opt_grad_steps 4720 / train/actor_opt_loss -14.79 / train/adv_mag 0.09 / train/adv_max 0.08 / train/adv_mean -1.8e-4 / train/adv_min -0.02
/ train/adv_std 2.3e-3 / train/cont_avg 1 / train/cont_loss_mean 2.8e-7 / train/cont_loss_std 1.6e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.94 /
train/dyn_loss_std 4.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 4720 / train/extr_critic_critic_opt_loss 
6934.19 / train/extr_critic_mag 0.04 / train/extr_critic_max 0.04 / train/extr_critic_mean 0.02 / train/extr_critic_min 0.02 / train/extr_critic_std 8.3e-4 / train/extr_return_normed_mag 0.1 / train/extr_return_normed_max 0.1 / train/extr_return_normed_mean 1.9e-4 / 
train/extr_return_normed_min -9.8e-4 / train/extr_return_normed_std 2.6e-3 / train/extr_return_rate 2.3e-5 / train/extr_return_raw_mag 0.12 / train/extr_return_raw_max 0.12 / train/extr_return_raw_mean 0.02 / train/extr_return_raw_min 0.02 / train/extr_return_raw_std 
2.6e-3 / train/extr_reward_mag 0.04 / train/extr_reward_max 0.04 / train/extr_reward_mean 3.1e-5 / train/extr_reward_min 5.6e-8 / train/extr_reward_std 8.7e-4 / train/image_loss_mean 3.44 / train/image_loss_std 3 / train/model_loss_mean 5.2 / train/model_loss_std 4.58 / 
train/model_opt_grad_norm 27.52 / train/model_opt_grad_steps 4711 / train/model_opt_loss 2013.11 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 400.03 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.64 / train/policy_entropy_min 1.78 / train/policy_entropy_std 0.15 / train/policy_logprob_mag 16.41 / train/policy_logprob_max -0.69 / train/policy_logprob_mean -5.64 / train/policy_logprob_min -16.41 / train/policy_logprob_std 1.43 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.58 / train/policy_randomness_std 0.02 / train/post_ent_mag 29.27 / train/post_ent_max 29.27 / train/post_ent_mean 18.97 / train/post_ent_min 
12.38 / train/post_ent_std 2.52 / train/prior_ent_mag 48.23 / train/prior_ent_max 48.23 / train/prior_ent_mean 22.38 / train/prior_ent_min 14.69 / train/prior_ent_std 4.58 / train/rep_loss_mean 2.94 / train/rep_loss_std 4.13 / train/reward_avg 7.7e-5 / 
train/reward_loss_mean 8e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.03 / train/reward_max_pred 0.03 / train/reward_neg_acc 1 / train/reward_neg_loss 7e-4 / train/reward_pos_acc 1 / train/reward_pos_loss 0.4 / train/reward_pred 7.4e-5 / train/reward_rate 
2.4e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.63 / report/cont_avg 1 / report/cont_loss_mean 1.5e-7 / report/cont_loss_std 6.9e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-7 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.68 / report/dyn_loss_std 4.22 / report/image_loss_mean 2.61 / report/image_loss_std 1.98 / report/model_loss_mean 4.22 / report/model_loss_std 3.86 / report/post_ent_mag 28.56 / report/post_ent_max 28.56 / 
report/post_ent_mean 18.33 / report/post_ent_min 12.31 / report/post_ent_std 2.48 / report/prior_ent_mag 49.17 / report/prior_ent_max 49.17 / report/prior_ent_mean 21.57 / report/prior_ent_min 14.44 / report/prior_ent_std 4.52 / report/rep_loss_mean 2.68 / 
report/rep_loss_std 4.22 / report/reward_avg 0 / report/reward_loss_mean 8.4e-5 / report/reward_loss_std 1.4e-5 / report/reward_max_data 0 / report/reward_max_pred 3.4e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 8.4e-5 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 6.8e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2e-7 / eval/cont_loss_std 1.1e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-7 / eval/cont_pred 1 / 
eval/cont_rate 1 / eval/dyn_loss_mean 11.53 / eval/dyn_loss_std 6.83 / eval/image_loss_mean 11.1 / eval/image_loss_std 5.55 / eval/model_loss_mean 18.02 / eval/model_loss_std 8.46 / eval/post_ent_mag 35.68 / eval/post_ent_max 35.68 / eval/post_ent_mean 23.39 / 
eval/post_ent_min 12.84 / eval/post_ent_std 3.83 / eval/prior_ent_mag 49.17 / eval/prior_ent_max 49.17 / eval/prior_ent_mean 28.1 / eval/prior_ent_min 18.39 / eval/prior_ent_std 5.06 / eval/rep_loss_mean 11.53 / eval/rep_loss_std 6.83 / eval/reward_avg 2.4e-8 / 
eval/reward_loss_mean 1.3e-3 / eval/reward_loss_std 0.02 / eval/reward_max_data 2.4e-5 / eval/reward_max_pred 0.06 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.6e-4 / eval/reward_rate 0 / 
replay/size 1.2e4 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3828 / timer/env.step_total 20.21 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 439.18 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7335 / timer/agent.policy_total 16.31 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.66 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 12500 Counter(12500) 12437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 13000 Counter(13000) 12937
Saved chunk: 20230921T214352F801092-5rLXwgqYz1sdnuEhw3bwZo-4XnL9Bk1z5wev6KJHzCL07-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214415F796780-52sJSuI5VMIiK37xeu89Ph-2GHGXOAz9GZG0t7RsAy3dA-1024.npz
Starting evaluation at step 13500 Counter(13500) 13437
eval_Episode has 500 steps and return 3.4.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 14000 Counter(14000) 13937
Saved chunk: 20230921T214512F468696-4XnL9Bk1z5wev6KJHzCL07-616XJFbczdvQSSUmxPo0B6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214537F171766-2GHGXOAz9GZG0t7RsAy3dA-77iyUxO5uMvsqKDaVeSwYc-1024.npz
Starting evaluation at step 14500 Counter(14500) 14437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 15000 Counter(15000) 14937
Saved chunk: 20230921T214631F613407-616XJFbczdvQSSUmxPo0B6-1v73y2IPQ6GwKTdveituCE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214657F797845-77iyUxO5uMvsqKDaVeSwYc-4fGaw1CMsfbn5LAEjy1ItX-1024.npz
Starting evaluation at step 15500 Counter(15500) 15437
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 16000 Counter(16000) 15937
Saved chunk: 20230921T214750F359821-1v73y2IPQ6GwKTdveituCE-0OL0M9VciBp7s43PAGoA4K-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 32462 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.17 / train/action_max 4.99 / train/action_mean 0.02 / train/action_min -5.04 / train/action_std 1.31 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.2e-4 / train/actor_opt_grad_steps 6620 / train/actor_opt_loss -15.76 / train/adv_mag 0.06 / train/adv_max 0.05 / train/adv_mean -8.7e-5 / train/adv_min -0.02
/ train/adv_std 1.5e-3 / train/cont_avg 1 / train/cont_loss_mean 7.5e-8 / train/cont_loss_std 4.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.5e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.76 /
train/dyn_loss_std 4.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 6620 / train/extr_critic_critic_opt_loss 
4976.65 / train/extr_critic_mag 0.05 / train/extr_critic_max 0.05 / train/extr_critic_mean 0.01 / train/extr_critic_min 0.01 / train/extr_critic_std 1.1e-3 / train/extr_return_normed_mag 0.07 / train/extr_return_normed_max 0.07 / train/extr_return_normed_mean 2.3e-4 / 
train/extr_return_normed_min -6e-4 / train/extr_return_normed_std 2e-3 / train/extr_return_rate 1.4e-5 / train/extr_return_raw_mag 0.08 / train/extr_return_raw_max 0.08 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 0.01 / train/extr_return_raw_std 2e-3 / 
train/extr_reward_mag 0.03 / train/extr_reward_max 0.03 / train/extr_reward_mean 2.2e-5 / train/extr_reward_min -9.8e-8 / train/extr_reward_std 6.6e-4 / train/image_loss_mean 2.59 / train/image_loss_std 2.6 / train/model_loss_mean 4.25 / train/model_loss_std 4.35 / 
train/model_opt_grad_norm 20.02 / train/model_opt_grad_steps 6611 / train/model_opt_loss 6336.09 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1501.32 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.66 / train/policy_entropy_min 2.35 / train/policy_entropy_std 0.12 / train/policy_logprob_mag 16.58 / train/policy_logprob_max -1.21 / train/policy_logprob_mean -5.66 / train/policy_logprob_min -16.58 / train/policy_logprob_std 1.42 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.64 / train/policy_randomness_std 0.01 / train/post_ent_mag 29.16 / train/post_ent_max 29.16 / train/post_ent_mean 19.36 / train/post_ent_min 
12.49 / train/post_ent_std 2.61 / train/prior_ent_mag 49.56 / train/prior_ent_max 49.56 / train/prior_ent_mean 22.48 / train/prior_ent_min 14.93 / train/prior_ent_std 4.69 / train/rep_loss_mean 2.76 / train/rep_loss_std 4.29 / train/reward_avg 5.6e-5 / 
train/reward_loss_mean 5.9e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.03 / train/reward_max_pred 0.03 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-4 / train/reward_pos_acc 1 / train/reward_pos_loss 0.36 / train/reward_pred 5.6e-5 / 
train/reward_rate 1.6e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.63 / report/cont_avg 1 / report/cont_loss_mean 3.2e-8 / report/cont_loss_std 1.6e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.2e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.46 / report/dyn_loss_std 3.85 / report/image_loss_mean 2.05 / report/image_loss_std 1.6 / report/model_loss_mean 3.52 / report/model_loss_std 3.22 / report/post_ent_mag 26.62 / 
report/post_ent_max 26.62 / report/post_ent_mean 19.4 / report/post_ent_min 13.01 / report/post_ent_std 2.54 / report/prior_ent_mag 50.53 / report/prior_ent_max 50.53 / report/prior_ent_mean 22.43 / report/prior_ent_min 15.65 / report/prior_ent_std 4.56 / 
report/rep_loss_mean 2.46 / report/rep_loss_std 3.85 / report/reward_avg 0 / report/reward_loss_mean 2.9e-5 / report/reward_loss_std 1.9e-6 / report/reward_max_data 0 / report/reward_max_pred 1.8e-6 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-5 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.9e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-8 / eval/cont_loss_std 2e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
4.1e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 11.95 / eval/dyn_loss_std 7.2 / eval/image_loss_mean 9.63 / eval/image_loss_std 5.35 / eval/model_loss_mean 16.81 / eval/model_loss_std 8.59 / eval/post_ent_mag 35.77 / eval/post_ent_max 35.77 / 
eval/post_ent_mean 22.27 / eval/post_ent_min 11.69 / eval/post_ent_std 4.12 / eval/prior_ent_mag 50.53 / eval/prior_ent_max 50.53 / eval/prior_ent_mean 27.13 / eval/prior_ent_min 16.67 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 11.95 / eval/rep_loss_std 7.2 / 
eval/reward_avg 2.4e-8 / eval/reward_loss_mean 8.7e-4 / eval/reward_loss_std 0.01 / eval/reward_max_data 2.4e-5 / eval/reward_max_pred 0.05 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.7e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.2e-4
/ eval/reward_rate 0 / replay/size 1.6e4 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.7e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3782 / timer/env.step_total 20.02 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 429.38 / timer/replay._sample_frac 1.43 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / 
timer/replay._sample_max 0.09 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.01 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1891 / 
timer/agent.train_total 241.6 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T214818F019761-4fGaw1CMsfbn5LAEjy1ItX-4P9z4zW9hn16JDViON5R2U-1024.npz
Starting evaluation at step 16500 Counter(16500) 16437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 17000 Counter(17000) 16937
Saved chunk: 20230921T214909F110554-0OL0M9VciBp7s43PAGoA4K-5L958JVW1SX5sIr8BpohOh-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 2.5.
Saved chunk: 20230921T214938F941490-4P9z4zW9hn16JDViON5R2U-5csiiUObO7u3zNbIF1kFmq-1024.npz
Starting evaluation at step 17500 Counter(17500) 17437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 18000 Counter(18000) 17937
Saved chunk: 20230921T215028F838081-5L958JVW1SX5sIr8BpohOh-4pPnbYmqBa0LYTPhxyCXGP-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215059F847607-5csiiUObO7u3zNbIF1kFmq-04yFQrDYEJiqnbTuDrUM1i-1024.npz
Starting evaluation at step 18500 Counter(18500) 18437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 19000 Counter(19000) 18937
Saved chunk: 20230921T215147F951291-4pPnbYmqBa0LYTPhxyCXGP-56F5YJ04347RId4dVKSMv0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215220F346927-04yFQrDYEJiqnbTuDrUM1i-6v9nve9KRqwMWln1hulCRo-1024.npz
Starting evaluation at step 19500 Counter(19500) 19437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 20000 Counter(20000) 19937
Saved chunk: 20230921T215306F865572-56F5YJ04347RId4dVKSMv0-474A3VvGqCLhpKKnPqDSHH-1024.npz
eval_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 40022 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.15 / train/action_max 4.94 / train/action_mean -0.2 / train/action_min -5.03 / train/action_std 1.28 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3e-3 / train/actor_opt_grad_steps 8510 / train/actor_opt_loss -19.28 / train/adv_mag 0.29 / train/adv_max 0.27 / train/adv_mean 2.8e-4 / train/adv_min -0.05 / 
train/adv_std 7.3e-3 / train/cont_avg 1 / train/cont_loss_mean 2e-8 / train/cont_loss_std 1.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.92 / 
train/dyn_loss_std 4.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.01 / train/extr_critic_critic_opt_grad_steps 8510 / train/extr_critic_critic_opt_loss 
4690.01 / train/extr_critic_mag 0.1 / train/extr_critic_max 0.1 / train/extr_critic_mean 0.01 / train/extr_critic_min 8.5e-3 / train/extr_critic_std 2.7e-3 / train/extr_return_normed_mag 0.32 / train/extr_return_normed_max 0.32 / train/extr_return_normed_mean 1.2e-3 / 
train/extr_return_normed_min -4.8e-4 / train/extr_return_normed_std 8.8e-3 / train/extr_return_rate 2.3e-4 / train/extr_return_raw_mag 0.33 / train/extr_return_raw_max 0.33 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 8.9e-3 / train/extr_return_raw_std 
8.8e-3 / train/extr_reward_mag 0.16 / train/extr_reward_max 0.16 / train/extr_reward_mean 8.3e-5 / train/extr_reward_min 1.5e-6 / train/extr_reward_std 2.5e-3 / train/image_loss_mean 2.46 / train/image_loss_std 2.31 / train/model_loss_mean 4.21 / train/model_loss_std 4.23
/ train/model_opt_grad_norm 17.72 / train/model_opt_grad_steps 8500.77 / train/model_opt_loss 1.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4404.76 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.63 / train/policy_entropy_min 0.18 / train/policy_entropy_std 0.28 / train/policy_logprob_mag 16.4 / train/policy_logprob_max 1 / train/policy_logprob_mean -5.63 / train/policy_logprob_min -16.4 / train/policy_logprob_std 1.46 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.4 / train/policy_randomness_std 0.03 / train/post_ent_mag 29.66 / train/post_ent_max 29.66 / train/post_ent_mean 20.55 / train/post_ent_min 12.77
/ train/post_ent_std 2.91 / train/prior_ent_mag 51.12 / train/prior_ent_max 51.12 / train/prior_ent_mean 23.71 / train/prior_ent_min 15.29 / train/prior_ent_std 4.88 / train/rep_loss_mean 2.92 / train/rep_loss_std 4.42 / train/reward_avg 9.5e-5 / train/reward_loss_mean 
4.8e-4 / train/reward_loss_std 7.4e-3 / train/reward_max_data 0.04 / train/reward_max_pred 0.03 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-4 / train/reward_pos_acc 0.95 / train/reward_pos_loss 0.57 / train/reward_pred 8e-5 / train/reward_rate 1.9e-4 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.57 / report/cont_avg 1 / report/cont_loss_mean 1.2e-8 / report/cont_loss_std 6.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-8 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 2.99 / report/dyn_loss_std 4.44 / report/image_loss_mean 2.38 / report/image_loss_std 2.12 / report/model_loss_mean 4.17 / report/model_loss_std 4.16 / report/post_ent_mag 29.12 / report/post_ent_max 29.12 / 
report/post_ent_mean 20.96 / report/post_ent_min 12.33 / report/post_ent_std 2.98 / report/prior_ent_mag 52.06 / report/prior_ent_max 52.06 / report/prior_ent_mean 23.82 / report/prior_ent_min 14.21 / report/prior_ent_std 4.77 / report/rep_loss_mean 2.99 / 
report/rep_loss_std 4.44 / report/reward_avg 0 / report/reward_loss_mean 1.2e-5 / report/reward_loss_std 1.2e-5 / report/reward_max_data 0 / report/reward_max_pred 7.2e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-5 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 1.2e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-8 / eval/cont_loss_std 5.4e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-8 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 13.41 / eval/dyn_loss_std 7.36 / eval/image_loss_mean 9.28 / eval/image_loss_std 4.4 / eval/model_loss_mean 17.33 / eval/model_loss_std 7.69 / eval/post_ent_mag 36.24 / eval/post_ent_max 36.24 / eval/post_ent_mean 23.47 / 
eval/post_ent_min 13.91 / eval/post_ent_std 4.17 / eval/prior_ent_mag 52.06 / eval/prior_ent_max 52.06 / eval/prior_ent_mean 28.69 / eval/prior_ent_min 17.43 / eval/prior_ent_std 5.44 / eval/rep_loss_mean 13.41 / eval/rep_loss_std 7.36 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.4e-5 / eval/reward_loss_std 3.8e-5 / eval/reward_max_data 0 / eval/reward_max_pred 1.8e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.4e-6 / eval/reward_rate 0 / 
replay/size 2e4 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3780 / timer/env.step_total 19.98 / timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 435.59 / timer/replay._sample_frac 1.45 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.1 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7788 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.6e-3 / 
timer/dataset_train_count 1890 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1890 / timer/agent.train_total 241.77 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215340F820481-6v9nve9KRqwMWln1hulCRo-4grq04W8MxSdlDRxr7PtHF-1024.npz
Starting evaluation at step 20500 Counter(20500) 20437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21000 Counter(21000) 20937
Saved chunk: 20230921T215425F607827-474A3VvGqCLhpKKnPqDSHH-7DtA4kZxZRCqJAoSt3r6P8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21500 Counter(21500) 21437
eval_Episode has 500 steps and return 3.7.
Saved chunk: 20230921T215501F880690-4grq04W8MxSdlDRxr7PtHF-5F8NN0kzF1RphjSAYOMhTH-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22000 Counter(22000) 21937
Saved chunk: 20230921T215545F448296-7DtA4kZxZRCqJAoSt3r6P8-2hHD2fEvdgroG05MpQpO7j-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22500 Counter(22500) 22437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215626F263985-5F8NN0kzF1RphjSAYOMhTH-1lQzB97NwJbUP9QKULHcyr-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T215746F658155-1lQzB97NwJbUP9QKULHcyr-0000000000000000000000-272.npz
Saved chunk: 20230921T215704F507195-2hHD2fEvdgroG05MpQpO7j-0000000000000000000000-616.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 23000 Counter(23000) 22937
Saved chunk: 20230921T215704F507195-2hHD2fEvdgroG05MpQpO7j-1036ndGvusT1sDo6WPgziD-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 23500 Counter(23500) 23437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215746F658155-1lQzB97NwJbUP9QKULHcyr-3LWpHcdwft3OrDwKvrNglm-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 47666 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.82 / train/action_max 4.51 / train/action_mean -0.27 / train/action_min -4.72 / train/action_std 1.15 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 1e4 / train/actor_opt_loss -176.41 / train/adv_mag 1.69 / train/adv_max 1.66 / train/adv_mean 0.02 / train/adv_min -0.44 / 
train/adv_std 0.1 / train/cont_avg 1 / train/cont_loss_mean 7.9e-9 / train/cont_loss_std 4.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.9e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.03 / 
train/dyn_loss_std 4.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.31 / train/extr_critic_critic_opt_grad_steps 1e4 / train/extr_critic_critic_opt_loss 1e4 /
train/extr_critic_mag 0.68 / train/extr_critic_max 0.68 / train/extr_critic_mean 0.12 / train/extr_critic_min 0.02 / train/extr_critic_std 0.12 / train/extr_return_normed_mag 2.12 / train/extr_return_normed_max 2.12 / train/extr_return_normed_mean 0.11 / 
train/extr_return_normed_min 9.4e-4 / train/extr_return_normed_std 0.18 / train/extr_return_rate 0.13 / train/extr_return_raw_mag 2.15 / train/extr_return_raw_max 2.15 / train/extr_return_raw_mean 0.14 / train/extr_return_raw_min 0.02 / train/extr_return_raw_std 0.18 / 
train/extr_reward_mag 0.62 / train/extr_reward_max 0.62 / train/extr_reward_mean 1.9e-3 / train/extr_reward_min 4.9e-7 / train/extr_reward_std 0.02 / train/image_loss_mean 2.32 / train/image_loss_std 2.2 / train/model_loss_mean 4.14 / train/model_loss_std 4.29 / 
train/model_opt_grad_norm 15.47 / train/model_opt_grad_steps 1e4 / train/model_opt_loss 2.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5287.96 / train/policy_entropy_mag 5.58 / train/policy_entropy_max 5.58 / 
train/policy_entropy_mean 3.51 / train/policy_entropy_min -2.85 / train/policy_entropy_std 1.7 / train/policy_logprob_mag 15.35 / train/policy_logprob_max 4.42 / train/policy_logprob_mean -3.52 / train/policy_logprob_min -15.35 / train/policy_logprob_std 2.32 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.77 / train/policy_randomness_min 0.07 / train/policy_randomness_std 0.19 / train/post_ent_mag 30.97 / train/post_ent_max 30.97 / train/post_ent_mean 21.46 / 
train/post_ent_min 13.28 / train/post_ent_std 3.05 / train/prior_ent_mag 52.91 / train/prior_ent_max 52.91 / train/prior_ent_mean 24.68 / train/prior_ent_min 15.94 / train/prior_ent_std 5.04 / train/rep_loss_mean 3.03 / train/rep_loss_std 4.63 / train/reward_avg 2.2e-4 / 
train/reward_loss_mean 5.3e-4 / train/reward_loss_std 8.3e-3 / train/reward_max_data 0.1 / train/reward_max_pred 0.1 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-4 / train/reward_pos_acc 1 / train/reward_pos_loss 0.54 / train/reward_pred 2.2e-4 / 
train/reward_rate 3.6e-4 / train_stats/mean_log_entropy 4.05 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.2e-9 / report/cont_loss_std 1.7e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 6.2e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.06 / report/dyn_loss_std 5.03 / report/image_loss_mean 2.26 / report/image_loss_std 2.09 / report/model_loss_mean 4.1 / report/model_loss_std 4.36 / report/post_ent_mag 33.61 / 
report/post_ent_max 33.61 / report/post_ent_mean 22.55 / report/post_ent_min 14.07 / report/post_ent_std 3.3 / report/prior_ent_mag 54.09 / report/prior_ent_max 54.09 / report/prior_ent_mean 25.66 / report/prior_ent_min 15.45 / report/prior_ent_std 5.08 / 
report/rep_loss_mean 3.06 / report/rep_loss_std 5.03 / report/reward_avg 8e-6 / report/reward_loss_mean 2.5e-4 / report/reward_loss_std 6.2e-3 / report/reward_max_data 6.7e-3 / report/reward_max_pred 2.8e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-4 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 3.9e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-9 / eval/cont_loss_std 3.3e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
5.3e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 12.17 / eval/dyn_loss_std 7.21 / eval/image_loss_mean 7.37 / eval/image_loss_std 4.35 / eval/model_loss_mean 14.67 / eval/model_loss_std 7.79 / eval/post_ent_mag 34.87 / eval/post_ent_max 34.87 / 
eval/post_ent_mean 22.79 / eval/post_ent_min 13.28 / eval/post_ent_std 3.85 / eval/prior_ent_mag 54.09 / eval/prior_ent_max 54.09 / eval/prior_ent_mean 27.63 / eval/prior_ent_min 18.6 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 12.17 / eval/rep_loss_std 7.21 / 
eval/reward_avg 0 / eval/reward_loss_mean 5e-6 / eval/reward_loss_std 1.6e-5 / eval/reward_max_data 0 / eval/reward_max_pred 7.5e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 5.3e-7 / 
eval/reward_rate 0 / replay/size 2.4e4 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.4e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3822 / timer/env.step_total 20.3 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 441.31 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7329 / timer/agent.policy_total 16.37 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / 
timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1911 / timer/agent.train_total 244.49 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.48

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 24000 Counter(24000) 23937
Saved chunk: 20230921T215823F650795-1036ndGvusT1sDo6WPgziD-1Jnqf9jgGk1gZtqMefDdEo-1024.npz
eval_Episode has 500 steps and return 2.2.
train_Episode has 500 steps and return 0.6.
Starting evaluation at step 24500 Counter(24500) 24437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215907F385435-3LWpHcdwft3OrDwKvrNglm-7wuy3gRPFYYqhj3GEOuJax-1024.npz
Starting evaluation at step 25000 Counter(25000) 24937
Saved chunk: 20230921T215943F173064-1Jnqf9jgGk1gZtqMefDdEo-5XXzH7H2RDUw8qDqAKgGG3-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 25500 Counter(25500) 25437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220028F799266-7wuy3gRPFYYqhj3GEOuJax-0IKtYHtxqpJiyNFhOnHQWf-1024.npz
Starting evaluation at step 26000 Counter(26000) 25937
Saved chunk: 20230921T220102F460968-5XXzH7H2RDUw8qDqAKgGG3-2iWkxllwSMPr5jYoyNYuve-1024.npz
eval_Episode has 500 steps and return 0.3.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 26500 Counter(26500) 26437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220149F357880-0IKtYHtxqpJiyNFhOnHQWf-6cPiDyc2j3hUTtMolWDPT0-1024.npz
Starting evaluation at step 27000 Counter(27000) 26937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220221F322601-2iWkxllwSMPr5jYoyNYuve-5SbOWcSMZ1iIEun13tzRrF-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 27500 Counter(27500) 27437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 55210 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.54 / train/action_max 4.46 / train/action_mean 0.12 / train/action_min -4.2 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.03 / train/actor_opt_grad_steps 1.2e4 / train/actor_opt_loss -24.53 / train/adv_mag 0.73 / train/adv_max 0.67 / train/adv_mean 1.8e-3 / train/adv_min -0.23 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.5e-9 / train/cont_loss_std 4.2e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.93 / 
train/dyn_loss_std 4.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.18 / train/extr_critic_critic_opt_grad_steps 1.2e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 0.97 / train/extr_critic_max 0.97 / train/extr_critic_mean 0.67 / train/extr_critic_min 0.56 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.85 / train/extr_return_normed_max 0.85 / train/extr_return_normed_mean 0.07 / 
train/extr_return_normed_min -0.01 / train/extr_return_normed_std 0.04 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 1.45 / train/extr_return_raw_max 1.45 / train/extr_return_raw_mean 0.67 / train/extr_return_raw_min 0.59 / train/extr_return_raw_std 0.04 / 
train/extr_reward_mag 0.37 / train/extr_reward_max 0.37 / train/extr_reward_mean 1.7e-4 / train/extr_reward_min 8.2e-8 / train/extr_reward_std 6.3e-3 / train/image_loss_mean 2.06 / train/image_loss_std 2.07 / train/model_loss_mean 3.82 / train/model_loss_std 4.27 / 
train/model_opt_grad_norm 13.18 / train/model_opt_grad_steps 1.2e4 / train/model_opt_loss 1.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3994.71 / train/policy_entropy_mag 5.46 / train/policy_entropy_max 5.46 / 
train/policy_entropy_mean 2.4 / train/policy_entropy_min -2.97 / train/policy_entropy_std 1.49 / train/policy_logprob_mag 14.09 / train/policy_logprob_max 4.38 / train/policy_logprob_mean -2.4 / train/policy_logprob_min -14.09 / train/policy_logprob_std 2.06 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.64 / train/policy_randomness_min 0.06 / train/policy_randomness_std 0.16 / train/post_ent_mag 31.81 / train/post_ent_max 31.81 / train/post_ent_mean 22.18 / 
train/post_ent_min 13.83 / train/post_ent_std 3.1 / train/prior_ent_mag 54.78 / train/prior_ent_max 54.78 / train/prior_ent_mean 25.29 / train/prior_ent_min 16.44 / train/prior_ent_std 5.19 / train/rep_loss_mean 2.93 / train/rep_loss_std 4.74 / train/reward_avg 1.2e-4 / 
train/reward_loss_mean 3.5e-4 / train/reward_loss_std 6e-3 / train/reward_max_data 0.06 / train/reward_max_pred 0.06 / train/reward_neg_acc 1 / train/reward_neg_loss 2.5e-4 / train/reward_pos_acc 1 / train/reward_pos_loss 0.4 / train/reward_pred 1.2e-4 / train/reward_rate
2.3e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.99 / report/cont_avg 1 / report/cont_loss_mean 4.2e-9 / report/cont_loss_std 3.4e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.81 / report/dyn_loss_std 4.67 / report/image_loss_mean 1.81 / report/image_loss_std 1.59 / report/model_loss_mean 3.5 / report/model_loss_std 3.79 / report/post_ent_mag 33.05 / report/post_ent_max 33.05 / 
report/post_ent_mean 22.99 / report/post_ent_min 13.18 / report/post_ent_std 3.4 / report/prior_ent_mag 55.55 / report/prior_ent_max 55.55 / report/prior_ent_mean 25.97 / report/prior_ent_min 16.91 / report/prior_ent_std 5.3 / report/rep_loss_mean 2.81 / 
report/rep_loss_std 4.67 / report/reward_avg 2.6e-5 / report/reward_loss_mean 6.5e-4 / report/reward_loss_std 0.01 / report/reward_max_data 0.01 / report/reward_max_pred 9.3e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 6.5e-4 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 2e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-9 / eval/cont_loss_std 4.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-9 / eval/cont_pred 1 / 
eval/cont_rate 1 / eval/dyn_loss_mean 5.77 / eval/dyn_loss_std 8.07 / eval/image_loss_mean 3.33 / eval/image_loss_std 5.21 / eval/model_loss_mean 6.79 / eval/model_loss_std 9.46 / eval/post_ent_mag 32.55 / eval/post_ent_max 32.55 / eval/post_ent_mean 20.4 / 
eval/post_ent_min 14.07 / eval/post_ent_std 2.91 / eval/prior_ent_mag 55.55 / eval/prior_ent_max 55.55 / eval/prior_ent_mean 23.66 / eval/prior_ent_min 16.59 / eval/prior_ent_std 6.07 / eval/rep_loss_mean 5.77 / eval/rep_loss_std 8.07 / eval/reward_avg 2.4e-8 / 
eval/reward_loss_mean 1.4e-3 / eval/reward_loss_std 0.03 / eval/reward_max_data 2.4e-5 / eval/reward_max_pred 0.1 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.8e-4 / eval/reward_rate 0 / 
replay/size 2.8e4 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3772 / timer/env.step_total 19.81 / timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3 /
timer/env.step_min 4.5e-3 / timer/env.step_max 7.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 438.02 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7780 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.08 / 
timer/dataset_train_count 1886 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 6.3e-4 / timer/agent.train_count 1886 / timer/agent.train_total 241.75 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.61 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.15

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T220310F224310-6cPiDyc2j3hUTtMolWDPT0-7AQg2El3nZg3nxcgsIp2nb-1024.npz
Starting evaluation at step 28000 Counter(28000) 27937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 28500 Counter(28500) 28437
Saved chunk: 20230921T220340F559924-5SbOWcSMZ1iIEun13tzRrF-0pN3DGVMw70tpma91sxb64-1024.npz
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 1.9.
Saved chunk: 20230921T220431F176793-7AQg2El3nZg3nxcgsIp2nb-3FfwiCoI9TAKxTOGaAbiIo-1024.npz
Starting evaluation at step 29000 Counter(29000) 28937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 29500 Counter(29500) 29437
Saved chunk: 20230921T220536F252217-0pN3DGVMw70tpma91sxb64-0a0YFKP680tutjGnIn9HEa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220551F993600-3FfwiCoI9TAKxTOGaAbiIo-4s7e6YOHVh6bMsClldxSM8-1024.npz
Starting evaluation at step 30000 Counter(30000) 29937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 30500 Counter(30500) 30437
Saved chunk: 20230921T220655F260106-0a0YFKP680tutjGnIn9HEa-7AilgVKhKBzIDa85BrJWl0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 3.0.
Saved chunk: 20230921T220712F560419-4s7e6YOHVh6bMsClldxSM8-31WhWecuKiXCNDJzldj4CB-1024.npz
Starting evaluation at step 31000 Counter(31000) 30937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 62866 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.96 / train/action_max 4.68 / train/action_mean -0.35 / train/action_min -4.84 / train/action_std 1.17 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 1.4e4 / train/actor_opt_loss 37.88 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean -5.3e-3 / train/adv_min -0.28 / 
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 3.2e-9 / train/cont_loss_std 7.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.92 / 
train/dyn_loss_std 4.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.4e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 0.84 / train/extr_critic_max 0.84 / train/extr_critic_mean 0.46 / train/extr_critic_min 0.43 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.57 / train/extr_return_normed_max 0.57 / train/extr_return_normed_mean 4.1e-3 / 
train/extr_return_normed_min -0.02 / train/extr_return_normed_std 0.02 / train/extr_return_rate 0.24 / train/extr_return_raw_mag 1.02 / train/extr_return_raw_max 1.02 / train/extr_return_raw_mean 0.45 / train/extr_return_raw_min 0.43 / train/extr_return_raw_std 0.02 / 
train/extr_reward_mag 0.25 / train/extr_reward_max 0.25 / train/extr_reward_mean 1.7e-4 / train/extr_reward_min -3.7e-9 / train/extr_reward_std 5e-3 / train/image_loss_mean 1.86 / train/image_loss_std 1.89 / train/model_loss_mean 3.61 / train/model_loss_std 4.2 / 
train/model_opt_grad_norm 11.73 / train/model_opt_grad_steps 1.4e4 / train/model_opt_loss 1.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5235.6 / train/policy_entropy_mag 5.64 / train/policy_entropy_max 5.64 / 
train/policy_entropy_mean 4.74 / train/policy_entropy_min -1.74 / train/policy_entropy_std 0.78 / train/policy_logprob_mag 15.69 / train/policy_logprob_max 2.84 / train/policy_logprob_mean -4.73 / train/policy_logprob_min -15.69 / train/policy_logprob_std 1.62 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.9 / train/policy_randomness_min 0.19 / train/policy_randomness_std 0.08 / train/post_ent_mag 32.2 / train/post_ent_max 32.2 / train/post_ent_mean 22.75 / train/post_ent_min 
14.36 / train/post_ent_std 3.12 / train/prior_ent_mag 56.48 / train/prior_ent_max 56.48 / train/prior_ent_mean 25.81 / train/prior_ent_min 16.87 / train/prior_ent_std 5.32 / train/rep_loss_mean 2.92 / train/rep_loss_std 4.87 / train/reward_avg 2.4e-4 / 
train/reward_loss_mean 7.1e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.11 / train/reward_max_pred 0.1 / train/reward_neg_acc 1 / train/reward_neg_loss 2.6e-4 / train/reward_pos_acc 0.94 / train/reward_pos_loss 1.04 / train/reward_pred 2.2e-4 / 
train/reward_rate 4.2e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 4.73 / report/cont_avg 1 / report/cont_loss_mean 1.7e-9 / report/cont_loss_std 1.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.7e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.87 / report/dyn_loss_std 4.63 / report/image_loss_mean 1.81 / report/image_loss_std 1.67 / report/model_loss_mean 3.53 / report/model_loss_std 3.9 / report/post_ent_mag 32.06 / 
report/post_ent_max 32.06 / report/post_ent_mean 22.82 / report/post_ent_min 13.86 / report/post_ent_std 3.43 / report/prior_ent_mag 56.84 / report/prior_ent_max 56.84 / report/prior_ent_mean 26.11 / report/prior_ent_min 15.94 / report/prior_ent_std 5.31 / 
report/rep_loss_mean 2.87 / report/rep_loss_std 4.63 / report/reward_avg 0 / report/reward_loss_mean 1.3e-6 / report/reward_loss_std 3.7e-6 / report/reward_max_data 0 / report/reward_max_pred 1.7e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.9e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2e-9 / eval/cont_loss_std 1.8e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
2e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.49 / eval/dyn_loss_std 6.61 / eval/image_loss_mean 2.25 / eval/image_loss_std 4.12 / eval/model_loss_mean 4.95 / eval/model_loss_std 7.43 / eval/post_ent_mag 31.55 / eval/post_ent_max 31.55 / 
eval/post_ent_mean 23.4 / eval/post_ent_min 14.05 / eval/post_ent_std 2.62 / eval/prior_ent_mag 56.84 / eval/prior_ent_max 56.84 / eval/prior_ent_mean 26.8 / eval/prior_ent_min 20.39 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 4.49 / eval/rep_loss_std 6.61 / 
eval/reward_avg 2.4e-8 / eval/reward_loss_mean 7.7e-4 / eval/reward_loss_std 0.01 / eval/reward_max_data 2.4e-5 / eval/reward_max_pred 0.05 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.7e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.1e-4
/ eval/reward_rate 0 / replay/size 3.1e4 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.2e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.8e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3828 / timer/env.step_total 20.2 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 440.96 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7335 / timer/agent.policy_total 16.18 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 8.4e-3 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1914 / 
timer/agent.train_total 244.86 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.5e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 31500 Counter(31500) 31437
Saved chunk: 20230921T220814F179981-7AilgVKhKBzIDa85BrJWl0-5YBxK9QK141yMRsF1YVTRa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220833F028015-31WhWecuKiXCNDJzldj4CB-3brvm5Aplkf1p2pUz7Z84X-1024.npz
Starting evaluation at step 32000 Counter(32000) 31937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 32500 Counter(32500) 32437
Saved chunk: 20230921T220933F644606-5YBxK9QK141yMRsF1YVTRa-68xSBpwHvdBusCsPErHQAo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220954F232466-3brvm5Aplkf1p2pUz7Z84X-08vuiQPzP9UAW53cd47qds-1024.npz
Starting evaluation at step 33000 Counter(33000) 32937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 33500 Counter(33500) 33437
Saved chunk: 20230921T221053F011697-68xSBpwHvdBusCsPErHQAo-2DUYKcVVixY1wh6KtdjucR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221115F054600-08vuiQPzP9UAW53cd47qds-3cwKVSlaBOYiLOySMtY1HV-1024.npz
Starting evaluation at step 34000 Counter(34000) 33937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T221235F422098-3cwKVSlaBOYiLOySMtY1HV-0000000000000000000000-409.npz
Saved chunk: 20230921T221211F901505-2DUYKcVVixY1wh6KtdjucR-0000000000000000000000-875.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 34500 Counter(34500) 34437
Saved chunk: 20230921T221211F901505-2DUYKcVVixY1wh6KtdjucR-1KaypswNC7mNmlEVtThtK0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 2.9.
Saved chunk: 20230921T221235F422098-3cwKVSlaBOYiLOySMtY1HV-6ZhsvL3NcVzUAYtXaQ9i6m-1024.npz
Starting evaluation at step 35000 Counter(35000) 34937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 70422 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 1.4e-3 / episode/reward_rate 0 / train/action_mag 5.05 / train/action_max 4.62 / train/action_mean -0.62 / train/action_min -5.02 / train/action_std 1.16 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.3e-3 / train/actor_opt_grad_steps 1.6e4 / train/actor_opt_loss 12.35 / train/adv_mag 0.55 / train/adv_max 0.42 / train/adv_mean -2.8e-3 / train/adv_min -0.33
/ train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 1.7e-9 / train/cont_loss_std 3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.97 / 
train/dyn_loss_std 4.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 0.78 / train/extr_critic_max 0.78 / train/extr_critic_mean 0.3 / train/extr_critic_min 0.27 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.7 / train/extr_return_normed_max 0.7 / train/extr_return_normed_mean 0.01 / 
train/extr_return_normed_min -0.02 / train/extr_return_normed_std 0.03 / train/extr_return_rate 7.3e-4 / train/extr_return_raw_mag 0.99 / train/extr_return_raw_max 0.99 / train/extr_return_raw_mean 0.3 / train/extr_return_raw_min 0.27 / train/extr_return_raw_std 0.03 / 
train/extr_reward_mag 0.26 / train/extr_reward_max 0.26 / train/extr_reward_mean 2.1e-4 / train/extr_reward_min 0 / train/extr_reward_std 5.8e-3 / train/image_loss_mean 1.77 / train/image_loss_std 1.8 / train/model_loss_mean 3.55 / train/model_loss_std 4.21 / 
train/model_opt_grad_norm 11.68 / train/model_opt_grad_steps 1.6e4 / train/model_opt_loss 2.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5978.84 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.31 / train/policy_entropy_min -1.84 / train/policy_entropy_std 0.56 / train/policy_logprob_mag 15.97 / train/policy_logprob_max 2.93 / train/policy_logprob_mean -5.31 / train/policy_logprob_min -15.97 / train/policy_logprob_std 1.53 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.96 / train/policy_randomness_min 0.18 / train/policy_randomness_std 0.06 / train/post_ent_mag 33.06 / train/post_ent_max 33.06 / train/post_ent_mean 23.62 / train/post_ent_min 
14.95 / train/post_ent_std 3.1 / train/prior_ent_mag 58.14 / train/prior_ent_max 58.14 / train/prior_ent_mean 26.71 / train/prior_ent_min 17.51 / train/prior_ent_std 5.39 / train/rep_loss_mean 2.97 / train/rep_loss_std 4.96 / train/reward_avg 2.6e-4 / 
train/reward_loss_mean 5.2e-4 / train/reward_loss_std 8.6e-3 / train/reward_max_data 0.11 / train/reward_max_pred 0.11 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-4 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.62 / train/reward_pred 2.5e-4 / 
train/reward_rate 4.1e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.28 / report/cont_avg 1 / report/cont_loss_mean 1.6e-9 / report/cont_loss_std 2.6e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.6e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.9 / report/dyn_loss_std 5.03 / report/image_loss_mean 1.84 / report/image_loss_std 1.66 / report/model_loss_mean 3.58 / report/model_loss_std 4.03 / report/post_ent_mag 32.9 / 
report/post_ent_max 32.9 / report/post_ent_mean 23.59 / report/post_ent_min 14.87 / report/post_ent_std 3.23 / report/prior_ent_mag 58.71 / report/prior_ent_max 58.71 / report/prior_ent_mean 26.81 / report/prior_ent_min 18.08 / report/prior_ent_std 5.46 / 
report/rep_loss_mean 2.9 / report/rep_loss_std 5.03 / report/reward_avg 0 / report/reward_loss_mean 3.9e-6 / report/reward_loss_std 4.4e-5 / report/reward_max_data 0 / report/reward_max_pred 2.1e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 6.1e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-9 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
1.3e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.88 / eval/dyn_loss_std 5.95 / eval/image_loss_mean 1.73 / eval/image_loss_std 2.98 / eval/model_loss_mean 4.05 / eval/model_loss_std 5.96 / eval/post_ent_mag 32.9 / eval/post_ent_max 32.9 / 
eval/post_ent_mean 24.77 / eval/post_ent_min 15.82 / eval/post_ent_std 3.14 / eval/prior_ent_mag 58.71 / eval/prior_ent_max 58.71 / eval/prior_ent_mean 27.19 / eval/prior_ent_min 19.95 / eval/prior_ent_std 5.12 / eval/rep_loss_mean 3.88 / eval/rep_loss_std 5.95 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.1e-6 / eval/reward_loss_std 8.6e-7 / eval/reward_max_data 0 / eval/reward_max_pred 2.9e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.5e-7 / 
eval/reward_rate 0 / replay/size 3.5e4 / replay/inserts 3778 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.6e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3778 / timer/env.step_total 19.94 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3e4 / timer/replay._sample_total 442.73 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.8e-3 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7786 / timer/agent.policy_total 17.19 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1889 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / 
timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1889 / timer/agent.train_total 241.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.18

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 35500 Counter(35500) 35437
Saved chunk: 20230921T221330F912735-1KaypswNC7mNmlEVtThtK0-7EpyZa5YeMLyvrJ0ssX9o1-1024.npz
eval_Episode has 500 steps and return 0.3.
train_Episode has 500 steps and return 0.1.
Saved chunk: 20230921T221355F985377-6ZhsvL3NcVzUAYtXaQ9i6m-1C0bkgix3UqU8GgA5tSWSK-1024.npz
Starting evaluation at step 36000 Counter(36000) 35937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 36500 Counter(36500) 36437
Saved chunk: 20230921T221450F348675-7EpyZa5YeMLyvrJ0ssX9o1-7anYUS9AeR7yAAV6rXOQWH-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221517F198421-1C0bkgix3UqU8GgA5tSWSK-39dLXnJ2fWM3HsgwYE1iMr-1024.npz
Starting evaluation at step 37000 Counter(37000) 36937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.1.
Starting evaluation at step 37500 Counter(37500) 37437
Saved chunk: 20230921T221609F508321-7anYUS9AeR7yAAV6rXOQWH-5wJYsFbX04FK773eElGEyE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221637F824201-39dLXnJ2fWM3HsgwYE1iMr-0WFFwKIE1omac46xZkWDPa-1024.npz
Starting evaluation at step 38000 Counter(38000) 37937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 38500 Counter(38500) 38437
Saved chunk: 20230921T221728F498266-5wJYsFbX04FK773eElGEyE-1GKqSpDptIft2DroDkGNzJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221758F247046-0WFFwKIE1omac46xZkWDPa-587ktAOY8OjHtJ69pXuBvi-1024.npz
Starting evaluation at step 39000 Counter(39000) 38937
eval_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 78002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.1 / train/action_max 4.84 / train/action_mean -0.34 / train/action_min -5.02 / train/action_std 1.25 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.02 / train/actor_opt_grad_steps 1.8e4 / train/actor_opt_loss -12.9 / train/adv_mag 0.71 / train/adv_max 0.62 / train/adv_mean -2.5e-4 / train/adv_min -0.37 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.2e-9 / train/cont_loss_std 2.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.07 / 
train/dyn_loss_std 5.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.8e4 / train/extr_critic_critic_opt_loss 
8622.39 / train/extr_critic_mag 0.86 / train/extr_critic_max 0.86 / train/extr_critic_mean 0.21 / train/extr_critic_min 0.19 / train/extr_critic_std 0.04 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.02 / train/extr_return_normed_mean 0.02 / 
train/extr_return_normed_min -9.2e-3 / train/extr_return_normed_std 0.06 / train/extr_return_rate 0.01 / train/extr_return_raw_mag 1.21 / train/extr_return_raw_max 1.21 / train/extr_return_raw_mean 0.21 / train/extr_return_raw_min 0.18 / train/extr_return_raw_std 0.06 / 
train/extr_reward_mag 0.33 / train/extr_reward_max 0.33 / train/extr_reward_mean 5.1e-4 / train/extr_reward_min 4.8e-8 / train/extr_reward_std 9.3e-3 / train/image_loss_mean 1.75 / train/image_loss_std 1.78 / train/model_loss_mean 3.59 / train/model_loss_std 4.28 / 
train/model_opt_grad_norm 10.4 / train/model_opt_grad_steps 1.8e4 / train/model_opt_loss 1.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5342.11 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.24 / train/policy_entropy_min -2.35 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 16.32 / train/policy_logprob_max 3.65 / train/policy_logprob_mean -5.24 / train/policy_logprob_min -16.32 / train/policy_logprob_std 1.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.95 / train/policy_randomness_min 0.13 / train/policy_randomness_std 0.09 / train/post_ent_mag 33.87 / train/post_ent_max 33.87 / train/post_ent_mean 24.34 / train/post_ent_min 
15.5 / train/post_ent_std 3.1 / train/prior_ent_mag 59.67 / train/prior_ent_max 59.67 / train/prior_ent_mean 27.51 / train/prior_ent_min 18.45 / train/prior_ent_std 5.51 / train/rep_loss_mean 3.07 / train/rep_loss_std 5.09 / train/reward_avg 4.1e-4 / 
train/reward_loss_mean 8.9e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.14 / train/reward_max_pred 0.13 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-4 / train/reward_pos_acc 0.88 / train/reward_pos_loss 0.86 / train/reward_pred 4e-4 / 
train/reward_rate 7.3e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.35 / report/cont_avg 1 / report/cont_loss_mean 6.3e-10 / report/cont_loss_std 4.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 6.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.56 / report/dyn_loss_std 4.55 / report/image_loss_mean 1.29 / report/image_loss_std 1.09 / report/model_loss_mean 2.83 / report/model_loss_std 3.56 / report/post_ent_mag 33.35 
/ report/post_ent_max 33.35 / report/post_ent_mean 23.24 / report/post_ent_min 15.4 / report/post_ent_std 3.38 / report/prior_ent_mag 59.65 / report/prior_ent_max 59.65 / report/prior_ent_mean 26.02 / report/prior_ent_min 17.27 / report/prior_ent_std 5.55 / 
report/rep_loss_mean 2.56 / report/rep_loss_std 4.55 / report/reward_avg 0 / report/reward_loss_mean 1.2e-6 / report/reward_loss_std 9.6e-7 / report/reward_max_data 0 / report/reward_max_pred 2e-6 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 2.4e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-9 / eval/cont_loss_std 1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
1.1e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.96 / eval/dyn_loss_std 5.37 / eval/image_loss_mean 1.14 / eval/image_loss_std 2.34 / eval/model_loss_mean 2.91 / eval/model_loss_std 5.08 / eval/post_ent_mag 32.85 / eval/post_ent_max 32.85 / 
eval/post_ent_mean 27.37 / eval/post_ent_min 17.3 / eval/post_ent_std 3.2 / eval/prior_ent_mag 59.65 / eval/prior_ent_max 59.65 / eval/prior_ent_mean 29.53 / eval/prior_ent_min 21.82 / eval/prior_ent_std 4.77 / eval/rep_loss_mean 2.96 / eval/rep_loss_std 5.37 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.1e-6 / eval/reward_loss_std 5.9e-7 / eval/reward_max_data 0 / eval/reward_max_pred 1.9e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.7e-7 / 
eval/reward_rate 0 / replay/size 3.9e4 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.78 / timer/env.step_count 3790 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.51 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.7e-3 / 
timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.02 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1895 / 
timer/agent.train_total 242.38 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 39500 Counter(39500) 39437
Saved chunk: 20230921T221847F212526-1GKqSpDptIft2DroDkGNzJ-3DG6cezaSEXrHX4oJS0aJd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221918F654078-587ktAOY8OjHtJ69pXuBvi-4wipHKi1vokhi8lTuLf2S0-1024.npz
Starting evaluation at step 40000 Counter(40000) 39937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 40500 Counter(40500) 40437
Saved chunk: 20230921T222006F981302-3DG6cezaSEXrHX4oJS0aJd-6bCGXT3OkO38GcIqf6srBw-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222040F140526-4wipHKi1vokhi8lTuLf2S0-3wFTOifrRJ7F9mdj17d4iF-1024.npz
Starting evaluation at step 41000 Counter(41000) 40937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 41500 Counter(41500) 41437
Saved chunk: 20230921T222126F269244-6bCGXT3OkO38GcIqf6srBw-324acLV2WM8vQ617ywikLY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 1.7.
Saved chunk: 20230921T222200F829414-3wFTOifrRJ7F9mdj17d4iF-3xhG3efsKXHHXlR8AwFavC-1024.npz
Starting evaluation at step 42000 Counter(42000) 41937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 42500 Counter(42500) 42437
Saved chunk: 20230921T222245F133547-324acLV2WM8vQ617ywikLY-5dwouezqTnQlP5kKZ5b3XF-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 85654 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.47 / train/action_max 4.25 / train/action_mean -0.35 / train/action_min -4.3 / train/action_std 1.02 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2e4 / train/actor_opt_loss -170.34 / train/adv_mag 0.85 / train/adv_max 0.81 / train/adv_mean 0.02 / train/adv_min -0.43 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 7.7e-10 / train/cont_loss_std 1.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.09 / 
train/dyn_loss_std 5.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.32 / train/extr_critic_critic_opt_grad_steps 2e4 / train/extr_critic_critic_opt_loss 
9079.56 / train/extr_critic_mag 1.15 / train/extr_critic_max 1.15 / train/extr_critic_mean 0.49 / train/extr_critic_min 0.32 / train/extr_critic_std 0.15 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.33 / train/extr_return_normed_mean 0.17 / 
train/extr_return_normed_min -4.6e-3 / train/extr_return_normed_std 0.16 / train/extr_return_rate 0.52 / train/extr_return_raw_mag 1.67 / train/extr_return_raw_max 1.67 / train/extr_return_raw_mean 0.51 / train/extr_return_raw_min 0.34 / train/extr_return_raw_std 0.16 / 
train/extr_reward_mag 0.37 / train/extr_reward_max 0.37 / train/extr_reward_mean 6e-4 / train/extr_reward_min 3.7e-9 / train/extr_reward_std 0.01 / train/image_loss_mean 1.69 / train/image_loss_std 1.74 / train/model_loss_mean 3.55 / train/model_loss_std 4.31 / 
train/model_opt_grad_norm 10.41 / train/model_opt_grad_steps 2e4 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7015.71 / train/policy_entropy_mag 5.42 / train/policy_entropy_max 5.42 / 
train/policy_entropy_mean 1.5 / train/policy_entropy_min -3.46 / train/policy_entropy_std 1.99 / train/policy_logprob_mag 13.82 / train/policy_logprob_max 5.28 / train/policy_logprob_mean -1.5 / train/policy_logprob_min -13.82 / train/policy_logprob_std 2.47 / 
train/policy_randomness_mag 0.97 / train/policy_randomness_max 0.97 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 7.9e-3 / train/policy_randomness_std 0.22 / train/post_ent_mag 34.73 / train/post_ent_max 34.73 / train/post_ent_mean 25 / 
train/post_ent_min 15.93 / train/post_ent_std 3.2 / train/prior_ent_mag 61.05 / train/prior_ent_max 61.05 / train/prior_ent_mean 28.2 / train/prior_ent_min 18.73 / train/prior_ent_std 5.68 / train/rep_loss_mean 3.09 / train/rep_loss_std 5.17 / train/reward_avg 3.1e-4 / 
train/reward_loss_mean 6.3e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.11 / train/reward_max_pred 0.11 / train/reward_neg_acc 1 / train/reward_neg_loss 2.3e-4 / train/reward_pos_acc 0.91 / train/reward_pos_loss 0.66 / train/reward_pred 3.1e-4 / 
train/reward_rate 5.7e-4 / train_stats/mean_log_entropy 1.31 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.2e-10 / report/cont_loss_std 1.4e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 9.2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.56 / report/dyn_loss_std 5.72 / report/image_loss_mean 2.12 / report/image_loss_std 3.07 / report/model_loss_mean 4.26 / report/model_loss_std 5.93 / report/post_ent_mag 35.54 
/ report/post_ent_max 35.54 / report/post_ent_mean 24.93 / report/post_ent_min 16.33 / report/post_ent_std 4.05 / report/prior_ent_mag 61.16 / report/prior_ent_max 61.16 / report/prior_ent_mean 28.37 / report/prior_ent_min 17.65 / report/prior_ent_std 6.85 / 
report/rep_loss_mean 3.56 / report/rep_loss_std 5.72 / report/reward_avg 0 / report/reward_loss_mean 1.2e-6 / report/reward_loss_std 9.3e-6 / report/reward_max_data 0 / report/reward_max_pred 5.6e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 2.7e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-10 / eval/cont_loss_std 4.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.51 / eval/dyn_loss_std 6.33 / eval/image_loss_mean 1.82 / eval/image_loss_std 2.4 / eval/model_loss_mean 4.53 / eval/model_loss_std 5.78 / eval/post_ent_mag 31.33 / eval/post_ent_max 
31.33 / eval/post_ent_mean 25.17 / eval/post_ent_min 17.86 / eval/post_ent_std 2.89 / eval/prior_ent_mag 61.16 / eval/prior_ent_max 61.16 / eval/prior_ent_mean 28.28 / eval/prior_ent_min 19.43 / eval/prior_ent_std 5.35 / eval/rep_loss_mean 4.51 / eval/rep_loss_std 6.33 / 
eval/reward_avg 0 / eval/reward_loss_mean 1e-6 / eval/reward_loss_std 1.8e-5 / eval/reward_max_data 0 / eval/reward_max_pred 1.5e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 3.1e-7 / 
eval/reward_rate 0 / replay/size 4.3e4 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.3e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3826 / timer/env.step_total 20.19 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 450.19 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 9.9e-4 / 
timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 16.25 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 8.4e-3 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1913 / 
timer/agent.train_total 244.72 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.8e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 43000 Counter(43000) 42937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222321F232466-3xhG3efsKXHHXlR8AwFavC-67ZXacpVIe3g7OGXAx8APm-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 43500 Counter(43500) 43437
Saved chunk: 20230921T222403F936071-5dwouezqTnQlP5kKZ5b3XF-2a6K5OguSku9C3v12PmbUc-1024.npz
eval_Episode has 500 steps and return 1.4.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 44000 Counter(44000) 43937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222445F853680-67ZXacpVIe3g7OGXAx8APm-0jtUC19zP5IuvGFFfgGyKI-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 44500 Counter(44500) 44437
Saved chunk: 20230921T222523F709334-2a6K5OguSku9C3v12PmbUc-5YpYdEbX6J33b4Y5w7tXna-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 45000 Counter(45000) 44937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222606F728128-0jtUC19zP5IuvGFFfgGyKI-2HyBTbJr8cMJllK3YSlRjx-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 45500 Counter(45500) 45437
Saved chunk: 20230921T222642F982054-5YpYdEbX6J33b4Y5w7tXna-0axbGCdifkpCqJM7vB4JFj-1024.npz
eval_Episode has 500 steps and return 0.8.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T222801F870964-0axbGCdifkpCqJM7vB4JFj-0000000000000000000000-110.npz
Saved chunk: 20230921T222727F339137-2HyBTbJr8cMJllK3YSlRjx-0000000000000000000000-544.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 46000 Counter(46000) 45937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222727F339137-2HyBTbJr8cMJllK3YSlRjx-5kUGK5cxw9fcd1ckkksQso-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 46500 Counter(46500) 46437
Saved chunk: 20230921T222801F870964-0axbGCdifkpCqJM7vB4JFj-2VzYSel5rNCiTp825ycOO8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 93194 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.8 / train/action_max 4.52 / train/action_mean -0.4 / train/action_min -4.72 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 2.2e4 / train/actor_opt_loss 66.92 / train/adv_mag 0.5 / train/adv_max 0.42 / train/adv_mean -7.8e-3 / train/adv_min -0.31 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.2e-10 / train/cont_loss_std 2e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.06 / 
train/dyn_loss_std 5.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.2e4 / train/extr_critic_critic_opt_loss 
9990.19 / train/extr_critic_mag 1.18 / train/extr_critic_max 1.18 / train/extr_critic_mean 0.66 / train/extr_critic_min 0.62 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.72 / train/extr_return_normed_max 0.72 / train/extr_return_normed_mean 5.6e-3 / 
train/extr_return_normed_min -0.03 / train/extr_return_normed_std 0.03 / train/extr_return_rate 1 / train/extr_return_raw_mag 1.37 / train/extr_return_raw_max 1.37 / train/extr_return_raw_mean 0.65 / train/extr_return_raw_min 0.62 / train/extr_return_raw_std 0.03 / 
train/extr_reward_mag 0.25 / train/extr_reward_max 0.25 / train/extr_reward_mean 2.3e-4 / train/extr_reward_min -1.1e-8 / train/extr_reward_std 5.7e-3 / train/image_loss_mean 1.64 / train/image_loss_std 1.68 / train/model_loss_mean 3.47 / train/model_loss_std 4.3 / 
train/model_opt_grad_norm 10.01 / train/model_opt_grad_steps 2.2e4 / train/model_opt_loss 2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5744.68 / train/policy_entropy_mag 5.63 / train/policy_entropy_max 5.63 / 
train/policy_entropy_mean 3.2 / train/policy_entropy_min -3.22 / train/policy_entropy_std 1.96 / train/policy_logprob_mag 15.1 / train/policy_logprob_max 4.85 / train/policy_logprob_mean -3.2 / train/policy_logprob_min -15.1 / train/policy_logprob_std 2.44 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.73 / train/policy_randomness_min 0.03 / train/policy_randomness_std 0.21 / train/post_ent_mag 35.16 / train/post_ent_max 35.16 / train/post_ent_mean 25.67 / train/post_ent_min 
16.42 / train/post_ent_std 3.29 / train/prior_ent_mag 62.37 / train/prior_ent_max 62.37 / train/prior_ent_mean 28.81 / train/prior_ent_min 19.15 / train/prior_ent_std 5.78 / train/rep_loss_mean 3.06 / train/rep_loss_std 5.25 / train/reward_avg 3e-4 / 
train/reward_loss_mean 6.9e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.1 / train/reward_max_pred 0.1 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-4 / train/reward_pos_acc 0.96 / train/reward_pos_loss 0.74 / train/reward_pred 3e-4 / train/reward_rate
5.9e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.12 / report/cont_avg 1 / report/cont_loss_mean 5.1e-10 / report/cont_loss_std 8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.84 / report/dyn_loss_std 5.22 / report/image_loss_mean 1.31 / report/image_loss_std 1.54 / report/model_loss_mean 3.01 / report/model_loss_std 4.22 / report/post_ent_mag 36.14 / report/post_ent_max 36.14 / 
report/post_ent_mean 27.08 / report/post_ent_min 18.02 / report/post_ent_std 3.3 / report/prior_ent_mag 62.95 / report/prior_ent_max 62.95 / report/prior_ent_mean 30.06 / report/prior_ent_min 22.33 / report/prior_ent_std 5.54 / report/rep_loss_mean 2.84 / 
report/rep_loss_std 5.22 / report/reward_avg 0 / report/reward_loss_mean 6.3e-7 / report/reward_loss_std 7.1e-6 / report/reward_max_data 0 / report/reward_max_pred 3.3e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 6.3e-7 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 1.8e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.9e-10 / eval/cont_loss_std 6.7e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.9e-10 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 4.59 / eval/dyn_loss_std 7.38 / eval/image_loss_mean 2.22 / eval/image_loss_std 4.45 / eval/model_loss_mean 4.97 / eval/model_loss_std 8.15 / eval/post_ent_mag 35.76 / eval/post_ent_max 35.76 / eval/post_ent_mean 27.78 / 
eval/post_ent_min 15.64 / eval/post_ent_std 3.35 / eval/prior_ent_mag 62.95 / eval/prior_ent_max 62.95 / eval/prior_ent_mean 30.5 / eval/prior_ent_min 20.39 / eval/prior_ent_std 5.63 / eval/rep_loss_mean 4.59 / eval/rep_loss_std 7.38 / eval/reward_avg 0 / 
eval/reward_loss_mean 6.8e-7 / eval/reward_loss_std 5.4e-6 / eval/reward_max_data 0 / eval/reward_max_pred 5.8e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 2.5e-7 / eval/reward_rate 0 / 
replay/size 4.7e4 / replay/inserts 3770 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3770 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.56 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7778 / timer/agent.policy_total 17.34 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1885 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 6e-4 / timer/agent.train_count 1885 / timer/agent.train_total 241.3 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 47000 Counter(47000) 46937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222848F016089-5kUGK5cxw9fcd1ckkksQso-2lweV8MMYol6uVegTM1MvC-1024.npz
Starting evaluation at step 47500 Counter(47500) 47437
Saved chunk: 20230921T222921F029266-2VzYSel5rNCiTp825ycOO8-7qqATA1J3Qqr0Bw4uKWAk4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 48000 Counter(48000) 47937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223009F369253-2lweV8MMYol6uVegTM1MvC-6ZUYLSJzIwDyCiSFROg39I-1024.npz
Starting evaluation at step 48500 Counter(48500) 48437
Saved chunk: 20230921T223040F954195-7qqATA1J3Qqr0Bw4uKWAk4-5ArbkaeqYnwfLaO5gPOTAf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.4.
Starting evaluation at step 49000 Counter(49000) 48937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223130F180878-6ZUYLSJzIwDyCiSFROg39I-6Uap3tcGzc7CY0KgGMCMsd-1024.npz
Starting evaluation at step 49500 Counter(49500) 49437
eval_Episode has 500 steps and return 1.4.
Saved chunk: 20230921T223200F047312-5ArbkaeqYnwfLaO5gPOTAf-49I3s1khn41IPDYAM0uXuN-1024.npz
train_Episode has 500 steps and return 2.6.
Starting evaluation at step 50000 Counter(50000) 49937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223250F702416-6Uap3tcGzc7CY0KgGMCMsd-5wApFcC5OL6FsSF9N5NItV-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 100846 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5 / train/action_max 4.76 / train/action_mean -0.2 / train/action_min -4.9 / train/action_std 1.22 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 2.4e4 / train/actor_opt_loss 22.73 / train/adv_mag 0.47 / train/adv_max 0.38 / train/adv_mean -3.7e-3 / train/adv_min -0.31 /
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 4.8e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.1 / 
train/dyn_loss_std 5.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.4e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 1.01 / train/extr_critic_max 1.01 / train/extr_critic_mean 0.43 / train/extr_critic_min 0.4 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.71 / train/extr_return_normed_max 0.71 / train/extr_return_normed_mean 0.02 / 
train/extr_return_normed_min -0.02 / train/extr_return_normed_std 0.04 / train/extr_return_rate 0.06 / train/extr_return_raw_mag 1.12 / train/extr_return_raw_max 1.12 / train/extr_return_raw_mean 0.43 / train/extr_return_raw_min 0.4 / train/extr_return_raw_std 0.04 / 
train/extr_reward_mag 0.23 / train/extr_reward_max 0.23 / train/extr_reward_mean 2.3e-4 / train/extr_reward_min 1.2e-9 / train/extr_reward_std 5.4e-3 / train/image_loss_mean 1.59 / train/image_loss_std 1.6 / train/model_loss_mean 3.45 / train/model_loss_std 4.31 / 
train/model_opt_grad_norm 9.66 / train/model_opt_grad_steps 2.4e4 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8958.33 / train/policy_entropy_mag 5.66 / train/policy_entropy_max 5.66 / 
train/policy_entropy_mean 4.6 / train/policy_entropy_min -2.35 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 15.73 / train/policy_logprob_max 3.53 / train/policy_logprob_mean -4.6 / train/policy_logprob_min -15.73 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.88 / train/policy_randomness_min 0.13 / train/policy_randomness_std 0.12 / train/post_ent_mag 35.86 / train/post_ent_max 35.86 / train/post_ent_mean 26.38 / train/post_ent_min 
16.69 / train/post_ent_std 3.34 / train/prior_ent_mag 63.85 / train/prior_ent_max 63.85 / train/prior_ent_mean 29.55 / train/prior_ent_min 19.47 / train/prior_ent_std 5.86 / train/rep_loss_mean 3.1 / train/rep_loss_std 5.33 / train/reward_avg 3.1e-4 / 
train/reward_loss_mean 5.8e-4 / train/reward_loss_std 9.3e-3 / train/reward_max_data 0.1 / train/reward_max_pred 0.1 / train/reward_neg_acc 1 / train/reward_neg_loss 2.1e-4 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.62 / train/reward_pred 3e-4 / 
train/reward_rate 5.8e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 3.67 / report/cont_avg 1 / report/cont_loss_mean 5.1e-10 / report/cont_loss_std 4.3e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 5.1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.97 / report/dyn_loss_std 5.18 / report/image_loss_mean 1.41 / report/image_loss_std 1.26 / report/model_loss_mean 3.19 / report/model_loss_std 3.95 / report/post_ent_mag 36 / 
report/post_ent_max 36 / report/post_ent_mean 26.72 / report/post_ent_min 16.13 / report/post_ent_std 3.08 / report/prior_ent_mag 64.33 / report/prior_ent_max 64.33 / report/prior_ent_mean 30.12 / report/prior_ent_min 18.86 / report/prior_ent_std 5.52 / 
report/rep_loss_mean 2.97 / report/rep_loss_std 5.18 / report/reward_avg 0 / report/reward_loss_mean 1.4e-7 / report/reward_loss_std 1.3e-6 / report/reward_max_data 0 / report/reward_max_pred 1.8e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-7 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-10 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
5.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.07 / eval/dyn_loss_std 8.36 / eval/image_loss_mean 2.74 / eval/image_loss_std 3.99 / eval/model_loss_mean 6.42 / eval/model_loss_std 8.62 / eval/post_ent_mag 37.57 / eval/post_ent_max 37.57 / 
eval/post_ent_mean 26.66 / eval/post_ent_min 16.41 / eval/post_ent_std 3.47 / eval/prior_ent_mag 64.33 / eval/prior_ent_max 64.33 / eval/prior_ent_mean 30.34 / eval/prior_ent_min 20.78 / eval/prior_ent_std 5.99 / eval/rep_loss_mean 6.07 / eval/rep_loss_std 8.36 / 
eval/reward_avg 2.7e-4 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.47 / eval/reward_max_data 0.14 / eval/reward_max_pred 0.58 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 8.17 / eval/reward_pred 3.7e-3 / 
eval/reward_rate 9.8e-4 / replay/size 5e4 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.1e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3826 / timer/env.step_total 20.2 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 446.53 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-3 / 
timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 16.28 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 8.7e-3 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1913 / 
timer/agent.train_total 244.67 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 50500 Counter(50500) 50437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223318F976821-49I3s1khn41IPDYAM0uXuN-3Dgu3uSDxbrqttCHsSV1zz-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 51000 Counter(51000) 50937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223411F030551-5wApFcC5OL6FsSF9N5NItV-0tfBM16b61pzJKpB0AQGlq-1024.npz
Starting evaluation at step 51500 Counter(51500) 51437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 52000 Counter(52000) 51937
Saved chunk: 20230921T223438F378177-3Dgu3uSDxbrqttCHsSV1zz-3IuPx9UpIC3fOirynS7IiX-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223532F294238-0tfBM16b61pzJKpB0AQGlq-6i8wUhFXTOQILufiTgUWzV-1024.npz
Starting evaluation at step 52500 Counter(52500) 52437
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 53000 Counter(53000) 52937
Saved chunk: 20230921T223633F324405-3IuPx9UpIC3fOirynS7IiX-4sHEu6F5DDpSMkNgzv4oPl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223652F671392-6i8wUhFXTOQILufiTgUWzV-1i3JZgKpLTcnSZsHOEjbAj-1024.npz
Starting evaluation at step 53500 Counter(53500) 53437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 54000 Counter(54000) 53937
Saved chunk: 20230921T223752F120406-4sHEu6F5DDpSMkNgzv4oPl-1n9IYqBq3hQ798IFNKWXaN-1024.npz
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 108418 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0.12 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 5.09 / train/action_max 4.85 / train/action_mean -0.15 / train/action_min -4.99 / train/action_std 1.29 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.6e-3 / train/actor_opt_grad_steps 2.6e4 / train/actor_opt_loss 18.13 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean -3.4e-3 / train/adv_min -0.31 
/ train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 3.7e-10 / train/cont_loss_std 1.2e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.24 /
train/dyn_loss_std 5.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.6e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 1 / train/extr_critic_max 1 / train/extr_critic_mean 0.31 / train/extr_critic_min 0.29 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.85 / train/extr_return_normed_max 0.85 / train/extr_return_normed_mean 2.3e-3 / 
train/extr_return_normed_min -0.01 / train/extr_return_normed_std 0.03 / train/extr_return_rate 1.1e-3 / train/extr_return_raw_mag 1.15 / train/extr_return_raw_max 1.15 / train/extr_return_raw_mean 0.31 / train/extr_return_raw_min 0.29 / train/extr_return_raw_std 0.03 / 
train/extr_reward_mag 0.25 / train/extr_reward_max 0.25 / train/extr_reward_mean 3e-4 / train/extr_reward_min 0 / train/extr_reward_std 6.7e-3 / train/image_loss_mean 1.64 / train/image_loss_std 1.69 / train/model_loss_mean 3.59 / train/model_loss_std 4.5 / 
train/model_opt_grad_norm 10.03 / train/model_opt_grad_steps 2.6e4 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.12 / train/policy_entropy_min -2.13 / train/policy_entropy_std 0.72 / train/policy_logprob_mag 16.11 / train/policy_logprob_max 3.29 / train/policy_logprob_mean -5.12 / train/policy_logprob_min -16.11 / train/policy_logprob_std 1.59 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.94 / train/policy_randomness_min 0.15 / train/policy_randomness_std 0.08 / train/post_ent_mag 36.53 / train/post_ent_max 36.53 / train/post_ent_mean 27.15 / train/post_ent_min 
17.25 / train/post_ent_std 3.35 / train/prior_ent_mag 65.18 / train/prior_ent_max 65.18 / train/prior_ent_mean 30.45 / train/prior_ent_min 20.15 / train/prior_ent_std 5.9 / train/rep_loss_mean 3.24 / train/rep_loss_std 5.53 / train/reward_avg 3.8e-4 / 
train/reward_loss_mean 7.9e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.12 / train/reward_max_pred 0.12 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.58 / train/reward_pred 3.9e-4 / 
train/reward_rate 7.8e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 4.66 / report/cont_avg 1 / report/cont_loss_mean 2.5e-10 / report/cont_loss_std 4.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.2 / report/dyn_loss_std 5.56 / report/image_loss_mean 1.53 / report/image_loss_std 1.21 / report/model_loss_mean 3.45 / report/model_loss_std 4.13 / report/post_ent_mag 36.51 /
report/post_ent_max 36.51 / report/post_ent_mean 28.24 / report/post_ent_min 18.48 / report/post_ent_std 3.05 / report/prior_ent_mag 65.8 / report/prior_ent_max 65.8 / report/prior_ent_mean 31.44 / report/prior_ent_min 21.8 / report/prior_ent_std 5.54 / 
report/rep_loss_mean 3.2 / report/rep_loss_std 5.56 / report/reward_avg 0 / report/reward_loss_mean 1.3e-6 / report/reward_loss_std 2.8e-5 / report/reward_max_data 0 / report/reward_max_pred 1.4e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 2.7e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-10 / eval/cont_loss_std 7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
3.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.33 / eval/dyn_loss_std 9.41 / eval/image_loss_mean 2.68 / eval/image_loss_std 4.32 / eval/model_loss_mean 6.47 / eval/model_loss_std 9.55 / eval/post_ent_mag 37.26 / eval/post_ent_max 37.26 / 
eval/post_ent_mean 28.41 / eval/post_ent_min 19.88 / eval/post_ent_std 3.36 / eval/prior_ent_mag 65.8 / eval/prior_ent_max 65.8 / eval/prior_ent_mean 31.83 / eval/prior_ent_min 20.54 / eval/prior_ent_std 6.2 / eval/rep_loss_mean 6.33 / eval/rep_loss_std 9.41 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.7e-6 / eval/reward_loss_std 4.8e-5 / eval/reward_max_data 0 / eval/reward_max_pred 4.6e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 5.1e-7 / 
eval/reward_rate 0 / replay/size 5.4e4 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.5e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3786 / timer/env.step_total 19.9 / timer/env.step_frac 0.07 / 
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.6e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.9 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / 
timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.09 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1893 / 
timer/agent.train_total 241.67 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.3e-5 / timer/dataset_eval_frac 7.8e-8 / timer/dataset_eval_avg 2.3e-5 / timer/dataset_eval_min 2.3e-5 / timer/dataset_eval_max 2.3e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T223813F060522-1i3JZgKpLTcnSZsHOEjbAj-22ZYSvjLQxNEGahRn4zg3P-1024.npz
Starting evaluation at step 54500 Counter(54500) 54437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 55000 Counter(55000) 54937
Saved chunk: 20230921T223910F820015-1n9IYqBq3hQ798IFNKWXaN-3pE9cVpt3w5R7VOAUTN2jo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223933F964855-22ZYSvjLQxNEGahRn4zg3P-3O6BxJQCto43ZtZWnbR7gg-1024.npz
Starting evaluation at step 55500 Counter(55500) 55437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 56000 Counter(56000) 55937
Saved chunk: 20230921T224030F562547-3pE9cVpt3w5R7VOAUTN2jo-2cOnPd8dfbjD8YVDDvCPH5-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224054F739131-3O6BxJQCto43ZtZWnbR7gg-06t1be9SWW7xyJKGPnIu8V-1024.npz
Starting evaluation at step 56500 Counter(56500) 56437
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 57000 Counter(57000) 56937
Saved chunk: 20230921T224149F507566-2cOnPd8dfbjD8YVDDvCPH5-5KCFtEWeijtdFULHli2wd3-1024.npz
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T224308F336707-5KCFtEWeijtdFULHli2wd3-0000000000000000000000-369.npz
Saved chunk: 20230921T224215F230239-06t1be9SWW7xyJKGPnIu8V-0000000000000000000000-781.npz
train_Episode has 500 steps and return 0.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T224215F230239-06t1be9SWW7xyJKGPnIu8V-16JFVib5aGnYhex9RN5alS-1024.npz
Starting evaluation at step 57500 Counter(57500) 57437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.4.
Starting evaluation at step 58000 Counter(58000) 57937
Saved chunk: 20230921T224308F336707-5KCFtEWeijtdFULHli2wd3-27BcQOkGtiO2a5Ahyjlrcw-1024.npz
eval_Episode has 500 steps and return 0.1.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 116002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0.11 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0.36 / episode/reward_rate 2e-3 / train/action_mag 5.17 / train/action_max 4.97 / train/action_mean -0.16 / train/action_min -5.06 / train/action_std 1.32 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.7e-3 / train/actor_opt_grad_steps 2.8e4 / train/actor_opt_loss 7.54 / train/adv_mag 0.53 / train/adv_max 0.39 / train/adv_mean -2.4e-3 / train/adv_min -0.36 
/ train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 3.2e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.2 / 
train/dyn_loss_std 5.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 2.8e4 / train/extr_critic_critic_opt_loss 
7290.55 / train/extr_critic_mag 0.94 / train/extr_critic_max 0.94 / train/extr_critic_mean 0.19 / train/extr_critic_min 0.18 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.83 / train/extr_return_normed_max 0.83 / train/extr_return_normed_mean 4.6e-3 / 
train/extr_return_normed_min -9.4e-3 / train/extr_return_normed_std 0.03 / train/extr_return_rate 7.7e-4 / train/extr_return_raw_mag 1.02 / train/extr_return_raw_max 1.02 / train/extr_return_raw_mean 0.19 / train/extr_return_raw_min 0.18 / train/extr_return_raw_std 0.03 /
train/extr_reward_mag 0.27 / train/extr_reward_max 0.27 / train/extr_reward_mean 2.4e-4 / train/extr_reward_min 0 / train/extr_reward_std 6.2e-3 / train/image_loss_mean 1.55 / train/image_loss_std 1.55 / train/model_loss_mean 3.48 / train/model_loss_std 4.4 / 
train/model_opt_grad_norm 10.08 / train/model_opt_grad_steps 2.7e4 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.41 / train/policy_entropy_min -1.91 / train/policy_entropy_std 0.5 / train/policy_logprob_mag 16.32 / train/policy_logprob_max 3.02 / train/policy_logprob_mean -5.41 / train/policy_logprob_min -16.32 / train/policy_logprob_std 1.51 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.97 / train/policy_randomness_min 0.18 / train/policy_randomness_std 0.05 / train/post_ent_mag 37.08 / train/post_ent_max 37.08 / train/post_ent_mean 27.79 / train/post_ent_min 
17.68 / train/post_ent_std 3.35 / train/prior_ent_mag 66.3 / train/prior_ent_max 66.3 / train/prior_ent_mean 31.02 / train/prior_ent_min 20.57 / train/prior_ent_std 5.9 / train/rep_loss_mean 3.2 / train/rep_loss_std 5.57 / train/reward_avg 2.8e-4 / train/reward_loss_mean 
6.2e-4 / train/reward_loss_std 9.1e-3 / train/reward_max_data 0.11 / train/reward_max_pred 0.11 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 0.63 / train/reward_pred 2.8e-4 / train/reward_rate 5.1e-4 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 4.79 / report/cont_avg 1 / report/cont_loss_mean 1.6e-10 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.27 / report/dyn_loss_std 5.89 / report/image_loss_mean 1.56 / report/image_loss_std 1.44 / report/model_loss_mean 3.52 / report/model_loss_std 4.51 / report/post_ent_mag 37.57 / report/post_ent_max 37.57 / 
report/post_ent_mean 27.9 / report/post_ent_min 17.38 / report/post_ent_std 3.25 / report/prior_ent_mag 66.96 / report/prior_ent_max 66.96 / report/prior_ent_mean 31.22 / report/prior_ent_min 19.3 / report/prior_ent_std 5.72 / report/rep_loss_mean 3.27 / 
report/rep_loss_std 5.89 / report/reward_avg 8.5e-5 / report/reward_loss_mean 2e-3 / report/reward_loss_std 0.02 / report/reward_max_data 0.02 / report/reward_max_pred 0.03 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 9.1e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-10 / eval/cont_loss_std 4.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.47 / eval/dyn_loss_std 6.59 / eval/image_loss_mean 1.47 / eval/image_loss_std 3.9 / eval/model_loss_mean 3.63 / eval/model_loss_std 7.72 / eval/post_ent_mag 40.18 / eval/post_ent_max 40.18 / eval/post_ent_mean 29.83 / 
eval/post_ent_min 16.97 / eval/post_ent_std 3.43 / eval/prior_ent_mag 66.96 / eval/prior_ent_max 66.96 / eval/prior_ent_mean 32.51 / eval/prior_ent_min 23.13 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 3.47 / eval/rep_loss_std 6.59 / eval/reward_avg 4.4e-3 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 1.12 / eval/reward_max_data 1.2 / eval/reward_max_pred 4.1e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.6e-4 / eval/reward_pos_acc 0 / eval/reward_pos_loss 16.07 / eval/reward_pred 8.2e-6 / eval/reward_rate 4.9e-3 /
replay/size 5.8e4 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.9e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.92 / timer/env.step_count 3792 / timer/env.step_total 20.02 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 442.98 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7800 / timer/agent.policy_total 17.34 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1896 / timer/agent.train_total 242.23 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.2

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224335F724600-16JFVib5aGnYhex9RN5alS-7JdGbwoAS0RS2UmjYBGcSl-1024.npz
Starting evaluation at step 58500 Counter(58500) 58437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 59000 Counter(59000) 58937
Saved chunk: 20230921T224427F259160-27BcQOkGtiO2a5Ahyjlrcw-4PbStwBOd98ipiR3FvkGbg-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224456F795779-7JdGbwoAS0RS2UmjYBGcSl-1YUxVskvhkMh3EOwn85I2z-1024.npz
Starting evaluation at step 59500 Counter(59500) 59437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 60000 Counter(60000) 59937
Saved chunk: 20230921T224547F091913-4PbStwBOd98ipiR3FvkGbg-2qZDv3xvAYUzc1WfFBUdKa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224617F551139-1YUxVskvhkMh3EOwn85I2z-2N3ehtZoG8QcrqHNcDsxUe-1024.npz
Starting evaluation at step 60500 Counter(60500) 60437
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 61000 Counter(61000) 60937
Saved chunk: 20230921T224706F098181-2qZDv3xvAYUzc1WfFBUdKa-26LP2aBlwa074smhKA7Q4y-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 3.7.
Saved chunk: 20230921T224738F013670-2N3ehtZoG8QcrqHNcDsxUe-5139eBynl1CWBpSJe6TVSv-1024.npz
Starting evaluation at step 61500 Counter(61500) 61437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 123660 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 5.17 / train/action_max 4.98 / train/action_mean -0.07 / train/action_min -5.06 / train/action_std 1.34 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.8e-3 / train/actor_opt_grad_steps 2.9e4 / train/actor_opt_loss -3.21 / train/adv_mag 0.57 / train/adv_max 0.44 / train/adv_mean -1.3e-3 / train/adv_min -0.4 
/ train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 2.6e-10 / train/cont_loss_std 1.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.14 /
train/dyn_loss_std 5.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 2.9e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 1 / train/extr_critic_max 1 / train/extr_critic_mean 0.12 / train/extr_critic_min 0.11 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.97 / train/extr_return_normed_max 0.97 / train/extr_return_normed_mean 3.3e-3 / 
train/extr_return_normed_min -5.7e-3 / train/extr_return_normed_std 0.03 / train/extr_return_rate 8.8e-4 / train/extr_return_raw_mag 1.09 / train/extr_return_raw_max 1.09 / train/extr_return_raw_mean 0.12 / train/extr_return_raw_min 0.11 / train/extr_return_raw_std 0.03 /
train/extr_reward_mag 0.32 / train/extr_reward_max 0.32 / train/extr_reward_mean 2.8e-4 / train/extr_reward_min -1.8e-6 / train/extr_reward_std 7e-3 / train/image_loss_mean 1.46 / train/image_loss_std 1.47 / train/model_loss_mean 3.34 / train/model_loss_std 4.35 / 
train/model_opt_grad_norm 9.06 / train/model_opt_grad_steps 2.9e4 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.55 / train/policy_entropy_min -1.86 / train/policy_entropy_std 0.41 / train/policy_logprob_mag 16.34 / train/policy_logprob_max 3.05 / train/policy_logprob_mean -5.55 / train/policy_logprob_min -16.34 / train/policy_logprob_std 1.48 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.18 / train/policy_randomness_std 0.04 / train/post_ent_mag 38.08 / train/post_ent_max 38.08 / train/post_ent_mean 28.5 / train/post_ent_min 
17.99 / train/post_ent_std 3.43 / train/prior_ent_mag 67.21 / train/prior_ent_max 67.21 / train/prior_ent_mean 31.69 / train/prior_ent_min 21.14 / train/prior_ent_std 5.89 / train/rep_loss_mean 3.14 / train/rep_loss_std 5.6 / train/reward_avg 3.3e-4 / 
train/reward_loss_mean 7e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.12 / train/reward_max_pred 0.11 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-4 / train/reward_pos_acc 0.9 / train/reward_pos_loss 0.7 / train/reward_pred 3.2e-4 / train/reward_rate
6.5e-4 / train_stats/mean_log_entropy 5.54 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.4e-10 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.96 / report/dyn_loss_std 5.49 / report/image_loss_mean 1.24 / report/image_loss_std 1.08 / report/model_loss_mean 3.01 / report/model_loss_std 4.06 / report/post_ent_mag 37.33 / report/post_ent_max 37.33 / 
report/post_ent_mean 29.13 / report/post_ent_min 16.92 / report/post_ent_std 3.11 / report/prior_ent_mag 67.71 / report/prior_ent_max 67.71 / report/prior_ent_mean 32.09 / report/prior_ent_min 23.18 / report/prior_ent_std 5.69 / report/rep_loss_mean 2.96 / 
report/rep_loss_std 5.49 / report/reward_avg 0 / report/reward_loss_mean 2e-7 / report/reward_loss_std 5.1e-6 / report/reward_max_data 0 / report/reward_max_pred 2.5e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-7 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 3.8e-8 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.03 / eval/dyn_loss_std 5.9 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.39 / eval/model_loss_mean 2.79 / eval/model_loss_std 4.68 / eval/post_ent_mag 37.42 / eval/post_ent_max 37.42 / eval/post_ent_mean 29.99 / 
eval/post_ent_min 20.47 / eval/post_ent_std 3.58 / eval/prior_ent_mag 67.71 / eval/prior_ent_max 67.71 / eval/prior_ent_mean 31.67 / eval/prior_ent_min 20.62 / eval/prior_ent_std 5.91 / eval/rep_loss_mean 3.03 / eval/rep_loss_std 5.9 / eval/reward_avg 0 / 
eval/reward_loss_mean 4.9e-8 / eval/reward_loss_std 8.5e-7 / eval/reward_max_data 0 / eval/reward_max_pred 1e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.9e-8 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 2.2e-8 / eval/reward_rate 0 / 
replay/size 6.2e4 / replay/inserts 3829 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.2e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3829 / timer/env.step_total 20.22 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 448.31 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7336 / timer/agent.policy_total 16.37 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / 
timer/dataset_train_count 1914 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1914 / timer/agent.train_total 244.49 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 62000 Counter(62000) 61937
Saved chunk: 20230921T224824F844309-26LP2aBlwa074smhKA7Q4y-0M9qB1P9tllvOpi2UqgAsE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224858F384087-5139eBynl1CWBpSJe6TVSv-5z6cQv5ApHWkD07mozJD08-1024.npz
Starting evaluation at step 62500 Counter(62500) 62437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 63000 Counter(63000) 62937
Saved chunk: 20230921T224944F409570-0M9qB1P9tllvOpi2UqgAsE-4flUJlecr81K8EyQ4hf9UY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.2.
Saved chunk: 20230921T225019F779237-5z6cQv5ApHWkD07mozJD08-55uH0wrsXrZBVpEYBXuGVZ-1024.npz
Starting evaluation at step 63500 Counter(63500) 63437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 64000 Counter(64000) 63937
Saved chunk: 20230921T225104F296328-4flUJlecr81K8EyQ4hf9UY-3GPu05zj4fgZQLSXBlDDj5-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 64500 Counter(64500) 64437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225140F971177-55uH0wrsXrZBVpEYBXuGVZ-02dTz34sPo7qXLSqRq1p3h-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 65000 Counter(65000) 64937
Saved chunk: 20230921T225223F075421-3GPu05zj4fgZQLSXBlDDj5-6mcK0Ix1b7bhOAWSGbhEa9-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 2.6.
Starting evaluation at step 65500 Counter(65500) 65437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225304F802036-02dTz34sPo7qXLSqRq1p3h-3Q3ISP3LxcOkuwBAGqehOc-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 131202 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 2.62 / episode/reward_rate 1e-2 / train/action_mag 5.19 / train/action_max 4.99 / train/action_mean -0.03 / train/action_min -5.07 / train/action_std 1.34 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.7e-3 / train/actor_opt_grad_steps 3.1e4 / train/actor_opt_loss -10.1 / train/adv_mag 0.46 / train/adv_max 0.37 / train/adv_mean -6.4e-4 / train/adv_min -0.29
/ train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 2.2e-10 / train/cont_loss_std 8.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.2 /
train/dyn_loss_std 5.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 3.1e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 0.78 / train/extr_critic_max 0.78 / train/extr_critic_mean 0.08 / train/extr_critic_min 0.07 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.86 / train/extr_return_normed_max 0.86 / train/extr_return_normed_mean 3.9e-3 / 
train/extr_return_normed_min -3.6e-3 / train/extr_return_normed_std 0.03 / train/extr_return_rate 7.9e-4 / train/extr_return_raw_mag 0.93 / train/extr_return_raw_max 0.93 / train/extr_return_raw_mean 0.08 / train/extr_return_raw_min 0.07 / train/extr_return_raw_std 0.03 /
train/extr_reward_mag 0.27 / train/extr_reward_max 0.27 / train/extr_reward_mean 3e-4 / train/extr_reward_min 0 / train/extr_reward_std 6.8e-3 / train/image_loss_mean 1.45 / train/image_loss_std 1.48 / train/model_loss_mean 3.37 / train/model_loss_std 4.42 / 
train/model_opt_grad_norm 10.12 / train/model_opt_grad_steps 3.1e4 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 5.57 / train/policy_entropy_min -1.43 / train/policy_entropy_std 0.35 / train/policy_logprob_mag 16.36 / train/policy_logprob_max 2.45 / train/policy_logprob_mean -5.57 / train/policy_logprob_min -16.36 / train/policy_logprob_std 1.47 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.23 / train/policy_randomness_std 0.04 / train/post_ent_mag 38.78 / train/post_ent_max 38.78 / train/post_ent_mean 29.24 / train/post_ent_min 
18.44 / train/post_ent_std 3.47 / train/prior_ent_mag 68.24 / train/prior_ent_max 68.24 / train/prior_ent_mean 32.41 / train/prior_ent_min 21.92 / train/prior_ent_std 5.9 / train/rep_loss_mean 3.2 / train/rep_loss_std 5.66 / train/reward_avg 4.2e-4 / 
train/reward_loss_mean 7.5e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.14 / train/reward_max_pred 0.14 / train/reward_neg_acc 1 / train/reward_neg_loss 2.5e-4 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.62 / train/reward_pred 4.2e-4 / 
train/reward_rate 7.8e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 5.41 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 4.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.69 / report/dyn_loss_std 4.72 / report/image_loss_mean 1.03 / report/image_loss_std 1.04 / report/model_loss_mean 2.65 / report/model_loss_std 3.58 / report/post_ent_mag 37.57 / 
report/post_ent_max 37.57 / report/post_ent_mean 29.86 / report/post_ent_min 18.46 / report/post_ent_std 3.04 / report/prior_ent_mag 68.68 / report/prior_ent_max 68.68 / report/prior_ent_mean 33 / report/prior_ent_min 23.29 / report/prior_ent_std 5.48 / 
report/rep_loss_mean 2.69 / report/rep_loss_std 4.72 / report/reward_avg 0 / report/reward_loss_mean 4.7e-7 / report/reward_loss_std 1.2e-5 / report/reward_max_data 0 / report/reward_max_pred 6.3e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 4.7e-7 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 8.4e-8 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-10 / eval/cont_loss_std 6.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.41 / eval/dyn_loss_std 7.31 / eval/image_loss_mean 1.66 / eval/image_loss_std 2.77 / eval/model_loss_mean 4.3 / eval/model_loss_std 6.78 / eval/post_ent_mag 38.57 / eval/post_ent_max 
38.57 / eval/post_ent_mean 29.49 / eval/post_ent_min 18.96 / eval/post_ent_std 3.35 / eval/prior_ent_mag 68.68 / eval/prior_ent_max 68.68 / eval/prior_ent_mean 32.89 / eval/prior_ent_min 23.21 / eval/prior_ent_std 6.08 / eval/rep_loss_mean 4.41 / eval/rep_loss_std 7.31 / 
eval/reward_avg 0 / eval/reward_loss_mean 2e-7 / eval/reward_loss_std 4.3e-6 / eval/reward_max_data 0 / eval/reward_max_pred 2.2e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 4.6e-8 / 
eval/reward_rate 0 / replay/size 6.6e4 / replay/inserts 3771 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.6e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3771 / timer/env.step_total 19.86 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.6e-3 / timer/env.step_max 7.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.55 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-3 / 
timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7779 / timer/agent.policy_total 17.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.66 / timer/dataset_train_count 1886 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1886 / 
timer/agent.train_total 240.92 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.2e-5 / timer/dataset_eval_frac 7.3e-8 / timer/dataset_eval_avg 2.2e-5 / timer/dataset_eval_min 2.2e-5 / timer/dataset_eval_max 2.2e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 66000 Counter(66000) 65937
Saved chunk: 20230921T225341F879659-6mcK0Ix1b7bhOAWSGbhEa9-5gLgx06HJChRXm7KvdRulb-1024.npz
eval_Episode has 500 steps and return 0.6.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 66500 Counter(66500) 66437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225425F216870-3Q3ISP3LxcOkuwBAGqehOc-2MaA8zwZaQgeyARUsoWMPW-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 67000 Counter(67000) 66937
Saved chunk: 20230921T225501F540311-5gLgx06HJChRXm7KvdRulb-4v3fGgnz3IsWoKNYmI2CB2-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 67500 Counter(67500) 67437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225546F684382-2MaA8zwZaQgeyARUsoWMPW-1yHfb6eUqwwydL6bhgBZ2I-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 68000 Counter(68000) 67937
Saved chunk: 20230921T225620F774509-4v3fGgnz3IsWoKNYmI2CB2-6KkytibChJq7gIrdvleqgG-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.7.
Starting evaluation at step 68500 Counter(68500) 68437
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T225739F706339-6KkytibChJq7gIrdvleqgG-0000000000000000000000-628.npz
Saved chunk: 20230921T225707F264109-1yHfb6eUqwwydL6bhgBZ2I-0000000000000000000000-1016.npz
Saved chunk: 20230921T225707F264109-1yHfb6eUqwwydL6bhgBZ2I-5puX1o6uqhoEduC4n64SU4-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 69000 Counter(69000) 68937
Saved chunk: 20230921T225739F706339-6KkytibChJq7gIrdvleqgG-2FRHZ7VXEZBkisrus5SCeS-1024.npz
eval_Episode has 500 steps and return 0.3.
train_Episode has 500 steps and return 0.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 138848 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0.33 / eval_episode/reward_rate 4e-3 / train/action_mag 5.22 / train/action_max 5.05 / train/action_mean -0.02 / train/action_min -5.06 / train/action_std 1.33 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.01 / train/actor_opt_grad_steps 3.3e4 / train/actor_opt_loss -11.91 / train/adv_mag 0.52 / train/adv_max 0.4 / train/adv_mean -4.6e-4 / train/adv_min -0.36 /
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 2.1e-10 / train/cont_loss_std 8.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.21 / 
train/dyn_loss_std 5.69 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 3.3e4 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 0.9 / train/extr_critic_max 0.9 / train/extr_critic_mean 0.05 / train/extr_critic_min 0.05 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.97 / train/extr_return_normed_max 0.97 / train/extr_return_normed_mean 2.6e-3 / 
train/extr_return_normed_min -2.8e-3 / train/extr_return_normed_std 0.03 / train/extr_return_rate 8.5e-4 / train/extr_return_raw_mag 1.02 / train/extr_return_raw_max 1.02 / train/extr_return_raw_mean 0.05 / train/extr_return_raw_min 0.05 / train/extr_return_raw_std 0.03 /
train/extr_reward_mag 0.31 / train/extr_reward_max 0.31 / train/extr_reward_mean 3.3e-4 / train/extr_reward_min -1.9e-9 / train/extr_reward_std 7.7e-3 / train/image_loss_mean 1.42 / train/image_loss_std 1.41 / train/model_loss_mean 3.35 / train/model_loss_std 4.38 / 
train/model_opt_grad_norm 9.44 / train/model_opt_grad_steps 3.3e4 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 5.68 / train/policy_entropy_max 5.68 / 
train/policy_entropy_mean 5.61 / train/policy_entropy_min -1.96 / train/policy_entropy_std 0.38 / train/policy_logprob_mag 16.46 / train/policy_logprob_max 3.08 / train/policy_logprob_mean -5.61 / train/policy_logprob_min -16.46 / train/policy_logprob_std 1.48 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.99 / train/policy_randomness_min 0.17 / train/policy_randomness_std 0.04 / train/post_ent_mag 39.43 / train/post_ent_max 39.43 / train/post_ent_mean 29.85 / train/post_ent_min 
18.7 / train/post_ent_std 3.48 / train/prior_ent_mag 69.36 / train/prior_ent_max 69.36 / train/prior_ent_mean 33.07 / train/prior_ent_min 22.29 / train/prior_ent_std 5.95 / train/rep_loss_mean 3.21 / train/rep_loss_std 5.69 / train/reward_avg 4.4e-4 / 
train/reward_loss_mean 8.7e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.16 / train/reward_max_pred 0.16 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-4 / train/reward_pos_acc 0.92 / train/reward_pos_loss 0.68 / train/reward_pred 4.4e-4 / 
train/reward_rate 8e-4 / train_stats/mean_log_entropy 5.54 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-10 / report/cont_loss_std 8.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.7e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.91 / report/dyn_loss_std 5.84 / report/image_loss_mean 1.14 / report/image_loss_std 1.48 / report/model_loss_mean 2.88 / report/model_loss_std 4.45 / report/post_ent_mag 38.78 
/ report/post_ent_max 38.78 / report/post_ent_mean 29.33 / report/post_ent_min 19.31 / report/post_ent_std 4.02 / report/prior_ent_mag 69.55 / report/prior_ent_max 69.55 / report/prior_ent_mean 32.12 / report/prior_ent_min 20.94 / report/prior_ent_std 6.61 / 
report/rep_loss_mean 2.91 / report/rep_loss_std 5.84 / report/reward_avg 0 / report/reward_loss_mean 6.8e-6 / report/reward_loss_std 1.7e-4 / report/reward_max_data 0 / report/reward_max_pred 8.7e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 6.8e-6 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.1e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-10 / eval/cont_loss_std 1.9e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.86 / eval/dyn_loss_std 7.73 / eval/image_loss_mean 1.81 / eval/image_loss_std 3.07 / eval/model_loss_mean 4.72 / eval/model_loss_std 7.34 / eval/post_ent_mag 38.23 / eval/post_ent_max 
38.23 / eval/post_ent_mean 29.96 / eval/post_ent_min 18.89 / eval/post_ent_std 3.1 / eval/prior_ent_mag 69.55 / eval/prior_ent_max 69.55 / eval/prior_ent_mean 32.83 / eval/prior_ent_min 22.36 / eval/prior_ent_std 6.2 / eval/rep_loss_mean 4.86 / eval/rep_loss_std 7.73 / 
eval/reward_avg 0 / eval/reward_loss_mean 2.8e-8 / eval/reward_loss_std 2.1e-7 / eval/reward_max_data 0 / eval/reward_max_pred 8.3e-7 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-8 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 6.9e-9 / 
eval/reward_rate 0 / replay/size 6.9e4 / replay/inserts 3823 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3823 / timer/env.step_total 20.18 / timer/env.step_frac 0.07 /
timer/env.step_avg 5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.38 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / 
timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7330 / timer/agent.policy_total 16.5 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1911 / timer/agent.train_total 244.42 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / 
timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.49

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 69500 Counter(69500) 69437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225827F839318-5puX1o6uqhoEduC4n64SU4-5xserXW8frlQMwCTGIWcja-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 70000 Counter(70000) 69937
Saved chunk: 20230921T225858F756385-2FRHZ7VXEZBkisrus5SCeS-7cGDHVGCMOhYJEcKtDdr2O-1024.npz
eval_Episode has 500 steps and return 1.6.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 70500 Counter(70500) 70437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225949F128130-5xserXW8frlQMwCTGIWcja-4DCimDG0RoFMMjVclLqF2K-1024.npz
Starting evaluation at step 71000 Counter(71000) 70937
Saved chunk: 20230921T230018F605593-7cGDHVGCMOhYJEcKtDdr2O-63zaQgNKvRawsir5iiiujf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.6.
Starting evaluation at step 71500 Counter(71500) 71437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.1.
Saved chunk: 20230921T230109F990826-4DCimDG0RoFMMjVclLqF2K-3gGmx0Gn9hKkALMIKW1LsU-1024.npz
Starting evaluation at step 72000 Counter(72000) 71937
Saved chunk: 20230921T230137F756074-63zaQgNKvRawsir5iiiujf-4gosqx63lJJAHEO3xF7sfG-1024.npz
eval_Episode has 500 steps and return 0.1.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 72500 Counter(72500) 72437
eval_Episode has 500 steps and return 9.6.
train_Episode has 500 steps and return 4.9.
Saved chunk: 20230921T230230F500402-3gGmx0Gn9hKkALMIKW1LsU-14Sl8u2H9rlyp2PmJtQXSA-1024.npz
Starting evaluation at step 73000 Counter(73000) 72937
eval_Episode has 500 steps and return 3.2.
Saved chunk: 20230921T230256F599496-4gosqx63lJJAHEO3xF7sfG-43jvSLhvlHGjlw3oWi3Oh6-1024.npz
train_Episode has 500 steps and return 10.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 146406 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 3.2 / eval_episode/reward_rate 0.03 / episode/length 500 / episode/score 9.96 / episode/reward_rate 0.06 / train/action_mag 5.06 / train/action_max 4.91 / train/action_mean 0.14 / train/action_min -4.86 / train/action_std 1.25 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.04 / train/actor_opt_grad_steps 3.5e4 / train/actor_opt_loss -117.9 / train/adv_mag 0.61 / train/adv_max 0.51 / train/adv_mean 0.01 / train/adv_min -0.42 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.1e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.26 / 
train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.23 / train/extr_critic_critic_opt_grad_steps 3.5e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 0.94 / train/extr_critic_max 0.94 / train/extr_critic_mean 0.09 / train/extr_critic_min 0.05 / train/extr_critic_std 0.05 / train/extr_return_normed_mag 0.98 / train/extr_return_normed_max 0.98 / train/extr_return_normed_mean 0.04 / 
train/extr_return_normed_min -1.3e-3 / train/extr_return_normed_std 0.06 / train/extr_return_rate 0.02 / train/extr_return_raw_mag 1.03 / train/extr_return_raw_max 1.03 / train/extr_return_raw_mean 0.1 / train/extr_return_raw_min 0.05 / train/extr_return_raw_std 0.06 / 
train/extr_reward_mag 0.29 / train/extr_reward_max 0.29 / train/extr_reward_mean 5.9e-4 / train/extr_reward_min -1.5e-8 / train/extr_reward_std 7.9e-3 / train/image_loss_mean 1.44 / train/image_loss_std 1.44 / train/model_loss_mean 3.4 / train/model_loss_std 4.5 / 
train/model_opt_grad_norm 9.23 / train/model_opt_grad_steps 3.5e4 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 5.67 / train/policy_entropy_max 5.67 / 
train/policy_entropy_mean 4.36 / train/policy_entropy_min -2.89 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 15.57 / train/policy_logprob_max 4.29 / train/policy_logprob_mean -4.36 / train/policy_logprob_min -15.57 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.86 / train/policy_randomness_min 0.07 / train/policy_randomness_std 0.13 / train/post_ent_mag 40.25 / train/post_ent_max 40.25 / train/post_ent_mean 30.27 / train/post_ent_min 
18.82 / train/post_ent_std 3.63 / train/prior_ent_mag 70.52 / train/prior_ent_max 70.52 / train/prior_ent_mean 33.55 / train/prior_ent_min 22.43 / train/prior_ent_std 6.07 / train/rep_loss_mean 3.26 / train/rep_loss_std 5.84 / train/reward_avg 3.2e-4 / 
train/reward_loss_mean 7.7e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.11 / train/reward_max_pred 0.11 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-4 / train/reward_pos_acc 0.95 / train/reward_pos_loss 0.69 / train/reward_pred 3.2e-4 / 
train/reward_rate 6.4e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 3.23 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 3.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss
2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.06 / report/dyn_loss_std 5.53 / report/image_loss_mean 1.31 / report/image_loss_std 1.33 / report/model_loss_mean 3.15 / report/model_loss_std 4.2 / report/post_ent_mag 39.8 / report/post_ent_max 
39.8 / report/post_ent_mean 31.34 / report/post_ent_min 17.62 / report/post_ent_std 3.44 / report/prior_ent_mag 71.09 / report/prior_ent_max 71.09 / report/prior_ent_mean 34.57 / report/prior_ent_min 22.23 / report/prior_ent_std 5.87 / report/rep_loss_mean 3.06 / 
report/rep_loss_std 5.53 / report/reward_avg 0 / report/reward_loss_mean 2.8e-6 / report/reward_loss_std 3.6e-5 / report/reward_max_data 0 / report/reward_max_pred 1.8e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-6 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 6.7e-7 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-10 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-10 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 5.85 / eval/dyn_loss_std 9.13 / eval/image_loss_mean 2.81 / eval/image_loss_std 4.76 / eval/model_loss_mean 6.32 / eval/model_loss_std 9.58 / eval/post_ent_mag 39.88 / eval/post_ent_max 39.88 / eval/post_ent_mean 29.83 / 
eval/post_ent_min 16.29 / eval/post_ent_std 3.72 / eval/prior_ent_mag 71.09 / eval/prior_ent_max 71.09 / eval/prior_ent_mean 33.85 / eval/prior_ent_min 22.64 / eval/prior_ent_std 6.83 / eval/rep_loss_mean 5.85 / eval/rep_loss_std 9.13 / eval/reward_avg 0 / 
eval/reward_loss_mean 3.6e-4 / eval/reward_loss_std 4.8e-3 / eval/reward_max_data 0 / eval/reward_max_pred 0.02 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 6.5e-5 / eval/reward_rate 0 / 
replay/size 7.3e4 / replay/inserts 3779 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3779 / timer/env.step_total 19.85 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.07 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7787 / timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.8e-3 / 
timer/dataset_train_count 1890 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1890 / timer/agent.train_total 241.78 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 73500 Counter(73500) 73437
eval_Episode has 500 steps and return 0.9.
train_Episode has 500 steps and return 10.1.
Saved chunk: 20230921T230350F794489-14Sl8u2H9rlyp2PmJtQXSA-1elZW6no3OLm6xTqWKD7il-1024.npz
Starting evaluation at step 74000 Counter(74000) 73937
eval_Episode has 500 steps and return 39.0.
train_Episode has 500 steps and return 21.0.
Starting evaluation at step 74500 Counter(74500) 74437
Saved chunk: 20230921T230415F268709-43jvSLhvlHGjlw3oWi3Oh6-1qpe8sVl6S1W7oZ9wdnS7Y-1024.npz
eval_Episode has 500 steps and return 34.0.
train_Episode has 500 steps and return 31.6.
Saved chunk: 20230921T230511F960333-1elZW6no3OLm6xTqWKD7il-6JVcXmcrqVEnHRNQKFAc5v-1024.npz
Starting evaluation at step 75000 Counter(75000) 74937
eval_Episode has 500 steps and return 42.6.
train_Episode has 500 steps and return 51.4.
Starting evaluation at step 75500 Counter(75500) 75437
Saved chunk: 20230921T230611F058636-1qpe8sVl6S1W7oZ9wdnS7Y-0ISkDxRJWc0a0q2WDQRhMg-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.5.
Saved chunk: 20230921T230632F582692-6JVcXmcrqVEnHRNQKFAc5v-1qKFuApSFCPohrDC0ZFBAH-1024.npz
Starting evaluation at step 76000 Counter(76000) 75937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 34.0.
Starting evaluation at step 76500 Counter(76500) 76437
Saved chunk: 20230921T230729F823585-0ISkDxRJWc0a0q2WDQRhMg-6DjWDTRlCoNvKCUArFq9GH-1024.npz
eval_Episode has 500 steps and return 13.7.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230752F841961-1qKFuApSFCPohrDC0ZFBAH-6r855lj0y8wFvbQ0Je7i25-1024.npz
Starting evaluation at step 77000 Counter(77000) 76937
eval_Episode has 500 steps and return 22.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 154002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 21.99 / eval_episode/reward_rate 0.08 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 3.72 / train/action_max 3.57 / train/action_mean 0.23 / train/action_min -3.17 / train/action_std 0.89 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 3.7e4 / train/actor_opt_loss -1193.66 / train/adv_mag 1.42 / train/adv_max 1.41 / train/adv_mean 0.12 / train/adv_min -0.58
/ train/adv_std 0.16 / train/cont_avg 1 / train/cont_loss_mean 1.5e-10 / train/cont_loss_std 6.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.5
/ train/dyn_loss_std 6.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.95 / train/extr_critic_critic_opt_grad_steps 3.7e4 / train/extr_critic_critic_opt_loss
1.7e4 / train/extr_critic_mag 4.52 / train/extr_critic_max 4.52 / train/extr_critic_mean 3.2 / train/extr_critic_min 1.49 / train/extr_critic_std 0.55 / train/extr_return_normed_mag 2.34 / train/extr_return_normed_max 2.34 / train/extr_return_normed_mean 0.59 / 
train/extr_return_normed_min -0.12 / train/extr_return_normed_std 0.36 / train/extr_return_rate 0.96 / train/extr_return_raw_mag 6.79 / train/extr_return_raw_max 6.79 / train/extr_return_raw_mean 3.43 / train/extr_return_raw_min 2.02 / train/extr_return_raw_std 0.71 / 
train/extr_reward_mag 0.74 / train/extr_reward_max 0.74 / train/extr_reward_mean 9.6e-3 / train/extr_reward_min -1.9e-9 / train/extr_reward_std 0.06 / train/image_loss_mean 1.59 / train/image_loss_std 1.72 / train/model_loss_mean 3.7 / train/model_loss_std 4.88 / 
train/model_opt_grad_norm 9.48 / train/model_opt_grad_steps 3.7e4 / train/model_opt_loss 2.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6289.47 / train/policy_entropy_mag 4.48 / train/policy_entropy_max 4.38 / 
train/policy_entropy_mean -2.3 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.27 / train/policy_logprob_mag 9.61 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.3 / train/policy_logprob_min -9.61 / train/policy_logprob_std 1.93 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 8.3e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 41.43 / train/post_ent_max 41.43 / train/post_ent_mean 30.83 / 
train/post_ent_min 19.24 / train/post_ent_std 3.64 / train/prior_ent_mag 72 / train/prior_ent_max 72 / train/prior_ent_mean 34.32 / train/prior_ent_min 23.19 / train/prior_ent_std 6.22 / train/rep_loss_mean 3.5 / train/rep_loss_std 6.09 / train/reward_avg 1.7e-3 / 
train/reward_loss_mean 5.3e-3 / train/reward_loss_std 0.06 / train/reward_max_data 0.32 / train/reward_max_pred 0.3 / train/reward_neg_acc 1 / train/reward_neg_loss 1.1e-3 / train/reward_pos_acc 0.92 / train/reward_pos_loss 1.1 / train/reward_pred 1.7e-3 / 
train/reward_rate 3.6e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.58 / report/cont_avg 1 / report/cont_loss_mean 1.7e-10 / report/cont_loss_std 4.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.7e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.47 / report/dyn_loss_std 6.44 / report/image_loss_mean 1.65 / report/image_loss_std 1.65 / report/model_loss_mean 3.74 / report/model_loss_std 4.98 / report/post_ent_mag 
38.27 / report/post_ent_max 38.27 / report/post_ent_mean 30.25 / report/post_ent_min 18.9 / report/post_ent_std 4.13 / report/prior_ent_mag 71.94 / report/prior_ent_max 71.94 / report/prior_ent_mean 33.85 / report/prior_ent_min 20.86 / report/prior_ent_std 6.55 / 
report/rep_loss_mean 3.47 / report/rep_loss_std 6.44 / report/reward_avg 1.4e-3 / report/reward_loss_mean 2.6e-3 / report/reward_loss_std 0.05 / report/reward_max_data 0.74 / report/reward_max_pred 0.94 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 1.17 / report/reward_pred 1.9e-3 / report/reward_rate 2e-3 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-10 / eval/cont_loss_std 2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.83 / eval/dyn_loss_std 6.87 / eval/image_loss_mean 1.83 / eval/image_loss_std 2.21 / eval/model_loss_mean 4.73 / eval/model_loss_std 5.92 / eval/post_ent_mag 41.29 / 
eval/post_ent_max 41.29 / eval/post_ent_mean 30.74 / eval/post_ent_min 19.7 / eval/post_ent_std 4.67 / eval/prior_ent_mag 71.94 / eval/prior_ent_max 71.94 / eval/prior_ent_mean 33.81 / eval/prior_ent_min 20.75 / eval/prior_ent_std 6.87 / eval/rep_loss_mean 4.83 / 
eval/rep_loss_std 6.87 / eval/reward_avg 0 / eval/reward_loss_mean 1.3e-6 / eval/reward_loss_std 9e-6 / eval/reward_max_data 0 / eval/reward_max_pred 8.9e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / 
eval/reward_pred 4.1e-7 / eval/reward_rate 0 / replay/size 7.7e4 / replay/inserts 3798 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.8e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.94 / timer/env.step_count 3798 / timer/env.step_total 19.91
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.11 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
5.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7806 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.6e-3 / timer/dataset_train_count 1899 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.7e-4 / 
timer/agent.train_count 1899 / timer/agent.train_total 242.68 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / 
timer/dataset_eval_max 3.6e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 77500 Counter(77500) 77437
Saved chunk: 20230921T230848F448953-6DjWDTRlCoNvKCUArFq9GH-0enXbH6dHel7EyyA1iAkvS-1024.npz
eval_Episode has 500 steps and return 60.1.
train_Episode has 500 steps and return 48.3.
Saved chunk: 20230921T230912F997933-6r855lj0y8wFvbQ0Je7i25-6Kh8lfRc5wCz3DjwvLynoH-1024.npz
Starting evaluation at step 78000 Counter(78000) 77937
eval_Episode has 500 steps and return 54.2.
train_Episode has 500 steps and return 57.4.
Starting evaluation at step 78500 Counter(78500) 78437
Saved chunk: 20230921T231008F000795-0enXbH6dHel7EyyA1iAkvS-4sFgIwufn142aTMdBXNpJ7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 66.1.
Saved chunk: 20230921T231034F408025-6Kh8lfRc5wCz3DjwvLynoH-5gJHlsg51iGcr0EXHWetVI-1024.npz
Starting evaluation at step 79000 Counter(79000) 78937
eval_Episode has 500 steps and return 77.3.
train_Episode has 500 steps and return 64.4.
Starting evaluation at step 79500 Counter(79500) 79437
Saved chunk: 20230921T231127F159946-4sFgIwufn142aTMdBXNpJ7-6rzvfgGDq3pE0Xe140Kdjx-1024.npz
eval_Episode has 500 steps and return 68.2.
train_Episode has 500 steps and return 66.1.
Saved chunk: 20230921T231155F047558-5gJHlsg51iGcr0EXHWetVI-7k9TuL1BzGyTf8sfMD6cd4-1024.npz
Starting evaluation at step 80000 Counter(80000) 79937
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T231315F386366-7k9TuL1BzGyTf8sfMD6cd4-0000000000000000000000-228.npz
Saved chunk: 20230921T231246F079349-6rzvfgGDq3pE0Xe140Kdjx-0000000000000000000000-887.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 65.9.
Starting evaluation at step 80500 Counter(80500) 80437
Saved chunk: 20230921T231246F079349-6rzvfgGDq3pE0Xe140Kdjx-2qX4KV4cNVhBJGAwBTeN5v-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 161650 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 2.83 / train/action_max 2.72 / train/action_mean 0.18 / train/action_min -2.47 / train/action_std 0.86 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 3.9e4 / train/actor_opt_loss -819.86 / train/adv_mag 1.21 / train/adv_max 1.19 / train/adv_mean 0.08 / train/adv_min -0.63 
/ train/adv_std 0.12 / train/cont_avg 1 / train/cont_loss_mean 1.7e-10 / train/cont_loss_std 1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.61 /
train/dyn_loss_std 6.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.63 / train/extr_critic_critic_opt_grad_steps 3.9e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 11.97 / train/extr_critic_max 11.97 / train/extr_critic_mean 9.61 / train/extr_critic_min 5.07 / train/extr_critic_std 1.17 / train/extr_return_normed_mag 1.68 / train/extr_return_normed_max 1.67 / train/extr_return_normed_mean 0.53 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 14.53 / train/extr_return_raw_max 14.53 / train/extr_return_raw_mean 9.95 / train/extr_return_raw_min 6.9 / train/extr_return_raw_std 1.36 / 
train/extr_reward_mag 0.93 / train/extr_reward_max 0.93 / train/extr_reward_mean 0.02 / train/extr_reward_min 0 / train/extr_reward_std 0.09 / train/image_loss_mean 1.65 / train/image_loss_std 1.67 / train/model_loss_mean 3.82 / train/model_loss_std 4.85 / 
train/model_opt_grad_norm 9.47 / train/model_opt_grad_steps 3.9e4 / train/model_opt_loss 2.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5994.76 / train/policy_entropy_mag 3.7 / train/policy_entropy_max 2.9 / 
train/policy_entropy_mean -2.99 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 8.27 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.99 / train/policy_logprob_min -8.27 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 3.6e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 42.05 / train/post_ent_max 42.05 / train/post_ent_mean 31.18 / 
train/post_ent_min 19.17 / train/post_ent_std 3.77 / train/prior_ent_mag 73.25 / train/prior_ent_max 73.25 / train/prior_ent_mean 34.82 / train/prior_ent_min 23.28 / train/prior_ent_std 6.38 / train/rep_loss_mean 3.61 / train/rep_loss_std 6.11 / train/reward_avg 5.3e-3 
/ train/reward_loss_mean 9.6e-3 / train/reward_loss_std 0.08 / train/reward_max_data 0.54 / train/reward_max_pred 0.49 / train/reward_neg_acc 1 / train/reward_neg_loss 1.1e-3 / train/reward_pos_acc 0.98 / train/reward_pos_loss 0.87 / train/reward_pred 5.2e-3 / 
train/reward_rate 9.7e-3 / train_stats/mean_log_entropy -3.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.4e-10 / report/cont_loss_std 4.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.4e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.89 / report/dyn_loss_std 6.5 / report/image_loss_mean 1.91 / report/image_loss_std 1.76 / report/model_loss_mean 4.26 / report/model_loss_std 5.17 / report/post_ent_mag 39.87
/ report/post_ent_max 39.87 / report/post_ent_mean 30.89 / report/post_ent_min 18.45 / report/post_ent_std 3.46 / report/prior_ent_mag 73.42 / report/prior_ent_max 73.42 / report/prior_ent_mean 34.83 / report/prior_ent_min 22.48 / report/prior_ent_std 6.18 / 
report/rep_loss_mean 3.89 / report/rep_loss_std 6.5 / report/reward_avg 0.01 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.09 / report/reward_max_data 0.82 / report/reward_max_pred 0.84 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.65 / report/reward_pred 0.01 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 4.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.71 / eval/dyn_loss_std 8.8 / eval/image_loss_mean 2.52 / eval/image_loss_std 3.56 / eval/model_loss_mean 5.95 / eval/model_loss_std 8.22 / eval/post_ent_mag 42.13 / eval/post_ent_max
42.13 / eval/post_ent_mean 32.28 / eval/post_ent_min 17.89 / eval/post_ent_std 3.48 / eval/prior_ent_mag 73.42 / eval/prior_ent_max 73.42 / eval/prior_ent_mean 36.24 / eval/prior_ent_min 25.51 / eval/prior_ent_std 5.71 / eval/rep_loss_mean 5.71 / eval/rep_loss_std 8.8 /
eval/reward_avg 0 / eval/reward_loss_mean 4e-5 / eval/reward_loss_std 1.2e-3 / eval/reward_max_data 0 / eval/reward_max_pred 8.8e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 9.5e-6 / 
eval/reward_rate 0 / replay/size 8.1e4 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.1e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3824 / timer/env.step_total 20.17 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.3e-3 / timer/env.step_min 4.6e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 450.77 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7331 / timer/agent.policy_total 16.36 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1912 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1912 / timer/agent.train_total 244.75 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac
1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.49

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T231315F386366-7k9TuL1BzGyTf8sfMD6cd4-4npXfUpJuuRE09GRIcPU6s-1024.npz
Starting evaluation at step 81000 Counter(81000) 80937
eval_Episode has 500 steps and return 68.1.
train_Episode has 500 steps and return 0.1.
Starting evaluation at step 81500 Counter(81500) 81437
Saved chunk: 20230921T231405F129815-2qX4KV4cNVhBJGAwBTeN5v-2L7x5l3qehZvPKhr5TSsqf-1024.npz
eval_Episode has 500 steps and return 65.7.
train_Episode has 500 steps and return 66.9.
Saved chunk: 20230921T231436F809135-4npXfUpJuuRE09GRIcPU6s-6rjqOVJx1BFMgvZbyUB5zm-1024.npz
Starting evaluation at step 82000 Counter(82000) 81937
eval_Episode has 500 steps and return 75.3.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 82500 Counter(82500) 82437
Saved chunk: 20230921T231524F997558-2L7x5l3qehZvPKhr5TSsqf-25kS7Ste27mXztV6vRhp0n-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231557F721755-6rjqOVJx1BFMgvZbyUB5zm-28LyjKsPoOQGOoJMmiOx0J-1024.npz
Starting evaluation at step 83000 Counter(83000) 82937
eval_Episode has 500 steps and return 92.8.
train_Episode has 500 steps and return 71.5.
Starting evaluation at step 83500 Counter(83500) 83437
Saved chunk: 20230921T231644F186545-25kS7Ste27mXztV6vRhp0n-1ydUxMVdWyzGZJwyYTaDFw-1024.npz
eval_Episode has 500 steps and return 68.6.
train_Episode has 500 steps and return 75.6.
Saved chunk: 20230921T231718F328790-28LyjKsPoOQGOoJMmiOx0J-3f7GCQ0fTMaUb7XGBI0f9r-1024.npz
Starting evaluation at step 84000 Counter(84000) 83937
eval_Episode has 500 steps and return 82.8.
train_Episode has 500 steps and return 86.0.
Starting evaluation at step 84500 Counter(84500) 84437
Saved chunk: 20230921T231803F041508-1ydUxMVdWyzGZJwyYTaDFw-074iPFwEHHibA22qGCz7OB-1024.npz
eval_Episode has 500 steps and return 79.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 169202 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 79.14 / eval_episode/reward_rate 0.27 / episode/length 500 / episode/score 86.01 / episode/reward_rate 0.31 / train/action_mag 3.44 / train/action_max 3.26 / train/action_mean 0.13 / train/action_min -3.05 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.31 / train/actor_opt_grad_steps 4.1e4 / train/actor_opt_loss -492.27 / train/adv_mag 1.13 / train/adv_max 1.13 / train/adv_mean 0.05 / train/adv_min
-0.54 / train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 1.5e-10 / train/cont_loss_std 8.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 6.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.47 / train/extr_critic_critic_opt_grad_steps 4.1e4 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 21.31 / train/extr_critic_max 21.31 / train/extr_critic_mean 16.88 / train/extr_critic_min 10.07 / train/extr_critic_std 2.62 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.39 / 
train/extr_return_normed_mean 0.5 / train/extr_return_normed_min -0.1 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 23.82 / train/extr_return_raw_max 23.82 / train/extr_return_raw_mean 17.25 / train/extr_return_raw_min 12.83 
/ train/extr_return_raw_std 2.78 / train/extr_reward_mag 0.99 / train/extr_reward_max 0.99 / train/extr_reward_mean 0.02 / train/extr_reward_min 0 / train/extr_reward_std 0.11 / train/image_loss_mean 1.64 / train/image_loss_std 1.59 / train/model_loss_mean 3.85 / 
train/model_loss_std 4.87 / train/model_opt_grad_norm 9.14 / train/model_opt_grad_steps 4.1e4 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8412.7 / train/policy_entropy_mag 4.21 / 
train/policy_entropy_max 4.11 / train/policy_entropy_mean -2.43 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.41 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.43 / train/policy_logprob_min -9.41 / 
train/policy_logprob_std 1.87 / train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 5e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 42.02 / train/post_ent_max 42.02 / 
train/post_ent_mean 31.44 / train/post_ent_min 19.1 / train/post_ent_std 3.85 / train/prior_ent_mag 74.49 / train/prior_ent_max 74.49 / train/prior_ent_mean 35.13 / train/prior_ent_min 23.2 / train/prior_ent_std 6.48 / train/rep_loss_mean 3.65 / train/rep_loss_std 6.24 
/ train/reward_avg 8.9e-3 / train/reward_loss_mean 0.01 / train/reward_loss_std 0.1 / train/reward_max_data 0.68 / train/reward_max_pred 0.63 / train/reward_neg_acc 1 / train/reward_neg_loss 1.3e-3 / train/reward_pos_acc 0.98 / train/reward_pos_loss 0.81 / 
train/reward_pred 8.8e-3 / train/reward_rate 0.02 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.39 / report/cont_avg 1 / report/cont_loss_mean 1.8e-10 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.55 / report/dyn_loss_std 5.57 / report/image_loss_mean 1.51 / report/image_loss_std 1.38 / report/model_loss_mean 3.66 / report/model_loss_std 4.35 / 
report/post_ent_mag 41.86 / report/post_ent_max 41.86 / report/post_ent_mean 32.65 / report/post_ent_min 18.95 / report/post_ent_std 3.47 / report/prior_ent_mag 75.08 / report/prior_ent_max 75.08 / report/prior_ent_mean 36.35 / report/prior_ent_min 23.57 / 
report/prior_ent_std 5.83 / report/rep_loss_mean 3.55 / report/rep_loss_std 5.57 / report/reward_avg 0.02 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.17 / report/reward_max_data 0.9 / report/reward_max_pred 0.86 / report/reward_neg_acc 1 / 
report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.68 / report/reward_pred 0.02 / report/reward_rate 0.03 / eval/cont_avg 1 / eval/cont_loss_mean 2e-10 / eval/cont_loss_std 7.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.08 / eval/dyn_loss_std 13 / eval/image_loss_mean 2.98 / eval/image_loss_std 5.82 / eval/model_loss_mean 7.23 / eval/model_loss_std 13.35 / eval/post_ent_mag 42.39
/ eval/post_ent_max 42.39 / eval/post_ent_mean 33.41 / eval/post_ent_min 20.68 / eval/post_ent_std 3.71 / eval/prior_ent_mag 75.08 / eval/prior_ent_max 75.08 / eval/prior_ent_mean 36.8 / eval/prior_ent_min 25.39 / eval/prior_ent_std 6.07 / eval/rep_loss_mean 7.08 / 
eval/rep_loss_std 13 / eval/reward_avg 0 / eval/reward_loss_mean 7.6e-6 / eval/reward_loss_std 1.7e-4 / eval/reward_max_data 0 / eval/reward_max_pred 1e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.6e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / 
eval/reward_pred 1.6e-6 / eval/reward_rate 0 / replay/size 8.5e4 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.5e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3776 / timer/env.step_total 19.79
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 441.32 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.6e-4 / 
timer/agent.train_count 1888 / timer/agent.train_total 241.7 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 8.9e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / 
timer/dataset_eval_max 2.7e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 74.4.
Saved chunk: 20230921T231838F691801-3f7GCQ0fTMaUb7XGBI0f9r-6jgUqIfozZAqxyRkIozZGI-1024.npz
Starting evaluation at step 85000 Counter(85000) 84937
eval_Episode has 500 steps and return 87.3.
train_Episode has 500 steps and return 90.1.
Starting evaluation at step 85500 Counter(85500) 85437
Saved chunk: 20230921T231921F856100-074iPFwEHHibA22qGCz7OB-2S5DAf6AuZ56EBgQHWCNVL-1024.npz
eval_Episode has 500 steps and return 104.3.
train_Episode has 500 steps and return 77.2.
Starting evaluation at step 86000 Counter(86000) 85937
eval_Episode has 500 steps and return 79.7.
Saved chunk: 20230921T231959F922820-6jgUqIfozZAqxyRkIozZGI-4RIw7hXooUQ7kOi9jwywuK-1024.npz
train_Episode has 500 steps and return 87.3.
Starting evaluation at step 86500 Counter(86500) 86437
Saved chunk: 20230921T232041F843537-2S5DAf6AuZ56EBgQHWCNVL-57H2kMLjKi6i1o4M8YXlkN-1024.npz
eval_Episode has 500 steps and return 83.0.
train_Episode has 500 steps and return 86.3.
Starting evaluation at step 87000 Counter(87000) 86937
eval_Episode has 500 steps and return 76.5.
Saved chunk: 20230921T232124F270975-4RIw7hXooUQ7kOi9jwywuK-4kGvBH6YRiJGuKgJdgIjuj-1024.npz
train_Episode has 500 steps and return 67.7.
Starting evaluation at step 87500 Counter(87500) 87437
Saved chunk: 20230921T232200F855810-57H2kMLjKi6i1o4M8YXlkN-30GzcGqSVwC5CHNHz9Sor2-1024.npz
eval_Episode has 500 steps and return 83.8.
train_Episode has 500 steps and return 85.3.
Starting evaluation at step 88000 Counter(88000) 87937
eval_Episode has 500 steps and return 103.0.
Saved chunk: 20230921T232244F735914-4kGvBH6YRiJGuKgJdgIjuj-4g6yqOmSwGhOU6UVvx7377-1024.npz
train_Episode has 500 steps and return 112.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 176854 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 112.78 / episode/reward_rate 0.32 / eval_episode/length 500 / eval_episode/score 103.02 / eval_episode/reward_rate 0.34 / train/action_mag 2.96 / train/action_max 2.88 / train/action_mean 0.07 / train/action_min -2.6 / train/action_std
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 4.3e4 / train/actor_opt_loss -625.09 / train/adv_mag 1.96 / train/adv_max 1.96 / train/adv_mean 0.06 / train/adv_min
-0.45 / train/adv_std 0.1 / train/cont_avg 1 / train/cont_loss_mean 2.1e-10 / train/cont_loss_std 2.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.74 / train/dyn_loss_std 6.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.24 / train/extr_critic_critic_opt_grad_steps 4.3e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 30.9 / train/extr_critic_max 30.9 / train/extr_critic_mean 27.2 / train/extr_critic_min 15.98 / train/extr_critic_std 1.9 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.49 / 
train/extr_return_normed_mean 0.52 / train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 33.41 / train/extr_return_raw_max 33.41 / train/extr_return_raw_mean 27.59 / train/extr_return_raw_min 
23.68 / train/extr_return_raw_std 2.03 / train/extr_reward_mag 1.09 / train/extr_reward_max 1.09 / train/extr_reward_mean 0.03 / train/extr_reward_min 0 / train/extr_reward_std 0.13 / train/image_loss_mean 1.66 / train/image_loss_std 1.56 / train/model_loss_mean 3.93 / 
train/model_loss_std 4.94 / train/model_opt_grad_norm 9.22 / train/model_opt_grad_steps 4.3e4 / train/model_opt_loss 2.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6178.01 / train/policy_entropy_mag 4 / train/policy_entropy_max 
3.85 / train/policy_entropy_mean -2.84 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.99 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.84 / train/policy_logprob_min -8.99 / train/policy_logprob_std 1.7 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 3.6e-4 / train/policy_randomness_std 0.1 / train/post_ent_mag 43.02 / train/post_ent_max 43.02 / train/post_ent_mean 31.54 / 
train/post_ent_min 18.38 / train/post_ent_std 4.07 / train/prior_ent_mag 75.63 / train/prior_ent_max 75.63 / train/prior_ent_mean 35.31 / train/prior_ent_min 22.28 / train/prior_ent_std 6.67 / train/rep_loss_mean 3.74 / train/rep_loss_std 6.4 / train/reward_avg 0.01 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.14 / train/reward_max_data 0.85 / train/reward_max_pred 0.8 / train/reward_neg_acc 1 / train/reward_neg_loss 1.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.79 / train/reward_pred 0.01 / 
train/reward_rate 0.03 / train_stats/mean_log_entropy -3.2 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.81 / report/dyn_loss_std 5.2 / report/image_loss_mean 1.05 / report/image_loss_std 1.09 / report/model_loss_mean 2.74 / report/model_loss_std 3.86 / report/post_ent_mag 45.82 / report/post_ent_max 
45.82 / report/post_ent_mean 32.44 / report/post_ent_min 20.58 / report/post_ent_std 4.4 / report/prior_ent_mag 75.97 / report/prior_ent_max 75.97 / report/prior_ent_mean 35.34 / report/prior_ent_min 22.4 / report/prior_ent_std 6.71 / report/rep_loss_mean 2.81 / 
report/rep_loss_std 5.2 / report/reward_avg 6.8e-3 / report/reward_loss_mean 7.7e-3 / report/reward_loss_std 0.08 / report/reward_max_data 0.86 / report/reward_max_pred 0.81 / report/reward_neg_acc 1 / report/reward_neg_loss 5.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.74 / report/reward_pred 6.8e-3 / report/reward_rate 9.8e-3 / eval/cont_avg 1 / eval/cont_loss_mean 3e-10 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.17 / eval/dyn_loss_std 7.87 / eval/image_loss_mean 2.06 / eval/image_loss_std 2.95 / eval/model_loss_mean 5.16 / eval/model_loss_std 7.24 / eval/post_ent_mag 43.26 / eval/post_ent_max 43.26 / eval/post_ent_mean 
31.53 / eval/post_ent_min 19.45 / eval/post_ent_std 4.16 / eval/prior_ent_mag 75.97 / eval/prior_ent_max 75.97 / eval/prior_ent_mean 35.21 / eval/prior_ent_min 23.2 / eval/prior_ent_std 6.98 / eval/rep_loss_mean 5.17 / eval/rep_loss_std 7.87 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.2e-6 / eval/reward_loss_std 6.2e-6 / eval/reward_max_data 0 / eval/reward_max_pred 3.5e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 4.1e-7 / eval/reward_rate 0 / 
replay/size 8.8e4 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.9e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3826 / timer/env.step_total 19.99 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 450.97 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.8e-3 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7333 / timer/agent.policy_total 16.16 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1913 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1913 / timer/agent.train_total 245.13 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 88500 Counter(88500) 88437
Saved chunk: 20230921T232319F674897-30GzcGqSVwC5CHNHz9Sor2-1pFzyGguunNqn4LdsoFWAB-1024.npz
eval_Episode has 500 steps and return 100.8.
train_Episode has 500 steps and return 90.4.
Starting evaluation at step 89000 Counter(89000) 88937
eval_Episode has 500 steps and return 68.5.
Saved chunk: 20230921T232405F088755-4g6yqOmSwGhOU6UVvx7377-3kvakm91lNKuHSl3ddvgs4-1024.npz
train_Episode has 500 steps and return 81.5.
Starting evaluation at step 89500 Counter(89500) 89437
Saved chunk: 20230921T232439F291491-1pFzyGguunNqn4LdsoFWAB-0zxInwsQImOFRYeotCXnlM-1024.npz
eval_Episode has 500 steps and return 91.3.
train_Episode has 500 steps and return 88.9.
Starting evaluation at step 90000 Counter(90000) 89937
eval_Episode has 500 steps and return 106.3.
Saved chunk: 20230921T232526F459994-3kvakm91lNKuHSl3ddvgs4-4oOjJq5VrX95Q55TRSBp9r-1024.npz
train_Episode has 500 steps and return 109.0.
Starting evaluation at step 90500 Counter(90500) 90437
Saved chunk: 20230921T232558F483355-0zxInwsQImOFRYeotCXnlM-6hU3ePQOFLwLxG6uvsXael-1024.npz
eval_Episode has 500 steps and return 121.3.
train_Episode has 500 steps and return 58.2.
Starting evaluation at step 91000 Counter(91000) 90937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232647F107999-4oOjJq5VrX95Q55TRSBp9r-00xpmmy5CBtFP6r23n1yPd-1024.npz
train_Episode has 500 steps and return 75.8.
Starting evaluation at step 91500 Counter(91500) 91437
Saved chunk: 20230921T232717F427463-6hU3ePQOFLwLxG6uvsXael-1e0HI0ufNyBjkdBxKyvYxv-1024.npz
eval_Episode has 500 steps and return 82.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T232836F189895-1e0HI0ufNyBjkdBxKyvYxv-0000000000000000000000-122.npz
Saved chunk: 20230921T232807F544358-00xpmmy5CBtFP6r23n1yPd-0000000000000000000000-464.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 85.8.
Starting evaluation at step 92000 Counter(92000) 91937
eval_Episode has 500 steps and return 93.1.
Saved chunk: 20230921T232807F544358-00xpmmy5CBtFP6r23n1yPd-1SIE7XVjlM9TCUjtlnQWkJ-1024.npz
train_Episode has 500 steps and return 98.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 184406 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 93.15 / eval_episode/reward_rate 0.28 / episode/length 500 / episode/score 98.46 / episode/reward_rate 0.27 / train/action_mag 3.07 / train/action_max 3.04 / train/action_mean 0.06 / train/action_min -2.4 / train/action_std 
0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 4.5e4 / train/actor_opt_loss -515.04 / train/adv_mag 2.38 / train/adv_max 2.38 / train/adv_mean 0.05 / train/adv_min
-0.5 / train/adv_std 0.1 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.76 / train/dyn_loss_std 6.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 4.5e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 40.59 / train/extr_critic_max 40.59 / train/extr_critic_mean 36.57 / train/extr_critic_min 20.35 / train/extr_critic_std 2.15 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.43 / 
train/extr_return_normed_mean 0.51 / train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 43.24 / train/extr_return_raw_max 43.24 / train/extr_return_raw_mean 36.93 / train/extr_return_raw_min 
31.75 / train/extr_return_raw_std 2.28 / train/extr_reward_mag 1.13 / train/extr_reward_max 1.13 / train/extr_reward_mean 0.04 / train/extr_reward_min -3.2e-9 / train/extr_reward_std 0.16 / train/image_loss_mean 1.61 / train/image_loss_std 1.5 / train/model_loss_mean 
3.9 / train/model_loss_std 4.95 / train/model_opt_grad_norm 9.44 / train/model_opt_grad_steps 4.5e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.84 / 
train/policy_entropy_max 3.53 / train/policy_entropy_mean -2.99 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.77 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.99 / train/policy_logprob_min -8.69 / 
train/policy_logprob_std 1.61 / train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 43.88 / train/post_ent_max 43.88 / 
train/post_ent_mean 31.91 / train/post_ent_min 18.52 / train/post_ent_std 4.17 / train/prior_ent_mag 76.67 / train/prior_ent_max 76.67 / train/prior_ent_mean 35.68 / train/prior_ent_min 22.4 / train/prior_ent_std 6.72 / train/rep_loss_mean 3.76 / train/rep_loss_std 6.47
/ train/reward_avg 0.02 / train/reward_loss_mean 0.03 / train/reward_loss_std 0.16 / train/reward_max_data 0.99 / train/reward_max_pred 0.91 / train/reward_neg_acc 1 / train/reward_neg_loss 1.9e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.82 / 
train/reward_pred 0.02 / train/reward_rate 0.04 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.21 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 5.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.1 / report/dyn_loss_std 6.14 / report/image_loss_mean 1.16 / report/image_loss_std 1.33 / report/model_loss_mean 3.02 / report/model_loss_std 4.64 / 
report/post_ent_mag 45.11 / report/post_ent_max 45.11 / report/post_ent_mean 33.75 / report/post_ent_min 19.7 / report/post_ent_std 3.58 / report/prior_ent_mag 77.31 / report/prior_ent_max 77.31 / report/prior_ent_mean 36.35 / report/prior_ent_min 24.95 / 
report/prior_ent_std 6.13 / report/rep_loss_mean 3.1 / report/rep_loss_std 6.14 / report/reward_avg 1.8e-4 / report/reward_loss_mean 2e-3 / report/reward_loss_std 0.04 / report/reward_max_data 0.08 / report/reward_max_pred 0.08 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2e-3 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 1.6e-4 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 9.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.53 / eval/dyn_loss_std 7.89 / eval/image_loss_mean 2.21 / eval/image_loss_std 2.95 / eval/model_loss_mean 5.53 / eval/model_loss_std 7.2 / eval/post_ent_mag 
41.87 / eval/post_ent_max 41.87 / eval/post_ent_mean 32.74 / eval/post_ent_min 16.29 / eval/post_ent_std 3.93 / eval/prior_ent_mag 77.31 / eval/prior_ent_max 77.31 / eval/prior_ent_mean 36.66 / eval/prior_ent_min 21.2 / eval/prior_ent_std 6.35 / eval/rep_loss_mean 5.53 
/ eval/rep_loss_std 7.89 / eval/reward_avg 0 / eval/reward_loss_mean 7.5e-7 / eval/reward_loss_std 3e-6 / eval/reward_max_data 0 / eval/reward_max_pred 2.5e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.5e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / 
eval/reward_pred 2.9e-7 / eval/reward_rate 0 / replay/size 9.2e4 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.3e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3776 / timer/env.step_total 19.98
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.12 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
3.8e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7784 / timer/agent.policy_total 
17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1888 / timer/agent.train_total 241.67 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / 
timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 
1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 92500 Counter(92500) 92437
Saved chunk: 20230921T232836F189895-1e0HI0ufNyBjkdBxKyvYxv-1H033ZfcA88dlW3lAPxcbt-1024.npz
eval_Episode has 500 steps and return 116.8.
train_Episode has 500 steps and return 110.9.
Starting evaluation at step 93000 Counter(93000) 92937
eval_Episode has 500 steps and return 89.8.
train_Episode has 500 steps and return 103.1.
Saved chunk: 20230921T232928F151333-1SIE7XVjlM9TCUjtlnQWkJ-3DIJCkFIKC3QeAJEKF1MMF-1024.npz
Starting evaluation at step 93500 Counter(93500) 93437
Saved chunk: 20230921T232956F163835-1H033ZfcA88dlW3lAPxcbt-5f5AIYiNG6PUDydBidwme8-1024.npz
eval_Episode has 500 steps and return 100.6.
train_Episode has 500 steps and return 98.7.
Starting evaluation at step 94000 Counter(94000) 93937
eval_Episode has 500 steps and return 107.4.
train_Episode has 500 steps and return 99.8.
Saved chunk: 20230921T233049F749706-3DIJCkFIKC3QeAJEKF1MMF-7lm1I2zmtk0C81G7XoLMOP-1024.npz
Starting evaluation at step 94500 Counter(94500) 94437
Saved chunk: 20230921T233115F436947-5f5AIYiNG6PUDydBidwme8-0jVH5wN4YroJ6uquNNVKg3-1024.npz
eval_Episode has 500 steps and return 116.1.
train_Episode has 500 steps and return 119.9.
Starting evaluation at step 95000 Counter(95000) 94937
eval_Episode has 500 steps and return 127.9.
train_Episode has 500 steps and return 112.1.
Saved chunk: 20230921T233210F339658-7lm1I2zmtk0C81G7XoLMOP-7wR8ysvGGhfWSw0MiVsv8I-1024.npz
Starting evaluation at step 95500 Counter(95500) 95437
eval_Episode has 500 steps and return 98.0.
Saved chunk: 20230921T233234F360317-0jVH5wN4YroJ6uquNNVKg3-1t0gF9CJfwPV1rin4MiOUr-1024.npz
train_Episode has 500 steps and return 125.5.
Starting evaluation at step 96000 Counter(96000) 95937
eval_Episode has 500 steps and return 111.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 192002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 111.77 / eval_episode/reward_rate 0.28 / episode/length 500 / episode/score 125.49 / episode/reward_rate 0.33 / train/action_mag 3.04 / train/action_max 2.99 / train/action_mean 0.06 / train/action_min -2.42 / 
train/action_std 0.84 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 4.7e4 / train/actor_opt_loss -470.56 / train/adv_mag 2.68 / train/adv_max 2.67 / train/adv_mean 
0.05 / train/adv_min -0.48 / train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 1 
/ train/dyn_loss_mean 3.72 / train/dyn_loss_std 6.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 4.7e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 51.19 / train/extr_critic_max 51.19 / train/extr_critic_mean 46.09 / train/extr_critic_min 26.27 / train/extr_critic_std 2.55 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.41 / 
train/extr_return_normed_mean 0.51 / train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 53.56 / train/extr_return_raw_max 53.56 / train/extr_return_raw_mean 46.47 / train/extr_return_raw_min 
40.52 / train/extr_return_raw_std 2.71 / train/extr_reward_mag 1.16 / train/extr_reward_max 1.16 / train/extr_reward_mean 0.04 / train/extr_reward_min 0 / train/extr_reward_std 0.17 / train/image_loss_mean 1.56 / train/image_loss_std 1.4 / train/model_loss_mean 3.82 / 
train/model_loss_std 4.88 / train/model_opt_grad_norm 9.04 / train/model_opt_grad_steps 4.6e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.77 / train/policy_entropy_max 
3.27 / train/policy_entropy_mean -3.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 8.25 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.06 / train/policy_logprob_min -8.25 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 44.69 / train/post_ent_max 44.69 / train/post_ent_mean 32.16 / 
train/post_ent_min 18.98 / train/post_ent_std 4.16 / train/prior_ent_mag 77.43 / train/prior_ent_max 77.43 / train/prior_ent_mean 35.91 / train/prior_ent_min 22.83 / train/prior_ent_std 6.78 / train/rep_loss_mean 3.72 / train/rep_loss_std 6.47 / train/reward_avg 0.03 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.17 / train/reward_max_data 1.04 / train/reward_max_pred 0.98 / train/reward_neg_acc 1 / train/reward_neg_loss 1.9e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.78 / train/reward_pred 0.03 / 
train/reward_rate 0.04 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.2 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 7.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.99 / report/dyn_loss_std 5.96 / report/image_loss_mean 1.15 / report/image_loss_std 1.17 / report/model_loss_mean 2.97 / report/model_loss_std 4.42 / report/post_ent_mag 
46.84 / report/post_ent_max 46.84 / report/post_ent_mean 33.12 / report/post_ent_min 17.34 / report/post_ent_std 4.54 / report/prior_ent_mag 77.77 / report/prior_ent_max 77.77 / report/prior_ent_mean 36.24 / report/prior_ent_min 21.5 / report/prior_ent_std 6.68 / 
report/rep_loss_mean 2.99 / report/rep_loss_std 5.96 / report/reward_avg 0.01 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.23 / report/reward_max_data 1.41 / report/reward_max_pred 0.96 / report/reward_neg_acc 1 / report/reward_neg_loss 6.1e-5 / 
report/reward_pos_acc 0.94 / report/reward_pos_loss 1.39 / report/reward_pred 0.01 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 7.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.34 / eval/dyn_loss_std 9.54 / eval/image_loss_mean 2.45 / eval/image_loss_std 3.61 / eval/model_loss_mean 6.25 / eval/model_loss_std 8.82 / eval/post_ent_mag 45.67 / 
eval/post_ent_max 45.67 / eval/post_ent_mean 33.62 / eval/post_ent_min 19.18 / eval/post_ent_std 3.98 / eval/prior_ent_mag 77.77 / eval/prior_ent_max 77.77 / eval/prior_ent_mean 37.7 / eval/prior_ent_min 27.29 / eval/prior_ent_std 5.89 / eval/rep_loss_mean 6.34 / 
eval/rep_loss_std 9.54 / eval/reward_avg 0 / eval/reward_loss_mean 4.4e-7 / eval/reward_loss_std 5.2e-6 / eval/reward_max_data 0 / eval/reward_max_pred 4.8e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.4e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / 
eval/reward_pred 1.3e-7 / eval/reward_rate 0 / replay/size 9.6e4 / replay/inserts 3798 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.7e4 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.51 / timer/env.step_count 3798 / timer/env.step_total 19.83
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.58 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7806 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 9.5e-3 / timer/dataset_train_count 1899 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.2e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1899 /
timer/agent.train_total 243.24 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.4e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 140.5.
Saved chunk: 20230921T233330F671165-7wR8ysvGGhfWSw0MiVsv8I-49aNcmrg8iXQiNLSFUPIK8-1024.npz
Starting evaluation at step 96500 Counter(96500) 96437
eval_Episode has 500 steps and return 137.3.
Saved chunk: 20230921T233353F133047-1t0gF9CJfwPV1rin4MiOUr-4A0U6xCqyOBTyb4IgrhElm-1024.npz
train_Episode has 500 steps and return 118.5.
Starting evaluation at step 97000 Counter(97000) 96937
eval_Episode has 500 steps and return 132.8.
train_Episode has 500 steps and return 121.5.
Saved chunk: 20230921T233451F827401-49aNcmrg8iXQiNLSFUPIK8-6J5CUQ4j00K8qqWuxSMUgQ-1024.npz
Starting evaluation at step 97500 Counter(97500) 97437
eval_Episode has 500 steps and return 111.2.
train_Episode has 500 steps and return 129.4.
Starting evaluation at step 98000 Counter(98000) 97937
Saved chunk: 20230921T233512F845871-4A0U6xCqyOBTyb4IgrhElm-4MFZKG7Twy04LtcmdfK9c2-1024.npz
eval_Episode has 500 steps and return 124.8.
train_Episode has 500 steps and return 141.1.
Saved chunk: 20230921T233612F731258-6J5CUQ4j00K8qqWuxSMUgQ-1fIBRvoaD6xULJ7UgcobMB-1024.npz
Starting evaluation at step 98500 Counter(98500) 98437
eval_Episode has 500 steps and return 144.5.
train_Episode has 500 steps and return 132.6.
Starting evaluation at step 99000 Counter(99000) 98937
Saved chunk: 20230921T233708F055829-4MFZKG7Twy04LtcmdfK9c2-52XB89E08qhEgq0gkidaa1-1024.npz
eval_Episode has 500 steps and return 164.0.
train_Episode has 500 steps and return 158.8.
Saved chunk: 20230921T233733F336322-1fIBRvoaD6xULJ7UgcobMB-0b702dXvQaOUaVSKoEY3dJ-1024.npz
Starting evaluation at step 99500 Counter(99500) 99437
eval_Episode has 500 steps and return 146.7.
train_Episode has 500 steps and return 114.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 199650 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 114.42 / episode/reward_rate 0.28 / eval_episode/length 500 / eval_episode/score 146.68 / eval_episode/reward_rate 0.39 / train/action_mag 2.97 / train/action_max 2.9 / train/action_mean 0.07 / train/action_min -2.43 / train/action_std
0.84 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 4.8e4 / train/actor_opt_loss -440.86 / train/adv_mag 3.07 / train/adv_max 3.07 / train/adv_mean 0.05 / train/adv_min
-0.43 / train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 7.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.83 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 4.8e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 62.38 / train/extr_critic_max 62.38 / train/extr_critic_mean 56.67 / train/extr_critic_min 30.65 / train/extr_critic_std 3.15 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.35 / 
train/extr_return_normed_mean 0.53 / train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 64.92 / train/extr_return_raw_max 64.92 / train/extr_return_raw_mean 57.1 / train/extr_return_raw_min 50.79
/ train/extr_return_raw_std 3.28 / train/extr_reward_mag 1.22 / train/extr_reward_max 1.22 / train/extr_reward_mean 0.06 / train/extr_reward_min -6.2e-10 / train/extr_reward_std 0.2 / train/image_loss_mean 1.59 / train/image_loss_std 1.4 / train/model_loss_mean 3.93 / 
train/model_loss_std 4.95 / train/model_opt_grad_norm 8.95 / train/model_opt_grad_steps 4.8e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.69 / train/policy_entropy_max 
3.03 / train/policy_entropy_mean -3.07 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.67 / train/policy_logprob_mag 8.23 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.07 / train/policy_logprob_min -8.23 / train/policy_logprob_std 1.57 / 
train/policy_randomness_mag 0.71 / train/policy_randomness_max 0.71 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 45.17 / train/post_ent_max 45.17 / train/post_ent_mean 32.34 / 
train/post_ent_min 18.64 / train/post_ent_std 4.27 / train/prior_ent_mag 78.3 / train/prior_ent_max 78.3 / train/prior_ent_mean 36.18 / train/prior_ent_min 22.61 / train/prior_ent_std 6.86 / train/rep_loss_mean 3.83 / train/rep_loss_std 6.57 / train/reward_avg 0.04 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.2 / train/reward_max_data 1.14 / train/reward_max_pred 1.06 / train/reward_neg_acc 1 / train/reward_neg_loss 2.2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.76 / train/reward_pred 0.04 / 
train/reward_rate 0.06 / train_stats/mean_log_entropy -3.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.8e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 6.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.13 / report/dyn_loss_std 6.27 / report/image_loss_mean 1.2 / report/image_loss_std 1.12 / report/model_loss_mean 3.1 / report/model_loss_std 4.61 / report/post_ent_mag 43.81 
/ report/post_ent_max 43.81 / report/post_ent_mean 32.71 / report/post_ent_min 21.61 / report/post_ent_std 3.78 / report/prior_ent_mag 78.47 / report/prior_ent_max 78.47 / report/prior_ent_mean 36.07 / report/prior_ent_min 26.45 / report/prior_ent_std 6.36 / 
report/rep_loss_mean 3.13 / report/rep_loss_std 6.27 / report/reward_avg 0.03 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.14 / report/reward_max_data 1.14 / report/reward_max_pred 1.12 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.04 / report/reward_rate 0.04 / eval/cont_avg 1 / eval/cont_loss_mean 9.8e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 9.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.81 / eval/dyn_loss_std 8.9 / eval/image_loss_mean 2.18 / eval/image_loss_std 3.79 / eval/model_loss_mean 5.67 / eval/model_loss_std 8.64 / eval/post_ent_mag 47.7 / eval/post_ent_max 
47.7 / eval/post_ent_mean 32.66 / eval/post_ent_min 20.64 / eval/post_ent_std 4.01 / eval/prior_ent_mag 78.47 / eval/prior_ent_max 78.47 / eval/prior_ent_mean 36.84 / eval/prior_ent_min 22.85 / eval/prior_ent_std 6.64 / eval/rep_loss_mean 5.81 / eval/rep_loss_std 8.9 / 
eval/reward_avg 9.8e-5 / eval/reward_loss_mean 3.4e-3 / eval/reward_loss_std 0.07 / eval/reward_max_data 0.04 / eval/reward_max_pred 0.03 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 7e-5 /
eval/reward_rate 0 / replay/size 1e5 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3824 / timer/env.step_total 19.96 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 447.41 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-4 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7331 / timer/agent.policy_total 16.39 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 8.3e-3 / timer/dataset_train_count 1912 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1912 / 
timer/agent.train_total 244.74 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.49

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 100000 Counter(100000) 99937
Saved chunk: 20230921T233826F845780-52XB89E08qhEgq0gkidaa1-60P7fev5QP0v1itZn7izHy-1024.npz
eval_Episode has 500 steps and return 123.8.
train_Episode has 500 steps and return 123.3.
Saved chunk: 20230921T233853F630730-0b702dXvQaOUaVSKoEY3dJ-1Zdy14u0dgTEyD5Mrf1v2L-1024.npz
Starting evaluation at step 100500 Counter(100500) 100437
eval_Episode has 500 steps and return 115.0.
train_Episode has 500 steps and return 127.9.
Starting evaluation at step 101000 Counter(101000) 100937
Saved chunk: 20230921T233946F434981-60P7fev5QP0v1itZn7izHy-2dt1qajqltRozW3i3I98PD-1024.npz
eval_Episode has 500 steps and return 166.0.
train_Episode has 500 steps and return 127.2.
Saved chunk: 20230921T234015F062449-1Zdy14u0dgTEyD5Mrf1v2L-4eCW2tBpkotJMV5GNvwlys-1024.npz
Starting evaluation at step 101500 Counter(101500) 101437
eval_Episode has 500 steps and return 157.7.
train_Episode has 500 steps and return 142.7.
Starting evaluation at step 102000 Counter(102000) 101937
Saved chunk: 20230921T234105F903643-2dt1qajqltRozW3i3I98PD-0Pyu6m1PfrTKPc0ohO9QnJ-1024.npz
eval_Episode has 500 steps and return 167.0.
train_Episode has 500 steps and return 139.6.
Saved chunk: 20230921T234136F092222-4eCW2tBpkotJMV5GNvwlys-0eDmvC16kkmEDdgAwxPC7b-1024.npz
Starting evaluation at step 102500 Counter(102500) 102437
eval_Episode has 500 steps and return 144.1.
train_Episode has 500 steps and return 145.0.
Starting evaluation at step 103000 Counter(103000) 102937
Saved chunk: 20230921T234225F291224-0Pyu6m1PfrTKPc0ohO9QnJ-5b98dRr5D5u9JflPiiAFBf-1024.npz
eval_Episode has 500 steps and return 167.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230921T234344F433304-5b98dRr5D5u9JflPiiAFBf-0000000000000000000000-381.npz
Saved chunk: 20230921T234256F898524-0eDmvC16kkmEDdgAwxPC7b-0000000000000000000000-700.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 149.2.
Saved chunk: 20230921T234256F898524-0eDmvC16kkmEDdgAwxPC7b-73oRJ1qTbRi6qP0MdqgYkd-1024.npz
Starting evaluation at step 103500 Counter(103500) 103437
eval_Episode has 500 steps and return 168.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 207166 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 168.49 / eval_episode/reward_rate 0.38 / episode/length 500 / episode/score 149.17 / episode/reward_rate 0.33 / train/action_mag 2.83 / train/action_max 2.72 / train/action_mean 0.07 / train/action_min -2.41 / 
train/action_std 0.84 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 5e4 / train/actor_opt_loss -380.63 / train/adv_mag 2.28 / train/adv_max 2.28 / train/adv_mean 0.04 
/ train/adv_min -0.45 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 7.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 5e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 73.92 / train/extr_critic_max 73.92 / train/extr_critic_mean 67.68 / train/extr_critic_min 46.84 / train/extr_critic_std 3.47 / train/extr_return_normed_mag 1.29 / train/extr_return_normed_max 1.29 / 
train/extr_return_normed_mean 0.53 / train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 76.1 / train/extr_return_raw_max 76.1 / train/extr_return_raw_mean 68.1 / train/extr_return_raw_min 60.98 /
train/extr_return_raw_std 3.61 / train/extr_reward_mag 1.31 / train/extr_reward_max 1.31 / train/extr_reward_mean 0.07 / train/extr_reward_min 0 / train/extr_reward_std 0.22 / train/image_loss_mean 1.59 / train/image_loss_std 1.35 / train/model_loss_mean 3.98 / 
train/model_loss_std 4.96 / train/model_opt_grad_norm 9.35 / train/model_opt_grad_steps 5e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.64 / train/policy_entropy_max 2.68 
/ train/policy_entropy_mean -3.04 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.23 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.05 / train/policy_logprob_min -8.23 / train/policy_logprob_std 1.56 / 
train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.05 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 45.92 / train/post_ent_max 45.92 / train/post_ent_mean 32.54 / 
train/post_ent_min 18.76 / train/post_ent_std 4.33 / train/prior_ent_mag 79.03 / train/prior_ent_max 79.03 / train/prior_ent_mean 36.45 / train/prior_ent_min 22.67 / train/prior_ent_std 6.94 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.66 / train/reward_avg 0.05 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.21 / train/reward_max_data 1.16 / train/reward_max_pred 1.11 / train/reward_neg_acc 1 / train/reward_neg_loss 2.6e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.74 / train/reward_pred 0.05 / 
train/reward_rate 0.07 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.13 / report/cont_avg 1 / report/cont_loss_mean 9.5e-11 / report/cont_loss_std 3.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 9.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.15 / report/dyn_loss_std 7.23 / report/image_loss_mean 1.69 / report/image_loss_std 1.6 / report/model_loss_mean 4.25 / report/model_loss_std 5.59 / report/post_ent_mag 43.29
/ report/post_ent_max 43.29 / report/post_ent_mean 32.53 / report/post_ent_min 19.81 / report/post_ent_std 4.1 / report/prior_ent_mag 79.17 / report/prior_ent_max 79.17 / report/prior_ent_mean 36.76 / report/prior_ent_min 23.24 / report/prior_ent_std 6.62 / 
report/rep_loss_mean 4.15 / report/rep_loss_std 7.23 / report/reward_avg 0.07 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.23 / report/reward_max_data 1.4 / report/reward_max_pred 1.18 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.64 / report/reward_pred 0.07 / report/reward_rate 0.1 / eval/cont_avg 1 / eval/cont_loss_mean 8.9e-11 / eval/cont_loss_std 4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.94 / eval/dyn_loss_std 8.87 / eval/image_loss_mean 2.42 / eval/image_loss_std 2.84 / eval/model_loss_mean 6.61 / eval/model_loss_std 7.55 / eval/post_ent_mag 48.51 / 
eval/post_ent_max 48.51 / eval/post_ent_mean 32.72 / eval/post_ent_min 19.64 / eval/post_ent_std 4.07 / eval/prior_ent_mag 79.17 / eval/prior_ent_max 79.17 / eval/prior_ent_mean 37.66 / eval/prior_ent_min 22.78 / eval/prior_ent_std 6.46 / eval/rep_loss_mean 6.94 / 
eval/rep_loss_std 8.87 / eval/reward_avg 0.01 / eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.12 / eval/reward_max_data 0.8 / eval/reward_max_pred 0.81 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / 
eval/reward_pred 0.01 / eval/reward_rate 0.03 / replay/size 1e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3758 / timer/env.step_total 19.54
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.58 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
2.4e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7766 / timer/agent.policy_total 
17.46 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1879 / timer/agent.train_total 241.37 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.4e-8 / 
timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 99.3.
Starting evaluation at step 104000 Counter(104000) 103937
Saved chunk: 20230921T234344F433304-5b98dRr5D5u9JflPiiAFBf-61u25gE7MkoGl8bs2yLo6x-1024.npz
eval_Episode has 500 steps and return 150.6.
train_Episode has 500 steps and return 116.7.
Saved chunk: 20230921T234417F813003-73oRJ1qTbRi6qP0MdqgYkd-1DrDGhqgvpD2utB91l6Lpd-1024.npz
Starting evaluation at step 104500 Counter(104500) 104437
eval_Episode has 500 steps and return 161.1.
train_Episode has 500 steps and return 140.7.
Starting evaluation at step 105000 Counter(105000) 104937
Saved chunk: 20230921T234504F716400-61u25gE7MkoGl8bs2yLo6x-2SXRCCxInhqtqGRufrkBVq-1024.npz
eval_Episode has 500 steps and return 136.1.
train_Episode has 500 steps and return 128.6.
Saved chunk: 20230921T234539F672312-1DrDGhqgvpD2utB91l6Lpd-43ci8srDmqApCjlPrVbrdo-1024.npz
Starting evaluation at step 105500 Counter(105500) 105437
eval_Episode has 500 steps and return 163.1.
train_Episode has 500 steps and return 139.2.
Starting evaluation at step 106000 Counter(106000) 105937
Saved chunk: 20230921T234624F237021-2SXRCCxInhqtqGRufrkBVq-3PYfiJD8dGck1V6QxcVyba-1024.npz
eval_Episode has 500 steps and return 194.4.
train_Episode has 500 steps and return 143.0.
Starting evaluation at step 106500 Counter(106500) 106437
Saved chunk: 20230921T234700F674099-43ci8srDmqApCjlPrVbrdo-14RoZJIY0ZGMjoS0hogpSf-1024.npz
eval_Episode has 500 steps and return 180.8.
train_Episode has 500 steps and return 133.8.
Starting evaluation at step 107000 Counter(107000) 106937
Saved chunk: 20230921T234744F395625-3PYfiJD8dGck1V6QxcVyba-63kFqcnTtfpvkIm0Wo18df-1024.npz
eval_Episode has 500 steps and return 191.9.
train_Episode has 500 steps and return 168.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 214766 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 168.61 / episode/reward_rate 0.34 / eval_episode/length 500 / eval_episode/score 191.95 / eval_episode/reward_rate 0.41 / train/action_mag 2.88 / train/action_max 2.72 / train/action_mean 0.07 / train/action_min -2.55 / 
train/action_std 0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 5.2e4 / train/actor_opt_loss -306.25 / train/adv_mag 1.6 / train/adv_max 1.6 / train/adv_mean 0.03 
/ train/adv_min -0.46 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 7.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 5.2e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 84.97 / train/extr_critic_max 84.97 / train/extr_critic_mean 78.08 / train/extr_critic_min 61.74 / train/extr_critic_std 3.79 / train/extr_return_normed_mag 1.26 / train/extr_return_normed_max 1.26 / 
train/extr_return_normed_mean 0.52 / train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 87.2 / train/extr_return_raw_max 87.2 / train/extr_return_raw_mean 78.47 / train/extr_return_raw_min 69.92 
/ train/extr_return_raw_std 3.95 / train/extr_reward_mag 1.46 / train/extr_reward_max 1.46 / train/extr_reward_mean 0.07 / train/extr_reward_min 0 / train/extr_reward_std 0.24 / train/image_loss_mean 1.56 / train/image_loss_std 1.34 / train/model_loss_mean 3.95 / 
train/model_loss_std 4.99 / train/model_opt_grad_norm 9.1 / train/model_opt_grad_steps 5.2e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.61 / train/policy_entropy_max 
2.68 / train/policy_entropy_mean -3.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 8.25 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 3.01 / train/policy_logprob_min -8.25 / train/policy_logprob_std 1.58 / 
train/policy_randomness_mag 0.67 / train/policy_randomness_max 0.67 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.07 / train/post_ent_mag 46.93 / train/post_ent_max 46.93 / train/post_ent_mean 32.65 / 
train/post_ent_min 18.63 / train/post_ent_std 4.44 / train/prior_ent_mag 79.83 / train/prior_ent_max 79.83 / train/prior_ent_mean 36.54 / train/prior_ent_min 22.66 / train/prior_ent_std 7.1 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.72 / train/reward_avg 0.05 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.22 / train/reward_max_data 1.24 / train/reward_max_pred 1.19 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.73 / train/reward_pred 0.05 / 
train/reward_rate 0.07 / train_stats/mean_log_entropy -3.15 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 4.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 6.7 / report/image_loss_mean 1.41 / report/image_loss_std 1.1 / report/model_loss_mean 3.55 / report/model_loss_std 4.78 / report/post_ent_mag 47.97 
/ report/post_ent_max 47.97 / report/post_ent_mean 32.43 / report/post_ent_min 17.8 / report/post_ent_std 4.09 / report/prior_ent_mag 79.82 / report/prior_ent_max 79.82 / report/prior_ent_mean 35.94 / report/prior_ent_min 19.34 / report/prior_ent_std 6.91 / 
report/rep_loss_mean 3.54 / report/rep_loss_std 6.7 / report/reward_avg 0.03 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.12 / report/reward_max_data 1.12 / report/reward_max_pred 1.1 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-5 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.63 / report/reward_pred 0.03 / report/reward_rate 0.03 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.46 / eval/dyn_loss_std 7.6 / eval/image_loss_mean 1.56 / eval/image_loss_std 2.32 / eval/model_loss_mean 4.25 / eval/model_loss_std 6.39 / eval/post_ent_mag 48.58 / eval/post_ent_max
48.58 / eval/post_ent_mean 33.92 / eval/post_ent_min 21.56 / eval/post_ent_std 3.7 / eval/prior_ent_mag 79.82 / eval/prior_ent_max 79.82 / eval/prior_ent_mean 37.53 / eval/prior_ent_min 24.42 / eval/prior_ent_std 6.97 / eval/rep_loss_mean 4.46 / eval/rep_loss_std 7.6 / 
eval/reward_avg 0.01 / eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.13 / eval/reward_max_data 0.84 / eval/reward_max_pred 0.79 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.76 / eval/reward_pred 0.01 / 
eval/reward_rate 0.02 / replay/size 1.1e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3800 / timer/env.step_total 19.75 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.28 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7307 / timer/agent.policy_total 16.45 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1900 / 
timer/agent.train_total 244.84 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.99 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.33

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 107500 Counter(107500) 107437
eval_Episode has 500 steps and return 190.2.
Saved chunk: 20230921T234822F297348-14RoZJIY0ZGMjoS0hogpSf-5UtFwVhwVYkasiQiCfFopJ-1024.npz
train_Episode has 500 steps and return 180.5.
Starting evaluation at step 108000 Counter(108000) 107937
Saved chunk: 20230921T234903F373601-63kFqcnTtfpvkIm0Wo18df-7DjqSA5hC3e5Uxm8xak3Zi-1024.npz
eval_Episode has 500 steps and return 177.2.
train_Episode has 500 steps and return 168.6.
Starting evaluation at step 108500 Counter(108500) 108437
eval_Episode has 500 steps and return 168.6.
Saved chunk: 20230921T234947F116188-5UtFwVhwVYkasiQiCfFopJ-06krtC91XENnvZEjS3o4Y9-1024.npz
train_Episode has 500 steps and return 163.1.
Starting evaluation at step 109000 Counter(109000) 108937
Saved chunk: 20230921T235023F472968-7DjqSA5hC3e5Uxm8xak3Zi-1RpqK6tsrBsU45AgZYuMdh-1024.npz
eval_Episode has 500 steps and return 169.4.
train_Episode has 500 steps and return 161.4.
Starting evaluation at step 109500 Counter(109500) 109437
eval_Episode has 500 steps and return 193.2.
Saved chunk: 20230921T235108F229303-06krtC91XENnvZEjS3o4Y9-64u1oz6WQDvq0acoZOBg6Z-1024.npz
train_Episode has 500 steps and return 183.0.
Starting evaluation at step 110000 Counter(110000) 109937
Saved chunk: 20230921T235142F831460-1RpqK6tsrBsU45AgZYuMdh-5SaKkfbjMxzIkHvm1GK0nP-1024.npz
eval_Episode has 500 steps and return 186.8.
train_Episode has 500 steps and return 159.2.
Starting evaluation at step 110500 Counter(110500) 110437
eval_Episode has 500 steps and return 200.6.
Saved chunk: 20230921T235229F063496-64u1oz6WQDvq0acoZOBg6Z-7irLIXKsxVOkqp6RBxHbxc-1024.npz
train_Episode has 500 steps and return 157.0.
Starting evaluation at step 111000 Counter(111000) 110937
Saved chunk: 20230921T235302F061942-5SaKkfbjMxzIkHvm1GK0nP-1uetHSgkftjPiQUBThiDsH-1024.npz
eval_Episode has 500 steps and return 197.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 222290 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 197.84 / eval_episode/reward_rate 0.35 / episode/length 500 / episode/score 156.98 / episode/reward_rate 0.34 / train/action_mag 3.05 / train/action_max 2.82 / train/action_mean 0.08 / train/action_min -2.76 / 
train/action_std 0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 5.4e4 / train/actor_opt_loss -262.22 / train/adv_mag 1.94 / train/adv_max 1.92 / train/adv_mean 
0.03 / train/adv_min -0.52 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 6.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 3.87 / train/dyn_loss_std 6.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 5.4e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 96.38 / train/extr_critic_max 96.38 / train/extr_critic_mean 89.13 / train/extr_critic_min 65.16 / train/extr_critic_std 4.16 / train/extr_return_normed_mag 1.25 / train/extr_return_normed_max 1.25 / 
train/extr_return_normed_mean 0.54 / train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 98.85 / train/extr_return_raw_max 98.85 / train/extr_return_raw_mean 89.51 / train/extr_return_raw_min 
77.89 / train/extr_return_raw_std 4.29 / train/extr_reward_mag 1.53 / train/extr_reward_max 1.53 / train/extr_reward_mean 0.07 / train/extr_reward_min 0 / train/extr_reward_std 0.25 / train/image_loss_mean 1.52 / train/image_loss_std 1.3 / train/model_loss_mean 3.9 / 
train/model_loss_std 4.97 / train/model_opt_grad_norm 9.26 / train/model_opt_grad_steps 5.4e4 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8989.36 / train/policy_entropy_mag 3.58 / 
train/policy_entropy_max 2.92 / train/policy_entropy_mean -2.89 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.82 / train/policy_logprob_mag 8.55 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.89 / train/policy_logprob_min -8.55 / 
train/policy_logprob_std 1.64 / train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 47.25 / train/post_ent_max 47.25 / 
train/post_ent_mean 32.97 / train/post_ent_min 19.09 / train/post_ent_std 4.41 / train/prior_ent_mag 80.37 / train/prior_ent_max 80.37 / train/prior_ent_mean 36.85 / train/prior_ent_min 23.31 / train/prior_ent_std 7.11 / train/rep_loss_mean 3.87 / train/rep_loss_std 
6.72 / train/reward_avg 0.06 / train/reward_loss_mean 0.06 / train/reward_loss_std 0.22 / train/reward_max_data 1.29 / train/reward_max_pred 1.25 / train/reward_neg_acc 1 / train/reward_neg_loss 2.3e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.71 / 
train/reward_pred 0.06 / train/reward_rate 0.08 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.09 / report/cont_avg 1 / report/cont_loss_mean 9.3e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 9.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 6.98 / report/image_loss_mean 1.43 / report/image_loss_std 1.36 / report/model_loss_mean 3.64 / report/model_loss_std 5.19 / 
report/post_ent_mag 45.72 / report/post_ent_max 45.72 / report/post_ent_mean 33 / report/post_ent_min 20.09 / report/post_ent_std 4.19 / report/prior_ent_mag 80.51 / report/prior_ent_max 80.51 / report/prior_ent_mean 36.83 / report/prior_ent_min 26.4 / 
report/prior_ent_std 7.13 / report/rep_loss_mean 3.64 / report/rep_loss_std 6.98 / report/reward_avg 0.03 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.15 / report/reward_max_data 1.36 / report/reward_max_pred 1.36 / report/reward_neg_acc 1 / 
report/reward_neg_loss 6.1e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.73 / report/reward_pred 0.04 / report/reward_rate 0.04 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.68 / eval/dyn_loss_std 9.08 / eval/image_loss_mean 2.21 / eval/image_loss_std 2.98 / eval/model_loss_mean 5.65 / eval/model_loss_std 7.96 / eval/post_ent_mag 
48.08 / eval/post_ent_max 48.08 / eval/post_ent_mean 34.2 / eval/post_ent_min 18.58 / eval/post_ent_std 4.65 / eval/prior_ent_mag 80.51 / eval/prior_ent_max 80.51 / eval/prior_ent_mean 38.18 / eval/prior_ent_min 24.36 / eval/prior_ent_std 6.87 / eval/rep_loss_mean 5.68 
/ eval/rep_loss_std 9.08 / eval/reward_avg 0.03 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.19 / eval/reward_max_data 1.11 / eval/reward_max_pred 1.07 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.76 / 
eval/reward_pred 0.03 / eval/reward_rate 0.04 / replay/size 1.1e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3762 / timer/env.step_total 19.58
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 436.26 / timer/replay._sample_frac 1.45 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 1.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.4 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1881 / timer/agent.train_total 241.79 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / 
timer/dataset_eval_max 2.7e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 162.4.
Starting evaluation at step 111500 Counter(111500) 111437
eval_Episode has 500 steps and return 182.4.
Saved chunk: 20230921T235349F764017-7irLIXKsxVOkqp6RBxHbxc-5gYSUPPjABOAiTflTA8vBk-1024.npz
train_Episode has 500 steps and return 169.4.
Starting evaluation at step 112000 Counter(112000) 111937
Saved chunk: 20230921T235421F105280-1uetHSgkftjPiQUBThiDsH-1se0CN9zEfM9AchA2EoBlf-1024.npz
eval_Episode has 500 steps and return 181.6.
train_Episode has 500 steps and return 177.6.
Starting evaluation at step 112500 Counter(112500) 112437
eval_Episode has 500 steps and return 211.8.
Saved chunk: 20230921T235511F323359-5gYSUPPjABOAiTflTA8vBk-3ssv4ye0Td5ruUYZ0DyT2W-1024.npz
train_Episode has 500 steps and return 175.6.
Starting evaluation at step 113000 Counter(113000) 112937
Saved chunk: 20230921T235541F278365-1se0CN9zEfM9AchA2EoBlf-2t6mREc5JW0rN31PAoTepT-1024.npz
eval_Episode has 500 steps and return 200.3.
train_Episode has 500 steps and return 156.7.
Starting evaluation at step 113500 Counter(113500) 113437
eval_Episode has 500 steps and return 206.1.
Saved chunk: 20230921T235632F308100-3ssv4ye0Td5ruUYZ0DyT2W-74L4ePaeYYlcsQPbpfWVDA-1024.npz
train_Episode has 500 steps and return 181.2.
Starting evaluation at step 114000 Counter(114000) 113937
Saved chunk: 20230921T235700F644701-2t6mREc5JW0rN31PAoTepT-6hfxFwOL8XPsX4NNK2PcRR-1024.npz
eval_Episode has 500 steps and return 189.5.
train_Episode has 500 steps and return 173.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 114500 Counter(114500) 114437
Saved chunk: 20230921T235753F078603-74L4ePaeYYlcsQPbpfWVDA-0000000000000000000000-836.npz
Saved chunk: 20230921T235819F727974-6hfxFwOL8XPsX4NNK2PcRR-0000000000000000000000-139.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
eval_Episode has 500 steps and return 196.5.
Saved chunk: 20230921T235753F078603-74L4ePaeYYlcsQPbpfWVDA-2xsydSV55xCJa44jSTTYKj-1024.npz
train_Episode has 500 steps and return 175.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 229910 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 175.14 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 196.46 / eval_episode/reward_rate 0.39 / train/action_mag 3.05 / train/action_max 2.9 / train/action_mean 0.08 / train/action_min -2.63 / train/action_std
0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 5.6e4 / train/actor_opt_loss -270.57 / train/adv_mag 2.67 / train/adv_max 2.67 / train/adv_mean 0.03 / train/adv_min
-0.45 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.94 / train/dyn_loss_std 6.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 5.6e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 108.1 / train/extr_critic_max 108.1 / train/extr_critic_mean 100.09 / train/extr_critic_min 64.93 / train/extr_critic_std 4.75 / train/extr_return_normed_mag 1.23 / train/extr_return_normed_max 1.23 / 
train/extr_return_normed_mean 0.55 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 110.33 / train/extr_return_raw_max 110.33 / train/extr_return_raw_mean 100.51 / train/extr_return_raw_min 
88.29 / train/extr_return_raw_std 4.83 / train/extr_reward_mag 1.58 / train/extr_reward_max 1.58 / train/extr_reward_mean 0.09 / train/extr_reward_min 0 / train/extr_reward_std 0.27 / train/image_loss_mean 1.54 / train/image_loss_std 1.31 / train/model_loss_mean 3.97 / 
train/model_loss_std 5.05 / train/model_opt_grad_norm 8.91 / train/model_opt_grad_steps 5.6e4 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8368.42 / train/policy_entropy_mag 3.58 / 
train/policy_entropy_max 2.83 / train/policy_entropy_mean -2.95 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.78 / train/policy_logprob_mag 8.38 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.95 / train/policy_logprob_min -8.38 / 
train/policy_logprob_std 1.62 / train/policy_randomness_mag 0.69 / train/policy_randomness_max 0.69 / train/policy_randomness_mean 0.06 / train/policy_randomness_min 2.2e-4 / train/policy_randomness_std 0.08 / train/post_ent_mag 47.53 / train/post_ent_max 47.53 / 
train/post_ent_mean 33.07 / train/post_ent_min 18.93 / train/post_ent_std 4.53 / train/prior_ent_mag 81.08 / train/prior_ent_max 81.08 / train/prior_ent_mean 37.04 / train/prior_ent_min 22.97 / train/prior_ent_std 7.23 / train/rep_loss_mean 3.94 / train/rep_loss_std 
6.83 / train/reward_avg 0.07 / train/reward_loss_mean 0.06 / train/reward_loss_std 0.23 / train/reward_max_data 1.4 / train/reward_max_pred 1.36 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.71 / 
train/reward_pred 0.07 / train/reward_rate 0.09 / train_stats/mean_log_entropy -3.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 4.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 6.53 / report/image_loss_mean 1.63 / report/image_loss_std 1.13 / report/model_loss_mean 4.12 / report/model_loss_std 4.69 / 
report/post_ent_mag 43.7 / report/post_ent_max 43.7 / report/post_ent_mean 32.31 / report/post_ent_min 17.38 / report/post_ent_std 4.84 / report/prior_ent_mag 81.27 / report/prior_ent_max 81.27 / report/prior_ent_mean 36.46 / report/prior_ent_min 19.28 / 
report/prior_ent_std 7.7 / report/rep_loss_mean 3.99 / report/rep_loss_std 6.53 / report/reward_avg 0.12 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.25 / report/reward_max_data 1.38 / report/reward_max_pred 1.53 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.65 / report/reward_pred 0.11 / report/reward_rate 0.14 / eval/cont_avg 1 / eval/cont_loss_mean 6.3e-11 / eval/cont_loss_std 3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 6.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 11.69 / eval/dyn_loss_std 17.31 / eval/image_loss_mean 4.4 / eval/image_loss_std 6.63 / eval/model_loss_mean 11.46 / eval/model_loss_std 16.69 / eval/post_ent_mag
45.29 / eval/post_ent_max 45.29 / eval/post_ent_mean 32.19 / eval/post_ent_min 19.06 / eval/post_ent_std 4.31 / eval/prior_ent_mag 81.27 / eval/prior_ent_max 81.27 / eval/prior_ent_mean 37.91 / eval/prior_ent_min 23.17 / eval/prior_ent_std 7.22 / eval/rep_loss_mean 
11.69 / eval/rep_loss_std 17.31 / eval/reward_avg 0.03 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.19 / eval/reward_max_data 0.89 / eval/reward_max_pred 0.97 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.9e-5 / eval/reward_pos_acc 0.97 / 
eval/reward_pos_loss 0.67 / eval/reward_pred 0.03 / eval/reward_rate 0.06 / replay/size 1.1e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3810 / 
timer/env.step_total 19.77 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.7 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 
/ timer/replay._sample_min 8.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7317 
/ timer/agent.policy_total 16.55 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / 
timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1905 / timer/agent.train_total 244.72 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 115000 Counter(115000) 114937
Saved chunk: 20230921T235819F727974-6hfxFwOL8XPsX4NNK2PcRR-2H73SQcfzyobPZTRlO71Pq-1024.npz
eval_Episode has 500 steps and return 192.1.
train_Episode has 500 steps and return 180.7.
Starting evaluation at step 115500 Counter(115500) 115437
eval_Episode has 500 steps and return 184.5.
Saved chunk: 20230921T235913F938602-2xsydSV55xCJa44jSTTYKj-5VkaDt2VFKXEi94ldBT6ho-1024.npz
train_Episode has 500 steps and return 207.0.
Starting evaluation at step 116000 Counter(116000) 115937
Saved chunk: 20230921T235939F740695-2H73SQcfzyobPZTRlO71Pq-3hnXceXBfIN8Dj12eCQxai-1024.npz
eval_Episode has 500 steps and return 196.2.
train_Episode has 500 steps and return 197.5.
Starting evaluation at step 116500 Counter(116500) 116437
eval_Episode has 500 steps and return 197.1.
train_Episode has 500 steps and return 188.2.
Saved chunk: 20230922T000035F642691-5VkaDt2VFKXEi94ldBT6ho-2DCVqzKHQzIjzc5d6U4yb5-1024.npz
Starting evaluation at step 117000 Counter(117000) 116937
Saved chunk: 20230922T000059F283251-3hnXceXBfIN8Dj12eCQxai-2QfxIpw978xq6xj9N0yPZe-1024.npz
eval_Episode has 500 steps and return 221.7.
train_Episode has 500 steps and return 201.4.
Starting evaluation at step 117500 Counter(117500) 117437
eval_Episode has 500 steps and return 216.0.
train_Episode has 500 steps and return 182.1.
Saved chunk: 20230922T000156F536266-2DCVqzKHQzIjzc5d6U4yb5-6lZC2VoFkv1Ah0D506KM4I-1024.npz
Starting evaluation at step 118000 Counter(118000) 117937
Saved chunk: 20230922T000218F540743-2QfxIpw978xq6xj9N0yPZe-04TPkSCBBmvbpKBcjgDEuA-1024.npz
eval_Episode has 500 steps and return 192.3.
train_Episode has 500 steps and return 182.9.
Starting evaluation at step 118500 Counter(118500) 118437
eval_Episode has 500 steps and return 211.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 237442 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 211.18 / eval_episode/reward_rate 0.37 / episode/length 500 / episode/score 182.85 / episode/reward_rate 0.34 / train/action_mag 3.05 / train/action_max 2.95 / train/action_mean 0.09 / train/action_min -2.56 / 
train/action_std 0.85 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 5.8e4 / train/actor_opt_loss -193.31 / train/adv_mag 1.61 / train/adv_max 1.61 / train/adv_mean 
0.02 / train/adv_min -0.45 / train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 9.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 5.8e4 / 
train/extr_critic_critic_opt_loss 9875.11 / train/extr_critic_mag 117.05 / train/extr_critic_max 117.05 / train/extr_critic_mean 108.02 / train/extr_critic_min 86.66 / train/extr_critic_std 4.86 / train/extr_return_normed_mag 1.21 / train/extr_return_normed_max 1.21 / 
train/extr_return_normed_mean 0.52 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 118.64 / train/extr_return_raw_max 118.64 / train/extr_return_raw_mean 108.33 / train/extr_return_raw_min 
95.86 / train/extr_return_raw_std 5.03 / train/extr_reward_mag 1.62 / train/extr_reward_max 1.62 / train/extr_reward_mean 0.09 / train/extr_reward_min 0 / train/extr_reward_std 0.28 / train/image_loss_mean 1.51 / train/image_loss_std 1.26 / train/model_loss_mean 3.93 / 
train/model_loss_std 5 / train/model_opt_grad_norm 9.36 / train/model_opt_grad_steps 5.8e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.65 / train/policy_entropy_max 3.2 
/ train/policy_entropy_mean -2.92 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.83 / train/policy_logprob_mag 8.45 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.92 / train/policy_logprob_min -8.45 / train/policy_logprob_std 1.64 / 
train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 48.87 / train/post_ent_max 48.87 / train/post_ent_mean 33.38 / 
train/post_ent_min 19.04 / train/post_ent_std 4.56 / train/prior_ent_mag 81.53 / train/prior_ent_max 81.53 / train/prior_ent_mean 37.3 / train/prior_ent_min 23.31 / train/prior_ent_std 7.23 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.81 / train/reward_avg 0.08 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.23 / train/reward_max_data 1.43 / train/reward_max_pred 1.39 / train/reward_neg_acc 1 / train/reward_neg_loss 2.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.69 / train/reward_pred 0.08 / train/reward_rate 
0.1 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.16 / report/cont_avg 1 / report/cont_loss_mean 1.5e-10 / report/cont_loss_std 1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 6.34 / report/image_loss_mean 1.32 / report/image_loss_std 1.06 / report/model_loss_mean 3.61 / report/model_loss_std 4.62 / report/post_ent_mag 51.36 / report/post_ent_max 51.36 /
report/post_ent_mean 33.44 / report/post_ent_min 22.42 / report/post_ent_std 4.19 / report/prior_ent_mag 81.98 / report/prior_ent_max 81.98 / report/prior_ent_mean 37.08 / report/prior_ent_min 26.26 / report/prior_ent_std 6.96 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 6.34 / report/reward_avg 0.12 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.32 / report/reward_max_data 1.79 / report/reward_max_pred 1.63 / report/reward_neg_acc 1 / report/reward_neg_loss 5.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.81 / report/reward_pred 0.12 / report/reward_rate 0.12 / eval/cont_avg 1 / eval/cont_loss_mean 7.4e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.33 / eval/dyn_loss_std 8.71 / eval/image_loss_mean 2.32 / eval/image_loss_std 2.96 / eval/model_loss_mean 6.16 / eval/model_loss_std 7.81 / eval/post_ent_mag 47.82 / eval/post_ent_max 47.82 / eval/post_ent_mean 
34.63 / eval/post_ent_min 17.53 / eval/post_ent_std 4.54 / eval/prior_ent_mag 81.98 / eval/prior_ent_max 81.98 / eval/prior_ent_mean 38.8 / eval/prior_ent_min 23.89 / eval/prior_ent_std 6.46 / eval/rep_loss_mean 6.33 / eval/rep_loss_std 8.71 / eval/reward_avg 0.03 / 
eval/reward_loss_mean 0.05 / eval/reward_loss_std 0.24 / eval/reward_max_data 1.19 / eval/reward_max_pred 1.14 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.5e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.91 / eval/reward_pred 0.03 / eval/reward_rate 0.05 / 
replay/size 1.2e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3766 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.98 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.48 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.7 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.8e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 172.5.
Saved chunk: 20230922T000317F270383-6lZC2VoFkv1Ah0D506KM4I-3V6C8NQH2Fwu6zwDyVLFrO-1024.npz
Starting evaluation at step 119000 Counter(119000) 118937
eval_Episode has 500 steps and return 210.8.
Saved chunk: 20230922T000337F600860-04TPkSCBBmvbpKBcjgDEuA-5u0PhpaRA4iSRoRxA8CUgn-1024.npz
train_Episode has 500 steps and return 161.6.
Starting evaluation at step 119500 Counter(119500) 119437
eval_Episode has 500 steps and return 214.9.
train_Episode has 500 steps and return 199.0.
Saved chunk: 20230922T000438F449317-3V6C8NQH2Fwu6zwDyVLFrO-3GNZqgQ9lMUu1703JMrpI1-1024.npz
Starting evaluation at step 120000 Counter(120000) 119937
eval_Episode has 500 steps and return 200.4.
Saved chunk: 20230922T000457F336650-5u0PhpaRA4iSRoRxA8CUgn-7tV5IB3x2CiypAGMYmd2L7-1024.npz
train_Episode has 500 steps and return 179.2.
Starting evaluation at step 120500 Counter(120500) 120437
eval_Episode has 500 steps and return 211.7.
train_Episode has 500 steps and return 208.6.
Saved chunk: 20230922T000559F503317-3GNZqgQ9lMUu1703JMrpI1-4DCHxPwgB1PWBempw6jafE-1024.npz
Starting evaluation at step 121000 Counter(121000) 120937
eval_Episode has 500 steps and return 192.0.
train_Episode has 500 steps and return 160.9.
Starting evaluation at step 121500 Counter(121500) 121437
Saved chunk: 20230922T000616F798014-7tV5IB3x2CiypAGMYmd2L7-2MWfLm6kJ6c0ASlux5ecuM-1024.npz
eval_Episode has 500 steps and return 178.6.
train_Episode has 500 steps and return 130.2.
Saved chunk: 20230922T000720F419707-4DCHxPwgB1PWBempw6jafE-0oIYQU8oGrSKyJv5jFSZD7-1024.npz
Starting evaluation at step 122000 Counter(122000) 121937
eval_Episode has 500 steps and return 204.8.
train_Episode has 500 steps and return 189.1.
Starting evaluation at step 122500 Counter(122500) 122437
Saved chunk: 20230922T000811F952767-2MWfLm6kJ6c0ASlux5ecuM-2vG9JLjiFYDkWlFvA3kOqu-1024.npz
eval_Episode has 500 steps and return 190.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 245002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 189.15 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 190.87 / eval_episode/reward_rate 0.4 / train_stats/mean_log_entropy -3.12 / train/action_mag 2.93 / train/action_max 2.61 / train/action_mean 0.08 / 
train/action_min -2.8 / train/action_std 0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 6e4 / train/actor_opt_loss -203.47 / train/adv_mag 2.03 / train/adv_max 
2.03 / train/adv_mean 0.02 / train/adv_min -0.42 / train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 5.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 
/ train/cont_rate 1 / train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / 
train/extr_critic_critic_opt_grad_steps 6e4 / train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 127.54 / train/extr_critic_max 127.54 / train/extr_critic_mean 118.4 / train/extr_critic_min 85.52 / train/extr_critic_std 5.58 / train/extr_return_normed_mag 
1.17 / train/extr_return_normed_max 1.17 / train/extr_return_normed_mean 0.55 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 129.28 / train/extr_return_raw_max 129.28 / 
train/extr_return_raw_mean 118.77 / train/extr_return_raw_min 104.48 / train/extr_return_raw_std 5.62 / train/extr_reward_mag 1.68 / train/extr_reward_max 1.68 / train/extr_reward_mean 0.1 / train/extr_reward_min 0 / train/extr_reward_std 0.3 / train/image_loss_mean 
1.48 / train/image_loss_std 1.26 / train/model_loss_mean 3.89 / train/model_loss_std 5.02 / train/model_opt_grad_norm 9.07 / train/model_opt_grad_steps 6e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 3.6 / train/policy_entropy_max 2.93 / train/policy_entropy_mean -2.87 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.62 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.87 / 
train/policy_logprob_min -8.62 / train/policy_logprob_std 1.66 / train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 3.9e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 48.85 / 
train/post_ent_max 48.85 / train/post_ent_mean 33.66 / train/post_ent_min 19.28 / train/post_ent_std 4.54 / train/prior_ent_mag 82.03 / train/prior_ent_max 82.03 / train/prior_ent_mean 37.55 / train/prior_ent_min 23.41 / train/prior_ent_std 7.26 / train/rep_loss_mean 
3.9 / train/rep_loss_std 6.84 / train/reward_avg 0.09 / train/reward_loss_mean 0.07 / train/reward_loss_std 0.24 / train/reward_max_data 1.5 / train/reward_max_pred 1.46 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 0.99 / 
train/reward_pos_loss 0.69 / train/reward_pred 0.09 / train/reward_rate 0.1 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.78 / report/dyn_loss_std 6.81 / report/image_loss_mean 1.37 / report/image_loss_std 0.96 / report/model_loss_mean 3.72 / report/model_loss_std 4.76 / report/post_ent_mag 46.49 
/ report/post_ent_max 46.49 / report/post_ent_mean 33.96 / report/post_ent_min 21.3 / report/post_ent_std 4.06 / report/prior_ent_mag 81.98 / report/prior_ent_max 81.98 / report/prior_ent_mean 37.71 / report/prior_ent_min 24.93 / report/prior_ent_std 6.96 / 
report/rep_loss_mean 3.78 / report/rep_loss_std 6.81 / report/reward_avg 0.07 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.23 / report/reward_max_data 1.14 / report/reward_max_pred 1.17 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.66 / report/reward_pred 0.07 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.91 / eval/dyn_loss_std 8.41 / eval/image_loss_mean 2.46 / eval/image_loss_std 2.51 / eval/model_loss_mean 6.69 / eval/model_loss_std 7.07 / eval/post_ent_mag 52.91 / 
eval/post_ent_max 52.91 / eval/post_ent_mean 34 / eval/post_ent_min 19.89 / eval/post_ent_std 4.14 / eval/prior_ent_mag 81.98 / eval/prior_ent_max 81.98 / eval/prior_ent_mean 39.2 / eval/prior_ent_min 26.99 / eval/prior_ent_std 6.79 / eval/rep_loss_mean 6.91 / 
eval/rep_loss_std 8.41 / eval/reward_avg 0.07 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.11 / eval/reward_max_pred 1.16 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.7e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.74 / 
eval/reward_pred 0.07 / eval/reward_rate 0.11 / replay/size 1.2e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.97 / timer/env.step_count 3780 / timer/env.step_total 19.65
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.24 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7788 / timer/agent.policy_total 17.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.3e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.4e-4 
/ timer/agent.train_count 1890 / timer/agent.train_total 242.46 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / 
timer/dataset_eval_max 4e-5 / fps 25.12

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 173.3.
Saved chunk: 20230922T000840F872060-0oIYQU8oGrSKyJv5jFSZD7-1Kdz7ebIVgWr6yTNgocnaT-1024.npz
Starting evaluation at step 123000 Counter(123000) 122937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 190.8.
Starting evaluation at step 123500 Counter(123500) 123437
Saved chunk: 20230922T000930F837090-2vG9JLjiFYDkWlFvA3kOqu-5r5JShT3kVWDmr3GeDNoaR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 209.5.
Saved chunk: 20230922T001002F185250-1Kdz7ebIVgWr6yTNgocnaT-7ivLRuc6d4g52RMqrZMq93-1024.npz
Starting evaluation at step 124000 Counter(124000) 123937
eval_Episode has 500 steps and return 198.2.
train_Episode has 500 steps and return 187.0.
Starting evaluation at step 124500 Counter(124500) 124437
Saved chunk: 20230922T001050F979573-5r5JShT3kVWDmr3GeDNoaR-4m5pcV9pEVkZkRFRrjLGzx-1024.npz
eval_Episode has 500 steps and return 217.3.
train_Episode has 500 steps and return 168.2.
Saved chunk: 20230922T001123F267817-7ivLRuc6d4g52RMqrZMq93-7cke4X5FqIzFFqMwQ1Iata-1024.npz
Starting evaluation at step 125000 Counter(125000) 124937
eval_Episode has 500 steps and return 204.9.
train_Episode has 500 steps and return 207.7.
Starting evaluation at step 125500 Counter(125500) 125437
Saved chunk: 20230922T001210F355742-4m5pcV9pEVkZkRFRrjLGzx-1LcQcIivScsvSP0DJNblkp-1024.npz
eval_Episode has 500 steps and return 235.2.
train_Episode has 500 steps and return 195.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T001329F431462-1LcQcIivScsvSP0DJNblkp-0000000000000000000000-398.npz
Saved chunk: 20230922T001244F167576-7cke4X5FqIzFFqMwQ1Iata-0000000000000000000000-973.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T001244F167576-7cke4X5FqIzFFqMwQ1Iata-5IOjuqHFqhg3b30fIqnu5z-1024.npz
Starting evaluation at step 126000 Counter(126000) 125937
eval_Episode has 500 steps and return 193.6.
train_Episode has 500 steps and return 193.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 252626 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 193.47 / episode/reward_rate 0.38 / eval_episode/length 500 / eval_episode/score 193.65 / eval_episode/reward_rate 0.37 / train/action_mag 2.86 / train/action_max 2.52 / train/action_mean 0.1 / train/action_min -2.77 / train/action_std
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 6.2e4 / train/actor_opt_loss -103.41 / train/adv_mag 1.28 / train/adv_max 1.26 / train/adv_mean 0.01 / train/adv_min
-0.45 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 9.9e-11 / train/cont_loss_std 5.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.99 / train/dyn_loss_std 6.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 6.2e4 / 
train/extr_critic_critic_opt_loss 9500.38 / train/extr_critic_mag 133.29 / train/extr_critic_max 133.29 / train/extr_critic_mean 124.5 / train/extr_critic_min 105.57 / train/extr_critic_std 5.12 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.17 / 
train/extr_return_normed_mean 0.52 / train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 134.98 / train/extr_return_raw_max 134.98 / train/extr_return_raw_mean 124.68 / train/extr_return_raw_min 
111.59 / train/extr_return_raw_std 5.26 / train/extr_reward_mag 1.72 / train/extr_reward_max 1.72 / train/extr_reward_mean 0.12 / train/extr_reward_min 0 / train/extr_reward_std 0.33 / train/image_loss_mean 1.5 / train/image_loss_std 1.25 / train/model_loss_mean 3.98 / 
train/model_loss_std 5.06 / train/model_opt_grad_norm 9.04 / train/model_opt_grad_steps 6.2e4 / train/model_opt_loss 4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.53 / train/policy_entropy_max 
2.53 / train/policy_entropy_mean -2.86 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.8 / train/policy_logprob_mag 8.65 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.86 / train/policy_logprob_min -8.65 / train/policy_logprob_std 1.63 / 
train/policy_randomness_mag 0.66 / train/policy_randomness_max 0.66 / train/policy_randomness_mean 0.07 / train/policy_randomness_min 4.8e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 49.48 / train/post_ent_max 49.48 / train/post_ent_mean 33.83 / 
train/post_ent_min 19.56 / train/post_ent_std 4.53 / train/prior_ent_mag 82.45 / train/prior_ent_max 82.45 / train/prior_ent_mean 37.82 / train/prior_ent_min 23.98 / train/prior_ent_std 7.26 / train/rep_loss_mean 3.99 / train/rep_loss_std 6.92 / train/reward_avg 0.1 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.25 / train/reward_max_data 1.54 / train/reward_max_pred 1.52 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.67 / train/reward_pred 0.1 / train/reward_rate 
0.12 / train_stats/mean_log_entropy -3.03 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.7e-11 / report/cont_loss_std 3.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.44 / report/dyn_loss_std 6.34 / report/image_loss_mean 1.23 / report/image_loss_std 0.96 / report/model_loss_mean 3.37 / report/model_loss_std 4.55 / report/post_ent_mag 46.61 / report/post_ent_max 46.61 /
report/post_ent_mean 34.9 / report/post_ent_min 21.02 / report/post_ent_std 4.3 / report/prior_ent_mag 82.71 / report/prior_ent_max 82.71 / report/prior_ent_mean 38.36 / report/prior_ent_min 25.28 / report/prior_ent_std 6.66 / report/rep_loss_mean 3.44 / 
report/rep_loss_std 6.34 / report/reward_avg 0.11 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.24 / report/reward_max_data 1.77 / report/reward_max_pred 1.79 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.67 / report/reward_pred 0.11 / report/reward_rate 0.12 / eval/cont_avg 1 / eval/cont_loss_mean 7.6e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.92 / eval/dyn_loss_std 7.68 / eval/image_loss_mean 1.86 / eval/image_loss_std 2.49 / eval/model_loss_mean 4.88 / eval/model_loss_std 6.62 / eval/post_ent_mag 49.4 / eval/post_ent_max 49.4 / eval/post_ent_mean 
35.47 / eval/post_ent_min 16.74 / eval/post_ent_std 4.58 / eval/prior_ent_mag 82.71 / eval/prior_ent_max 82.71 / eval/prior_ent_mean 39.56 / eval/prior_ent_min 27.03 / eval/prior_ent_std 6.39 / eval/rep_loss_mean 4.92 / eval/rep_loss_std 7.68 / eval/reward_avg 0.05 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.13 / eval/reward_max_pred 1.19 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.77 / eval/reward_pred 0.06 / eval/reward_rate 0.09 / 
replay/size 1.3e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3812 / timer/env.step_total 19.83 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.82 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.2e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.59 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.7 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / 
timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 126500 Counter(126500) 126437
Saved chunk: 20230922T001329F431462-1LcQcIivScsvSP0DJNblkp-2o76BHuPeb8JzNAgOFGum9-1024.npz
eval_Episode has 500 steps and return 232.0.
train_Episode has 500 steps and return 212.5.
Saved chunk: 20230922T001404F861225-5IOjuqHFqhg3b30fIqnu5z-1EnIGysdowFzsV298aU7Ox-1024.npz
Starting evaluation at step 127000 Counter(127000) 126937
eval_Episode has 500 steps and return 210.2.
train_Episode has 500 steps and return 200.7.
Starting evaluation at step 127500 Counter(127500) 127437
Saved chunk: 20230922T001449F467429-2o76BHuPeb8JzNAgOFGum9-0MBcVzkLVgjLCc2qOj4szP-1024.npz
eval_Episode has 500 steps and return 202.6.
train_Episode has 500 steps and return 215.1.
Starting evaluation at step 128000 Counter(128000) 127937
Saved chunk: 20230922T001526F597944-1EnIGysdowFzsV298aU7Ox-1TAc0nDazkIP88NgHOATMz-1024.npz
eval_Episode has 500 steps and return 233.8.
train_Episode has 500 steps and return 202.8.
Starting evaluation at step 128500 Counter(128500) 128437
Saved chunk: 20230922T001609F022294-0MBcVzkLVgjLCc2qOj4szP-2FJGFFAUDKXBWJCj5XQ4fy-1024.npz
eval_Episode has 500 steps and return 213.4.
train_Episode has 500 steps and return 196.1.
Starting evaluation at step 129000 Counter(129000) 128937
eval_Episode has 500 steps and return 228.8.
Saved chunk: 20230922T001647F605242-1TAc0nDazkIP88NgHOATMz-39C3EScaPK4PUBnj5SuCBl-1024.npz
train_Episode has 500 steps and return 185.0.
Starting evaluation at step 129500 Counter(129500) 129437
Saved chunk: 20230922T001728F378224-2FJGFFAUDKXBWJCj5XQ4fy-6nLMbnIXxcvD3lppcllTXU-1024.npz
eval_Episode has 500 steps and return 222.2.
train_Episode has 500 steps and return 221.8.
Starting evaluation at step 130000 Counter(130000) 129937
eval_Episode has 500 steps and return 221.2.
Saved chunk: 20230922T001811F967789-39C3EScaPK4PUBnj5SuCBl-0cjLdmIAcCNSFoLQPwGLE1-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 260146 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 221.2 / eval_episode/reward_rate 0.4 / episode/length 500 / episode/score 221.81 / episode/reward_rate 0.43 / train/action_mag 2.87 / train/action_max 2.56 / train/action_mean 0.1 / train/action_min -2.74 / train/action_std 
0.86 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 6.4e4 / train/actor_opt_loss -133.68 / train/adv_mag 1.59 / train/adv_max 1.58 / train/adv_mean 0.01 / train/adv_min
-0.41 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 9.5e-11 / train/cont_loss_std 4.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.93 / train/dyn_loss_std 6.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 6.4e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 140.2 / train/extr_critic_max 140.2 / train/extr_critic_mean 129.76 / train/extr_critic_min 102.04 / train/extr_critic_std 6.19 / train/extr_return_normed_mag 1.15 / train/extr_return_normed_max 1.15 / 
train/extr_return_normed_mean 0.55 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 141.22 / train/extr_return_raw_max 141.22 / train/extr_return_raw_mean 130.04 / train/extr_return_raw_min 
114.18 / train/extr_return_raw_std 6.31 / train/extr_reward_mag 1.75 / train/extr_reward_max 1.75 / train/extr_reward_mean 0.12 / train/extr_reward_min 0 / train/extr_reward_std 0.33 / train/image_loss_mean 1.45 / train/image_loss_std 1.2 / train/model_loss_mean 3.89 / 
train/model_loss_std 5.01 / train/model_opt_grad_norm 9.34 / train/model_opt_grad_steps 6.4e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.61 / train/policy_entropy_max 
2.97 / train/policy_entropy_mean -2.84 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.56 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.84 / train/policy_logprob_min -8.56 / train/policy_logprob_std 1.67 / 
train/policy_randomness_mag 0.71 / train/policy_randomness_max 0.71 / train/policy_randomness_mean 0.08 / train/policy_randomness_min 3.5e-4 / train/policy_randomness_std 0.09 / train/post_ent_mag 49.65 / train/post_ent_max 49.65 / train/post_ent_mean 34.09 / 
train/post_ent_min 19.57 / train/post_ent_std 4.5 / train/prior_ent_mag 82.77 / train/prior_ent_max 82.77 / train/prior_ent_mean 38.02 / train/prior_ent_min 24.2 / train/prior_ent_std 7.26 / train/rep_loss_mean 3.93 / train/rep_loss_std 6.9 / train/reward_avg 0.11 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.25 / train/reward_max_data 1.59 / train/reward_max_pred 1.56 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.66 / train/reward_pred 0.11 / train/reward_rate 
0.12 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -3.11 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 3.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.23 / report/dyn_loss_std 7.14 / report/image_loss_mean 1.66 / report/image_loss_std 1.24 / report/model_loss_mean 4.34 / report/model_loss_std 5.1 / report/post_ent_mag 51.34 / report/post_ent_max 51.34 / 
report/post_ent_mean 33.93 / report/post_ent_min 19.48 / report/post_ent_std 4.8 / report/prior_ent_mag 83 / report/prior_ent_max 83 / report/prior_ent_mean 38.31 / report/prior_ent_min 25.71 / report/prior_ent_std 7.4 / report/rep_loss_mean 4.23 / report/rep_loss_std 
7.14 / report/reward_avg 0.19 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.32 / report/reward_max_data 1.64 / report/reward_max_pred 1.58 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.68 / 
report/reward_pred 0.19 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 4.73 / eval/dyn_loss_std 7.43 / eval/image_loss_mean 1.45 / eval/image_loss_std 1.47 / eval/model_loss_mean 4.42 / eval/model_loss_std 5.65 / eval/post_ent_mag 54.32 / eval/post_ent_max 54.32 / eval/post_ent_mean 35.4 / eval/post_ent_min 19.21 / 
eval/post_ent_std 4.24 / eval/prior_ent_mag 83 / eval/prior_ent_max 83 / eval/prior_ent_mean 39.5 / eval/prior_ent_min 27 / eval/prior_ent_std 6.47 / eval/rep_loss_mean 4.73 / eval/rep_loss_std 7.43 / eval/reward_avg 0.11 / eval/reward_loss_mean 0.13 / 
eval/reward_loss_std 0.42 / eval/reward_max_data 1.24 / eval/reward_max_pred 1.21 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 0.97 / eval/reward_pos_loss 0.8 / eval/reward_pred 0.11 / eval/reward_rate 0.15 / replay/size 1.3e5 / 
replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3760 / timer/env.step_total 19.58 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 
4.5e-3 / timer/env.step_max 7.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 441.16 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.52 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count
1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.65 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 207.2.
Starting evaluation at step 130500 Counter(130500) 130437
Saved chunk: 20230922T001847F510889-6nLMbnIXxcvD3lppcllTXU-75EStZ6ZhJ8hszf9TYnt4l-1024.npz
eval_Episode has 500 steps and return 205.1.
train_Episode has 500 steps and return 169.8.
Starting evaluation at step 131000 Counter(131000) 130937
eval_Episode has 500 steps and return 227.1.
Saved chunk: 20230922T001932F604263-0cjLdmIAcCNSFoLQPwGLE1-1Byg9ke0z4coYZ2EmoEq7w-1024.npz
train_Episode has 500 steps and return 216.8.
Starting evaluation at step 131500 Counter(131500) 131437
Saved chunk: 20230922T002007F515427-75EStZ6ZhJ8hszf9TYnt4l-47Bddd8avcfbc9leTS7iew-1024.npz
eval_Episode has 500 steps and return 232.3.
train_Episode has 500 steps and return 218.2.
Starting evaluation at step 132000 Counter(132000) 131937
eval_Episode has 500 steps and return 229.8.
Saved chunk: 20230922T002054F491407-1Byg9ke0z4coYZ2EmoEq7w-0ehGDDOXkLgeN38KmJXart-1024.npz
train_Episode has 500 steps and return 206.5.
Starting evaluation at step 132500 Counter(132500) 132437
Saved chunk: 20230922T002127F037209-47Bddd8avcfbc9leTS7iew-6aSEsE0Cra5PMe8rXX24Yc-1024.npz
eval_Episode has 500 steps and return 211.5.
train_Episode has 500 steps and return 217.4.
Starting evaluation at step 133000 Counter(133000) 132937
eval_Episode has 500 steps and return 220.8.
Saved chunk: 20230922T002215F427333-0ehGDDOXkLgeN38KmJXart-3Kz6JVaKktEP88o9CyGg9a-1024.npz
train_Episode has 500 steps and return 174.3.
Starting evaluation at step 133500 Counter(133500) 133437
Saved chunk: 20230922T002246F292784-6aSEsE0Cra5PMe8rXX24Yc-1g2r2eNPrTsZQU4iQQmHOr-1024.npz
eval_Episode has 500 steps and return 229.7.
train_Episode has 500 steps and return 173.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 267770 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 173.66 / episode/reward_rate 0.35 / eval_episode/length 500 / eval_episode/score 229.73 / eval_episode/reward_rate 0.43 / train/action_mag 2.92 / train/action_max 2.61 / train/action_mean 0.09 / train/action_min -2.82 / 
train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.24 / train/actor_opt_grad_steps 6.5e4 / train/actor_opt_loss -120.26 / train/adv_mag 1.72 / train/adv_max 1.71 / train/adv_mean 
0.01 / train/adv_min -0.41 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 8.8e-11 / train/cont_loss_std 4.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.8e-11 / train/cont_pred 1 / train/cont_rate 
1 / train/dyn_loss_mean 3.93 / train/dyn_loss_std 6.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 6.5e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 148.06 / train/extr_critic_max 148.06 / train/extr_critic_mean 137.66 / train/extr_critic_min 103.42 / train/extr_critic_std 6.69 / train/extr_return_normed_mag 1.13 / train/extr_return_normed_max 1.13 / 
train/extr_return_normed_mean 0.58 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 149.09 / train/extr_return_raw_max 149.09 / train/extr_return_raw_mean 137.93 / train/extr_return_raw_min 
120.01 / train/extr_return_raw_std 6.72 / train/extr_reward_mag 1.77 / train/extr_reward_max 1.77 / train/extr_reward_mean 0.13 / train/extr_reward_min 0 / train/extr_reward_std 0.34 / train/image_loss_mean 1.44 / train/image_loss_std 1.2 / train/model_loss_mean 3.88 / 
train/model_loss_std 5.01 / train/model_opt_grad_norm 9.35 / train/model_opt_grad_steps 6.5e4 / train/model_opt_loss 3.9e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.59 / train/policy_entropy_max 
2.76 / train/policy_entropy_mean -2.73 / train/policy_entropy_min -3.53 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.84 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.73 / train/policy_logprob_min -8.84 / train/policy_logprob_std 1.7 / 
train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.09 / train/policy_randomness_min 3.7e-4 / train/policy_randomness_std 0.1 / train/post_ent_mag 49.85 / train/post_ent_max 49.85 / train/post_ent_mean 34.36 / 
train/post_ent_min 19.6 / train/post_ent_std 4.5 / train/prior_ent_mag 83.11 / train/prior_ent_max 83.11 / train/prior_ent_mean 38.29 / train/prior_ent_min 24.39 / train/prior_ent_std 7.26 / train/rep_loss_mean 3.93 / train/rep_loss_std 6.91 / train/reward_avg 0.11 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.25 / train/reward_max_data 1.57 / train/reward_max_pred 1.56 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.65 / train/reward_pred 0.11 / train/reward_rate 
0.13 / train_stats/mean_log_entropy -2.98 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.8e-11 / report/cont_loss_std 6.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 6.79 / report/image_loss_mean 1.25 / report/image_loss_std 0.97 / report/model_loss_mean 3.56 / report/model_loss_std 4.76 / report/post_ent_mag 51.5 / report/post_ent_max 51.5 / 
report/post_ent_mean 34.6 / report/post_ent_min 17.8 / report/post_ent_std 4.23 / report/prior_ent_mag 83.4 / report/prior_ent_max 83.4 / report/prior_ent_mean 38.36 / report/prior_ent_min 23.52 / report/prior_ent_std 7.18 / report/rep_loss_mean 3.74 / 
report/rep_loss_std 6.79 / report/reward_avg 0.1 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.24 / report/reward_max_data 1.63 / report/reward_max_pred 1.58 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.09 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 7.7e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 8.1 / eval/dyn_loss_std 12.13 / eval/image_loss_mean 2.86 / eval/image_loss_std 4.64 / eval/model_loss_mean 7.76 / eval/model_loss_std 11.49 / eval/post_ent_mag 52.29 / eval/post_ent_max 52.29 / eval/post_ent_mean
32.76 / eval/post_ent_min 18.31 / eval/post_ent_std 5.2 / eval/prior_ent_mag 83.4 / eval/prior_ent_max 83.4 / eval/prior_ent_mean 37.92 / eval/prior_ent_min 20.6 / eval/prior_ent_std 8.25 / eval/rep_loss_mean 8.1 / eval/rep_loss_std 12.13 / eval/reward_avg 0.03 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.27 / eval/reward_max_data 1.1 / eval/reward_max_pred 1.11 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.7e-4 / eval/reward_pos_acc 0.96 / eval/reward_pos_loss 0.89 / eval/reward_pred 0.03 / eval/reward_rate 0.05 / 
replay/size 1.3e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3812 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.9 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.87 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 134000 Counter(134000) 133937
eval_Episode has 500 steps and return 197.4.
Saved chunk: 20230922T002336F145158-3Kz6JVaKktEP88o9CyGg9a-7x4SEqP5zjInmLtTY8gQKS-1024.npz
train_Episode has 500 steps and return 225.5.
Starting evaluation at step 134500 Counter(134500) 134437
Saved chunk: 20230922T002405F344167-1g2r2eNPrTsZQU4iQQmHOr-2U5LyNaZCLmmwQ5CKhg0tv-1024.npz
eval_Episode has 500 steps and return 223.3.
train_Episode has 500 steps and return 205.7.
Starting evaluation at step 135000 Counter(135000) 134937
eval_Episode has 500 steps and return 192.5.
Saved chunk: 20230922T002457F598535-7x4SEqP5zjInmLtTY8gQKS-02anbGs2vQ553998nvDEou-1024.npz
train_Episode has 500 steps and return 212.7.
Starting evaluation at step 135500 Counter(135500) 135437
Saved chunk: 20230922T002525F512773-2U5LyNaZCLmmwQ5CKhg0tv-6Xd4p8zrTdEkFH2amFam05-1024.npz
eval_Episode has 500 steps and return 228.7.
train_Episode has 500 steps and return 194.7.
Starting evaluation at step 136000 Counter(136000) 135937
eval_Episode has 500 steps and return 208.9.
Saved chunk: 20230922T002618F665375-02anbGs2vQ553998nvDEou-3hYmAR44relK0bHbhbvO8T-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 136500 Counter(136500) 136437
Saved chunk: 20230922T002644F838908-6Xd4p8zrTdEkFH2amFam05-3HFZMu6REKvVFYg0tKrxLg-1024.npz
eval_Episode has 500 steps and return 190.4.
train_Episode has 500 steps and return 234.7.
Starting evaluation at step 137000 Counter(137000) 136937
eval_Episode has 500 steps and return 242.8.
Saved chunk: 20230922T002739F469308-3hYmAR44relK0bHbhbvO8T-3U5ADc2SvUVJJ9k73yqQ8F-1024.npz
train_Episode has 500 steps and return 215.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T002900F039371-3U5ADc2SvUVJJ9k73yqQ8F-0000000000000000000000-84.npz
Saved chunk: 20230922T002804F024348-3HFZMu6REKvVFYg0tKrxLg-0000000000000000000000-657.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 137500 Counter(137500) 137437
Saved chunk: 20230922T002804F024348-3HFZMu6REKvVFYg0tKrxLg-68Xt1zBeGVM4oI9Cvj9TRT-1024.npz
eval_Episode has 500 steps and return 212.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 275290 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 212.39 / eval_episode/reward_rate 0.37 / episode/length 500 / episode/score 215.3 / episode/reward_rate 0.4 / train/action_mag 3.11 / train/action_max 2.77 / train/action_mean 0.09 / train/action_min -3.03 / train/action_std 
0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 6.7e4 / train/actor_opt_loss -64.75 / train/adv_mag 1.48 / train/adv_max 1.47 / train/adv_mean 7.4e-3 / 
train/adv_min -0.41 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 8.7e-11 / train/cont_loss_std 4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 6.7e4 / 
train/extr_critic_critic_opt_loss 9943.1 / train/extr_critic_mag 152.78 / train/extr_critic_max 152.78 / train/extr_critic_mean 143.69 / train/extr_critic_min 117.44 / train/extr_critic_std 6.07 / train/extr_return_normed_mag 1.12 / train/extr_return_normed_max 1.12 / 
train/extr_return_normed_mean 0.55 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 154.51 / train/extr_return_raw_max 154.51 / train/extr_return_raw_mean 143.82 / train/extr_return_raw_min 
128.08 / train/extr_return_raw_std 6.14 / train/extr_reward_mag 1.78 / train/extr_reward_max 1.78 / train/extr_reward_mean 0.14 / train/extr_reward_min 0 / train/extr_reward_std 0.36 / train/image_loss_mean 1.41 / train/image_loss_std 1.17 / train/model_loss_mean 3.84 /
train/model_loss_std 5.01 / train/model_opt_grad_norm 9.29 / train/model_opt_grad_steps 6.7e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.75 / train/policy_entropy_max 
3.29 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.03 / train/policy_logprob_mag 9.17 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -9.17 / train/policy_logprob_std 1.75 / 
train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 4e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 49.76 / train/post_ent_max 49.76 / train/post_ent_mean 34.6 / 
train/post_ent_min 19.56 / train/post_ent_std 4.48 / train/prior_ent_mag 83.46 / train/prior_ent_max 83.46 / train/prior_ent_mean 38.5 / train/prior_ent_min 24.42 / train/prior_ent_std 7.25 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.93 / train/reward_avg 0.12 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.25 / train/reward_max_data 1.6 / train/reward_max_pred 1.57 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.65 / train/reward_pred 0.12 / train/reward_rate 
0.13 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.75 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 6.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 7.13 / report/image_loss_mean 1.28 / report/image_loss_std 1.19 / report/model_loss_mean 3.63 / report/model_loss_std 5.17 / report/post_ent_mag 46.59 / report/post_ent_max 46.59 /
report/post_ent_mean 33.82 / report/post_ent_min 20.38 / report/post_ent_std 5.43 / report/prior_ent_mag 83.71 / report/prior_ent_max 83.71 / report/prior_ent_mean 37.37 / report/prior_ent_min 20.83 / report/prior_ent_std 8.43 / report/rep_loss_mean 3.75 / 
report/rep_loss_std 7.13 / report/reward_avg 0.15 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.25 / report/reward_max_data 1.67 / report/reward_max_pred 1.61 / report/reward_neg_acc 1 / report/reward_neg_loss 5.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.15 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 1e-10 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.36 / eval/dyn_loss_std 7.14 / eval/image_loss_mean 1.59 / eval/image_loss_std 2.17 / eval/model_loss_mean 4.27 / eval/model_loss_std 5.8 / eval/post_ent_mag 53.24 / eval/post_ent_max 53.24 / eval/post_ent_mean 33.91 / 
eval/post_ent_min 18.89 / eval/post_ent_std 6.2 / eval/prior_ent_mag 83.71 / eval/prior_ent_max 83.71 / eval/prior_ent_mean 37.52 / eval/prior_ent_min 21.96 / eval/prior_ent_std 8.53 / eval/rep_loss_mean 4.36 / eval/rep_loss_std 7.14 / eval/reward_avg 0.08 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.22 / eval/reward_max_data 1.37 / eval/reward_max_pred 1.31 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.66 / eval/reward_pred 0.08 / eval/reward_rate 0.1 / 
replay/size 1.4e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3760 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.34 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.58 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.32 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 
0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 225.7.
Starting evaluation at step 138000 Counter(138000) 137937
eval_Episode has 500 steps and return 238.5.
Saved chunk: 20230922T002900F039371-3U5ADc2SvUVJJ9k73yqQ8F-3D1rsrGMp9ktEdiEK4wzmB-1024.npz
train_Episode has 500 steps and return 183.2.
Starting evaluation at step 138500 Counter(138500) 138437
Saved chunk: 20230922T002923F258633-68Xt1zBeGVM4oI9Cvj9TRT-4kNcFiyHYjEu9olFsJXkIG-1024.npz
eval_Episode has 500 steps and return 221.4.
train_Episode has 500 steps and return 203.8.
Starting evaluation at step 139000 Counter(139000) 138937
eval_Episode has 500 steps and return 226.6.
Saved chunk: 20230922T003021F819101-3D1rsrGMp9ktEdiEK4wzmB-4kAHK7N8517QVYzbXXy2hS-1024.npz
train_Episode has 500 steps and return 198.7.
Starting evaluation at step 139500 Counter(139500) 139437
Saved chunk: 20230922T003043F344956-4kNcFiyHYjEu9olFsJXkIG-6lveE1E7mqMmmlpbCtG2MZ-1024.npz
eval_Episode has 500 steps and return 223.9.
train_Episode has 500 steps and return 226.6.
Starting evaluation at step 140000 Counter(140000) 139937
eval_Episode has 500 steps and return 239.4.
train_Episode has 500 steps and return 219.0.
Saved chunk: 20230922T003142F739220-4kAHK7N8517QVYzbXXy2hS-3xhd5PoUStId3xxp0zKK5X-1024.npz
Starting evaluation at step 140500 Counter(140500) 140437
Saved chunk: 20230922T003202F621120-6lveE1E7mqMmmlpbCtG2MZ-0hxbqz81wyLrJvmDfxDgDw-1024.npz
eval_Episode has 500 steps and return 249.8.
train_Episode has 500 steps and return 204.0.
Starting evaluation at step 141000 Counter(141000) 140937
eval_Episode has 500 steps and return 244.1.
train_Episode has 500 steps and return 210.3.
Saved chunk: 20230922T003303F448044-3xhd5PoUStId3xxp0zKK5X-4IGupV8tltN5sZMJZE5ZZc-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 282922 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 210.31 / episode/reward_rate 0.38 / eval_episode/length 500 / eval_episode/score 244.08 / eval_episode/reward_rate 0.45 / train/action_mag 3.31 / train/action_max 2.87 / train/action_mean 0.1 / train/action_min -3.24 / train/action_std
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 6.9e4 / train/actor_opt_loss -29.59 / train/adv_mag 0.62 / train/adv_max 0.57 / train/adv_mean 3.8e-3 / 
train/adv_min -0.36 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 8.7e-11 / train/cont_loss_std 4.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.91 / train/dyn_loss_std 6.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 6.9e4 / 
train/extr_critic_critic_opt_loss 8949.49 / train/extr_critic_mag 155.74 / train/extr_critic_max 155.74 / train/extr_critic_mean 145.39 / train/extr_critic_min 123.81 / train/extr_critic_std 7.18 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 156.62 / train/extr_return_raw_max 156.62 / train/extr_return_raw_mean 145.48 / train/extr_return_raw_min 
123.85 / train/extr_return_raw_std 7.31 / train/extr_reward_mag 1.8 / train/extr_reward_max 1.8 / train/extr_reward_mean 0.15 / train/extr_reward_min 0 / train/extr_reward_std 0.37 / train/image_loss_mean 1.39 / train/image_loss_std 1.15 / train/model_loss_mean 3.83 / 
train/model_loss_std 5 / train/model_opt_grad_norm 9.4 / train/model_opt_grad_steps 6.9e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.9 / train/policy_entropy_max 3.68 /
train/policy_entropy_mean -2.5 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.1 / train/policy_logprob_mag 9.31 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.5 / train/policy_logprob_min -9.31 / train/policy_logprob_std 1.79 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 50.4 / train/post_ent_max 50.4 / train/post_ent_mean 34.88 / 
train/post_ent_min 19.69 / train/post_ent_std 4.51 / train/prior_ent_mag 83.68 / train/prior_ent_max 83.68 / train/prior_ent_mean 38.79 / train/prior_ent_min 24.61 / train/prior_ent_std 7.23 / train/rep_loss_mean 3.91 / train/rep_loss_std 6.93 / train/reward_avg 0.13 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.25 / train/reward_max_data 1.62 / train/reward_max_pred 1.6 / train/reward_neg_acc 1 / train/reward_neg_loss 2.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.64 / train/reward_pred 0.13 / train/reward_rate 
0.14 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.8e-11 / report/cont_loss_std 3.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 7.06 / report/image_loss_mean 1.31 / report/image_loss_std 0.98 / report/model_loss_mean 3.51 / report/model_loss_std 4.91 / report/post_ent_mag 52.39 / report/post_ent_max 52.39 /
report/post_ent_mean 34.94 / report/post_ent_min 16.94 / report/post_ent_std 4.71 / report/prior_ent_mag 84.19 / report/prior_ent_max 84.19 / report/prior_ent_mean 38.91 / report/prior_ent_min 22.6 / report/prior_ent_std 7.41 / report/rep_loss_mean 3.58 / 
report/rep_loss_std 7.06 / report/reward_avg 0.08 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.18 / report/reward_max_data 1.51 / report/reward_max_pred 1.51 / report/reward_neg_acc 1 / report/reward_neg_loss 6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.63 / report/reward_pred 0.08 / report/reward_rate 0.08 / eval/cont_avg 1 / eval/cont_loss_mean 6.9e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.73 / eval/dyn_loss_std 9.8 / eval/image_loss_mean 2.22 / eval/image_loss_std 3 / eval/model_loss_mean 6.36 / eval/model_loss_std 8.26 / eval/post_ent_mag 50.61 / eval/post_ent_max 50.61 / eval/post_ent_mean 
34.88 / eval/post_ent_min 17.05 / eval/post_ent_std 4.75 / eval/prior_ent_mag 84.19 / eval/prior_ent_max 84.19 / eval/prior_ent_mean 40.07 / eval/prior_ent_min 26.45 / eval/prior_ent_std 7.12 / eval/rep_loss_mean 6.73 / eval/rep_loss_std 9.8 / eval/reward_avg 0.11 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.4 / eval/reward_max_pred 1.36 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.6e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.68 / eval/reward_pred 0.11 / eval/reward_rate 0.14 / 
replay/size 1.4e5 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3816 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 442.63 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-4 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7323 / timer/agent.policy_total 16.43 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1908 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1908 / timer/agent.train_total 244.84 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 141500 Counter(141500) 141437
Saved chunk: 20230922T003321F711190-0hxbqz81wyLrJvmDfxDgDw-43DPZuluF7l3qqEYtvSSkw-1024.npz
eval_Episode has 500 steps and return 236.8.
train_Episode has 500 steps and return 226.0.
Starting evaluation at step 142000 Counter(142000) 141937
eval_Episode has 500 steps and return 208.7.
train_Episode has 500 steps and return 202.5.
Saved chunk: 20230922T003423F969790-4IGupV8tltN5sZMJZE5ZZc-5h59CsU4CnHss5UVsYaNJC-1024.npz
Starting evaluation at step 142500 Counter(142500) 142437
eval_Episode has 500 steps and return 217.9.
Saved chunk: 20230922T003441F455270-43DPZuluF7l3qqEYtvSSkw-6gEAproxti5gaOeI5L6gG4-1024.npz
train_Episode has 500 steps and return 234.2.
Starting evaluation at step 143000 Counter(143000) 142937
eval_Episode has 500 steps and return 217.9.
train_Episode has 500 steps and return 209.0.
Saved chunk: 20230922T003545F641959-5h59CsU4CnHss5UVsYaNJC-2vZRvOveBAuTopCwQXBLX5-1024.npz
Starting evaluation at step 143500 Counter(143500) 143437
eval_Episode has 500 steps and return 235.3.
Saved chunk: 20230922T003600F812190-6gEAproxti5gaOeI5L6gG4-5xHicrmtNebg54K7YEB1Tc-1024.npz
train_Episode has 500 steps and return 210.6.
Starting evaluation at step 144000 Counter(144000) 143937
eval_Episode has 500 steps and return 240.6.
train_Episode has 500 steps and return 225.5.
Saved chunk: 20230922T003706F575323-2vZRvOveBAuTopCwQXBLX5-0aNHkJYPNhuAlYUpGFItFs-1024.npz
Starting evaluation at step 144500 Counter(144500) 144437
eval_Episode has 500 steps and return 218.5.
train_Episode has 500 steps and return 201.7.
Starting evaluation at step 145000 Counter(145000) 144937
Saved chunk: 20230922T003720F155056-5xHicrmtNebg54K7YEB1Tc-1EAr63y2S2sGML5a7cKfzo-1024.npz
eval_Episode has 500 steps and return 227.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 290450 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 227.72 / eval_episode/reward_rate 0.41 / episode/length 500 / episode/score 201.69 / episode/reward_rate 0.37 / train/action_mag 3.23 / train/action_max 3 / train/action_mean 0.1 / train/action_min -3.06 / train/action_std 
0.88 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 7.1e4 / train/actor_opt_loss -44.61 / train/adv_mag 1.25 / train/adv_max 1.22 / train/adv_mean 5.3e-3 / 
train/adv_min -0.36 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 8.5e-11 / train/cont_loss_std 4.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.9 / train/dyn_loss_std 6.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 7.1e4 / 
train/extr_critic_critic_opt_loss 8457.5 / train/extr_critic_mag 158.8 / train/extr_critic_max 158.8 / train/extr_critic_mean 147.24 / train/extr_critic_min 108.78 / train/extr_critic_std 8.94 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.67 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 159.35 / train/extr_return_raw_max 159.35 / train/extr_return_raw_mean 147.39 / train/extr_return_raw_min 
118.6 / train/extr_return_raw_std 9.01 / train/extr_reward_mag 1.81 / train/extr_reward_max 1.81 / train/extr_reward_mean 0.15 / train/extr_reward_min 0 / train/extr_reward_std 0.38 / train/image_loss_mean 1.39 / train/image_loss_std 1.16 / train/model_loss_mean 3.82 / 
train/model_loss_std 4.99 / train/model_opt_grad_norm 9.28 / train/model_opt_grad_steps 7.1e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.99 / train/policy_entropy_max 
3.81 / train/policy_entropy_mean -2.41 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.62 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.41 / train/policy_logprob_min -9.62 / train/policy_logprob_std 1.8 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 6.1e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 51 / train/post_ent_max 51 / train/post_ent_mean 35.08 / train/post_ent_min
19.69 / train/post_ent_std 4.58 / train/prior_ent_mag 83.93 / train/prior_ent_max 83.93 / train/prior_ent_mean 38.97 / train/prior_ent_min 24.1 / train/prior_ent_std 7.32 / train/rep_loss_mean 3.9 / train/rep_loss_std 6.93 / train/reward_avg 0.14 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.25 / train/reward_max_data 1.65 / train/reward_max_pred 1.63 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred 0.14 / train/reward_rate 
0.15 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.69 / report/cont_avg 1 / report/cont_loss_mean 6.9e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.34 / report/dyn_loss_std 6.63 / report/image_loss_mean 1.19 / report/image_loss_std 0.99 / report/model_loss_mean 3.3 / report/model_loss_std 4.66 / report/post_ent_mag 52.47 / report/post_ent_max 52.47 / 
report/post_ent_mean 36.68 / report/post_ent_min 22.86 / report/post_ent_std 3.51 / report/prior_ent_mag 83.92 / report/prior_ent_max 83.92 / report/prior_ent_mean 39.82 / report/prior_ent_min 27.99 / report/prior_ent_std 6.42 / report/rep_loss_mean 3.34 / 
report/rep_loss_std 6.63 / report/reward_avg 0.15 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.24 / report/reward_max_data 1.47 / report/reward_max_pred 1.47 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.15 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 8.5e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6 / eval/dyn_loss_std 8.6 / eval/image_loss_mean 1.97 / eval/image_loss_std 2.67 / eval/model_loss_mean 5.66 / eval/model_loss_std 7.25 / eval/post_ent_mag 47.42 / eval/post_ent_max 47.42 / eval/post_ent_mean 
33.58 / eval/post_ent_min 18.93 / eval/post_ent_std 6.59 / eval/prior_ent_mag 83.92 / eval/prior_ent_max 83.92 / eval/prior_ent_mean 37.79 / eval/prior_ent_min 19.28 / eval/prior_ent_std 9.24 / eval/rep_loss_mean 6 / eval/rep_loss_std 8.6 / eval/reward_avg 0.1 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.28 / eval/reward_max_data 1.69 / eval/reward_max_pred 1.63 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.11 / eval/reward_rate 0.13 / 
replay/size 1.5e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3764 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 439.43 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1882 / timer/agent.train_total 241.67 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 221.8.
Saved chunk: 20230922T003827F301761-0aNHkJYPNhuAlYUpGFItFs-4VEBRmj6Db6E6YoulZFtPU-1024.npz
Starting evaluation at step 145500 Counter(145500) 145437
eval_Episode has 500 steps and return 224.5.
train_Episode has 500 steps and return 219.7.
Starting evaluation at step 146000 Counter(146000) 145937
Saved chunk: 20230922T003915F231819-1EAr63y2S2sGML5a7cKfzo-5W0H6qos2AY5KD9VlLVWkZ-1024.npz
eval_Episode has 500 steps and return 220.7.
train_Episode has 500 steps and return 232.7.
Saved chunk: 20230922T003948F720045-4VEBRmj6Db6E6YoulZFtPU-5bEbq3T7bf8NCnsZbWvYIP-1024.npz
Starting evaluation at step 146500 Counter(146500) 146437
eval_Episode has 500 steps and return 242.1.
train_Episode has 500 steps and return 246.1.
Starting evaluation at step 147000 Counter(147000) 146937
Saved chunk: 20230922T004035F313523-5W0H6qos2AY5KD9VlLVWkZ-1Rktn9s8xUq6swZ59O7R5o-1024.npz
eval_Episode has 500 steps and return 238.0.
train_Episode has 500 steps and return 233.5.
Saved chunk: 20230922T004109F691134-5bEbq3T7bf8NCnsZbWvYIP-0zKdAnAUrCj14cy0UQZpl6-1024.npz
Starting evaluation at step 147500 Counter(147500) 147437
eval_Episode has 500 steps and return 227.7.
train_Episode has 500 steps and return 219.2.
Starting evaluation at step 148000 Counter(148000) 147937
Saved chunk: 20230922T004154F608082-1Rktn9s8xUq6swZ59O7R5o-1q2LXTNqIZQyg8PE5KadWI-1024.npz
eval_Episode has 500 steps and return 225.4.
train_Episode has 500 steps and return 196.4.
Saved chunk: 20230922T004230F491098-0zKdAnAUrCj14cy0UQZpl6-0Q3SzzBMNjS6Hx28BIprXU-1024.npz
Starting evaluation at step 148500 Counter(148500) 148437
eval_Episode has 500 steps and return 239.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T004351F042722-0Q3SzzBMNjS6Hx28BIprXU-0000000000000000000000-220.npz
Saved chunk: 20230922T004313F674427-1q2LXTNqIZQyg8PE5KadWI-0000000000000000000000-916.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 220.6.
Starting evaluation at step 149000 Counter(149000) 148937
Saved chunk: 20230922T004313F674427-1q2LXTNqIZQyg8PE5KadWI-27r30iiIiBk9FFKkxkDcrR-1024.npz
eval_Episode has 500 steps and return 242.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 298002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 220.61 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 242.71 / eval_episode/reward_rate 0.42 / train/action_mag 3.59 / train/action_max 3.33 / train/action_mean 0.1 / train/action_min -3.42 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 7.3e4 / train/actor_opt_loss -46.31 / train/adv_mag 1.63 / train/adv_max 1.6 / train/adv_mean 5.4e-3 / train/adv_min
-0.34 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 8.2e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.92 / train/dyn_loss_std 6.94 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 7.3e4 / 
train/extr_critic_critic_opt_loss 9272.86 / train/extr_critic_mag 162.23 / train/extr_critic_max 162.23 / train/extr_critic_mean 151.15 / train/extr_critic_min 100.88 / train/extr_critic_std 8.77 / train/extr_return_normed_mag 1.27 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 162.75 / train/extr_return_raw_max 162.75 / train/extr_return_raw_mean 151.32 / train/extr_return_raw_min 
122.94 / train/extr_return_raw_std 8.79 / train/extr_reward_mag 1.83 / train/extr_reward_max 1.83 / train/extr_reward_mean 0.16 / train/extr_reward_min 0 / train/extr_reward_std 0.39 / train/image_loss_mean 1.39 / train/image_loss_std 1.15 / train/model_loss_mean 3.84 /
train/model_loss_std 5.01 / train/model_opt_grad_norm 9.08 / train/model_opt_grad_steps 7.3e4 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7354.5 / train/policy_entropy_mag 4.75 / 
train/policy_entropy_max 4.75 / train/policy_entropy_mean -2.12 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.45 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.12 / train/policy_logprob_min -10.45 / 
train/policy_logprob_std 2 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 8.9e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.28 / train/post_ent_max 51.28 / 
train/post_ent_mean 35.39 / train/post_ent_min 19.73 / train/post_ent_std 4.59 / train/prior_ent_mag 84.12 / train/prior_ent_max 84.12 / train/prior_ent_mean 39.32 / train/prior_ent_min 24.38 / train/prior_ent_std 7.28 / train/rep_loss_mean 3.92 / train/rep_loss_std 
6.94 / train/reward_avg 0.15 / train/reward_loss_mean 0.1 / train/reward_loss_std 0.26 / train/reward_max_data 1.66 / train/reward_max_pred 1.64 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / 
train/reward_pred 0.15 / train/reward_rate 0.16 / train_stats/mean_log_entropy -2.51 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.3e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 7.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 6.92 / report/image_loss_mean 1.31 / report/image_loss_std 1.06 / report/model_loss_mean 3.62 / report/model_loss_std 4.96 / 
report/post_ent_mag 50.38 / report/post_ent_max 50.38 / report/post_ent_mean 35.03 / report/post_ent_min 20.51 / report/post_ent_std 4.81 / report/prior_ent_mag 84.29 / report/prior_ent_max 84.29 / report/prior_ent_mean 38.79 / report/prior_ent_min 22.7 / 
report/prior_ent_std 7.51 / report/rep_loss_mean 3.7 / report/rep_loss_std 6.92 / report/reward_avg 0.13 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.23 / report/reward_max_data 1.71 / report/reward_max_pred 1.72 / report/reward_neg_acc 1 / 
report/reward_neg_loss 5.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.13 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 7.6e-11 / eval/cont_loss_std 3.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.65 / eval/dyn_loss_std 8.14 / eval/image_loss_mean 1.92 / eval/image_loss_std 2.76 / eval/model_loss_mean 5.48 / eval/model_loss_std 7.33 / eval/post_ent_mag 
48.47 / eval/post_ent_max 48.47 / eval/post_ent_mean 34.45 / eval/post_ent_min 16.42 / eval/post_ent_std 5.57 / eval/prior_ent_mag 84.29 / eval/prior_ent_max 84.29 / eval/prior_ent_mean 38.64 / eval/prior_ent_min 19.9 / eval/prior_ent_std 8.2 / eval/rep_loss_mean 5.65 /
eval/rep_loss_std 8.14 / eval/reward_avg 0.14 / eval/reward_loss_mean 0.16 / eval/reward_loss_std 0.63 / eval/reward_max_data 1.51 / eval/reward_max_pred 1.52 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 1.02 / 
eval/reward_pred 0.13 / eval/reward_rate 0.15 / replay/size 1.5e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.03 / timer/env.step_count 3776 / timer/env.step_total 19.57
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 440.5 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
6.1e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7784 / timer/agent.policy_total 
17.47 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / 
timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1888 / timer/agent.train_total 242.54 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / 
timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.5e-5 / timer/dataset_eval_frac
8.3e-8 / timer/dataset_eval_avg 2.5e-5 / timer/dataset_eval_min 2.5e-5 / timer/dataset_eval_max 2.5e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 227.4.
Starting evaluation at step 149500 Counter(149500) 149437
eval_Episode has 500 steps and return 234.1.
Saved chunk: 20230922T004351F042722-0Q3SzzBMNjS6Hx28BIprXU-4WSNq0zNgS4hhoeDYwIjEB-1024.npz
train_Episode has 500 steps and return 221.2.
Starting evaluation at step 150000 Counter(150000) 149937
Saved chunk: 20230922T004432F868559-27r30iiIiBk9FFKkxkDcrR-5QjYyNYJjqY02ylP0hbOMG-1024.npz
eval_Episode has 500 steps and return 226.0.
train_Episode has 500 steps and return 210.1.
Starting evaluation at step 150500 Counter(150500) 150437
eval_Episode has 500 steps and return 227.1.
Saved chunk: 20230922T004516F506063-4WSNq0zNgS4hhoeDYwIjEB-4jfFN42s2af0z2yrzo09UH-1024.npz
train_Episode has 500 steps and return 229.9.
Starting evaluation at step 151000 Counter(151000) 150937
Saved chunk: 20230922T004553F242423-5QjYyNYJjqY02ylP0hbOMG-1L0NjSWEmp8pr5DC97WDOi-1024.npz
eval_Episode has 500 steps and return 235.2.
train_Episode has 500 steps and return 210.3.
Starting evaluation at step 151500 Counter(151500) 151437
eval_Episode has 500 steps and return 217.6.
Saved chunk: 20230922T004637F503641-4jfFN42s2af0z2yrzo09UH-20dRDCvHVECA1hJKwTwOAd-1024.npz
train_Episode has 500 steps and return 231.7.
Starting evaluation at step 152000 Counter(152000) 151937
Saved chunk: 20230922T004712F549536-1L0NjSWEmp8pr5DC97WDOi-4mrsJrIlEB8kmhQU4U7Uka-1024.npz
eval_Episode has 500 steps and return 246.9.
train_Episode has 500 steps and return 212.1.
Starting evaluation at step 152500 Counter(152500) 152437
eval_Episode has 500 steps and return 237.8.
Saved chunk: 20230922T004758F279042-20dRDCvHVECA1hJKwTwOAd-7bFC60XF7QMUxpQdRShQt6-1024.npz
train_Episode has 500 steps and return 243.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 305622 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 243.05 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 237.81 / eval_episode/reward_rate 0.42 / train/action_mag 3.6 / train/action_max 3.49 / train/action_mean 0.1 / train/action_min -3.35 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 7.5e4 / train/actor_opt_loss -41.54 / train/adv_mag 0.86 / train/adv_max 0.81 / train/adv_mean 4.9e-3 / 
train/adv_min -0.33 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 8e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 7.5e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 166.51 / train/extr_critic_max 166.51 / train/extr_critic_mean 154.85 / train/extr_critic_min 118.28 / train/extr_critic_std 9.81 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.69 / train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 166.98 / train/extr_return_raw_max 166.98 / train/extr_return_raw_mean 155 / train/extr_return_raw_min 
122.44 / train/extr_return_raw_std 9.83 / train/extr_reward_mag 1.84 / train/extr_reward_max 1.84 / train/extr_reward_mean 0.16 / train/extr_reward_min 0 / train/extr_reward_std 0.39 / train/image_loss_mean 1.35 / train/image_loss_std 1.12 / train/model_loss_mean 3.78 /
train/model_loss_std 5.01 / train/model_opt_grad_norm 9.32 / train/model_opt_grad_steps 7.5e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.53 / train/policy_entropy_max 
4.51 / train/policy_entropy_mean -2.11 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.58 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.1 / train/policy_logprob_min -10.58 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 50.92 / train/post_ent_max 50.92 / train/post_ent_mean 35.61 / 
train/post_ent_min 19.99 / train/post_ent_std 4.63 / train/prior_ent_mag 84.29 / train/prior_ent_max 84.29 / train/prior_ent_mean 39.51 / train/prior_ent_min 24.65 / train/prior_ent_std 7.31 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.96 / train/reward_avg 0.15 / 
train/reward_loss_mean 0.1 / train/reward_loss_std 0.26 / train/reward_max_data 1.68 / train/reward_max_pred 1.66 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.63 / train/reward_pred 0.15 / train/reward_rate 
0.16 / train_stats/mean_log_entropy -2.55 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.6e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.92 / report/dyn_loss_std 6.91 / report/image_loss_mean 1.38 / report/image_loss_std 1.25 / report/model_loss_mean 3.88 / report/model_loss_std 5.15 / report/post_ent_mag 52.34 / report/post_ent_max 52.34 /
report/post_ent_mean 36.71 / report/post_ent_min 19.5 / report/post_ent_std 4.31 / report/prior_ent_mag 84 / report/prior_ent_max 84 / report/prior_ent_mean 40.47 / report/prior_ent_min 28.3 / report/prior_ent_std 6.44 / report/rep_loss_mean 3.92 / report/rep_loss_std 
6.91 / report/reward_avg 0.18 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.34 / report/reward_max_data 1.7 / report/reward_max_pred 1.69 / report/reward_neg_acc 1 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.69 / 
report/reward_pred 0.18 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.49 / eval/dyn_loss_std 6.03 / eval/image_loss_mean 1.04 / eval/image_loss_std 0.64 / eval/model_loss_mean 3.26 / eval/model_loss_std 4.14 / eval/post_ent_mag 46.6 / eval/post_ent_max 46.6 / eval/post_ent_mean 38.34 / eval/post_ent_min 25.63 / 
eval/post_ent_std 3.13 / eval/prior_ent_mag 84 / eval/prior_ent_max 84 / eval/prior_ent_mean 41.58 / eval/prior_ent_min 33.65 / eval/prior_ent_std 5.84 / eval/rep_loss_mean 3.49 / eval/rep_loss_std 6.03 / eval/reward_avg 0.19 / eval/reward_loss_mean 0.13 / 
eval/reward_loss_std 0.31 / eval/reward_max_data 1.64 / eval/reward_max_pred 1.63 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.65 / eval/reward_pred 0.19 / eval/reward_rate 0.19 / replay/size 1.5e5 / 
replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3810 / timer/env.step_total 19.78 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 
4.5e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.48 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7317 / timer/agent.policy_total 16.48 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count
1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1905 / timer/agent.train_total 244.72 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 153000 Counter(153000) 152937
Saved chunk: 20230922T004831F672052-4mrsJrIlEB8kmhQU4U7Uka-2kxfzJ5uqYWvhG8uFTLsHq-1024.npz
eval_Episode has 500 steps and return 220.2.
train_Episode has 500 steps and return 212.3.
Starting evaluation at step 153500 Counter(153500) 153437
eval_Episode has 500 steps and return 245.6.
Saved chunk: 20230922T004918F880534-7bFC60XF7QMUxpQdRShQt6-6i9oLePlvzsZIxLkdlSgka-1024.npz
train_Episode has 500 steps and return 215.7.
Starting evaluation at step 154000 Counter(154000) 153937
Saved chunk: 20230922T004951F583452-2kxfzJ5uqYWvhG8uFTLsHq-3EXpcmLLa8gLi0wleH3YUj-1024.npz
eval_Episode has 500 steps and return 242.7.
train_Episode has 500 steps and return 222.3.
Starting evaluation at step 154500 Counter(154500) 154437
eval_Episode has 500 steps and return 227.9.
Saved chunk: 20230922T005040F663719-6i9oLePlvzsZIxLkdlSgka-3M7bhgGpfuKZGwFmcvk3ij-1024.npz
train_Episode has 500 steps and return 232.0.
Starting evaluation at step 155000 Counter(155000) 154937
Saved chunk: 20230922T005111F046600-3EXpcmLLa8gLi0wleH3YUj-4a5Bi7Xby7NYSMyws2E6IL-1024.npz
eval_Episode has 500 steps and return 228.4.
train_Episode has 500 steps and return 214.0.
Starting evaluation at step 155500 Counter(155500) 155437
eval_Episode has 500 steps and return 218.2.
Saved chunk: 20230922T005201F583859-3M7bhgGpfuKZGwFmcvk3ij-5uMKdFq8fv26baK5ElNoMD-1024.npz
train_Episode has 500 steps and return 218.1.
Starting evaluation at step 156000 Counter(156000) 155937
Saved chunk: 20230922T005230F361658-4a5Bi7Xby7NYSMyws2E6IL-2t0Vsvk9JhXr4K8k3UGlOW-1024.npz
eval_Episode has 500 steps and return 246.2.
train_Episode has 500 steps and return 201.5.
Starting evaluation at step 156500 Counter(156500) 156437
eval_Episode has 500 steps and return 235.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 313146 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 235.65 / eval_episode/reward_rate 0.38 / episode/length 500 / episode/score 201.53 / episode/reward_rate 0.34 / train/action_mag 3.69 / train/action_max 3.6 / train/action_mean 0.11 / train/action_min -3.34 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 7.7e4 / train/actor_opt_loss -24.41 / train/adv_mag 0.56 / train/adv_max 0.49 / train/adv_mean 3.1e-3 / train/adv_min
-0.33 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 7.8e-11 / train/cont_loss_std 4.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.87 / train/dyn_loss_std 6.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 7.7e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 170.15 / train/extr_critic_max 170.15 / train/extr_critic_mean 158.77 / train/extr_critic_min 125.13 / train/extr_critic_std 9.85 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.7 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 170.61 / train/extr_return_raw_max 170.61 / train/extr_return_raw_mean 158.87 / train/extr_return_raw_min 
126.58 / train/extr_return_raw_std 9.89 / train/extr_reward_mag 1.85 / train/extr_reward_max 1.85 / train/extr_reward_mean 0.18 / train/extr_reward_min 0 / train/extr_reward_std 0.41 / train/image_loss_mean 1.32 / train/image_loss_std 1.1 / train/model_loss_mean 3.75 / 
train/model_loss_std 4.97 / train/model_opt_grad_norm 9.11 / train/model_opt_grad_steps 7.7e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.46 / train/policy_entropy_max 
4.41 / train/policy_entropy_mean -2.16 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.37 / train/policy_logprob_mag 10.36 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.16 / train/policy_logprob_min -10.36 / train/policy_logprob_std 1.99 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.15 / train/post_ent_max 51.15 / train/post_ent_mean 35.95 / 
train/post_ent_min 20.09 / train/post_ent_std 4.58 / train/prior_ent_mag 84.5 / train/prior_ent_max 84.5 / train/prior_ent_mean 39.83 / train/prior_ent_min 25.07 / train/prior_ent_std 7.26 / train/rep_loss_mean 3.87 / train/rep_loss_std 6.92 / train/reward_avg 0.16 / 
train/reward_loss_mean 0.11 / train/reward_loss_std 0.27 / train/reward_max_data 1.7 / train/reward_max_pred 1.69 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.62 / train/reward_pred 0.16 / train/reward_rate 
0.17 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.56 / report/cont_avg 1 / report/cont_loss_mean 4.7e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.18 / report/dyn_loss_std 7.13 / report/image_loss_mean 1.42 / report/image_loss_std 1.13 / report/model_loss_mean 4.05 / report/model_loss_std 5.12 / report/post_ent_mag 47.9 / report/post_ent_max 47.9 / 
report/post_ent_mean 36.87 / report/post_ent_min 21.39 / report/post_ent_std 4.61 / report/prior_ent_mag 84.44 / report/prior_ent_max 84.44 / report/prior_ent_mean 40.94 / report/prior_ent_min 27.42 / report/prior_ent_std 6.77 / report/rep_loss_mean 4.18 / 
report/rep_loss_std 7.13 / report/reward_avg 0.17 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.27 / report/reward_max_data 1.64 / report/reward_max_pred 1.56 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.17 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.41 / eval/dyn_loss_std 8.72 / eval/image_loss_mean 2.16 / eval/image_loss_std 2.66 / eval/model_loss_mean 6.14 / eval/model_loss_std 7.37 / eval/post_ent_mag 46.29 / eval/post_ent_max 46.29 / eval/post_ent_mean 
35.69 / eval/post_ent_min 19.56 / eval/post_ent_std 4.92 / eval/prior_ent_mag 84.44 / eval/prior_ent_max 84.44 / eval/prior_ent_mean 41.29 / eval/prior_ent_min 23.38 / eval/prior_ent_std 6.77 / eval/rep_loss_mean 6.41 / eval/rep_loss_std 8.72 / eval/reward_avg 0.2 / 
eval/reward_loss_mean 0.14 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.72 / eval/reward_max_pred 1.69 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.67 / eval/reward_pred 0.2 / eval/reward_rate 0.21 / 
replay/size 1.6e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3762 / timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 437.06 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / 
timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.36 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T005322F319105-5uMKdFq8fv26baK5ElNoMD-2eFlfcjWE9zQ6Um6x5nsKY-1024.npz
train_Episode has 500 steps and return 179.7.
Starting evaluation at step 157000 Counter(157000) 156937
Saved chunk: 20230922T005349F446016-2t0Vsvk9JhXr4K8k3UGlOW-2pCY0MuWTtZvRNMSdZuakA-1024.npz
eval_Episode has 500 steps and return 261.1.
train_Episode has 500 steps and return 219.9.
Starting evaluation at step 157500 Counter(157500) 157437
eval_Episode has 500 steps and return 257.2.
Saved chunk: 20230922T005443F759290-2eFlfcjWE9zQ6Um6x5nsKY-0ydsnvDEP22jDwdhlIBQ8V-1024.npz
train_Episode has 500 steps and return 224.2.
Starting evaluation at step 158000 Counter(158000) 157937
Saved chunk: 20230922T005509F500230-2pCY0MuWTtZvRNMSdZuakA-57Bo4EUBBSTvKSETXMhHZX-1024.npz
eval_Episode has 500 steps and return 242.8.
train_Episode has 500 steps and return 239.3.
Starting evaluation at step 158500 Counter(158500) 158437
eval_Episode has 500 steps and return 252.4.
Saved chunk: 20230922T005605F818788-0ydsnvDEP22jDwdhlIBQ8V-0Wk0Zyg7N2tGBNreTwbUna-1024.npz
train_Episode has 500 steps and return 210.7.
Starting evaluation at step 159000 Counter(159000) 158937
Saved chunk: 20230922T005629F890110-57Bo4EUBBSTvKSETXMhHZX-7Mc8wtq6XGn5Oo6gYYEvXd-1024.npz
eval_Episode has 500 steps and return 234.5.
train_Episode has 500 steps and return 241.2.
Starting evaluation at step 159500 Counter(159500) 159437
eval_Episode has 500 steps and return 236.2.
Saved chunk: 20230922T005726F705017-0Wk0Zyg7N2tGBNreTwbUna-1u55ht8aFUYrEFzXy0st9P-1024.npz
train_Episode has 500 steps and return 210.9.
Starting evaluation at step 160000 Counter(160000) 159937
Saved chunk: 20230922T005749F114488-7Mc8wtq6XGn5Oo6gYYEvXd-0MPntvPrpDCFyUu2GNz3az-1024.npz
eval_Episode has 500 steps and return 244.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T005847F315544-1u55ht8aFUYrEFzXy0st9P-0000000000000000000000-356.npz
Saved chunk: 20230922T005908F151652-0MPntvPrpDCFyUu2GNz3az-0000000000000000000000-151.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 228.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 320734 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 228.51 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 244.63 / eval_episode/reward_rate 0.41 / train/action_mag 3.64 / train/action_max 3.59 / train/action_mean 0.11 / train/action_min -3.15 / train/action_std
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 7.9e4 / train/actor_opt_loss -26.38 / train/adv_mag 0.49 / train/adv_max 0.44 / train/adv_mean 3.3e-3 / 
train/adv_min -0.33 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6.9e-11 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 7.9e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 172.82 / train/extr_critic_max 172.82 / train/extr_critic_mean 161.72 / train/extr_critic_min 133.1 / train/extr_critic_std 8.35 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.69 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 173.32 / train/extr_return_raw_max 173.32 / train/extr_return_raw_mean 161.82 / train/extr_return_raw_min 
135.73 / train/extr_return_raw_std 8.36 / train/extr_reward_mag 1.85 / train/extr_reward_max 1.85 / train/extr_reward_mean 0.18 / train/extr_reward_min 0 / train/extr_reward_std 0.41 / train/image_loss_mean 1.34 / train/image_loss_std 1.11 / train/model_loss_mean 3.78 /
train/model_loss_std 4.99 / train/model_opt_grad_norm 9.23 / train/model_opt_grad_steps 7.9e4 / train/model_opt_loss 3.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.25 / train/policy_entropy_max 
4.18 / train/policy_entropy_mean -2.13 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 10.08 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.13 / train/policy_logprob_min -10.08 / train/policy_logprob_std 1.97 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 1.4e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.59 / train/post_ent_max 51.59 / train/post_ent_mean 36.2 / 
train/post_ent_min 20.18 / train/post_ent_std 4.63 / train/prior_ent_mag 84.67 / train/prior_ent_max 84.67 / train/prior_ent_mean 40.08 / train/prior_ent_min 25.15 / train/prior_ent_std 7.26 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.95 / train/reward_avg 0.16 / 
train/reward_loss_mean 0.11 / train/reward_loss_std 0.26 / train/reward_max_data 1.7 / train/reward_max_pred 1.69 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.16 / train/reward_rate 
0.17 / train_stats/mean_log_entropy -2.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.4e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.4 / report/dyn_loss_std 6.24 / report/image_loss_mean 1.01 / report/image_loss_std 0.77 / report/model_loss_mean 3.17 / report/model_loss_std 4.31 / report/post_ent_mag 48.41 / report/post_ent_max 48.41 / 
report/post_ent_mean 36.36 / report/post_ent_min 20.1 / report/post_ent_std 5.37 / report/prior_ent_mag 84.63 / report/prior_ent_max 84.63 / report/prior_ent_mean 39.64 / report/prior_ent_min 22.05 / report/prior_ent_std 7.97 / report/rep_loss_mean 3.4 / 
report/rep_loss_std 6.24 / report/reward_avg 0.21 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.25 / report/reward_max_data 1.64 / report/reward_max_pred 1.64 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.22 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.27 / eval/dyn_loss_std 8.6 / eval/image_loss_mean 2.1 / eval/image_loss_std 2.47 / eval/model_loss_mean 5.97 / eval/model_loss_std 7.09 / eval/post_ent_mag 45.57 / eval/post_ent_max 45.57 / eval/post_ent_mean 
35.62 / eval/post_ent_min 21.31 / eval/post_ent_std 4.73 / eval/prior_ent_mag 84.63 / eval/prior_ent_max 84.63 / eval/prior_ent_mean 40.6 / eval/prior_ent_min 27.44 / eval/prior_ent_std 6.93 / eval/rep_loss_mean 6.27 / eval/rep_loss_std 8.6 / eval/reward_avg 0.14 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.29 / eval/reward_max_data 1.48 / eval/reward_max_pred 1.48 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.67 / eval/reward_pred 0.14 / eval/reward_rate 0.16 / 
replay/size 1.6e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3794 / timer/env.step_total 19.84 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.98 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7301 / timer/agent.policy_total 16.62 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.09 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1897 / timer/agent.train_total 244.73 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.15 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 160500 Counter(160500) 160437
eval_Episode has 500 steps and return 253.0.
Saved chunk: 20230922T005847F315544-1u55ht8aFUYrEFzXy0st9P-35uS5fzsg0s6WRGTJ9kb0g-1024.npz
train_Episode has 500 steps and return 216.1.
Starting evaluation at step 161000 Counter(161000) 160937
Saved chunk: 20230922T005908F151652-0MPntvPrpDCFyUu2GNz3az-7iNOyBzMv5llgM79OHZxwK-1024.npz
eval_Episode has 500 steps and return 250.7.
train_Episode has 500 steps and return 228.3.
Starting evaluation at step 161500 Counter(161500) 161437
eval_Episode has 500 steps and return 239.7.
Saved chunk: 20230922T010009F139437-35uS5fzsg0s6WRGTJ9kb0g-4ENj98wrQuSNyoSMHgOa09-1024.npz
train_Episode has 500 steps and return 241.7.
Starting evaluation at step 162000 Counter(162000) 161937
Saved chunk: 20230922T010028F523913-7iNOyBzMv5llgM79OHZxwK-6aiUDGixoYwA9lSy0IfUnn-1024.npz
eval_Episode has 500 steps and return 248.8.
train_Episode has 500 steps and return 244.7.
Starting evaluation at step 162500 Counter(162500) 162437
eval_Episode has 500 steps and return 240.5.
Saved chunk: 20230922T010130F131650-4ENj98wrQuSNyoSMHgOa09-4G70nVGmGZWIgVdG93pCXH-1024.npz
train_Episode has 500 steps and return 208.4.
Starting evaluation at step 163000 Counter(163000) 162937
Saved chunk: 20230922T010147F919838-6aiUDGixoYwA9lSy0IfUnn-4HDqMsbUQzyATaLsd01UJl-1024.npz
eval_Episode has 500 steps and return 264.7.
train_Episode has 500 steps and return 216.4.
Starting evaluation at step 163500 Counter(163500) 163437
eval_Episode has 500 steps and return 240.6.
train_Episode has 500 steps and return 241.6.
Saved chunk: 20230922T010250F950997-4G70nVGmGZWIgVdG93pCXH-3bAPFUnuLrExv9YAOk3NDE-1024.npz
Starting evaluation at step 164000 Counter(164000) 163937
eval_Episode has 500 steps and return 252.0.
Saved chunk: 20230922T010307F091445-4HDqMsbUQzyATaLsd01UJl-6whmubxPmbDggG094shGID-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 328262 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 252 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 241.56 / episode/reward_rate 0.42 / train/action_mag 3.97 / train/action_max 3.96 / train/action_mean 0.1 / train/action_min -3.1 / train/action_std 0.9
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 8.1e4 / train/actor_opt_loss -26.99 / train/adv_mag 0.65 / train/adv_max 0.6 / train/adv_mean 3.4e-3 / train/adv_min 
-0.36 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.8e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.83 / train/dyn_loss_std 6.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 8.1e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 174.97 / train/extr_critic_max 174.97 / train/extr_critic_mean 163.56 / train/extr_critic_min 127.75 / train/extr_critic_std 9.84 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.07 / 
train/extr_return_normed_mean 0.68 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 175.51 / train/extr_return_raw_max 175.51 / train/extr_return_raw_mean 163.66 / train/extr_return_raw_min 
130.4 / train/extr_return_raw_std 9.8 / train/extr_reward_mag 1.85 / train/extr_reward_max 1.85 / train/extr_reward_mean 0.19 / train/extr_reward_min 0 / train/extr_reward_std 0.42 / train/image_loss_mean 1.29 / train/image_loss_std 1.08 / train/model_loss_mean 3.69 / 
train/model_loss_std 4.94 / train/model_opt_grad_norm 9.31 / train/model_opt_grad_steps 8.1e4 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8457.45 / train/policy_entropy_mag 3.91 / 
train/policy_entropy_max 3.71 / train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 9.97 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.03 / train/policy_logprob_min -9.97 / 
train/policy_logprob_std 1.96 / train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.5e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 52 / train/post_ent_max 52 / 
train/post_ent_mean 36.48 / train/post_ent_min 19.89 / train/post_ent_std 4.74 / train/prior_ent_mag 84.81 / train/prior_ent_max 84.81 / train/prior_ent_mean 40.32 / train/prior_ent_min 25.12 / train/prior_ent_std 7.32 / train/rep_loss_mean 3.83 / train/rep_loss_std 6.9
/ train/reward_avg 0.17 / train/reward_loss_mean 0.11 / train/reward_loss_std 0.27 / train/reward_max_data 1.71 / train/reward_max_pred 1.7 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 
0.17 / train/reward_rate 0.18 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.13 / report/cont_avg 1 / report/cont_loss_mean 7e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 6.68 / report/image_loss_mean 1.2 / report/image_loss_std 0.89 / report/model_loss_mean 3.5 / report/model_loss_std 4.65 / report/post_ent_mag 56.54 / 
report/post_ent_max 56.54 / report/post_ent_mean 35.81 / report/post_ent_min 20.55 / report/post_ent_std 5.29 / report/prior_ent_mag 85.04 / report/prior_ent_max 85.04 / report/prior_ent_mean 39.58 / report/prior_ent_min 22.03 / report/prior_ent_std 8.03 / 
report/rep_loss_mean 3.65 / report/rep_loss_std 6.68 / report/reward_avg 0.16 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.26 / report/reward_max_data 1.79 / report/reward_max_pred 1.84 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.6 / report/reward_pred 0.16 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 5.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.34 / eval/dyn_loss_std 7.55 / eval/image_loss_mean 1.72 / eval/image_loss_std 1.78 / eval/model_loss_mean 5.05 / eval/model_loss_std 5.81 / eval/post_ent_mag 47.42 / 
eval/post_ent_max 47.42 / eval/post_ent_mean 36.93 / eval/post_ent_min 18.15 / eval/post_ent_std 5 / eval/prior_ent_mag 85.04 / eval/prior_ent_max 85.04 / eval/prior_ent_mean 41.72 / eval/prior_ent_min 20.44 / eval/prior_ent_std 6.9 / eval/rep_loss_mean 5.34 / 
eval/rep_loss_std 7.55 / eval/reward_avg 0.19 / eval/reward_loss_mean 0.13 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.59 / eval/reward_max_pred 1.58 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 0.97 / eval/reward_pos_loss 0.65 / 
eval/reward_pred 0.19 / eval/reward_rate 0.2 / replay/size 1.6e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3764 / timer/env.step_total 19.58
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.8 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
3.3e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.3e-4 / 
timer/agent.train_count 1882 / timer/agent.train_total 241.49 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / 
timer/dataset_eval_max 3.8e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 234.2.
Starting evaluation at step 164500 Counter(164500) 164437
eval_Episode has 500 steps and return 256.1.
train_Episode has 500 steps and return 219.4.
Saved chunk: 20230922T010411F586430-3bAPFUnuLrExv9YAOk3NDE-67wfV8YMmapr6qIHf8j9NO-1024.npz
Starting evaluation at step 165000 Counter(165000) 164937
eval_Episode has 500 steps and return 256.6.
Saved chunk: 20230922T010426F119399-6whmubxPmbDggG094shGID-1cVjCjxyH0o0V2q3nEirwN-1024.npz
train_Episode has 500 steps and return 249.1.
Starting evaluation at step 165500 Counter(165500) 165437
eval_Episode has 500 steps and return 245.7.
train_Episode has 500 steps and return 224.9.
Saved chunk: 20230922T010533F285800-67wfV8YMmapr6qIHf8j9NO-7AbPPLp7RJRN5TSjCepb4g-1024.npz
Starting evaluation at step 166000 Counter(166000) 165937
eval_Episode has 500 steps and return 263.9.
Saved chunk: 20230922T010546F333925-1cVjCjxyH0o0V2q3nEirwN-5SLInG37QW2eqxlGsFAl8x-1024.npz
train_Episode has 500 steps and return 245.2.
Starting evaluation at step 166500 Counter(166500) 166437
eval_Episode has 500 steps and return 216.0.
train_Episode has 500 steps and return 231.5.
Saved chunk: 20230922T010654F221900-7AbPPLp7RJRN5TSjCepb4g-4QQXGxnmMrk7XqLLwCPvth-1024.npz
Starting evaluation at step 167000 Counter(167000) 166937
eval_Episode has 500 steps and return 241.2.
train_Episode has 500 steps and return 228.5.
Starting evaluation at step 167500 Counter(167500) 167437
Saved chunk: 20230922T010705F692577-5SLInG37QW2eqxlGsFAl8x-2TMCvjo9rbO5UqrieIcwMY-1024.npz
eval_Episode has 500 steps and return 225.6.
train_Episode has 500 steps and return 234.7.
Saved chunk: 20230922T010814F894886-4QQXGxnmMrk7XqLLwCPvth-50Qm9ALIZshJkHhM6zMRbN-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 335886 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 234.67 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 225.6 / eval_episode/reward_rate 0.4 / train/action_mag 4.13 / train/action_max 4.12 / train/action_mean 0.11 / train/action_min -3.04 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.21 / train/actor_opt_grad_steps 8.2e4 / train/actor_opt_loss -28.67 / train/adv_mag 0.52 / train/adv_max 0.46 / train/adv_mean 3.6e-3 / 
train/adv_min -0.4 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 7.1e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.97 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 8.2e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 176.65 / train/extr_critic_max 176.65 / train/extr_critic_mean 166.07 / train/extr_critic_min 138.92 / train/extr_critic_std 8.24 / train/extr_return_normed_mag 1.19 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 177.25 / train/extr_return_raw_max 177.25 / train/extr_return_raw_mean 166.16 / train/extr_return_raw_min 
140.07 / train/extr_return_raw_std 8.21 / train/extr_reward_mag 1.85 / train/extr_reward_max 1.85 / train/extr_reward_mean 0.2 / train/extr_reward_min 0 / train/extr_reward_std 0.44 / train/image_loss_mean 1.29 / train/image_loss_std 1.07 / train/model_loss_mean 3.73 / 
train/model_loss_std 4.97 / train/model_opt_grad_norm 9.41 / train/model_opt_grad_steps 8.2e4 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8900.52 / train/policy_entropy_mag 3.81 / 
train/policy_entropy_max 3.47 / train/policy_entropy_mean -2.1 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 9.84 / train/policy_logprob_max 5.45 / train/policy_logprob_mean 2.1 / train/policy_logprob_min -9.84 / 
train/policy_logprob_std 1.96 / train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.4e-3 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.86 / train/post_ent_max 51.86 / 
train/post_ent_mean 36.8 / train/post_ent_min 20.26 / train/post_ent_std 4.76 / train/prior_ent_mag 84.9 / train/prior_ent_max 84.9 / train/prior_ent_mean 40.66 / train/prior_ent_min 25.03 / train/prior_ent_std 7.32 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.97 /
train/reward_avg 0.19 / train/reward_loss_mean 0.12 / train/reward_loss_std 0.27 / train/reward_max_data 1.73 / train/reward_max_pred 1.72 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 
0.18 / train/reward_rate 0.19 / train_stats/mean_log_entropy -2.11 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 6.82 / report/image_loss_mean 1.24 / report/image_loss_std 0.91 / report/model_loss_mean 3.68 / report/model_loss_std 4.76 / report/post_ent_mag 
47.95 / report/post_ent_max 47.95 / report/post_ent_mean 37.33 / report/post_ent_min 21.25 / report/post_ent_std 5.13 / report/prior_ent_mag 84.88 / report/prior_ent_max 84.88 / report/prior_ent_mean 41.29 / report/prior_ent_min 23.39 / report/prior_ent_std 7.59 / 
report/rep_loss_mean 3.85 / report/rep_loss_std 6.82 / report/reward_avg 0.23 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.28 / report/reward_max_data 1.84 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.61 / report/reward_pred 0.23 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.7 / eval/dyn_loss_std 12.56 / eval/image_loss_mean 2.66 / eval/image_loss_std 4.85 / eval/model_loss_mean 7.44 / eval/model_loss_std 12.01 / eval/post_ent_mag 47.73 / 
eval/post_ent_max 47.73 / eval/post_ent_mean 38.16 / eval/post_ent_min 21.47 / eval/post_ent_std 4.23 / eval/prior_ent_mag 84.88 / eval/prior_ent_max 84.88 / eval/prior_ent_mean 42.49 / eval/prior_ent_min 26.91 / eval/prior_ent_std 6.67 / eval/rep_loss_mean 7.7 / 
eval/rep_loss_std 12.56 / eval/reward_avg 0.28 / eval/reward_loss_mean 0.17 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.67 / eval/reward_max_pred 1.67 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 /
eval/reward_pred 0.28 / eval/reward_rate 0.26 / replay/size 1.7e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3812 / timer/env.step_total 19.93
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.15 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
1.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.71 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.8e-4 / 
timer/agent.train_count 1906 / timer/agent.train_total 244.36 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / 
timer/dataset_eval_max 3.6e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 168000 Counter(168000) 167937
eval_Episode has 500 steps and return 244.0.
train_Episode has 500 steps and return 217.6.
Starting evaluation at step 168500 Counter(168500) 168437
Saved chunk: 20230922T010900F685070-2TMCvjo9rbO5UqrieIcwMY-66LRgEeKuG8YuhBeOZSRp0-1024.npz
eval_Episode has 500 steps and return 226.7.
train_Episode has 500 steps and return 240.8.
Saved chunk: 20230922T010935F502351-50Qm9ALIZshJkHhM6zMRbN-4vGrEJOyWZvpcuVpLrzlxG-1024.npz
Starting evaluation at step 169000 Counter(169000) 168937
eval_Episode has 500 steps and return 261.6.
train_Episode has 500 steps and return 231.0.
Starting evaluation at step 169500 Counter(169500) 169437
Saved chunk: 20230922T011020F720723-66LRgEeKuG8YuhBeOZSRp0-1aluNrdOAzNhdMrNxoOng6-1024.npz
eval_Episode has 500 steps and return 250.8.
train_Episode has 500 steps and return 229.7.
Saved chunk: 20230922T011057F302880-4vGrEJOyWZvpcuVpLrzlxG-0D9RcmGpgjReJ39jw5Ildm-1024.npz
Starting evaluation at step 170000 Counter(170000) 169937
eval_Episode has 500 steps and return 250.6.
train_Episode has 500 steps and return 231.7.
Starting evaluation at step 170500 Counter(170500) 170437
Saved chunk: 20230922T011140F052531-1aluNrdOAzNhdMrNxoOng6-3WjY1zw5pB7SBZxjQCIsxn-1024.npz
eval_Episode has 500 steps and return 256.6.
train_Episode has 500 steps and return 208.4.
Starting evaluation at step 171000 Counter(171000) 170937
eval_Episode has 500 steps and return 267.8.
Saved chunk: 20230922T011218F126466-0D9RcmGpgjReJ39jw5Ildm-5BHX9hcERmod8GRy255NFs-1024.npz
train_Episode has 500 steps and return 215.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 171500 Counter(171500) 171437
Saved chunk: 20230922T011259F195985-3WjY1zw5pB7SBZxjQCIsxn-0000000000000000000000-933.npz
Saved chunk: 20230922T011342F288103-5BHX9hcERmod8GRy255NFs-0000000000000000000000-492.npz
Saved chunk: 20230922T011259F195985-3WjY1zw5pB7SBZxjQCIsxn-4Jk6psY5rywNwzxX783Q2t-1024.npz
eval_Episode has 500 steps and return 256.3.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 343406 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 256.28 / eval_episode/reward_rate 0.41 / episode/length 500 / episode/score 215.14 / episode/reward_rate 0.4 / train/action_mag 4.17 / train/action_max 4.16 / train/action_mean 0.1 / train/action_min -2.99 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 8.4e4 / train/actor_opt_loss -15.74 / train/adv_mag 0.47 / train/adv_max 0.36 / train/adv_mean 2.3e-3 / train/adv_min
-0.43 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.7e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.85 / train/dyn_loss_std 6.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 8.4e4 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 177.98 / train/extr_critic_max 177.98 / train/extr_critic_mean 167.86 / train/extr_critic_min 144.98 / train/extr_critic_std 7.34 / train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 178.67 / train/extr_return_raw_max 178.67 / train/extr_return_raw_mean 167.91 / train/extr_return_raw_min 
145.03 / train/extr_return_raw_std 7.38 / train/extr_reward_mag 1.85 / train/extr_reward_max 1.85 / train/extr_reward_mean 0.2 / train/extr_reward_min 0 / train/extr_reward_std 0.44 / train/image_loss_mean 1.28 / train/image_loss_std 1.07 / train/model_loss_mean 3.71 / 
train/model_loss_std 4.94 / train/model_opt_grad_norm 9.1 / train/model_opt_grad_steps 8.4e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.6 / train/policy_entropy_max 
2.75 / train/policy_entropy_mean -2.26 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 9.49 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.27 / train/policy_logprob_min -9.49 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.68 / train/policy_randomness_max 0.68 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 1.2e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.65 / train/post_ent_max 52.65 / train/post_ent_mean 37.01 / 
train/post_ent_min 20.21 / train/post_ent_std 4.84 / train/prior_ent_mag 85.03 / train/prior_ent_max 85.03 / train/prior_ent_mean 40.87 / train/prior_ent_min 25.04 / train/prior_ent_std 7.34 / train/rep_loss_mean 3.85 / train/rep_loss_std 6.92 / train/reward_avg 0.19 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.28 / train/reward_max_data 1.73 / train/reward_max_pred 1.72 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.61 / train/reward_pred 0.19 / train/reward_rate 
0.19 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.19 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 6.68 / report/image_loss_mean 1.18 / report/image_loss_std 1.01 / report/model_loss_mean 3.51 / report/model_loss_std 4.77 / report/post_ent_mag 51.46 / report/post_ent_max 51.46 / 
report/post_ent_mean 36.96 / report/post_ent_min 21.21 / report/post_ent_std 4.5 / report/prior_ent_mag 85.04 / report/prior_ent_max 85.04 / report/prior_ent_mean 40.8 / report/prior_ent_min 26.34 / report/prior_ent_std 7.25 / report/rep_loss_mean 3.7 / 
report/rep_loss_std 6.68 / report/reward_avg 0.19 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.26 / report/reward_max_data 1.77 / report/reward_max_pred 1.78 / report/reward_neg_acc 1 / report/reward_neg_loss 9.3e-4 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.18 / report/reward_rate 0.18 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.39 / eval/dyn_loss_std 8.29 / eval/image_loss_mean 1.67 / eval/image_loss_std 2.21 / eval/model_loss_mean 5.11 / eval/model_loss_std 6.63 / eval/post_ent_mag 47.7 / eval/post_ent_max 47.7 / eval/post_ent_mean 
38.19 / eval/post_ent_min 17.99 / eval/post_ent_std 4.46 / eval/prior_ent_mag 85.04 / eval/prior_ent_max 85.04 / eval/prior_ent_mean 42.94 / eval/prior_ent_min 29.73 / eval/prior_ent_std 6.6 / eval/rep_loss_mean 5.39 / eval/rep_loss_std 8.29 / eval/reward_avg 0.27 / 
eval/reward_loss_mean 0.2 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.58 / eval/reward_max_pred 1.59 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.7 / eval/reward_pred 0.27 / eval/reward_rate 0.28 / 
replay/size 1.7e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3760 / timer/env.step_total 19.59 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 438.01 / timer/replay._sample_frac 1.46 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.58 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.31 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.4e-8 / timer/dataset_eval_avg 2.8e-5 / 
timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 236.2.
Starting evaluation at step 172000 Counter(172000) 171937
eval_Episode has 500 steps and return 256.1.
Saved chunk: 20230922T011342F288103-5BHX9hcERmod8GRy255NFs-6Gfos4y3UyETzsyyQN9dBe-1024.npz
train_Episode has 500 steps and return 250.3.
Starting evaluation at step 172500 Counter(172500) 172437
Saved chunk: 20230922T011418F346184-4Jk6psY5rywNwzxX783Q2t-7w0SgMdjZK2HJ7E8dqVMVQ-1024.npz
eval_Episode has 500 steps and return 254.7.
train_Episode has 500 steps and return 224.0.
Starting evaluation at step 173000 Counter(173000) 172937
eval_Episode has 500 steps and return 256.3.
Saved chunk: 20230922T011504F192611-6Gfos4y3UyETzsyyQN9dBe-6NmX4UlPCbySVGLFoiVf3m-1024.npz
train_Episode has 500 steps and return 230.3.
Starting evaluation at step 173500 Counter(173500) 173437
Saved chunk: 20230922T011538F815131-7w0SgMdjZK2HJ7E8dqVMVQ-4YzHhUESU23b2YqdCfsCsu-1024.npz
eval_Episode has 500 steps and return 270.7.
train_Episode has 500 steps and return 215.7.
Starting evaluation at step 174000 Counter(174000) 173937
eval_Episode has 500 steps and return 241.6.
Saved chunk: 20230922T011625F213119-6NmX4UlPCbySVGLFoiVf3m-5sDGAJZ5SGk9T9BKO60xxR-1024.npz
train_Episode has 500 steps and return 236.8.
Starting evaluation at step 174500 Counter(174500) 174437
Saved chunk: 20230922T011658F151850-4YzHhUESU23b2YqdCfsCsu-2HYT6MAdDBOzkEnjLpzUYc-1024.npz
eval_Episode has 500 steps and return 264.0.
train_Episode has 500 steps and return 215.2.
Starting evaluation at step 175000 Counter(175000) 174937
eval_Episode has 500 steps and return 248.6.
Saved chunk: 20230922T011746F018479-5sDGAJZ5SGk9T9BKO60xxR-5j7WqZpmrXdYfJ73EYjxqk-1024.npz
train_Episode has 500 steps and return 248.1.
Starting evaluation at step 175500 Counter(175500) 175437
Saved chunk: 20230922T011817F274093-2HYT6MAdDBOzkEnjLpzUYc-1hQ4rm9a2tsrhuTERKXNtu-1024.npz
eval_Episode has 500 steps and return 267.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 351002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 248.08 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 267.47 / eval_episode/reward_rate 0.41 / train/action_mag 4.26 / train/action_max 4.25 / train/action_mean 0.12 / train/action_min -2.97 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 8.6e4 / train/actor_opt_loss -13.42 / train/adv_mag 0.44 / train/adv_max 0.32 / train/adv_mean 
2.1e-3 / train/adv_min -0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.7e-11 / train/cont_loss_std 3.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.7e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 8.6e4 / train/extr_critic_critic_opt_loss 9894.35 / train/extr_critic_mag 178.95 / train/extr_critic_max 178.95 / train/extr_critic_mean 169.41 / train/extr_critic_min 148.67 / train/extr_critic_std 6.88 / 
train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 179.82 / train/extr_return_raw_max 
179.82 / train/extr_return_raw_mean 169.46 / train/extr_return_raw_min 147.72 / train/extr_return_raw_std 6.92 / train/extr_reward_mag 1.86 / train/extr_reward_max 1.86 / train/extr_reward_mean 0.2 / train/extr_reward_min 0 / train/extr_reward_std 0.44 / 
train/image_loss_mean 1.28 / train/image_loss_std 1.07 / train/model_loss_mean 3.71 / train/model_loss_std 4.97 / train/model_opt_grad_norm 9.13 / train/model_opt_grad_steps 8.6e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.54 / train/policy_entropy_max 2.52 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.52 / train/policy_logprob_max 5.45 / 
train/policy_logprob_mean 2.31 / train/policy_logprob_min -9.52 / train/policy_logprob_std 1.85 / train/policy_randomness_mag 0.66 / train/policy_randomness_max 0.66 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 1.3e-3 / train/policy_randomness_std 
0.13 / train/post_ent_mag 52.15 / train/post_ent_max 52.15 / train/post_ent_mean 37.26 / train/post_ent_min 20.22 / train/post_ent_std 4.87 / train/prior_ent_mag 85.11 / train/prior_ent_max 85.11 / train/prior_ent_mean 41.12 / train/prior_ent_min 25.04 / 
train/prior_ent_std 7.34 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.95 / train/reward_avg 0.19 / train/reward_loss_mean 0.12 / train/reward_loss_std 0.27 / train/reward_max_data 1.74 / train/reward_max_pred 1.74 / train/reward_neg_acc 1 / train/reward_neg_loss 
3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.19 / train/reward_rate 0.19 / train_stats/mean_log_entropy -2.29 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 9.6e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 6.32 / report/image_loss_mean 1.14 / report/image_loss_std 0.95 / 
report/model_loss_mean 3.34 / report/model_loss_std 4.48 / report/post_ent_mag 55.19 / report/post_ent_max 55.19 / report/post_ent_mean 36.79 / report/post_ent_min 21.11 / report/post_ent_std 5.26 / report/prior_ent_mag 85.05 / report/prior_ent_max 85.05 / 
report/prior_ent_mean 40.08 / report/prior_ent_min 20.96 / report/prior_ent_std 7.79 / report/rep_loss_mean 3.54 / report/rep_loss_std 6.32 / report/reward_avg 0.16 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.21 / report/reward_max_data 1.84 / 
report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.16 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 8.1e-11 / eval/cont_loss_std 3e-10 /
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.23 / eval/dyn_loss_std 7.55 / eval/image_loss_mean 1.63 / eval/image_loss_std 1.69 / eval/model_loss_mean 4.96 
/ eval/model_loss_std 5.72 / eval/post_ent_mag 48.82 / eval/post_ent_max 48.82 / eval/post_ent_mean 37.38 / eval/post_ent_min 16.72 / eval/post_ent_std 4.8 / eval/prior_ent_mag 85.05 / eval/prior_ent_max 85.05 / eval/prior_ent_mean 41.74 / eval/prior_ent_min 22.11 / 
eval/prior_ent_std 6.67 / eval/rep_loss_mean 5.23 / eval/rep_loss_std 7.55 / eval/reward_avg 0.28 / eval/reward_loss_mean 0.2 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.75 / eval/reward_max_pred 1.69 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.5e-3 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.28 / eval/reward_rate 0.3 / replay/size 1.8e5 / replay/inserts 3798 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.74 / 
timer/env.step_count 3798 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.68 / timer/replay._sample_frac 1.47 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7806 / timer/agent.policy_total 17.44 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1899 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1899 / timer/agent.train_total 243.95 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / 
timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 254.2.
Starting evaluation at step 176000 Counter(176000) 175937
eval_Episode has 500 steps and return 243.9.
Saved chunk: 20230922T011906F657749-5j7WqZpmrXdYfJ73EYjxqk-1WTzgEYynhVpQ8xWtvzXzS-1024.npz
train_Episode has 500 steps and return 189.1.
Starting evaluation at step 176500 Counter(176500) 176437
Saved chunk: 20230922T011936F364796-1hQ4rm9a2tsrhuTERKXNtu-4ZYibSf6MknxkDfeIUdwU5-1024.npz
eval_Episode has 500 steps and return 251.1.
train_Episode has 500 steps and return 233.7.
Starting evaluation at step 177000 Counter(177000) 176937
eval_Episode has 500 steps and return 272.1.
Saved chunk: 20230922T012028F366829-1WTzgEYynhVpQ8xWtvzXzS-5NXi5K220rV4FEDG3LSjYV-1024.npz
train_Episode has 500 steps and return 234.2.
Starting evaluation at step 177500 Counter(177500) 177437
Saved chunk: 20230922T012056F632302-4ZYibSf6MknxkDfeIUdwU5-2O6MftAG0c2KoBkoEhGXf7-1024.npz
eval_Episode has 500 steps and return 260.3.
train_Episode has 500 steps and return 219.9.
Starting evaluation at step 178000 Counter(178000) 177937
eval_Episode has 500 steps and return 237.7.
Saved chunk: 20230922T012149F318097-5NXi5K220rV4FEDG3LSjYV-3EvB9S1K0XBFlSITiITrJ9-1024.npz
train_Episode has 500 steps and return 237.7.
Starting evaluation at step 178500 Counter(178500) 178437
Saved chunk: 20230922T012215F971941-2O6MftAG0c2KoBkoEhGXf7-4F3CWN758YwB1Kjw9fgbJA-1024.npz
eval_Episode has 500 steps and return 238.8.
train_Episode has 500 steps and return 229.6.
Starting evaluation at step 179000 Counter(179000) 178937
eval_Episode has 500 steps and return 235.3.
Saved chunk: 20230922T012310F077141-3EvB9S1K0XBFlSITiITrJ9-7pr1XvFhXeyaQmOGv9M4UI-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 358626 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 229.59 / episode/reward_rate 0.38 / eval_episode/length 500 / eval_episode/score 235.27 / eval_episode/reward_rate 0.39 / train/action_mag 4.33 / train/action_max 4.32 / train/action_mean 0.12 / train/action_min -2.98 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 8.8e4 / train/actor_opt_loss -4.28 / train/adv_mag 0.43 / train/adv_max 0.32 / train/adv_mean 1.1e-3
/ train/adv_min -0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.6e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.89 / train/dyn_loss_std 6.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 8.8e4 / 
train/extr_critic_critic_opt_loss 9386.97 / train/extr_critic_mag 179.33 / train/extr_critic_max 179.33 / train/extr_critic_mean 170.25 / train/extr_critic_min 149.1 / train/extr_critic_std 6.97 / train/extr_return_normed_mag 1.08 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 180.52 / train/extr_return_raw_max 180.52 / train/extr_return_raw_mean 170.28 / train/extr_return_raw_min 
147.82 / train/extr_return_raw_std 7.03 / train/extr_reward_mag 1.86 / train/extr_reward_max 1.86 / train/extr_reward_mean 0.22 / train/extr_reward_min 0 / train/extr_reward_std 0.46 / train/image_loss_mean 1.28 / train/image_loss_std 1.07 / train/model_loss_mean 3.73 /
train/model_loss_std 4.97 / train/model_opt_grad_norm 9.15 / train/model_opt_grad_steps 8.8e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.6 / train/policy_entropy_max 
2.81 / train/policy_entropy_mean -2.22 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.8 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.22 / train/policy_logprob_min -9.8 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.69 / train/policy_randomness_max 0.69 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 1.7e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.02 / train/post_ent_max 52.02 / train/post_ent_mean 37.6 / 
train/post_ent_min 20.45 / train/post_ent_std 4.85 / train/prior_ent_mag 85.16 / train/prior_ent_max 85.16 / train/prior_ent_mean 41.48 / train/prior_ent_min 25.7 / train/prior_ent_std 7.24 / train/rep_loss_mean 3.89 / train/rep_loss_std 6.95 / train/reward_avg 0.2 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.28 / train/reward_max_data 1.75 / train/reward_max_pred 1.74 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.2 / train/reward_rate 
0.2 / train_stats/mean_log_entropy -2.19 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.4e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.03 / report/dyn_loss_std 7.21 / report/image_loss_mean 1.39 / report/image_loss_std 1.22 / report/model_loss_mean 3.91 / report/model_loss_std 5.22 / report/post_ent_mag 54.75 / report/post_ent_max 54.75 /
report/post_ent_mean 37.53 / report/post_ent_min 19.08 / report/post_ent_std 4.96 / report/prior_ent_mag 85.3 / report/prior_ent_max 85.3 / report/prior_ent_mean 41.67 / report/prior_ent_min 27.61 / report/prior_ent_std 7.15 / report/rep_loss_mean 4.03 / 
report/rep_loss_std 7.21 / report/reward_avg 0.18 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.28 / report/reward_max_data 1.97 / report/reward_max_pred 1.73 / report/reward_neg_acc 1 / report/reward_neg_loss 9.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.18 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 9.6e-11 / eval/cont_loss_std 6.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.69 / eval/dyn_loss_std 6.9 / eval/image_loss_mean 1.42 / eval/image_loss_std 1.47 / eval/model_loss_mean 4.48 / eval/model_loss_std 5.08 / eval/post_ent_mag 49.69 / eval/post_ent_max 49.69 / eval/post_ent_mean 
38.61 / eval/post_ent_min 21.88 / eval/post_ent_std 4.38 / eval/prior_ent_mag 85.3 / eval/prior_ent_max 85.3 / eval/prior_ent_mean 43.12 / eval/prior_ent_min 30.1 / eval/prior_ent_std 6.29 / eval/rep_loss_mean 4.69 / eval/rep_loss_std 6.9 / eval/reward_avg 0.36 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.71 / eval/reward_max_pred 1.73 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.66 / eval/reward_pred 0.36 / eval/reward_rate 0.37 / 
replay/size 1.8e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3812 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.33 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.5 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.87 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 240.4.
Starting evaluation at step 179500 Counter(179500) 179437
Saved chunk: 20230922T012335F103245-4F3CWN758YwB1Kjw9fgbJA-4q4R6a3vuI1PwhyhdVHc9q-1024.npz
eval_Episode has 500 steps and return 270.2.
train_Episode has 500 steps and return 242.8.
Starting evaluation at step 180000 Counter(180000) 179937
eval_Episode has 500 steps and return 267.4.
Saved chunk: 20230922T012430F744510-7pr1XvFhXeyaQmOGv9M4UI-5aVPY5jfGXaPH3i2vhxmgo-1024.npz
train_Episode has 500 steps and return 247.8.
Starting evaluation at step 180500 Counter(180500) 180437
Saved chunk: 20230922T012455F118062-4q4R6a3vuI1PwhyhdVHc9q-25UVmBBOVpfRYVLxwKalVy-1024.npz
eval_Episode has 500 steps and return 205.2.
train_Episode has 500 steps and return 253.5.
Starting evaluation at step 181000 Counter(181000) 180937
eval_Episode has 500 steps and return 266.8.
Saved chunk: 20230922T012552F590995-5aVPY5jfGXaPH3i2vhxmgo-4W8TIFe5vsplpJS7SZSIq8-1024.npz
train_Episode has 500 steps and return 224.5.
Starting evaluation at step 181500 Counter(181500) 181437
Saved chunk: 20230922T012614F546324-25UVmBBOVpfRYVLxwKalVy-3Ulz4wYrqZjjHRVT2HTfi4-1024.npz
eval_Episode has 500 steps and return 274.2.
train_Episode has 500 steps and return 246.2.
Starting evaluation at step 182000 Counter(182000) 181937
eval_Episode has 500 steps and return 227.5.
Saved chunk: 20230922T012713F598421-4W8TIFe5vsplpJS7SZSIq8-0BwXTzzARhx9UUOiSmCnDE-1024.npz
train_Episode has 500 steps and return 203.5.
Starting evaluation at step 182500 Counter(182500) 182437
Saved chunk: 20230922T012733F909713-3Ulz4wYrqZjjHRVT2HTfi4-5E0gmyD43DTbKcFDiouZEj-1024.npz
eval_Episode has 500 steps and return 261.5.
train_Episode has 500 steps and return 225.4.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T012834F294737-0BwXTzzARhx9UUOiSmCnDE-0000000000000000000000-629.npz
Saved chunk: 20230922T012852F981370-5E0gmyD43DTbKcFDiouZEj-0000000000000000000000-168.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 183000 Counter(183000) 182937
eval_Episode has 500 steps and return 235.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 366138 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 225.37 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 235.34 / eval_episode/reward_rate 0.36 / train/action_mag 4.33 / train/action_max 4.32 / train/action_mean 0.11 / train/action_min -3.17 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 9e4 / train/actor_opt_loss -13.74 / train/adv_mag 0.42 / train/adv_max 0.3 / train/adv_mean 2.1e-3 /
train/adv_min -0.41 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 6.2e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.83 / train/dyn_loss_std 6.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 9e4 / 
train/extr_critic_critic_opt_loss 9130.07 / train/extr_critic_mag 180.43 / train/extr_critic_max 180.43 / train/extr_critic_mean 170.7 / train/extr_critic_min 152.09 / train/extr_critic_std 6.87 / train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 181.17 / train/extr_return_raw_max 181.17 / train/extr_return_raw_mean 170.75 / train/extr_return_raw_min 
150.08 / train/extr_return_raw_std 6.91 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.22 / train/extr_reward_min 0 / train/extr_reward_std 0.46 / train/image_loss_mean 1.24 / train/image_loss_std 1.05 / train/model_loss_mean 3.66 /
train/model_loss_std 4.93 / train/model_opt_grad_norm 9.18 / train/model_opt_grad_steps 9e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.59 / train/policy_entropy_max 2.8
/ train/policy_entropy_mean -2.21 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 9.62 / train/policy_logprob_max 5.44 / train/policy_logprob_mean 2.21 / train/policy_logprob_min -9.62 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.69 / train/policy_randomness_max 0.69 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 1.7e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.94 / train/post_ent_max 52.94 / train/post_ent_mean 37.68 / 
train/post_ent_min 20.41 / train/post_ent_std 4.91 / train/prior_ent_mag 85.26 / train/prior_ent_max 85.26 / train/prior_ent_mean 41.51 / train/prior_ent_min 25.22 / train/prior_ent_std 7.35 / train/rep_loss_mean 3.83 / train/rep_loss_std 6.93 / train/reward_avg 0.2 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.27 / train/reward_max_data 1.76 / train/reward_max_pred 1.75 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.2 / train/reward_rate 
0.19 / train_stats/mean_log_entropy -2.2 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.8e-11 / report/cont_loss_std 3.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.79 / report/dyn_loss_std 6.53 / report/image_loss_mean 1.14 / report/image_loss_std 0.88 / report/model_loss_mean 3.56 / report/model_loss_std 4.58 / report/post_ent_mag 53.52 / report/post_ent_max 53.52 /
report/post_ent_mean 39.32 / report/post_ent_min 22.91 / report/post_ent_std 4.33 / report/prior_ent_mag 85.41 / report/prior_ent_max 85.41 / report/prior_ent_mean 43.06 / report/prior_ent_min 28.15 / report/prior_ent_std 6.6 / report/rep_loss_mean 3.79 / 
report/rep_loss_std 6.53 / report/reward_avg 0.26 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.27 / report/reward_max_data 1.83 / report/reward_max_pred 1.8 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.25 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 7.97 / eval/dyn_loss_std 10.89 / eval/image_loss_mean 2.44 / eval/image_loss_std 2.97 / eval/model_loss_mean 7.35 / eval/model_loss_std 9.09 / eval/post_ent_mag 48.11 / eval/post_ent_max 48.11 / eval/post_ent_mean
37.54 / eval/post_ent_min 20.12 / eval/post_ent_std 5.47 / eval/prior_ent_mag 85.41 / eval/prior_ent_max 85.41 / eval/prior_ent_mean 43.12 / eval/prior_ent_min 30.05 / eval/prior_ent_std 6.79 / eval/rep_loss_mean 7.97 / eval/rep_loss_std 10.89 / eval/reward_avg 0.18 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.85 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.18 / eval/reward_rate 0.19 / 
replay/size 1.8e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3756 / timer/env.step_total 19.69 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.06 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.8e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7764 / timer/agent.policy_total 17.82 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.04 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T012834F294737-0BwXTzzARhx9UUOiSmCnDE-7tiRoCQsfS93aPAeysK4Up-1024.npz
train_Episode has 500 steps and return 242.3.
Starting evaluation at step 183500 Counter(183500) 183437
Saved chunk: 20230922T012852F981370-5E0gmyD43DTbKcFDiouZEj-1IgeglVe2u5cQgEtOIfiOB-1024.npz
eval_Episode has 500 steps and return 219.8.
train_Episode has 500 steps and return 253.2.
Starting evaluation at step 184000 Counter(184000) 183937
eval_Episode has 500 steps and return 241.1.
Saved chunk: 20230922T012956F072030-7tiRoCQsfS93aPAeysK4Up-5BB34hzvF45VzkZnNOwhFg-1024.npz
train_Episode has 500 steps and return 258.5.
Starting evaluation at step 184500 Counter(184500) 184437
Saved chunk: 20230922T013013F331839-1IgeglVe2u5cQgEtOIfiOB-6kgfsK3vRCTL7JUwLxMCyy-1024.npz
eval_Episode has 500 steps and return 246.2.
train_Episode has 500 steps and return 192.1.
Starting evaluation at step 185000 Counter(185000) 184937
eval_Episode has 500 steps and return 236.9.
Saved chunk: 20230922T013117F173988-5BB34hzvF45VzkZnNOwhFg-09P3JcV6rHqgwYxfwpoHQI-1024.npz
train_Episode has 500 steps and return 233.2.
Starting evaluation at step 185500 Counter(185500) 185437
Saved chunk: 20230922T013132F815158-6kgfsK3vRCTL7JUwLxMCyy-1IHvmOYU5UdPJOsWM6zpxG-1024.npz
eval_Episode has 500 steps and return 242.0.
train_Episode has 500 steps and return 230.2.
Starting evaluation at step 186000 Counter(186000) 185937
eval_Episode has 500 steps and return 264.1.
train_Episode has 500 steps and return 234.5.
Saved chunk: 20230922T013238F034501-09P3JcV6rHqgwYxfwpoHQI-70iykYtKeeOZgSMYSrPLnR-1024.npz
Starting evaluation at step 186500 Counter(186500) 186437
Saved chunk: 20230922T013252F018912-1IHvmOYU5UdPJOsWM6zpxG-5ITAOKrAHde0KrTdXpJ2R5-1024.npz
eval_Episode has 500 steps and return 243.9.
train_Episode has 500 steps and return 222.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 373758 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 222.67 / episode/reward_rate 0.34 / eval_episode/length 500 / eval_episode/score 243.92 / eval_episode/reward_rate 0.37 / train/action_mag 4.29 / train/action_max 4.28 / train/action_mean 0.1 / train/action_min -3.33 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 9.2e4 / train/actor_opt_loss -10.9 / train/adv_mag 0.43 / train/adv_max 0.31 / train/adv_mean 1.8e-3 / train/adv_min 
-0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.8e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 9.2e4 / 
train/extr_critic_critic_opt_loss 8722.71 / train/extr_critic_mag 182.01 / train/extr_critic_max 182.01 / train/extr_critic_mean 171.31 / train/extr_critic_min 152.65 / train/extr_critic_std 6.91 / train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.6 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 181.95 / train/extr_return_raw_max 181.95 / train/extr_return_raw_mean 171.34 / train/extr_return_raw_min 
150.31 / train/extr_return_raw_std 6.98 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.23 / train/extr_reward_min 0 / train/extr_reward_std 0.47 / train/image_loss_mean 1.23 / train/image_loss_std 1.05 / train/model_loss_mean 3.66 /
train/model_loss_std 4.93 / train/model_opt_grad_norm 8.97 / train/model_opt_grad_steps 9.2e4 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 3.59 / 
train/policy_entropy_max 2.86 / train/policy_entropy_mean -2.29 / train/policy_entropy_min -3.52 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.48 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -9.48 / 
train/policy_logprob_std 1.87 / train/policy_randomness_mag 0.69 / train/policy_randomness_max 0.69 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 1.2e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 53.18 / train/post_ent_max 53.18 / 
train/post_ent_mean 37.85 / train/post_ent_min 20.52 / train/post_ent_std 5.01 / train/prior_ent_mag 85.21 / train/prior_ent_max 85.21 / train/prior_ent_mean 41.68 / train/prior_ent_min 25.25 / train/prior_ent_std 7.38 / train/rep_loss_mean 3.84 / train/rep_loss_std 
6.93 / train/reward_avg 0.21 / train/reward_loss_mean 0.12 / train/reward_loss_std 0.27 / train/reward_max_data 1.78 / train/reward_max_pred 1.77 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / 
train/reward_pred 0.21 / train/reward_rate 0.2 / train_stats/mean_log_entropy -2.39 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.3e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.9 / report/dyn_loss_std 6.73 / report/image_loss_mean 1.25 / report/image_loss_std 1.31 / report/model_loss_mean 3.75 / report/model_loss_std 5.13 / 
report/post_ent_mag 58.64 / report/post_ent_max 58.64 / report/post_ent_mean 38.71 / report/post_ent_min 21.11 / report/post_ent_std 4.8 / report/prior_ent_mag 85.2 / report/prior_ent_max 85.2 / report/prior_ent_mean 42.81 / report/prior_ent_min 29.47 / 
report/prior_ent_std 6.92 / report/rep_loss_mean 3.9 / report/rep_loss_std 6.73 / report/reward_avg 0.26 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.34 / report/reward_max_data 1.81 / report/reward_max_pred 1.83 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.62 / report/reward_pred 0.26 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 7.7e-11 / eval/cont_loss_std 3.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 7.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.39 / eval/dyn_loss_std 9.25 / eval/image_loss_mean 1.57 / eval/image_loss_std 2.2 / eval/model_loss_mean 4.99 / eval/model_loss_std 7.42 / eval/post_ent_mag 
48.02 / eval/post_ent_max 48.02 / eval/post_ent_mean 38.6 / eval/post_ent_min 21.29 / eval/post_ent_std 5.42 / eval/prior_ent_mag 85.2 / eval/prior_ent_max 85.2 / eval/prior_ent_mean 43.29 / eval/prior_ent_min 24.22 / eval/prior_ent_std 7.23 / eval/rep_loss_mean 5.39 / 
eval/rep_loss_std 9.25 / eval/reward_avg 0.29 / eval/reward_loss_mean 0.19 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.81 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.62 / 
eval/reward_pred 0.29 / eval/reward_rate 0.3 / replay/size 1.9e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3810 / timer/env.step_total 19.83
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.04 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
6.2e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7317 / timer/agent.policy_total 16.68 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.3e-4 / 
timer/agent.train_count 1905 / timer/agent.train_total 244.54 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / 
timer/dataset_eval_max 2.9e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 187000 Counter(187000) 186937
eval_Episode has 500 steps and return 273.2.
train_Episode has 500 steps and return 234.2.
Saved chunk: 20230922T013358F702594-70iykYtKeeOZgSMYSrPLnR-6WUmomPZEWpqlsQCwIdDHV-1024.npz
Starting evaluation at step 187500 Counter(187500) 187437
eval_Episode has 500 steps and return 222.6.
Saved chunk: 20230922T013411F154623-5ITAOKrAHde0KrTdXpJ2R5-05AN6jFr4ChB7TATDpSGHZ-1024.npz
train_Episode has 500 steps and return 205.8.
Starting evaluation at step 188000 Counter(188000) 187937
eval_Episode has 500 steps and return 270.1.
train_Episode has 500 steps and return 250.7.
Saved chunk: 20230922T013520F287250-6WUmomPZEWpqlsQCwIdDHV-1G7IoHoFjP0RzY8qAGIyqX-1024.npz
Starting evaluation at step 188500 Counter(188500) 188437
eval_Episode has 500 steps and return 265.9.
Saved chunk: 20230922T013531F212642-05AN6jFr4ChB7TATDpSGHZ-1Bgd7Mfar131urkcR6rJnx-1024.npz
train_Episode has 500 steps and return 227.0.
Starting evaluation at step 189000 Counter(189000) 188937
eval_Episode has 500 steps and return 261.5.
train_Episode has 500 steps and return 214.7.
Saved chunk: 20230922T013641F196966-1G7IoHoFjP0RzY8qAGIyqX-7tTADoiuIz2x9HDH2ezIZE-1024.npz
Starting evaluation at step 189500 Counter(189500) 189437
eval_Episode has 500 steps and return 247.3.
Saved chunk: 20230922T013650F531819-1Bgd7Mfar131urkcR6rJnx-7iVeqsWmuV0SFzbY6wuqdI-1024.npz
train_Episode has 500 steps and return 259.0.
Starting evaluation at step 190000 Counter(190000) 189937
eval_Episode has 500 steps and return 254.8.
train_Episode has 500 steps and return 225.5.
Saved chunk: 20230922T013802F091524-7tTADoiuIz2x9HDH2ezIZE-5aeXeBad7fM3y16ay6ZPon-1024.npz
Starting evaluation at step 190500 Counter(190500) 190437
eval_Episode has 500 steps and return 219.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 381282 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 218.99 / eval_episode/reward_rate 0.36 / episode/length 500 / episode/score 225.47 / episode/reward_rate 0.35 / train/action_mag 4.31 / train/action_max 4.3 / train/action_mean 0.11 / train/action_min -3.17 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 9.4e4 / train/actor_opt_loss -19.09 / train/adv_mag 0.44 / train/adv_max 0.32 / train/adv_mean 2.7e-3 / train/adv_min
-0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.4e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.92 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 9.4e4 / 
train/extr_critic_critic_opt_loss 8396.02 / train/extr_critic_mag 182.54 / train/extr_critic_max 182.54 / train/extr_critic_mean 172.31 / train/extr_critic_min 153.4 / train/extr_critic_std 6.67 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 182.85 / train/extr_return_raw_max 182.85 / train/extr_return_raw_mean 172.36 / train/extr_return_raw_min 
151.49 / train/extr_return_raw_std 6.74 / train/extr_reward_mag 1.88 / train/extr_reward_max 1.88 / train/extr_reward_mean 0.23 / train/extr_reward_min 0 / train/extr_reward_std 0.47 / train/image_loss_mean 1.23 / train/image_loss_std 1.04 / train/model_loss_mean 3.66 /
train/model_loss_std 4.92 / train/model_opt_grad_norm 9.16 / train/model_opt_grad_steps 9.4e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.64 / train/policy_entropy_max 
2.95 / train/policy_entropy_mean -2.41 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.32 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.41 / train/policy_logprob_min -9.32 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 9.9e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 53.17 / train/post_ent_max 53.17 / train/post_ent_mean 38.11 / 
train/post_ent_min 20.58 / train/post_ent_std 4.98 / train/prior_ent_mag 85.28 / train/prior_ent_max 85.28 / train/prior_ent_mean 41.95 / train/prior_ent_min 25.59 / train/prior_ent_std 7.32 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.92 / train/reward_avg 0.21 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.27 / train/reward_max_data 1.77 / train/reward_max_pred 1.76 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.21 / train/reward_rate 
0.2 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.48 / report/cont_avg 1 / report/cont_loss_mean 5.5e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.06 / report/dyn_loss_std 7.58 / report/image_loss_mean 1.3 / report/image_loss_std 1.14 / report/model_loss_mean 3.86 / report/model_loss_std 5.4 / report/post_ent_mag 49.04 / report/post_ent_max 49.04 / 
report/post_ent_mean 38.29 / report/post_ent_min 21.13 / report/post_ent_std 5.03 / report/prior_ent_mag 85.27 / report/prior_ent_max 85.27 / report/prior_ent_mean 42.37 / report/prior_ent_min 27.85 / report/prior_ent_std 7.38 / report/rep_loss_mean 4.06 / 
report/rep_loss_std 7.58 / report/reward_avg 0.21 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.25 / report/reward_max_data 1.63 / report/reward_max_pred 1.66 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.21 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 3.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.11 / eval/dyn_loss_std 7.82 / eval/image_loss_mean 1.4 / eval/image_loss_std 1.66 / eval/model_loss_mean 4.74 / eval/model_loss_std 6.11 / eval/post_ent_mag 56.31 / eval/post_ent_max 56.31 / eval/post_ent_mean 
39.53 / eval/post_ent_min 22.86 / eval/post_ent_std 4.49 / eval/prior_ent_mag 85.27 / eval/prior_ent_max 85.27 / eval/prior_ent_mean 44.07 / eval/prior_ent_min 33.25 / eval/prior_ent_std 6.16 / eval/rep_loss_mean 5.11 / eval/rep_loss_std 7.82 / eval/reward_avg 0.35 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.58 / eval/reward_max_data 1.7 / eval/reward_max_pred 1.64 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.73 / eval/reward_pred 0.34 / eval/reward_rate 0.38 / 
replay/size 1.9e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3762 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 441.75 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.4e-3 
/ timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.64 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 251.6.
Starting evaluation at step 191000 Counter(191000) 190937
Saved chunk: 20230922T013809F839655-7iVeqsWmuV0SFzbY6wuqdI-3v8x3cAiLB9c4g4Vv0J9Gj-1024.npz
eval_Episode has 500 steps and return 276.0.
train_Episode has 500 steps and return 242.5.
Saved chunk: 20230922T013922F720584-5aeXeBad7fM3y16ay6ZPon-7oS96HPhmd8LVkZyBewstR-1024.npz
Starting evaluation at step 191500 Counter(191500) 191437
eval_Episode has 500 steps and return 265.5.
train_Episode has 500 steps and return 221.1.
Starting evaluation at step 192000 Counter(192000) 191937
Saved chunk: 20230922T014005F756428-3v8x3cAiLB9c4g4Vv0J9Gj-3imoop6re7X8J7ZvXeQRb2-1024.npz
eval_Episode has 500 steps and return 246.7.
train_Episode has 500 steps and return 242.3.
Starting evaluation at step 192500 Counter(192500) 192437
eval_Episode has 500 steps and return 274.4.
Saved chunk: 20230922T014044F516035-7oS96HPhmd8LVkZyBewstR-24ToX0f74JQs5CiI0GASf2-1024.npz
train_Episode has 500 steps and return 223.3.
Starting evaluation at step 193000 Counter(193000) 192937
Saved chunk: 20230922T014125F175483-3imoop6re7X8J7ZvXeQRb2-5wk42PzW1z84QyJnkFRkXH-1024.npz
eval_Episode has 500 steps and return 248.6.
train_Episode has 500 steps and return 216.1.
Starting evaluation at step 193500 Counter(193500) 193437
eval_Episode has 500 steps and return 257.8.
Saved chunk: 20230922T014208F947156-24ToX0f74JQs5CiI0GASf2-2OzzhskqCwMxpJTZvWqiBy-1024.npz
train_Episode has 500 steps and return 259.6.
Starting evaluation at step 194000 Counter(194000) 193937
Saved chunk: 20230922T014244F418623-5wk42PzW1z84QyJnkFRkXH-6YWs8SDg4p43bHHNjwKErp-1024.npz
eval_Episode has 500 steps and return 280.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T014329F401003-2OzzhskqCwMxpJTZvWqiBy-0000000000000000000000-764.npz
Saved chunk: 20230922T014403F224172-6YWs8SDg4p43bHHNjwKErp-0000000000000000000000-427.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 244.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 388906 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 244.4 / episode/reward_rate 0.38 / eval_episode/length 500 / eval_episode/score 280.17 / eval_episode/reward_rate 0.41 / train/action_mag 4.11 / train/action_max 4.1 / train/action_mean 0.1 / train/action_min -2.98 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 9.6e4 / train/actor_opt_loss -23.59 / train/adv_mag 1.11 / train/adv_max 1.05 / train/adv_mean 3.2e-3 / train/adv_min
-0.43 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 9.6e4 / 
train/extr_critic_critic_opt_loss 8047.03 / train/extr_critic_mag 183.27 / train/extr_critic_max 183.27 / train/extr_critic_mean 173.34 / train/extr_critic_min 145.1 / train/extr_critic_std 6.64 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.59 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 183.85 / train/extr_return_raw_max 183.85 / train/extr_return_raw_mean 173.41 / train/extr_return_raw_min 
152.23 / train/extr_return_raw_std 6.7 / train/extr_reward_mag 1.88 / train/extr_reward_max 1.88 / train/extr_reward_mean 0.23 / train/extr_reward_min 0 / train/extr_reward_std 0.47 / train/image_loss_mean 1.23 / train/image_loss_std 1.05 / train/model_loss_mean 3.66 / 
train/model_loss_std 4.92 / train/model_opt_grad_norm 9.16 / train/model_opt_grad_steps 9.6e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.65 / train/policy_entropy_max 
2.99 / train/policy_entropy_mean -2.58 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.04 / train/policy_logprob_mag 9.14 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.58 / train/policy_logprob_min -9.14 / train/policy_logprob_std 1.76 / 
train/policy_randomness_mag 0.71 / train/policy_randomness_max 0.71 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 7e-4 / train/policy_randomness_std 0.11 / train/post_ent_mag 53.13 / train/post_ent_max 53.13 / train/post_ent_mean 38.27 / 
train/post_ent_min 20.34 / train/post_ent_std 5.05 / train/prior_ent_mag 85.34 / train/prior_ent_max 85.34 / train/prior_ent_mean 42.09 / train/prior_ent_min 25.33 / train/prior_ent_std 7.31 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.91 / train/reward_avg 0.21 / 
train/reward_loss_mean 0.12 / train/reward_loss_std 0.27 / train/reward_max_data 1.78 / train/reward_max_pred 1.77 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.21 / train/reward_rate 
0.2 / train_stats/mean_log_entropy -2.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 7.22 / report/image_loss_mean 1.37 / report/image_loss_std 1.41 / report/model_loss_mean 3.81 / report/model_loss_std 5.37 / report/post_ent_mag 56.72 / report/post_ent_max 56.72 /
report/post_ent_mean 37.32 / report/post_ent_min 19.21 / report/post_ent_std 5.13 / report/prior_ent_mag 85.24 / report/prior_ent_max 85.24 / report/prior_ent_mean 41.53 / report/prior_ent_min 24.08 / report/prior_ent_std 7.45 / report/rep_loss_mean 3.95 / 
report/rep_loss_std 7.22 / report/reward_avg 0.12 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.31 / report/reward_max_data 1.87 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.12 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 8.1e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.16 / eval/dyn_loss_std 7.99 / eval/image_loss_mean 1.56 / eval/image_loss_std 1.95 / eval/model_loss_mean 4.97 / eval/model_loss_std 6.31 / eval/post_ent_mag 49.22 / eval/post_ent_max 49.22 / eval/post_ent_mean 
39.74 / eval/post_ent_min 21.38 / eval/post_ent_std 4.52 / eval/prior_ent_mag 85.24 / eval/prior_ent_max 85.24 / eval/prior_ent_mean 44.54 / eval/prior_ent_min 27.2 / eval/prior_ent_std 6.47 / eval/rep_loss_mean 5.16 / eval/rep_loss_std 7.99 / eval/reward_avg 0.38 / 
eval/reward_loss_mean 0.32 / eval/reward_loss_std 0.72 / eval/reward_max_data 1.79 / eval/reward_max_pred 1.83 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.82 / eval/reward_pred 0.37 / eval/reward_rate 0.39 / 
replay/size 1.9e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3812 / timer/env.step_total 19.78 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.44 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.8e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.6 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1906 / timer/agent.train_total 245 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.13 
/ timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 194500 Counter(194500) 194437
eval_Episode has 500 steps and return 259.9.
Saved chunk: 20230922T014329F401003-2OzzhskqCwMxpJTZvWqiBy-0TCconuBlRzxH6jgV2eOHz-1024.npz
train_Episode has 500 steps and return 237.7.
Starting evaluation at step 195000 Counter(195000) 194937
Saved chunk: 20230922T014403F224172-6YWs8SDg4p43bHHNjwKErp-6fqqEFd3FzVUgKqTkUpeQD-1024.npz
eval_Episode has 500 steps and return 275.7.
train_Episode has 500 steps and return 242.5.
Starting evaluation at step 195500 Counter(195500) 195437
eval_Episode has 500 steps and return 254.4.
Saved chunk: 20230922T014451F019383-0TCconuBlRzxH6jgV2eOHz-2WQR7rxuCkBl0OIsGIzy9B-1024.npz
train_Episode has 500 steps and return 244.4.
Starting evaluation at step 196000 Counter(196000) 195937
Saved chunk: 20230922T014523F473761-6fqqEFd3FzVUgKqTkUpeQD-5Qq3f4A0H7eVOwIO5NNkfH-1024.npz
eval_Episode has 500 steps and return 262.2.
train_Episode has 500 steps and return 233.3.
Starting evaluation at step 196500 Counter(196500) 196437
eval_Episode has 500 steps and return 250.7.
Saved chunk: 20230922T014611F885765-2WQR7rxuCkBl0OIsGIzy9B-7AAd1sgRFwxbaZ6TaEITDT-1024.npz
train_Episode has 500 steps and return 229.9.
Starting evaluation at step 197000 Counter(197000) 196937
Saved chunk: 20230922T014642F725027-5Qq3f4A0H7eVOwIO5NNkfH-0HzY76DjkUSN06KYJM4Cfs-1024.npz
eval_Episode has 500 steps and return 272.5.
train_Episode has 500 steps and return 214.4.
Starting evaluation at step 197500 Counter(197500) 197437
eval_Episode has 500 steps and return 224.5.
Saved chunk: 20230922T014732F585552-7AAd1sgRFwxbaZ6TaEITDT-75fnM2Lt8WO2eWrcvtaUae-1024.npz
train_Episode has 500 steps and return 221.7.
Starting evaluation at step 198000 Counter(198000) 197937
Saved chunk: 20230922T014801F741725-0HzY76DjkUSN06KYJM4Cfs-4tZTB0raJ8uDchBECOWbsY-1024.npz
eval_Episode has 500 steps and return 273.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 396450 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 273.91 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 221.74 / episode/reward_rate 0.36 / train/action_mag 3.88 / train/action_max 3.86 / train/action_mean 0.1 / train/action_min -3.14 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 9.8e4 / train/actor_opt_loss -31.23 / train/adv_mag 3.48 / train/adv_max 3.47 / train/adv_mean 4e-3 / train/adv_min 
-0.42 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.86 / train/dyn_loss_std 6.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 9.8e4 / 
train/extr_critic_critic_opt_loss 7612.68 / train/extr_critic_mag 184.59 / train/extr_critic_max 184.59 / train/extr_critic_mean 174.81 / train/extr_critic_min 107.06 / train/extr_critic_std 6.8 / train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.61 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 185.19 / train/extr_return_raw_max 185.19 / train/extr_return_raw_mean 174.89 / train/extr_return_raw_min 
153.87 / train/extr_return_raw_std 6.82 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.25 / train/extr_reward_min 0 / train/extr_reward_std 0.49 / train/image_loss_mean 1.22 / train/image_loss_std 1.02 / train/model_loss_mean 3.67 /
train/model_loss_std 4.9 / train/model_opt_grad_norm 9.18 / train/model_opt_grad_steps 9.8e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.83 / train/policy_entropy_max 
3.43 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.08 / train/policy_logprob_mag 9.15 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.15 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 5.8e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.82 / train/post_ent_max 52.82 / train/post_ent_mean 38.42 / 
train/post_ent_min 20.18 / train/post_ent_std 5.14 / train/prior_ent_mag 85.27 / train/prior_ent_max 85.27 / train/prior_ent_mean 42.26 / train/prior_ent_min 25 / train/prior_ent_std 7.38 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.9 / train/reward_avg 0.22 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.28 / train/reward_max_data 1.78 / train/reward_max_pred 1.77 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.22 / train/reward_rate 
0.21 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.83 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.03 / report/dyn_loss_std 6.73 / report/image_loss_mean 1.19 / report/image_loss_std 0.87 / report/model_loss_mean 3.76 / report/model_loss_std 4.78 / report/post_ent_mag 49.38 / report/post_ent_max 49.38 /
report/post_ent_mean 39.01 / report/post_ent_min 21.36 / report/post_ent_std 4.9 / report/prior_ent_mag 85.23 / report/prior_ent_max 85.23 / report/prior_ent_mean 42.71 / report/prior_ent_min 24.44 / report/prior_ent_std 6.88 / report/rep_loss_mean 4.03 / 
report/rep_loss_std 6.73 / report/reward_avg 0.28 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.33 / report/reward_max_data 1.87 / report/reward_max_pred 1.87 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.28 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 9.7e-11 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.72 / eval/dyn_loss_std 7.15 / eval/image_loss_mean 1.29 / eval/image_loss_std 1.04 / eval/model_loss_mean 4.34 / eval/model_loss_std 5.09 / eval/post_ent_mag 49.97 / eval/post_ent_max 49.97 / eval/post_ent_mean 
40.71 / eval/post_ent_min 23.89 / eval/post_ent_std 4.28 / eval/prior_ent_mag 85.23 / eval/prior_ent_max 85.23 / eval/prior_ent_mean 44.64 / eval/prior_ent_min 29.6 / eval/prior_ent_std 5.81 / eval/rep_loss_mean 4.72 / eval/rep_loss_std 7.15 / eval/reward_avg 0.37 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.45 / eval/reward_max_data 1.71 / eval/reward_max_pred 1.76 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.37 / eval/reward_rate 0.35 / 
replay/size 2e5 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3772 / timer/env.step_total 19.55 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.2e-3 / timer/env.step_max 8.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.29 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7780 / timer/agent.policy_total 17.43 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1886 / timer/agent.train_total 242.47 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.15

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 239.4.
Starting evaluation at step 198500 Counter(198500) 198437
eval_Episode has 500 steps and return 261.8.
Saved chunk: 20230922T014853F045483-75fnM2Lt8WO2eWrcvtaUae-1BXCNCDThGA0DE0aQMsGBd-1024.npz
train_Episode has 500 steps and return 236.4.
Starting evaluation at step 199000 Counter(199000) 198937
Saved chunk: 20230922T014920F567347-4tZTB0raJ8uDchBECOWbsY-4gcpiHoqWCRPtw2CQgMGAL-1024.npz
eval_Episode has 500 steps and return 244.9.
train_Episode has 500 steps and return 264.4.
Starting evaluation at step 199500 Counter(199500) 199437
eval_Episode has 500 steps and return 281.1.
Saved chunk: 20230922T015014F354985-1BXCNCDThGA0DE0aQMsGBd-3pvQLhvxkNdSBuqiAd1Mps-1024.npz
train_Episode has 500 steps and return 232.8.
Starting evaluation at step 200000 Counter(200000) 199937
Saved chunk: 20230922T015040F444642-4gcpiHoqWCRPtw2CQgMGAL-2naIWR3XbujgtoQwecJ5TV-1024.npz
eval_Episode has 500 steps and return 169.8.
train_Episode has 500 steps and return 235.5.
Starting evaluation at step 200500 Counter(200500) 200437
eval_Episode has 500 steps and return 275.5.
Saved chunk: 20230922T015135F036326-3pvQLhvxkNdSBuqiAd1Mps-3Wuk63IL8Y1DBKXKlN7wKr-1024.npz
train_Episode has 500 steps and return 243.3.
Starting evaluation at step 201000 Counter(201000) 200937
Saved chunk: 20230922T015159F515914-2naIWR3XbujgtoQwecJ5TV-5EWd05oT2Gnn4LG7U51iVx-1024.npz
eval_Episode has 500 steps and return 284.1.
train_Episode has 500 steps and return 256.4.
Starting evaluation at step 201500 Counter(201500) 201437
eval_Episode has 500 steps and return 259.2.
Saved chunk: 20230922T015255F653654-3Wuk63IL8Y1DBKXKlN7wKr-6w2hCizZL3k5IxcLE1MWAK-1024.npz
train_Episode has 500 steps and return 236.4.
Starting evaluation at step 202000 Counter(202000) 201937
Saved chunk: 20230922T015318F450151-5EWd05oT2Gnn4LG7U51iVx-4jzzRqwZAUvw9G0SJyFlkn-1024.npz
eval_Episode has 500 steps and return 276.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 404002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 236.4 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 276.45 / eval_episode/reward_rate 0.4 / train/action_mag 3.9 / train/action_max 3.89 / train/action_mean 0.1 / train/action_min -3.13 / train/action_std 
0.89 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -29.94 / train/adv_mag 0.97 / train/adv_max 0.92 / train/adv_mean 3.8e-3 / train/adv_min 
-0.45 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 5.2e-11 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 7400.79 / train/extr_critic_mag 186.53 / train/extr_critic_max 186.53 / train/extr_critic_mean 176.88 / train/extr_critic_min 152.95 / train/extr_critic_std 6.4 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / 
train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 187 / train/extr_return_raw_max 187 / train/extr_return_raw_mean 176.96 / train/extr_return_raw_min 156.02 /
train/extr_return_raw_std 6.46 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.49 / train/image_loss_mean 1.22 / train/image_loss_std 1.02 / train/model_loss_mean 3.67 / 
train/model_loss_std 4.89 / train/model_opt_grad_norm 8.8 / train/model_opt_grad_steps 9.9e4 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.01 / train/policy_entropy_max 
3.78 / train/policy_entropy_mean -2.61 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.41 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.61 / train/policy_logprob_min -9.41 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 5e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.74 / train/post_ent_max 52.74 / train/post_ent_mean 38.78 / 
train/post_ent_min 20.7 / train/post_ent_std 4.98 / train/prior_ent_mag 85.31 / train/prior_ent_max 85.31 / train/prior_ent_mean 42.64 / train/prior_ent_min 26.03 / train/prior_ent_std 7.15 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.87 / train/reward_avg 0.23 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.81 / train/reward_max_pred 1.79 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.6 / train/reward_pred 0.23 / train/reward_rate 
0.22 / train_stats/mean_log_entropy -2.8 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.09 / report/dyn_loss_std 7.23 / report/image_loss_mean 1.38 / report/image_loss_std 1.16 / report/model_loss_mean 3.97 / report/model_loss_std 5.18 / report/post_ent_mag 55.36 / report/post_ent_max 55.36 /
report/post_ent_mean 38.42 / report/post_ent_min 18.18 / report/post_ent_std 5.12 / report/prior_ent_mag 85.29 / report/prior_ent_max 85.29 / report/prior_ent_mean 42.55 / report/prior_ent_min 24.04 / report/prior_ent_std 7.21 / report/rep_loss_mean 4.09 / 
report/rep_loss_std 7.23 / report/reward_avg 0.21 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.27 / report/reward_max_data 1.81 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 4.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.21 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.94 / eval/dyn_loss_std 7.49 / eval/image_loss_mean 1.54 / eval/image_loss_std 1.9 / eval/model_loss_mean 4.74 / eval/model_loss_std 5.88 / eval/post_ent_mag 49.95 / eval/post_ent_max 49.95 / eval/post_ent_mean 
40.51 / eval/post_ent_min 24.49 / eval/post_ent_std 4.41 / eval/prior_ent_mag 85.29 / eval/prior_ent_max 85.29 / eval/prior_ent_mean 44.94 / eval/prior_ent_min 29.75 / eval/prior_ent_std 6.02 / eval/rep_loss_mean 4.94 / eval/rep_loss_std 7.49 / eval/reward_avg 0.44 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.79 / eval/reward_max_pred 1.82 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.44 / eval/reward_rate 0.4 / 
replay/size 2e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3776 / timer/env.step_total 19.61 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.65 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7784 / timer/agent.policy_total 17.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1888 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1888 / timer/agent.train_total 242.54 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.16

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 200.4.
Starting evaluation at step 202500 Counter(202500) 202437
eval_Episode has 500 steps and return 268.4.
Saved chunk: 20230922T015416F016720-6w2hCizZL3k5IxcLE1MWAK-2Qn9j5n2aR1weqfVuETeHY-1024.npz
train_Episode has 500 steps and return 227.2.
Starting evaluation at step 203000 Counter(203000) 202937
Saved chunk: 20230922T015437F338569-4jzzRqwZAUvw9G0SJyFlkn-6G0DgALN5VGcDWdcB482Yv-1024.npz
eval_Episode has 500 steps and return 258.8.
train_Episode has 500 steps and return 215.6.
Starting evaluation at step 203500 Counter(203500) 203437
eval_Episode has 500 steps and return 223.7.
Saved chunk: 20230922T015537F606623-2Qn9j5n2aR1weqfVuETeHY-2O2vquTRm14q2ZLy6XPY48-1024.npz
train_Episode has 500 steps and return 223.4.
Starting evaluation at step 204000 Counter(204000) 203937
Saved chunk: 20230922T015557F368137-6G0DgALN5VGcDWdcB482Yv-6mitrBTCXvAmupxLpuvmRq-1024.npz
eval_Episode has 500 steps and return 264.0.
train_Episode has 500 steps and return 226.7.
Starting evaluation at step 204500 Counter(204500) 204437
eval_Episode has 500 steps and return 276.3.
Saved chunk: 20230922T015658F303675-2O2vquTRm14q2ZLy6XPY48-2Vw35oK9XScCgu8XSPxxcO-1024.npz
train_Episode has 500 steps and return 252.4.
Starting evaluation at step 205000 Counter(205000) 204937
Saved chunk: 20230922T015716F458561-6mitrBTCXvAmupxLpuvmRq-5wH26BduD0KtT8PldGpRih-1024.npz
eval_Episode has 500 steps and return 288.0.
train_Episode has 500 steps and return 245.9.
Starting evaluation at step 205500 Counter(205500) 205437
eval_Episode has 500 steps and return 265.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T015835F299260-5wH26BduD0KtT8PldGpRih-0000000000000000000000-686.npz
Saved chunk: 20230922T015818F779186-2Vw35oK9XScCgu8XSPxxcO-0000000000000000000000-900.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 411646 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 245.9 / episode/reward_rate 0.38 / eval_episode/length 500 / eval_episode/score 265.06 / eval_episode/reward_rate 0.38 / train/action_mag 3.88 / train/action_max 3.85 / train/action_mean 0.09 / train/action_min -3.08 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -28.51 / train/adv_mag 0.67 / train/adv_max 0.55 / train/adv_mean 3.7e-3 / train/adv_min 
-0.58 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 2.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 8129.16 / train/extr_critic_mag 188.5 / train/extr_critic_max 188.5 / train/extr_critic_mean 177.78 / train/extr_critic_min 142.95 / train/extr_critic_std 8.61 / train/extr_return_normed_mag 1.08 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.66 / train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 188.89 / train/extr_return_raw_max 188.89 / train/extr_return_raw_mean 177.88 / train/extr_return_raw_min 
144.79 / train/extr_return_raw_std 8.66 / train/extr_reward_mag 1.86 / train/extr_reward_max 1.86 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.5 / train/image_loss_mean 1.22 / train/image_loss_std 1.06 / train/model_loss_mean 3.67 / 
train/model_loss_std 4.95 / train/model_opt_grad_norm 9.21 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.86 / train/policy_entropy_max 
3.52 / train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.35 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -9.35 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 4.5e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 53.04 / train/post_ent_max 53.04 / train/post_ent_mean 38.92 / 
train/post_ent_min 20.79 / train/post_ent_std 5.09 / train/prior_ent_mag 85.35 / train/prior_ent_max 85.35 / train/prior_ent_mean 42.76 / train/prior_ent_min 25.98 / train/prior_ent_std 7.25 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.93 / train/reward_avg 0.23 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.28 / train/reward_max_data 1.8 / train/reward_max_pred 1.79 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.23 / train/reward_rate 
0.22 / train_stats/mean_log_entropy -2.82 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.33 / report/dyn_loss_std 7.62 / report/image_loss_mean 1.42 / report/image_loss_std 1.08 / report/model_loss_mean 4.16 / report/model_loss_std 5.31 / report/post_ent_mag 48.94 / report/post_ent_max 48.94 /
report/post_ent_mean 38.49 / report/post_ent_min 20.31 / report/post_ent_std 5.85 / report/prior_ent_mag 85.34 / report/prior_ent_max 85.34 / report/prior_ent_mean 42.74 / report/prior_ent_min 20.86 / report/prior_ent_std 8.04 / report/rep_loss_mean 4.33 / 
report/rep_loss_std 7.62 / report/reward_avg 0.23 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.28 / report/reward_max_data 1.88 / report/reward_max_pred 1.84 / report/reward_neg_acc 1 / report/reward_neg_loss 8.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.23 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 7.2e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.22 / eval/dyn_loss_std 6.59 / eval/image_loss_mean 1.16 / eval/image_loss_std 1.09 / eval/model_loss_mean 3.93 / eval/model_loss_std 4.67 / eval/post_ent_mag 49.89 / eval/post_ent_max 49.89 / eval/post_ent_mean 
41.25 / eval/post_ent_min 22.81 / eval/post_ent_std 4 / eval/prior_ent_mag 85.34 / eval/prior_ent_max 85.34 / eval/prior_ent_mean 45.38 / eval/prior_ent_min 30.88 / eval/prior_ent_std 5.76 / eval/rep_loss_mean 4.22 / eval/rep_loss_std 6.59 / eval/reward_avg 0.47 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.86 / eval/reward_max_pred 1.84 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.47 / eval/reward_rate 0.39 / 
replay/size 2.1e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3822 / timer/env.step_total 19.98 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.74 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-4 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7329 / timer/agent.policy_total 16.65 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1911 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1911 / timer/agent.train_total 245.34 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9e-8 / timer/dataset_eval_avg 2.7e-5 / 
timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.48

Saved chunk: 20230922T015818F779186-2Vw35oK9XScCgu8XSPxxcO-3D8hCTT3AbpYihMbzeNDVv-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 226.4.
Starting evaluation at step 206000 Counter(206000) 205937
Saved chunk: 20230922T015835F299260-5wH26BduD0KtT8PldGpRih-6ipyp993tZbUvVJGwiccM4-1024.npz
eval_Episode has 500 steps and return 280.9.
train_Episode has 500 steps and return 230.5.
Starting evaluation at step 206500 Counter(206500) 206437
eval_Episode has 500 steps and return 268.9.
Saved chunk: 20230922T015939F459817-3D8hCTT3AbpYihMbzeNDVv-1TqnJmel57ipy6Axg2UEc9-1024.npz
train_Episode has 500 steps and return 246.5.
Starting evaluation at step 207000 Counter(207000) 206937
Saved chunk: 20230922T015955F066143-6ipyp993tZbUvVJGwiccM4-2HCuUWrcFhiQjnaEpl3HRw-1024.npz
eval_Episode has 500 steps and return 255.5.
train_Episode has 500 steps and return 242.0.
Starting evaluation at step 207500 Counter(207500) 207437
eval_Episode has 500 steps and return 254.3.
Saved chunk: 20230922T020100F773391-1TqnJmel57ipy6Axg2UEc9-5huBQrEq98o5Du6PQsYE5k-1024.npz
train_Episode has 500 steps and return 217.0.
Starting evaluation at step 208000 Counter(208000) 207937
Saved chunk: 20230922T020114F185907-2HCuUWrcFhiQjnaEpl3HRw-0bDp2br4zkrP5l06LFtNsk-1024.npz
eval_Episode has 500 steps and return 285.8.
train_Episode has 500 steps and return 207.0.
Starting evaluation at step 208500 Counter(208500) 208437
eval_Episode has 500 steps and return 272.6.
Saved chunk: 20230922T020221F318817-5huBQrEq98o5Du6PQsYE5k-5wDgtJaMsfxW6Hm7gzLibS-1024.npz
train_Episode has 500 steps and return 233.7.
Starting evaluation at step 209000 Counter(209000) 208937
Saved chunk: 20230922T020233F100650-0bDp2br4zkrP5l06LFtNsk-2wsPV3VRKrM36UwMV4pxjr-1024.npz
eval_Episode has 500 steps and return 270.1.
train_Episode has 500 steps and return 232.8.
Starting evaluation at step 209500 Counter(209500) 209437
eval_Episode has 500 steps and return 260.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 419210 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 232.78 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 260.87 / eval_episode/reward_rate 0.38 / train/action_mag 3.85 / train/action_max 3.83 / train/action_mean 0.08 / train/action_min -3.08 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -35.86 / train/adv_mag 0.45 / train/adv_max 0.35 / train/adv_mean 4.4e-3 
/ train/adv_min -0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.8e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1e5 / 
train/extr_critic_critic_opt_loss 9462.59 / train/extr_critic_mag 190.87 / train/extr_critic_max 190.87 / train/extr_critic_mean 180.92 / train/extr_critic_min 158.19 / train/extr_critic_std 6.92 / train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 191.24 / train/extr_return_raw_max 191.24 / train/extr_return_raw_mean 181.01 / train/extr_return_raw_min 
158.64 / train/extr_return_raw_std 6.95 / train/extr_reward_mag 1.86 / train/extr_reward_max 1.86 / train/extr_reward_mean 0.25 / train/extr_reward_min 0 / train/extr_reward_std 0.49 / train/image_loss_mean 1.2 / train/image_loss_std 1.03 / train/model_loss_mean 3.63 / 
train/model_loss_std 4.88 / train/model_opt_grad_norm 9.06 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.85 / train/policy_entropy_max 
3.62 / train/policy_entropy_mean -2.49 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.44 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.49 / train/policy_logprob_min -9.44 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 4.6e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.77 / train/post_ent_max 52.77 / train/post_ent_mean 39.01 / 
train/post_ent_min 21.12 / train/post_ent_std 5.12 / train/prior_ent_mag 85.31 / train/prior_ent_max 85.31 / train/prior_ent_mean 42.82 / train/prior_ent_min 26.14 / train/prior_ent_std 7.28 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.84 / train/reward_avg 0.23 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.28 / train/reward_max_data 1.8 / train/reward_max_pred 1.79 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.23 / train/reward_rate 
0.22 / train_stats/mean_log_entropy -2.66 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.93 / report/dyn_loss_std 7.09 / report/image_loss_mean 1.16 / report/image_loss_std 0.94 / report/model_loss_mean 3.64 / report/model_loss_std 4.96 / report/post_ent_mag 55.7 / report/post_ent_max 55.7 / 
report/post_ent_mean 39.51 / report/post_ent_min 20.19 / report/post_ent_std 4.61 / report/prior_ent_mag 85.29 / report/prior_ent_max 85.29 / report/prior_ent_mean 43.41 / report/prior_ent_min 23.68 / report/prior_ent_std 6.84 / report/rep_loss_mean 3.93 / 
report/rep_loss_std 7.09 / report/reward_avg 0.23 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.26 / report/reward_max_data 1.83 / report/reward_max_pred 1.84 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.24 / report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.46 / eval/dyn_loss_std 6.72 / eval/image_loss_mean 1.22 / eval/image_loss_std 1.36 / eval/model_loss_mean 4.12 / eval/model_loss_std 4.95 / eval/post_ent_mag 49.53 / eval/post_ent_max 49.53 / eval/post_ent_mean 
41.4 / eval/post_ent_min 23.17 / eval/post_ent_std 4.02 / eval/prior_ent_mag 85.29 / eval/prior_ent_max 85.29 / eval/prior_ent_mean 45.61 / eval/prior_ent_min 33.29 / eval/prior_ent_std 5.74 / eval/rep_loss_mean 4.46 / eval/rep_loss_std 6.72 / eval/reward_avg 0.44 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.89 / eval/reward_max_pred 1.84 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.43 / eval/reward_rate 0.37 / 
replay/size 2.1e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3782 / timer/env.step_total 19.6 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.25 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-4 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.9e-3 
/ timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1891 / timer/agent.train_total 242.76 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 255.1.
Saved chunk: 20230922T020341F547560-5wDgtJaMsfxW6Hm7gzLibS-1F9llTiX2HCcK1kr4CdKdx-1024.npz
Starting evaluation at step 210000 Counter(210000) 209937
eval_Episode has 500 steps and return 246.4.
Saved chunk: 20230922T020351F741885-2wsPV3VRKrM36UwMV4pxjr-4LtonxPU1La2tcOj9KOXhA-1024.npz
train_Episode has 500 steps and return 267.7.
Starting evaluation at step 210500 Counter(210500) 210437
eval_Episode has 500 steps and return 253.6.
train_Episode has 500 steps and return 243.2.
Saved chunk: 20230922T020502F851066-1F9llTiX2HCcK1kr4CdKdx-2nGhOhCBMNnAYJtLgwEIxB-1024.npz
Starting evaluation at step 211000 Counter(211000) 210937
eval_Episode has 500 steps and return 259.1.
Saved chunk: 20230922T020511F502030-4LtonxPU1La2tcOj9KOXhA-0CoUtBmtPdO6VfLeiGxE7Y-1024.npz
train_Episode has 500 steps and return 261.9.
Starting evaluation at step 211500 Counter(211500) 211437
eval_Episode has 500 steps and return 280.4.
train_Episode has 500 steps and return 227.1.
Saved chunk: 20230922T020623F541642-2nGhOhCBMNnAYJtLgwEIxB-3czI8NFzFb03Te9BzOsoyO-1024.npz
Starting evaluation at step 212000 Counter(212000) 211937
eval_Episode has 500 steps and return 289.6.
Saved chunk: 20230922T020630F594279-0CoUtBmtPdO6VfLeiGxE7Y-1wDjr08LVRkFur3j3ZaWW3-1024.npz
train_Episode has 500 steps and return 241.8.
Starting evaluation at step 212500 Counter(212500) 212437
eval_Episode has 500 steps and return 255.0.
train_Episode has 500 steps and return 258.4.
Saved chunk: 20230922T020744F234129-3czI8NFzFb03Te9BzOsoyO-1SGFsqnxxTBxoXerf1tieA-1024.npz
Starting evaluation at step 213000 Counter(213000) 212937
eval_Episode has 500 steps and return 289.7.
Saved chunk: 20230922T020749F674281-1wDjr08LVRkFur3j3ZaWW3-018xRZF4uqi4gG66MmfJSJ-1024.npz
train_Episode has 500 steps and return 254.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 426854 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 254.26 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 289.7 / eval_episode/reward_rate 0.43 / train/action_mag 3.86 / train/action_max 3.84 / train/action_mean 0.08 / train/action_min -3.23 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -27.75 / train/adv_mag 0.51 / train/adv_max 0.38 / train/adv_mean 3.6e-3 / train/adv_min 
-0.44 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.87 / train/dyn_loss_std 6.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 193.16 / train/extr_critic_max 193.16 / train/extr_critic_mean 183.47 / train/extr_critic_min 160.02 / train/extr_critic_std 6.86 / train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 193.51 / train/extr_return_raw_max 193.51 / train/extr_return_raw_mean 183.55 / train/extr_return_raw_min 
160.63 / train/extr_return_raw_std 6.91 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.5 / train/image_loss_mean 1.2 / train/image_loss_std 1.02 / train/model_loss_mean 3.66 / 
train/model_loss_std 4.91 / train/model_opt_grad_norm 9.01 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.89 / train/policy_entropy_max 
3.6 / train/policy_entropy_mean -2.44 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.17 / train/policy_logprob_mag 9.56 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.44 / train/policy_logprob_min -9.56 / train/policy_logprob_std 1.84 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 4.6e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.75 / train/post_ent_max 52.75 / train/post_ent_mean 39.19 / 
train/post_ent_min 21.08 / train/post_ent_std 5.13 / train/prior_ent_mag 85.42 / train/prior_ent_max 85.42 / train/prior_ent_mean 43.05 / train/prior_ent_min 26.23 / train/prior_ent_std 7.26 / train/rep_loss_mean 3.87 / train/rep_loss_std 6.9 / train/reward_avg 0.24 / 
train/reward_loss_mean 0.13 / train/reward_loss_std 0.28 / train/reward_max_data 1.81 / train/reward_max_pred 1.8 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.24 / train/reward_rate 
0.22 / train_stats/mean_log_entropy -2.61 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.94 / report/dyn_loss_std 6.7 / report/image_loss_mean 1.13 / report/image_loss_std 0.97 / report/model_loss_mean 3.63 / report/model_loss_std 4.73 / report/post_ent_mag 53.19 / report/post_ent_max 53.19 / 
report/post_ent_mean 38.81 / report/post_ent_min 19.21 / report/post_ent_std 6.7 / report/prior_ent_mag 85.33 / report/prior_ent_max 85.33 / report/prior_ent_mean 42.53 / report/prior_ent_min 19.99 / report/prior_ent_std 8.97 / report/rep_loss_mean 3.94 / 
report/rep_loss_std 6.7 / report/reward_avg 0.28 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.28 / report/reward_max_data 1.84 / report/reward_max_pred 1.81 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.27 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.93 / eval/dyn_loss_std 7.51 / eval/image_loss_mean 1.39 / eval/image_loss_std 1.71 / eval/model_loss_mean 4.61 / eval/model_loss_std 5.71 / eval/post_ent_mag 48.89 / eval/post_ent_max 48.89 / eval/post_ent_mean 
41.05 / eval/post_ent_min 22.56 / eval/post_ent_std 4.48 / eval/prior_ent_mag 85.33 / eval/prior_ent_max 85.33 / eval/prior_ent_mean 45.55 / eval/prior_ent_min 26.27 / eval/prior_ent_std 6.13 / eval/rep_loss_mean 4.93 / eval/rep_loss_std 7.51 / eval/reward_avg 0.46 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.82 / eval/reward_max_pred 1.78 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.45 / eval/reward_rate 0.4 / 
replay/size 2.1e5 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3822 / timer/env.step_total 20.13 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 450.14 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7329 / timer/agent.policy_total 16.55 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1911 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1911 / timer/agent.train_total 245.13 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.5e-5 / timer/dataset_eval_frac 8.2e-8 / timer/dataset_eval_avg 2.5e-5 / timer/dataset_eval_min 2.5e-5 / timer/dataset_eval_max 2.5e-5 / fps 25.47

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 213500 Counter(213500) 213437
eval_Episode has 500 steps and return 273.7.
train_Episode has 500 steps and return 256.7.
Starting evaluation at step 214000 Counter(214000) 213937
eval_Episode has 500 steps and return 274.1.
Saved chunk: 20230922T020904F554081-1SGFsqnxxTBxoXerf1tieA-2CXzVAPo2WWkoxFR6vX8Cw-1024.npz
train_Episode has 500 steps and return 268.5.
Starting evaluation at step 214500 Counter(214500) 214437
Saved chunk: 20230922T020908F575574-018xRZF4uqi4gG66MmfJSJ-1829DO2n3MSgwS99YKq4qZ-1024.npz
eval_Episode has 500 steps and return 279.5.
train_Episode has 500 steps and return 233.6.
Starting evaluation at step 215000 Counter(215000) 214937
eval_Episode has 500 steps and return 272.4.
Saved chunk: 20230922T021029F836221-2CXzVAPo2WWkoxFR6vX8Cw-4n1xySdAjEchB1vYQOMydq-1024.npz
train_Episode has 500 steps and return 263.9.
Starting evaluation at step 215500 Counter(215500) 215437
Saved chunk: 20230922T021104F900403-1829DO2n3MSgwS99YKq4qZ-4DRBbk1QXMqcOXpHc2astT-1024.npz
eval_Episode has 500 steps and return 268.7.
train_Episode has 500 steps and return 216.6.
Starting evaluation at step 216000 Counter(216000) 215937
eval_Episode has 500 steps and return 291.9.
Saved chunk: 20230922T021150F798795-4n1xySdAjEchB1vYQOMydq-4oEC8KPTG6nTVk7S6amGJU-1024.npz
train_Episode has 500 steps and return 252.9.
Starting evaluation at step 216500 Counter(216500) 216437
Saved chunk: 20230922T021225F355946-4DRBbk1QXMqcOXpHc2astT-50wacuUhqUbYvd8ANauX56-1024.npz
eval_Episode has 500 steps and return 289.2.
train_Episode has 500 steps and return 264.9.
Starting evaluation at step 217000 Counter(217000) 216937
eval_Episode has 500 steps and return 280.6.
Saved chunk: 20230922T021312F777031-4oEC8KPTG6nTVk7S6amGJU-4dGro4Sr3rzkp6npK9Sdxb-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T021433F502470-4dGro4Sr3rzkp6npK9Sdxb-0000000000000000000000-12.npz
Saved chunk: 20230922T021344F531272-50wacuUhqUbYvd8ANauX56-0000000000000000000000-945.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 434334 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 280.55 / eval_episode/reward_rate 0.41 / episode/length 500 / episode/score 264.89 / episode/reward_rate 0.42 / train/action_mag 4.01 / train/action_max 3.97 / train/action_mean 0.08 / train/action_min -3.56 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -27.11 / train/adv_mag 0.53 / train/adv_max 0.42 / train/adv_mean 
3.5e-3 / train/adv_min -0.42 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / 
train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 195.39 / train/extr_critic_max 195.39 / train/extr_critic_mean 185.37 / train/extr_critic_min 161.06 / train/extr_critic_std 7.24 / 
train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 195.7 / train/extr_return_raw_max 
195.7 / train/extr_return_raw_mean 185.44 / train/extr_return_raw_min 162.86 / train/extr_return_raw_std 7.27 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.26 / train/extr_reward_min 0 / train/extr_reward_std 0.5 / 
train/image_loss_mean 1.18 / train/image_loss_std 1.01 / train/model_loss_mean 3.62 / train/model_loss_std 4.84 / train/model_opt_grad_norm 8.89 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.03 / train/policy_entropy_max 3.85 / train/policy_entropy_mean -2.36 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 9.58 / train/policy_logprob_max 5.48 / 
train/policy_logprob_mean 2.36 / train/policy_logprob_min -9.58 / train/policy_logprob_std 1.89 / train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 4.3e-4 / train/policy_randomness_std 
0.14 / train/post_ent_mag 53.21 / train/post_ent_max 53.21 / train/post_ent_mean 39.34 / train/post_ent_min 20.65 / train/post_ent_std 5.14 / train/prior_ent_mag 85.36 / train/prior_ent_max 85.36 / train/prior_ent_mean 43.15 / train/prior_ent_min 25.95 / 
train/prior_ent_std 7.22 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.81 / train/reward_avg 0.25 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.82 / train/reward_max_pred 1.8 / train/reward_neg_acc 1 / train/reward_neg_loss 
3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.24 / train/reward_rate 0.23 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.49 / report/cont_avg 1 / report/cont_loss_mean 4.7e-11 / report/cont_loss_std 5e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.83 / report/image_loss_mean 1.16 / report/image_loss_std 0.92 / 
report/model_loss_mean 3.52 / report/model_loss_std 4.72 / report/post_ent_mag 55.37 / report/post_ent_max 55.37 / report/post_ent_mean 39.66 / report/post_ent_min 20.35 / report/post_ent_std 4.86 / report/prior_ent_mag 85.2 / report/prior_ent_max 85.2 / 
report/prior_ent_mean 43.37 / report/prior_ent_min 23.73 / report/prior_ent_std 7.08 / report/rep_loss_mean 3.72 / report/rep_loss_std 6.83 / report/reward_avg 0.22 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.27 / report/reward_max_data 1.79 / 
report/reward_max_pred 1.8 / report/reward_neg_acc 1 / report/reward_neg_loss 6.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.23 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.2e-10 
/ eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.99 / eval/dyn_loss_std 7.92 / eval/image_loss_mean 1.54 / eval/image_loss_std 2.4 / eval/model_loss_mean 4.82
/ eval/model_loss_std 6.75 / eval/post_ent_mag 49.05 / eval/post_ent_max 49.05 / eval/post_ent_mean 40.99 / eval/post_ent_min 20.87 / eval/post_ent_std 4.58 / eval/prior_ent_mag 85.2 / eval/prior_ent_max 85.2 / eval/prior_ent_mean 45.5 / eval/prior_ent_min 30.83 / 
eval/prior_ent_std 5.83 / eval/rep_loss_mean 4.99 / eval/rep_loss_std 7.92 / eval/reward_avg 0.47 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.53 / eval/reward_max_data 1.79 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.64 / eval/reward_pred 0.47 / eval/reward_rate 0.42 / replay/size 2.2e5 / replay/inserts 3740 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3740 / timer/env.step_total 19.51 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.55 / timer/replay._sample_frac 1.48 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7748 / timer/agent.policy_total 17.61 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1870 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1870 / timer/agent.train_total 241.45 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 1.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 2.2e-5 / timer/dataset_eval_frac 7.4e-8 / timer/dataset_eval_avg 2.2e-5 / timer/dataset_eval_min 2.2e-5 / timer/dataset_eval_max 2.2e-5 / fps 24.93

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 222.8.
Starting evaluation at step 217500 Counter(217500) 217437
Saved chunk: 20230922T021344F531272-50wacuUhqUbYvd8ANauX56-7IvfJ7CE5dFD12Lsmk9h40-1024.npz
eval_Episode has 500 steps and return 293.3.
train_Episode has 500 steps and return 252.6.
Starting evaluation at step 218000 Counter(218000) 217937
eval_Episode has 500 steps and return 275.9.
Saved chunk: 20230922T021433F502470-4dGro4Sr3rzkp6npK9Sdxb-0JleRjjxstMSdsw4dZhUBB-1024.npz
train_Episode has 500 steps and return 273.8.
Starting evaluation at step 218500 Counter(218500) 218437
Saved chunk: 20230922T021504F795091-7IvfJ7CE5dFD12Lsmk9h40-4gu64ZkJ8kq0MagLDi2UxT-1024.npz
eval_Episode has 500 steps and return 260.3.
train_Episode has 500 steps and return 269.0.
Starting evaluation at step 219000 Counter(219000) 218937
eval_Episode has 500 steps and return 291.4.
Saved chunk: 20230922T021555F553313-0JleRjjxstMSdsw4dZhUBB-0PcIpzjt4a5TdRGCJTWa0R-1024.npz
train_Episode has 500 steps and return 259.1.
Starting evaluation at step 219500 Counter(219500) 219437
Saved chunk: 20230922T021624F204939-4gu64ZkJ8kq0MagLDi2UxT-2N0ZXDByWfnNAeXn3BCQX5-1024.npz
eval_Episode has 500 steps and return 287.4.
train_Episode has 500 steps and return 244.9.
Starting evaluation at step 220000 Counter(220000) 219937
eval_Episode has 500 steps and return 263.0.
Saved chunk: 20230922T021716F419349-0PcIpzjt4a5TdRGCJTWa0R-1TtMe01nG9uOrjWqCF0l4U-1024.npz
train_Episode has 500 steps and return 259.7.
Starting evaluation at step 220500 Counter(220500) 220437
Saved chunk: 20230922T021743F468101-2N0ZXDByWfnNAeXn3BCQX5-43LlsHwyAqJRuokoQiYqoo-1024.npz
eval_Episode has 500 steps and return 296.1.
train_Episode has 500 steps and return 244.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 441958 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 244.52 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 296.07 / eval_episode/reward_rate 0.45 / train/action_mag 3.93 / train/action_max 3.93 / train/action_mean 0.08 / train/action_min -3.13 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -24.58 / train/adv_mag 0.67 / train/adv_max 0.55 / train/adv_mean 
3.3e-3 / train/adv_min -0.46 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.86 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 197.38 / train/extr_critic_max 197.38 / train/extr_critic_mean 187.59 / train/extr_critic_min 161.14 / train/extr_critic_std 6.8 / 
train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.1 / train/extr_return_normed_mean 0.62 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 197.74 / train/extr_return_raw_max 
197.74 / train/extr_return_raw_mean 187.66 / train/extr_return_raw_min 165.47 / train/extr_return_raw_std 6.83 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.27 / train/extr_reward_min 0 / train/extr_reward_std 0.51 / 
train/image_loss_mean 1.18 / train/image_loss_std 1.02 / train/model_loss_mean 3.64 / train/model_loss_std 4.88 / train/model_opt_grad_norm 8.77 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.76 / train/policy_entropy_max 3.1 / train/policy_entropy_mean -2.57 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.24 / train/policy_logprob_max 5.48 / 
train/policy_logprob_mean 2.57 / train/policy_logprob_min -9.24 / train/policy_logprob_std 1.77 / train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.7e-4 / train/policy_randomness_std 
0.12 / train/post_ent_mag 52.99 / train/post_ent_max 52.99 / train/post_ent_mean 39.32 / train/post_ent_min 20.82 / train/post_ent_std 5.28 / train/prior_ent_mag 85.36 / train/prior_ent_max 85.36 / train/prior_ent_mean 43.16 / train/prior_ent_min 25.66 / 
train/prior_ent_std 7.36 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.86 / train/reward_avg 0.25 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.81 / train/reward_max_pred 1.8 / train/reward_neg_acc 1 / train/reward_neg_loss 
3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.25 / train/reward_rate 0.23 / train_stats/mean_log_entropy -2.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.3e-11 / report/cont_loss_std 2.1e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.34 / report/dyn_loss_std 6.02 / report/image_loss_mean 0.89 / report/image_loss_std 0.66 / 
report/model_loss_mean 3.01 / report/model_loss_std 4.13 / report/post_ent_mag 55.44 / report/post_ent_max 55.44 / report/post_ent_mean 37.91 / report/post_ent_min 19.32 / report/post_ent_std 7.2 / report/prior_ent_mag 85.21 / report/prior_ent_max 85.21 / 
report/prior_ent_mean 41.09 / report/prior_ent_min 19.36 / report/prior_ent_std 9.46 / report/rep_loss_mean 3.34 / report/rep_loss_std 6.02 / report/reward_avg 0.27 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.26 / report/reward_max_data 1.83 / 
report/reward_max_pred 1.83 / report/reward_neg_acc 1 / report/reward_neg_loss 4.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.28 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.9e-10
/ eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.85 / eval/dyn_loss_std 7.15 / eval/image_loss_mean 1.36 / eval/image_loss_std 1.77 / eval/model_loss_mean 
4.53 / eval/model_loss_std 5.74 / eval/post_ent_mag 49.71 / eval/post_ent_max 49.71 / eval/post_ent_mean 41.21 / eval/post_ent_min 17.4 / eval/post_ent_std 4.75 / eval/prior_ent_mag 85.21 / eval/prior_ent_max 85.21 / eval/prior_ent_mean 45.77 / eval/prior_ent_min 25.25 
/ eval/prior_ent_std 5.92 / eval/rep_loss_mean 4.85 / eval/rep_loss_std 7.15 / eval/reward_avg 0.43 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.5 / eval/reward_max_data 1.73 / eval/reward_max_pred 1.8 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / 
eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.43 / eval/reward_rate 0.38 / replay/size 2.2e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / 
timer/env.step_count 3812 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.25 / timer/replay._sample_frac 1.49 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.54 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.87 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 221000 Counter(221000) 220937
eval_Episode has 500 steps and return 289.0.
Saved chunk: 20230922T021837F067944-1TtMe01nG9uOrjWqCF0l4U-0RZJlQkqwgN2YZ6VXYV67d-1024.npz
train_Episode has 500 steps and return 255.6.
Starting evaluation at step 221500 Counter(221500) 221437
Saved chunk: 20230922T021902F510991-43LlsHwyAqJRuokoQiYqoo-0RisrFQxXW3BoC7jK0p4VX-1024.npz
eval_Episode has 500 steps and return 275.0.
train_Episode has 500 steps and return 241.7.
Starting evaluation at step 222000 Counter(222000) 221937
eval_Episode has 500 steps and return 300.6.
Saved chunk: 20230922T021958F669331-0RZJlQkqwgN2YZ6VXYV67d-0ujzFPJjNHRqxe0JTpowR0-1024.npz
train_Episode has 500 steps and return 270.5.
Starting evaluation at step 222500 Counter(222500) 222437
Saved chunk: 20230922T022022F718386-0RisrFQxXW3BoC7jK0p4VX-6FJXnbxf8BdndWzJoGTZxM-1024.npz
eval_Episode has 500 steps and return 284.3.
train_Episode has 500 steps and return 237.8.
Starting evaluation at step 223000 Counter(223000) 222937
eval_Episode has 500 steps and return 291.4.
Saved chunk: 20230922T022119F744071-0ujzFPJjNHRqxe0JTpowR0-5zQr0DKnmHdV0Ofrk59A3P-1024.npz
train_Episode has 500 steps and return 260.4.
Starting evaluation at step 223500 Counter(223500) 223437
Saved chunk: 20230922T022142F152179-6FJXnbxf8BdndWzJoGTZxM-6UnwXsXFjzSKI6geGw9OG0-1024.npz
eval_Episode has 500 steps and return 283.6.
train_Episode has 500 steps and return 264.1.
Starting evaluation at step 224000 Counter(224000) 223937
eval_Episode has 500 steps and return 293.8.
Saved chunk: 20230922T022240F656897-5zQr0DKnmHdV0Ofrk59A3P-4MsHHuOOSHJXYHdCSEqfil-1024.npz
train_Episode has 500 steps and return 256.0.
Starting evaluation at step 224500 Counter(224500) 224437
Saved chunk: 20230922T022301F404771-6UnwXsXFjzSKI6geGw9OG0-1sbSPBHorHnryL7nnttYYA-1024.npz
eval_Episode has 500 steps and return 260.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 449482 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 260.74 / eval_episode/reward_rate 0.39 / episode/length 500 / episode/score 256.05 / episode/reward_rate 0.38 / train/action_mag 3.96 / train/action_max 3.96 / train/action_mean 0.08 / train/action_min -3 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -14.81 / train/adv_mag 0.88 / train/adv_max 0.77 / train/adv_mean 2.3e-3 / 
train/adv_min -0.48 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.86 / train/dyn_loss_std 6.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 199.29 / train/extr_critic_max 199.29 / train/extr_critic_mean 189.4 / train/extr_critic_min 154.9 / train/extr_critic_std 7.29 / train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.65 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 199.67 / train/extr_return_raw_max 199.67 / train/extr_return_raw_mean 189.46 / train/extr_return_raw_min 
163.25 / train/extr_return_raw_std 7.32 / train/extr_reward_mag 1.87 / train/extr_reward_max 1.87 / train/extr_reward_mean 0.27 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.18 / train/image_loss_std 1.01 / train/model_loss_mean 3.64 /
train/model_loss_std 4.87 / train/model_opt_grad_norm 8.98 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.84 / train/policy_entropy_max 
3.32 / train/policy_entropy_mean -2.53 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.33 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.53 / train/policy_logprob_min -9.33 / train/policy_logprob_std 1.8 / 
train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.4e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.99 / train/post_ent_max 52.99 / train/post_ent_mean 39.56 / 
train/post_ent_min 20.91 / train/post_ent_std 5.14 / train/prior_ent_mag 85.29 / train/prior_ent_max 85.29 / train/prior_ent_mean 43.43 / train/prior_ent_min 26.34 / train/prior_ent_std 7.19 / train/rep_loss_mean 3.86 / train/rep_loss_std 6.83 / train/reward_avg 0.26 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.83 / train/reward_max_pred 1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.26 / train/reward_rate 
0.23 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.69 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.97 / report/dyn_loss_std 6.72 / report/image_loss_mean 1.12 / report/image_loss_std 0.78 / report/model_loss_mean 3.68 / report/model_loss_std 4.61 / report/post_ent_mag 52.35 / report/post_ent_max 52.35 /
report/post_ent_mean 40.69 / report/post_ent_min 19.31 / report/post_ent_std 4.93 / report/prior_ent_mag 85.28 / report/prior_ent_max 85.28 / report/prior_ent_mean 44.59 / report/prior_ent_min 25.05 / report/prior_ent_std 6.76 / report/rep_loss_mean 3.97 / 
report/rep_loss_std 6.72 / report/reward_avg 0.34 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.29 / report/reward_max_data 1.77 / report/reward_max_pred 1.74 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.33 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.68 / eval/dyn_loss_std 7.41 / eval/image_loss_mean 1.46 / eval/image_loss_std 2.33 / eval/model_loss_mean 4.51 / eval/model_loss_std 6.04 / eval/post_ent_mag 49.8 / eval/post_ent_max 49.8 / eval/post_ent_mean 41.54 / 
eval/post_ent_min 21.28 / eval/post_ent_std 4.71 / eval/prior_ent_mag 85.28 / eval/prior_ent_max 85.28 / eval/prior_ent_mean 45.56 / eval/prior_ent_min 26 / eval/prior_ent_std 6.09 / eval/rep_loss_mean 4.68 / eval/rep_loss_std 7.41 / eval/reward_avg 0.48 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.82 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.47 / eval/reward_rate 0.41 / 
replay/size 2.2e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3762 / timer/env.step_total 19.59 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 445.97 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.54 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 243.5.
Starting evaluation at step 225000 Counter(225000) 224937
eval_Episode has 500 steps and return 288.7.
Saved chunk: 20230922T022401F206452-4MsHHuOOSHJXYHdCSEqfil-3LRQARql75DlOuSihp2GRg-1024.npz
train_Episode has 500 steps and return 265.8.
Starting evaluation at step 225500 Counter(225500) 225437
Saved chunk: 20230922T022420F320339-1sbSPBHorHnryL7nnttYYA-7lLqqslvaG5HSCWOG7InF8-1024.npz
eval_Episode has 500 steps and return 265.7.
train_Episode has 500 steps and return 254.1.
Starting evaluation at step 226000 Counter(226000) 225937
eval_Episode has 500 steps and return 266.1.
Saved chunk: 20230922T022522F919714-3LRQARql75DlOuSihp2GRg-5UqOfzIyOXmwxk7QFDiX5x-1024.npz
train_Episode has 500 steps and return 247.1.
Starting evaluation at step 226500 Counter(226500) 226437
Saved chunk: 20230922T022540F645507-7lLqqslvaG5HSCWOG7InF8-3tPo11lPXIbYrp2GC5zn76-1024.npz
eval_Episode has 500 steps and return 296.8.
train_Episode has 500 steps and return 263.6.
Starting evaluation at step 227000 Counter(227000) 226937
eval_Episode has 500 steps and return 288.5.
Saved chunk: 20230922T022643F885336-5UqOfzIyOXmwxk7QFDiX5x-5D6NuiFPBgFRQsbayDkaBX-1024.npz
train_Episode has 500 steps and return 250.3.
Starting evaluation at step 227500 Counter(227500) 227437
Saved chunk: 20230922T022659F898700-3tPo11lPXIbYrp2GC5zn76-1koMkcz2wXyrfwI2guOSdN-1024.npz
eval_Episode has 500 steps and return 255.6.
train_Episode has 500 steps and return 247.3.
Starting evaluation at step 228000 Counter(228000) 227937
eval_Episode has 500 steps and return 274.9.
Saved chunk: 20230922T022804F542074-5D6NuiFPBgFRQsbayDkaBX-4WNIHVvBogZ4WTqCbHHVPq-1024.npz
train_Episode has 500 steps and return 274.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 228500 Counter(228500) 228437
Saved chunk: 20230922T022924F989416-4WNIHVvBogZ4WTqCbHHVPq-0000000000000000000000-148.npz
Saved chunk: 20230922T022818F964242-1koMkcz2wXyrfwI2guOSdN-0000000000000000000000-703.npz
Saved chunk: 20230922T022818F964242-1koMkcz2wXyrfwI2guOSdN-33OmXuWq5PJePiyCZgY0pU-1024.npz
eval_Episode has 500 steps and return 299.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 457006 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 274.71 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 299.42 / eval_episode/reward_rate 0.44 / train/action_mag 4.05 / train/action_max 4.05 / train/action_mean 0.06 / train/action_min -2.89 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -15.17 / train/adv_mag 0.74 / train/adv_max 0.64 / train/adv_mean 
2.3e-3 / train/adv_min -0.44 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.88 / train/dyn_loss_std 6.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 200.59 / train/extr_critic_max 200.59 / train/extr_critic_mean 190.77 / train/extr_critic_min 161.08 / train/extr_critic_std 6.96 / train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.1 / 
train/extr_return_normed_mean 0.63 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 200.95 / train/extr_return_raw_max 200.95 / train/extr_return_raw_mean 190.82 / train/extr_return_raw_min 
167.24 / train/extr_return_raw_std 6.98 / train/extr_reward_mag 1.88 / train/extr_reward_max 1.88 / train/extr_reward_mean 0.27 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.19 / train/image_loss_std 1.04 / train/model_loss_mean 3.66 /
train/model_loss_std 4.92 / train/model_opt_grad_norm 8.97 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.68 / train/policy_entropy_max 
3.12 / train/policy_entropy_mean -2.54 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.07 / train/policy_logprob_mag 9.3 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.54 / train/policy_logprob_min -9.3 / train/policy_logprob_std 1.77 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.95 / train/post_ent_max 52.95 / train/post_ent_mean 39.65 / 
train/post_ent_min 20.73 / train/post_ent_std 5.19 / train/prior_ent_mag 85.3 / train/prior_ent_max 85.3 / train/prior_ent_mean 43.51 / train/prior_ent_min 26.21 / train/prior_ent_std 7.22 / train/rep_loss_mean 3.88 / train/rep_loss_std 6.9 / train/reward_avg 0.26 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.28 / train/reward_max_data 1.83 / train/reward_max_pred 1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.26 / train/reward_rate 
0.23 / train_stats/mean_log_entropy -2.6 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.63 / report/dyn_loss_std 6.96 / report/image_loss_mean 1.07 / report/image_loss_std 0.82 / report/model_loss_mean 3.37 / report/model_loss_std 4.79 / report/post_ent_mag 51.82 / report/post_ent_max 51.82 /
report/post_ent_mean 39.81 / report/post_ent_min 18.43 / report/post_ent_std 5.27 / report/prior_ent_mag 85.32 / report/prior_ent_max 85.32 / report/prior_ent_mean 43.41 / report/prior_ent_min 24.92 / report/prior_ent_std 7.33 / report/rep_loss_mean 3.63 / 
report/rep_loss_std 6.96 / report/reward_avg 0.22 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.26 / report/reward_max_data 1.75 / report/reward_max_pred 1.77 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.22 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-11 / eval/cont_loss_std 3.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.9 / eval/dyn_loss_std 6.44 / eval/image_loss_mean 1.08 / eval/image_loss_std 1.12 / eval/model_loss_mean 3.69 / eval/model_loss_std 4.68 / eval/post_ent_mag 49.23 / eval/post_ent_max 49.23 / eval/post_ent_mean 
42.12 / eval/post_ent_min 20.41 / eval/post_ent_std 3.88 / eval/prior_ent_mag 85.32 / eval/prior_ent_max 85.32 / eval/prior_ent_mean 45.89 / eval/prior_ent_min 28.96 / eval/prior_ent_std 5.62 / eval/rep_loss_mean 3.9 / eval/rep_loss_std 6.44 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.8 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.54 / eval/reward_rate 0.46 / 
replay/size 2.3e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3762 / timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.05 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.73 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 6e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.16 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.07

Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 260.6.
Starting evaluation at step 229000 Counter(229000) 228937
eval_Episode has 500 steps and return 301.8.
Saved chunk: 20230922T022924F989416-4WNIHVvBogZ4WTqCbHHVPq-1TlGmyIniCuXbRGADWOZyb-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 229500 Counter(229500) 229437
Saved chunk: 20230922T022937F977040-33OmXuWq5PJePiyCZgY0pU-60GoUhQy5P4Iz0W4bo4hzq-1024.npz
eval_Episode has 500 steps and return 291.2.
train_Episode has 500 steps and return 254.3.
Starting evaluation at step 230000 Counter(230000) 229937
eval_Episode has 500 steps and return 276.9.
Saved chunk: 20230922T023047F094664-1TlGmyIniCuXbRGADWOZyb-6BCor7GxsTAOHnRL4m1krp-1024.npz
train_Episode has 500 steps and return 274.8.
Starting evaluation at step 230500 Counter(230500) 230437
Saved chunk: 20230922T023058F425087-60GoUhQy5P4Iz0W4bo4hzq-2XwL7c7xto4QFaz8o3JilW-1024.npz
eval_Episode has 500 steps and return 292.9.
train_Episode has 500 steps and return 251.4.
Starting evaluation at step 231000 Counter(231000) 230937
eval_Episode has 500 steps and return 276.3.
Saved chunk: 20230922T023207F739665-6BCor7GxsTAOHnRL4m1krp-5BjNfWQZVaG8lvBXXmGSgG-1024.npz
train_Episode has 500 steps and return 260.2.
Starting evaluation at step 231500 Counter(231500) 231437
Saved chunk: 20230922T023217F495884-2XwL7c7xto4QFaz8o3JilW-0fRJNy8Pj2ziRG0BpXSPc2-1024.npz
eval_Episode has 500 steps and return 297.4.
train_Episode has 500 steps and return 237.4.
Starting evaluation at step 232000 Counter(232000) 231937
eval_Episode has 500 steps and return 288.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 464646 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 237.4 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 288.5 / eval_episode/reward_rate 0.44 / train/action_mag 3.98 / train/action_max 3.97 / train/action_mean 0.07 / train/action_min -3.07 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -11.09 / train/adv_mag 0.61 / train/adv_max 0.52 / train/adv_mean 1.9e-3 / 
train/adv_min -0.43 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.82 / train/dyn_loss_std 6.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 201.76 / train/extr_critic_max 201.76 / train/extr_critic_mean 191.94 / train/extr_critic_min 163.78 / train/extr_critic_std 7.03 / train/extr_return_normed_mag 1.09 / train/extr_return_normed_max 1.09 / 
train/extr_return_normed_mean 0.64 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 202.12 / train/extr_return_raw_max 202.12 / train/extr_return_raw_mean 191.98 / train/extr_return_raw_min 
168.08 / train/extr_return_raw_std 7.07 / train/extr_reward_mag 1.88 / train/extr_reward_max 1.88 / train/extr_reward_mean 0.27 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.15 / train/image_loss_std 0.99 / train/model_loss_mean 3.58 /
train/model_loss_std 4.84 / train/model_opt_grad_norm 8.89 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.8 / train/policy_entropy_max 
3.37 / train/policy_entropy_mean -2.52 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.12 / train/policy_logprob_mag 9.38 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.52 / train/policy_logprob_min -9.38 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.74 / train/post_ent_max 52.74 / train/post_ent_mean 39.77 / 
train/post_ent_min 21.25 / train/post_ent_std 5.16 / train/prior_ent_mag 85.35 / train/prior_ent_max 85.35 / train/prior_ent_mean 43.57 / train/prior_ent_min 26.5 / train/prior_ent_std 7.21 / train/rep_loss_mean 3.82 / train/rep_loss_std 6.82 / train/reward_avg 0.26 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.83 / train/reward_max_pred 1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.59 / train/reward_pred 0.26 / train/reward_rate 
0.24 / train_stats/mean_log_entropy -2.5 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-10 / report/cont_loss_std 5.9e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.68 / report/dyn_loss_std 6.19 / report/image_loss_mean 1.06 / report/image_loss_std 0.99 / report/model_loss_mean 3.43 / report/model_loss_std 4.48 / report/post_ent_mag 49.53 / report/post_ent_max 49.53 /
report/post_ent_mean 40.99 / report/post_ent_min 23.59 / report/post_ent_std 4.2 / report/prior_ent_mag 85.28 / report/prior_ent_max 85.28 / report/prior_ent_mean 44.63 / report/prior_ent_min 30.33 / report/prior_ent_std 6.34 / report/rep_loss_mean 3.68 / 
report/rep_loss_std 6.19 / report/reward_avg 0.31 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.33 / report/reward_max_data 1.86 / report/reward_max_pred 1.8 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.31 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.29 / eval/dyn_loss_std 6.79 / eval/image_loss_mean 1.25 / eval/image_loss_std 1.56 / eval/model_loss_mean 4.05 / eval/model_loss_std 5.15 / eval/post_ent_mag 49.43 / eval/post_ent_max 49.43 / eval/post_ent_mean 
41.79 / eval/post_ent_min 23.31 / eval/post_ent_std 4.27 / eval/prior_ent_mag 85.28 / eval/prior_ent_max 85.28 / eval/prior_ent_mean 45.96 / eval/prior_ent_min 33.01 / eval/prior_ent_std 6.01 / eval/rep_loss_mean 4.29 / eval/rep_loss_std 6.79 / eval/reward_avg 0.46 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.84 / eval/reward_max_pred 1.76 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.45 / eval/reward_rate 0.39 / 
replay/size 2.3e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3820 / timer/env.step_total 19.92 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 452.56 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 16.65 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1910 / timer/agent.train_total 244.58 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.7e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.46

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T023328F223887-5BjNfWQZVaG8lvBXXmGSgG-6fIQS8kIPtETQkrmh43F6i-1024.npz
train_Episode has 500 steps and return 245.6.
Starting evaluation at step 232500 Counter(232500) 232437
Saved chunk: 20230922T023336F363316-0fRJNy8Pj2ziRG0BpXSPc2-4aVVZKmWUXfIA8lBNmTHAC-1024.npz
eval_Episode has 500 steps and return 263.7.
train_Episode has 500 steps and return 247.4.
Starting evaluation at step 233000 Counter(233000) 232937
eval_Episode has 500 steps and return 276.7.
train_Episode has 500 steps and return 241.4.
Saved chunk: 20230922T023449F627092-6fIQS8kIPtETQkrmh43F6i-4hZsBOs09mE98y8YtLcDdc-1024.npz
Starting evaluation at step 233500 Counter(233500) 233437
eval_Episode has 500 steps and return 262.2.
Saved chunk: 20230922T023456F278044-4aVVZKmWUXfIA8lBNmTHAC-7432wAxHAcSOtmvi1ZQBXF-1024.npz
train_Episode has 500 steps and return 276.8.
Starting evaluation at step 234000 Counter(234000) 233937
eval_Episode has 500 steps and return 291.7.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023610F663779-4hZsBOs09mE98y8YtLcDdc-6BbfZtlc20fExIWWPUiCmM-1024.npz
Starting evaluation at step 234500 Counter(234500) 234437
eval_Episode has 500 steps and return 239.4.
Saved chunk: 20230922T023615F685891-7432wAxHAcSOtmvi1ZQBXF-6gMnhB0fhT7eoXsf4ZWXRa-1024.npz
train_Episode has 500 steps and return 258.5.
Starting evaluation at step 235000 Counter(235000) 234937
eval_Episode has 500 steps and return 277.7.
train_Episode has 500 steps and return 260.0.
Starting evaluation at step 235500 Counter(235500) 235437
eval_Episode has 500 steps and return 283.2.
Saved chunk: 20230922T023734F919190-6gMnhB0fhT7eoXsf4ZWXRa-1hYS8FJvzbja5QDkWvWPPX-1024.npz
Saved chunk: 20230922T023731F462061-6BbfZtlc20fExIWWPUiCmM-3laocoRUF05Q6wvOpPytvp-1024.npz
train_Episode has 500 steps and return 223.1.
Starting evaluation at step 236000 Counter(236000) 235937
eval_Episode has 500 steps and return 266.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 472178 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 223.1 / episode/reward_rate 0.33 / eval_episode/length 500 / eval_episode/score 266.18 / eval_episode/reward_rate 0.41 / train/action_mag 3.92 / train/action_max 3.91 / train/action_mean 0.07 / train/action_min -3.09 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.28 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -9.55 / train/adv_mag 0.62 / train/adv_max 0.53 / train/adv_mean 1.7e-3 / train/adv_min
-0.47 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.84 / train/dyn_loss_std 6.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 202.72 / train/extr_critic_max 202.72 / train/extr_critic_mean 192.64 / train/extr_critic_min 161.32 / train/extr_critic_std 7.57 / train/extr_return_normed_mag 1.1 / train/extr_return_normed_max 1.08 / 
train/extr_return_normed_mean 0.66 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 203.1 / train/extr_return_raw_max 203.1 / train/extr_return_raw_mean 192.68 / train/extr_return_raw_min 
165.22 / train/extr_return_raw_std 7.63 / train/extr_reward_mag 1.89 / train/extr_reward_max 1.89 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.17 / train/image_loss_std 1.04 / train/model_loss_mean 3.61 /
train/model_loss_std 4.9 / train/model_opt_grad_norm 8.93 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.84 / train/policy_entropy_max 
3.38 / train/policy_entropy_mean -2.49 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.15 / train/policy_logprob_mag 9.41 / train/policy_logprob_max 5.49 / train/policy_logprob_mean 2.49 / train/policy_logprob_min -9.41 / train/policy_logprob_std 1.83 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 53.11 / train/post_ent_max 53.11 / train/post_ent_mean 39.79 / 
train/post_ent_min 20.93 / train/post_ent_std 5.31 / train/prior_ent_mag 85.33 / train/prior_ent_max 85.33 / train/prior_ent_mean 43.61 / train/prior_ent_min 25.97 / train/prior_ent_std 7.32 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.87 / train/reward_avg 0.27 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.28 / train/reward_max_data 1.82 / train/reward_max_pred 1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.26 / train/reward_rate 
0.24 / train_stats/mean_log_entropy -2.64 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-10 / report/cont_loss_std 6.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 7.03 / report/image_loss_mean 1.22 / report/image_loss_std 0.95 / report/model_loss_mean 3.65 / report/model_loss_std 4.98 / report/post_ent_mag 51.65 / report/post_ent_max 51.65 /
report/post_ent_mean 40.59 / report/post_ent_min 23.37 / report/post_ent_std 4.63 / report/prior_ent_mag 85.09 / report/prior_ent_max 85.09 / report/prior_ent_mean 44.38 / report/prior_ent_min 27.42 / report/prior_ent_std 6.51 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 7.03 / report/reward_avg 0.2 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.29 / report/reward_max_data 1.65 / report/reward_max_pred 1.7 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.62 / report/reward_pred 0.2 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.61 / eval/dyn_loss_std 7 / eval/image_loss_mean 1.18 / eval/image_loss_std 1.34 / eval/model_loss_mean 4.21 / eval/model_loss_std 5.21 / eval/post_ent_mag 48.94 / eval/post_ent_max 48.94 / eval/post_ent_mean 
41.69 / eval/post_ent_min 24 / eval/post_ent_std 3.9 / eval/prior_ent_mag 85.09 / eval/prior_ent_max 85.09 / eval/prior_ent_mean 46.02 / eval/prior_ent_min 34.56 / eval/prior_ent_std 5.61 / eval/rep_loss_mean 4.61 / eval/rep_loss_std 7 / eval/reward_avg 0.49 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.49 / eval/reward_rate 0.42 / 
replay/size 2.4e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3766 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.93 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.56 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 
/ timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.42 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 236.3.
Starting evaluation at step 236500 Counter(236500) 236437
eval_Episode has 500 steps and return 284.7.
Saved chunk: 20230922T023853F900900-1hYS8FJvzbja5QDkWvWPPX-33ITCdYFtca8aG8l61klHV-1024.npz
Saved chunk: 20230922T023855F560684-3laocoRUF05Q6wvOpPytvp-56krjdfBBa5HN5HcECFdq3-1024.npz
train_Episode has 500 steps and return 271.5.
Starting evaluation at step 237000 Counter(237000) 236937
eval_Episode has 500 steps and return 287.8.
train_Episode has 500 steps and return 245.1.
Starting evaluation at step 237500 Counter(237500) 237437
eval_Episode has 500 steps and return 275.8.
Saved chunk: 20230922T024017F193114-56krjdfBBa5HN5HcECFdq3-5zTRMMR126u1tqX90YZOA1-1024.npz
train_Episode has 500 steps and return 280.0.
Starting evaluation at step 238000 Counter(238000) 237937
Saved chunk: 20230922T024013F955804-33ITCdYFtca8aG8l61klHV-4UrgWYmkO1ghTYOayiotJ7-1024.npz
eval_Episode has 500 steps and return 296.7.
train_Episode has 500 steps and return 234.1.
Starting evaluation at step 238500 Counter(238500) 238437
eval_Episode has 500 steps and return 294.9.
Saved chunk: 20230922T024138F107540-5zTRMMR126u1tqX90YZOA1-0FXgvPHWZXMtv5EI2oiGJq-1024.npz
train_Episode has 500 steps and return 232.3.
Starting evaluation at step 239000 Counter(239000) 238937
Saved chunk: 20230922T024209F319124-4UrgWYmkO1ghTYOayiotJ7-4C8SglvBbGKTY1OnAtISFB-1024.npz
eval_Episode has 500 steps and return 277.2.
train_Episode has 500 steps and return 231.5.
Starting evaluation at step 239500 Counter(239500) 239437
eval_Episode has 500 steps and return 281.4.
Saved chunk: 20230922T024258F783271-0FXgvPHWZXMtv5EI2oiGJq-0SWLtcI0uz6MViKr9KLthM-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 479802 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 231.48 / episode/reward_rate 0.34 / eval_episode/length 500 / eval_episode/score 281.36 / eval_episode/reward_rate 0.41 / train/action_mag 4.01 / train/action_max 3.99 / train/action_mean 0.06 / train/action_min -3.18 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.01 / train/adv_mag 0.53 / train/adv_max 0.46 / train/adv_mean 
1.1e-3 / train/adv_min -0.41 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.82 / train/dyn_loss_std 6.81 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / 
train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 203.61 / train/extr_critic_max 203.61 / train/extr_critic_mean 192.86 / train/extr_critic_min 154.58 / train/extr_critic_std 9.37 / 
train/extr_return_normed_mag 1.2 / train/extr_return_normed_max 1.06 / train/extr_return_normed_mean 0.72 / train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 203.95 / train/extr_return_raw_max 
203.95 / train/extr_return_raw_mean 192.9 / train/extr_return_raw_min 158.66 / train/extr_return_raw_std 9.45 / train/extr_reward_mag 1.89 / train/extr_reward_max 1.89 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / 
train/image_loss_mean 1.14 / train/image_loss_std 0.99 / train/model_loss_mean 3.57 / train/model_loss_std 4.83 / train/model_opt_grad_norm 9.03 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 8874.35 / train/policy_entropy_mag 3.61 / train/policy_entropy_max 2.88 / train/policy_entropy_mean -2.38 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.47 / train/policy_logprob_max 
5.48 / train/policy_logprob_mean 2.38 / train/policy_logprob_min -9.47 / train/policy_logprob_std 1.85 / train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2.4e-4 / 
train/policy_randomness_std 0.13 / train/post_ent_mag 52.96 / train/post_ent_max 52.96 / train/post_ent_mean 39.94 / train/post_ent_min 20.9 / train/post_ent_std 5.28 / train/prior_ent_mag 85.32 / train/prior_ent_max 85.32 / train/prior_ent_mean 43.75 / 
train/prior_ent_min 26.13 / train/prior_ent_std 7.27 / train/rep_loss_mean 3.82 / train/rep_loss_std 6.81 / train/reward_avg 0.27 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.84 / train/reward_max_pred 1.82 / train/reward_neg_acc 
1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.27 / train/reward_rate 0.24 / train_stats/mean_log_entropy -2.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / 
report/cont_loss_std 3.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.31 / report/dyn_loss_std 6.05 / report/image_loss_mean 0.95 / 
report/image_loss_std 0.81 / report/model_loss_mean 3.07 / report/model_loss_std 4.23 / report/post_ent_mag 54.98 / report/post_ent_max 54.98 / report/post_ent_mean 38.8 / report/post_ent_min 20.59 / report/post_ent_std 5.53 / report/prior_ent_mag 85.41 / 
report/prior_ent_max 85.41 / report/prior_ent_mean 42.23 / report/prior_ent_min 25.08 / report/prior_ent_std 7.58 / report/rep_loss_mean 3.31 / report/rep_loss_std 6.05 / report/reward_avg 0.23 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.27 / 
report/reward_max_data 1.83 / report/reward_max_pred 1.79 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.59 / report/reward_pred 0.23 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 
4.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.29 / eval/dyn_loss_std 6.64 / eval/image_loss_mean 1.09 / 
eval/image_loss_std 0.96 / eval/model_loss_mean 3.9 / eval/model_loss_std 4.68 / eval/post_ent_mag 50.42 / eval/post_ent_max 50.42 / eval/post_ent_mean 40.99 / eval/post_ent_min 23.07 / eval/post_ent_std 4.96 / eval/prior_ent_mag 85.41 / eval/prior_ent_max 85.41 / 
eval/prior_ent_mean 45.27 / eval/prior_ent_min 26.44 / eval/prior_ent_std 6.64 / eval/rep_loss_mean 4.29 / eval/rep_loss_std 6.64 / eval/reward_avg 0.48 / eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.92 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 8.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.47 / eval/reward_rate 0.38 / replay/size 2.4e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3812 / timer/env.step_total 19.9 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 454.27 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / 
timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.61 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 
0.11 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.71 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.41

Saved chunk: 20230922T024419F382684-0SWLtcI0uz6MViKr9KLthM-0000000000000000000000-284.npz
Saved chunk: 20230922T024328F370266-4C8SglvBbGKTY1OnAtISFB-0000000000000000000000-962.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 215.4.
Starting evaluation at step 240000 Counter(240000) 239937
Saved chunk: 20230922T024328F370266-4C8SglvBbGKTY1OnAtISFB-38xspKfKxeB2d8SYNkCuvg-1024.npz
eval_Episode has 500 steps and return 288.2.
train_Episode has 500 steps and return 243.3.
Starting evaluation at step 240500 Counter(240500) 240437
eval_Episode has 500 steps and return 279.7.
Saved chunk: 20230922T024419F382684-0SWLtcI0uz6MViKr9KLthM-1RJxkzwSKUM1Q18BqXWknu-1024.npz
train_Episode has 500 steps and return 268.6.
Starting evaluation at step 241000 Counter(241000) 240937
Saved chunk: 20230922T024448F567987-38xspKfKxeB2d8SYNkCuvg-4N4XMWg8y1jdCew8tlsIAX-1024.npz
eval_Episode has 500 steps and return 284.4.
train_Episode has 500 steps and return 246.0.
Starting evaluation at step 241500 Counter(241500) 241437
eval_Episode has 500 steps and return 273.9.
Saved chunk: 20230922T024541F462381-1RJxkzwSKUM1Q18BqXWknu-7sP5aZZPn6JfiFEXEuHqyy-1024.npz
train_Episode has 500 steps and return 259.2.
Starting evaluation at step 242000 Counter(242000) 241937
Saved chunk: 20230922T024608F041206-4N4XMWg8y1jdCew8tlsIAX-6wtjXuye1blhUWuB4DuClW-1024.npz
eval_Episode has 500 steps and return 282.6.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 242500 Counter(242500) 242437
eval_Episode has 500 steps and return 251.3.
Saved chunk: 20230922T024702F352897-7sP5aZZPn6JfiFEXEuHqyy-55Ic2FzWRIlFjbz8ZDsEvU-1024.npz
train_Episode has 500 steps and return 264.2.
Starting evaluation at step 243000 Counter(243000) 242937
Saved chunk: 20230922T024727F269866-6wtjXuye1blhUWuB4DuClW-03VYPYQzWRHn4lAbdR8oOJ-1024.npz
eval_Episode has 500 steps and return 281.3.
train_Episode has 500 steps and return 272.3.
Starting evaluation at step 243500 Counter(243500) 243437
eval_Episode has 500 steps and return 284.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 487322 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 272.33 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 284.33 / eval_episode/reward_rate 0.45 / train/action_mag 3.99 / train/action_max 3.98 / train/action_mean 0.06 / train/action_min -3.15 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -13.06 / train/adv_mag 0.53 / train/adv_max 0.48 / train/adv_mean 2e-3 
/ train/adv_min -0.37 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.84 / train/dyn_loss_std 6.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 204.17 / train/extr_critic_max 204.17 / train/extr_critic_mean 193.15 / train/extr_critic_min 149.54 / train/extr_critic_std 10.75 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.73 / train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 204.58 / train/extr_return_raw_max 204.58 / train/extr_return_raw_mean 193.22 / train/extr_return_raw_min 
153.59 / train/extr_return_raw_std 10.66 / train/extr_reward_mag 1.89 / train/extr_reward_max 1.89 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 1.15 / train/image_loss_std 1.01 / train/model_loss_mean 3.6 /
train/model_loss_std 4.86 / train/model_opt_grad_norm 8.49 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8484.04 / train/policy_entropy_mag 3.64 / 
train/policy_entropy_max 2.95 / train/policy_entropy_mean -2.35 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.16 / train/policy_logprob_mag 9.53 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.35 / train/policy_logprob_min -9.53 / 
train/policy_logprob_std 1.83 / train/policy_randomness_mag 0.7 / train/policy_randomness_max 0.7 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.72 / train/post_ent_max 52.72 / 
train/post_ent_mean 39.99 / train/post_ent_min 20.86 / train/post_ent_std 5.3 / train/prior_ent_mag 85.28 / train/prior_ent_max 85.28 / train/prior_ent_mean 43.81 / train/prior_ent_min 25.81 / train/prior_ent_std 7.3 / train/rep_loss_mean 3.84 / train/rep_loss_std 6.84 
/ train/reward_avg 0.27 / train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.83 / train/reward_max_pred 1.81 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred
0.27 / train/reward_rate 0.24 / train_stats/mean_log_entropy -1.84 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 5.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.75 / report/dyn_loss_std 6.92 / report/image_loss_mean 1.07 / report/image_loss_std 0.93 / report/model_loss_mean 3.48 / report/model_loss_std 4.88 / report/post_ent_mag 
50.34 / report/post_ent_max 50.34 / report/post_ent_mean 41.11 / report/post_ent_min 20.9 / report/post_ent_std 4.81 / report/prior_ent_mag 85.13 / report/prior_ent_max 85.13 / report/prior_ent_mean 44.81 / report/prior_ent_min 26.25 / report/prior_ent_std 6.71 / 
report/rep_loss_mean 3.75 / report/rep_loss_std 6.92 / report/reward_avg 0.33 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.84 / report/reward_max_pred 1.83 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.33 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.85 / eval/dyn_loss_std 7.67 / eval/image_loss_mean 1.42 / eval/image_loss_std 2.2 / eval/model_loss_mean 4.56 / eval/model_loss_std 6.33 / eval/post_ent_mag 49.43 / eval/post_ent_max 
49.43 / eval/post_ent_mean 41.55 / eval/post_ent_min 16.07 / eval/post_ent_std 4.88 / eval/prior_ent_mag 85.13 / eval/prior_ent_max 85.13 / eval/prior_ent_mean 45.93 / eval/prior_ent_min 28.57 / eval/prior_ent_std 5.97 / eval/rep_loss_mean 4.85 / eval/rep_loss_std 7.67 
/ eval/reward_avg 0.5 / eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.85 / eval/reward_max_pred 1.84 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.5 / 
eval/reward_rate 0.4 / replay/size 2.4e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3760 / timer/env.step_total 19.69 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.3 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.35 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1880 / 
timer/agent.train_total 241.67 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T024823F072439-55Ic2FzWRIlFjbz8ZDsEvU-0K6Q630QAfx6HFvte6lTdS-1024.npz
train_Episode has 500 steps and return 264.0.
Starting evaluation at step 244000 Counter(244000) 243937
Saved chunk: 20230922T024846F378041-03VYPYQzWRHn4lAbdR8oOJ-24dIvTD7uDUmj0zItMtvOa-1024.npz
eval_Episode has 500 steps and return 283.9.
train_Episode has 500 steps and return 275.8.
Starting evaluation at step 244500 Counter(244500) 244437
eval_Episode has 500 steps and return 241.0.
Saved chunk: 20230922T024944F511732-0K6Q630QAfx6HFvte6lTdS-5LvsiRiKN9s6WlaOpCx7tr-1024.npz
train_Episode has 500 steps and return 247.4.
Starting evaluation at step 245000 Counter(245000) 244937
Saved chunk: 20230922T025006F440330-24dIvTD7uDUmj0zItMtvOa-0ISljgoMFcPMJQUuO3i4V3-1024.npz
eval_Episode has 500 steps and return 276.0.
train_Episode has 500 steps and return 217.5.
Starting evaluation at step 245500 Counter(245500) 245437
eval_Episode has 500 steps and return 278.7.
Saved chunk: 20230922T025105F651026-5LvsiRiKN9s6WlaOpCx7tr-5YNOAUk8VgwKm8m69v3GE5-1024.npz
train_Episode has 500 steps and return 242.5.
Starting evaluation at step 246000 Counter(246000) 245937
Saved chunk: 20230922T025125F866129-0ISljgoMFcPMJQUuO3i4V3-6q6ntqUJ4t0x21T2TVh9Z5-1024.npz
eval_Episode has 500 steps and return 298.8.
train_Episode has 500 steps and return 245.9.
Starting evaluation at step 246500 Counter(246500) 246437
eval_Episode has 500 steps and return 270.1.
Saved chunk: 20230922T025226F529417-5YNOAUk8VgwKm8m69v3GE5-5RRx80eO95eroStQ6RmLhu-1024.npz
train_Episode has 500 steps and return 261.3.
Starting evaluation at step 247000 Counter(247000) 246937
Saved chunk: 20230922T025245F151133-6q6ntqUJ4t0x21T2TVh9Z5-6k4tJtMZ0SZpuUbnSvFLfc-1024.npz
eval_Episode has 500 steps and return 275.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 494946 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 261.26 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 275.91 / eval_episode/reward_rate 0.41 / train/action_mag 4.03 / train/action_max 4 / train/action_mean 0.06 / train/action_min -3.24 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -25.55 / train/adv_mag 1.02 / train/adv_max 0.97 / train/adv_mean 3.3e-3 / 
train/adv_min -0.58 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 204.12 / train/extr_critic_max 204.12 / train/extr_critic_mean 193.06 / train/extr_critic_min 131.66 / train/extr_critic_std 11.37 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.57 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 204.51 / train/extr_return_raw_max 204.51 / train/extr_return_raw_mean 193.19 / train/extr_return_raw_min 
143.02 / train/extr_return_raw_std 11.06 / train/extr_reward_mag 1.9 / train/extr_reward_max 1.9 / train/extr_reward_mean 0.29 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.13 / train/image_loss_std 1.01 / train/model_loss_mean 3.56 / 
train/model_loss_std 4.84 / train/model_opt_grad_norm 8.93 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.78 / train/policy_entropy_max 
3.37 / train/policy_entropy_mean -2.36 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.21 / train/policy_logprob_mag 9.6 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.36 / train/policy_logprob_min -9.6 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.53 / train/post_ent_max 52.53 / train/post_ent_mean 40.1 / 
train/post_ent_min 20.93 / train/post_ent_std 5.33 / train/prior_ent_mag 85.18 / train/prior_ent_max 85.18 / train/prior_ent_mean 43.89 / train/prior_ent_min 26.02 / train/prior_ent_std 7.29 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.8 / train/reward_avg 0.28 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.84 / train/reward_max_pred 1.83 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.28 / train/reward_rate 
0.24 / train_stats/mean_log_entropy -2.5 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.57 / report/dyn_loss_std 6.56 / report/image_loss_mean 1.02 / report/image_loss_std 0.89 / report/model_loss_mean 3.3 / report/model_loss_std 4.63 / report/post_ent_mag 54.28 / report/post_ent_max 54.28 / 
report/post_ent_mean 40.76 / report/post_ent_min 26.02 / report/post_ent_std 4.27 / report/prior_ent_mag 85.01 / report/prior_ent_max 85.01 / report/prior_ent_mean 44.34 / report/prior_ent_min 32.28 / report/prior_ent_std 6.41 / report/rep_loss_mean 3.57 / 
report/rep_loss_std 6.56 / report/reward_avg 0.24 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.29 / report/reward_max_data 1.8 / report/reward_max_pred 1.82 / report/reward_neg_acc 1 / report/reward_neg_loss 8.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.24 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.6 / eval/dyn_loss_std 7.3 / eval/image_loss_mean 1.3 / eval/image_loss_std 1.8 / eval/model_loss_mean 4.3 / eval/model_loss_std 5.73 / eval/post_ent_mag 49.71 / eval/post_ent_max 49.71 / eval/post_ent_mean 41.77 / 
eval/post_ent_min 19.71 / eval/post_ent_std 4.42 / eval/prior_ent_mag 85.01 / eval/prior_ent_max 85.01 / eval/prior_ent_mean 46.28 / eval/prior_ent_min 31.02 / eval/prior_ent_std 5.84 / eval/rep_loss_mean 4.6 / eval/rep_loss_std 7.3 / eval/reward_avg 0.49 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.49 / eval/reward_rate 0.39 / 
replay/size 2.5e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3812 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.89 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.2e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.73 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / 
timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.69 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 8.9e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 258.4.
Starting evaluation at step 247500 Counter(247500) 247437
eval_Episode has 500 steps and return 278.6.
Saved chunk: 20230922T025347F152008-5RRx80eO95eroStQ6RmLhu-6vcx6JAnYNNdZtFKX8QFPv-1024.npz
train_Episode has 500 steps and return 240.5.
Starting evaluation at step 248000 Counter(248000) 247937
Saved chunk: 20230922T025404F199986-6k4tJtMZ0SZpuUbnSvFLfc-7norQ1P2nndsAjeu3O6huy-1024.npz
eval_Episode has 500 steps and return 289.3.
train_Episode has 500 steps and return 270.7.
Starting evaluation at step 248500 Counter(248500) 248437
eval_Episode has 500 steps and return 286.6.
Saved chunk: 20230922T025508F638664-6vcx6JAnYNNdZtFKX8QFPv-2usLQRvpdpBrTGKFmXP9Ny-1024.npz
train_Episode has 500 steps and return 266.1.
Starting evaluation at step 249000 Counter(249000) 248937
Saved chunk: 20230922T025524F158410-7norQ1P2nndsAjeu3O6huy-5kYTbuhMg9uZkSYE52mDbb-1024.npz
eval_Episode has 500 steps and return 289.9.
train_Episode has 500 steps and return 269.0.
Starting evaluation at step 249500 Counter(249500) 249437
eval_Episode has 500 steps and return 266.0.
Saved chunk: 20230922T025629F614934-2usLQRvpdpBrTGKFmXP9Ny-201NsThy8tRblgKdc7f4nR-1024.npz
train_Episode has 500 steps and return 245.0.
Starting evaluation at step 250000 Counter(250000) 249937
Saved chunk: 20230922T025643F585781-5kYTbuhMg9uZkSYE52mDbb-3LDje72UAn1TMl5Dz5AAsH-1024.npz
eval_Episode has 500 steps and return 287.2.
train_Episode has 500 steps and return 255.6.
Starting evaluation at step 250500 Counter(250500) 250437
eval_Episode has 500 steps and return 267.9.
Saved chunk: 20230922T025750F448347-201NsThy8tRblgKdc7f4nR-0GBasJnNmeATfjlPWcpeFt-1024.npz
Starting evaluation at step 251000 Counter(251000) 250937
Saved chunk: 20230922T025802F744096-3LDje72UAn1TMl5Dz5AAsH-63cszMhtnKn6b4zsaN24T5-1024.npz
eval_Episode has 500 steps and return 296.3.
train_Episode has 500 steps and return 274.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 502480 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 274.24 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 296.33 / eval_episode/reward_rate 0.45 / train/action_mag 3.89 / train/action_max 3.83 / train/action_mean 0.04 / train/action_min -3.37 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -1.59 / train/adv_mag 0.41 / train/adv_max 0.34 / train/adv_mean 8.7e-4
/ train/adv_min -0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.81 / train/dyn_loss_std 6.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 204.7 / train/extr_critic_max 204.7 / train/extr_critic_mean 193.81 / train/extr_critic_min 152.44 / train/extr_critic_std 10.71 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.74 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 205.13 / train/extr_return_raw_max 205.13 / train/extr_return_raw_mean 193.84 / train/extr_return_raw_min 
154.7 / train/extr_return_raw_std 10.74 / train/extr_reward_mag 1.9 / train/extr_reward_max 1.9 / train/extr_reward_mean 0.28 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.13 / train/image_loss_std 1 / train/model_loss_mean 3.56 / 
train/model_loss_std 4.85 / train/model_opt_grad_norm 8.64 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 3.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.79 / train/policy_entropy_max 
3.46 / train/policy_entropy_mean -2.34 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.52 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.34 / train/policy_logprob_min -9.52 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.53 / train/post_ent_max 52.53 / train/post_ent_mean 40.12 / 
train/post_ent_min 20.79 / train/post_ent_std 5.28 / train/prior_ent_mag 85.23 / train/prior_ent_max 85.23 / train/prior_ent_mean 43.92 / train/prior_ent_min 26.05 / train/prior_ent_std 7.24 / train/rep_loss_mean 3.81 / train/rep_loss_std 6.83 / train/reward_avg 0.28 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.28 / train/reward_max_data 1.86 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.28 / train/reward_rate 
0.24 / train_stats/mean_log_entropy -2.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.92 / report/dyn_loss_std 7.16 / report/image_loss_mean 1.1 / report/image_loss_std 1 / report/model_loss_mean 3.63 / report/model_loss_std 5.07 / report/post_ent_mag 50.12 / report/post_ent_max 50.12 / 
report/post_ent_mean 40.94 / report/post_ent_min 19.9 / report/post_ent_std 5.1 / report/prior_ent_mag 85.38 / report/prior_ent_max 85.38 / report/prior_ent_mean 45.08 / report/prior_ent_min 29.18 / report/prior_ent_std 6.93 / report/rep_loss_mean 3.92 / 
report/rep_loss_std 7.16 / report/reward_avg 0.36 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 1.85 / report/reward_max_pred 1.82 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.36 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 3.9e-11 / eval/cont_loss_std 9.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.43 / eval/dyn_loss_std 7.15 / eval/image_loss_mean 1.15 / eval/image_loss_std 1.59 / eval/model_loss_mean 4.08 / eval/model_loss_std 5.32 / eval/post_ent_mag 49.65 / eval/post_ent_max 49.65 / eval/post_ent_mean 
41.94 / eval/post_ent_min 22.71 / eval/post_ent_std 3.95 / eval/prior_ent_mag 85.38 / eval/prior_ent_max 85.38 / eval/prior_ent_mean 46.38 / eval/prior_ent_min 30.66 / eval/prior_ent_std 5.69 / eval/rep_loss_mean 4.43 / eval/rep_loss_std 7.15 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.54 / eval/reward_rate 0.44 / 
replay/size 2.5e5 / replay/inserts 3767 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3767 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.76 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.8e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7775 / timer/agent.policy_total 17.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.4e-3 
/ timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.53 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.11

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T025910F881766-0GBasJnNmeATfjlPWcpeFt-0000000000000000000000-420.npz
Saved chunk: 20230922T025921F622611-63cszMhtnKn6b4zsaN24T5-0000000000000000000000-197.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 251500 Counter(251500) 251437
eval_Episode has 500 steps and return 291.8.
train_Episode has 500 steps and return 271.0.
Saved chunk: 20230922T025910F881766-0GBasJnNmeATfjlPWcpeFt-6u3ZRRUMJyC8DOHmDdfWoP-1024.npz
Starting evaluation at step 252000 Counter(252000) 251937
Saved chunk: 20230922T025921F622611-63cszMhtnKn6b4zsaN24T5-73kHCaEizgIwEALFOi4Dhh-1024.npz
eval_Episode has 500 steps and return 295.2.
train_Episode has 500 steps and return 242.7.
Starting evaluation at step 252500 Counter(252500) 252437
eval_Episode has 500 steps and return 257.9.
train_Episode has 500 steps and return 248.4.
Saved chunk: 20230922T030032F789681-6u3ZRRUMJyC8DOHmDdfWoP-1BQpUOjz766qj5uqlPez3R-1024.npz
Starting evaluation at step 253000 Counter(253000) 252937
Saved chunk: 20230922T030041F999810-73kHCaEizgIwEALFOi4Dhh-4ZGSs6ECQ0ZG6DoQS1cunX-1024.npz
eval_Episode has 500 steps and return 287.5.
train_Episode has 500 steps and return 237.6.
Starting evaluation at step 253500 Counter(253500) 253437
eval_Episode has 500 steps and return 292.9.
train_Episode has 500 steps and return 261.4.
Saved chunk: 20230922T030153F678778-1BQpUOjz766qj5uqlPez3R-3NbRxZ2BsUHAOv099OlB57-1024.npz
Starting evaluation at step 254000 Counter(254000) 253937
Saved chunk: 20230922T030201F330143-4ZGSs6ECQ0ZG6DoQS1cunX-4oxnQbaOFEs1BoQyq0gr4m-1024.npz
eval_Episode has 500 steps and return 272.2.
train_Episode has 500 steps and return 262.7.
Starting evaluation at step 254500 Counter(254500) 254437
eval_Episode has 500 steps and return 288.6.
train_Episode has 500 steps and return 264.7.
Saved chunk: 20230922T030314F246063-3NbRxZ2BsUHAOv099OlB57-2pDPBSwGkRhzbIErN7hZ4F-1024.npz
Starting evaluation at step 255000 Counter(255000) 254937
Saved chunk: 20230922T030320F285424-4oxnQbaOFEs1BoQyq0gr4m-762tsM5uZH5xpDosKnRdxk-1024.npz
eval_Episode has 500 steps and return 280.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 510002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 280.6 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 264.68 / episode/reward_rate 0.42 / train/action_mag 3.81 / train/action_max 3.77 / train/action_mean 0.04 / train/action_min -3.31 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -0.8 / train/adv_mag 0.42 / train/adv_max 0.37 / train/adv_mean 7.9e-4 / train/adv_min 
-0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.79 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 205.38 / train/extr_critic_max 205.38 / train/extr_critic_mean 194.92 / train/extr_critic_min 153.12 / train/extr_critic_std 9.97 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.06 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 205.82 / train/extr_return_raw_max 205.82 / train/extr_return_raw_mean 194.95 / train/extr_return_raw_min 
156.53 / train/extr_return_raw_std 9.99 / train/extr_reward_mag 1.9 / train/extr_reward_max 1.9 / train/extr_reward_mean 0.29 / train/extr_reward_min 0 / train/extr_reward_std 0.53 / train/image_loss_mean 1.12 / train/image_loss_std 1 / train/model_loss_mean 3.54 / 
train/model_loss_std 4.83 / train/model_opt_grad_norm 8.65 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.76 / train/policy_entropy_max 
3.38 / train/policy_entropy_mean -2.36 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.16 / train/policy_logprob_mag 9.5 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.36 / train/policy_logprob_min -9.5 / train/policy_logprob_std 1.84 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 53.03 / train/post_ent_max 53.03 / train/post_ent_mean 40.16 / 
train/post_ent_min 20.8 / train/post_ent_std 5.27 / train/prior_ent_mag 85.15 / train/prior_ent_max 85.15 / train/prior_ent_mean 43.93 / train/prior_ent_min 26.09 / train/prior_ent_std 7.22 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.79 / train/reward_avg 0.28 / 
train/reward_loss_mean 0.14 / train/reward_loss_std 0.29 / train/reward_max_data 1.84 / train/reward_max_pred 1.82 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.28 / train/reward_rate 
0.25 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.49 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.19 / report/dyn_loss_std 5.57 / report/image_loss_mean 0.85 / report/image_loss_std 0.57 / report/model_loss_mean 2.94 / report/model_loss_std 3.82 / report/post_ent_mag 57.06 / report/post_ent_max 57.06 /
report/post_ent_mean 41.62 / report/post_ent_min 24.97 / report/post_ent_std 3.91 / report/prior_ent_mag 85.48 / report/prior_ent_max 85.48 / report/prior_ent_mean 44.75 / report/prior_ent_min 28.62 / report/prior_ent_std 6.28 / report/rep_loss_mean 3.19 / 
report/rep_loss_std 5.57 / report/reward_avg 0.36 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 1.83 / report/reward_max_pred 1.84 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.36 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.72 / eval/dyn_loss_std 7.08 / eval/image_loss_mean 1.23 / eval/image_loss_std 1.41 / eval/model_loss_mean 4.27 / eval/model_loss_std 5.31 / eval/post_ent_mag 50.14 / eval/post_ent_max 50.14 / eval/post_ent_mean 
41.56 / eval/post_ent_min 18.42 / eval/post_ent_std 4.53 / eval/prior_ent_mag 85.48 / eval/prior_ent_max 85.48 / eval/prior_ent_mean 46.03 / eval/prior_ent_min 34.86 / eval/prior_ent_std 5.7 / eval/rep_loss_mean 4.72 / eval/rep_loss_std 7.08 / eval/reward_avg 0.46 / 
eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.46 / eval/reward_rate 0.38 / 
replay/size 2.5e5 / replay/inserts 3761 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3761 / timer/env.step_total 19.72 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.65 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7769 / timer/agent.policy_total 17.65 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.32 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / 
timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.07

train_Episode has 500 steps and return 238.2.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 255500 Counter(255500) 255437
eval_Episode has 500 steps and return 288.9.
train_Episode has 500 steps and return 239.6.
Starting evaluation at step 256000 Counter(256000) 255937
Saved chunk: 20230922T030434F827601-2pDPBSwGkRhzbIErN7hZ4F-1o9S1lKlwMPrk8fx4rHt8H-1024.npz
Saved chunk: 20230922T030439F278367-762tsM5uZH5xpDosKnRdxk-0gjnbCK6Aodw2d6lu11EJV-1024.npz
eval_Episode has 500 steps and return 270.0.
train_Episode has 500 steps and return 258.6.
Starting evaluation at step 256500 Counter(256500) 256437
eval_Episode has 500 steps and return 291.9.
train_Episode has 500 steps and return 269.5.
Starting evaluation at step 257000 Counter(257000) 256937
eval_Episode has 500 steps and return 284.4.
Saved chunk: 20230922T030559F497042-0gjnbCK6Aodw2d6lu11EJV-20F9VMmupPcVnXGjfpNFMT-1024.npz
train_Episode has 500 steps and return 227.4.
Saved chunk: 20230922T030556F596116-1o9S1lKlwMPrk8fx4rHt8H-54CU40eCcDePtPQNHzKIiq-1024.npz
Starting evaluation at step 257500 Counter(257500) 257437
eval_Episode has 500 steps and return 282.7.
train_Episode has 500 steps and return 247.3.
Starting evaluation at step 258000 Counter(258000) 257937
eval_Episode has 500 steps and return 294.6.
Saved chunk: 20230922T030718F745085-20F9VMmupPcVnXGjfpNFMT-6tJLNPuGY41qkBioyNkUWp-1024.npz
train_Episode has 500 steps and return 265.3.
Saved chunk: 20230922T030720F959941-54CU40eCcDePtPQNHzKIiq-5YPY4LWKUdmhUmda05us02-1024.npz
Starting evaluation at step 258500 Counter(258500) 258437
eval_Episode has 500 steps and return 299.0.
train_Episode has 500 steps and return 257.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 517630 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 257.38 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 299.03 / eval_episode/reward_rate 0.47 / train_stats/mean_log_entropy -2.53 / train/action_mag 3.75 / train/action_max 3.7 / train/action_mean 0.05 / 
train/action_min -3.24 / train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 0.09 / train/adv_mag 0.37 / train/adv_max 0.29 
/ train/adv_mean 7.2e-4 / train/adv_min -0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 
/ train/cont_rate 1 / train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / 
train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 205.91 / train/extr_critic_max 205.91 / train/extr_critic_mean 195.54 / train/extr_critic_min 156.36 / train/extr_critic_std 10.43 / 
train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.06 / train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 206.36 / train/extr_return_raw_max 
206.36 / train/extr_return_raw_mean 195.56 / train/extr_return_raw_min 156.11 / train/extr_return_raw_std 10.45 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / 
train/image_loss_mean 1.11 / train/image_loss_std 0.98 / train/model_loss_mean 3.54 / train/model_loss_std 4.79 / train/model_opt_grad_norm 8.92 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.65 / train/policy_entropy_max 3.16 / train/policy_entropy_mean -2.41 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.44 / train/policy_logprob_max 5.48 / 
train/policy_logprob_mean 2.41 / train/policy_logprob_min -9.44 / train/policy_logprob_std 1.82 / train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2.7e-4 / train/policy_randomness_std 
0.12 / train/post_ent_mag 52.64 / train/post_ent_max 52.64 / train/post_ent_mean 40.28 / train/post_ent_min 21.19 / train/post_ent_std 5.27 / train/prior_ent_mag 85.08 / train/prior_ent_max 85.08 / train/prior_ent_mean 44.05 / train/prior_ent_min 26.01 / 
train/prior_ent_std 7.23 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.74 / train/reward_avg 0.29 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.85 / train/reward_max_pred 1.83 / train/reward_neg_acc 1 / train/reward_neg_loss 
3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.29 / train/reward_rate 0.25 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.93 / report/dyn_loss_std 6.04 / report/image_loss_mean 0.79 / report/image_loss_std 0.65 / report/model_loss_mean 2.66 / 
report/model_loss_std 4.16 / report/post_ent_mag 57.06 / report/post_ent_max 57.06 / report/post_ent_mean 38.66 / report/post_ent_min 18.49 / report/post_ent_std 6.86 / report/prior_ent_mag 85.11 / report/prior_ent_max 85.11 / report/prior_ent_mean 41.56 / 
report/prior_ent_min 19.77 / report/prior_ent_std 9 / report/rep_loss_mean 2.93 / report/rep_loss_std 6.04 / report/reward_avg 0.22 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.25 / report/reward_max_data 1.78 / report/reward_max_pred 1.8 / 
report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.22 / report/reward_rate 0.19 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.8 / eval/dyn_loss_std 7.42 / eval/image_loss_mean 1.28 / eval/image_loss_std 1.71 / eval/model_loss_mean 4.39 / eval/model_loss_std 
5.78 / eval/post_ent_mag 50.06 / eval/post_ent_max 50.06 / eval/post_ent_mean 41.53 / eval/post_ent_min 24.9 / eval/post_ent_std 4.5 / eval/prior_ent_mag 85.11 / eval/prior_ent_max 85.11 / eval/prior_ent_mean 45.97 / eval/prior_ent_min 30.31 / eval/prior_ent_std 6.2 / 
eval/rep_loss_mean 4.8 / eval/rep_loss_std 7.42 / eval/reward_avg 0.45 / eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.57 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.84 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.4e-3 / eval/reward_pos_acc 0.99 / 
eval/reward_pos_loss 0.6 / eval/reward_pred 0.45 / eval/reward_rate 0.37 / replay/size 2.6e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3814 / 
timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 449.49 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 
0.01 / timer/replay._sample_min 2.2e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.49 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.8e-3 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.9 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.7e-8 / timer/dataset_eval_avg 2.6e-5 / 
timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 259000 Counter(259000) 258937
eval_Episode has 500 steps and return 280.0.
Saved chunk: 20230922T030837F859622-6tJLNPuGY41qkBioyNkUWp-6TAAfwrpFxF9XKFsSwXRmK-1024.npz
train_Episode has 500 steps and return 276.9.
Saved chunk: 20230922T030841F653054-5YPY4LWKUdmhUmda05us02-6ayUNGtzA13btu4GvsAalt-1024.npz
Starting evaluation at step 259500 Counter(259500) 259437
eval_Episode has 500 steps and return 272.1.
train_Episode has 500 steps and return 254.8.
Starting evaluation at step 260000 Counter(260000) 259937
eval_Episode has 500 steps and return 298.1.
train_Episode has 500 steps and return 276.4.
Saved chunk: 20230922T031003F181088-6ayUNGtzA13btu4GvsAalt-6K5tyeRkOXuhe8MpTLEeUn-1024.npz
Starting evaluation at step 260500 Counter(260500) 260437
Saved chunk: 20230922T030957F802776-6TAAfwrpFxF9XKFsSwXRmK-5bVRwACHWs8ChEbQYtE4JZ-1024.npz
eval_Episode has 500 steps and return 265.3.
train_Episode has 500 steps and return 265.6.
Starting evaluation at step 261000 Counter(261000) 260937
eval_Episode has 500 steps and return 296.5.
train_Episode has 500 steps and return 227.0.
Saved chunk: 20230922T031124F163323-6K5tyeRkOXuhe8MpTLEeUn-4ekLFbJQWgDvS0XDXkmLB2-1024.npz
Starting evaluation at step 261500 Counter(261500) 261437
Saved chunk: 20230922T031153F262813-5bVRwACHWs8ChEbQYtE4JZ-7wcQZXtAZyWMysoeUaRQRG-1024.npz
eval_Episode has 500 steps and return 302.8.
train_Episode has 500 steps and return 281.9.
Starting evaluation at step 262000 Counter(262000) 261937
eval_Episode has 500 steps and return 278.9.
train_Episode has 500 steps and return 263.9.
Saved chunk: 20230922T031244F870986-4ekLFbJQWgDvS0XDXkmLB2-1kMlIRjsQPVHRWQqs9SY4U-1024.npz
Starting evaluation at step 262500 Counter(262500) 262437
Saved chunk: 20230922T031312F257404-7wcQZXtAZyWMysoeUaRQRG-5bKrXZ0b8FJQybPKsKXDNP-1024.npz
eval_Episode has 500 steps and return 277.1.
train_Episode has 500 steps and return 267.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 525162 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 277.12 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 267.57 / episode/reward_rate 0.44 / train/action_mag 3.8 / train/action_max 3.76 / train/action_mean 0.05 / train/action_min -3.27 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 2.3 / train/adv_mag 0.37 / train/adv_max 0.29 / train/adv_mean 4.7e-4 / train/adv_min 
-0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 6.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 206.45 / train/extr_critic_max 206.45 / train/extr_critic_mean 195.81 / train/extr_critic_min 152.91 / train/extr_critic_std 11.4 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.75 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 206.9 / train/extr_return_raw_max 206.9 / train/extr_return_raw_mean 195.83 / train/extr_return_raw_min 
152.2 / train/extr_return_raw_std 11.44 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.1 / train/image_loss_std 0.96 / train/model_loss_mean 3.52 / 
train/model_loss_std 4.77 / train/model_opt_grad_norm 8.51 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.91 / train/policy_entropy_max 
3.65 / train/policy_entropy_mean -2.31 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.23 / train/policy_logprob_mag 9.64 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.31 / train/policy_logprob_min -9.64 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.98 / train/post_ent_max 52.98 / train/post_ent_mean 40.3 / 
train/post_ent_min 21.07 / train/post_ent_std 5.28 / train/prior_ent_mag 85.02 / train/prior_ent_max 85.02 / train/prior_ent_mean 44.07 / train/prior_ent_min 26.13 / train/prior_ent_std 7.22 / train/rep_loss_mean 3.78 / train/rep_loss_std 6.74 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.86 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.58 / train/reward_pred 0.29 / train/reward_rate 
0.25 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.49 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.06 / report/dyn_loss_std 7.17 / report/image_loss_mean 1.24 / report/image_loss_std 1.16 / report/model_loss_mean 3.87 / report/model_loss_std 5.09 / report/post_ent_mag 49.87 / report/post_ent_max 49.87 /
report/post_ent_mean 40.06 / report/post_ent_min 20.45 / report/post_ent_std 5.8 / report/prior_ent_mag 84.77 / report/prior_ent_max 84.77 / report/prior_ent_mean 44.03 / report/prior_ent_min 25.31 / report/prior_ent_std 7.37 / report/rep_loss_mean 4.06 / 
report/rep_loss_std 7.17 / report/reward_avg 0.34 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.32 / report/reward_max_data 1.75 / report/reward_max_pred 1.76 / report/reward_neg_acc 1 / report/reward_neg_loss 4.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.35 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.13 / eval/dyn_loss_std 6.48 / eval/image_loss_mean 1.14 / eval/image_loss_std 1.52 / eval/model_loss_mean 3.85 / eval/model_loss_std 4.96 / eval/post_ent_mag 49.9 / eval/post_ent_max 49.9 / eval/post_ent_mean 
42.02 / eval/post_ent_min 21.55 / eval/post_ent_std 3.86 / eval/prior_ent_mag 84.77 / eval/prior_ent_max 84.77 / eval/prior_ent_mean 46.01 / eval/prior_ent_min 33.5 / eval/prior_ent_std 5.68 / eval/rep_loss_mean 4.13 / eval/rep_loss_std 6.48 / eval/reward_avg 0.53 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.82 / eval/reward_max_pred 1.78 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.52 / eval/reward_rate 0.41 / 
replay/size 2.6e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3766 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 446.75 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / 
timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.79 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T031405F411863-1kMlIRjsQPVHRWQqs9SY4U-0000000000000000000000-556.npz
Saved chunk: 20230922T031431F335929-5bKrXZ0b8FJQybPKsKXDNP-0000000000000000000000-456.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 263000 Counter(263000) 262937
eval_Episode has 500 steps and return 290.6.
train_Episode has 500 steps and return 264.4.
Saved chunk: 20230922T031405F411863-1kMlIRjsQPVHRWQqs9SY4U-1LKlzfypmfWYlBDBGEkZWg-1024.npz
Starting evaluation at step 263500 Counter(263500) 263437
Saved chunk: 20230922T031431F335929-5bKrXZ0b8FJQybPKsKXDNP-3DorrFibhsr4IywNd1oHfE-1024.npz
eval_Episode has 500 steps and return 296.9.
train_Episode has 500 steps and return 283.7.
Starting evaluation at step 264000 Counter(264000) 263937
eval_Episode has 500 steps and return 246.8.
train_Episode has 500 steps and return 251.4.
Saved chunk: 20230922T031527F498840-1LKlzfypmfWYlBDBGEkZWg-1ZIJIzV77RjcVaqJ2eZSd3-1024.npz
Starting evaluation at step 264500 Counter(264500) 264437
Saved chunk: 20230922T031551F964854-3DorrFibhsr4IywNd1oHfE-5k3boH5r2tARGuKoKfhLAg-1024.npz
eval_Episode has 500 steps and return 285.4.
train_Episode has 500 steps and return 267.1.
Starting evaluation at step 265000 Counter(265000) 264937
eval_Episode has 500 steps and return 274.8.
train_Episode has 500 steps and return 271.2.
Saved chunk: 20230922T031648F413968-1ZIJIzV77RjcVaqJ2eZSd3-24lgIShGQrQ3jI12y3DhaL-1024.npz
Starting evaluation at step 265500 Counter(265500) 265437
Saved chunk: 20230922T031711F233606-5k3boH5r2tARGuKoKfhLAg-2G8bYtqIHYAT2wLBeArl3L-1024.npz
eval_Episode has 500 steps and return 264.3.
train_Episode has 500 steps and return 264.0.
Starting evaluation at step 266000 Counter(266000) 265937
eval_Episode has 500 steps and return 282.2.
train_Episode has 500 steps and return 243.6.
Saved chunk: 20230922T031809F177728-24lgIShGQrQ3jI12y3DhaL-1e8E0jFKEAhNEOXxCEhqbC-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 532778 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 282.17 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 243.63 / episode/reward_rate 0.39 / train/action_mag 3.75 / train/action_max 3.7 / train/action_mean 0.05 / train/action_min -3.3 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 0.39 / train/adv_mag 0.37 / train/adv_max 0.28 / train/adv_mean 6.6e-4 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 206.9 / train/extr_critic_max 206.9 / train/extr_critic_mean 196.6 / train/extr_critic_min 156.82 / train/extr_critic_std 10.16 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 207.38 / train/extr_return_raw_max 207.38 / train/extr_return_raw_mean 196.63 / train/extr_return_raw_min 
157.01 / train/extr_return_raw_std 10.18 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.3 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 1.11 / train/image_loss_std 0.98 / train/model_loss_mean 3.52 /
train/model_loss_std 4.8 / train/model_opt_grad_norm 8.67 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.19 / train/policy_entropy_max 
3.98 / train/policy_entropy_mean -2.32 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.7 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.32 / train/policy_logprob_min -9.7 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.92 / train/post_ent_max 52.92 / train/post_ent_mean 40.4 / 
train/post_ent_min 21.03 / train/post_ent_std 5.14 / train/prior_ent_mag 85.04 / train/prior_ent_max 85.04 / train/prior_ent_mean 44.16 / train/prior_ent_min 26.39 / train/prior_ent_std 7.1 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.77 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.85 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.29 / train/reward_rate 
0.25 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.5 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 4.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.12 / report/dyn_loss_std 7.02 / report/image_loss_mean 1.19 / report/image_loss_std 1.05 / report/model_loss_mean 3.78 / report/model_loss_std 4.94 / report/post_ent_mag 55.71 / report/post_ent_max 55.71 /
report/post_ent_mean 39.89 / report/post_ent_min 18.88 / report/post_ent_std 5.1 / report/prior_ent_mag 85.1 / report/prior_ent_max 85.1 / report/prior_ent_mean 44.03 / report/prior_ent_min 25.46 / report/prior_ent_std 7.02 / report/rep_loss_mean 4.12 / 
report/rep_loss_std 7.02 / report/reward_avg 0.27 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.24 / report/reward_max_data 1.84 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.27 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.55 / eval/dyn_loss_std 7.08 / eval/image_loss_mean 1.25 / eval/image_loss_std 1.69 / eval/model_loss_mean 4.21 / eval/model_loss_std 5.42 / eval/post_ent_mag 50.73 / eval/post_ent_max 50.73 / eval/post_ent_mean 
41.91 / eval/post_ent_min 21.6 / eval/post_ent_std 4.39 / eval/prior_ent_mag 85.1 / eval/prior_ent_max 85.1 / eval/prior_ent_mean 46.18 / eval/prior_ent_min 26.55 / eval/prior_ent_std 5.77 / eval/rep_loss_mean 4.55 / eval/rep_loss_std 7.08 / eval/reward_avg 0.52 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.89 / eval/reward_max_pred 1.83 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.52 / eval/reward_rate 0.4 / 
replay/size 2.7e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3808 / timer/env.step_total 20.02 / timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.59 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.58 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.55 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 266500 Counter(266500) 266437
Saved chunk: 20230922T031830F308879-2G8bYtqIHYAT2wLBeArl3L-6pK7ds86Z5Z6dGi58FiTh2-1024.npz
eval_Episode has 500 steps and return 278.8.
train_Episode has 500 steps and return 257.9.
Starting evaluation at step 267000 Counter(267000) 266937
eval_Episode has 500 steps and return 279.3.
train_Episode has 500 steps and return 268.5.
Saved chunk: 20230922T031929F700909-1e8E0jFKEAhNEOXxCEhqbC-1A2gaAhN4uXy0dVKgmeEX1-1024.npz
Starting evaluation at step 267500 Counter(267500) 267437
Saved chunk: 20230922T031950F213923-6pK7ds86Z5Z6dGi58FiTh2-0EgIgdC4N7ugEAlEszo49Q-1024.npz
eval_Episode has 500 steps and return 285.1.
train_Episode has 500 steps and return 232.9.
Starting evaluation at step 268000 Counter(268000) 267937
eval_Episode has 500 steps and return 265.1.
train_Episode has 500 steps and return 272.4.
Saved chunk: 20230922T032051F563266-1A2gaAhN4uXy0dVKgmeEX1-1fkc7XuOW06uT3GSAXikAF-1024.npz
Starting evaluation at step 268500 Counter(268500) 268437
Saved chunk: 20230922T032109F670028-0EgIgdC4N7ugEAlEszo49Q-3XhDmHNPisC6Xg1xk6xhbs-1024.npz
eval_Episode has 500 steps and return 288.1.
train_Episode has 500 steps and return 247.1.
Starting evaluation at step 269000 Counter(269000) 268937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 276.3.
Saved chunk: 20230922T032212F476121-1fkc7XuOW06uT3GSAXikAF-1VoKRgug2G6tnheVLHZ15B-1024.npz
Starting evaluation at step 269500 Counter(269500) 269437
Saved chunk: 20230922T032228F991467-3XhDmHNPisC6Xg1xk6xhbs-2fd0c0kAaWVaRzspaiJCjv-1024.npz
eval_Episode has 500 steps and return 289.7.
train_Episode has 500 steps and return 238.8.
Starting evaluation at step 270000 Counter(270000) 269937
eval_Episode has 500 steps and return 279.3.
train_Episode has 500 steps and return 258.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 540306 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 279.33 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 258.68 / episode/reward_rate 0.37 / train/action_mag 3.72 / train/action_max 3.64 / train/action_mean 0.04 / train/action_min -3.3 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss 1.68 / train/adv_mag 0.34 / train/adv_max 0.28 / train/adv_mean 5.4e-4 / train/adv_min 
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 207.44 / train/extr_critic_max 207.44 / train/extr_critic_mean 197.12 / train/extr_critic_min 156.54 / train/extr_critic_std 10.88 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 207.89 / train/extr_return_raw_max 207.89 / train/extr_return_raw_mean 197.14 / train/extr_return_raw_min 
155.76 / train/extr_return_raw_std 10.91 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.1 / train/image_loss_std 0.98 / train/model_loss_mean 3.53 /
train/model_loss_std 4.8 / train/model_opt_grad_norm 8.78 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.41 / train/policy_entropy_max 
4.24 / train/policy_entropy_mean -2.35 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 9.94 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.35 / train/policy_logprob_min -9.94 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.76 / train/post_ent_max 52.76 / train/post_ent_mean 40.48 / 
train/post_ent_min 21.18 / train/post_ent_std 5.22 / train/prior_ent_mag 85.04 / train/prior_ent_max 85.04 / train/prior_ent_mean 44.24 / train/prior_ent_min 26 / train/prior_ent_std 7.16 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.76 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.85 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.3 / train/reward_rate 
0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.52 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.8 / report/dyn_loss_std 6.69 / report/image_loss_mean 1.15 / report/image_loss_std 0.99 / report/model_loss_mean 3.6 / report/model_loss_std 4.77 / report/post_ent_mag 51.33 / report/post_ent_max 51.33 / 
report/post_ent_mean 40.73 / report/post_ent_min 20.91 / report/post_ent_std 5.35 / report/prior_ent_mag 84.99 / report/prior_ent_max 84.99 / report/prior_ent_mean 44.62 / report/prior_ent_min 24.26 / report/prior_ent_std 7.22 / report/rep_loss_mean 3.8 / 
report/rep_loss_std 6.69 / report/reward_avg 0.37 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.27 / report/reward_max_data 1.87 / report/reward_max_pred 1.81 / report/reward_neg_acc 1 / report/reward_neg_loss 8.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.52 / report/reward_pred 0.37 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.73 / eval/dyn_loss_std 5.91 / eval/image_loss_mean 0.93 / eval/image_loss_std 0.64 / eval/model_loss_mean 3.43 / eval/model_loss_std 4.13 / eval/post_ent_mag 50.46 / eval/post_ent_max 50.46 / eval/post_ent_mean 
42.71 / eval/post_ent_min 23.67 / eval/post_ent_std 3.43 / eval/prior_ent_mag 84.99 / eval/prior_ent_max 84.99 / eval/prior_ent_mean 46.39 / eval/prior_ent_min 39.2 / eval/prior_ent_std 5.35 / eval/rep_loss_mean 3.73 / eval/rep_loss_std 5.91 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.86 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.56 / eval/reward_rate 0.45 / 
replay/size 2.7e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3764 / timer/env.step_total 19.58 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.71 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.48 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1882 / timer/agent.train_total 241.69 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T032333F179396-1VoKRgug2G6tnheVLHZ15B-5CtFpMyUMKIpDzRMxokOSd-1024.npz
Starting evaluation at step 270500 Counter(270500) 270437
Saved chunk: 20230922T032348F090279-2fd0c0kAaWVaRzspaiJCjv-0yOZ2WjQpYVRkN6rgEKa2f-1024.npz
eval_Episode has 500 steps and return 269.8.
train_Episode has 500 steps and return 275.3.
Starting evaluation at step 271000 Counter(271000) 270937
eval_Episode has 500 steps and return 281.6.
train_Episode has 500 steps and return 264.0.
Saved chunk: 20230922T032454F568582-5CtFpMyUMKIpDzRMxokOSd-1Ppc7wGS9lUNoC5phdmqlr-1024.npz
Starting evaluation at step 271500 Counter(271500) 271437
Saved chunk: 20230922T032507F956734-0yOZ2WjQpYVRkN6rgEKa2f-2OlgPyayi2DI1VWrfOkXvo-1024.npz
eval_Episode has 500 steps and return 277.1.
train_Episode has 500 steps and return 230.3.
Starting evaluation at step 272000 Counter(272000) 271937
eval_Episode has 500 steps and return 284.8.
train_Episode has 500 steps and return 238.9.
Saved chunk: 20230922T032615F531689-1Ppc7wGS9lUNoC5phdmqlr-2jYao3hbFhnXzSmowBXf5R-1024.npz
Starting evaluation at step 272500 Counter(272500) 272437
Saved chunk: 20230922T032627F325495-2OlgPyayi2DI1VWrfOkXvo-64pOS0WIZzd304G33P3Cfk-1024.npz
eval_Episode has 500 steps and return 271.1.
train_Episode has 500 steps and return 249.0.
Starting evaluation at step 273000 Counter(273000) 272937
eval_Episode has 500 steps and return 292.1.
train_Episode has 500 steps and return 273.0.
Saved chunk: 20230922T032736F187303-2jYao3hbFhnXzSmowBXf5R-71E5PrIIH5nzWMLgiMdje4-1024.npz
Starting evaluation at step 273500 Counter(273500) 273437
Saved chunk: 20230922T032746F347948-64pOS0WIZzd304G33P3Cfk-2qyths6OYjjvQJMnQSbUfU-1024.npz
eval_Episode has 500 steps and return 287.5.
train_Episode has 500 steps and return 255.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 547942 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 287.48 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 255.76 / episode/reward_rate 0.41 / train/action_mag 3.74 / train/action_max 3.68 / train/action_mean 0.04 / train/action_min -3.25 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 2.2 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 5e-4 / 
train/adv_min -0.36 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.76 / train/dyn_loss_std 6.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 207.93 / train/extr_critic_max 207.93 / train/extr_critic_mean 197.72 / train/extr_critic_min 153.72 / train/extr_critic_std 10.88 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 208.41 / train/extr_return_raw_max 208.41 / train/extr_return_raw_mean 197.74 / train/extr_return_raw_min 
154.04 / train/extr_return_raw_std 10.93 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.08 / train/image_loss_std 0.98 / train/model_loss_mean 3.49 
/ train/model_loss_std 4.76 / train/model_opt_grad_norm 8.59 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 2.6e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 4.43 / 
train/policy_entropy_max 4.22 / train/policy_entropy_mean -2.4 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.14 / train/policy_logprob_mag 9.93 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.4 / train/policy_logprob_min -9.93 / 
train/policy_logprob_std 1.83 / train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.95 / train/post_ent_max 52.95 / 
train/post_ent_mean 40.54 / train/post_ent_min 21.2 / train/post_ent_std 5.15 / train/prior_ent_mag 84.87 / train/prior_ent_max 84.87 / train/prior_ent_mean 44.29 / train/prior_ent_min 26.23 / train/prior_ent_std 7.06 / train/rep_loss_mean 3.76 / train/rep_loss_std 6.71
/ train/reward_avg 0.3 / train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.85 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 
0.3 / train/reward_rate 0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.59 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.74 / report/image_loss_mean 1.12 / report/image_loss_std 1.19 / report/model_loss_mean 3.58 / report/model_loss_std 4.83 / report/post_ent_mag 
50.27 / report/post_ent_max 50.27 / report/post_ent_mean 41.15 / report/post_ent_min 21.57 / report/post_ent_std 4.51 / report/prior_ent_mag 84.63 / report/prior_ent_max 84.63 / report/prior_ent_mean 44.95 / report/prior_ent_min 30.47 / report/prior_ent_std 6.4 / 
report/rep_loss_mean 3.83 / report/rep_loss_std 6.74 / report/reward_avg 0.35 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.78 / report/reward_max_pred 1.79 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.35 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.23 / eval/dyn_loss_std 8.47 / eval/image_loss_mean 1.45 / eval/image_loss_std 2.16 / eval/model_loss_mean 4.81 / eval/model_loss_std 6.75 / eval/post_ent_mag 50.29 / 
eval/post_ent_max 50.29 / eval/post_ent_mean 41.13 / eval/post_ent_min 18.93 / eval/post_ent_std 5.05 / eval/prior_ent_mag 84.63 / eval/prior_ent_max 84.63 / eval/prior_ent_mean 45.62 / eval/prior_ent_min 24.42 / eval/prior_ent_std 6.23 / eval/rep_loss_mean 5.23 / 
eval/rep_loss_std 8.47 / eval/reward_avg 0.49 / eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.78 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / 
eval/reward_pred 0.49 / eval/reward_rate 0.4 / replay/size 2.7e5 / replay/inserts 3818 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3818 / timer/env.step_total 19.8 
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.29 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7325 / timer/agent.policy_total 16.44 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 
2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.9e-3 / timer/dataset_train_count 1909 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.3e-4 
/ timer/agent.train_count 1909 / timer/agent.train_total 244.91 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.6e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / 
timer/dataset_eval_max 2.6e-5 / fps 25.45

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 274000 Counter(274000) 273937
eval_Episode has 500 steps and return 292.7.
train_Episode has 500 steps and return 274.4.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T032856F604351-71E5PrIIH5nzWMLgiMdje4-0000000000000000000000-693.npz
Saved chunk: 20230922T032905F216624-2qyths6OYjjvQJMnQSbUfU-0000000000000000000000-715.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T032856F604351-71E5PrIIH5nzWMLgiMdje4-1URxH3veIti5TSDXGAZscg-1024.npz
Starting evaluation at step 274500 Counter(274500) 274437
Saved chunk: 20230922T032905F216624-2qyths6OYjjvQJMnQSbUfU-2hgDZYmbqaAoomucj5iRYh-1024.npz
eval_Episode has 500 steps and return 284.4.
train_Episode has 500 steps and return 253.8.
Starting evaluation at step 275000 Counter(275000) 274937
eval_Episode has 500 steps and return 260.6.
train_Episode has 500 steps and return 259.8.
Saved chunk: 20230922T033018F524095-1URxH3veIti5TSDXGAZscg-3OIuZzisJ0Z8wlZ5uW1EXH-1024.npz
Starting evaluation at step 275500 Counter(275500) 275437
Saved chunk: 20230922T033025F587982-2hgDZYmbqaAoomucj5iRYh-2vCG2ORxikFiHozK3pdAzE-1024.npz
eval_Episode has 500 steps and return 288.9.
train_Episode has 500 steps and return 253.5.
Starting evaluation at step 276000 Counter(276000) 275937
eval_Episode has 500 steps and return 293.6.
train_Episode has 500 steps and return 272.4.
Saved chunk: 20230922T033139F397668-3OIuZzisJ0Z8wlZ5uW1EXH-0QjT05W5OW03RRlGnAJPDy-1024.npz
Starting evaluation at step 276500 Counter(276500) 276437
Saved chunk: 20230922T033144F868579-2vCG2ORxikFiHozK3pdAzE-7i10ifEpNz4IesENR18kWF-1024.npz
eval_Episode has 500 steps and return 273.4.
train_Episode has 500 steps and return 254.6.
Starting evaluation at step 277000 Counter(277000) 276937
eval_Episode has 500 steps and return 289.8.
train_Episode has 500 steps and return 283.0.
Starting evaluation at step 277500 Counter(277500) 277437
Saved chunk: 20230922T033303F909381-7i10ifEpNz4IesENR18kWF-5IZsWX3pUE2AnFN37PNUPZ-1024.npz
eval_Episode has 500 steps and return 272.3.
Saved chunk: 20230922T033300F017986-0QjT05W5OW03RRlGnAJPDy-10fVKdWthfdjHC4PuAFbww-1024.npz
train_Episode has 500 steps and return 271.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 555438 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 272.35 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 271.65 / episode/reward_rate 0.41 / train/action_mag 3.77 / train/action_max 3.68 / train/action_mean 0.04 / train/action_min -3.34 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 3.99 / train/adv_mag 0.38 / train/adv_max 0.3 / train/adv_mean 2.9e-4 /
train/adv_min -0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.79 / train/dyn_loss_std 6.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 208.28 / train/extr_critic_max 208.28 / train/extr_critic_mean 197.67 / train/extr_critic_min 150.2 / train/extr_critic_std 11.75 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.48 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 208.75 / train/extr_return_raw_max 208.75 / train/extr_return_raw_mean 197.68 / train/extr_return_raw_min 
149.84 / train/extr_return_raw_std 11.79 / train/extr_reward_mag 1.91 / train/extr_reward_max 1.91 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.09 / train/image_loss_std 0.99 / train/model_loss_mean 3.51 
/ train/model_loss_std 4.79 / train/model_opt_grad_norm 8.77 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.51 / train/policy_entropy_max
4.38 / train/policy_entropy_mean -2.29 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.98 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -9.98 / train/policy_logprob_std 1.89 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.98 / train/post_ent_max 52.98 / train/post_ent_mean 40.57 / 
train/post_ent_min 21.13 / train/post_ent_std 5.2 / train/prior_ent_mag 84.8 / train/prior_ent_max 84.8 / train/prior_ent_mean 44.33 / train/prior_ent_min 26.26 / train/prior_ent_std 7.13 / train/rep_loss_mean 3.79 / train/rep_loss_std 6.75 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.86 / train/reward_max_pred 1.84 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.3 / train/reward_rate 
0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.54 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.11 / report/dyn_loss_std 7.63 / report/image_loss_mean 1.26 / report/image_loss_std 1.37 / report/model_loss_mean 3.86 / report/model_loss_std 5.7 / report/post_ent_mag 56.16 / report/post_ent_max 56.16 / 
report/post_ent_mean 39.92 / report/post_ent_min 19.71 / report/post_ent_std 5.68 / report/prior_ent_mag 84.96 / report/prior_ent_max 84.96 / report/prior_ent_mean 43.98 / report/prior_ent_min 25.52 / report/prior_ent_std 7.34 / report/rep_loss_mean 4.11 / 
report/rep_loss_std 7.63 / report/reward_avg 0.25 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.34 / report/reward_max_data 1.78 / report/reward_max_pred 1.82 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.61 / report/reward_pred 0.26 / report/reward_rate 0.21 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 8.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.75 / eval/dyn_loss_std 6.06 / eval/image_loss_mean 0.92 / eval/image_loss_std 0.77 / eval/model_loss_mean 3.43 / eval/model_loss_std 4.25 / eval/post_ent_mag 49.93 / eval/post_ent_max 49.93 / eval/post_ent_mean 
42.64 / eval/post_ent_min 27.38 / eval/post_ent_std 3.5 / eval/prior_ent_mag 84.96 / eval/prior_ent_max 84.96 / eval/prior_ent_mean 46.3 / eval/prior_ent_min 34.57 / eval/prior_ent_std 5.5 / eval/rep_loss_mean 3.75 / eval/rep_loss_std 6.06 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.85 / eval/reward_max_pred 1.82 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.9e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.57 / eval/reward_rate 0.46 / 
replay/size 2.8e5 / replay/inserts 3748 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3748 / timer/env.step_total 19.52 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.45 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7756 / timer/agent.policy_total 17.65 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1874 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1874 / timer/agent.train_total 241.59 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.46 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 24.98

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 278000 Counter(278000) 277937
eval_Episode has 500 steps and return 295.1.
train_Episode has 500 steps and return 256.7.
Starting evaluation at step 278500 Counter(278500) 278437
Saved chunk: 20230922T033424F097161-5IZsWX3pUE2AnFN37PNUPZ-3yd8sZbDgDbyo7PCofpFUi-1024.npz
eval_Episode has 500 steps and return 283.6.
Saved chunk: 20230922T033425F294049-10fVKdWthfdjHC4PuAFbww-2PkIFFejQ1cCVTxB07JAi2-1024.npz
train_Episode has 500 steps and return 275.8.
Starting evaluation at step 279000 Counter(279000) 278937
eval_Episode has 500 steps and return 258.4.
train_Episode has 500 steps and return 271.9.
Starting evaluation at step 279500 Counter(279500) 279437
Saved chunk: 20230922T033544F407256-3yd8sZbDgDbyo7PCofpFUi-0hZ2DmqMuCggOUh9FsAuTn-1024.npz
eval_Episode has 500 steps and return 297.3.
Saved chunk: 20230922T033547F187075-2PkIFFejQ1cCVTxB07JAi2-1cJCR5tT3H9qpkIvvoBZT5-1024.npz
train_Episode has 500 steps and return 244.9.
Starting evaluation at step 280000 Counter(280000) 279937
eval_Episode has 500 steps and return 297.1.
train_Episode has 500 steps and return 254.7.
Starting evaluation at step 280500 Counter(280500) 280437
eval_Episode has 500 steps and return 288.1.
Saved chunk: 20230922T033703F505717-0hZ2DmqMuCggOUh9FsAuTn-2xWv5SFn6WyKIZIT3SoFlP-1024.npz
train_Episode has 500 steps and return 248.1.
Saved chunk: 20230922T033707F834911-1cJCR5tT3H9qpkIvvoBZT5-5pw3sbTU4eQe1QslSOhM4Q-1024.npz
Starting evaluation at step 281000 Counter(281000) 280937
eval_Episode has 500 steps and return 293.8.
train_Episode has 500 steps and return 274.6.
Starting evaluation at step 281500 Counter(281500) 281437
eval_Episode has 500 steps and return 298.9.
Saved chunk: 20230922T033822F480611-2xWv5SFn6WyKIZIT3SoFlP-47ziFtpyh2FBMUIuDXwxgF-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 563002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 298.93 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 274.6 / episode/reward_rate 0.44 / train/action_mag 3.8 / train/action_max 3.72 / train/action_mean 0.04 / train/action_min -3.4 / train/action_std 
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 3.9 / train/adv_mag 0.48 / train/adv_max 0.39 / train/adv_mean 2.9e-4 / train/adv_min 
-0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.76 / train/dyn_loss_std 6.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 208.7 / train/extr_critic_max 208.7 / train/extr_critic_mean 197.97 / train/extr_critic_min 147.93 / train/extr_critic_std 12.54 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 209.21 / train/extr_return_raw_max 209.21 / train/extr_return_raw_mean 197.99 / train/extr_return_raw_min 
148.88 / train/extr_return_raw_std 12.6 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.55 / train/image_loss_mean 1.08 / train/image_loss_std 0.96 / train/model_loss_mean 3.48 /
train/model_loss_std 4.77 / train/model_opt_grad_norm 8.53 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.6 / train/policy_entropy_max 
4.49 / train/policy_entropy_mean -2.29 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 10.26 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -10.26 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.81 / train/post_ent_max 52.81 / train/post_ent_mean 40.63 / 
train/post_ent_min 21.43 / train/post_ent_std 5.17 / train/prior_ent_mag 84.82 / train/prior_ent_max 84.82 / train/prior_ent_mean 44.37 / train/prior_ent_min 26.84 / train/prior_ent_std 7.09 / train/rep_loss_mean 3.76 / train/rep_loss_std 6.73 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.87 / train/reward_max_pred 1.85 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.3 / train/reward_rate 
0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.52 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.67 / report/dyn_loss_std 7.01 / report/image_loss_mean 1.2 / report/image_loss_std 1.24 / report/model_loss_mean 3.5 / report/model_loss_std 5.11 / report/post_ent_mag 51.34 / report/post_ent_max 51.34 / 
report/post_ent_mean 39.84 / report/post_ent_min 20.04 / report/post_ent_std 4.87 / report/prior_ent_mag 84.61 / report/prior_ent_max 84.61 / report/prior_ent_mean 43.51 / report/prior_ent_min 28.23 / report/prior_ent_std 6.7 / report/rep_loss_mean 3.67 / 
report/rep_loss_std 7.01 / report/reward_avg 0.21 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.22 / report/reward_max_data 1.75 / report/reward_max_pred 1.76 / report/reward_neg_acc 1 / report/reward_neg_loss 8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.52 / report/reward_pred 0.21 / report/reward_rate 0.19 / eval/cont_avg 1 / eval/cont_loss_mean 3.9e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.43 / eval/dyn_loss_std 7.29 / eval/image_loss_mean 1.21 / eval/image_loss_std 1.74 / eval/model_loss_mean 4.14 / eval/model_loss_std 5.79 / eval/post_ent_mag 50.65 / eval/post_ent_max 50.65 / eval/post_ent_mean 
41.95 / eval/post_ent_min 21.68 / eval/post_ent_std 4.37 / eval/prior_ent_mag 84.61 / eval/prior_ent_max 84.61 / eval/prior_ent_mean 46.11 / eval/prior_ent_min 29.9 / eval/prior_ent_std 5.62 / eval/rep_loss_mean 4.43 / eval/rep_loss_std 7.29 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.88 / eval/reward_max_pred 1.83 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.9e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.54 / eval/reward_rate 0.44
/ replay/size 2.8e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.95 / timer/env.step_count 3782 / timer/env.step_total 19.76 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.65 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7790 / timer/agent.policy_total 17.6 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.15 / 
timer/dataset_train_count 1891 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 6.2e-4 / timer/agent.train_count 1891 / timer/agent.train_total 242.29 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 266.8.
Saved chunk: 20230922T033828F357923-5pw3sbTU4eQe1QslSOhM4Q-0b7BbG1ffHoeQBkbMvqIz5-1024.npz
Starting evaluation at step 282000 Counter(282000) 281937
eval_Episode has 500 steps and return 271.2.
train_Episode has 500 steps and return 267.9.
Starting evaluation at step 282500 Counter(282500) 282437
eval_Episode has 500 steps and return 293.8.
Saved chunk: 20230922T033941F262477-47ziFtpyh2FBMUIuDXwxgF-0XXlHFhFcc3qbU7IZU10Dt-1024.npz
train_Episode has 500 steps and return 265.6.
Saved chunk: 20230922T033949F654236-0b7BbG1ffHoeQBkbMvqIz5-0ZhwTTe6szhyZ9upTd6vlE-1024.npz
Starting evaluation at step 283000 Counter(283000) 282937
eval_Episode has 500 steps and return 281.5.
train_Episode has 500 steps and return 269.0.
Starting evaluation at step 283500 Counter(283500) 283437
eval_Episode has 500 steps and return 291.4.
train_Episode has 500 steps and return 245.0.
Saved chunk: 20230922T034110F513577-0ZhwTTe6szhyZ9upTd6vlE-6BBa7NUUFjyorOrBpTptew-1024.npz
Starting evaluation at step 284000 Counter(284000) 283937
Saved chunk: 20230922T034101F486380-0XXlHFhFcc3qbU7IZU10Dt-6ALFVgcKMceY7NJPgPbDvi-1024.npz
eval_Episode has 500 steps and return 294.0.
train_Episode has 500 steps and return 255.4.
Starting evaluation at step 284500 Counter(284500) 284437
eval_Episode has 500 steps and return 308.0.
train_Episode has 500 steps and return 266.9.
Saved chunk: 20230922T034231F377518-6BBa7NUUFjyorOrBpTptew-1IrW8k6P0t5wmrgjeZml9N-1024.npz
Starting evaluation at step 285000 Counter(285000) 284937
Saved chunk: 20230922T034256F769497-6ALFVgcKMceY7NJPgPbDvi-3P7gwl9TIE5qHNZzMYKJKB-1024.npz
eval_Episode has 500 steps and return 284.8.
train_Episode has 500 steps and return 283.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 570634 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 283.93 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 284.8 / eval_episode/reward_rate 0.43 / train/action_mag 3.74 / train/action_max 3.66 / train/action_mean 0.04 / train/action_min -3.35 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss 2.36 / train/adv_mag 0.6 / train/adv_max 0.52 / train/adv_mean 4.3e-4 / train/adv_min 
-0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.1e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.8 / train/dyn_loss_std 6.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 209.04 / train/extr_critic_max 209.04 / train/extr_critic_mean 198.48 / train/extr_critic_min 140.68 / train/extr_critic_std 12.49 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 209.55 / train/extr_return_raw_max 209.55 / train/extr_return_raw_mean 198.5 / train/extr_return_raw_min 
148.25 / train/extr_return_raw_std 12.52 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 1.08 / train/image_loss_std 0.98 / train/model_loss_mean 3.52 
/ train/model_loss_std 4.77 / train/model_opt_grad_norm 8.74 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.42 / train/policy_entropy_max
4.22 / train/policy_entropy_mean -2.24 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.22 / train/policy_logprob_mag 9.95 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.24 / train/policy_logprob_min -9.95 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 3.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.43 / train/post_ent_max 52.43 / train/post_ent_mean 40.73 / 
train/post_ent_min 21.18 / train/post_ent_std 5.18 / train/prior_ent_mag 84.7 / train/prior_ent_max 84.7 / train/prior_ent_mean 44.52 / train/prior_ent_min 26.67 / train/prior_ent_std 7.07 / train/rep_loss_mean 3.8 / train/rep_loss_std 6.72 / train/reward_avg 0.31 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.87 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.31 / train/reward_rate 
0.27 / train_stats/mean_log_entropy -2.5 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.95 / report/dyn_loss_std 6.85 / report/image_loss_mean 1.17 / report/image_loss_std 0.95 / report/model_loss_mean 3.68 / report/model_loss_std 4.81 / report/post_ent_mag 51.02 / report/post_ent_max 51.02 /
report/post_ent_mean 40.69 / report/post_ent_min 20.21 / report/post_ent_std 5.47 / report/prior_ent_mag 84.69 / report/prior_ent_max 84.69 / report/prior_ent_mean 44.8 / report/prior_ent_min 24.53 / report/prior_ent_std 7.24 / report/rep_loss_mean 3.95 / 
report/rep_loss_std 6.85 / report/reward_avg 0.28 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.27 / report/reward_max_data 1.87 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.28 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 6.3e-11 / eval/cont_loss_std 1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.3e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.17 / eval/dyn_loss_std 7.69 / eval/image_loss_mean 1.46 / eval/image_loss_std 2.07 / eval/model_loss_mean 4.78 / eval/model_loss_std 6.25 / eval/post_ent_mag 51.72 / eval/post_ent_max 51.72 / eval/post_ent_mean 41.08 / 
eval/post_ent_min 22.61 / eval/post_ent_std 4.92 / eval/prior_ent_mag 84.69 / eval/prior_ent_max 84.69 / eval/prior_ent_mean 45.76 / eval/prior_ent_min 29.96 / eval/prior_ent_std 6.03 / eval/rep_loss_mean 5.17 / eval/rep_loss_std 7.69 / eval/reward_avg 0.47 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.83 / eval/reward_max_pred 1.83 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.46 / eval/reward_rate 0.37 / 
replay/size 2.9e5 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3816 / timer/env.step_total 19.97 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.18 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7323 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1908 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1908 / timer/agent.train_total 244.73 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.3e-5 / timer/dataset_eval_frac 7.6e-8 / timer/dataset_eval_avg 2.3e-5 / timer/dataset_eval_min 2.3e-5 / timer/dataset_eval_max 2.3e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 285500 Counter(285500) 285437
Saved chunk: 20230922T034351F940318-1IrW8k6P0t5wmrgjeZml9N-0000000000000000000000-828.npz
Saved chunk: 20230922T034415F686966-3P7gwl9TIE5qHNZzMYKJKB-0000000000000000000000-473.npz
eval_Episode has 500 steps and return 292.3.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 265.5.
Saved chunk: 20230922T034351F940318-1IrW8k6P0t5wmrgjeZml9N-5LvAoxy1NiC01fgPalhWTQ-1024.npz
Starting evaluation at step 286000 Counter(286000) 285937
Saved chunk: 20230922T034415F686966-3P7gwl9TIE5qHNZzMYKJKB-54kWHJQvo8qCalc36afqIm-1024.npz
eval_Episode has 500 steps and return 283.7.
train_Episode has 500 steps and return 268.1.
Starting evaluation at step 286500 Counter(286500) 286437
eval_Episode has 500 steps and return 288.7.
train_Episode has 500 steps and return 251.3.
Saved chunk: 20230922T034513F897344-5LvAoxy1NiC01fgPalhWTQ-3ioprcYboKuEzDvRVJYZUp-1024.npz
Starting evaluation at step 287000 Counter(287000) 286937
Saved chunk: 20230922T034536F221023-54kWHJQvo8qCalc36afqIm-6Z0dscacEOC218A7y4Hmw5-1024.npz
eval_Episode has 500 steps and return 285.5.
train_Episode has 500 steps and return 275.6.
Starting evaluation at step 287500 Counter(287500) 287437
eval_Episode has 500 steps and return 282.0.
train_Episode has 500 steps and return 276.4.
Saved chunk: 20230922T034634F776113-3ioprcYboKuEzDvRVJYZUp-2OsPrgROkHq6LVqV2FPX1E-1024.npz
Starting evaluation at step 288000 Counter(288000) 287937
Saved chunk: 20230922T034655F490924-6Z0dscacEOC218A7y4Hmw5-7y8FEEQdQ3sOtd9XogkGcp-1024.npz
eval_Episode has 500 steps and return 300.7.
train_Episode has 500 steps and return 266.1.
Starting evaluation at step 288500 Counter(288500) 288437
eval_Episode has 500 steps and return 278.9.
train_Episode has 500 steps and return 275.6.
Saved chunk: 20230922T034755F486276-2OsPrgROkHq6LVqV2FPX1E-7EB6nntw64RcFqce4AqkTx-1024.npz
Starting evaluation at step 289000 Counter(289000) 288937
Saved chunk: 20230922T034814F532662-7y8FEEQdQ3sOtd9XogkGcp-0L2MXfAhZPMF06oHYNEMx1-1024.npz
eval_Episode has 500 steps and return 302.3.
train_Episode has 500 steps and return 267.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 578158 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 302.28 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 267.32 / episode/reward_rate 0.4 / train/action_mag 3.75 / train/action_max 3.67 / train/action_mean 0.04 / train/action_min -3.34 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -0.91 / train/adv_mag 0.75 / train/adv_max 0.7 / train/adv_mean 7.6e-4 / train/adv_min 
-0.37 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.78 / train/dyn_loss_std 6.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 209.18 / train/extr_critic_max 209.18 / train/extr_critic_mean 198.58 / train/extr_critic_min 138.28 / train/extr_critic_std 12 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 209.68 / train/extr_return_raw_max 209.68 / train/extr_return_raw_mean 198.61 / train/extr_return_raw_min 
149.49 / train/extr_return_raw_std 12.01 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.31 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 1.08 / train/image_loss_std 1 / train/model_loss_mean 3.51 / 
train/model_loss_std 4.81 / train/model_opt_grad_norm 8.65 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.39 / train/policy_entropy_max 
4.29 / train/policy_entropy_mean -2.22 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 10.01 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.22 / train/policy_logprob_min -10.01 / train/policy_logprob_std 1.9 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 3.1e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 53.18 / train/post_ent_max 53.18 / train/post_ent_mean 40.67 / 
train/post_ent_min 21.08 / train/post_ent_std 5.23 / train/prior_ent_mag 84.67 / train/prior_ent_max 84.67 / train/prior_ent_mean 44.41 / train/prior_ent_min 26.24 / train/prior_ent_std 7.13 / train/rep_loss_mean 3.78 / train/rep_loss_std 6.77 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.87 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.3 / train/reward_rate 
0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.44 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 6.72 / report/image_loss_mean 1.01 / report/image_loss_std 1.03 / report/model_loss_mean 3.51 / report/model_loss_std 4.84 / report/post_ent_mag 50.17 / report/post_ent_max 50.17 /
report/post_ent_mean 42.1 / report/post_ent_min 22.38 / report/post_ent_std 4.31 / report/prior_ent_mag 84.47 / report/prior_ent_max 84.47 / report/prior_ent_mean 45.99 / report/prior_ent_min 31.44 / report/prior_ent_std 6.16 / report/rep_loss_mean 3.82 / 
report/rep_loss_std 6.72 / report/reward_avg 0.43 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.31 / report/reward_max_data 1.97 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 7.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.43 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 3.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.49 / eval/dyn_loss_std 8.17 / eval/image_loss_mean 1.74 / eval/image_loss_std 2.51 / eval/model_loss_mean 5.26 / eval/model_loss_std 6.88 / eval/post_ent_mag 52.5 / eval/post_ent_max 52.5 / eval/post_ent_mean 
40.95 / eval/post_ent_min 21.03 / eval/post_ent_std 5.59 / eval/prior_ent_mag 84.47 / eval/prior_ent_max 84.47 / eval/prior_ent_mean 45.55 / eval/prior_ent_min 27.91 / eval/prior_ent_std 6.13 / eval/rep_loss_mean 5.49 / eval/rep_loss_std 8.17 / eval/reward_avg 0.52 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.51 / eval/reward_rate 0.41 / 
replay/size 2.9e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3762 / timer/env.step_total 19.64 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.27 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-4 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.5 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 6.2e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.48 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 289500 Counter(289500) 289437
eval_Episode has 500 steps and return 297.1.
train_Episode has 500 steps and return 247.1.
Saved chunk: 20230922T034915F965549-7EB6nntw64RcFqce4AqkTx-0ueRscxTY5uqvatDwARMGD-1024.npz
Starting evaluation at step 290000 Counter(290000) 289937
Saved chunk: 20230922T034933F455045-0L2MXfAhZPMF06oHYNEMx1-0sGSLLTQl3l8PvgKsoQSTC-1024.npz
eval_Episode has 500 steps and return 288.7.
train_Episode has 500 steps and return 256.2.
Starting evaluation at step 290500 Counter(290500) 290437
eval_Episode has 500 steps and return 246.8.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035037F809285-0ueRscxTY5uqvatDwARMGD-2aaoiAN8raaQUBXtZKjpz5-1024.npz
Starting evaluation at step 291000 Counter(291000) 290937
Saved chunk: 20230922T035053F800842-0sGSLLTQl3l8PvgKsoQSTC-6rmodbxHc1tEPbqj3fYwxX-1024.npz
eval_Episode has 500 steps and return 283.3.
train_Episode has 500 steps and return 283.1.
Starting evaluation at step 291500 Counter(291500) 291437
eval_Episode has 500 steps and return 307.3.
train_Episode has 500 steps and return 281.7.
Saved chunk: 20230922T035158F638165-2aaoiAN8raaQUBXtZKjpz5-1WwNozqtgEmBE10e03dQ4s-1024.npz
Starting evaluation at step 292000 Counter(292000) 291937
Saved chunk: 20230922T035213F009336-6rmodbxHc1tEPbqj3fYwxX-1HHEuW8xmywOaOyj250VNI-1024.npz
eval_Episode has 500 steps and return 281.4.
train_Episode has 500 steps and return 263.1.
Starting evaluation at step 292500 Counter(292500) 292437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 267.5.
Saved chunk: 20230922T035319F253112-1WwNozqtgEmBE10e03dQ4s-0wUrR5QcHwlm1VunSZSid5-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 585790 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 267.46 / episode/reward_rate 0.39 / train/action_mag 3.69 / train/action_max 3.63 / train/action_mean 0.04 / train/action_min -3.2 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -5.13 / train/adv_mag 0.79 / train/adv_max 0.74 / train/adv_mean 1.2e-3 / train/adv_min -0.34 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.75 
/ train/dyn_loss_std 6.67 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss
9998.04 / train/extr_critic_mag 209.46 / train/extr_critic_max 209.46 / train/extr_critic_mean 199.14 / train/extr_critic_min 141.71 / train/extr_critic_std 11.06 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.78
/ train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 210.03 / train/extr_return_raw_max 210.03 / train/extr_return_raw_mean 199.19 / train/extr_return_raw_min 153.85 / train/extr_return_raw_std 
11.01 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 1.06 / train/image_loss_std 0.96 / train/model_loss_mean 3.47 / train/model_loss_std 4.72 / 
train/model_opt_grad_norm 8.87 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.15 / train/policy_entropy_max 3.97 / 
train/policy_entropy_mean -2.29 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.11 / train/policy_logprob_mag 9.87 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.29 / train/policy_logprob_min -9.87 / train/policy_logprob_std 1.81 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 53.22 / train/post_ent_max 53.22 / train/post_ent_mean 40.85 / 
train/post_ent_min 21.76 / train/post_ent_std 5.02 / train/prior_ent_mag 84.75 / train/prior_ent_max 84.75 / train/prior_ent_mean 44.57 / train/prior_ent_min 27.33 / train/prior_ent_std 6.92 / train/rep_loss_mean 3.75 / train/rep_loss_std 6.67 / train/reward_avg 0.31 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.87 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.31 / train/reward_rate 
0.27 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -1.41 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 4.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.57 / report/dyn_loss_std 6.34 / report/image_loss_mean 0.99 / report/image_loss_std 0.87 / report/model_loss_mean 3.28 / report/model_loss_std 4.59 / report/post_ent_mag 56.06 / report/post_ent_max 56.06 /
report/post_ent_mean 41.38 / report/post_ent_min 21.02 / report/post_ent_std 4.42 / report/prior_ent_mag 84.86 / report/prior_ent_max 84.86 / report/prior_ent_mean 44.84 / report/prior_ent_min 28.16 / report/prior_ent_std 6.36 / report/rep_loss_mean 3.57 / 
report/rep_loss_std 6.34 / report/reward_avg 0.26 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.36 / report/reward_max_data 1.88 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 5.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.64 / report/reward_pred 0.26 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 5.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.81 / eval/dyn_loss_std 6.08 / eval/image_loss_mean 0.94 / eval/image_loss_std 0.95 / eval/model_loss_mean 3.47 / eval/model_loss_std 4.35 / eval/post_ent_mag 49.8 / eval/post_ent_max 49.8 / eval/post_ent_mean 
42.42 / eval/post_ent_min 26.99 / eval/post_ent_std 3.6 / eval/prior_ent_mag 84.86 / eval/prior_ent_max 84.86 / eval/prior_ent_mean 46.37 / eval/prior_ent_min 34.5 / eval/prior_ent_std 5.7 / eval/rep_loss_mean 3.81 / eval/rep_loss_std 6.08 / eval/reward_avg 0.59 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.59 / eval/reward_rate 0.45 / 
replay/size 2.9e5 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3816 / timer/env.step_total 20.01 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 452.39 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7323 / timer/agent.policy_total 16.56 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.8e-3 
/ timer/dataset_train_count 1908 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1908 / timer/agent.train_total 244.57 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.8e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 293000 Counter(293000) 292937
Saved chunk: 20230922T035332F023280-1HHEuW8xmywOaOyj250VNI-66ZjdXTjnK9cdzmqYh5YCu-1024.npz
eval_Episode has 500 steps and return 299.3.
train_Episode has 500 steps and return 258.0.
Starting evaluation at step 293500 Counter(293500) 293437
eval_Episode has 500 steps and return 280.9.
train_Episode has 500 steps and return 252.8.
Saved chunk: 20230922T035439F722222-0wUrR5QcHwlm1VunSZSid5-4H5ejOSinEgrMzWwTB41iH-1024.npz
Starting evaluation at step 294000 Counter(294000) 293937
Saved chunk: 20230922T035451F837115-66ZjdXTjnK9cdzmqYh5YCu-3814kx7PV7Trj8ulR0IrhF-1024.npz
eval_Episode has 500 steps and return 302.3.
train_Episode has 500 steps and return 256.9.
Starting evaluation at step 294500 Counter(294500) 294437
eval_Episode has 500 steps and return 284.0.
train_Episode has 500 steps and return 284.4.
Saved chunk: 20230922T035601F568028-4H5ejOSinEgrMzWwTB41iH-6iKkql4sg2Jp4GOFxo1h3l-1024.npz
Starting evaluation at step 295000 Counter(295000) 294937
Saved chunk: 20230922T035611F228623-3814kx7PV7Trj8ulR0IrhF-5fbZr4wz1TEeSFMT8lxWk2-1024.npz
eval_Episode has 500 steps and return 286.5.
train_Episode has 500 steps and return 284.1.
Starting evaluation at step 295500 Counter(295500) 295437
eval_Episode has 500 steps and return 289.9.
train_Episode has 500 steps and return 275.3.
Saved chunk: 20230922T035722F206761-6iKkql4sg2Jp4GOFxo1h3l-2VDU6aCUkARFhVcORnndvF-1024.npz
Starting evaluation at step 296000 Counter(296000) 295937
Saved chunk: 20230922T035730F247480-5fbZr4wz1TEeSFMT8lxWk2-1wQTcHVCjtaklZKCsY13rm-1024.npz
eval_Episode has 500 steps and return 301.1.
train_Episode has 500 steps and return 246.3.
Starting evaluation at step 296500 Counter(296500) 296437
eval_Episode has 500 steps and return 268.4.
train_Episode has 500 steps and return 280.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 593334 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 268.35 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 280.92 / episode/reward_rate 0.43 / train/action_mag 3.7 / train/action_max 3.62 / train/action_mean 0.05 / train/action_min -3.28 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -6.88 / train/adv_mag 0.7 / train/adv_max 0.65 / train/adv_mean 1.4e-3 / train/adv_min 
-0.32 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.74 / train/dyn_loss_std 6.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9651.84 / train/extr_critic_mag 209.82 / train/extr_critic_max 209.82 / train/extr_critic_mean 198.71 / train/extr_critic_min 132.76 / train/extr_critic_std 14.46 / train/extr_return_normed_mag 1.55 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 210.49 / train/extr_return_raw_max 210.49 / train/extr_return_raw_mean 198.77 / train/extr_return_raw_min 
140.48 / train/extr_return_raw_std 14.39 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.33 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.05 / train/image_loss_std 0.95 / train/model_loss_mean 3.45 
/ train/model_loss_std 4.74 / train/model_opt_grad_norm 8.61 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.25 / train/policy_entropy_max
4.09 / train/policy_entropy_mean -2.23 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.19 / train/policy_logprob_mag 9.93 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.23 / train/policy_logprob_min -9.93 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 3.2e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.61 / train/post_ent_max 52.61 / train/post_ent_mean 40.89 / 
train/post_ent_min 21.28 / train/post_ent_std 5.15 / train/prior_ent_mag 84.67 / train/prior_ent_max 84.67 / train/prior_ent_mean 44.61 / train/prior_ent_min 26.66 / train/prior_ent_std 7.05 / train/rep_loss_mean 3.74 / train/rep_loss_std 6.7 / train/reward_avg 0.31 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.31 / train/reward_rate 
0.27 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.42 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 2.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 7.09 / report/image_loss_mean 1.19 / report/image_loss_std 1.06 / report/model_loss_mean 3.73 / report/model_loss_std 5.01 / report/post_ent_mag 50.88 / report/post_ent_max 50.88 /
report/post_ent_mean 40.54 / report/post_ent_min 18.9 / report/post_ent_std 5.14 / report/prior_ent_mag 84.59 / report/prior_ent_max 84.59 / report/prior_ent_mean 44.55 / report/prior_ent_min 30.59 / report/prior_ent_std 6.95 / report/rep_loss_mean 3.99 / 
report/rep_loss_std 7.09 / report/reward_avg 0.31 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.29 / report/reward_max_data 1.85 / report/reward_max_pred 1.84 / report/reward_neg_acc 1 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.31 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.61 / eval/dyn_loss_std 7.27 / eval/image_loss_mean 1.2 / eval/image_loss_std 1.51 / eval/model_loss_mean 4.22 / eval/model_loss_std 5.58 / eval/post_ent_mag 50.23 / eval/post_ent_max 50.23 / eval/post_ent_mean 
42.12 / eval/post_ent_min 21.18 / eval/post_ent_std 4.35 / eval/prior_ent_mag 84.59 / eval/prior_ent_max 84.59 / eval/prior_ent_mean 46.36 / eval/prior_ent_min 32.14 / eval/prior_ent_std 5.75 / eval/rep_loss_mean 4.61 / eval/rep_loss_std 7.27 / eval/reward_avg 0.54 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.53 / eval/reward_rate 0.42 / 
replay/size 3e5 / replay/inserts 3772 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3772 / timer/env.step_total 19.72 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.69 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7780 / timer/agent.policy_total 17.44 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1886 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1886 / timer/agent.train_total 241.57 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.14

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T035849F146417-1wQTcHVCjtaklZKCsY13rm-0000000000000000000000-732.npz
Saved chunk: 20230922T035842F662185-2VDU6aCUkARFhVcORnndvF-0000000000000000000000-964.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T035842F662185-2VDU6aCUkARFhVcORnndvF-6PEqz1Po7EzK3kkKpcoNIW-1024.npz
Starting evaluation at step 297000 Counter(297000) 296937
Saved chunk: 20230922T035849F146417-1wQTcHVCjtaklZKCsY13rm-5YJPfKgcIMj7NfjQHmMzPC-1024.npz
eval_Episode has 500 steps and return 278.0.
train_Episode has 500 steps and return 258.9.
Starting evaluation at step 297500 Counter(297500) 297437
eval_Episode has 500 steps and return 278.3.
train_Episode has 500 steps and return 278.3.
Saved chunk: 20230922T040004F263195-6PEqz1Po7EzK3kkKpcoNIW-5YqNeZM27ZQNpNge6DWuDA-1024.npz
Starting evaluation at step 298000 Counter(298000) 297937
Saved chunk: 20230922T040009F182530-5YJPfKgcIMj7NfjQHmMzPC-0B9SXXUGhph1ORe6uUJpsy-1024.npz
eval_Episode has 500 steps and return 281.9.
train_Episode has 500 steps and return 287.7.
Starting evaluation at step 298500 Counter(298500) 298437
eval_Episode has 500 steps and return 311.1.
train_Episode has 500 steps and return 262.8.
Starting evaluation at step 299000 Counter(299000) 298937
Saved chunk: 20230922T040128F509729-0B9SXXUGhph1ORe6uUJpsy-6Y1uSfiQv8XH6jZNuaJ3yV-1024.npz
eval_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T040125F163888-5YqNeZM27ZQNpNge6DWuDA-6Atd68nMu1kcuVfCWkEI3Z-1024.npz
train_Episode has 500 steps and return 280.3.
Starting evaluation at step 299500 Counter(299500) 299437
eval_Episode has 500 steps and return 290.8.
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 300000 Counter(300000) 299937
Saved chunk: 20230922T040247F615117-6Y1uSfiQv8XH6jZNuaJ3yV-7Gfp5GBOX9Y8PWMcwv9ina-1024.npz
eval_Episode has 500 steps and return 278.3.
Saved chunk: 20230922T040249F394502-6Atd68nMu1kcuVfCWkEI3Z-2KiZwKnMURKvQUgrJWm9d6-1024.npz
train_Episode has 500 steps and return 262.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 600966 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 278.26 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 262.37 / episode/reward_rate 0.39 / train/action_mag 3.73 / train/action_max 3.65 / train/action_mean 0.04 / train/action_min -3.31 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -1.18 / train/adv_mag 0.42 / train/adv_max 0.37 / train/adv_mean 7.7e-4
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.77 / train/dyn_loss_std 6.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9413.22 / train/extr_critic_mag 210.05 / train/extr_critic_max 210.05 / train/extr_critic_mean 199.72 / train/extr_critic_min 149.97 / train/extr_critic_std 11.99 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 210.79 / train/extr_return_raw_max 210.79 / train/extr_return_raw_mean 199.76 / train/extr_return_raw_min 
151.09 / train/extr_return_raw_std 11.98 / train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.32 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.07 / train/image_loss_std 0.97 / train/model_loss_mean 3.48 
/ train/model_loss_std 4.75 / train/model_opt_grad_norm 8.59 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.42 / train/policy_entropy_max
4.33 / train/policy_entropy_mean -2.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.2 / train/policy_logprob_mag 10.01 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.15 / train/policy_logprob_min -10.01 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 3.2e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.84 / train/post_ent_max 52.84 / train/post_ent_mean 40.86 / 
train/post_ent_min 21.39 / train/post_ent_std 5.12 / train/prior_ent_mag 84.61 / train/prior_ent_max 84.61 / train/prior_ent_mean 44.6 / train/prior_ent_min 27.01 / train/prior_ent_std 6.99 / train/rep_loss_mean 3.77 / train/rep_loss_std 6.7 / train/reward_avg 0.31 / 
train/reward_loss_mean 0.15 / train/reward_loss_std 0.29 / train/reward_max_data 1.87 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.31 / train/reward_rate 
0.26 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.38 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 4.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.91 / report/dyn_loss_std 7.1 / report/image_loss_mean 1.1 / report/image_loss_std 1.15 / report/model_loss_mean 3.6 / report/model_loss_std 5.1 / report/post_ent_mag 51.44 / report/post_ent_max 51.44 / 
report/post_ent_mean 39.84 / report/post_ent_min 19.56 / report/post_ent_std 6.01 / report/prior_ent_mag 84.73 / report/prior_ent_max 84.73 / report/prior_ent_mean 43.55 / report/prior_ent_min 26.63 / report/prior_ent_std 7.86 / report/rep_loss_mean 3.91 / 
report/rep_loss_std 7.1 / report/reward_avg 0.31 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.28 / report/reward_max_data 1.89 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.31 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.81 / eval/dyn_loss_std 7.59 / eval/image_loss_mean 1.35 / eval/image_loss_std 1.86 / eval/model_loss_mean 4.45 / eval/model_loss_std 5.96 / eval/post_ent_mag 51.71 / eval/post_ent_max 51.71 / eval/post_ent_mean 
40.68 / eval/post_ent_min 20.37 / eval/post_ent_std 6.02 / eval/prior_ent_mag 84.73 / eval/prior_ent_max 84.73 / eval/prior_ent_mean 44.88 / eval/prior_ent_min 26.9 / eval/prior_ent_std 7.5 / eval/rep_loss_mean 4.81 / eval/rep_loss_std 7.59 / eval/reward_avg 0.47 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.47 / eval/reward_rate 0.38 / 
replay/size 3e5 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3816 / timer/env.step_total 19.91 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 465.59 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7323 / timer/agent.policy_total 16.79 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1908 / timer/agent.train_total 244.5 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 300500 Counter(300500) 300437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 297.2.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 301000 Counter(301000) 300937
Saved chunk: 20230922T040406F515164-7Gfp5GBOX9Y8PWMcwv9ina-1DaoNzIM3Uc15zWz4nyHpp-1024.npz
eval_Episode has 500 steps and return 287.0.
Saved chunk: 20230922T040409F842773-2KiZwKnMURKvQUgrJWm9d6-73osEmprMG6D4oforsxv9y-1024.npz
train_Episode has 500 steps and return 272.8.
Starting evaluation at step 301500 Counter(301500) 301437
eval_Episode has 500 steps and return 288.6.
train_Episode has 500 steps and return 268.5.
Starting evaluation at step 302000 Counter(302000) 301937
Saved chunk: 20230922T040526F607431-1DaoNzIM3Uc15zWz4nyHpp-4jKSFH1m1qzb26vdaYTEaz-1024.npz
eval_Episode has 500 steps and return 293.2.
Saved chunk: 20230922T040531F528193-73osEmprMG6D4oforsxv9y-7D1YOhsGc1YbHZpG60uaeR-1024.npz
train_Episode has 500 steps and return 277.8.
Starting evaluation at step 302500 Counter(302500) 302437
eval_Episode has 500 steps and return 287.0.
train_Episode has 500 steps and return 276.3.
Starting evaluation at step 303000 Counter(303000) 302937
eval_Episode has 500 steps and return 277.2.
Saved chunk: 20230922T040645F835407-4jKSFH1m1qzb26vdaYTEaz-5gM4ThuPYe9Ni8lyCMJeQ5-1024.npz
train_Episode has 500 steps and return 287.0.
Saved chunk: 20230922T040652F325378-7D1YOhsGc1YbHZpG60uaeR-31p6usWOgMIBPaD9uQL1Ng-1024.npz
Starting evaluation at step 303500 Counter(303500) 303437
eval_Episode has 500 steps and return 297.5.
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 304000 Counter(304000) 303937
eval_Episode has 500 steps and return 306.7.
Saved chunk: 20230922T040804F898868-5gM4ThuPYe9Ni8lyCMJeQ5-4XR1InzXkwkjJcJq1854VO-1024.npz
train_Episode has 500 steps and return 275.8.
Saved chunk: 20230922T040812F926517-31p6usWOgMIBPaD9uQL1Ng-5h2l3lp2qOIOePmGoqvemk-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 608502 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 306.7 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 275.83 / episode/reward_rate 0.42 / train/action_mag 3.78 / train/action_max 3.68 / train/action_mean 0.02 / train/action_min -3.43 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 3.27 / train/adv_mag 0.42 / train/adv_max 0.36 / train/adv_mean 2.9e-4 / train/adv_min 
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.71 / train/dyn_loss_std 6.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9238.94 / train/extr_critic_mag 210.13 / train/extr_critic_max 210.13 / train/extr_critic_mean 199 / train/extr_critic_min 137.86 / train/extr_critic_std 15.09 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 210.99 / train/extr_return_raw_max 210.99 / train/extr_return_raw_mean 199.02 / train/extr_return_raw_min 
140.61 / train/extr_return_raw_std 15.11 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.33 / train/extr_reward_min 0 / train/extr_reward_std 0.57 / train/image_loss_mean 1.04 / train/image_loss_std 0.94 / train/model_loss_mean 3.42 
/ train/model_loss_std 4.68 / train/model_opt_grad_norm 8.37 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.35 / train/policy_entropy_max
4.24 / train/policy_entropy_mean -2.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.29 / train/policy_logprob_mag 10.39 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.06 / train/policy_logprob_min -10.39 / train/policy_logprob_std 1.93 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 53 / train/post_ent_max 53 / train/post_ent_mean 40.84 / train/post_ent_min
21.17 / train/post_ent_std 5.22 / train/prior_ent_mag 84.6 / train/prior_ent_max 84.6 / train/prior_ent_mean 44.53 / train/prior_ent_min 26.61 / train/prior_ent_std 7.1 / train/rep_loss_mean 3.71 / train/rep_loss_std 6.63 / train/reward_avg 0.32 / train/reward_loss_mean
0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.32 / train/reward_rate 0.27 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -1.73 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 6.39 / report/image_loss_mean 1.04 / report/image_loss_std 0.8 / report/model_loss_mean 3.5 / report/model_loss_std 4.44 / report/post_ent_mag 52.38 / report/post_ent_max 52.38 / 
report/post_ent_mean 42.23 / report/post_ent_min 19.88 / report/post_ent_std 4.11 / report/prior_ent_mag 84.59 / report/prior_ent_max 84.59 / report/prior_ent_mean 46.06 / report/prior_ent_min 33.16 / report/prior_ent_std 5.73 / report/rep_loss_mean 3.82 / 
report/rep_loss_std 6.39 / report/reward_avg 0.36 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.32 / report/reward_max_data 1.87 / report/reward_max_pred 1.82 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.35 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 9.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.95 / eval/dyn_loss_std 7.38 / eval/image_loss_mean 1.48 / eval/image_loss_std 2.62 / eval/model_loss_mean 4.71 / eval/model_loss_std 6.46 / eval/post_ent_mag 50.46 / eval/post_ent_max 50.46 / eval/post_ent_mean 
41.59 / eval/post_ent_min 22.7 / eval/post_ent_std 4.83 / eval/prior_ent_mag 84.59 / eval/prior_ent_max 84.59 / eval/prior_ent_mean 46.09 / eval/prior_ent_min 30.69 / eval/prior_ent_std 5.93 / eval/rep_loss_mean 4.95 / eval/rep_loss_std 7.38 / eval/reward_avg 0.53 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.82 / eval/reward_max_pred 1.79 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.53 / eval/reward_rate 0.42 / 
replay/size 3e5 / replay/inserts 3768 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3768 / timer/env.step_total 19.69 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.52 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7776 / timer/agent.policy_total 17.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1884 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 6.2e-4 / timer/agent.train_count 1884 / timer/agent.train_total 241.56 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.11

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 304500 Counter(304500) 304437
eval_Episode has 500 steps and return 287.7.
train_Episode has 500 steps and return 276.6.
Starting evaluation at step 305000 Counter(305000) 304937
eval_Episode has 500 steps and return 306.1.
Saved chunk: 20230922T040923F896682-4XR1InzXkwkjJcJq1854VO-3NUMRlhxlpZHLja40Kh4W7-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040933F487331-5h2l3lp2qOIOePmGoqvemk-12xY7ggK9WKtXlo53J0bSk-1024.npz
Starting evaluation at step 305500 Counter(305500) 305437
eval_Episode has 500 steps and return 285.7.
train_Episode has 500 steps and return 265.2.
Starting evaluation at step 306000 Counter(306000) 305937
eval_Episode has 500 steps and return 291.9.
Saved chunk: 20230922T041044F166871-3NUMRlhxlpZHLja40Kh4W7-5JjW0oLcCu8OKhdbQymzms-1024.npz
train_Episode has 500 steps and return 271.4.
Saved chunk: 20230922T041055F350097-12xY7ggK9WKtXlo53J0bSk-6lvDJSntLBmsid2k9nNMuW-1024.npz
Starting evaluation at step 306500 Counter(306500) 306437
eval_Episode has 500 steps and return 282.8.
train_Episode has 500 steps and return 277.5.
Starting evaluation at step 307000 Counter(307000) 306937
eval_Episode has 500 steps and return 296.6.
train_Episode has 500 steps and return 270.3.
Saved chunk: 20230922T041216F223320-6lvDJSntLBmsid2k9nNMuW-3qJB1tx1m1GOAGb7MgEADq-1024.npz
Starting evaluation at step 307500 Counter(307500) 307437
Saved chunk: 20230922T041203F463633-5JjW0oLcCu8OKhdbQymzms-0n45olxQ7OGg6TwkChlYI3-1024.npz
eval_Episode has 500 steps and return 307.4.
train_Episode has 500 steps and return 285.1.
Starting evaluation at step 308000 Counter(308000) 307937
eval_Episode has 500 steps and return 306.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 616034 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 306.09 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 285.07 / episode/reward_rate 0.45 / train/action_mag 3.87 / train/action_max 3.75 / train/action_mean 0.03 / train/action_min -3.48 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 1.55 / train/adv_mag 0.5 / train/adv_max 0.45 / train/adv_mean 4.3e-4 
/ train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 9067.08 / train/extr_critic_mag 210.28 / train/extr_critic_max 210.28 / train/extr_critic_mean 199.55 / train/extr_critic_min 133.61 / train/extr_critic_std 14.52 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.03 /
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 211.21 / train/extr_return_raw_max 211.21 / train/extr_return_raw_mean 199.58 / train/extr_return_raw_min 
142.35 / train/extr_return_raw_std 14.53 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.04 / train/image_loss_std 0.95 / train/model_loss_mean 3.44 
/ train/model_loss_std 4.72 / train/model_opt_grad_norm 8.53 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.51 / train/policy_entropy_max
4.41 / train/policy_entropy_mean -1.96 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.33 / train/policy_logprob_mag 10.42 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 1.96 / train/policy_logprob_min -10.42 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.5e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.29 / train/post_ent_max 52.29 / train/post_ent_mean 40.94 / 
train/post_ent_min 21 / train/post_ent_std 5.24 / train/prior_ent_mag 84.56 / train/prior_ent_max 84.56 / train/prior_ent_mean 44.64 / train/prior_ent_min 26.11 / train/prior_ent_std 7.11 / train/rep_loss_mean 3.73 / train/rep_loss_std 6.68 / train/reward_avg 0.33 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.33 / train/reward_rate 
0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -1.21 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 7.6 / report/image_loss_mean 1.22 / report/image_loss_std 1.23 / report/model_loss_mean 3.62 / report/model_loss_std 5.38 / report/post_ent_mag 50.38 / report/post_ent_max 50.38 / 
report/post_ent_mean 39.41 / report/post_ent_min 19.62 / report/post_ent_std 5.52 / report/prior_ent_mag 84.46 / report/prior_ent_max 84.46 / report/prior_ent_mean 43.45 / report/prior_ent_min 27.06 / report/prior_ent_std 7.76 / report/rep_loss_mean 3.85 / 
report/rep_loss_std 7.6 / report/reward_avg 0.19 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.22 / report/reward_max_data 1.87 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.19 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.87 / eval/dyn_loss_std 6.01 / eval/image_loss_mean 0.96 / eval/image_loss_std 1.1 / eval/model_loss_mean 3.53 / eval/model_loss_std 4.39 / eval/post_ent_mag 50.34 / eval/post_ent_max 50.34 / eval/post_ent_mean 
42.27 / eval/post_ent_min 23.16 / eval/post_ent_std 3.97 / eval/prior_ent_mag 84.46 / eval/prior_ent_max 84.46 / eval/prior_ent_mean 46.39 / eval/prior_ent_min 27.86 / eval/prior_ent_std 5.63 / eval/rep_loss_mean 3.87 / eval/rep_loss_std 6.01 / eval/reward_avg 0.59 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.59 / eval/reward_rate 0.46 / 
replay/size 3.1e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3766 / timer/env.step_total 19.58 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.22 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.42 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.73 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 272.0.
Saved chunk: 20230922T041336F708597-3qJB1tx1m1GOAGb7MgEADq-6vhky0MaZRLoAT4xjyYrkA-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T041458F180138-6vhky0MaZRLoAT4xjyYrkA-0000000000000000000000-76.npz
Saved chunk: 20230922T041358F376658-0n45olxQ7OGg6TwkChlYI3-0000000000000000000000-991.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 308500 Counter(308500) 308437
Saved chunk: 20230922T041358F376658-0n45olxQ7OGg6TwkChlYI3-7njP4lO7NsWbQCyxPbf4Uq-1024.npz
eval_Episode has 500 steps and return 293.6.
train_Episode has 500 steps and return 287.9.
Starting evaluation at step 309000 Counter(309000) 308937
eval_Episode has 500 steps and return 292.7.
train_Episode has 500 steps and return 270.8.
Saved chunk: 20230922T041458F180138-6vhky0MaZRLoAT4xjyYrkA-1zTJISM1tqjgvylNN0Lw8x-1024.npz
Starting evaluation at step 309500 Counter(309500) 309437
Saved chunk: 20230922T041518F658917-7njP4lO7NsWbQCyxPbf4Uq-0YyQvaBmufy5DGHdkNhafO-1024.npz
eval_Episode has 500 steps and return 293.4.
train_Episode has 500 steps and return 274.1.
Starting evaluation at step 310000 Counter(310000) 309937
eval_Episode has 500 steps and return 302.0.
train_Episode has 500 steps and return 272.1.
Saved chunk: 20230922T041619F453846-1zTJISM1tqjgvylNN0Lw8x-4MdEGrjKBdhCEHuhFKKzWD-1024.npz
Starting evaluation at step 310500 Counter(310500) 310437
Saved chunk: 20230922T041637F971751-0YyQvaBmufy5DGHdkNhafO-7Mmvt8ICRhe3V04EoJslIL-1024.npz
eval_Episode has 500 steps and return 296.6.
train_Episode has 500 steps and return 265.5.
Starting evaluation at step 311000 Counter(311000) 310937
eval_Episode has 500 steps and return 295.7.
train_Episode has 500 steps and return 273.2.
Saved chunk: 20230922T041740F082751-4MdEGrjKBdhCEHuhFKKzWD-7hecn5zoLQTo6hiztKPa9z-1024.npz
Starting evaluation at step 311500 Counter(311500) 311437
Saved chunk: 20230922T041756F999524-7Mmvt8ICRhe3V04EoJslIL-5iPj2G5fRXkRW4EqWn33QJ-1024.npz
eval_Episode has 500 steps and return 299.5.
train_Episode has 500 steps and return 276.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 623662 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 276.87 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 299.46 / eval_episode/reward_rate 0.46 / train/action_mag 3.81 / train/action_max 3.71 / train/action_mean 0.03 / train/action_min -3.41 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss 0.74 / train/adv_mag 0.65 / train/adv_max 0.62 / train/adv_mean 5.3e-4 / train/adv_min 
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.5e5 / 
train/extr_critic_critic_opt_loss 8921.79 / train/extr_critic_mag 210.66 / train/extr_critic_max 210.66 / train/extr_critic_mean 199.59 / train/extr_critic_min 128.03 / train/extr_critic_std 15.03 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 211.46 / train/extr_return_raw_max 211.46 / train/extr_return_raw_mean 199.62 / train/extr_return_raw_min 
142.04 / train/extr_return_raw_std 15.02 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.04 / train/image_loss_std 0.95 / train/model_loss_mean 3.43 
/ train/model_loss_std 4.7 / train/model_opt_grad_norm 8.39 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.5 / train/policy_entropy_max 
4.4 / train/policy_entropy_mean -2.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.3 / train/policy_logprob_mag 10.41 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.41 / train/policy_logprob_std 1.94 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.5e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.63 / train/post_ent_max 52.63 / train/post_ent_mean 40.93 / 
train/post_ent_min 21.25 / train/post_ent_std 5.17 / train/prior_ent_mag 84.47 / train/prior_ent_max 84.47 / train/prior_ent_mean 44.63 / train/prior_ent_min 26.49 / train/prior_ent_std 7.08 / train/rep_loss_mean 3.73 / train/rep_loss_std 6.64 / train/reward_avg 0.32 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.86 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.32 / train/reward_rate 
0.27 / train_stats/mean_log_entropy -2.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.83 / report/dyn_loss_std 6.8 / report/image_loss_mean 1.11 / report/image_loss_std 1.01 / report/model_loss_mean 3.56 / report/model_loss_std 4.77 / report/post_ent_mag 53.98 / report/post_ent_max 53.98 / 
report/post_ent_mean 40.45 / report/post_ent_min 21.85 / report/post_ent_std 5.24 / report/prior_ent_mag 84.42 / report/prior_ent_max 84.42 / report/prior_ent_mean 44.32 / report/prior_ent_min 28.9 / report/prior_ent_std 7.05 / report/rep_loss_mean 3.83 / 
report/rep_loss_std 6.8 / report/reward_avg 0.35 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.28 / report/reward_max_data 1.89 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.35 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 5.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.69 / eval/dyn_loss_std 7.99 / eval/image_loss_mean 1.34 / eval/image_loss_std 2.09 / eval/model_loss_mean 4.38 / eval/model_loss_std 6.39 / eval/post_ent_mag 50.02 / eval/post_ent_max 50.02 / eval/post_ent_mean 
41.91 / eval/post_ent_min 23.38 / eval/post_ent_std 4.72 / eval/prior_ent_mag 84.42 / eval/prior_ent_max 84.42 / eval/prior_ent_mean 46.18 / eval/prior_ent_min 31.24 / eval/prior_ent_std 6.28 / eval/rep_loss_mean 4.69 / eval/rep_loss_std 7.99 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.83 / eval/reward_max_pred 1.8 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.55 / eval/reward_rate 0.42 / 
replay/size 3.1e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3814 / timer/env.step_total 19.79 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 459.18 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.3e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.63 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.68 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 312000 Counter(312000) 311937
eval_Episode has 500 steps and return 290.1.
train_Episode has 500 steps and return 274.2.
Saved chunk: 20230922T041900F525589-7hecn5zoLQTo6hiztKPa9z-4JZP2YI9mDuQPSmLa9Ddac-1024.npz
Starting evaluation at step 312500 Counter(312500) 312437
Saved chunk: 20230922T041915F870425-5iPj2G5fRXkRW4EqWn33QJ-0evd3eVAOv7IP7IR9U7MA9-1024.npz
eval_Episode has 500 steps and return 305.4.
train_Episode has 500 steps and return 292.4.
Starting evaluation at step 313000 Counter(313000) 312937
eval_Episode has 500 steps and return 271.9.
train_Episode has 500 steps and return 273.8.
Saved chunk: 20230922T042022F256802-4JZP2YI9mDuQPSmLa9Ddac-0D6h4mE0lmTJMOFdX9gNFn-1024.npz
Starting evaluation at step 313500 Counter(313500) 313437
Saved chunk: 20230922T042036F147235-0evd3eVAOv7IP7IR9U7MA9-3r1GhxO0SfIxaHnOXiZhEP-1024.npz
eval_Episode has 500 steps and return 287.1.
train_Episode has 500 steps and return 282.2.
Starting evaluation at step 314000 Counter(314000) 313937
eval_Episode has 500 steps and return 289.4.
train_Episode has 500 steps and return 264.9.
Saved chunk: 20230922T042143F185604-0D6h4mE0lmTJMOFdX9gNFn-27CWDcOPgoi1jljeuJdoky-1024.npz
Starting evaluation at step 314500 Counter(314500) 314437
Saved chunk: 20230922T042155F467730-3r1GhxO0SfIxaHnOXiZhEP-1KdVr6ZRgH4Qe2AUdjNEos-1024.npz
eval_Episode has 500 steps and return 280.8.
train_Episode has 500 steps and return 285.2.
Starting evaluation at step 315000 Counter(315000) 314937
eval_Episode has 500 steps and return 279.6.
train_Episode has 500 steps and return 276.1.
Saved chunk: 20230922T042303F858468-27CWDcOPgoi1jljeuJdoky-45xEyrVUocjNIKwr89Drd9-1024.npz
Starting evaluation at step 315500 Counter(315500) 315437
Saved chunk: 20230922T042314F503166-1KdVr6ZRgH4Qe2AUdjNEos-5M7Rd07V879cEjTsLnW3jS-1024.npz
eval_Episode has 500 steps and return 281.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 631190 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 281.24 / eval_episode/reward_rate 0.41 / episode/length 500 / episode/score 276.12 / episode/reward_rate 0.41 / train/action_mag 3.83 / train/action_max 3.74 / train/action_mean 0.03 / train/action_min -3.47 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 3.12 / train/adv_mag 0.56 / train/adv_max 0.52 / train/adv_mean 2.7e-4
/ train/adv_min -0.22 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 8778.35 / train/extr_critic_mag 211.32 / train/extr_critic_max 211.32 / train/extr_critic_mean 200.04 / train/extr_critic_min 130.01 / train/extr_critic_std 14.27 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.03 /
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 211.63 / train/extr_return_raw_max 211.63 / train/extr_return_raw_mean 200.05 / 
train/extr_return_raw_min 144.34 / train/extr_return_raw_std 14.27 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.04 / train/image_loss_std 0.94 / 
train/model_loss_mean 3.44 / train/model_loss_std 4.69 / train/model_opt_grad_norm 8.61 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.58
/ train/policy_entropy_max 4.5 / train/policy_entropy_mean -1.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.33 / train/policy_logprob_mag 10.36 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 1.94 / train/policy_logprob_min -10.36 / 
train/policy_logprob_std 1.96 / train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.7e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.25 / train/post_ent_max 52.25 / 
train/post_ent_mean 41.06 / train/post_ent_min 21.37 / train/post_ent_std 5.15 / train/prior_ent_mag 84.42 / train/prior_ent_max 84.42 / train/prior_ent_mean 44.76 / train/prior_ent_min 26.78 / train/prior_ent_std 6.97 / train/rep_loss_mean 3.73 / train/rep_loss_std 
6.64 / train/reward_avg 0.33 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.33 / train/reward_rate 0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.16 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.71 / report/dyn_loss_std 6.64 / report/image_loss_mean 0.94 / report/image_loss_std 0.81 / report/model_loss_mean 3.34 / report/model_loss_std 4.64 / 
report/post_ent_mag 50.7 / report/post_ent_max 50.7 / report/post_ent_mean 42.14 / report/post_ent_min 25.94 / report/post_ent_std 3.99 / report/prior_ent_mag 84.63 / report/prior_ent_max 84.63 / report/prior_ent_mean 45.86 / report/prior_ent_min 33.2 / 
report/prior_ent_std 5.92 / report/rep_loss_mean 3.71 / report/rep_loss_std 6.64 / report/reward_avg 0.36 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 1.92 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.36 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.72 / eval/dyn_loss_std 7.78 / eval/image_loss_mean 1.27 / eval/image_loss_std 1.8 / eval/model_loss_mean 4.32 / eval/model_loss_std 5.92 / eval/post_ent_mag 
50.53 / eval/post_ent_max 50.53 / eval/post_ent_mean 41.78 / eval/post_ent_min 14.81 / eval/post_ent_std 4.54 / eval/prior_ent_mag 84.63 / eval/prior_ent_max 84.63 / eval/prior_ent_mean 46.08 / eval/prior_ent_min 24.88 / eval/prior_ent_std 6.02 / eval/rep_loss_mean 4.72
/ eval/rep_loss_std 7.78 / eval/reward_avg 0.53 / eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.29 / eval/reward_max_data 1.85 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / 
eval/reward_pred 0.52 / eval/reward_rate 0.41 / replay/size 3.2e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3764 / timer/env.step_total 19.65
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.71 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
7.8e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.48 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.8e-4 / 
timer/agent.train_count 1882 / timer/agent.train_total 241.49 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / 
timer/dataset_eval_max 3.4e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 283.4.
Starting evaluation at step 316000 Counter(316000) 315937
eval_Episode has 500 steps and return 299.9.
train_Episode has 500 steps and return 279.1.
Saved chunk: 20230922T042424F240527-45xEyrVUocjNIKwr89Drd9-2rf1LoDkdavzpFEMVknxzR-1024.npz
Starting evaluation at step 316500 Counter(316500) 316437
Saved chunk: 20230922T042433F352400-5M7Rd07V879cEjTsLnW3jS-1JCzROp7hSFPotNfnjTtwG-1024.npz
eval_Episode has 500 steps and return 307.0.
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 317000 Counter(317000) 316937
eval_Episode has 500 steps and return 278.6.
train_Episode has 500 steps and return 247.6.
Saved chunk: 20230922T042546F026666-2rf1LoDkdavzpFEMVknxzR-1fjPviZV45EX0SviJqVkvf-1024.npz
Starting evaluation at step 317500 Counter(317500) 317437
Saved chunk: 20230922T042553F562135-1JCzROp7hSFPotNfnjTtwG-72SjEpgQrORYaioabxtt1O-1024.npz
eval_Episode has 500 steps and return 277.4.
train_Episode has 500 steps and return 264.6.
Starting evaluation at step 318000 Counter(318000) 317937
eval_Episode has 500 steps and return 286.6.
train_Episode has 500 steps and return 238.4.
Saved chunk: 20230922T042706F774526-1fjPviZV45EX0SviJqVkvf-30XGs4VYOkgHMtrZkHUmq3-1024.npz
Starting evaluation at step 318500 Counter(318500) 318437
Saved chunk: 20230922T042712F717897-72SjEpgQrORYaioabxtt1O-7krytKjZnaHfQEe31JYTXu-1024.npz
eval_Episode has 500 steps and return 284.9.
train_Episode has 500 steps and return 283.7.
Starting evaluation at step 319000 Counter(319000) 318937
eval_Episode has 500 steps and return 285.5.
train_Episode has 500 steps and return 265.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 638826 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 264.97 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 285.54 / eval_episode/reward_rate 0.43 / train/action_mag 3.73 / train/action_max 3.64 / train/action_mean 0.03 / train/action_min -3.35 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 2.07 / train/adv_mag 0.4 / train/adv_max 0.35 / train/adv_mean 4e-4 / 
train/adv_min -0.22 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.75 / train/dyn_loss_std 6.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 8560.92 / train/extr_critic_mag 212.22 / train/extr_critic_max 212.22 / train/extr_critic_mean 200.94 / train/extr_critic_min 147.5 / train/extr_critic_std 12.48 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 211.99 / train/extr_return_raw_max 211.99 / train/extr_return_raw_mean 200.96 / train/extr_return_raw_min 
152.27 / train/extr_return_raw_std 12.48 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.04 / train/image_loss_std 0.96 / train/model_loss_mean 3.45 
/ train/model_loss_std 4.74 / train/model_opt_grad_norm 8.7 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.44 / train/policy_entropy_max 
4.29 / train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 10.15 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2.04 / train/policy_logprob_min -10.15 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 3.6e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.62 / train/post_ent_max 52.62 / train/post_ent_mean 41.09 / 
train/post_ent_min 21.22 / train/post_ent_std 5.12 / train/prior_ent_mag 84.37 / train/prior_ent_max 84.37 / train/prior_ent_mean 44.82 / train/prior_ent_min 26.97 / train/prior_ent_std 6.96 / train/rep_loss_mean 3.75 / train/rep_loss_std 6.68 / train/reward_avg 0.33 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.33 / train/reward_rate 
0.28 / train_stats/mean_log_entropy -2.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 7.06 / report/image_loss_mean 1.12 / report/image_loss_std 1.09 / report/model_loss_mean 3.55 / report/model_loss_std 5.05 / report/post_ent_mag 57.1 / report/post_ent_max 57.1 / 
report/post_ent_mean 40.73 / report/post_ent_min 23.63 / report/post_ent_std 5.29 / report/prior_ent_mag 84.46 / report/prior_ent_max 84.46 / report/prior_ent_mean 44.64 / report/prior_ent_min 30.76 / report/prior_ent_std 7.08 / report/rep_loss_mean 3.85 / 
report/rep_loss_std 7.06 / report/reward_avg 0.26 / report/reward_loss_mean 0.12 / report/reward_loss_std 0.26 / report/reward_max_data 1.94 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 3.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.26 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 9.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.98 / eval/dyn_loss_std 7.51 / eval/image_loss_mean 1.53 / eval/image_loss_std 2.69 / eval/model_loss_mean 4.77 / eval/model_loss_std 6.6 / eval/post_ent_mag 51.01 / eval/post_ent_max 51.01 / eval/post_ent_mean 41.69 / 
eval/post_ent_min 21.54 / eval/post_ent_std 4.79 / eval/prior_ent_mag 84.46 / eval/prior_ent_max 84.46 / eval/prior_ent_mean 46.21 / eval/prior_ent_min 28.51 / eval/prior_ent_std 6.08 / eval/rep_loss_mean 4.98 / eval/rep_loss_std 7.51 / eval/reward_avg 0.51 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.51 / eval/reward_rate 0.39 / 
replay/size 3.2e5 / replay/inserts 3818 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3818 / timer/env.step_total 19.83 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 448.98 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7325 / timer/agent.policy_total 16.52 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1909 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.3e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1909 / timer/agent.train_total 244.8 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.45

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T042827F361025-30XGs4VYOkgHMtrZkHUmq3-3NRGxd4bB8Y0pgzt6qIceK-1024.npz
Starting evaluation at step 319500 Counter(319500) 319437
Saved chunk: 20230922T042831F713587-7krytKjZnaHfQEe31JYTXu-6XaLj39PB2x6NhDDGR72jD-1024.npz
eval_Episode has 500 steps and return 288.6.
train_Episode has 500 steps and return 277.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T042948F744310-3NRGxd4bB8Y0pgzt6qIceK-0000000000000000000000-212.npz
Saved chunk: 20230922T042951F571263-6XaLj39PB2x6NhDDGR72jD-0000000000000000000000-226.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 320000 Counter(320000) 319937
eval_Episode has 500 steps and return 292.8.
train_Episode has 500 steps and return 245.9.
Starting evaluation at step 320500 Counter(320500) 320437
Saved chunk: 20230922T042951F571263-6XaLj39PB2x6NhDDGR72jD-1ovim77Yvb7thJKEkojSP7-1024.npz
eval_Episode has 500 steps and return 299.6.
Saved chunk: 20230922T042948F744310-3NRGxd4bB8Y0pgzt6qIceK-0IONUFLmV59qL4DA86ni1m-1024.npz
train_Episode has 500 steps and return 285.3.
Starting evaluation at step 321000 Counter(321000) 320937
eval_Episode has 500 steps and return 306.3.
train_Episode has 500 steps and return 265.7.
Starting evaluation at step 321500 Counter(321500) 321437
Saved chunk: 20230922T043111F111813-1ovim77Yvb7thJKEkojSP7-6QyV8bgl2ypmLaINMy0JtZ-1024.npz
eval_Episode has 500 steps and return 302.6.
Saved chunk: 20230922T043113F478861-0IONUFLmV59qL4DA86ni1m-2LSnxzgQFApANViM5ZrN7j-1024.npz
train_Episode has 500 steps and return 248.8.
Starting evaluation at step 322000 Counter(322000) 321937
eval_Episode has 500 steps and return 306.9.
train_Episode has 500 steps and return 274.4.
Starting evaluation at step 322500 Counter(322500) 322437
Saved chunk: 20230922T043230F310738-6QyV8bgl2ypmLaINMy0JtZ-7i7ZYCUoaUp3WAnsSmAQrq-1024.npz
eval_Episode has 500 steps and return 309.3.
Saved chunk: 20230922T043234F185547-2LSnxzgQFApANViM5ZrN7j-3A7w1nIgkdEYxtst41MA6Q-1024.npz
train_Episode has 500 steps and return 279.6.
Starting evaluation at step 323000 Counter(323000) 322937
eval_Episode has 500 steps and return 294.7.
train_Episode has 500 steps and return 286.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 646358 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 294.72 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 286.34 / episode/reward_rate 0.43 / train/action_mag 3.79 / train/action_max 3.72 / train/action_mean 0.03 / train/action_min -3.38 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 1.2 / train/adv_mag 0.35 / train/adv_max 0.3 / train/adv_mean 4.9e-4 /
train/adv_min -0.2 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.73 / train/dyn_loss_std 6.62 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 8349.23 / train/extr_critic_mag 212.76 / train/extr_critic_max 212.76 / train/extr_critic_mean 200.64 / train/extr_critic_min 139.41 / train/extr_critic_std 14.62 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 212.39 / train/extr_return_raw_max 212.39 / train/extr_return_raw_mean 200.66 / train/extr_return_raw_min
143.66 / train/extr_return_raw_std 14.63 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.02 / train/image_loss_std 0.94 / train/model_loss_mean 3.42 
/ train/model_loss_std 4.68 / train/model_opt_grad_norm 8.41 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.45 / train/policy_entropy_max
4.31 / train/policy_entropy_mean -2.05 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.3 / train/policy_logprob_mag 10.33 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.05 / train/policy_logprob_min -10.33 / train/policy_logprob_std 1.94 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 3.4e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.6 / train/post_ent_max 52.6 / train/post_ent_mean 41.07 / 
train/post_ent_min 21.35 / train/post_ent_std 5.22 / train/prior_ent_mag 84.34 / train/prior_ent_max 84.34 / train/prior_ent_mean 44.78 / train/prior_ent_min 26.71 / train/prior_ent_std 7.06 / train/rep_loss_mean 3.73 / train/rep_loss_std 6.62 / train/reward_avg 0.34 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.3 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.34 / train/reward_rate 
0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.27 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.98 / report/dyn_loss_std 7 / report/image_loss_mean 1.13 / report/image_loss_std 1.08 / report/model_loss_mean 3.7 / report/model_loss_std 5.04 / report/post_ent_mag 51.34 / report/post_ent_max 51.34 / 
report/post_ent_mean 41.08 / report/post_ent_min 18.84 / report/post_ent_std 6.39 / report/prior_ent_mag 84.48 / report/prior_ent_max 84.48 / report/prior_ent_mean 45.13 / report/prior_ent_min 21.52 / report/prior_ent_std 7.92 / report/rep_loss_mean 3.98 / 
report/rep_loss_std 7 / report/reward_avg 0.38 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.33 / report/reward_max_data 1.91 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.38 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.86 / eval/dyn_loss_std 6.15 / eval/image_loss_mean 0.95 / eval/image_loss_std 1.15 / eval/model_loss_mean 3.52 / eval/model_loss_std 4.51 / eval/post_ent_mag 49.8 / eval/post_ent_max 49.8 / eval/post_ent_mean 
42.51 / eval/post_ent_min 22.9 / eval/post_ent_std 3.65 / eval/prior_ent_mag 84.48 / eval/prior_ent_max 84.48 / eval/prior_ent_mean 46.3 / eval/prior_ent_min 27.81 / eval/prior_ent_std 5.58 / eval/rep_loss_mean 3.86 / eval/rep_loss_std 6.15 / eval/reward_avg 0.59 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.58 / eval/reward_rate 0.45 / 
replay/size 3.2e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3766 / timer/env.step_total 19.58 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.51 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.6 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.45 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 323500 Counter(323500) 323437
eval_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T043349F126327-7i7ZYCUoaUp3WAnsSmAQrq-7zHRGRzQWbozGvdfdBsdAO-1024.npz
Saved chunk: 20230922T043354F615702-3A7w1nIgkdEYxtst41MA6Q-4tho5kUwHuJtcVZqH8MBke-1024.npz
train_Episode has 500 steps and return 217.6.
Starting evaluation at step 324000 Counter(324000) 323937
eval_Episode has 500 steps and return 300.3.
train_Episode has 500 steps and return 274.9.
Starting evaluation at step 324500 Counter(324500) 324437
eval_Episode has 500 steps and return 306.9.
Saved chunk: 20230922T043509F181010-7zHRGRzQWbozGvdfdBsdAO-6sYe7v2EfzcyamGyOAYWL6-1024.npz
Saved chunk: 20230922T043516F271956-4tho5kUwHuJtcVZqH8MBke-0iYLF7TcM5xSz5HrafDE32-1024.npz
train_Episode has 500 steps and return 253.9.
Starting evaluation at step 325000 Counter(325000) 324937
eval_Episode has 500 steps and return 291.0.
train_Episode has 500 steps and return 254.8.
Starting evaluation at step 325500 Counter(325500) 325437
eval_Episode has 500 steps and return 297.5.
Saved chunk: 20230922T043628F530103-6sYe7v2EfzcyamGyOAYWL6-0K6ZABL8ECxEkt8LFnkG7g-1024.npz
Saved chunk: 20230922T043637F104932-0iYLF7TcM5xSz5HrafDE32-4NPAN0YOgyoGt9lx3NQz5e-1024.npz
train_Episode has 500 steps and return 290.4.
Starting evaluation at step 326000 Counter(326000) 325937
eval_Episode has 500 steps and return 287.3.
train_Episode has 500 steps and return 276.2.
Starting evaluation at step 326500 Counter(326500) 326437
Saved chunk: 20230922T043747F475754-0K6ZABL8ECxEkt8LFnkG7g-7EJfK8Z6p67keULb3E2uSP-1024.npz
eval_Episode has 500 steps and return 297.1.
train_Episode has 500 steps and return 292.7.
Saved chunk: 20230922T043757F607925-4NPAN0YOgyoGt9lx3NQz5e-18gEsNrKhtqDYsM7SXwsXd-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 653998 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 297.14 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 292.72 / episode/reward_rate 0.42 / train/action_mag 3.8 / train/action_max 3.7 / train/action_mean 0.03 / train/action_min -3.43 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 2.07 / train/adv_mag 0.5 / train/adv_max 0.47 / train/adv_mean 3.9e-4 / train/adv_min 
-0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.74 / train/dyn_loss_std 6.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.6e5 / 
train/extr_critic_critic_opt_loss 8166.48 / train/extr_critic_mag 212.94 / train/extr_critic_max 212.94 / train/extr_critic_mean 200.86 / train/extr_critic_min 134.88 / train/extr_critic_std 14.55 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 212.66 / train/extr_return_raw_max 212.66 / train/extr_return_raw_mean 200.88 / train/extr_return_raw_min 
143.63 / train/extr_return_raw_std 14.56 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 1.03 / train/image_loss_std 0.96 / train/model_loss_mean 3.43 
/ train/model_loss_std 4.73 / train/model_opt_grad_norm 8.55 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.63 / train/policy_entropy_max
4.53 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.46 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.46 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.4e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 52.34 / train/post_ent_max 52.34 / train/post_ent_mean 41.1 / 
train/post_ent_min 21.16 / train/post_ent_std 5.2 / train/prior_ent_mag 84.3 / train/prior_ent_max 84.3 / train/prior_ent_mean 44.79 / train/prior_ent_min 26.3 / train/prior_ent_std 7.05 / train/rep_loss_mean 3.74 / train/rep_loss_std 6.66 / train/reward_avg 0.33 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.57 / train/reward_pred 0.33 / train/reward_rate 
0.28 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.23 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 6.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.01 / report/dyn_loss_std 7.27 / report/image_loss_mean 1.14 / report/image_loss_std 1.08 / report/model_loss_mean 3.71 / report/model_loss_std 5.17 / report/post_ent_mag 51.96 / report/post_ent_max 51.96 /
report/post_ent_mean 41.86 / report/post_ent_min 20.2 / report/post_ent_std 4.96 / report/prior_ent_mag 84.07 / report/prior_ent_max 84.07 / report/prior_ent_mean 45.75 / report/prior_ent_min 23.83 / report/prior_ent_std 6.68 / report/rep_loss_mean 4.01 / 
report/rep_loss_std 7.27 / report/reward_avg 0.34 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.29 / report/reward_max_data 1.8 / report/reward_max_pred 1.79 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.34 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.24 / eval/dyn_loss_std 6.93 / eval/image_loss_mean 1.1 / eval/image_loss_std 1.69 / eval/model_loss_mean 3.9 / eval/model_loss_std 5.39 / eval/post_ent_mag 50.41 / eval/post_ent_max 50.41 / eval/post_ent_mean 
42.29 / eval/post_ent_min 22.46 / eval/post_ent_std 4.07 / eval/prior_ent_mag 84.07 / eval/prior_ent_max 84.07 / eval/prior_ent_mean 46.2 / eval/prior_ent_min 29.15 / eval/prior_ent_std 5.9 / eval/rep_loss_mean 4.24 / eval/rep_loss_std 6.93 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.86 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.61 / eval/reward_rate 0.48 / 
replay/size 3.3e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.6e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3820 / timer/env.step_total 19.92 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 456.66 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7327 / timer/agent.policy_total 16.42 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 
/ timer/dataset_train_count 1910 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1910 / timer/agent.train_total 244.75 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.46

Starting evaluation at step 327000 Counter(327000) 326937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 295.2.
train_Episode has 500 steps and return 273.1.
Starting evaluation at step 327500 Counter(327500) 327437
eval_Episode has 500 steps and return 311.3.
Saved chunk: 20230922T043906F254637-7EJfK8Z6p67keULb3E2uSP-7DEoLRXztbNw5zbQ1Pa2TC-1024.npz
train_Episode has 500 steps and return 271.3.
Saved chunk: 20230922T043917F950684-18gEsNrKhtqDYsM7SXwsXd-6RjqqSbvLrNP0xbOxVYMB3-1024.npz
Starting evaluation at step 328000 Counter(328000) 327937
eval_Episode has 500 steps and return 300.5.
train_Episode has 500 steps and return 280.3.
Starting evaluation at step 328500 Counter(328500) 328437
eval_Episode has 500 steps and return 293.2.
Saved chunk: 20230922T044026F605823-7DEoLRXztbNw5zbQ1Pa2TC-1ni7n99z0kCikZMbJCsDms-1024.npz
train_Episode has 500 steps and return 283.7.
Saved chunk: 20230922T044040F048393-6RjqqSbvLrNP0xbOxVYMB3-2Drt85sDcxJNKIw3eb6ld2-1024.npz
Starting evaluation at step 329000 Counter(329000) 328937
eval_Episode has 500 steps and return 303.4.
train_Episode has 500 steps and return 258.0.
Starting evaluation at step 329500 Counter(329500) 329437
eval_Episode has 500 steps and return 297.5.
Saved chunk: 20230922T044146F096550-1ni7n99z0kCikZMbJCsDms-3Yn8hXETfNm1D48cD3fGlP-1024.npz
train_Episode has 500 steps and return 263.8.
Saved chunk: 20230922T044200F968557-2Drt85sDcxJNKIw3eb6ld2-1BK1ZhhwGEOoTkRm7jWUVW-1024.npz
Starting evaluation at step 330000 Counter(330000) 329937
eval_Episode has 500 steps and return 299.6.
train_Episode has 500 steps and return 260.6.
Starting evaluation at step 330500 Counter(330500) 330437
eval_Episode has 500 steps and return 286.3.
train_Episode has 500 steps and return 275.0.
Saved chunk: 20230922T044321F781017-1BK1ZhhwGEOoTkRm7jWUVW-2t4kdSv1QOD1qjeyLxMDoj-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 661514 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 286.34 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 275 / episode/reward_rate 0.39 / eval_stats/mean_log_entropy 0 / train/action_mag 3.86 / train/action_max 3.76 / train/action_mean 0.03 / 
train/action_min -3.5 / train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss 0.1 / train/adv_mag 0.51 / train/adv_max 0.46 
/ train/adv_mean 5.8e-4 / train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.72 / train/dyn_loss_std 6.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 7912.33 / train/extr_critic_mag 212.96 / train/extr_critic_max 212.96 / train/extr_critic_mean 200.83 / train/extr_critic_min 129.51 / train/extr_critic_std 15.94 / 
train/extr_return_normed_mag 1.5 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 212.79 / train/extr_return_raw_max 
212.79 / train/extr_return_raw_mean 200.86 / train/extr_return_raw_min 134.02 / train/extr_return_raw_std 15.95 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / 
train/image_loss_mean 1.02 / train/image_loss_std 0.94 / train/model_loss_mean 3.41 / train/model_loss_std 4.67 / train/model_opt_grad_norm 8.21 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.71 / train/policy_entropy_max 4.65 / train/policy_entropy_mean -1.96 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.71 / train/policy_logprob_max 5.47 / 
train/policy_logprob_mean 1.96 / train/policy_logprob_min -10.71 / train/policy_logprob_std 2.01 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.6e-4 / train/policy_randomness_std 
0.15 / train/post_ent_mag 52.49 / train/post_ent_max 52.49 / train/post_ent_mean 41.19 / train/post_ent_min 21.09 / train/post_ent_std 5.17 / train/prior_ent_mag 84.14 / train/prior_ent_max 84.14 / train/prior_ent_mean 44.89 / train/prior_ent_min 26.51 / 
train/prior_ent_std 6.98 / train/rep_loss_mean 3.72 / train/rep_loss_std 6.59 / train/reward_avg 0.34 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 
3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.34 / train/reward_rate 0.28 / train_stats/mean_log_entropy -2.2 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 8.5e-11 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.82 / report/dyn_loss_std 6.58 / report/image_loss_mean 0.96 / report/image_loss_std 0.74 / report/model_loss_mean 3.44 / 
report/model_loss_std 4.53 / report/post_ent_mag 54.71 / report/post_ent_max 54.71 / report/post_ent_mean 42.74 / report/post_ent_min 20.15 / report/post_ent_std 4.25 / report/prior_ent_mag 84.31 / report/prior_ent_max 84.31 / report/prior_ent_mean 46.49 / 
report/prior_ent_min 31.57 / report/prior_ent_std 5.9 / report/rep_loss_mean 3.82 / report/rep_loss_std 6.58 / report/reward_avg 0.36 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.33 / report/reward_max_data 1.94 / report/reward_max_pred 1.88 / 
report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.36 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 9.7e-11 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.37 / eval/dyn_loss_std 6.71 / eval/image_loss_mean 1.17 / eval/image_loss_std 1.53 / eval/model_loss_mean 4.04 / eval/model_loss_std 
5.03 / eval/post_ent_mag 50.22 / eval/post_ent_max 50.22 / eval/post_ent_mean 41.65 / eval/post_ent_min 19.93 / eval/post_ent_std 5.14 / eval/prior_ent_mag 84.31 / eval/prior_ent_max 84.31 / eval/prior_ent_mean 45.84 / eval/prior_ent_min 26.06 / eval/prior_ent_std 6.48 
/ eval/rep_loss_mean 4.37 / eval/rep_loss_std 6.71 / eval/reward_avg 0.57 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.88 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.4e-3 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.56 / eval/reward_pred 0.56 / eval/reward_rate 0.42 / replay/size 3.3e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3758 / 
timer/env.step_total 19.51 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 448.83 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01
/ timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7766 / timer/agent.policy_total 18.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 2.8e-4 / 
timer/agent.train_count 1879 / timer/agent.train_total 240.66 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.15 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 
4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / 
timer/dataset_eval_max 3.1e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 331000 Counter(331000) 330937
Saved chunk: 20230922T044305F372159-3Yn8hXETfNm1D48cD3fGlP-7L5w9bqW7rYglYdhW6OuTb-1024.npz
eval_Episode has 500 steps and return 284.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T044442F297689-2t4kdSv1QOD1qjeyLxMDoj-0000000000000000000000-348.npz
Saved chunk: 20230922T044501F274893-7L5w9bqW7rYglYdhW6OuTb-0000000000000000000000-485.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 267.8.
Starting evaluation at step 331500 Counter(331500) 331437
eval_Episode has 500 steps and return 298.2.
train_Episode has 500 steps and return 291.0.
Saved chunk: 20230922T044442F297689-2t4kdSv1QOD1qjeyLxMDoj-3IuByPtAm5SGN671gC3MMp-1024.npz
Starting evaluation at step 332000 Counter(332000) 331937
Saved chunk: 20230922T044501F274893-7L5w9bqW7rYglYdhW6OuTb-1lLEuX55T1XgH8ygqAuNMJ-1024.npz
eval_Episode has 500 steps and return 305.6.
train_Episode has 500 steps and return 290.6.
Starting evaluation at step 332500 Counter(332500) 332437
eval_Episode has 500 steps and return 301.0.
train_Episode has 500 steps and return 264.0.
Saved chunk: 20230922T044604F591857-3IuByPtAm5SGN671gC3MMp-62AyFngf7dK2hwAm2HkuXd-1024.npz
Starting evaluation at step 333000 Counter(333000) 332937
Saved chunk: 20230922T044621F047722-1lLEuX55T1XgH8ygqAuNMJ-1hB6UsdvmfPnFohfIhResX-1024.npz
eval_Episode has 500 steps and return 282.4.
train_Episode has 500 steps and return 266.4.
Starting evaluation at step 333500 Counter(333500) 333437
eval_Episode has 500 steps and return 287.4.
train_Episode has 500 steps and return 276.1.
Saved chunk: 20230922T044725F516180-62AyFngf7dK2hwAm2HkuXd-7fz7WBjjY9JxWGPaH71RE8-1024.npz
Starting evaluation at step 334000 Counter(334000) 333937
Saved chunk: 20230922T044740F323872-1hB6UsdvmfPnFohfIhResX-2A3AXsxANhFClPvcvvUQFd-1024.npz
eval_Episode has 500 steps and return 308.7.
train_Episode has 500 steps and return 286.3.
Starting evaluation at step 334500 Counter(334500) 334437
eval_Episode has 500 steps and return 276.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 669026 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 276.9 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 286.25 / episode/reward_rate 0.43 / train/action_mag 3.85 / train/action_max 3.72 / train/action_mean 0.02 / train/action_min -3.52 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 0.25 / train/adv_mag 0.52 / train/adv_max 0.48 / train/adv_mean 5.4e-4 / train/adv_min 
-0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.72 / train/dyn_loss_std 6.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 7859.22 / train/extr_critic_mag 212.81 / train/extr_critic_max 212.81 / train/extr_critic_mean 201.5 / train/extr_critic_min 136.96 / train/extr_critic_std 13.79 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 212.86 / train/extr_return_raw_max 212.86 / train/extr_return_raw_mean 201.53 / train/extr_return_raw_min 
144.93 / train/extr_return_raw_std 13.77 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.35 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.02 / train/image_loss_std 0.93 / train/model_loss_mean 3.41 
/ train/model_loss_std 4.66 / train/model_opt_grad_norm 8.67 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9281.91 / train/policy_entropy_mag 4.79 / 
train/policy_entropy_max 4.77 / train/policy_entropy_mean -1.89 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.44 / train/policy_logprob_mag 10.8 / train/policy_logprob_max 5.46 / train/policy_logprob_mean 1.89 / train/policy_logprob_min -10.8 / 
train/policy_logprob_std 2.03 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 3.8e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 52.39 / train/post_ent_max 52.39 / 
train/post_ent_mean 41.28 / train/post_ent_min 21.42 / train/post_ent_std 5.04 / train/prior_ent_mag 84.14 / train/prior_ent_max 84.14 / train/prior_ent_mean 44.97 / train/prior_ent_min 27.11 / train/prior_ent_std 6.88 / train/rep_loss_mean 3.72 / train/rep_loss_std 
6.59 / train/reward_avg 0.34 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.88 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.34 / train/reward_rate 0.29 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.19 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.57 / report/dyn_loss_std 6.32 / report/image_loss_mean 0.89 / report/image_loss_std 0.79 / report/model_loss_mean 3.18 / report/model_loss_std 4.39 / 
report/post_ent_mag 53.74 / report/post_ent_max 53.74 / report/post_ent_mean 41.47 / report/post_ent_min 22.73 / report/post_ent_std 4.86 / report/prior_ent_mag 84.1 / report/prior_ent_max 84.1 / report/prior_ent_mean 45.22 / report/prior_ent_min 29.34 / 
report/prior_ent_std 6.69 / report/rep_loss_mean 3.57 / report/rep_loss_std 6.32 / report/reward_avg 0.34 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.27 / report/reward_max_data 1.91 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / 
report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / report/reward_pred 0.34 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.11 / eval/dyn_loss_std 6.43 / eval/image_loss_mean 1.08 / eval/image_loss_std 1.4 / eval/model_loss_mean 3.78 / eval/model_loss_std 4.88 / eval/post_ent_mag 50.07
/ eval/post_ent_max 50.07 / eval/post_ent_mean 42.23 / eval/post_ent_min 20.4 / eval/post_ent_std 4.21 / eval/prior_ent_mag 84.1 / eval/prior_ent_max 84.1 / eval/prior_ent_mean 46.24 / eval/prior_ent_min 26.75 / eval/prior_ent_std 5.9 / eval/rep_loss_mean 4.11 / 
eval/rep_loss_std 6.43 / eval/reward_avg 0.58 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.85 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.55 / 
eval/reward_pred 0.57 / eval/reward_rate 0.43 / replay/size 3.3e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3756 / timer/env.step_total 19.53
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.65 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
1.2e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7764 / timer/agent.policy_total 
17.6 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.33 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9e-8 / 
timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 300.7.
Saved chunk: 20230922T044846F200644-7fz7WBjjY9JxWGPaH71RE8-4ZjaTs9wRNxf7cnOpKcMu3-1024.npz
Starting evaluation at step 335000 Counter(335000) 334937
Saved chunk: 20230922T044859F423707-2A3AXsxANhFClPvcvvUQFd-4d6xDPRu8YHJJZoXThP3Fv-1024.npz
eval_Episode has 500 steps and return 286.8.
train_Episode has 500 steps and return 279.6.
Starting evaluation at step 335500 Counter(335500) 335437
eval_Episode has 500 steps and return 279.5.
train_Episode has 500 steps and return 291.8.
Saved chunk: 20230922T045007F870592-4ZjaTs9wRNxf7cnOpKcMu3-6RB06GFkHzGxaYd27V1dVQ-1024.npz
Starting evaluation at step 336000 Counter(336000) 335937
Saved chunk: 20230922T045019F622848-4d6xDPRu8YHJJZoXThP3Fv-1D4nmsoSai8Kv3jDa979p3-1024.npz
eval_Episode has 500 steps and return 279.1.
train_Episode has 500 steps and return 287.5.
Starting evaluation at step 336500 Counter(336500) 336437
eval_Episode has 500 steps and return 307.5.
train_Episode has 500 steps and return 276.8.
Saved chunk: 20230922T045128F939991-6RB06GFkHzGxaYd27V1dVQ-1X4j21plOyJFF8f7yPjoJ8-1024.npz
Starting evaluation at step 337000 Counter(337000) 336937
Saved chunk: 20230922T045139F069791-1D4nmsoSai8Kv3jDa979p3-7iz78BhV6UHrsgaBBlJaJZ-1024.npz
eval_Episode has 500 steps and return 289.4.
train_Episode has 500 steps and return 295.2.
Starting evaluation at step 337500 Counter(337500) 337437
eval_Episode has 500 steps and return 290.3.
train_Episode has 500 steps and return 247.1.
Saved chunk: 20230922T045249F773873-1X4j21plOyJFF8f7yPjoJ8-4tX2wMXmQWYmcc1ijHIfQQ-1024.npz
Starting evaluation at step 338000 Counter(338000) 337937
Saved chunk: 20230922T045258F306618-7iz78BhV6UHrsgaBBlJaJZ-36A7W3iPkTfqGYlDtLqCMn-1024.npz
eval_Episode has 500 steps and return 304.6.
train_Episode has 500 steps and return 264.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 676642 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 264.25 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 304.56 / eval_episode/reward_rate 0.45 / train/action_mag 3.78 / train/action_max 3.69 / train/action_mean 0.03 / train/action_min -3.43 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 1.13 / train/adv_mag 0.36 / train/adv_max 0.3 / train/adv_mean 4.7e-4 
/ train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.71 / train/dyn_loss_std 6.58 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 7596.88 / train/extr_critic_mag 212.81 / train/extr_critic_max 212.81 / train/extr_critic_mean 202.23 / train/extr_critic_min 153.11 / train/extr_critic_std 12.12 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 213.09 / train/extr_return_raw_max 213.09 / train/extr_return_raw_mean 202.25 / train/extr_return_raw_min 
153.91 / train/extr_return_raw_std 12.16 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / train/extr_reward_std 0.59 / train/image_loss_mean 1.02 / train/image_loss_std 0.96 / train/model_loss_mean 3.41 
/ train/model_loss_std 4.67 / train/model_opt_grad_norm 7.97 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 2.8e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8089.01 / train/policy_entropy_mag 4.79 / 
train/policy_entropy_max 4.77 / train/policy_entropy_mean -1.96 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.39 / train/policy_logprob_mag 10.66 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.96 / train/policy_logprob_min -10.66 / 
train/policy_logprob_std 2 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3.4e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 52.31 / train/post_ent_max 52.31 / 
train/post_ent_mean 41.33 / train/post_ent_min 21.28 / train/post_ent_std 5.09 / train/prior_ent_mag 84.15 / train/prior_ent_max 84.15 / train/prior_ent_mean 45.02 / train/prior_ent_min 26.72 / train/prior_ent_std 6.89 / train/rep_loss_mean 3.71 / train/rep_loss_std 
6.58 / train/reward_avg 0.34 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.9 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.34 / train/reward_rate 0.29 / train_stats/mean_log_entropy -2.27 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc
1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.39 / report/dyn_loss_std 6.04 / report/image_loss_mean 0.9 / report/image_loss_std 0.71 / report/model_loss_mean 3.07 / report/model_loss_std 4.14 / report/post_ent_mag 
55.58 / report/post_ent_max 55.58 / report/post_ent_mean 40.87 / report/post_ent_min 22.91 / report/post_ent_std 4.94 / report/prior_ent_mag 84.03 / report/prior_ent_max 84.03 / report/prior_ent_mean 44.15 / report/prior_ent_min 28.18 / report/prior_ent_std 6.82 / 
report/rep_loss_mean 3.39 / report/rep_loss_std 6.04 / report/reward_avg 0.28 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.29 / report/reward_max_data 1.89 / report/reward_max_pred 1.91 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.28 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 8.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.68 / eval/dyn_loss_std 7.5 / eval/image_loss_mean 1.28 / eval/image_loss_std 2.05 / eval/model_loss_mean 4.3 / eval/model_loss_std 5.98 / eval/post_ent_mag 51.86 / eval/post_ent_max 
51.86 / eval/post_ent_mean 41.68 / eval/post_ent_min 20.41 / eval/post_ent_std 4.76 / eval/prior_ent_mag 84.03 / eval/prior_ent_max 84.03 / eval/prior_ent_mean 45.98 / eval/prior_ent_min 26.4 / eval/prior_ent_std 5.98 / eval/rep_loss_mean 4.68 / eval/rep_loss_std 7.5 / 
eval/reward_avg 0.49 / eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.52 / eval/reward_pred 0.49 / 
eval/reward_rate 0.38 / replay/size 3.4e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3808 / timer/env.step_total 19.79 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.14 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / 
timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.75 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.16 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1904 / 
timer/agent.train_total 244.42 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 338500 Counter(338500) 338437
eval_Episode has 500 steps and return 292.2.
train_Episode has 500 steps and return 273.2.
Saved chunk: 20230922T045410F498953-4tX2wMXmQWYmcc1ijHIfQQ-2hEVCMlfHFG5ANtuxc6a7M-1024.npz
Starting evaluation at step 339000 Counter(339000) 338937
Saved chunk: 20230922T045417F439062-36A7W3iPkTfqGYlDtLqCMn-03n3zz6LFe58CWLauQb3hn-1024.npz
eval_Episode has 500 steps and return 287.4.
train_Episode has 500 steps and return 267.1.
Starting evaluation at step 339500 Counter(339500) 339437
eval_Episode has 500 steps and return 301.9.
train_Episode has 500 steps and return 274.0.
Saved chunk: 20230922T045532F342163-2hEVCMlfHFG5ANtuxc6a7M-6pRee4DJDFuNSM7CdxsHNd-1024.npz
Starting evaluation at step 340000 Counter(340000) 339937
Saved chunk: 20230922T045537F752358-03n3zz6LFe58CWLauQb3hn-39yrI4YwXRd7B0bsKnPYv2-1024.npz
eval_Episode has 500 steps and return 291.4.
train_Episode has 500 steps and return 279.1.
Starting evaluation at step 340500 Counter(340500) 340437
eval_Episode has 500 steps and return 305.9.
train_Episode has 500 steps and return 277.6.
Saved chunk: 20230922T045653F247052-6pRee4DJDFuNSM7CdxsHNd-4UayCDV3t1bUawUcpixwpQ-1024.npz
Starting evaluation at step 341000 Counter(341000) 340937
Saved chunk: 20230922T045657F072588-39yrI4YwXRd7B0bsKnPYv2-7tqTAO2IJYSzhXczSWuBbq-1024.npz
eval_Episode has 500 steps and return 291.8.
train_Episode has 500 steps and return 264.4.
Starting evaluation at step 341500 Counter(341500) 341437
eval_Episode has 500 steps and return 295.8.
train_Episode has 500 steps and return 288.1.
Starting evaluation at step 342000 Counter(342000) 341937
Saved chunk: 20230922T045816F079693-7tqTAO2IJYSzhXczSWuBbq-1xC2P3jA6kB5noMzW3a2nV-1024.npz
eval_Episode has 500 steps and return 278.2.
Saved chunk: 20230922T045813F860252-4UayCDV3t1bUawUcpixwpQ-1CpDAN5RyR5Ane12gLrCf9-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 684174 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 278.18 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 288.1 / episode/reward_rate 0.43 / train/action_mag 3.77 / train/action_max 3.66 / train/action_mean 0.03 / train/action_min -3.42 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 2.2 / train/adv_mag 0.32 / train/adv_max 0.27 / train/adv_mean 3.8e-4 / train/adv_min 
-0.22 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.69 / train/dyn_loss_std 6.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 7295.51 / train/extr_critic_mag 212.95 / train/extr_critic_max 212.95 / train/extr_critic_mean 202.38 / train/extr_critic_min 148.23 / train/extr_critic_std 13.03 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.26 / train/extr_return_rate 1 / train/extr_return_raw_mag 213.29 / train/extr_return_raw_max 213.29 / train/extr_return_raw_mean 202.39 / train/extr_return_raw_min 
148.93 / train/extr_return_raw_std 13.05 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 1 / train/image_loss_std 0.94 / train/model_loss_mean 3.38 / 
train/model_loss_std 4.63 / train/model_opt_grad_norm 8.4 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.56 / train/policy_entropy_max 
4.5 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.36 / train/policy_logprob_mag 10.42 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.42 / train/policy_logprob_std 1.97 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 52.27 / train/post_ent_max 52.27 / train/post_ent_mean 41.49 / 
train/post_ent_min 21.81 / train/post_ent_std 5.03 / train/prior_ent_mag 84.08 / train/prior_ent_max 84.08 / train/prior_ent_mean 45.17 / train/prior_ent_min 27.08 / train/prior_ent_std 6.84 / train/rep_loss_mean 3.69 / train/rep_loss_std 6.52 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.89 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.35 / train/reward_rate 
0.29 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.29 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.13 / report/dyn_loss_std 5.91 / report/image_loss_mean 0.8 / report/image_loss_std 0.76 / report/model_loss_mean 2.84 / report/model_loss_std 4.13 / report/post_ent_mag 50.8 / report/post_ent_max 50.8 / 
report/post_ent_mean 39.85 / report/post_ent_min 19.64 / report/post_ent_std 7.95 / report/prior_ent_mag 84.1 / report/prior_ent_max 84.1 / report/prior_ent_mean 43.04 / report/prior_ent_min 20.15 / report/prior_ent_std 9.63 / report/rep_loss_mean 3.13 / 
report/rep_loss_std 5.91 / report/reward_avg 0.31 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.3 / report/reward_max_data 1.91 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.31 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 9.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.77 / eval/dyn_loss_std 6.1 / eval/image_loss_mean 0.91 / eval/image_loss_std 1.02 / eval/model_loss_mean 3.41 / eval/model_loss_std 4.41 / eval/post_ent_mag 50.89 / eval/post_ent_max 50.89 / eval/post_ent_mean 
42.67 / eval/post_ent_min 21.82 / eval/post_ent_std 3.9 / eval/prior_ent_mag 84.1 / eval/prior_ent_max 84.1 / eval/prior_ent_mean 46.38 / eval/prior_ent_min 26.93 / eval/prior_ent_std 5.61 / eval/rep_loss_mean 3.77 / eval/rep_loss_std 6.1 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.83 / eval/reward_max_pred 1.84 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.58 / eval/reward_rate 0.43 / 
replay/size 3.4e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3766 / timer/env.step_total 19.55 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 1e-2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.89 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.5e-4 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.5 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.5 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 283.5.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 342500 Counter(342500) 342437
Saved chunk: 20230922T045934F917864-1xC2P3jA6kB5noMzW3a2nV-0000000000000000000000-243.npz
Saved chunk: 20230922T045937F810108-1CpDAN5RyR5Ane12gLrCf9-0000000000000000000000-484.npz
eval_Episode has 500 steps and return 294.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 289.7.
Starting evaluation at step 343000 Counter(343000) 342937
Saved chunk: 20230922T045934F917864-1xC2P3jA6kB5noMzW3a2nV-2EnURpGYsWm1uf17gSOIlO-1024.npz
eval_Episode has 500 steps and return 299.7.
Saved chunk: 20230922T045937F810108-1CpDAN5RyR5Ane12gLrCf9-3iQue6q69C54oD8XFX7JLC-1024.npz
train_Episode has 500 steps and return 257.6.
Starting evaluation at step 343500 Counter(343500) 343437
eval_Episode has 500 steps and return 279.7.
train_Episode has 500 steps and return 278.9.
Starting evaluation at step 344000 Counter(344000) 343937
Saved chunk: 20230922T050055F567811-2EnURpGYsWm1uf17gSOIlO-53bh95bCcYGe3iOLRZ51fQ-1024.npz
eval_Episode has 500 steps and return 291.1.
Saved chunk: 20230922T050100F069010-3iQue6q69C54oD8XFX7JLC-72j0uDCrc9ngw5QtoxhrB7-1024.npz
train_Episode has 500 steps and return 270.0.
Starting evaluation at step 344500 Counter(344500) 344437
eval_Episode has 500 steps and return 305.8.
train_Episode has 500 steps and return 278.5.
Starting evaluation at step 345000 Counter(345000) 344937
Saved chunk: 20230922T050216F299033-53bh95bCcYGe3iOLRZ51fQ-2QofrqDU0t9wqlU0aPAW8y-1024.npz
eval_Episode has 500 steps and return 297.1.
Saved chunk: 20230922T050222F326472-72j0uDCrc9ngw5QtoxhrB7-3GguczQ1Ru3lutVs3z8xXc-1024.npz
train_Episode has 500 steps and return 274.2.
Starting evaluation at step 345500 Counter(345500) 345437
eval_Episode has 500 steps and return 282.2.
train_Episode has 500 steps and return 282.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 691758 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 282.81 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 282.22 / eval_episode/reward_rate 0.42 / train/action_mag 3.85 / train/action_max 3.77 / train/action_mean 0.03 / train/action_min -3.35 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -12.87 / train/adv_mag 0.45 / train/adv_max 0.39 / train/adv_mean 
1.9e-3 / train/adv_min -0.27 / train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / 
train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 7438.46 / train/extr_critic_mag 213.19 / train/extr_critic_max 213.19 / train/extr_critic_mean 201.81 / train/extr_critic_min 144.15 / train/extr_critic_std 14.72 / 
train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 213.58 / train/extr_return_raw_max 
213.58 / train/extr_return_raw_mean 201.9 / train/extr_return_raw_min 145.1 / train/extr_return_raw_std 14.59 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / 
train/image_loss_mean 1.01 / train/image_loss_std 0.95 / train/model_loss_mean 3.39 / train/model_loss_std 4.66 / train/model_opt_grad_norm 8.29 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.22 / train/policy_entropy_max 4.05 / train/policy_entropy_mean -2.03 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 10.19 / train/policy_logprob_max 5.47 /
train/policy_logprob_mean 2.03 / train/policy_logprob_min -10.19 / train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 
0.15 / train/post_ent_mag 52.36 / train/post_ent_max 52.36 / train/post_ent_mean 41.2 / train/post_ent_min 21.25 / train/post_ent_std 5.21 / train/prior_ent_mag 83.98 / train/prior_ent_max 83.98 / train/prior_ent_mean 44.88 / train/prior_ent_min 26.58 / 
train/prior_ent_std 7 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.57 / train/reward_avg 0.34 / train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.89 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 /
train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.34 / train/reward_rate 0.28 / train_stats/mean_log_entropy -2.28 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 1.4e-10 / 
report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.54 / report/dyn_loss_std 6.29 / report/image_loss_mean 0.91 / report/image_loss_std 0.79 / 
report/model_loss_mean 3.22 / report/model_loss_std 4.37 / report/post_ent_mag 51.5 / report/post_ent_max 51.5 / report/post_ent_mean 42.15 / report/post_ent_min 24.9 / report/post_ent_std 4.13 / report/prior_ent_mag 83.8 / report/prior_ent_max 83.8 / 
report/prior_ent_mean 45.61 / report/prior_ent_min 30.54 / report/prior_ent_std 6.14 / report/rep_loss_mean 3.54 / report/rep_loss_std 6.29 / report/reward_avg 0.39 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.29 / report/reward_max_data 1.76 / 
report/reward_max_pred 1.78 / report/reward_neg_acc 1 / report/reward_neg_loss 6.7e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.39 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1e-10 /
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.41 / eval/dyn_loss_std 7.45 / eval/image_loss_mean 1.17 / eval/image_loss_std 1.78 / eval/model_loss_mean 4.06 
/ eval/model_loss_std 5.9 / eval/post_ent_mag 50.26 / eval/post_ent_max 50.26 / eval/post_ent_mean 41.86 / eval/post_ent_min 20.86 / eval/post_ent_std 4.5 / eval/prior_ent_mag 83.8 / eval/prior_ent_max 83.8 / eval/prior_ent_mean 45.99 / eval/prior_ent_min 32.42 / 
eval/prior_ent_std 5.76 / eval/rep_loss_mean 4.41 / eval/rep_loss_std 7.45 / eval/reward_avg 0.58 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.85 / eval/reward_max_pred 1.82 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / 
eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.58 / eval/reward_rate 0.45 / replay/size 3.5e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3792 / timer/env.step_total 19.71 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.37 / timer/replay._sample_frac 1.49 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7299 / timer/agent.policy_total 16.64 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1896 / timer/agent.train_total 244.59 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 1.67 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 2.1e-5 / timer/dataset_eval_frac 7.2e-8 / timer/dataset_eval_avg 2.1e-5 / timer/dataset_eval_min 2.1e-5 / timer/dataset_eval_max 2.1e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 346000 Counter(346000) 345937
Saved chunk: 20230922T050335F170442-2QofrqDU0t9wqlU0aPAW8y-1MmGgGEL1IDhB835DINjaF-1024.npz
eval_Episode has 500 steps and return 289.2.
Saved chunk: 20230922T050342F717995-3GguczQ1Ru3lutVs3z8xXc-3GLPv0HG5vNIKcRgaPTrwn-1024.npz
train_Episode has 500 steps and return 271.6.
Starting evaluation at step 346500 Counter(346500) 346437
eval_Episode has 500 steps and return 290.2.
train_Episode has 500 steps and return 293.5.
Starting evaluation at step 347000 Counter(347000) 346937
Saved chunk: 20230922T050455F059061-1MmGgGEL1IDhB835DINjaF-3zNqgZkCQXJrj0fjapnSxM-1024.npz
eval_Episode has 500 steps and return 281.9.
Saved chunk: 20230922T050504F228437-3GLPv0HG5vNIKcRgaPTrwn-2rHeNXqF7Icjb6SyMVDGVn-1024.npz
train_Episode has 500 steps and return 287.0.
Starting evaluation at step 347500 Counter(347500) 347437
eval_Episode has 500 steps and return 291.9.
train_Episode has 500 steps and return 271.2.
Starting evaluation at step 348000 Counter(348000) 347937
Saved chunk: 20230922T050614F359613-3zNqgZkCQXJrj0fjapnSxM-1Mw9dS5cUyLYz9rRQN0rFH-1024.npz
eval_Episode has 500 steps and return 286.9.
Saved chunk: 20230922T050625F075830-2rHeNXqF7Icjb6SyMVDGVn-3Phsq1d1xLnZuxPX4slARf-1024.npz
train_Episode has 500 steps and return 249.6.
Starting evaluation at step 348500 Counter(348500) 348437
eval_Episode has 500 steps and return 315.4.
train_Episode has 500 steps and return 260.0.
Starting evaluation at step 349000 Counter(349000) 348937
Saved chunk: 20230922T050733F425163-1Mw9dS5cUyLYz9rRQN0rFH-3NCQUioAqRGD7ioDE32ADz-1024.npz
eval_Episode has 500 steps and return 282.7.
Saved chunk: 20230922T050745F722056-3Phsq1d1xLnZuxPX4slARf-01iLpmaxmhcw9xsWQXyhPb-1024.npz
train_Episode has 500 steps and return 270.1.
Starting evaluation at step 349500 Counter(349500) 349437
eval_Episode has 500 steps and return 290.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 699298 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 290.76 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 270.07 / episode/reward_rate 0.4 / train/action_mag 3.78 / train/action_max 3.69 / train/action_mean 0.03 / train/action_min -3.3 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss 0.86 / train/adv_mag 0.35 / train/adv_max 0.26 / train/adv_mean 5.6e-4 / train/adv_min 
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.64 / train/dyn_loss_std 6.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.7e5 / 
train/extr_critic_critic_opt_loss 7226.22 / train/extr_critic_mag 213.52 / train/extr_critic_max 213.52 / train/extr_critic_mean 202.66 / train/extr_critic_min 150.42 / train/extr_critic_std 13.2 / train/extr_return_normed_mag 1.51 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 213.86 / train/extr_return_raw_max 213.86 / train/extr_return_raw_mean 202.69 / train/extr_return_raw_min 
151.3 / train/extr_return_raw_std 13.23 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.36 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 0.98 / train/image_loss_std 0.91 / train/model_loss_mean 3.33 / 
train/model_loss_std 4.6 / train/model_opt_grad_norm 8.53 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.15 / train/policy_entropy_max 
3.83 / train/policy_entropy_mean -2.15 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.26 / train/policy_logprob_mag 10.02 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.16 / train/policy_logprob_min -10.02 / train/policy_logprob_std 1.91 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.41 / train/post_ent_max 52.41 / train/post_ent_mean 41.2 / 
train/post_ent_min 21.17 / train/post_ent_std 5.2 / train/prior_ent_mag 83.94 / train/prior_ent_max 83.94 / train/prior_ent_mean 44.82 / train/prior_ent_min 26.54 / train/prior_ent_std 7.01 / train/rep_loss_mean 3.64 / train/rep_loss_std 6.52 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.89 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.34 / train/reward_rate 
0.29 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.32 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.73 / report/dyn_loss_std 6.27 / report/image_loss_mean 0.95 / report/image_loss_std 0.92 / report/model_loss_mean 3.38 / report/model_loss_std 4.53 / report/post_ent_mag 55.98 / report/post_ent_max 55.98 /
report/post_ent_mean 41.06 / report/post_ent_min 21.53 / report/post_ent_std 5.36 / report/prior_ent_mag 84 / report/prior_ent_max 84 / report/prior_ent_mean 44.78 / report/prior_ent_min 28.24 / report/prior_ent_std 7.24 / report/rep_loss_mean 3.73 / report/rep_loss_std
6.27 / report/reward_avg 0.42 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.32 / report/reward_max_data 1.92 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 9.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / 
report/reward_pred 0.42 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 6.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 4.45 / eval/dyn_loss_std 7.56 / eval/image_loss_mean 1.25 / eval/image_loss_std 1.78 / eval/model_loss_mean 4.16 / eval/model_loss_std 5.82 / eval/post_ent_mag 49.79 / eval/post_ent_max 49.79 / eval/post_ent_mean 41.51 / eval/post_ent_min 20.66 / 
eval/post_ent_std 4.97 / eval/prior_ent_mag 84 / eval/prior_ent_max 84 / eval/prior_ent_mean 45.69 / eval/prior_ent_min 26.73 / eval/prior_ent_std 6.64 / eval/rep_loss_mean 4.45 / eval/rep_loss_std 7.56 / eval/reward_avg 0.57 / eval/reward_loss_mean 0.24 / 
eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.56 / eval/reward_rate 0.43 / replay/size 3.5e5 / 
replay/inserts 3770 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3770 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 
4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 442.08 / timer/replay._sample_frac 1.47 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7778 / timer/agent.policy_total 17.5 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 
1885 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1885 / timer/agent.train_total 241.67 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 275.1.
Starting evaluation at step 350000 Counter(350000) 349937
eval_Episode has 500 steps and return 285.7.
Saved chunk: 20230922T050852F291757-3NCQUioAqRGD7ioDE32ADz-12F5S0rwcRgXqmxfD6qOYd-1024.npz
train_Episode has 500 steps and return 256.7.
Saved chunk: 20230922T050906F099666-01iLpmaxmhcw9xsWQXyhPb-6chXrEIQkG7ZH15izP5ljp-1024.npz
Starting evaluation at step 350500 Counter(350500) 350437
eval_Episode has 500 steps and return 299.8.
train_Episode has 500 steps and return 261.5.
Starting evaluation at step 351000 Counter(351000) 350937
eval_Episode has 500 steps and return 305.2.
Saved chunk: 20230922T051012F264153-12F5S0rwcRgXqmxfD6qOYd-3ymB4PO3zU6KyR8NZ7pB0V-1024.npz
train_Episode has 500 steps and return 271.3.
Saved chunk: 20230922T051027F847617-6chXrEIQkG7ZH15izP5ljp-4UjupHvugnEXIflWT514gq-1024.npz
Starting evaluation at step 351500 Counter(351500) 351437
eval_Episode has 500 steps and return 275.3.
train_Episode has 500 steps and return 272.4.
Starting evaluation at step 352000 Counter(352000) 351937
eval_Episode has 500 steps and return 310.3.
Saved chunk: 20230922T051131F675473-3ymB4PO3zU6KyR8NZ7pB0V-6r8WdmpLpr8lEDYbRamGNd-1024.npz
train_Episode has 500 steps and return 268.7.
Saved chunk: 20230922T051148F698060-4UjupHvugnEXIflWT514gq-5FqIJiuOWSbi4wIr62H5fj-1024.npz
Starting evaluation at step 352500 Counter(352500) 352437
eval_Episode has 500 steps and return 305.3.
train_Episode has 500 steps and return 286.2.
Starting evaluation at step 353000 Counter(353000) 352937
eval_Episode has 500 steps and return 314.8.
Saved chunk: 20230922T051250F781685-6r8WdmpLpr8lEDYbRamGNd-6PIXkfzadkdtQmezte6euy-1024.npz
train_Episode has 500 steps and return 259.2.
Saved chunk: 20230922T051309F356677-5FqIJiuOWSbi4wIr62H5fj-5ief6YHVA8vrhxmInEXD8H-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 706926 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 259.17 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 314.8 / eval_episode/reward_rate 0.48 / train/action_mag 3.76 / train/action_max 3.67 / train/action_mean 0.03 / train/action_min -3.29 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 2.04 / train/adv_mag 0.39 / train/adv_max 0.3 / train/adv_mean 4.7e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.56 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6941.86 / train/extr_critic_mag 213.82 / train/extr_critic_max 213.82 / train/extr_critic_mean 204.02 / train/extr_critic_min 158.96 / train/extr_critic_std 10.94 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.05 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 214.2 / train/extr_return_raw_max 214.2 / train/extr_return_raw_mean 204.04 / train/extr_return_raw_min 
158.91 / train/extr_return_raw_std 10.99 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.99 / train/image_loss_std 0.95 / train/model_loss_mean 3.39 
/ train/model_loss_std 4.66 / train/model_opt_grad_norm 8.55 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.16 / train/policy_entropy_max
3.63 / train/policy_entropy_mean -2.24 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.18 / train/policy_logprob_mag 9.99 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.24 / train/policy_logprob_min -9.99 / train/policy_logprob_std 1.86 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.13 / train/post_ent_max 52.13 / train/post_ent_mean 41.43 / 
train/post_ent_min 21.22 / train/post_ent_std 5.11 / train/prior_ent_mag 83.9 / train/prior_ent_max 83.9 / train/prior_ent_mean 45.11 / train/prior_ent_min 26.65 / train/prior_ent_std 6.88 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.56 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.36 / train/reward_rate 
0.3 / train_stats/mean_log_entropy -2.37 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 9.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.33 / report/dyn_loss_std 5.9 / report/image_loss_mean 0.8 / report/image_loss_std 0.78 / report/model_loss_mean 3.01 / report/model_loss_std 4.18 / report/post_ent_mag 50.78 / report/post_ent_max 50.78 / 
report/post_ent_mean 41.13 / report/post_ent_min 19.82 / report/post_ent_std 6.39 / report/prior_ent_mag 84.02 / report/prior_ent_max 84.02 / report/prior_ent_mean 44.61 / report/prior_ent_min 21.7 / report/prior_ent_std 8.02 / report/rep_loss_mean 3.33 / 
report/rep_loss_std 5.9 / report/reward_avg 0.45 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.33 / report/reward_max_data 1.93 / report/reward_max_pred 1.89 / report/reward_neg_acc 1 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.45 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 9.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.79 / eval/dyn_loss_std 5.98 / eval/image_loss_mean 0.93 / eval/image_loss_std 1.02 / eval/model_loss_mean 3.48 / eval/model_loss_std 4.33 / eval/post_ent_mag 50.42 / eval/post_ent_max 50.42 / eval/post_ent_mean 
42.17 / eval/post_ent_min 17.21 / eval/post_ent_std 4.42 / eval/prior_ent_mag 84.02 / eval/prior_ent_max 84.02 / eval/prior_ent_mean 46.04 / eval/prior_ent_min 23.62 / eval/prior_ent_std 5.9 / eval/rep_loss_mean 3.79 / eval/rep_loss_std 5.98 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.6 / eval/reward_rate 0.48 / 
replay/size 3.5e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3814 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.61 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.77 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.2e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 353500 Counter(353500) 353437
eval_Episode has 500 steps and return 293.3.
train_Episode has 500 steps and return 274.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T051409F775543-6PIXkfzadkdtQmezte6euy-0000000000000000000000-502.npz
Saved chunk: 20230922T051429F860290-5ief6YHVA8vrhxmInEXD8H-0000000000000000000000-620.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 354000 Counter(354000) 353937
eval_Episode has 500 steps and return 308.6.
train_Episode has 500 steps and return 279.3.
Saved chunk: 20230922T051429F860290-5ief6YHVA8vrhxmInEXD8H-2rF3HFfy7vrYItxqVFzIIP-1024.npz
Starting evaluation at step 354500 Counter(354500) 354437
Saved chunk: 20230922T051409F775543-6PIXkfzadkdtQmezte6euy-38tdKVFL9MsIBR3wCIX2vo-1024.npz
eval_Episode has 500 steps and return 312.8.
train_Episode has 500 steps and return 270.1.
Starting evaluation at step 355000 Counter(355000) 354937
eval_Episode has 500 steps and return 306.5.
train_Episode has 500 steps and return 290.3.
Saved chunk: 20230922T051551F903328-2rF3HFfy7vrYItxqVFzIIP-0QasG1ozsEtfT7oWv0pmAW-1024.npz
Starting evaluation at step 355500 Counter(355500) 355437
Saved chunk: 20230922T051606F173755-38tdKVFL9MsIBR3wCIX2vo-6b8bfk7ezZSMbAdB8jBzHs-1024.npz
eval_Episode has 500 steps and return 308.2.
train_Episode has 500 steps and return 274.6.
Starting evaluation at step 356000 Counter(356000) 355937
eval_Episode has 500 steps and return 314.3.
train_Episode has 500 steps and return 284.0.
Saved chunk: 20230922T051712F662942-0QasG1ozsEtfT7oWv0pmAW-6g50lhBH8E2ElVESUxcaie-1024.npz
Starting evaluation at step 356500 Counter(356500) 356437
Saved chunk: 20230922T051725F344823-6b8bfk7ezZSMbAdB8jBzHs-2v5bWAQDTFwqEk2owNm3Jz-1024.npz
eval_Episode has 500 steps and return 269.1.
train_Episode has 500 steps and return 281.5.
Starting evaluation at step 357000 Counter(357000) 356937
eval_Episode has 500 steps and return 290.3.
train_Episode has 500 steps and return 277.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 714458 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 290.3 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 277.32 / episode/reward_rate 0.41 / train/action_mag 3.78 / train/action_max 3.71 / train/action_mean 0.03 / train/action_min -3.26 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 0.87 / train/adv_mag 0.44 / train/adv_max 0.38 / train/adv_mean 5.6e-4 / train/adv_min 
-0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 6.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6908.82 / train/extr_critic_mag 214.16 / train/extr_critic_max 214.16 / train/extr_critic_mean 203.32 / train/extr_critic_min 151.13 / train/extr_critic_std 13.16 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 214.49 / train/extr_return_raw_max 214.49 / train/extr_return_raw_mean 203.34 / train/extr_return_raw_min 
153.84 / train/extr_return_raw_std 13.2 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 0.99 / train/image_loss_std 0.93 / train/model_loss_mean 3.36 / 
train/model_loss_std 4.63 / train/model_opt_grad_norm 8.19 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.19 / train/policy_entropy_max 
3.83 / train/policy_entropy_mean -2.17 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 9.99 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.17 / train/policy_logprob_min -9.99 / train/policy_logprob_std 1.9 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.48 / train/post_ent_max 52.48 / train/post_ent_mean 41.37 / 
train/post_ent_min 21.32 / train/post_ent_std 5.18 / train/prior_ent_mag 83.9 / train/prior_ent_max 83.9 / train/prior_ent_mean 45.02 / train/prior_ent_min 26.59 / train/prior_ent_std 6.97 / train/rep_loss_mean 3.68 / train/rep_loss_std 6.53 / train/reward_avg 0.35 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.35 / train/reward_rate 
0.29 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.34 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.33 / report/dyn_loss_std 5.85 / report/image_loss_mean 0.85 / report/image_loss_std 0.61 / report/model_loss_mean 3.01 / report/model_loss_std 4.01 / report/post_ent_mag 52.69 / report/post_ent_max 52.69 /
report/post_ent_mean 41.95 / report/post_ent_min 28.75 / report/post_ent_std 4.13 / report/prior_ent_mag 84.28 / report/prior_ent_max 84.28 / report/prior_ent_mean 45.15 / report/prior_ent_min 31.44 / report/prior_ent_std 6.19 / report/rep_loss_mean 3.33 / 
report/rep_loss_std 5.85 / report/reward_avg 0.37 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.27 / report/reward_max_data 1.83 / report/reward_max_pred 1.83 / report/reward_neg_acc 1 / report/reward_neg_loss 4.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.37 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 7.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.5 / eval/dyn_loss_std 5.69 / eval/image_loss_mean 0.84 / eval/image_loss_std 1.14 / eval/model_loss_mean 3.17 / eval/model_loss_std 4.18 / eval/post_ent_mag 50.18 / eval/post_ent_max 50.18 / eval/post_ent_mean 
42.92 / eval/post_ent_min 23.49 / eval/post_ent_std 3.36 / eval/prior_ent_mag 84.28 / eval/prior_ent_max 84.28 / eval/prior_ent_mean 46.52 / eval/prior_ent_min 38.03 / eval/prior_ent_std 5.48 / eval/rep_loss_mean 3.5 / eval/rep_loss_std 5.69 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.56 / eval/reward_rate 0.42 / 
replay/size 3.6e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3766 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.94 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-4 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.45 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1883 / timer/agent.train_total 241.72 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / 
timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T051833F236184-6g50lhBH8E2ElVESUxcaie-5kbBBmoeONjpG3DMvVUNYS-1024.npz
Starting evaluation at step 357500 Counter(357500) 357437
Saved chunk: 20230922T051844F290152-2v5bWAQDTFwqEk2owNm3Jz-7u9BRit83f9RYzqnhXF9xI-1024.npz
eval_Episode has 500 steps and return 295.5.
train_Episode has 500 steps and return 276.2.
Starting evaluation at step 358000 Counter(358000) 357937
eval_Episode has 500 steps and return 297.8.
train_Episode has 500 steps and return 301.1.
Starting evaluation at step 358500 Counter(358500) 358437
eval_Episode has 500 steps and return 291.4.
Saved chunk: 20230922T051954F593690-5kbBBmoeONjpG3DMvVUNYS-7e14IbjJyvnQqinH6v5V8g-1024.npz
Saved chunk: 20230922T052004F164174-7u9BRit83f9RYzqnhXF9xI-0RLJQLqu3oeEnjLiCKU3XX-1024.npz
train_Episode has 500 steps and return 268.5.
Starting evaluation at step 359000 Counter(359000) 358937
eval_Episode has 500 steps and return 288.9.
train_Episode has 500 steps and return 238.0.
Saved chunk: 20230922T052115F477427-7e14IbjJyvnQqinH6v5V8g-0T6UFJyV3EgUfQ8TV6ayRs-1024.npz
Starting evaluation at step 359500 Counter(359500) 359437
Saved chunk: 20230922T052123F438635-0RLJQLqu3oeEnjLiCKU3XX-5X9bEIrvsdW8nB0Uf9tAF5-1024.npz
eval_Episode has 500 steps and return 301.3.
train_Episode has 500 steps and return 287.8.
Starting evaluation at step 360000 Counter(360000) 359937
eval_Episode has 500 steps and return 310.2.
train_Episode has 500 steps and return 246.4.
Saved chunk: 20230922T052314F628453-0T6UFJyV3EgUfQ8TV6ayRs-7C3JRCIb0VfZbQV1xpzcJn-1024.npz
Starting evaluation at step 360500 Counter(360500) 360437
Saved chunk: 20230922T052320F959338-5X9bEIrvsdW8nB0Uf9tAF5-0NDCpttsY0lB5RcUXnojzN-1024.npz
eval_Episode has 500 steps and return 0.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 721034 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 246.4 / episode/reward_rate 0.37 / train/action_mag 3.72 / train/action_max 3.65 / train/action_mean 0.03 / train/action_min -3.2 / train/action_std 0.91 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 0.62 / train/adv_mag 0.39 / train/adv_max 0.32 / train/adv_mean 5.9e-4 / train/adv_min -0.27 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.71 
/ train/dyn_loss_std 6.56 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss
6585.87 / train/extr_critic_mag 214.39 / train/extr_critic_max 214.39 / train/extr_critic_mean 204.01 / train/extr_critic_min 155.83 / train/extr_critic_std 11.86 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 
0.78 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 214.74 / train/extr_return_raw_max 214.74 / train/extr_return_raw_mean 204.04 / train/extr_return_raw_min 157.72 / 
train/extr_return_raw_std 11.85 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.99 / train/image_loss_std 0.93 / train/model_loss_mean 3.38 / 
train/model_loss_std 4.64 / train/model_opt_grad_norm 8.48 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.09 / train/policy_entropy_max 
3.68 / train/policy_entropy_mean -2.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.23 / train/policy_logprob_mag 9.77 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.16 / train/policy_logprob_min -9.77 / train/policy_logprob_std 1.89 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.24 / train/post_ent_max 52.24 / train/post_ent_mean 41.53 / 
train/post_ent_min 21.51 / train/post_ent_std 5.08 / train/prior_ent_mag 83.78 / train/prior_ent_max 83.78 / train/prior_ent_mean 45.21 / train/prior_ent_min 26.95 / train/prior_ent_std 6.83 / train/rep_loss_mean 3.71 / train/rep_loss_std 6.56 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.36 / train/reward_rate 
0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.35 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.29 / report/dyn_loss_std 5.58 / report/image_loss_mean 0.81 / report/image_loss_std 0.64 / report/model_loss_mean 2.99 / report/model_loss_std 3.9 / report/post_ent_mag 50.94 / report/post_ent_max 50.94 / 
report/post_ent_mean 43.43 / report/post_ent_min 29.35 / report/post_ent_std 3.23 / report/prior_ent_mag 83.79 / report/prior_ent_max 83.79 / report/prior_ent_mean 46.77 / report/prior_ent_min 37.41 / report/prior_ent_std 5.3 / report/rep_loss_mean 3.29 / 
report/rep_loss_std 5.58 / report/reward_avg 0.48 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 1.94 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.48 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 9.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.34 / eval/dyn_loss_std 7.09 / eval/image_loss_mean 1.18 / eval/image_loss_std 1.68 / eval/model_loss_mean 4 / eval/model_loss_std 5.5 / eval/post_ent_mag 50.33 / eval/post_ent_max 50.33 / eval/post_ent_mean 
42.25 / eval/post_ent_min 21.76 / eval/post_ent_std 4.47 / eval/prior_ent_mag 83.79 / eval/prior_ent_max 83.79 / eval/prior_ent_mean 46.44 / eval/prior_ent_min 32.45 / eval/prior_ent_std 5.88 / eval/rep_loss_mean 4.34 / eval/rep_loss_std 7.09 / eval/reward_avg 0.52 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.51 / eval/reward_rate 0.4 / 
replay/size 3.6e5 / replay/inserts 3288 / replay/samples 2.6e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3288 / timer/env.step_total 17.04 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 9e-3 / timer/replay._sample_count 2.6e4 / timer/replay._sample_total 392.88 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 6795 / timer/agent.policy_total 15.26 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1644 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1644 / timer/agent.train_total 210.76 / 
timer/agent.train_frac 0.7 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.5e-5 / timer/dataset_eval_frac 8.4e-8 / timer/dataset_eval_avg 2.5e-5 / timer/dataset_eval_min 2.5e-5 / timer/dataset_eval_max 2.5e-5 / fps 21.91

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 261.7.
Starting evaluation at step 361000 Counter(361000) 360937
eval_Episode has 500 steps and return 295.5.
train_Episode has 500 steps and return 272.1.
Saved chunk: 20230922T052434F733848-7C3JRCIb0VfZbQV1xpzcJn-59K0auLZGWqW2slpew5rom-1024.npz
Starting evaluation at step 361500 Counter(361500) 361437
Saved chunk: 20230922T052439F542523-0NDCpttsY0lB5RcUXnojzN-1qDXDRhrJ7oQMuUMpVWneb-1024.npz
eval_Episode has 500 steps and return 296.8.
train_Episode has 500 steps and return 280.7.
Starting evaluation at step 362000 Counter(362000) 361937
eval_Episode has 500 steps and return 302.7.
train_Episode has 500 steps and return 299.2.
Starting evaluation at step 362500 Counter(362500) 362437
Saved chunk: 20230922T052556F539127-59K0auLZGWqW2slpew5rom-1SUpkKv6FZy3QwiHtpOSZQ-1024.npz
Saved chunk: 20230922T052559F768846-1qDXDRhrJ7oQMuUMpVWneb-43WVPaG3Fat5bcotaLDQvp-1024.npz
eval_Episode has 500 steps and return 293.3.
train_Episode has 500 steps and return 264.6.
Starting evaluation at step 363000 Counter(363000) 362937
eval_Episode has 500 steps and return 294.4.
train_Episode has 500 steps and return 285.3.
Starting evaluation at step 363500 Counter(363500) 363437
Saved chunk: 20230922T052718F847059-43WVPaG3Fat5bcotaLDQvp-4BDQBym3c7D3OHjGkWoBID-1024.npz
eval_Episode has 500 steps and return 282.9.
Saved chunk: 20230922T052717F210274-1SUpkKv6FZy3QwiHtpOSZQ-0OylpAnFC2EcQvKeX5PKxr-1024.npz
train_Episode has 500 steps and return 271.3.
Starting evaluation at step 364000 Counter(364000) 363937
eval_Episode has 500 steps and return 314.7.
train_Episode has 500 steps and return 283.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 728682 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 283.48 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 314.72 / eval_episode/reward_rate 0.47 / train/action_mag 3.72 / train/action_max 3.68 / train/action_mean 0.03 / train/action_min -3.17 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -0.03 / train/adv_mag 0.39 / train/adv_max 0.33 / train/adv_mean 6.5e-4
/ train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.54 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6662.54 / train/extr_critic_mag 214.73 / train/extr_critic_max 214.73 / train/extr_critic_mean 204.11 / train/extr_critic_min 152.64 / train/extr_critic_std 12.58 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 215.08 / train/extr_return_raw_max 215.08 / train/extr_return_raw_mean 204.14 / train/extr_return_raw_min 
155.32 / train/extr_return_raw_std 12.61 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.37 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 0.99 / train/image_loss_std 0.94 / train/model_loss_mean 3.38 /
train/model_loss_std 4.63 / train/model_opt_grad_norm 8.41 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.89 / train/policy_entropy_max 
3.39 / train/policy_entropy_mean -2.16 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.21 / train/policy_logprob_mag 10.04 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.16 / train/policy_logprob_min -10.04 / train/policy_logprob_std 1.88 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.25 / train/post_ent_max 52.25 / train/post_ent_mean 41.47 / 
train/post_ent_min 21.37 / train/post_ent_std 5.18 / train/prior_ent_mag 83.79 / train/prior_ent_max 83.79 / train/prior_ent_mean 45.15 / train/prior_ent_min 26.71 / train/prior_ent_std 6.91 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.54 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.29 / train/reward_max_data 1.89 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.35 / train/reward_rate 
0.29 / train_stats/mean_log_entropy -2.35 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 6.43 / report/image_loss_mean 0.92 / report/image_loss_std 0.81 / report/model_loss_mean 3.28 / report/model_loss_std 4.56 / report/post_ent_mag 51.42 / report/post_ent_max 51.42 /
report/post_ent_mean 42.4 / report/post_ent_min 23.03 / report/post_ent_std 4.51 / report/prior_ent_mag 83.82 / report/prior_ent_max 83.82 / report/prior_ent_mean 46.06 / report/prior_ent_min 30.92 / report/prior_ent_std 6.4 / report/rep_loss_mean 3.64 / 
report/rep_loss_std 6.43 / report/reward_avg 0.37 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.33 / report/reward_max_data 1.83 / report/reward_max_pred 1.82 / report/reward_neg_acc 1 / report/reward_neg_loss 7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.38 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.87 / eval/dyn_loss_std 8.29 / eval/image_loss_mean 1.58 / eval/image_loss_std 2.9 / eval/model_loss_mean 4.71 / eval/model_loss_std 7.29 / eval/post_ent_mag 50.69 / eval/post_ent_max 50.69 / eval/post_ent_mean 
40.81 / eval/post_ent_min 20.77 / eval/post_ent_std 6.14 / eval/prior_ent_mag 83.82 / eval/prior_ent_max 83.82 / eval/prior_ent_mean 45.25 / eval/prior_ent_min 28.06 / eval/prior_ent_std 7.54 / eval/rep_loss_mean 4.87 / eval/rep_loss_std 8.29 / eval/reward_avg 0.51 / 
eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.51 / eval/reward_rate 0.37 / 
replay/size 3.6e5 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3824 / timer/env.step_total 19.86 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.01 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.7e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7331 / timer/agent.policy_total 16.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1912 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1912 / timer/agent.train_total 245.35 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.48

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 364500 Counter(364500) 364437
Saved chunk: 20230922T052837F665842-4BDQBym3c7D3OHjGkWoBID-4jc4NXJbk4YNiJz9j0LQFM-1024.npz
eval_Episode has 500 steps and return 299.3.
Saved chunk: 20230922T052841F036642-0OylpAnFC2EcQvKeX5PKxr-7sgiXmFDMNCNlImIT37OYe-1024.npz
train_Episode has 500 steps and return 283.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T052957F407704-4jc4NXJbk4YNiJz9j0LQFM-0000000000000000000000-260.npz
Saved chunk: 20230922T053002F381652-7sgiXmFDMNCNlImIT37OYe-0000000000000000000000-256.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 365000 Counter(365000) 364937
eval_Episode has 500 steps and return 301.6.
train_Episode has 500 steps and return 291.0.
Starting evaluation at step 365500 Counter(365500) 365437
Saved chunk: 20230922T052957F407704-4jc4NXJbk4YNiJz9j0LQFM-5kYgkDan21emBzXoz1J806-1024.npz
eval_Episode has 500 steps and return 305.7.
Saved chunk: 20230922T053002F381652-7sgiXmFDMNCNlImIT37OYe-6ABnIwLWiHmbkVxMdnk0TM-1024.npz
train_Episode has 500 steps and return 299.5.
Starting evaluation at step 366000 Counter(366000) 365937
eval_Episode has 500 steps and return 318.4.
train_Episode has 500 steps and return 287.3.
Starting evaluation at step 366500 Counter(366500) 366437
Saved chunk: 20230922T053116F930308-5kYgkDan21emBzXoz1J806-06VqwrDn1aa4VO7JdEnocI-1024.npz
eval_Episode has 500 steps and return 309.6.
Saved chunk: 20230922T053123F448442-6ABnIwLWiHmbkVxMdnk0TM-6tN3zvX6axrW8mKsEYGvkR-1024.npz
train_Episode has 500 steps and return 289.7.
Starting evaluation at step 367000 Counter(367000) 366937
eval_Episode has 500 steps and return 297.8.
train_Episode has 500 steps and return 261.9.
Starting evaluation at step 367500 Counter(367500) 367437
Saved chunk: 20230922T053235F950827-06VqwrDn1aa4VO7JdEnocI-3YW9GMEFtcQ8dWjDM202z1-1024.npz
eval_Episode has 500 steps and return 274.3.
Saved chunk: 20230922T053244F013510-6tN3zvX6axrW8mKsEYGvkR-04y5BlG36mi0MK0kG2D39u-1024.npz
train_Episode has 500 steps and return 292.5.
Starting evaluation at step 368000 Counter(368000) 367937
eval_Episode has 500 steps and return 296.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 736220 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 296.26 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 292.45 / episode/reward_rate 0.43 / train/action_mag 3.6 / train/action_max 3.58 / train/action_mean 0.02 / train/action_min -2.93 / train/action_std
0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -1.8 / train/adv_mag 0.34 / train/adv_max 0.28 / train/adv_mean 8.9e-4 / train/adv_min 
-0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6539.53 / train/extr_critic_mag 215.29 / train/extr_critic_max 215.29 / train/extr_critic_mean 205.94 / train/extr_critic_min 170.56 / train/extr_critic_std 9.05 / train/extr_return_normed_mag 1.24 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.11 / train/extr_return_normed_std 0.23 / train/extr_return_rate 1 / train/extr_return_raw_mag 215.63 / train/extr_return_raw_max 215.63 / train/extr_return_raw_mean 205.98 / train/extr_return_raw_min 
170.61 / train/extr_return_raw_std 9.07 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.99 / train/image_loss_std 0.94 / train/model_loss_mean 3.38 /
train/model_loss_std 4.66 / train/model_opt_grad_norm 8.65 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.76 / train/policy_entropy_max 
3.02 / train/policy_entropy_mean -2.34 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.06 / train/policy_logprob_mag 9.4 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.34 / train/policy_logprob_min -9.4 / train/policy_logprob_std 1.78 / 
train/policy_randomness_mag 0.71 / train/policy_randomness_max 0.71 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.13 / train/post_ent_max 52.13 / train/post_ent_mean 41.71 / 
train/post_ent_min 21.79 / train/post_ent_std 4.97 / train/prior_ent_mag 83.8 / train/prior_ent_max 83.8 / train/prior_ent_mean 45.38 / train/prior_ent_min 27.88 / train/prior_ent_std 6.73 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.57 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.29 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.36 / train/reward_rate 
0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.44 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 8.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.35 / report/dyn_loss_std 6.02 / report/image_loss_mean 0.85 / report/image_loss_std 0.91 / report/model_loss_mean 3.02 / report/model_loss_std 4.4 / report/post_ent_mag 51.8 / report/post_ent_max 51.8 / 
report/post_ent_mean 41.72 / report/post_ent_min 24.75 / report/post_ent_std 5.66 / report/prior_ent_mag 83.64 / report/prior_ent_max 83.64 / report/prior_ent_mean 45.04 / report/prior_ent_min 26.86 / report/prior_ent_std 7.39 / report/rep_loss_mean 3.35 / 
report/rep_loss_std 6.02 / report/reward_avg 0.38 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.92 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.38 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 4.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.45 / eval/dyn_loss_std 7.26 / eval/image_loss_mean 1.25 / eval/image_loss_std 2.03 / eval/model_loss_mean 4.16 / eval/model_loss_std 5.86 / eval/post_ent_mag 50.67 / eval/post_ent_max 50.67 / eval/post_ent_mean 
41.98 / eval/post_ent_min 19.58 / eval/post_ent_std 4.73 / eval/prior_ent_mag 83.64 / eval/prior_ent_max 83.64 / eval/prior_ent_mean 46.39 / eval/prior_ent_min 27.72 / eval/prior_ent_std 6.19 / eval/rep_loss_mean 4.45 / eval/rep_loss_std 7.26 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.3 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.59 / eval/reward_rate 0.46 / 
replay/size 3.7e5 / replay/inserts 3769 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3769 / timer/env.step_total 19.53 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.79 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7777 / timer/agent.policy_total 17.7 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1884 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1884 / timer/agent.train_total 242.13 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / 
timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.13

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 280.3.
Starting evaluation at step 368500 Counter(368500) 368437
Saved chunk: 20230922T053354F843965-3YW9GMEFtcQ8dWjDM202z1-3dq2tVmm17WvEYseHXtKcw-1024.npz
eval_Episode has 500 steps and return 306.4.
Saved chunk: 20230922T053404F461449-04y5BlG36mi0MK0kG2D39u-0G1hqPJZrJ3jr4VZgnQvYg-1024.npz
train_Episode has 500 steps and return 280.8.
Starting evaluation at step 369000 Counter(369000) 368937
eval_Episode has 500 steps and return 304.7.
train_Episode has 500 steps and return 289.6.
Starting evaluation at step 369500 Counter(369500) 369437
Saved chunk: 20230922T053514F800483-3dq2tVmm17WvEYseHXtKcw-7AGsIfozdWBDTw9bxXaf67-1024.npz
eval_Episode has 500 steps and return 289.7.
Saved chunk: 20230922T053526F065351-0G1hqPJZrJ3jr4VZgnQvYg-2K9b5RSKwBmtNp2reMoCwV-1024.npz
train_Episode has 500 steps and return 266.1.
Starting evaluation at step 370000 Counter(370000) 369937
eval_Episode has 500 steps and return 313.4.
train_Episode has 500 steps and return 284.4.
Starting evaluation at step 370500 Counter(370500) 370437
Saved chunk: 20230922T053634F118382-7AGsIfozdWBDTw9bxXaf67-3gVSNirYZM6SP7CG5ei1gx-1024.npz
eval_Episode has 500 steps and return 295.2.
Saved chunk: 20230922T053647F054108-2K9b5RSKwBmtNp2reMoCwV-5NTLD4CCNTpFKCSoRV75ti-1024.npz
train_Episode has 500 steps and return 272.0.
Starting evaluation at step 371000 Counter(371000) 370937
eval_Episode has 500 steps and return 298.1.
train_Episode has 500 steps and return 279.9.
Starting evaluation at step 371500 Counter(371500) 371437
Saved chunk: 20230922T053753F404868-3gVSNirYZM6SP7CG5ei1gx-4GAFnSDbrZGOEYQ5B5p3iy-1024.npz
eval_Episode has 500 steps and return 285.0.
Saved chunk: 20230922T053807F814958-5NTLD4CCNTpFKCSoRV75ti-4mcpityEqSxJW9Qk4lXuO3-1024.npz
train_Episode has 500 steps and return 247.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 743846 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 247.27 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 284.97 / eval_episode/reward_rate 0.42 / train/action_mag 3.65 / train/action_max 3.62 / train/action_mean 0.02 / train/action_min -3.02 / 
train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -2.9 / train/adv_mag 0.44 / train/adv_max 0.36 / train/adv_mean 1e-3 / 
train/adv_min -0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 6590.31 / train/extr_critic_mag 216.08 / train/extr_critic_max 216.08 / train/extr_critic_mean 206.27 / train/extr_critic_min 165.04 / train/extr_critic_std 10.05 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.19 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 216.38 / train/extr_return_raw_max 216.38 / train/extr_return_raw_mean 206.31 / train/extr_return_raw_min 
167.42 / train/extr_return_raw_std 10.08 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.98 / train/image_loss_std 0.94 / train/model_loss_mean 3.35 
/ train/model_loss_std 4.6 / train/model_opt_grad_norm 8.38 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.79 / train/policy_entropy_max 
3.19 / train/policy_entropy_mean -2.34 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.13 / train/policy_logprob_mag 9.61 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.34 / train/policy_logprob_min -9.61 / train/policy_logprob_std 1.83 / 
train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 52.09 / train/post_ent_max 52.09 / train/post_ent_mean 41.65 / 
train/post_ent_min 21.72 / train/post_ent_std 5.04 / train/prior_ent_mag 83.66 / train/prior_ent_max 83.66 / train/prior_ent_mean 45.29 / train/prior_ent_min 27.57 / train/prior_ent_std 6.76 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.49 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.16 / train/reward_loss_std 0.29 / train/reward_max_data 1.9 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.35 / train/reward_rate 
0.29 / train_stats/mean_log_entropy -2.46 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.61 / report/dyn_loss_std 6.38 / report/image_loss_mean 1 / report/image_loss_std 0.99 / report/model_loss_mean 3.31 / report/model_loss_std 4.55 / report/post_ent_mag 52.56 / report/post_ent_max 52.56 / 
report/post_ent_mean 41.37 / report/post_ent_min 21.52 / report/post_ent_std 5.11 / report/prior_ent_mag 83.54 / report/prior_ent_max 83.54 / report/prior_ent_mean 44.88 / report/prior_ent_min 27.51 / report/prior_ent_std 6.65 / report/rep_loss_mean 3.61 / 
report/rep_loss_std 6.38 / report/reward_avg 0.28 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.3 / report/reward_max_data 1.95 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.28 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 8.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.75 / eval/dyn_loss_std 5.89 / eval/image_loss_mean 0.92 / eval/image_loss_std 1.14 / eval/model_loss_mean 3.41 / eval/model_loss_std 4.34 / eval/post_ent_mag 50.99 / eval/post_ent_max 50.99 / eval/post_ent_mean 42.69 / 
eval/post_ent_min 20.37 / eval/post_ent_std 4 / eval/prior_ent_mag 83.54 / eval/prior_ent_max 83.54 / eval/prior_ent_mean 46.41 / eval/prior_ent_min 28.18 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 3.75 / eval/rep_loss_std 5.89 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.53 / eval/reward_pred 0.58 / eval/reward_rate 0.45 / 
replay/size 3.7e5 / replay/inserts 3813 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3813 / timer/env.step_total 19.97 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 460.13 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7320 / timer/agent.policy_total 16.52 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.76 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 372000 Counter(372000) 371937
eval_Episode has 500 steps and return 292.6.
train_Episode has 500 steps and return 270.2.
Starting evaluation at step 372500 Counter(372500) 372437
Saved chunk: 20230922T053912F211512-4GAFnSDbrZGOEYQ5B5p3iy-6vV1RonFfu065QvOj2SM69-1024.npz
eval_Episode has 500 steps and return 313.8.
train_Episode has 500 steps and return 255.8.
Saved chunk: 20230922T053928F155647-4mcpityEqSxJW9Qk4lXuO3-16B8S5ZFrQUN22egfoDTH3-1024.npz
Starting evaluation at step 373000 Counter(373000) 372937
eval_Episode has 500 steps and return 300.1.
train_Episode has 500 steps and return 278.0.
Starting evaluation at step 373500 Counter(373500) 373437
Saved chunk: 20230922T054032F438917-6vV1RonFfu065QvOj2SM69-6Yuc7uRdhWZvJcEK4hF46N-1024.npz
eval_Episode has 500 steps and return 316.9.
train_Episode has 500 steps and return 279.3.
Saved chunk: 20230922T054050F148114-16B8S5ZFrQUN22egfoDTH3-2QaEmQ6K8CSUKC53jSL0wo-1024.npz
Starting evaluation at step 374000 Counter(374000) 373937
eval_Episode has 500 steps and return 310.1.
train_Episode has 500 steps and return 281.4.
Starting evaluation at step 374500 Counter(374500) 374437
eval_Episode has 500 steps and return 284.1.
Saved chunk: 20230922T054151F862258-6Yuc7uRdhWZvJcEK4hF46N-2EJL6p7baBrtck5GR4zAwV-1024.npz
train_Episode has 500 steps and return 297.9.
Saved chunk: 20230922T054211F103989-2QaEmQ6K8CSUKC53jSL0wo-190NdFyeyxBfdF4qHnKNIi-1024.npz
Starting evaluation at step 375000 Counter(375000) 374937
eval_Episode has 500 steps and return 302.7.
train_Episode has 500 steps and return 282.7.
Starting evaluation at step 375500 Counter(375500) 375437
eval_Episode has 500 steps and return 321.3.
Saved chunk: 20230922T054311F146925-2EJL6p7baBrtck5GR4zAwV-4F9qWAiYteFSsbCcxVvHDg-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 751366 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 321.33 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 282.67 / episode/reward_rate 0.42 / train/action_mag 3.79 / train/action_max 3.72 / train/action_mean 0.02 / train/action_min -3.3 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -2.55 / train/adv_mag 0.36 / train/adv_max 0.27 / train/adv_mean 9.5e-4 / train/adv_min
-0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 6455.2 / train/extr_critic_mag 217.14 / train/extr_critic_max 217.14 / train/extr_critic_mean 207.54 / train/extr_critic_min 167.73 / train/extr_critic_std 9.93 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 217.46 / train/extr_return_raw_max 217.46 / train/extr_return_raw_mean 207.57 / train/extr_return_raw_min 
169.59 / train/extr_return_raw_std 9.97 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.98 / train/image_loss_std 0.93 / train/model_loss_mean 3.37 /
train/model_loss_std 4.59 / train/model_opt_grad_norm 8.26 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.97 / train/policy_entropy_max 
3.62 / train/policy_entropy_mean -2.28 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.21 / train/policy_logprob_mag 9.51 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.28 / train/policy_logprob_min -9.51 / train/policy_logprob_std 1.87 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.03 / train/post_ent_max 52.03 / train/post_ent_mean 41.81 / 
train/post_ent_min 21.7 / train/post_ent_std 4.97 / train/prior_ent_mag 83.53 / train/prior_ent_max 83.53 / train/prior_ent_mean 45.48 / train/prior_ent_min 27.45 / train/prior_ent_std 6.66 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.48 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.36 / train/reward_rate 
0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.4 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.77 / report/dyn_loss_std 6.34 / report/image_loss_mean 1.07 / report/image_loss_std 0.94 / report/model_loss_mean 3.47 / report/model_loss_std 4.49 / report/post_ent_mag 51.01 / report/post_ent_max 51.01 /
report/post_ent_mean 41.66 / report/post_ent_min 23.63 / report/post_ent_std 4.63 / report/prior_ent_mag 83.16 / report/prior_ent_max 83.16 / report/prior_ent_mean 45.47 / report/prior_ent_min 31.73 / report/prior_ent_std 6.1 / report/rep_loss_mean 3.77 / 
report/rep_loss_std 6.34 / report/reward_avg 0.32 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.27 / report/reward_max_data 1.94 / report/reward_max_pred 1.92 / report/reward_neg_acc 0.99 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.32 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.71 / eval/dyn_loss_std 7.75 / eval/image_loss_mean 1.19 / eval/image_loss_std 1.85 / eval/model_loss_mean 4.22 / eval/model_loss_std 6.13 / eval/post_ent_mag 51.12 / eval/post_ent_max 51.12 / eval/post_ent_mean 
42.51 / eval/post_ent_min 23.66 / eval/post_ent_std 4.24 / eval/prior_ent_mag 83.16 / eval/prior_ent_max 83.16 / eval/prior_ent_mean 46.7 / eval/prior_ent_min 34.11 / eval/prior_ent_std 5.82 / eval/rep_loss_mean 4.71 / eval/rep_loss_std 7.75 / eval/reward_avg 0.54 / 
eval/reward_loss_mean 0.21 / eval/reward_loss_std 0.29 / eval/reward_max_data 1.89 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.51 / eval/reward_pred 0.53 / eval/reward_rate 0.41 / 
replay/size 3.8e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3760 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.59 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.5e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.59 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.7e-3 
/ timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.53 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.4e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 304.5.
Saved chunk: 20230922T054331F816347-190NdFyeyxBfdF4qHnKNIi-7wMU0gfJPPwRUfnUDTaGBF-1024.npz
Starting evaluation at step 376000 Counter(376000) 375937
eval_Episode has 500 steps and return 300.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T054430F143747-4F9qWAiYteFSsbCcxVvHDg-0000000000000000000000-519.npz
Saved chunk: 20230922T054453F382985-7wMU0gfJPPwRUfnUDTaGBF-0000000000000000000000-392.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 274.8.
Starting evaluation at step 376500 Counter(376500) 376437
eval_Episode has 500 steps and return 313.5.
train_Episode has 500 steps and return 294.3.
Saved chunk: 20230922T054453F382985-7wMU0gfJPPwRUfnUDTaGBF-7nZSZi4woutGofDvzq8jHX-1024.npz
Starting evaluation at step 377000 Counter(377000) 376937
Saved chunk: 20230922T054430F143747-4F9qWAiYteFSsbCcxVvHDg-4xQSah1pLBE1r08heNjai0-1024.npz
eval_Episode has 500 steps and return 320.1.
train_Episode has 500 steps and return 272.8.
Starting evaluation at step 377500 Counter(377500) 377437
eval_Episode has 500 steps and return 325.1.
train_Episode has 500 steps and return 261.2.
Saved chunk: 20230922T054614F784453-7nZSZi4woutGofDvzq8jHX-2TLTsQgcUppx1eL25zKKBN-1024.npz
Starting evaluation at step 378000 Counter(378000) 377937
Saved chunk: 20230922T054626F950015-4xQSah1pLBE1r08heNjai0-1Pca31DCENN3Bv4OHwwX40-1024.npz
eval_Episode has 500 steps and return 320.2.
train_Episode has 500 steps and return 266.9.
Starting evaluation at step 378500 Counter(378500) 378437
eval_Episode has 500 steps and return 319.5.
train_Episode has 500 steps and return 274.1.
Saved chunk: 20230922T054735F730672-2TLTsQgcUppx1eL25zKKBN-4wMMAT6zUjdtM0YcJSl2X2-1024.npz
Starting evaluation at step 379000 Counter(379000) 378937
Saved chunk: 20230922T054746F252938-1Pca31DCENN3Bv4OHwwX40-1yUkwXZYCHlL80Ow6qQycs-1024.npz
eval_Episode has 500 steps and return 315.6.
train_Episode has 500 steps and return 278.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 758974 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 278.87 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 315.56 / eval_episode/reward_rate 0.45 / train/action_mag 3.74 / train/action_max 3.7 / train/action_mean 0.03 / train/action_min -3.27 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.47 / train/adv_mag 0.33 / train/adv_max 0.26 / train/adv_mean 1.1e-3 / train/adv_min
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.5 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 6679.7 / train/extr_critic_mag 218.33 / train/extr_critic_max 218.33 / train/extr_critic_mean 208.26 / train/extr_critic_min 164.05 / train/extr_critic_std 11.18 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 218.63 / train/extr_return_raw_max 218.63 / train/extr_return_raw_mean 208.31 / train/extr_return_raw_min 
164.78 / train/extr_return_raw_std 11.21 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.98 / train/image_loss_std 0.91 / train/model_loss_mean 3.37 /
train/model_loss_std 4.59 / train/model_opt_grad_norm 8.31 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 3.96 / train/policy_entropy_max 
3.54 / train/policy_entropy_mean -2.28 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.24 / train/policy_logprob_mag 9.79 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.28 / train/policy_logprob_min -9.79 / train/policy_logprob_std 1.89 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 52.03 / train/post_ent_max 52.03 / train/post_ent_mean 41.78 / 
train/post_ent_min 21.88 / train/post_ent_std 5 / train/prior_ent_mag 83.53 / train/prior_ent_max 83.53 / train/prior_ent_mean 45.45 / train/prior_ent_min 27.52 / train/prior_ent_std 6.71 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.5 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.36 / train/reward_rate 
0.3 / train_stats/mean_log_entropy -2.46 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.7e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.52 / report/dyn_loss_std 5.96 / report/image_loss_mean 0.93 / report/image_loss_std 0.74 / report/model_loss_mean 3.21 / report/model_loss_std 4.15 / report/post_ent_mag 50.81 / report/post_ent_max 50.81 /
report/post_ent_mean 42.65 / report/post_ent_min 24.29 / report/post_ent_std 3.88 / report/prior_ent_mag 83.95 / report/prior_ent_max 83.95 / report/prior_ent_mean 46.14 / report/prior_ent_min 30.98 / report/prior_ent_std 5.78 / report/rep_loss_mean 3.52 / 
report/rep_loss_std 5.96 / report/reward_avg 0.37 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 1.99 / report/reward_max_pred 1.91 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.37 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.85 / eval/dyn_loss_std 6.17 / eval/image_loss_mean 0.9 / eval/image_loss_std 1.02 / eval/model_loss_mean 3.47 / eval/model_loss_std 4.45 / eval/post_ent_mag 50.4 / eval/post_ent_max 50.4 / eval/post_ent_mean 
42.75 / eval/post_ent_min 24.56 / eval/post_ent_std 3.91 / eval/prior_ent_mag 83.95 / eval/prior_ent_max 83.95 / eval/prior_ent_mean 46.54 / eval/prior_ent_min 32.26 / eval/prior_ent_std 5.66 / eval/rep_loss_mean 3.85 / eval/rep_loss_std 6.17 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.86 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.61 / eval/reward_rate 0.46 / 
replay/size 3.8e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3804 / timer/env.step_total 19.91 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.5 / timer/replay._sample_frac 1.55 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.8e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.82 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1902 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.39 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.36

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 379500 Counter(379500) 379437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 281.2.
Saved chunk: 20230922T054856F353286-4wMMAT6zUjdtM0YcJSl2X2-6tNWD9i2eE72EioUgEVxzp-1024.npz
Starting evaluation at step 380000 Counter(380000) 379937
Saved chunk: 20230922T054905F314149-1yUkwXZYCHlL80Ow6qQycs-1EfzxCPKID9PJhabVhD6zM-1024.npz
eval_Episode has 500 steps and return 304.7.
train_Episode has 500 steps and return 273.6.
Starting evaluation at step 380500 Counter(380500) 380437
eval_Episode has 500 steps and return 293.9.
train_Episode has 500 steps and return 295.8.
Saved chunk: 20230922T055018F177067-6tNWD9i2eE72EioUgEVxzp-0XUJdXfThkeX7tsQ8qUcmk-1024.npz
Starting evaluation at step 381000 Counter(381000) 380937
Saved chunk: 20230922T055025F601906-1EfzxCPKID9PJhabVhD6zM-5ohlonptZqE1Tx8XRUrr1t-1024.npz
eval_Episode has 500 steps and return 301.7.
train_Episode has 500 steps and return 280.5.
Starting evaluation at step 381500 Counter(381500) 381437
eval_Episode has 500 steps and return 315.1.
train_Episode has 500 steps and return 271.3.
Saved chunk: 20230922T055139F129985-0XUJdXfThkeX7tsQ8qUcmk-6VMAC69OKKIj0zB4T9DPaM-1024.npz
Starting evaluation at step 382000 Counter(382000) 381937
Saved chunk: 20230922T055144F975808-5ohlonptZqE1Tx8XRUrr1t-58S0TZHQXqzl49cnE0jnw5-1024.npz
eval_Episode has 500 steps and return 311.2.
train_Episode has 500 steps and return 284.1.
Starting evaluation at step 382500 Counter(382500) 382437
eval_Episode has 500 steps and return 333.9.
train_Episode has 500 steps and return 294.1.
Saved chunk: 20230922T055259F974339-6VMAC69OKKIj0zB4T9DPaM-0XPmbxuStsbBkNwYosCNe2-1024.npz
Starting evaluation at step 383000 Counter(383000) 382937
Saved chunk: 20230922T055304F236218-58S0TZHQXqzl49cnE0jnw5-3c4sNF6EVphqT5CsXBimEf-1024.npz
eval_Episode has 500 steps and return 300.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 766498 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 300.88 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 294.06 / episode/reward_rate 0.43 / train/action_mag 3.9 / train/action_max 3.83 / train/action_mean 0.03 / train/action_min -3.47 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.26 / train/adv_mag 0.45 / train/adv_max 0.36 / train/adv_mean 1.1e-3 / train/adv_min
-0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.7 / train/dyn_loss_std 6.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 7211.45 / train/extr_critic_mag 219.51 / train/extr_critic_max 219.51 / train/extr_critic_mean 208.54 / train/extr_critic_min 150.85 / train/extr_critic_std 14.04 / train/extr_return_normed_mag 1.55 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.57 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 219.81 / train/extr_return_raw_max 219.81 / train/extr_return_raw_mean 208.58 / train/extr_return_raw_min 
152.54 / train/extr_return_raw_std 14.07 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.98 / train/image_loss_std 0.96 / train/model_loss_mean 3.37 /
train/model_loss_std 4.65 / train/model_opt_grad_norm 8.43 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.02 / train/policy_entropy_max 
3.68 / train/policy_entropy_mean -2.18 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.13 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.18 / train/policy_logprob_min -10.13 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 41.65 / 
train/post_ent_min 21.41 / train/post_ent_std 5.22 / train/prior_ent_mag 83.53 / train/prior_ent_max 83.53 / train/prior_ent_mean 45.3 / train/prior_ent_min 26.72 / train/prior_ent_std 6.9 / train/rep_loss_mean 3.7 / train/rep_loss_std 6.53 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.29 / train/reward_max_data 1.9 / train/reward_max_pred 1.88 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.37 / train/reward_rate 
0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.35 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 5.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.85 / report/dyn_loss_std 7.6 / report/image_loss_mean 1.18 / report/image_loss_std 1.31 / report/model_loss_mean 3.63 / report/model_loss_std 5.52 / report/post_ent_mag 50.36 / report/post_ent_max 50.36 / 
report/post_ent_mean 39.47 / report/post_ent_min 19.39 / report/post_ent_std 6.97 / report/prior_ent_mag 83.53 / report/prior_ent_max 83.53 / report/prior_ent_mean 43.43 / report/prior_ent_min 21.21 / report/prior_ent_std 8.76 / report/rep_loss_mean 3.85 / 
report/rep_loss_std 7.6 / report/reward_avg 0.27 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.27 / report/reward_max_data 1.92 / report/reward_max_pred 1.86 / report/reward_neg_acc 1 / report/reward_neg_loss 7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.27 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 7.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.25 / eval/dyn_loss_std 6.53 / eval/image_loss_mean 1.19 / eval/image_loss_std 2.12 / eval/model_loss_mean 3.98 / eval/model_loss_std 5.53 / eval/post_ent_mag 50.87 / eval/post_ent_max 50.87 / eval/post_ent_mean 
42.14 / eval/post_ent_min 23.19 / eval/post_ent_std 4.47 / eval/prior_ent_mag 83.53 / eval/prior_ent_max 83.53 / eval/prior_ent_mean 46.37 / eval/prior_ent_min 30.08 / eval/prior_ent_std 5.89 / eval/rep_loss_mean 4.25 / eval/rep_loss_std 6.53 / eval/reward_avg 0.54 / 
eval/reward_loss_mean 0.23 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.85 / eval/reward_max_pred 1.86 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.54 / eval/reward_pred 0.54 / eval/reward_rate 0.42 / 
replay/size 3.8e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3762 / timer/env.step_total 19.7 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.27 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.66 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.9e-3 
/ timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.24 / 
timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 244.8.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 383500 Counter(383500) 383437
eval_Episode has 500 steps and return 315.2.
train_Episode has 500 steps and return 307.2.
Starting evaluation at step 384000 Counter(384000) 383937
Saved chunk: 20230922T055420F467788-0XPmbxuStsbBkNwYosCNe2-6NaI3qFHId0aA6v7vKsUoE-1024.npz
Saved chunk: 20230922T055423F138907-3c4sNF6EVphqT5CsXBimEf-3OiNg7u7LxMwOygChXf4KV-1024.npz
eval_Episode has 500 steps and return 272.1.
train_Episode has 500 steps and return 263.7.
Starting evaluation at step 384500 Counter(384500) 384437
eval_Episode has 500 steps and return 312.9.
train_Episode has 500 steps and return 269.5.
Starting evaluation at step 385000 Counter(385000) 384937
Saved chunk: 20230922T055543F444651-3OiNg7u7LxMwOygChXf4KV-0sWsb2MqF36wMEDbxb4kgY-1024.npz
eval_Episode has 500 steps and return 300.8.
Saved chunk: 20230922T055542F334866-6NaI3qFHId0aA6v7vKsUoE-58ztOyoNaowCfNNS01HtDu-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 385500 Counter(385500) 385437
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 275.7.
Starting evaluation at step 386000 Counter(386000) 385937
Saved chunk: 20230922T055702F764035-0sWsb2MqF36wMEDbxb4kgY-45WT2KDsBAHvOqJBcgdZ70-1024.npz
eval_Episode has 500 steps and return 295.2.
Saved chunk: 20230922T055706F768119-58ztOyoNaowCfNNS01HtDu-2rnKmZ4sCDHxStGnczlX4K-1024.npz
train_Episode has 500 steps and return 267.0.
Starting evaluation at step 386500 Counter(386500) 386437
eval_Episode has 500 steps and return 313.5.
train_Episode has 500 steps and return 269.2.
Starting evaluation at step 387000 Counter(387000) 386937
Saved chunk: 20230922T055821F975166-45WT2KDsBAHvOqJBcgdZ70-2P2jXsDmEf5yLBEjo69Rgr-1024.npz
eval_Episode has 500 steps and return 312.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 774014 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 269.16 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 312 / eval_episode/reward_rate 0.45 / train/action_mag 3.91 / train/action_max 3.83 / train/action_mean 0.01 / train/action_min -3.5 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -5.7 / train/adv_mag 0.49 / train/adv_max 0.42 / train/adv_mean 1.3e-3 / train/adv_min 
-0.39 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 6.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 7737.77 / train/extr_critic_mag 220.61 / train/extr_critic_max 220.61 / train/extr_critic_mean 210.72 / train/extr_critic_min 162.38 / train/extr_critic_std 11.31 / train/extr_return_normed_mag 1.51 / train/extr_return_normed_max 1.05 /
train/extr_return_normed_mean 0.78 / train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 220.88 / train/extr_return_raw_max 220.88 / train/extr_return_raw_mean 210.76 / train/extr_return_raw_min 
163.09 / train/extr_return_raw_std 11.34 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.97 / train/image_loss_std 0.92 / train/model_loss_mean 3.35 /
train/model_loss_std 4.58 / train/model_opt_grad_norm 7.98 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.01 / train/policy_entropy_max 
3.62 / train/policy_entropy_mean -2.25 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.28 / train/policy_logprob_mag 10.09 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.25 / train/policy_logprob_min -10.09 / train/policy_logprob_std 1.92 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.05 / train/post_ent_max 52.05 / train/post_ent_mean 41.96 / 
train/post_ent_min 21.77 / train/post_ent_std 4.97 / train/prior_ent_mag 83.43 / train/prior_ent_max 83.43 / train/prior_ent_mean 45.61 / train/prior_ent_min 27.44 / train/prior_ent_std 6.65 / train/rep_loss_mean 3.68 / train/rep_loss_std 6.46 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.37 / train/reward_rate 0.31
/ train_stats/mean_log_entropy -1.85 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 6.49 / report/image_loss_mean 0.97 / report/image_loss_std 0.86 / report/model_loss_mean 3.32 / report/model_loss_std 4.59 / report/post_ent_mag 52.04 / report/post_ent_max 52.04 /
report/post_ent_mean 42.56 / report/post_ent_min 18.36 / report/post_ent_std 4.65 / report/prior_ent_mag 83.43 / report/prior_ent_max 83.43 / report/prior_ent_mean 46.17 / report/prior_ent_min 25.34 / report/prior_ent_std 6.2 / report/rep_loss_mean 3.65 / 
report/rep_loss_std 6.49 / report/reward_avg 0.33 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.3 / report/reward_max_data 1.87 / report/reward_max_pred 1.89 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.33 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 7.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.88 / eval/dyn_loss_std 6.36 / eval/image_loss_mean 0.98 / eval/image_loss_std 1.39 / eval/model_loss_mean 3.56 / eval/model_loss_std 4.83 / eval/post_ent_mag 50.56 / eval/post_ent_max 50.56 / eval/post_ent_mean 
42.45 / eval/post_ent_min 22.69 / eval/post_ent_std 4.11 / eval/prior_ent_mag 83.43 / eval/prior_ent_max 83.43 / eval/prior_ent_mean 46.42 / eval/prior_ent_min 27.85 / eval/prior_ent_std 5.66 / eval/rep_loss_mean 3.88 / eval/rep_loss_std 6.36 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.83 / eval/reward_max_pred 1.81 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.57 / eval/reward_rate 0.45 / 
replay/size 3.9e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3758 / timer/env.step_total 19.61 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 447.35 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7766 / timer/agent.policy_total 17.52 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 
/ timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1879 / timer/agent.train_total 241.53 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T055827F540090-2rnKmZ4sCDHxStGnczlX4K-1GnLsvVpa40b11ppC9Sech-1024.npz
train_Episode has 500 steps and return 277.8.
Starting evaluation at step 387500 Counter(387500) 387437
eval_Episode has 500 steps and return 303.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T055941F092779-2P2jXsDmEf5yLBEjo69Rgr-0000000000000000000000-778.npz
Saved chunk: 20230922T055949F220696-1GnLsvVpa40b11ppC9Sech-0000000000000000000000-528.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 284.0.
Starting evaluation at step 388000 Counter(388000) 387937
Saved chunk: 20230922T055941F092779-2P2jXsDmEf5yLBEjo69Rgr-5JdkqybxCHInqFE7J0ymSb-1024.npz
eval_Episode has 500 steps and return 309.1.
Saved chunk: 20230922T055949F220696-1GnLsvVpa40b11ppC9Sech-6092n649LI3XVZu7MqPu18-1024.npz
train_Episode has 500 steps and return 308.6.
Starting evaluation at step 388500 Counter(388500) 388437
eval_Episode has 500 steps and return 315.3.
train_Episode has 500 steps and return 298.0.
Starting evaluation at step 389000 Counter(389000) 388937
Saved chunk: 20230922T060101F693011-5JdkqybxCHInqFE7J0ymSb-0963NQPMbjpADygZr0BZ3F-1024.npz
eval_Episode has 500 steps and return 299.7.
Saved chunk: 20230922T060110F393930-6092n649LI3XVZu7MqPu18-0cR6TnyszeyqTMWzHkAvHz-1024.npz
train_Episode has 500 steps and return 286.2.
Starting evaluation at step 389500 Counter(389500) 389437
eval_Episode has 500 steps and return 309.6.
train_Episode has 500 steps and return 288.1.
Starting evaluation at step 390000 Counter(390000) 389937
Saved chunk: 20230922T060220F836187-0963NQPMbjpADygZr0BZ3F-3mX90Rfs0sAcBYAATWGFan-1024.npz
eval_Episode has 500 steps and return 330.6.
Saved chunk: 20230922T060231F082280-0cR6TnyszeyqTMWzHkAvHz-7AO9yKGCmnwsiQcRfkrvGy-1024.npz
train_Episode has 500 steps and return 280.9.
Starting evaluation at step 390500 Counter(390500) 390437
eval_Episode has 500 steps and return 321.0.
train_Episode has 500 steps and return 302.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 781642 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 302.54 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 320.99 / eval_episode/reward_rate 0.46 / train/action_mag 3.94 / train/action_max 3.79 / train/action_mean 4e-3 / train/action_min -3.69 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -0.45 / train/adv_mag 0.37 / train/adv_max 0.3 / train/adv_mean 6.9e-4
/ train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.67 / train/dyn_loss_std 6.5 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 1.9e5 / 
train/extr_critic_critic_opt_loss 8486.22 / train/extr_critic_mag 221.53 / train/extr_critic_max 221.53 / train/extr_critic_mean 210.84 / train/extr_critic_min 160.37 / train/extr_critic_std 12.86 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 /
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 221.81 / train/extr_return_raw_max 221.81 / train/extr_return_raw_mean 210.87 / train/extr_return_raw_min 
161.45 / train/extr_return_raw_std 12.9 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.38 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.97 / train/image_loss_std 0.92 / train/model_loss_mean 3.34 /
train/model_loss_std 4.6 / train/model_opt_grad_norm 8.52 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.04 / train/policy_entropy_max 
3.77 / train/policy_entropy_mean -2.14 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.16 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.14 / train/policy_logprob_min -10.16 / train/policy_logprob_std 1.97 / 
train/policy_randomness_mag 0.79 / train/policy_randomness_max 0.79 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.94 / train/post_ent_max 51.94 / train/post_ent_mean 41.69 / 
train/post_ent_min 21.45 / train/post_ent_std 5.12 / train/prior_ent_mag 83.38 / train/prior_ent_max 83.38 / train/prior_ent_mean 45.32 / train/prior_ent_min 26.97 / train/prior_ent_std 6.81 / train/rep_loss_mean 3.67 / train/rep_loss_std 6.5 / train/reward_avg 0.36 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.29 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.36 / train/reward_rate 
0.3 / train_stats/mean_log_entropy -2.31 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.43 / report/dyn_loss_std 5.86 / report/image_loss_mean 0.94 / report/image_loss_std 0.72 / report/model_loss_mean 3.15 / report/model_loss_std 4.05 / report/post_ent_mag 55.02 / report/post_ent_max 55.02 /
report/post_ent_mean 41.57 / report/post_ent_min 20.67 / report/post_ent_std 4.79 / report/prior_ent_mag 82.94 / report/prior_ent_max 82.94 / report/prior_ent_mean 45.02 / report/prior_ent_min 25.92 / report/prior_ent_std 6.4 / report/rep_loss_mean 3.43 / 
report/rep_loss_std 5.86 / report/reward_avg 0.33 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.29 / report/reward_max_data 1.88 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.33 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 5.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.7 / eval/dyn_loss_std 5.92 / eval/image_loss_mean 0.87 / eval/image_loss_std 0.93 / eval/model_loss_mean 3.36 / eval/model_loss_std 4.21 / eval/post_ent_mag 49.97 / eval/post_ent_max 49.97 / eval/post_ent_mean 42.83 / 
eval/post_ent_min 27.45 / eval/post_ent_std 3.75 / eval/prior_ent_mag 82.94 / eval/prior_ent_max 82.94 / eval/prior_ent_mean 46.58 / eval/prior_ent_min 34.25 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 3.7 / eval/rep_loss_std 5.92 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.86 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.64 / eval/reward_rate 0.48 / 
replay/size 3.9e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3814 / timer/env.step_total 20.11 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 453.5 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.4e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.68 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.36 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 
0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / 
timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 391000 Counter(391000) 390937
Saved chunk: 20230922T060339F751713-3mX90Rfs0sAcBYAATWGFan-6dI3N0K1Qscm78ec1gsAfS-1024.npz
eval_Episode has 500 steps and return 306.4.
Saved chunk: 20230922T060351F549419-7AO9yKGCmnwsiQcRfkrvGy-7ej8eZKcRLkPOd9SrHtnqc-1024.npz
train_Episode has 500 steps and return 285.4.
Starting evaluation at step 391500 Counter(391500) 391437
eval_Episode has 500 steps and return 315.6.
train_Episode has 500 steps and return 282.8.
Starting evaluation at step 392000 Counter(392000) 391937
Saved chunk: 20230922T060459F734507-6dI3N0K1Qscm78ec1gsAfS-4oIe8mWamlzsvJJpklk2rO-1024.npz
eval_Episode has 500 steps and return 308.3.
Saved chunk: 20230922T060513F222246-7ej8eZKcRLkPOd9SrHtnqc-7ENOV0zLjtlQ5p1tZpdQiG-1024.npz
train_Episode has 500 steps and return 292.7.
Starting evaluation at step 392500 Counter(392500) 392437
eval_Episode has 500 steps and return 314.5.
train_Episode has 500 steps and return 291.6.
Starting evaluation at step 393000 Counter(393000) 392937
Saved chunk: 20230922T060619F209232-4oIe8mWamlzsvJJpklk2rO-2XdtdXz9mjBwkGAH4G3wfr-1024.npz
eval_Episode has 500 steps and return 293.8.
Saved chunk: 20230922T060634F253375-7ENOV0zLjtlQ5p1tZpdQiG-6e0lJGXVJ2S438d6V1Ubam-1024.npz
train_Episode has 500 steps and return 254.8.
Starting evaluation at step 393500 Counter(393500) 393437
eval_Episode has 500 steps and return 307.1.
train_Episode has 500 steps and return 290.7.
Starting evaluation at step 394000 Counter(394000) 393937
Saved chunk: 20230922T060738F536536-2XdtdXz9mjBwkGAH4G3wfr-1cJPbcSHg8pLUdzYVQtCA5-1024.npz
eval_Episode has 500 steps and return 207.5.
Saved chunk: 20230922T060755F048219-6e0lJGXVJ2S438d6V1Ubam-2XD4OuTcboUzv0kpybsknX-1024.npz
train_Episode has 500 steps and return 283.1.
Starting evaluation at step 394500 Counter(394500) 394437
eval_Episode has 500 steps and return 311.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 789162 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 311.17 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 283.15 / episode/reward_rate 0.4 / train/action_mag 3.98 / train/action_max 3.84 / train/action_mean 9.4e-3 / train/action_min -3.7 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -0.56 / train/adv_mag 0.3 / train/adv_max 0.24 / train/adv_mean 6.9e-4 /
train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 8976.9 / train/extr_critic_mag 222.24 / train/extr_critic_max 222.24 / train/extr_critic_mean 211.66 / train/extr_critic_min 162.65 / train/extr_critic_std 12.3 / train/extr_return_normed_mag 1.39 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 222.52 / train/extr_return_raw_max 222.52 / train/extr_return_raw_mean 211.7 / train/extr_return_raw_min 
164.02 / train/extr_return_raw_std 12.32 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.61 / train/image_loss_mean 0.96 / train/image_loss_std 0.92 / train/model_loss_mean 3.32 
/ train/model_loss_std 4.56 / train/model_opt_grad_norm 8.4 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.08 / train/policy_entropy_max 
3.85 / train/policy_entropy_mean -2.1 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.17 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.1 / train/policy_logprob_min -10.17 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 52.1 / train/post_ent_max 52.1 / train/post_ent_mean 41.88 / 
train/post_ent_min 22.05 / train/post_ent_std 4.94 / train/prior_ent_mag 83.3 / train/prior_ent_max 83.3 / train/prior_ent_mean 45.5 / train/prior_ent_min 27.8 / train/prior_ent_std 6.63 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.42 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.37 / train/reward_rate 
0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.22 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 7.58 / report/image_loss_mean 0.98 / report/image_loss_std 1.01 / report/model_loss_mean 3.39 / report/model_loss_std 5.3 / report/post_ent_mag 50.67 / report/post_ent_max 50.67 / 
report/post_ent_mean 41.22 / report/post_ent_min 17.25 / report/post_ent_std 5.24 / report/prior_ent_mag 83.41 / report/prior_ent_max 83.41 / report/prior_ent_mean 44.87 / report/prior_ent_min 23.99 / report/prior_ent_std 7.12 / report/rep_loss_mean 3.76 / 
report/rep_loss_std 7.58 / report/reward_avg 0.3 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.3 / report/reward_max_data 1.85 / report/reward_max_pred 1.86 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.3 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.46 / eval/dyn_loss_std 7.43 / eval/image_loss_mean 1.22 / eval/image_loss_std 2.25 / eval/model_loss_mean 4.14 / eval/model_loss_std 6.43 / eval/post_ent_mag 49.83 / eval/post_ent_max 49.83 / eval/post_ent_mean 42.32 / 
eval/post_ent_min 20.81 / eval/post_ent_std 4.54 / eval/prior_ent_mag 83.41 / eval/prior_ent_max 83.41 / eval/prior_ent_mean 46.12 / eval/prior_ent_min 27.25 / eval/prior_ent_std 5.75 / eval/rep_loss_mean 4.46 / eval/rep_loss_std 7.43 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.54 / eval/reward_rate 0.44 / 
replay/size 3.9e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3760 / timer/env.step_total 19.57 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.09 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.8e-4 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.57 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.5 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 286.4.
Starting evaluation at step 395000 Counter(395000) 394937
Saved chunk: 20230922T060857F542570-1cJPbcSHg8pLUdzYVQtCA5-0BPxJORSlOWPi0b8WC6Caz-1024.npz
eval_Episode has 500 steps and return 309.4.
Saved chunk: 20230922T060915F646576-2XD4OuTcboUzv0kpybsknX-6c1KmjziPpKvyeqvpinTc9-1024.npz
train_Episode has 500 steps and return 277.5.
Starting evaluation at step 395500 Counter(395500) 395437
eval_Episode has 500 steps and return 302.2.
train_Episode has 500 steps and return 268.6.
Starting evaluation at step 396000 Counter(396000) 395937
eval_Episode has 500 steps and return 312.0.
Saved chunk: 20230922T061017F720544-0BPxJORSlOWPi0b8WC6Caz-3OYGKuqdsX6VAg4syuNRS8-1024.npz
train_Episode has 500 steps and return 276.2.
Saved chunk: 20230922T061037F501307-6c1KmjziPpKvyeqvpinTc9-4YUXqAjLTHxHrIdBna9c2l-1024.npz
Starting evaluation at step 396500 Counter(396500) 396437
eval_Episode has 500 steps and return 306.1.
train_Episode has 500 steps and return 289.2.
Starting evaluation at step 397000 Counter(397000) 396937
eval_Episode has 500 steps and return 322.6.
Saved chunk: 20230922T061137F008589-3OYGKuqdsX6VAg4syuNRS8-0RbQYi7Ki6V6I9whF2QsWa-1024.npz
train_Episode has 500 steps and return 287.6.
Saved chunk: 20230922T061158F294422-4YUXqAjLTHxHrIdBna9c2l-3lAVJZjgAHIeaZ6AbTam9B-1024.npz
Starting evaluation at step 397500 Counter(397500) 397437
eval_Episode has 500 steps and return 300.1.
train_Episode has 500 steps and return 303.9.
Starting evaluation at step 398000 Counter(398000) 397937
eval_Episode has 500 steps and return 306.1.
Saved chunk: 20230922T061256F204265-0RbQYi7Ki6V6I9whF2QsWa-4F1vr30OBXSOXy6y2GMkuO-1024.npz
train_Episode has 500 steps and return 302.7.
Saved chunk: 20230922T061318F986042-3lAVJZjgAHIeaZ6AbTam9B-39mpliD5hC5AAZlJ10Idrh-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 796790 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 302.72 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 306.09 / eval_episode/reward_rate 0.43 / train/action_mag 3.97 / train/action_max 3.85 / train/action_mean 0.02 / train/action_min -3.73 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 0.08 / train/adv_mag 0.31 / train/adv_max 0.24 / train/adv_mean 5.8e-4 /
train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.69 / train/dyn_loss_std 6.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 9412.36 / train/extr_critic_mag 222.91 / train/extr_critic_max 222.91 / train/extr_critic_mean 211.73 / train/extr_critic_min 156.54 / train/extr_critic_std 14.19 / train/extr_return_normed_mag 1.34 / train/extr_return_normed_max 1.03 /
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 223.19 / train/extr_return_raw_max 223.19 / train/extr_return_raw_mean 211.76 / train/extr_return_raw_min 
156.71 / train/extr_return_raw_std 14.22 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.97 / train/image_loss_std 0.93 / train/model_loss_mean 3.36 
/ train/model_loss_std 4.61 / train/model_opt_grad_norm 8.25 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 2.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7894.74 / train/policy_entropy_mag 4.2 / 
train/policy_entropy_max 4.06 / train/policy_entropy_mean -1.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.28 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.94 / train/policy_logprob_min -10.28 / 
train/policy_logprob_std 2 / train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.98 / train/post_ent_max 51.98 / 
train/post_ent_mean 41.86 / train/post_ent_min 21.71 / train/post_ent_std 5 / train/prior_ent_mag 83.29 / train/prior_ent_max 83.29 / train/prior_ent_mean 45.52 / train/prior_ent_min 27.7 / train/prior_ent_std 6.69 / train/rep_loss_mean 3.69 / train/rep_loss_std 6.49 / 
train/reward_avg 0.38 / train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.38 / train/reward_rate 0.31 / train_stats/mean_log_entropy -2.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 4.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.58 / report/dyn_loss_std 6.35 / report/image_loss_mean 0.91 / report/image_loss_std 0.81 / report/model_loss_mean 3.22 / report/model_loss_std 4.44 / report/post_ent_mag 
52.86 / report/post_ent_max 52.86 / report/post_ent_mean 41.54 / report/post_ent_min 25.07 / report/post_ent_std 4.8 / report/prior_ent_mag 83.3 / report/prior_ent_max 83.3 / report/prior_ent_mean 45.04 / report/prior_ent_min 29.8 / report/prior_ent_std 6.76 / 
report/rep_loss_mean 3.58 / report/rep_loss_std 6.35 / report/reward_avg 0.36 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.86 / report/reward_max_pred 1.86 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.36 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 5.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.52 / eval/dyn_loss_std 5.59 / eval/image_loss_mean 0.82 / eval/image_loss_std 0.79 / eval/model_loss_mean 3.19 / eval/model_loss_std 3.99 / eval/post_ent_mag 51.18 / 
eval/post_ent_max 51.18 / eval/post_ent_mean 43.05 / eval/post_ent_min 28.12 / eval/post_ent_std 3.51 / eval/prior_ent_mag 83.3 / eval/prior_ent_max 83.3 / eval/prior_ent_mean 46.56 / eval/prior_ent_min 35.88 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 3.52 / 
eval/rep_loss_std 5.59 / eval/reward_avg 0.61 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.89 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / 
eval/reward_pred 0.6 / eval/reward_rate 0.45 / replay/size 4e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3814 / timer/env.step_total 19.77
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 454.84 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 6.8e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 
/ timer/agent.train_count 1907 / timer/agent.train_total 244.89 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.7e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / 
timer/dataset_eval_max 2.9e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 398500 Counter(398500) 398437
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 278.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 399000 Counter(399000) 398937
Saved chunk: 20230922T061415F119376-4F1vr30OBXSOXy6y2GMkuO-0000000000000000000000-537.npz
Saved chunk: 20230922T061439F516312-39mpliD5hC5AAZlJ10Idrh-0000000000000000000000-664.npz
eval_Episode has 500 steps and return 302.4.
Saved chunk: 20230922T061415F119376-4F1vr30OBXSOXy6y2GMkuO-4AeXneugasRIrDTJFDzFmr-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 296.2.
Saved chunk: 20230922T061439F516312-39mpliD5hC5AAZlJ10Idrh-3eDZpkDyefGQvu1pcT70av-1024.npz
Starting evaluation at step 399500 Counter(399500) 399437
eval_Episode has 500 steps and return 321.0.
train_Episode has 500 steps and return 265.6.
Starting evaluation at step 400000 Counter(400000) 399937
eval_Episode has 500 steps and return 314.3.
train_Episode has 500 steps and return 291.7.
Saved chunk: 20230922T061601F876975-3eDZpkDyefGQvu1pcT70av-6d2njCL8PG9OBVV6Cud6Ww-1024.npz
Starting evaluation at step 400500 Counter(400500) 400437
Saved chunk: 20230922T061535F738458-4AeXneugasRIrDTJFDzFmr-4UWm8s0MGRz4toqDk3HcmS-1024.npz
eval_Episode has 500 steps and return 330.6.
train_Episode has 500 steps and return 274.1.
Starting evaluation at step 401000 Counter(401000) 400937
eval_Episode has 500 steps and return 319.4.
train_Episode has 500 steps and return 291.9.
Saved chunk: 20230922T061722F833590-6d2njCL8PG9OBVV6Cud6Ww-3GTQjfHjgtoRllv6ITPl5Z-1024.npz
Starting evaluation at step 401500 Counter(401500) 401437
Saved chunk: 20230922T061731F273624-4UWm8s0MGRz4toqDk3HcmS-4n3yyGiBnKhKDaIsFzzirf-1024.npz
eval_Episode has 500 steps and return 314.7.
train_Episode has 500 steps and return 296.2.
Starting evaluation at step 402000 Counter(402000) 401937
eval_Episode has 500 steps and return 320.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 804298 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 320.26 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 296.23 / episode/reward_rate 0.42 / train/action_mag 3.97 / train/action_max 3.88 / train/action_mean 0.02 / train/action_min -3.69 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -1.1 / train/adv_mag 0.34 / train/adv_max 0.28 / train/adv_mean 6.9e-4 /
train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.45 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 9707.78 / train/extr_critic_mag 223.49 / train/extr_critic_max 223.49 / train/extr_critic_mean 212.28 / train/extr_critic_min 153.08 / train/extr_critic_std 14.85 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.03 /
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 223.75 / train/extr_return_raw_max 223.75 / train/extr_return_raw_mean 212.32 / train/extr_return_raw_min 
152.7 / train/extr_return_raw_std 14.88 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.39 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.96 / train/image_loss_std 0.91 / train/model_loss_mean 3.33 /
train/model_loss_std 4.56 / train/model_opt_grad_norm 8.22 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9468.09 / train/policy_entropy_mag 4.31 / train/policy_entropy_max
4.24 / train/policy_entropy_mean -1.92 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.45 / train/policy_logprob_mag 10.44 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.92 / train/policy_logprob_min -10.44 / train/policy_logprob_std 2.03 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 2.7e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 41.84 / 
train/post_ent_min 21.77 / train/post_ent_std 5.01 / train/prior_ent_mag 83.15 / train/prior_ent_max 83.15 / train/prior_ent_mean 45.45 / train/prior_ent_min 27.52 / train/prior_ent_std 6.7 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.45 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.29 / train/reward_max_data 1.9 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.37 / train/reward_rate 
0.3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.16 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 5.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 6.54 / report/image_loss_mean 0.95 / report/image_loss_std 0.88 / report/model_loss_mean 3.31 / report/model_loss_std 4.55 / report/post_ent_mag 51.91 / report/post_ent_max 51.91 /
report/post_ent_mean 40.74 / report/post_ent_min 16.95 / report/post_ent_std 7.43 / report/prior_ent_mag 83.39 / report/prior_ent_max 83.39 / report/prior_ent_mean 44.26 / report/prior_ent_min 17.26 / report/prior_ent_std 9.19 / report/rep_loss_mean 3.64 / 
report/rep_loss_std 6.54 / report/reward_avg 0.36 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.29 / report/reward_max_data 1.93 / report/reward_max_pred 1.86 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.35 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 4.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.13 / eval/dyn_loss_std 6.34 / eval/image_loss_mean 1 / eval/image_loss_std 1.42 / eval/model_loss_mean 3.75 / eval/model_loss_std 5.02 / eval/post_ent_mag 51.01 / eval/post_ent_max 51.01 / eval/post_ent_mean 
42.33 / eval/post_ent_min 19.76 / eval/post_ent_std 4.04 / eval/prior_ent_mag 83.39 / eval/prior_ent_max 83.39 / eval/prior_ent_mean 46.4 / eval/prior_ent_min 33.68 / eval/prior_ent_std 5.56 / eval/rep_loss_mean 4.13 / eval/rep_loss_std 6.34 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.4 / eval/reward_max_data 1.84 / eval/reward_max_pred 1.81 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.57 / eval/reward_rate 0.44 / 
replay/size 4e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3754 / timer/env.step_total 19.62 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.35 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.83 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 6.2e-4 / timer/agent.train_count 1877 / timer/agent.train_total 241.1 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9e-8 / timer/dataset_eval_avg 2.7e-5 / 
timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 272.3.
Saved chunk: 20230922T061843F583680-3GTQjfHjgtoRllv6ITPl5Z-20YZURgA1BGySdEycW6ZQz-1024.npz
Starting evaluation at step 402500 Counter(402500) 402437
Saved chunk: 20230922T061850F424812-4n3yyGiBnKhKDaIsFzzirf-5QizhaFD7qQMf2oogxRrji-1024.npz
eval_Episode has 500 steps and return 314.6.
train_Episode has 500 steps and return 280.9.
Starting evaluation at step 403000 Counter(403000) 402937
eval_Episode has 500 steps and return 313.8.
train_Episode has 500 steps and return 282.8.
Saved chunk: 20230922T062005F274253-20YZURgA1BGySdEycW6ZQz-4W9Nj1TZMuj1t46F0hubDl-1024.npz
Starting evaluation at step 403500 Counter(403500) 403437
Saved chunk: 20230922T062010F578357-5QizhaFD7qQMf2oogxRrji-6b7NqxJQ4z5krhXRdG91Kh-1024.npz
eval_Episode has 500 steps and return 304.8.
train_Episode has 500 steps and return 279.0.
Starting evaluation at step 404000 Counter(404000) 403937
eval_Episode has 500 steps and return 300.4.
train_Episode has 500 steps and return 271.6.
Saved chunk: 20230922T062126F396636-4W9Nj1TZMuj1t46F0hubDl-1BM52igFt748gUKJGRhhGF-1024.npz
Starting evaluation at step 404500 Counter(404500) 404437
Saved chunk: 20230922T062130F125905-6b7NqxJQ4z5krhXRdG91Kh-2Fj82OAE7nIssTbLB9ia12-1024.npz
eval_Episode has 500 steps and return 312.2.
train_Episode has 500 steps and return 311.2.
Starting evaluation at step 405000 Counter(405000) 404937
eval_Episode has 500 steps and return 313.0.
train_Episode has 500 steps and return 294.8.
Starting evaluation at step 405500 Counter(405500) 405437
Saved chunk: 20230922T062249F464953-2Fj82OAE7nIssTbLB9ia12-14YbxWqBmIrKyKNCDAymK6-1024.npz
eval_Episode has 500 steps and return 326.0.
Saved chunk: 20230922T062247F352990-1BM52igFt748gUKJGRhhGF-5TumB3BbCO8tHboGAFOnAS-1024.npz
train_Episode has 500 steps and return 293.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 811910 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.09 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 325.99 / eval_episode/reward_rate 0.47 / train/action_mag 4.06 / train/action_max 3.94 / train/action_mean 0.03 / train/action_min -3.74 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss 1.05 / train/adv_mag 0.4 / train/adv_max 0.35 / train/adv_mean 4.7e-4 / 
train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.71 / train/dyn_loss_std 6.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 224.03 / train/extr_critic_max 224.03 / train/extr_critic_mean 213.26 / train/extr_critic_min 158 / train/extr_critic_std 13.12 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.83 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 224.34 / train/extr_return_raw_max 224.34 / train/extr_return_raw_mean 213.28 / train/extr_return_raw_min 
160.44 / train/extr_return_raw_std 13.15 / train/extr_reward_mag 1.93 / train/extr_reward_max 1.93 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.98 / train/image_loss_std 0.94 / train/model_loss_mean 3.37 /
train/model_loss_std 4.64 / train/model_opt_grad_norm 8.32 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 2.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7368.42 / train/policy_entropy_mag 4.1 / train/policy_entropy_max 
3.94 / train/policy_entropy_mean -1.92 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.56 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.92 / train/policy_logprob_min -10.56 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.77 / train/post_ent_max 51.77 / train/post_ent_mean 41.84 / 
train/post_ent_min 21.83 / train/post_ent_std 5.01 / train/prior_ent_mag 83.14 / train/prior_ent_max 83.14 / train/prior_ent_mean 45.5 / train/prior_ent_min 27.64 / train/prior_ent_std 6.67 / train/rep_loss_mean 3.71 / train/rep_loss_std 6.52 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.11 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 7.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.62 / report/dyn_loss_std 6.54 / report/image_loss_mean 0.89 / report/image_loss_std 0.73 / report/model_loss_mean 3.24 / report/model_loss_std 4.53 / report/post_ent_mag 51.81 / report/post_ent_max 51.81 /
report/post_ent_mean 42.31 / report/post_ent_min 24.14 / report/post_ent_std 4.17 / report/prior_ent_mag 82.88 / report/prior_ent_max 82.88 / report/prior_ent_mean 46 / report/prior_ent_min 34.84 / report/prior_ent_std 5.94 / report/rep_loss_mean 3.62 / 
report/rep_loss_std 6.54 / report/reward_avg 0.41 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.28 / report/reward_max_data 1.8 / report/reward_max_pred 1.85 / report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.41 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 6.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.79 / eval/dyn_loss_std 6.05 / eval/image_loss_mean 0.96 / eval/image_loss_std 1.15 / eval/model_loss_mean 3.47 / eval/model_loss_std 4.38 / eval/post_ent_mag 50.6 / eval/post_ent_max 50.6 / eval/post_ent_mean 
42.53 / eval/post_ent_min 21.7 / eval/post_ent_std 4.18 / eval/prior_ent_mag 82.88 / eval/prior_ent_max 82.88 / eval/prior_ent_mean 46.27 / eval/prior_ent_min 26.97 / eval/prior_ent_std 5.81 / eval/rep_loss_mean 3.79 / eval/rep_loss_std 6.05 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.88 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.57 / eval/reward_rate 0.44 / 
replay/size 4.1e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3806 / timer/env.step_total 19.77 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.42 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1903 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.77 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 406000 Counter(406000) 405937
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 251.6.
Starting evaluation at step 406500 Counter(406500) 406437
Saved chunk: 20230922T062408F493970-14YbxWqBmIrKyKNCDAymK6-0EPbWtrdIyepiQmaRcoRAa-1024.npz
eval_Episode has 500 steps and return 292.8.
Saved chunk: 20230922T062411F486859-5TumB3BbCO8tHboGAFOnAS-5WLbnmLBRyEXRVyu0hI6kQ-1024.npz
train_Episode has 500 steps and return 288.4.
Starting evaluation at step 407000 Counter(407000) 406937
eval_Episode has 500 steps and return 305.1.
train_Episode has 500 steps and return 290.9.
Starting evaluation at step 407500 Counter(407500) 407437
Saved chunk: 20230922T062528F844126-0EPbWtrdIyepiQmaRcoRAa-1TnHWV1gbNdHOnw0ujVQO9-1024.npz
eval_Episode has 500 steps and return 308.6.
Saved chunk: 20230922T062533F428148-5WLbnmLBRyEXRVyu0hI6kQ-6QPrzR4e30lN2sHbjcC0ty-1024.npz
train_Episode has 500 steps and return 278.3.
Starting evaluation at step 408000 Counter(408000) 407937
eval_Episode has 500 steps and return 293.0.
train_Episode has 500 steps and return 277.5.
Starting evaluation at step 408500 Counter(408500) 408437
Saved chunk: 20230922T062648F181355-1TnHWV1gbNdHOnw0ujVQO9-5p8lNmmPWn1zVE7tdkS4po-1024.npz
eval_Episode has 500 steps and return 315.6.
Saved chunk: 20230922T062654F318798-6QPrzR4e30lN2sHbjcC0ty-5K0DpZA1Bu6qwDYTbTKOQI-1024.npz
train_Episode has 500 steps and return 276.8.
Starting evaluation at step 409000 Counter(409000) 408937
eval_Episode has 500 steps and return 334.0.
train_Episode has 500 steps and return 314.4.
Starting evaluation at step 409500 Counter(409500) 409437
Saved chunk: 20230922T062807F319484-5p8lNmmPWn1zVE7tdkS4po-1lSLJl26iDAFvxM7eZtuJJ-1024.npz
eval_Episode has 500 steps and return 307.1.
Saved chunk: 20230922T062815F031775-5K0DpZA1Bu6qwDYTbTKOQI-2U8WVWfseqdZIL9Grp27fc-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 819434 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 307.1 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 314.38 / episode/reward_rate 0.45 / train/action_mag 4.02 / train/action_max 3.94 / train/action_mean 0.03 / train/action_min -3.7 / train/action_std 
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -0.39 / train/adv_mag 0.36 / train/adv_max 0.3 / train/adv_mean 6.2e-4 / train/adv_min 
-0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.63 / train/dyn_loss_std 6.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2e5 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 224.54 / train/extr_critic_max 224.54 / train/extr_critic_mean 213.2 / train/extr_critic_min 148.21 / train/extr_critic_std 15.26 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 224.84 / train/extr_return_raw_max 224.84 / train/extr_return_raw_mean 213.23 / train/extr_return_raw_min 
149.09 / train/extr_return_raw_std 15.28 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.94 / train/image_loss_std 0.89 / train/model_loss_mean 3.29 /
train/model_loss_std 4.52 / train/model_opt_grad_norm 8.47 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.19 / train/policy_entropy_max 
3.96 / train/policy_entropy_mean -1.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.26 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.94 / train/policy_logprob_min -10.26 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.99 / train/post_ent_max 51.99 / train/post_ent_mean 41.88 / 
train/post_ent_min 21.86 / train/post_ent_std 5.04 / train/prior_ent_mag 83.07 / train/prior_ent_max 83.07 / train/prior_ent_mean 45.47 / train/prior_ent_min 27.21 / train/prior_ent_std 6.71 / train/rep_loss_mean 3.63 / train/rep_loss_std 6.39 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.13 / report/cont_avg 1 / report/cont_loss_mean 1.3e-11 / report/cont_loss_std 3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.69 / report/dyn_loss_std 6.5 / report/image_loss_mean 0.97 / report/image_loss_std 0.96 / report/model_loss_mean 3.36 / report/model_loss_std 4.62 / report/post_ent_mag 51.08 / report/post_ent_max 51.08 / 
report/post_ent_mean 42.87 / report/post_ent_min 21.96 / report/post_ent_std 4.27 / report/prior_ent_mag 83.05 / report/prior_ent_max 83.05 / report/prior_ent_mean 46.28 / report/prior_ent_min 28.21 / report/prior_ent_std 5.95 / report/rep_loss_mean 3.69 / 
report/rep_loss_std 6.5 / report/reward_avg 0.39 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 1.9 / report/reward_max_pred 1.85 / report/reward_neg_acc 1 / report/reward_neg_loss 5.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.38 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.04 / eval/dyn_loss_std 6.31 / eval/image_loss_mean 1.06 / eval/image_loss_std 1.51 / eval/model_loss_mean 3.73 / eval/model_loss_std 4.93 / eval/post_ent_mag 50.5 / eval/post_ent_max 50.5 / eval/post_ent_mean 
42.31 / eval/post_ent_min 22.14 / eval/post_ent_std 4.37 / eval/prior_ent_mag 83.05 / eval/prior_ent_max 83.05 / eval/prior_ent_mean 46.18 / eval/prior_ent_min 26.74 / eval/prior_ent_std 5.92 / eval/rep_loss_mean 4.04 / eval/rep_loss_std 6.31 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.6 / eval/reward_rate 0.44 / 
replay/size 4.1e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3762 / timer/env.step_total 19.51 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.56 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.43 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.6e-3 
/ timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.82 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.07

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 281.5.
Starting evaluation at step 410000 Counter(410000) 409937
eval_Episode has 500 steps and return 307.4.
train_Episode has 500 steps and return 289.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T062935F588070-2U8WVWfseqdZIL9Grp27fc-0000000000000000000000-801.npz
Saved chunk: 20230922T062926F331211-1lSLJl26iDAFvxM7eZtuJJ-0000000000000000000000-795.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 410500 Counter(410500) 410437
Saved chunk: 20230922T062926F331211-1lSLJl26iDAFvxM7eZtuJJ-5oT1cCpvubunJsDCnDBr4u-1024.npz
eval_Episode has 500 steps and return 311.3.
Saved chunk: 20230922T062935F588070-2U8WVWfseqdZIL9Grp27fc-1e3D8KX7pcJEyie8LfDC8P-1024.npz
train_Episode has 500 steps and return 300.0.
Starting evaluation at step 411000 Counter(411000) 410937
eval_Episode has 500 steps and return 318.9.
train_Episode has 500 steps and return 303.3.
Starting evaluation at step 411500 Counter(411500) 411437
Saved chunk: 20230922T063047F050845-5oT1cCpvubunJsDCnDBr4u-0bUkOZ09DGlLlDXd7B8ZeJ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063057F950892-1e3D8KX7pcJEyie8LfDC8P-60QPgBv5x89WJeuNY1A13y-1024.npz
train_Episode has 500 steps and return 272.3.
Starting evaluation at step 412000 Counter(412000) 411937
eval_Episode has 500 steps and return 331.9.
train_Episode has 500 steps and return 233.9.
Starting evaluation at step 412500 Counter(412500) 412437
Saved chunk: 20230922T063206F488765-0bUkOZ09DGlLlDXd7B8ZeJ-2t6c2QaW7wdqShdjSTdMkh-1024.npz
eval_Episode has 500 steps and return 288.9.
Saved chunk: 20230922T063218F935702-60QPgBv5x89WJeuNY1A13y-5XuikW48oizI2b1GZO9EAI-1024.npz
train_Episode has 500 steps and return 281.7.
Starting evaluation at step 413000 Counter(413000) 412937
eval_Episode has 500 steps and return 318.4.
train_Episode has 500 steps and return 235.6.
Starting evaluation at step 413500 Counter(413500) 413437
Saved chunk: 20230922T063325F591844-2t6c2QaW7wdqShdjSTdMkh-2uKsRcLYjY9giFA6oVK8dv-1024.npz
eval_Episode has 500 steps and return 309.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 827002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 235.58 / episode/reward_rate 0.35 / eval_episode/length 500 / eval_episode/score 309.52 / eval_episode/reward_rate 0.43 / train/action_mag 3.99 / train/action_max 3.88 / train/action_mean 0.03 / train/action_min -3.73 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 1.69 / train/adv_mag 0.27 / train/adv_max 0.2 / train/adv_mean 4.1e-4 
/ train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.67 / train/dyn_loss_std 6.44 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 225.11 / train/extr_critic_max 225.11 / train/extr_critic_mean 214.07 / train/extr_critic_min 156.18 / train/extr_critic_std 14.37 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 225.39 / train/extr_return_raw_max 225.39 / train/extr_return_raw_mean 214.09 / train/extr_return_raw_min 
155.51 / train/extr_return_raw_std 14.4 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.96 / train/image_loss_std 0.93 / train/model_loss_mean 3.34 / 
train/model_loss_std 4.57 / train/model_opt_grad_norm 8.41 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.19 / train/policy_entropy_max 
4.05 / train/policy_entropy_mean -1.94 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.38 / train/policy_logprob_mag 10.24 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.94 / train/policy_logprob_min -10.24 / train/policy_logprob_std 1.99 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.88 / train/post_ent_max 51.88 / train/post_ent_mean 41.98 / 
train/post_ent_min 21.85 / train/post_ent_std 4.96 / train/prior_ent_mag 82.99 / train/prior_ent_max 82.99 / train/prior_ent_mean 45.61 / train/prior_ent_min 27.48 / train/prior_ent_std 6.6 / train/rep_loss_mean 3.67 / train/rep_loss_std 6.44 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.9 / train/reward_max_pred 1.89 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 2.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.64 / report/dyn_loss_std 6.63 / report/image_loss_mean 0.96 / report/image_loss_std 0.92 / report/model_loss_mean 3.28 / report/model_loss_std 4.63 / report/post_ent_mag 52.29 / report/post_ent_max 52.29 /
report/post_ent_mean 41.5 / report/post_ent_min 20.23 / report/post_ent_std 4.88 / report/prior_ent_mag 83.38 / report/prior_ent_max 83.38 / report/prior_ent_mean 45.17 / report/prior_ent_min 26.27 / report/prior_ent_std 6.68 / report/rep_loss_mean 3.64 / 
report/rep_loss_std 6.63 / report/reward_avg 0.28 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.28 / report/reward_max_data 1.91 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.28 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.18 / eval/dyn_loss_std 6.73 / eval/image_loss_mean 1.05 / eval/image_loss_std 1.41 / eval/model_loss_mean 3.82 / eval/model_loss_std 5.03 / eval/post_ent_mag 50.67 / eval/post_ent_max 50.67 / eval/post_ent_mean 
42.12 / eval/post_ent_min 20.42 / eval/post_ent_std 4.57 / eval/prior_ent_mag 83.38 / eval/prior_ent_max 83.38 / eval/prior_ent_mean 46.21 / eval/prior_ent_min 26.19 / eval/prior_ent_std 6.11 / eval/rep_loss_mean 4.18 / eval/rep_loss_std 6.73 / eval/reward_avg 0.59 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.58 / eval/reward_rate 0.45 / 
replay/size 4.1e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.09 / timer/env.step_count 3784 / timer/env.step_total 19.9 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.18 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7792 / timer/agent.policy_total 17.67 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1892 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1892 / timer/agent.train_total 243.11 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / 
timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T063339F565701-5XuikW48oizI2b1GZO9EAI-2KcXZAXYaKksQJzATVIY4K-1024.npz
train_Episode has 500 steps and return 311.2.
Starting evaluation at step 414000 Counter(414000) 413937
eval_Episode has 500 steps and return 319.1.
train_Episode has 500 steps and return 292.8.
Starting evaluation at step 414500 Counter(414500) 414437
Saved chunk: 20230922T063444F566298-2uKsRcLYjY9giFA6oVK8dv-2drtSwcaiG7mI0x3To4M2E-1024.npz
eval_Episode has 500 steps and return 330.3.
Saved chunk: 20230922T063501F234260-2KcXZAXYaKksQJzATVIY4K-3bSZuiLkyY3xkbmWgfnqI4-1024.npz
train_Episode has 500 steps and return 278.5.
Starting evaluation at step 415000 Counter(415000) 414937
eval_Episode has 500 steps and return 308.6.
train_Episode has 500 steps and return 273.8.
Starting evaluation at step 415500 Counter(415500) 415437
Saved chunk: 20230922T063605F080315-2drtSwcaiG7mI0x3To4M2E-78LzFzDk84nAB2BkclIABf-1024.npz
eval_Episode has 500 steps and return 328.3.
Saved chunk: 20230922T063622F274758-3bSZuiLkyY3xkbmWgfnqI4-61tKzan4Z64cSpstfte1cZ-1024.npz
train_Episode has 500 steps and return 305.8.
Starting evaluation at step 416000 Counter(416000) 415937
eval_Episode has 500 steps and return 304.4.
train_Episode has 500 steps and return 288.4.
Starting evaluation at step 416500 Counter(416500) 416437
Saved chunk: 20230922T063724F392995-78LzFzDk84nAB2BkclIABf-5GFnIIJREjsdT93R8QVeMm-1024.npz
eval_Episode has 500 steps and return 292.2.
Saved chunk: 20230922T063744F767096-61tKzan4Z64cSpstfte1cZ-5AVv3caxedtaaXOIDpDYQM-1024.npz
train_Episode has 500 steps and return 303.3.
Starting evaluation at step 417000 Counter(417000) 416937
eval_Episode has 500 steps and return 325.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 834578 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 303.3 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 325.49 / eval_episode/reward_rate 0.45 / train/action_mag 4.05 / train/action_max 3.95 / train/action_mean 0.04 / train/action_min -3.76 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 3.59 / train/adv_mag 0.34 / train/adv_max 0.28 / train/adv_mean 1.9e-4 / train/adv_min 
-0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 225.47 / train/extr_critic_max 225.47 / train/extr_critic_mean 214.09 / train/extr_critic_min 150.39 / train/extr_critic_std 15.31 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.83 / train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 225.74 / train/extr_return_raw_max 225.74 / train/extr_return_raw_mean 214.1 / train/extr_return_raw_min 
151.24 / train/extr_return_raw_std 15.37 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.96 / train/image_loss_std 0.92 / train/model_loss_mean 3.33 /
train/model_loss_std 4.56 / train/model_opt_grad_norm 8.2 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.49 / train/policy_entropy_max 
4.4 / train/policy_entropy_mean -1.85 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.48 / train/policy_logprob_mag 10.65 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.85 / train/policy_logprob_min -10.65 / train/policy_logprob_std 2.06 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 3.1e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 52.06 / train/post_ent_max 52.06 / train/post_ent_mean 41.88 / 
train/post_ent_min 22.02 / train/post_ent_std 5.02 / train/prior_ent_mag 82.93 / train/prior_ent_max 82.93 / train/prior_ent_mean 45.51 / train/prior_ent_min 27.56 / train/prior_ent_std 6.66 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.41 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.12 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.57 / report/dyn_loss_std 6.38 / report/image_loss_mean 0.96 / report/image_loss_std 1.01 / report/model_loss_mean 3.25 / report/model_loss_std 4.62 / report/post_ent_mag 51.63 / report/post_ent_max 51.63 /
report/post_ent_mean 40.41 / report/post_ent_min 19.66 / report/post_ent_std 6.68 / report/prior_ent_mag 82.91 / report/prior_ent_max 82.91 / report/prior_ent_mean 43.93 / report/prior_ent_min 22.7 / report/prior_ent_std 8.18 / report/rep_loss_mean 3.57 / 
report/rep_loss_std 6.38 / report/reward_avg 0.31 / report/reward_loss_mean 0.14 / report/reward_loss_std 0.28 / report/reward_max_data 1.92 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 4.4e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.31 / report/reward_rate 0.24 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.04 / eval/dyn_loss_std 6.45 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.48 / eval/model_loss_mean 3.67 / eval/model_loss_std 5 / eval/post_ent_mag 50.56 / eval/post_ent_max 50.56 / eval/post_ent_mean 
42.54 / eval/post_ent_min 17.02 / eval/post_ent_std 4.29 / eval/prior_ent_mag 82.91 / eval/prior_ent_max 82.91 / eval/prior_ent_mean 46.47 / eval/prior_ent_min 34.77 / eval/prior_ent_std 5.6 / eval/rep_loss_mean 4.04 / eval/rep_loss_std 6.45 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.41 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.61 / eval/reward_rate 0.45 / 
replay/size 4.2e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3788 / timer/env.step_total 19.64 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.89 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.2e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7295 / timer/agent.policy_total 16.46 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 
/ timer/dataset_train_count 1894 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1894 / timer/agent.train_total 245.11 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.85 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 261.1.
Starting evaluation at step 417500 Counter(417500) 417437
Saved chunk: 20230922T063845F117782-5GFnIIJREjsdT93R8QVeMm-1ZAUw8shMvfcQo2usaE6iU-1024.npz
eval_Episode has 500 steps and return 319.5.
Saved chunk: 20230922T063905F278085-5AVv3caxedtaaXOIDpDYQM-3yxvCf7cGPDCfMlAsIGolz-1024.npz
train_Episode has 500 steps and return 294.3.
Starting evaluation at step 418000 Counter(418000) 417937
eval_Episode has 500 steps and return 310.4.
train_Episode has 500 steps and return 290.2.
Starting evaluation at step 418500 Counter(418500) 418437
Saved chunk: 20230922T064005F111062-1ZAUw8shMvfcQo2usaE6iU-5enk9n45I2FlyrHJgXFfeh-1024.npz
eval_Episode has 500 steps and return 317.8.
Saved chunk: 20230922T064027F065025-3yxvCf7cGPDCfMlAsIGolz-0WuxSk6FWMdebfFXPg3PZn-1024.npz
train_Episode has 500 steps and return 277.1.
Starting evaluation at step 419000 Counter(419000) 418937
eval_Episode has 500 steps and return 323.7.
train_Episode has 500 steps and return 283.9.
Starting evaluation at step 419500 Counter(419500) 419437
eval_Episode has 500 steps and return 300.4.
Saved chunk: 20230922T064124F477898-5enk9n45I2FlyrHJgXFfeh-08hkSFNL0Mdx7eazcvN9NU-1024.npz
train_Episode has 500 steps and return 303.1.
Saved chunk: 20230922T064147F905255-0WuxSk6FWMdebfFXPg3PZn-7MC7iij0xl6YBc8j4R4ug8-1024.npz
Starting evaluation at step 420000 Counter(420000) 419937
eval_Episode has 500 steps and return 329.2.
train_Episode has 500 steps and return 299.2.
Starting evaluation at step 420500 Counter(420500) 420437
eval_Episode has 500 steps and return 307.7.
Saved chunk: 20230922T064243F632833-08hkSFNL0Mdx7eazcvN9NU-0TW3O3lfjszWwpOpA7huYU-1024.npz
train_Episode has 500 steps and return 293.9.
Saved chunk: 20230922T064308F600490-7MC7iij0xl6YBc8j4R4ug8-7H1eayVEttg2qzA4ttypqD-1024.npz
Starting evaluation at step 421000 Counter(421000) 420937
eval_Episode has 500 steps and return 303.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 842106 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 293.91 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 303.72 / eval_episode/reward_rate 0.43 / train/action_mag 4.03 / train/action_max 3.96 / train/action_mean 0.04 / train/action_min -3.71 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 1.29 / train/adv_mag 0.42 / train/adv_max 0.36 / train/adv_mean 4.5e-4
/ train/adv_min -0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 6.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 225.76 / train/extr_critic_max 225.76 / train/extr_critic_mean 214.05 / train/extr_critic_min 150.95 / train/extr_critic_std 15.82 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.04 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 226.02 / train/extr_return_raw_max 226.02 / train/extr_return_raw_mean 214.07 / train/extr_return_raw_min 
152 / train/extr_return_raw_std 15.83 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.96 / train/image_loss_std 0.94 / train/model_loss_mean 3.35 / 
train/model_loss_std 4.59 / train/model_opt_grad_norm 8.55 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.68 / train/policy_entropy_max 
4.62 / train/policy_entropy_mean -1.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.47 / train/policy_logprob_mag 10.59 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.93 / train/policy_logprob_min -10.59 / train/policy_logprob_std 2.06 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 52.05 / train/post_ent_max 52.05 / train/post_ent_mean 41.81 / 
train/post_ent_min 21.7 / train/post_ent_std 5.12 / train/prior_ent_mag 82.94 / train/prior_ent_max 82.94 / train/prior_ent_mean 45.47 / train/prior_ent_min 27.24 / train/prior_ent_std 6.73 / train/rep_loss_mean 3.68 / train/rep_loss_std 6.46 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 6.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.47 / report/dyn_loss_std 6.26 / report/image_loss_mean 0.91 / report/image_loss_std 0.78 / report/model_loss_mean 3.15 / report/model_loss_std 4.37 / report/post_ent_mag 51.45 / report/post_ent_max 51.45 /
report/post_ent_mean 41.6 / report/post_ent_min 20.78 / report/post_ent_std 5.13 / report/prior_ent_mag 83.04 / report/prior_ent_max 83.04 / report/prior_ent_mean 44.99 / report/prior_ent_min 26.48 / report/prior_ent_std 6.81 / report/rep_loss_mean 3.47 / 
report/rep_loss_std 6.26 / report/reward_avg 0.37 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 5.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.36 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / eval/cont_loss_std 8.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.5 / eval/dyn_loss_std 6.94 / eval/image_loss_mean 1.14 / eval/image_loss_std 1.61 / eval/model_loss_mean 4.1 / eval/model_loss_std 5.42 / eval/post_ent_mag 51.82 / eval/post_ent_max 51.82 / eval/post_ent_mean 
42.03 / eval/post_ent_min 22.8 / eval/post_ent_std 4.41 / eval/prior_ent_mag 83.04 / eval/prior_ent_max 83.04 / eval/prior_ent_mean 46.35 / eval/prior_ent_min 27.52 / eval/prior_ent_std 5.86 / eval/rep_loss_mean 4.5 / eval/rep_loss_std 6.94 / eval/reward_avg 0.57 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.43 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.57 / eval/reward_rate 0.43 / 
replay/size 4.2e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.6e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3764 / timer/env.step_total 19.5 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.1 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.48 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1882 / timer/agent.train_total 241.64 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 8.2e-5 / timer/dataset_eval_frac 2.7e-7 / timer/dataset_eval_avg 8.2e-5 / timer/dataset_eval_min 8.2e-5 / timer/dataset_eval_max 8.2e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 306.7.
Starting evaluation at step 421500 Counter(421500) 421437
eval_Episode has 500 steps and return 319.7.
Saved chunk: 20230922T064402F679830-0TW3O3lfjszWwpOpA7huYU-3PXZo2AQU0WwWWvlNdfS5g-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T064522F963787-3PXZo2AQU0WwWWvlNdfS5g-0000000000000000000000-30.npz
Saved chunk: 20230922T064429F165345-7H1eayVEttg2qzA4ttypqD-0000000000000000000000-936.npz
train_Episode has 500 steps and return 290.4.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T064429F165345-7H1eayVEttg2qzA4ttypqD-4PKGt7W4EPGy3GqoxprjoG-1024.npz
Starting evaluation at step 422000 Counter(422000) 421937
eval_Episode has 500 steps and return 309.0.
train_Episode has 500 steps and return 293.1.
Starting evaluation at step 422500 Counter(422500) 422437
eval_Episode has 500 steps and return 313.4.
Saved chunk: 20230922T064522F963787-3PXZo2AQU0WwWWvlNdfS5g-69nCGhy61lPQhMWdyx3pbY-1024.npz
train_Episode has 500 steps and return 293.8.
Saved chunk: 20230922T064551F395177-4PKGt7W4EPGy3GqoxprjoG-3AmFrQIrNDr4TBsoFtIZEQ-1024.npz
Starting evaluation at step 423000 Counter(423000) 422937
eval_Episode has 500 steps and return 321.5.
train_Episode has 500 steps and return 290.6.
Starting evaluation at step 423500 Counter(423500) 423437
eval_Episode has 500 steps and return 303.2.
train_Episode has 500 steps and return 296.1.
Saved chunk: 20230922T064712F220779-3AmFrQIrNDr4TBsoFtIZEQ-3yC99qd84sG8ZbCLRm1qP1-1024.npz
Starting evaluation at step 424000 Counter(424000) 423937
Saved chunk: 20230922T064642F464936-69nCGhy61lPQhMWdyx3pbY-1pko4eaKa9aSv89to8aGf8-1024.npz
eval_Episode has 500 steps and return 303.5.
train_Episode has 500 steps and return 297.1.
Starting evaluation at step 424500 Counter(424500) 424437
eval_Episode has 500 steps and return 330.0.
train_Episode has 500 steps and return 288.4.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 849722 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 288.43 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 330 / eval_episode/reward_rate 0.45 / train/action_mag 4.02 / train/action_max 3.91 / train/action_mean 0.03 / train/action_min -3.78 / train/action_std 
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 2.05 / train/adv_mag 0.35 / train/adv_max 0.29 / train/adv_mean 3.5e-4 / train/adv_min 
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 225.91 / train/extr_critic_max 225.91 / train/extr_critic_mean 214.35 / train/extr_critic_min 148.11 / train/extr_critic_std 15.72 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 226.16 / train/extr_return_raw_max 226.16 / train/extr_return_raw_mean 214.37 / train/extr_return_raw_min 
149.68 / train/extr_return_raw_std 15.75 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.4 / train/extr_reward_min 0 / train/extr_reward_std 0.62 / train/image_loss_mean 0.95 / train/image_loss_std 0.92 / train/model_loss_mean 3.32 /
train/model_loss_std 4.55 / train/model_opt_grad_norm 8.2 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.58 / train/policy_entropy_max 
4.53 / train/policy_entropy_mean -1.84 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.5 / train/policy_logprob_mag 10.71 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.84 / train/policy_logprob_min -10.71 / train/policy_logprob_std 2.08 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 3.2e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.88 / train/post_ent_max 51.88 / train/post_ent_mean 41.87 / 
train/post_ent_min 21.74 / train/post_ent_std 5.04 / train/prior_ent_mag 82.83 / train/prior_ent_max 82.83 / train/prior_ent_mean 45.49 / train/prior_ent_min 27.44 / train/prior_ent_std 6.68 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.41 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 3.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.45 / report/dyn_loss_std 6.46 / report/image_loss_mean 0.88 / report/image_loss_std 0.88 / report/model_loss_mean 3.14 / report/model_loss_std 4.53 / report/post_ent_mag 54 / report/post_ent_max 54 / 
report/post_ent_mean 41.19 / report/post_ent_min 19.83 / report/post_ent_std 6.58 / report/prior_ent_mag 83 / report/prior_ent_max 83 / report/prior_ent_mean 44.63 / report/prior_ent_min 22.3 / report/prior_ent_std 8.29 / report/rep_loss_mean 3.45 / report/rep_loss_std 
6.46 / report/reward_avg 0.38 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.3 / report/reward_max_data 1.89 / report/reward_max_pred 1.87 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.58 / 
report/reward_pred 0.38 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.58 / eval/dyn_loss_std 6.08 / eval/image_loss_mean 0.84 / eval/image_loss_std 0.95 / eval/model_loss_mean 3.26 / eval/model_loss_std 4.33 / eval/post_ent_mag 50.25 / eval/post_ent_max 50.25 / eval/post_ent_mean 42.63 / eval/post_ent_min 25 / 
eval/post_ent_std 3.53 / eval/prior_ent_mag 83 / eval/prior_ent_max 83 / eval/prior_ent_mean 46.35 / eval/prior_ent_min 35.89 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 3.58 / eval/rep_loss_std 6.08 / eval/reward_avg 0.64 / eval/reward_loss_mean 0.27 / 
eval/reward_loss_std 0.34 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.89 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.63 / eval/reward_rate 0.48 / replay/size 4.2e5 / 
replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3808 / timer/env.step_total 19.73 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 
4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 460.27 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.2e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.83 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / 
timer/agent.train_count 1904 / timer/agent.train_total 244.58 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 8.9e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / 
timer/dataset_eval_max 2.7e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T064832F860824-3yC99qd84sG8ZbCLRm1qP1-525miCEcooODeHUTedbpYy-1024.npz
Starting evaluation at step 425000 Counter(425000) 424937
Saved chunk: 20230922T064837F565357-1pko4eaKa9aSv89to8aGf8-3KIf9efZ9HyFvGB3wWpp5R-1024.npz
eval_Episode has 500 steps and return 286.1.
train_Episode has 500 steps and return 281.4.
Starting evaluation at step 425500 Counter(425500) 425437
eval_Episode has 500 steps and return 311.1.
train_Episode has 500 steps and return 275.9.
Saved chunk: 20230922T064954F491245-525miCEcooODeHUTedbpYy-6vtuQkDMuqYrrgQFlv6SN6-1024.npz
Starting evaluation at step 426000 Counter(426000) 425937
Saved chunk: 20230922T064957F648671-3KIf9efZ9HyFvGB3wWpp5R-3AixhRRZWennnliyaiZrwr-1024.npz
eval_Episode has 500 steps and return 317.1.
train_Episode has 500 steps and return 303.3.
Starting evaluation at step 426500 Counter(426500) 426437
eval_Episode has 500 steps and return 316.9.
train_Episode has 500 steps and return 275.3.
Starting evaluation at step 427000 Counter(427000) 426937
Saved chunk: 20230922T065117F205751-3AixhRRZWennnliyaiZrwr-0ATkjyGKHUsJJHDut4PDMi-1024.npz
eval_Episode has 500 steps and return 307.5.
Saved chunk: 20230922T065115F643175-6vtuQkDMuqYrrgQFlv6SN6-7LesmA5gbtbxgzC4siTCAy-1024.npz
train_Episode has 500 steps and return 255.7.
Starting evaluation at step 427500 Counter(427500) 427437
eval_Episode has 500 steps and return 318.6.
train_Episode has 500 steps and return 301.4.
Starting evaluation at step 428000 Counter(428000) 427937
Saved chunk: 20230922T065236F464356-0ATkjyGKHUsJJHDut4PDMi-74smhxPgYTGyo1S3ny7nls-1024.npz
eval_Episode has 500 steps and return 315.4.
Saved chunk: 20230922T065240F005041-7LesmA5gbtbxgzC4siTCAy-0yDvaYR3glDp1Cmq7WO9s4-1024.npz
train_Episode has 500 steps and return 280.0.
Starting evaluation at step 428500 Counter(428500) 428437
eval_Episode has 500 steps and return 279.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 857242 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 279.66 / eval_episode/reward_rate 0.39 / episode/length 500 / episode/score 280.04 / episode/reward_rate 0.4 / train/action_mag 4.01 / train/action_max 3.89 / train/action_mean 0.03 / train/action_min -3.78 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 1.36 / train/adv_mag 0.36 / train/adv_max 0.3 / train/adv_mean 4.4e-4 / train/adv_min 
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.68 / train/dyn_loss_std 6.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 226.33 / train/extr_critic_max 226.33 / train/extr_critic_mean 215.07 / train/extr_critic_min 159.44 / train/extr_critic_std 13.77 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.25 / train/extr_return_rate 1 / train/extr_return_raw_mag 226.61 / train/extr_return_raw_max 226.61 / train/extr_return_raw_mean 215.1 / train/extr_return_raw_min 
160.31 / train/extr_return_raw_std 13.8 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.96 / train/image_loss_std 0.94 / train/model_loss_mean 3.34 /
train/model_loss_std 4.59 / train/model_opt_grad_norm 8.2 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.43 / train/policy_entropy_max 
4.34 / train/policy_entropy_mean -1.91 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.43 / train/policy_logprob_mag 10.34 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.91 / train/policy_logprob_min -10.34 / train/policy_logprob_std 2.02 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.9 / train/post_ent_max 51.9 / train/post_ent_mean 41.91 / 
train/post_ent_min 21.91 / train/post_ent_std 4.98 / train/prior_ent_mag 82.76 / train/prior_ent_max 82.76 / train/prior_ent_mean 45.55 / train/prior_ent_min 27.87 / train/prior_ent_std 6.6 / train/rep_loss_mean 3.68 / train/rep_loss_std 6.46 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.16 / report/cont_avg 1 / report/cont_loss_mean 1.4e-11 / report/cont_loss_std 5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.17 / report/dyn_loss_std 7.52 / report/image_loss_mean 1.07 / report/image_loss_std 1.17 / report/model_loss_mean 3.76 / report/model_loss_std 5.46 / report/post_ent_mag 51.52 / report/post_ent_max 51.52 /
report/post_ent_mean 41.91 / report/post_ent_min 22.52 / report/post_ent_std 5.39 / report/prior_ent_mag 83.22 / report/prior_ent_max 83.22 / report/prior_ent_mean 46.1 / report/prior_ent_min 28.56 / report/prior_ent_std 6.73 / report/rep_loss_mean 4.17 / 
report/rep_loss_std 7.52 / report/reward_avg 0.38 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.29 / report/reward_max_data 1.88 / report/reward_max_pred 1.9 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.38 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.36 / eval/dyn_loss_std 5.18 / eval/image_loss_mean 0.75 / eval/image_loss_std 0.59 / eval/model_loss_mean 3.02 / eval/model_loss_std 3.65 / eval/post_ent_mag 51.08 / eval/post_ent_max 51.08 / eval/post_ent_mean 
42.89 / eval/post_ent_min 27.28 / eval/post_ent_std 3.39 / eval/prior_ent_mag 83.22 / eval/prior_ent_max 83.22 / eval/prior_ent_mean 46.28 / eval/prior_ent_min 39.23 / eval/prior_ent_std 5.36 / eval/rep_loss_mean 3.36 / eval/rep_loss_std 5.18 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.82 / eval/reward_max_pred 1.83 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.62 / eval/reward_rate 0.47 / 
replay/size 4.3e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3760 / timer/env.step_total 19.47 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.33 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.43 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 
/ timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.3e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.77 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.7e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 297.8.
Starting evaluation at step 429000 Counter(429000) 428937
Saved chunk: 20230922T065355F436239-74smhxPgYTGyo1S3ny7nls-6UacdafcGsAXhFH7y0RJEM-1024.npz
eval_Episode has 500 steps and return 299.5.
Saved chunk: 20230922T065400F566799-0yDvaYR3glDp1Cmq7WO9s4-6W8Mm1u8RrMd68qKBR8YKD-1024.npz
train_Episode has 500 steps and return 264.7.
Starting evaluation at step 429500 Counter(429500) 429437
eval_Episode has 500 steps and return 274.0.
train_Episode has 500 steps and return 284.0.
Starting evaluation at step 430000 Counter(430000) 429937
Saved chunk: 20230922T065515F676990-6UacdafcGsAXhFH7y0RJEM-4cmxBMoHMek46hXaXgkTdt-1024.npz
eval_Episode has 500 steps and return 305.3.
Saved chunk: 20230922T065522F455004-6W8Mm1u8RrMd68qKBR8YKD-6fXqXztyMYCxVoDMNhW9Nc-1024.npz
train_Episode has 500 steps and return 247.3.
Starting evaluation at step 430500 Counter(430500) 430437
eval_Episode has 500 steps and return 302.1.
train_Episode has 500 steps and return 300.4.
Starting evaluation at step 431000 Counter(431000) 430937
Saved chunk: 20230922T065635F163069-4cmxBMoHMek46hXaXgkTdt-2ZlXocsrpsqF6fXD40y2mv-1024.npz
eval_Episode has 500 steps and return 313.9.
Saved chunk: 20230922T065643F419005-6fXqXztyMYCxVoDMNhW9Nc-1xTIWqBYwa7jB1kdLytS5q-1024.npz
train_Episode has 500 steps and return 277.1.
Starting evaluation at step 431500 Counter(431500) 431437
eval_Episode has 500 steps and return 291.4.
train_Episode has 500 steps and return 292.4.
Starting evaluation at step 432000 Counter(432000) 431937
Saved chunk: 20230922T065754F345680-2ZlXocsrpsqF6fXD40y2mv-2XzElNuNohYGvgV2InGbtq-1024.npz
eval_Episode has 500 steps and return 281.3.
Saved chunk: 20230922T065804F201712-1xTIWqBYwa7jB1kdLytS5q-7sPRn9yfb8tAw2DzepTpNM-1024.npz
train_Episode has 500 steps and return 289.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 864858 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 289.27 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 281.33 / eval_episode/reward_rate 0.4 / train/action_mag 3.99 / train/action_max 3.86 / train/action_mean 0.03 / train/action_min -3.77 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss 0.96 / train/adv_mag 0.39 / train/adv_max 0.33 / train/adv_mean 4.9e-4 / train/adv_min 
-0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.1e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 226.65 / train/extr_critic_max 226.65 / train/extr_critic_mean 215.18 / train/extr_critic_min 154.49 / train/extr_critic_std 14.83 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 226.93 / train/extr_return_raw_max 226.93 / train/extr_return_raw_mean 215.21 / train/extr_return_raw_min 
155.36 / train/extr_return_raw_std 14.86 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.95 / train/image_loss_std 0.92 / train/model_loss_mean 3.32 
/ train/model_loss_std 4.55 / train/model_opt_grad_norm 8.48 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.39 / train/policy_entropy_max
4.25 / train/policy_entropy_mean -1.95 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.33 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.95 / train/policy_logprob_min -10.33 / train/policy_logprob_std 2.01 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.96 / train/post_ent_max 51.96 / train/post_ent_mean 41.89 / 
train/post_ent_min 21.77 / train/post_ent_std 4.99 / train/prior_ent_mag 82.7 / train/prior_ent_max 82.7 / train/prior_ent_mean 45.52 / train/prior_ent_min 27.42 / train/prior_ent_std 6.61 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.42 / train/reward_avg 0.38 / 
train/reward_loss_mean 0.17 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.38 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.7e-11 / report/cont_loss_std 8.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 4.18 / report/dyn_loss_std 7.39 / report/image_loss_mean 1.25 / report/image_loss_std 1.08 / report/model_loss_mean 3.88 / report/model_loss_std 5.2 / report/post_ent_mag 52.07 / report/post_ent_max 52.07 / 
report/post_ent_mean 41.19 / report/post_ent_min 19.55 / report/post_ent_std 5.47 / report/prior_ent_mag 82.79 / report/prior_ent_max 82.79 / report/prior_ent_mean 45.27 / report/prior_ent_min 27.82 / report/prior_ent_std 6.85 / report/rep_loss_mean 4.18 / 
report/rep_loss_std 7.39 / report/reward_avg 0.27 / report/reward_loss_mean 0.13 / report/reward_loss_std 0.28 / report/reward_max_data 1.99 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 3.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.27 / report/reward_rate 0.22 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.8 / eval/dyn_loss_std 5.92 / eval/image_loss_mean 0.92 / eval/image_loss_std 1.05 / eval/model_loss_mean 3.45 / eval/model_loss_std 4.44 / eval/post_ent_mag 49.85 / eval/post_ent_max 49.85 / eval/post_ent_mean 
42.57 / eval/post_ent_min 24.61 / eval/post_ent_std 3.96 / eval/prior_ent_mag 82.79 / eval/prior_ent_max 82.79 / eval/prior_ent_mean 46.37 / eval/prior_ent_min 35.83 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 3.8 / eval/rep_loss_std 5.92 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.64 / eval/reward_rate 0.46 / 
replay/size 4.3e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3808 / timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.43 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1904 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.83 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 432500 Counter(432500) 432437
eval_Episode has 500 steps and return 295.7.
train_Episode has 500 steps and return 287.7.
Starting evaluation at step 433000 Counter(433000) 432937
Saved chunk: 20230922T065913F389708-2XzElNuNohYGvgV2InGbtq-6eGa0WNxRyrBcSQ5GnPxbg-1024.npz
eval_Episode has 500 steps and return 289.0.
Saved chunk: 20230922T065924F781582-7sPRn9yfb8tAw2DzepTpNM-5IVrvSuiQdV33SpJhKnXV4-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T070033F760931-6eGa0WNxRyrBcSQ5GnPxbg-0000000000000000000000-289.npz
Saved chunk: 20230922T070046F812778-5IVrvSuiQdV33SpJhKnXV4-0000000000000000000000-48.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 287.8.
Starting evaluation at step 433500 Counter(433500) 433437
eval_Episode has 500 steps and return 292.5.
train_Episode has 500 steps and return 272.8.
Starting evaluation at step 434000 Counter(434000) 433937
Saved chunk: 20230922T070033F760931-6eGa0WNxRyrBcSQ5GnPxbg-6ZIkbjtSKVnKMfG4GAh6tc-1024.npz
eval_Episode has 500 steps and return 326.7.
Saved chunk: 20230922T070046F812778-5IVrvSuiQdV33SpJhKnXV4-3kD8uaDMyY6veuQ8m8p5YE-1024.npz
train_Episode has 500 steps and return 271.5.
Starting evaluation at step 434500 Counter(434500) 434437
eval_Episode has 500 steps and return 286.0.
train_Episode has 500 steps and return 294.0.
Starting evaluation at step 435000 Counter(435000) 434937
Saved chunk: 20230922T070153F421973-6ZIkbjtSKVnKMfG4GAh6tc-6Mm0LLUrf31aBWDeYqM8PS-1024.npz
eval_Episode has 500 steps and return 305.8.
Saved chunk: 20230922T070208F070689-3kD8uaDMyY6veuQ8m8p5YE-7eKuuYuOVwnVQqMFDSrUg1-1024.npz
train_Episode has 500 steps and return 276.5.
Starting evaluation at step 435500 Counter(435500) 435437
eval_Episode has 500 steps and return 299.1.
train_Episode has 500 steps and return 285.3.
Starting evaluation at step 436000 Counter(436000) 435937
Saved chunk: 20230922T070312F561985-6Mm0LLUrf31aBWDeYqM8PS-4Csy0rCYRBmEbHFBwfvwv8-1024.npz
eval_Episode has 500 steps and return 313.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 872374 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 313.15 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 285.3 / episode/reward_rate 0.41 / train/action_mag 4 / train/action_max 3.9 / train/action_mean 0.04 / train/action_min -3.72 / train/action_std 
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 1.7 / train/adv_mag 0.4 / train/adv_max 0.36 / train/adv_mean 4.1e-4 / train/adv_min 
-0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 226.96 / train/extr_critic_max 226.96 / train/extr_critic_mean 215.91 / train/extr_critic_min 152.26 / train/extr_critic_std 14.5 / train/extr_return_normed_mag 1.36 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 227.25 / train/extr_return_raw_max 227.25 / train/extr_return_raw_mean 215.94 / train/extr_return_raw_min 
156.75 / train/extr_return_raw_std 14.51 / train/extr_reward_mag 1.94 / train/extr_reward_max 1.94 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.94 / train/image_loss_std 0.9 / train/model_loss_mean 3.32 /
train/model_loss_std 4.52 / train/model_opt_grad_norm 8.29 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.47 / train/policy_entropy_max 
4.39 / train/policy_entropy_mean -1.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.41 / train/policy_logprob_mag 10.51 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.93 / train/policy_logprob_min -10.51 / train/policy_logprob_std 2.01 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.9 / train/post_ent_max 51.9 / train/post_ent_mean 42.03 / 
train/post_ent_min 22.02 / train/post_ent_std 4.93 / train/prior_ent_mag 82.66 / train/prior_ent_max 82.66 / train/prior_ent_mean 45.64 / train/prior_ent_min 27.71 / train/prior_ent_std 6.54 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.36 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.91 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 
0.31 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.18 / report/cont_avg 1 / report/cont_loss_mean 1.7e-11 / report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.28 / report/dyn_loss_std 5.78 / report/image_loss_mean 0.8 / report/image_loss_std 0.72 / report/model_loss_mean 2.95 / report/model_loss_std 4.09 / report/post_ent_mag 51.59 / report/post_ent_max 51.59 / 
report/post_ent_mean 42.72 / report/post_ent_min 26.5 / report/post_ent_std 3.67 / report/prior_ent_mag 82.88 / report/prior_ent_max 82.88 / report/prior_ent_mean 46.06 / report/prior_ent_min 35.3 / report/prior_ent_std 5.66 / report/rep_loss_mean 3.28 / 
report/rep_loss_std 5.78 / report/reward_avg 0.47 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 1.97 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.51 / report/reward_pred 0.47 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 5.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.38 / eval/dyn_loss_std 6.8 / eval/image_loss_mean 1.2 / eval/image_loss_std 2.14 / eval/model_loss_mean 4.12 / eval/model_loss_std 5.81 / eval/post_ent_mag 49.96 / eval/post_ent_max 49.96 / eval/post_ent_mean 
41.95 / eval/post_ent_min 20.62 / eval/post_ent_std 4.49 / eval/prior_ent_mag 82.88 / eval/prior_ent_max 82.88 / eval/prior_ent_mean 46.3 / eval/prior_ent_min 29.73 / eval/prior_ent_std 5.8 / eval/rep_loss_mean 4.38 / eval/rep_loss_std 6.8 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.29 / eval/reward_loss_std 0.41 / eval/reward_max_data 2 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.63 / eval/reward_rate 0.46 / 
replay/size 4.4e5 / replay/inserts 3758 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3758 / timer/env.step_total 19.67 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 444.96 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7766 / timer/agent.policy_total 17.57 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1879 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1879 / timer/agent.train_total 241.48 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.5e-8 / timer/dataset_eval_avg 2.6e-5 / 
timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T070328F628157-7eKuuYuOVwnVQqMFDSrUg1-2ETigR8MjuUonz2ngrQHq8-1024.npz
train_Episode has 500 steps and return 301.9.
Starting evaluation at step 436500 Counter(436500) 436437
eval_Episode has 500 steps and return 293.8.
train_Episode has 500 steps and return 273.0.
Starting evaluation at step 437000 Counter(437000) 436937
Saved chunk: 20230922T070431F500456-4Csy0rCYRBmEbHFBwfvwv8-3L18XvAt0sFczOU3f3GDMK-1024.npz
eval_Episode has 500 steps and return 303.2.
Saved chunk: 20230922T070450F178416-2ETigR8MjuUonz2ngrQHq8-0dDzsqSupBOZKM1ACi4yEy-1024.npz
train_Episode has 500 steps and return 294.2.
Starting evaluation at step 437500 Counter(437500) 437437
eval_Episode has 500 steps and return 306.4.
train_Episode has 500 steps and return 294.3.
Starting evaluation at step 438000 Counter(438000) 437937
Saved chunk: 20230922T070551F908235-3L18XvAt0sFczOU3f3GDMK-2R61ZseGUndDvPJCk8ueJ1-1024.npz
eval_Episode has 500 steps and return 312.4.
Saved chunk: 20230922T070611F159854-0dDzsqSupBOZKM1ACi4yEy-1NvV5JpKz702ISEzXVyuZd-1024.npz
train_Episode has 500 steps and return 281.8.
Starting evaluation at step 438500 Counter(438500) 438437
eval_Episode has 500 steps and return 320.1.
train_Episode has 500 steps and return 279.2.
Starting evaluation at step 439000 Counter(439000) 438937
Saved chunk: 20230922T070711F129158-2R61ZseGUndDvPJCk8ueJ1-02VzoaGLCUiQn6zweLKZZ1-1024.npz
eval_Episode has 500 steps and return 320.3.
Saved chunk: 20230922T070731F971194-1NvV5JpKz702ISEzXVyuZd-1G2dIncoqcvmBE7HBlBL0U-1024.npz
train_Episode has 500 steps and return 284.4.
Starting evaluation at step 439500 Counter(439500) 439437
eval_Episode has 500 steps and return 315.1.
train_Episode has 500 steps and return 298.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 879998 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 298.69 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 315.06 / eval_episode/reward_rate 0.44 / train/action_mag 4.03 / train/action_max 3.91 / train/action_mean 0.03 / train/action_min -3.76 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 2.77 / train/adv_mag 0.41 / train/adv_max 0.35 / train/adv_mean 3.1e-4
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 6.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 227.29 / train/extr_critic_max 227.29 / train/extr_critic_mean 215.79 / train/extr_critic_min 149.17 / train/extr_critic_std 16.1 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 227.56 / train/extr_return_raw_max 227.56 / train/extr_return_raw_mean 215.81 / train/extr_return_raw_min
151.42 / train/extr_return_raw_std 16.13 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.94 / train/image_loss_std 0.92 / train/model_loss_mean 3.31 
/ train/model_loss_std 4.56 / train/model_opt_grad_norm 8.58 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.2 / train/policy_entropy_max 
4.03 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.37 / train/policy_logprob_mag 10.35 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.35 / train/policy_logprob_std 1.98 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.76 / train/post_ent_max 51.76 / train/post_ent_mean 41.96 / 
train/post_ent_min 21.74 / train/post_ent_std 5.01 / train/prior_ent_mag 82.64 / train/prior_ent_max 82.64 / train/prior_ent_mean 45.57 / train/prior_ent_min 27.71 / train/prior_ent_std 6.64 / train/rep_loss_mean 3.65 / train/rep_loss_std 6.42 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 0.31
/ train_stats/mean_log_entropy -2.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.7e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.47 / report/dyn_loss_std 6.18 / report/image_loss_mean 0.83 / report/image_loss_std 0.8 / report/model_loss_mean 3.12 / report/model_loss_std 4.23 / report/post_ent_mag 51.06 / report/post_ent_max 51.06 / 
report/post_ent_mean 41.14 / report/post_ent_min 17.04 / report/post_ent_std 7.12 / report/prior_ent_mag 82.72 / report/prior_ent_max 82.72 / report/prior_ent_mean 44.77 / report/prior_ent_min 17.62 / report/prior_ent_std 8.54 / report/rep_loss_mean 3.47 / 
report/rep_loss_std 6.18 / report/reward_avg 0.46 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.29 / report/reward_max_data 1.84 / report/reward_max_pred 1.86 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.46 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 8.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.29 / eval/dyn_loss_std 8.49 / eval/image_loss_mean 1.48 / eval/image_loss_std 2.56 / eval/model_loss_mean 4.93 / eval/model_loss_std 7.29 / eval/post_ent_mag 49.82 / eval/post_ent_max 49.82 / eval/post_ent_mean 
41.57 / eval/post_ent_min 22.03 / eval/post_ent_std 5.04 / eval/prior_ent_mag 82.72 / eval/prior_ent_max 82.72 / eval/prior_ent_mean 46.19 / eval/prior_ent_min 27.54 / eval/prior_ent_std 6.29 / eval/rep_loss_mean 5.29 / eval/rep_loss_std 8.49 / eval/reward_avg 0.55 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.49 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.54 / eval/reward_rate 0.41 / 
replay/size 4.4e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3812 / timer/env.step_total 19.74 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 457.66 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.54 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.86 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.41

Starting evaluation at step 440000 Counter(440000) 439937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T070830F103959-02VzoaGLCUiQn6zweLKZZ1-6jLL9PffRLIkYaTJnlWxln-1024.npz
eval_Episode has 500 steps and return 312.7.
Saved chunk: 20230922T070852F496692-1G2dIncoqcvmBE7HBlBL0U-5CFSMWYSBEFb2xwL7qcv6l-1024.npz
train_Episode has 500 steps and return 287.7.
Starting evaluation at step 440500 Counter(440500) 440437
eval_Episode has 500 steps and return 294.2.
train_Episode has 500 steps and return 305.1.
Starting evaluation at step 441000 Counter(441000) 440937
Saved chunk: 20230922T070950F341173-6jLL9PffRLIkYaTJnlWxln-1cHZzhrJrdO7sHBr5qhEyE-1024.npz
eval_Episode has 500 steps and return 329.4.
Saved chunk: 20230922T071014F459471-5CFSMWYSBEFb2xwL7qcv6l-3UH780CdmwO36mnFR1ytJd-1024.npz
train_Episode has 500 steps and return 291.7.
Starting evaluation at step 441500 Counter(441500) 441437
eval_Episode has 500 steps and return 309.5.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 442000 Counter(442000) 441937
Saved chunk: 20230922T071109F769516-1cHZzhrJrdO7sHBr5qhEyE-6KCmBw4rSv2Vc3PCfIWUa7-1024.npz
eval_Episode has 500 steps and return 307.0.
Saved chunk: 20230922T071135F308114-3UH780CdmwO36mnFR1ytJd-660Uj2vYesWfi8AopUpQik-1024.npz
train_Episode has 500 steps and return 274.3.
Starting evaluation at step 442500 Counter(442500) 442437
eval_Episode has 500 steps and return 300.0.
train_Episode has 500 steps and return 302.5.
Starting evaluation at step 443000 Counter(443000) 442937
eval_Episode has 500 steps and return 302.4.
Saved chunk: 20230922T071228F925335-6KCmBw4rSv2Vc3PCfIWUa7-6Bipl0XmOvMJt13sPr8t0E-1024.npz
train_Episode has 500 steps and return 283.2.
Saved chunk: 20230922T071255F973932-660Uj2vYesWfi8AopUpQik-7C9BWTZzd8ag35TtDI9Ure-1024.npz
Starting evaluation at step 443500 Counter(443500) 443437
eval_Episode has 500 steps and return 299.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 887530 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 299.77 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 283.2 / episode/reward_rate 0.4 / eval_stats/mean_log_entropy 0 / train/action_mag 4.01 / train/action_max 3.86 / train/action_mean 0.04 / 
train/action_min -3.73 / train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -1.93 / train/adv_mag 0.39 / train/adv_max 
0.31 / train/adv_mean 8.1e-4 / train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.2e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.62 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / 
train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 227.54 / train/extr_critic_max 227.54 / train/extr_critic_mean 216.45 / train/extr_critic_min 157.51 / train/extr_critic_std 14.37 / 
train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.28 / train/extr_return_rate 1 / train/extr_return_raw_mag 227.8 / train/extr_return_raw_max 
227.8 / train/extr_return_raw_mean 216.49 / train/extr_return_raw_min 157.64 / train/extr_return_raw_std 14.32 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / 
train/image_loss_mean 0.93 / train/image_loss_std 0.91 / train/model_loss_mean 3.28 / train/model_loss_std 4.49 / train/model_opt_grad_norm 8.24 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / 
train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.14 / train/policy_entropy_max 3.91 / train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.31 / train/policy_logprob_mag 10.32 / train/policy_logprob_max 5.47 /
train/policy_logprob_mean 2.04 / train/policy_logprob_min -10.32 / train/policy_logprob_std 1.94 / train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 
0.14 / train/post_ent_mag 51.92 / train/post_ent_max 51.92 / train/post_ent_mean 42.08 / train/post_ent_min 22.02 / train/post_ent_std 4.88 / train/prior_ent_mag 82.53 / train/prior_ent_max 82.53 / train/prior_ent_mean 45.65 / train/prior_ent_min 27.99 / 
train/prior_ent_std 6.48 / train/rep_loss_mean 3.62 / train/rep_loss_std 6.29 / train/reward_avg 0.39 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 
3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 0.32 / train_stats/mean_log_entropy -1.33 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / 
report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 6.34 / report/image_loss_mean 0.93 / report/image_loss_std 0.86 / report/model_loss_mean 3.2 / 
report/model_loss_std 4.4 / report/post_ent_mag 52.08 / report/post_ent_max 52.08 / report/post_ent_mean 41.78 / report/post_ent_min 16.64 / report/post_ent_std 5.17 / report/prior_ent_mag 82.71 / report/prior_ent_max 82.71 / report/prior_ent_mean 45.34 / 
report/prior_ent_min 24.54 / report/prior_ent_std 6.73 / report/rep_loss_mean 3.49 / report/rep_loss_std 6.34 / report/reward_avg 0.38 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.29 / report/reward_max_data 1.95 / report/reward_max_pred 1.96 / 
report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.38 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 8.2e-11 / eval/cont_neg_acc nan / 
eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.81 / eval/dyn_loss_std 6.18 / eval/image_loss_mean 0.9 / eval/image_loss_std 1.22 / eval/model_loss_mean 3.44 / eval/model_loss_std 
4.61 / eval/post_ent_mag 51.1 / eval/post_ent_max 51.1 / eval/post_ent_mean 42.68 / eval/post_ent_min 23.74 / eval/post_ent_std 3.73 / eval/prior_ent_mag 82.71 / eval/prior_ent_max 82.71 / eval/prior_ent_mean 46.41 / eval/prior_ent_min 31.61 / eval/prior_ent_std 5.58 / 
eval/rep_loss_mean 3.81 / eval/rep_loss_std 6.18 / eval/reward_avg 0.61 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-4 / eval/reward_pos_acc 1 / 
eval/reward_pos_loss 0.57 / eval/reward_pred 0.6 / eval/reward_rate 0.43 / replay/size 4.4e5 / replay/inserts 3766 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / 
eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3766 / 
timer/env.step_total 19.54 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.38 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01
/ timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7774 / timer/agent.policy_total 17.86 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1883 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.4e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 2.7e-4 / 
timer/agent.train_count 1883 / timer/agent.train_total 240.99 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.15 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.7e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / 
timer/dataset_eval_max 2.9e-5 / fps 25.1

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 273.8.
Starting evaluation at step 444000 Counter(444000) 443937
eval_Episode has 500 steps and return 325.6.
Saved chunk: 20230922T071347F874824-6Bipl0XmOvMJt13sPr8t0E-5XfqZ81Wl5H3mCREsxTLgx-1024.npz
train_Episode has 500 steps and return 298.9.
Saved chunk: 20230922T071416F450040-7C9BWTZzd8ag35TtDI9Ure-7s342SpeQLDrcSX4BsS9cH-1024.npz
Starting evaluation at step 444500 Counter(444500) 444437
eval_Episode has 500 steps and return 313.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T071538F219929-7s342SpeQLDrcSX4BsS9cH-0000000000000000000000-184.npz
Saved chunk: 20230922T071507F877708-5XfqZ81Wl5H3mCREsxTLgx-0000000000000000000000-548.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 285.9.
Starting evaluation at step 445000 Counter(445000) 444937
eval_Episode has 500 steps and return 307.3.
Saved chunk: 20230922T071507F877708-5XfqZ81Wl5H3mCREsxTLgx-3fyyw5HjneF657do5jIx8k-1024.npz
train_Episode has 500 steps and return 272.1.
Saved chunk: 20230922T071538F219929-7s342SpeQLDrcSX4BsS9cH-4x7Lif7t0HvTVUwZGr0UVD-1024.npz
Starting evaluation at step 445500 Counter(445500) 445437
eval_Episode has 500 steps and return 320.9.
train_Episode has 500 steps and return 282.7.
Starting evaluation at step 446000 Counter(446000) 445937
eval_Episode has 500 steps and return 322.1.
Saved chunk: 20230922T071627F465981-3fyyw5HjneF657do5jIx8k-3AMDMfcyTDV5VZdHF9xiH5-1024.npz
train_Episode has 500 steps and return 274.5.
Saved chunk: 20230922T071659F380420-4x7Lif7t0HvTVUwZGr0UVD-6ueZuHRwXT5836tZiI18An-1024.npz
Starting evaluation at step 446500 Counter(446500) 446437
eval_Episode has 500 steps and return 331.8.
train_Episode has 500 steps and return 310.7.
Starting evaluation at step 447000 Counter(447000) 446937
eval_Episode has 500 steps and return 302.8.
train_Episode has 500 steps and return 296.2.
Saved chunk: 20230922T071819F995317-6ueZuHRwXT5836tZiI18An-4pgGOiy7mVyqU3flpUkbuK-1024.npz
Starting evaluation at step 447500 Counter(447500) 447437
Saved chunk: 20230922T071746F700822-3AMDMfcyTDV5VZdHF9xiH5-4djEdraZsAc1wJBdKlSs4Q-1024.npz
eval_Episode has 500 steps and return 314.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 895050 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 296.18 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 314.49 / eval_episode/reward_rate 0.47 / train/action_mag 4.01 / train/action_max 3.9 / train/action_mean 0.04 / train/action_min -3.75 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 1.49 / train/adv_mag 0.35 / train/adv_max 0.29 / train/adv_mean 4.5e-4 / train/adv_min 
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 6.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 227.81 / train/extr_critic_max 227.81 / train/extr_critic_mean 216.17 / train/extr_critic_min 150.8 / train/extr_critic_std 15.78 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 228.1 / train/extr_return_raw_max 228.1 / train/extr_return_raw_mean 216.2 / train/extr_return_raw_min 
152.5 / train/extr_return_raw_std 15.77 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.94 / train/image_loss_std 0.92 / train/model_loss_mean 3.31 /
train/model_loss_std 4.54 / train/model_opt_grad_norm 8.32 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.23 / train/policy_entropy_max 
4.04 / train/policy_entropy_mean -2.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.17 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.17 / train/policy_logprob_std 1.96 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.9e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.85 / train/post_ent_max 51.85 / train/post_ent_mean 41.99 / 
train/post_ent_min 21.62 / train/post_ent_std 4.96 / train/prior_ent_mag 82.59 / train/prior_ent_max 82.59 / train/prior_ent_mean 45.59 / train/prior_ent_min 27.53 / train/prior_ent_std 6.58 / train/rep_loss_mean 3.64 / train/rep_loss_std 6.4 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.9 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 0.31
/ train_stats/mean_log_entropy -2.25 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 2.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 7 / report/image_loss_mean 0.99 / report/image_loss_std 0.89 / report/model_loss_mean 3.41 / report/model_loss_std 4.85 / report/post_ent_mag 51.39 / report/post_ent_max 51.39 / 
report/post_ent_mean 41.52 / report/post_ent_min 23.04 / report/post_ent_std 5.03 / report/prior_ent_mag 82.7 / report/prior_ent_max 82.7 / report/prior_ent_mean 45.32 / report/prior_ent_min 30.07 / report/prior_ent_std 6.67 / report/rep_loss_mean 3.76 / 
report/rep_loss_std 7 / report/reward_avg 0.37 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 1.93 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 2.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.38 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.66 / eval/dyn_loss_std 5.92 / eval/image_loss_mean 0.83 / eval/image_loss_std 0.77 / eval/model_loss_mean 3.3 / eval/model_loss_std 4.19 / eval/post_ent_mag 49.94 / eval/post_ent_max 49.94 / eval/post_ent_mean 
42.72 / eval/post_ent_min 23.05 / eval/post_ent_std 3.63 / eval/prior_ent_mag 82.7 / eval/prior_ent_max 82.7 / eval/prior_ent_mean 46.31 / eval/prior_ent_min 38.38 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 3.66 / eval/rep_loss_std 5.92 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.66 / eval/reward_rate 0.48 / 
replay/size 4.5e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3760 / timer/env.step_total 19.46 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.77 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.67 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.56 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 289.2.
Starting evaluation at step 448000 Counter(448000) 447937
eval_Episode has 500 steps and return 307.8.
train_Episode has 500 steps and return 311.8.
Starting evaluation at step 448500 Counter(448500) 448437
Saved chunk: 20230922T071941F502488-4djEdraZsAc1wJBdKlSs4Q-1lXP9U6044ZtP61GQrkjJ5-1024.npz
eval_Episode has 500 steps and return 317.8.
Saved chunk: 20230922T071940F503517-4pgGOiy7mVyqU3flpUkbuK-5swcehw4v9EblMwUi3mNNl-1024.npz
train_Episode has 500 steps and return 304.1.
Starting evaluation at step 449000 Counter(449000) 448937
eval_Episode has 500 steps and return 318.1.
train_Episode has 500 steps and return 309.0.
Starting evaluation at step 449500 Counter(449500) 449437
Saved chunk: 20230922T072102F058187-1lXP9U6044ZtP61GQrkjJ5-6OOGS9GXPgZ38qf3lcZohZ-1024.npz
eval_Episode has 500 steps and return 325.9.
Saved chunk: 20230922T072106F189392-5swcehw4v9EblMwUi3mNNl-73tVwCbKQefUH6w88Q97NU-1024.npz
train_Episode has 500 steps and return 284.5.
Starting evaluation at step 450000 Counter(450000) 449937
eval_Episode has 500 steps and return 314.8.
train_Episode has 500 steps and return 274.5.
Starting evaluation at step 450500 Counter(450500) 450437
Saved chunk: 20230922T072221F261567-6OOGS9GXPgZ38qf3lcZohZ-7CT9A9Xo3vqCjIa0u2qYOy-1024.npz
eval_Episode has 500 steps and return 320.0.
Saved chunk: 20230922T072226F933768-73tVwCbKQefUH6w88Q97NU-22A99oIqXYDSzDnvPhWxX0-1024.npz
train_Episode has 500 steps and return 284.1.
Starting evaluation at step 451000 Counter(451000) 450937
eval_Episode has 500 steps and return 302.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 902674 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 284.12 / episode/reward_rate 0.39 / eval_episode/length 500 / eval_episode/score 302.67 / eval_episode/reward_rate 0.43 / train/action_mag 3.98 / train/action_max 3.88 / train/action_mean 0.04 / train/action_min -3.74 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss 2.55 / train/adv_mag 0.33 / train/adv_max 0.27 / train/adv_mean 3.6e-4
/ train/adv_min -0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 9.2e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 6.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.2e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.01 / train/extr_critic_max 228.01 / train/extr_critic_mean 216.5 / train/extr_critic_min 148.93 / train/extr_critic_std 16.41 / train/extr_return_normed_mag 1.47 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 228.26 / train/extr_return_raw_max 228.26 / train/extr_return_raw_mean 216.52 / 
train/extr_return_raw_min 150.05 / train/extr_return_raw_std 16.42 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.41 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.93 / train/image_loss_std 0.91 / 
train/model_loss_mean 3.3 / train/model_loss_std 4.53 / train/model_opt_grad_norm 8.52 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.33 
/ train/policy_entropy_max 4.1 / train/policy_entropy_mean -2.05 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 10.41 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.05 / train/policy_logprob_min -10.41 / 
train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 3.1e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.76 / train/post_ent_max 51.76 / 
train/post_ent_mean 42.04 / train/post_ent_min 21.66 / train/post_ent_std 5.02 / train/prior_ent_mag 82.53 / train/prior_ent_max 82.53 / train/prior_ent_mean 45.64 / train/prior_ent_min 27.03 / train/prior_ent_std 6.62 / train/rep_loss_mean 3.64 / train/rep_loss_std 
6.37 / train/reward_avg 0.39 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.39 / train/reward_rate 0.31 / train_stats/mean_log_entropy -2.27 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.38 / report/dyn_loss_std 6.55 / report/image_loss_mean 0.88 / report/image_loss_std 1.1 / report/model_loss_mean 3.06 / report/model_loss_std 4.82 / 
report/post_ent_mag 53.52 / report/post_ent_max 53.52 / report/post_ent_mean 40.06 / report/post_ent_min 17.45 / report/post_ent_std 7.14 / report/prior_ent_mag 82.34 / report/prior_ent_max 82.34 / report/prior_ent_mean 43.55 / report/prior_ent_min 17.49 / 
report/prior_ent_std 8.35 / report/rep_loss_mean 3.38 / report/rep_loss_std 6.55 / report/reward_avg 0.32 / report/reward_loss_mean 0.15 / report/reward_loss_std 0.29 / report/reward_max_data 1.9 / report/reward_max_pred 1.84 / report/reward_neg_acc 1 / 
report/reward_neg_loss 6.6e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.32 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4 / eval/dyn_loss_std 6.25 / eval/image_loss_mean 1.03 / eval/image_loss_std 1.45 / eval/model_loss_mean 3.68 / eval/model_loss_std 4.83 / eval/post_ent_mag 51.95
/ eval/post_ent_max 51.95 / eval/post_ent_mean 42.53 / eval/post_ent_min 23.85 / eval/post_ent_std 4.01 / eval/prior_ent_mag 82.34 / eval/prior_ent_max 82.34 / eval/prior_ent_mean 46.38 / eval/prior_ent_min 36.5 / eval/prior_ent_std 5.61 / eval/rep_loss_mean 4 / 
eval/rep_loss_std 6.25 / eval/reward_avg 0.57 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / 
eval/reward_pred 0.57 / eval/reward_rate 0.43 / replay/size 4.5e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3812 / timer/env.step_total 19.92
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 458.64 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
7e-3 / timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.45 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 6e-4 / timer/agent.train_count 1906 / 
timer/agent.train_total 244.87 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 268.7.
Starting evaluation at step 451500 Counter(451500) 451437
Saved chunk: 20230922T072340F277701-7CT9A9Xo3vqCjIa0u2qYOy-36GC5bKH5gQ6m0v98V8zGQ-1024.npz
eval_Episode has 500 steps and return 305.4.
Saved chunk: 20230922T072347F550923-22A99oIqXYDSzDnvPhWxX0-756x2aUnHpiJu1H9WWuw33-1024.npz
train_Episode has 500 steps and return 297.8.
Starting evaluation at step 452000 Counter(452000) 451937
eval_Episode has 500 steps and return 329.7.
train_Episode has 500 steps and return 287.3.
Starting evaluation at step 452500 Counter(452500) 452437
Saved chunk: 20230922T072500F403974-36GC5bKH5gQ6m0v98V8zGQ-2MfMeC5gTAAHJZyJIhCl57-1024.npz
eval_Episode has 500 steps and return 319.4.
Saved chunk: 20230922T072509F308001-756x2aUnHpiJu1H9WWuw33-5H1hTShGjw2ofIQ36OL0IE-1024.npz
train_Episode has 500 steps and return 292.3.
Starting evaluation at step 453000 Counter(453000) 452937
eval_Episode has 500 steps and return 243.8.
train_Episode has 500 steps and return 287.5.
Starting evaluation at step 453500 Counter(453500) 453437
Saved chunk: 20230922T072619F870267-2MfMeC5gTAAHJZyJIhCl57-2fNtxHziovscmxaQkaWCuG-1024.npz
eval_Episode has 500 steps and return 311.4.
Saved chunk: 20230922T072630F273127-5H1hTShGjw2ofIQ36OL0IE-5H4HfjPMInZQf8Ap6tulce-1024.npz
train_Episode has 500 steps and return 249.8.
Starting evaluation at step 454000 Counter(454000) 453937
eval_Episode has 500 steps and return 305.5.
train_Episode has 500 steps and return 308.3.
Starting evaluation at step 454500 Counter(454500) 454437
Saved chunk: 20230922T072739F083258-2fNtxHziovscmxaQkaWCuG-3f0pvirFrCCECy3Mgkpxri-1024.npz
eval_Episode has 500 steps and return 313.0.
Saved chunk: 20230922T072751F043572-5H4HfjPMInZQf8Ap6tulce-0Js75RhwaN669H5FVvYBtn-1024.npz
train_Episode has 500 steps and return 316.6.
Starting evaluation at step 455000 Counter(455000) 454937
eval_Episode has 500 steps and return 318.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 910198 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 316.58 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 318.27 / eval_episode/reward_rate 0.46 / train/action_mag 3.97 / train/action_max 3.83 / train/action_mean 0.04 / train/action_min -3.72 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 1.43 / train/adv_mag 0.35 / train/adv_max 0.29 / train/adv_mean 4.8e-4
/ train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 6.38 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.35 / train/extr_critic_max 228.35 / train/extr_critic_mean 217.28 / train/extr_critic_min 157.56 / train/extr_critic_std 14.5 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.27 / train/extr_return_rate 1 / train/extr_return_raw_mag 228.59 / train/extr_return_raw_max 228.59 / train/extr_return_raw_mean 217.31 / train/extr_return_raw_min 
158.59 / train/extr_return_raw_std 14.51 / train/extr_reward_mag 1.95 / train/extr_reward_max 1.95 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.94 / train/image_loss_std 0.91 / train/model_loss_mean 3.3 /
train/model_loss_std 4.53 / train/model_opt_grad_norm 8.08 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.34 / train/policy_entropy_max 
4.18 / train/policy_entropy_mean -2.07 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.3 / train/policy_logprob_mag 10.24 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.07 / train/policy_logprob_min -10.24 / train/policy_logprob_std 1.94 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.83 / train/post_ent_max 51.83 / train/post_ent_mean 42 / 
train/post_ent_min 21.99 / train/post_ent_std 4.97 / train/prior_ent_mag 82.47 / train/prior_ent_max 82.47 / train/prior_ent_mean 45.61 / train/prior_ent_min 27.76 / train/prior_ent_std 6.58 / train/rep_loss_mean 3.65 / train/rep_loss_std 6.38 / train/reward_avg 0.39 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 
0.31 / train_stats/mean_log_entropy -2.27 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 6.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.53 / report/dyn_loss_std 5.84 / report/image_loss_mean 0.82 / report/image_loss_std 0.68 / report/model_loss_mean 3.18 / report/model_loss_std 4.08 / report/post_ent_mag 50.53 / report/post_ent_max 50.53 /
report/post_ent_mean 42.72 / report/post_ent_min 26.54 / report/post_ent_std 3.8 / report/prior_ent_mag 82.73 / report/prior_ent_max 82.73 / report/prior_ent_mean 46.19 / report/prior_ent_min 31.54 / report/prior_ent_std 5.63 / report/rep_loss_mean 3.53 / 
report/rep_loss_std 5.84 / report/reward_avg 0.53 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.35 / report/reward_max_data 1.98 / report/reward_max_pred 1.95 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.53 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.87 / eval/dyn_loss_std 6.12 / eval/image_loss_mean 0.87 / eval/image_loss_std 1.1 / eval/model_loss_mean 3.44 / eval/model_loss_std 4.55 / eval/post_ent_mag 50.21 / eval/post_ent_max 50.21 / eval/post_ent_mean 
42.72 / eval/post_ent_min 21.11 / eval/post_ent_std 3.71 / eval/prior_ent_mag 82.73 / eval/prior_ent_max 82.73 / eval/prior_ent_mean 46.52 / eval/prior_ent_min 35.65 / eval/prior_ent_std 5.42 / eval/rep_loss_mean 3.87 / eval/rep_loss_std 6.12 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.61 / eval/reward_rate 0.45 / 
replay/size 4.6e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3762 / timer/env.step_total 19.52 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.81 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.38 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 
/ timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1881 / timer/agent.train_total 241.78 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 281.6.
Starting evaluation at step 455500 Counter(455500) 455437
Saved chunk: 20230922T072858F069798-3f0pvirFrCCECy3Mgkpxri-1yAALfBVNraKZz9Bwg00Gg-1024.npz
eval_Episode has 500 steps and return 292.1.
Saved chunk: 20230922T072911F540275-0Js75RhwaN669H5FVvYBtn-3Cu3QgzTHwxDGjURYwl9fH-1024.npz
train_Episode has 500 steps and return 299.7.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 456000 Counter(456000) 455937
Saved chunk: 20230922T073018F244741-1yAALfBVNraKZz9Bwg00Gg-0000000000000000000000-306.npz
Saved chunk: 20230922T073033F440143-3Cu3QgzTHwxDGjURYwl9fH-0000000000000000000000-320.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
eval_Episode has 500 steps and return 312.0.
train_Episode has 500 steps and return 285.8.
Starting evaluation at step 456500 Counter(456500) 456437
Saved chunk: 20230922T073018F244741-1yAALfBVNraKZz9Bwg00Gg-34FBbll2jzHXwNhypc8i7S-1024.npz
eval_Episode has 500 steps and return 328.6.
Saved chunk: 20230922T073033F440143-3Cu3QgzTHwxDGjURYwl9fH-47zjekePIgzo1XDjNcbE0E-1024.npz
train_Episode has 500 steps and return 316.6.
Starting evaluation at step 457000 Counter(457000) 456937
eval_Episode has 500 steps and return 308.9.
train_Episode has 500 steps and return 288.2.
Starting evaluation at step 457500 Counter(457500) 457437
Saved chunk: 20230922T073138F069743-34FBbll2jzHXwNhypc8i7S-5skaDCfibgpwYw2lUcNqVx-1024.npz
eval_Episode has 500 steps and return 325.4.
Saved chunk: 20230922T073154F728226-47zjekePIgzo1XDjNcbE0E-7zbIX1HRNmy3cFk8FF9KSM-1024.npz
train_Episode has 500 steps and return 303.4.
Starting evaluation at step 458000 Counter(458000) 457937
eval_Episode has 500 steps and return 307.8.
train_Episode has 500 steps and return 313.8.
Starting evaluation at step 458500 Counter(458500) 458437
Saved chunk: 20230922T073257F227921-5skaDCfibgpwYw2lUcNqVx-1Mq1Z9vvyZ4ZzOOwjIAIzg-1024.npz
eval_Episode has 500 steps and return 304.6.
Saved chunk: 20230922T073315F498252-7zbIX1HRNmy3cFk8FF9KSM-7q6RuEwmnhmAoeMcKdcs8L-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 917810 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 313.83 / episode/reward_rate 0.45 / eval_episode/length 500 / eval_episode/score 304.57 / eval_episode/reward_rate 0.43 / train/action_mag 4.01 / train/action_max 3.92 / train/action_mean 0.04 / train/action_min -3.68 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 2.81 / train/adv_mag 0.42 / train/adv_max 0.37 / train/adv_mean 3.3e-4
/ train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.66 / train/dyn_loss_std 6.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.59 / train/extr_critic_max 228.59 / train/extr_critic_mean 217.05 / train/extr_critic_min 147.34 / train/extr_critic_std 16.27 / train/extr_return_normed_mag 1.5 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 228.84 / train/extr_return_raw_max 228.84 / train/extr_return_raw_mean 217.07 / 
train/extr_return_raw_min 152.19 / train/extr_return_raw_std 16.29 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.95 / train/image_loss_std 0.93 / 
train/model_loss_mean 3.32 / train/model_loss_std 4.56 / train/model_opt_grad_norm 8.39 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.35
/ train/policy_entropy_max 4.12 / train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.34 / train/policy_logprob_mag 10.36 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.04 / train/policy_logprob_min -10.36 / 
train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.83 / train/policy_randomness_max 0.83 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.7e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.81 / train/post_ent_max 51.81 / 
train/post_ent_mean 41.98 / train/post_ent_min 21.72 / train/post_ent_std 5.03 / train/prior_ent_mag 82.43 / train/prior_ent_max 82.43 / train/prior_ent_mean 45.6 / train/prior_ent_min 27.31 / train/prior_ent_std 6.62 / train/rep_loss_mean 3.66 / train/rep_loss_std 6.41
/ train/reward_avg 0.39 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.39 / train/reward_rate 0.31 / train_stats/mean_log_entropy -2.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 5.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 6.47 / report/image_loss_mean 0.95 / report/image_loss_std 0.98 / report/model_loss_mean 3.38 / report/model_loss_std 4.55 / report/post_ent_mag 51 /
report/post_ent_max 51 / report/post_ent_mean 42.57 / report/post_ent_min 24.23 / report/post_ent_std 4.62 / report/prior_ent_mag 82.14 / report/prior_ent_max 82.14 / report/prior_ent_mean 46.32 / report/prior_ent_min 32.3 / report/prior_ent_std 6 / report/rep_loss_mean
3.74 / report/rep_loss_std 6.47 / report/reward_avg 0.39 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.31 / report/reward_max_data 1.89 / report/reward_max_pred 1.89 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.39 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 9.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.77 / eval/dyn_loss_std 5.74 / eval/image_loss_mean 0.9 / eval/image_loss_std 1.06 / eval/model_loss_mean 3.42 / eval/model_loss_std 4.23 / eval/post_ent_mag 49.89 / eval/post_ent_max 49.89 / eval/post_ent_mean 
42.4 / eval/post_ent_min 19.93 / eval/post_ent_std 4.21 / eval/prior_ent_mag 82.14 / eval/prior_ent_max 82.14 / eval/prior_ent_mean 46.11 / eval/prior_ent_min 27.22 / eval/prior_ent_std 5.78 / eval/rep_loss_mean 3.77 / eval/rep_loss_std 5.74 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.64 / eval/reward_rate 0.46 / 
replay/size 4.6e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3806 / timer/env.step_total 19.95 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.66 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.5e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.31 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / 
timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.36

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 289.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 459000 Counter(459000) 458937
eval_Episode has 500 steps and return 310.8.
train_Episode has 500 steps and return 307.6.
Starting evaluation at step 459500 Counter(459500) 459437
Saved chunk: 20230922T073416F263092-1Mq1Z9vvyZ4ZzOOwjIAIzg-1wVsO70he2O7lyQowhDxTn-1024.npz
eval_Episode has 500 steps and return 317.8.
Saved chunk: 20230922T073435F992683-7q6RuEwmnhmAoeMcKdcs8L-0FnQnUq6W6Huza0PFmFPV8-1024.npz
train_Episode has 500 steps and return 291.1.
Starting evaluation at step 460000 Counter(460000) 459937
eval_Episode has 500 steps and return 314.7.
train_Episode has 500 steps and return 308.5.
Starting evaluation at step 460500 Counter(460500) 460437
Saved chunk: 20230922T073536F625091-1wVsO70he2O7lyQowhDxTn-24WRkxMnAon70foJ31mPso-1024.npz
eval_Episode has 500 steps and return 335.4.
Saved chunk: 20230922T073558F130848-0FnQnUq6W6Huza0PFmFPV8-1LXvGIc3AYhQmTXs0YS3WB-1024.npz
train_Episode has 500 steps and return 297.9.
Starting evaluation at step 461000 Counter(461000) 460937
eval_Episode has 500 steps and return 322.9.
train_Episode has 500 steps and return 293.7.
Starting evaluation at step 461500 Counter(461500) 461437
Saved chunk: 20230922T073656F014355-24WRkxMnAon70foJ31mPso-793XBGNBoX2Lk2X2tNTJmJ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073718F970301-1LXvGIc3AYhQmTXs0YS3WB-7pDppPQzlJAqjxYlGhEO9c-1024.npz
train_Episode has 500 steps and return 286.8.
Starting evaluation at step 462000 Counter(462000) 461937
eval_Episode has 500 steps and return 330.1.
train_Episode has 500 steps and return 283.1.
Starting evaluation at step 462500 Counter(462500) 462437
Saved chunk: 20230922T073815F164313-793XBGNBoX2Lk2X2tNTJmJ-4mQoJ0SjwqhM5CumZQAjK7-1024.npz
eval_Episode has 500 steps and return 323.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 925330 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 283.06 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 323.3 / eval_episode/reward_rate 0.44 / train_stats/mean_log_entropy -2.18 / train/action_mag 4.02 / train/action_max 3.92 / train/action_mean 0.04 / 
train/action_min -3.7 / train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 3.73 / train/adv_mag 0.29 / train/adv_max 0.23
/ train/adv_mean 2.1e-4 / train/adv_min -0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 3.6 / train/dyn_loss_std 6.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.78 / train/extr_critic_max 228.78 / train/extr_critic_mean 216.98 / train/extr_critic_min 146.85 / train/extr_critic_std 17 / train/extr_return_normed_mag
1.5 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.31 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.01 / train/extr_return_raw_max 229.01 / 
train/extr_return_raw_mean 216.99 / train/extr_return_raw_min 148.21 / train/extr_return_raw_std 17.01 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 
0.92 / train/image_loss_std 0.91 / train/model_loss_mean 3.26 / train/model_loss_std 4.52 / train/model_opt_grad_norm 7.95 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 
1e4 / train/policy_entropy_mag 4.43 / train/policy_entropy_max 4.27 / train/policy_entropy_mean -1.96 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.39 / train/policy_logprob_mag 10.46 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 1.96 / 
train/policy_logprob_min -10.46 / train/policy_logprob_std 2 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.7e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.87 / 
train/post_ent_max 51.87 / train/post_ent_mean 42.02 / train/post_ent_min 21.71 / train/post_ent_std 5.05 / train/prior_ent_mag 82.36 / train/prior_ent_max 82.36 / train/prior_ent_mean 45.57 / train/prior_ent_min 27.35 / train/prior_ent_std 6.65 / train/rep_loss_mean 
3.6 / train/rep_loss_std 6.36 / train/reward_avg 0.39 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / 
train/reward_pos_loss 0.56 / train/reward_pred 0.39 / train/reward_rate 0.31 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 /
report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.6 / report/dyn_loss_std 6.28 / report/image_loss_mean 0.89 / report/image_loss_std 0.88 / report/model_loss_mean 3.24 / report/model_loss_std 4.49 / report/post_ent_mag 51.31
/ report/post_ent_max 51.31 / report/post_ent_mean 42.24 / report/post_ent_min 20.94 / report/post_ent_std 4.49 / report/prior_ent_mag 82.43 / report/prior_ent_max 82.43 / report/prior_ent_mean 45.88 / report/prior_ent_min 27.06 / report/prior_ent_std 6.09 / 
report/rep_loss_mean 3.6 / report/rep_loss_std 6.28 / report/reward_avg 0.4 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.33 / report/reward_max_data 1.81 / report/reward_max_pred 1.82 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.4 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.93 / eval/dyn_loss_std 6.06 / eval/image_loss_mean 0.94 / eval/image_loss_std 1.15 / eval/model_loss_mean 3.58 / eval/model_loss_std 4.47 / eval/post_ent_mag 50 / eval/post_ent_max 
50 / eval/post_ent_mean 42.51 / eval/post_ent_min 21.53 / eval/post_ent_std 4.01 / eval/prior_ent_mag 82.43 / eval/prior_ent_max 82.43 / eval/prior_ent_mean 46.48 / eval/prior_ent_min 33.57 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 3.93 / eval/rep_loss_std 6.06 / 
eval/reward_avg 0.67 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.35 / eval/reward_max_data 2 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.66 / 
eval/reward_rate 0.48 / replay/size 4.6e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3760 / timer/env.step_total 19.48 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.96 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 9.2e-4 / 
timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7768 / timer/agent.policy_total 17.7 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 /
timer/agent.policy_max 0.19 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 6.3e-4 / timer/agent.train_count 1880 / 
timer/agent.train_total 241.41 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T073839F653384-7pDppPQzlJAqjxYlGhEO9c-2azyE4x21tXXv8SEiHjt6Y-1024.npz
train_Episode has 500 steps and return 296.1.
Starting evaluation at step 463000 Counter(463000) 462937
eval_Episode has 500 steps and return 324.5.
train_Episode has 500 steps and return 288.3.
Starting evaluation at step 463500 Counter(463500) 463437
Saved chunk: 20230922T073934F082252-4mQoJ0SjwqhM5CumZQAjK7-6YUaJ5yZTGO5XmtzOxwvWn-1024.npz
eval_Episode has 500 steps and return 306.1.
Saved chunk: 20230922T074001F210373-2azyE4x21tXXv8SEiHjt6Y-5Cq8TRznAxQPeCIH6TDMQk-1024.npz
train_Episode has 500 steps and return 299.9.
Starting evaluation at step 464000 Counter(464000) 463937
eval_Episode has 500 steps and return 323.7.
train_Episode has 500 steps and return 308.7.
Starting evaluation at step 464500 Counter(464500) 464437
Saved chunk: 20230922T074054F447208-6YUaJ5yZTGO5XmtzOxwvWn-1oEjYSwtGYH7vAyXMGUfSt-1024.npz
eval_Episode has 500 steps and return 308.8.
Saved chunk: 20230922T074122F203862-5Cq8TRznAxQPeCIH6TDMQk-3xrIl76sM6Vpsk5L88Hek1-1024.npz
train_Episode has 500 steps and return 296.5.
Starting evaluation at step 465000 Counter(465000) 464937
eval_Episode has 500 steps and return 288.6.
train_Episode has 500 steps and return 301.1.
Starting evaluation at step 465500 Counter(465500) 465437
Saved chunk: 20230922T074213F714204-1oEjYSwtGYH7vAyXMGUfSt-47Poifxqv5NVPc3dCghmlu-1024.npz
eval_Episode has 500 steps and return 317.0.
Saved chunk: 20230922T074242F987820-3xrIl76sM6Vpsk5L88Hek1-6Tl0qVo195v87Y0wk4WoeZ-1024.npz
train_Episode has 500 steps and return 308.4.
Starting evaluation at step 466000 Counter(466000) 465937
eval_Episode has 500 steps and return 315.2.
train_Episode has 500 steps and return 301.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 932960 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 301.23 / episode/reward_rate 0.44 / eval_episode/length 500 / eval_episode/score 315.23 / eval_episode/reward_rate 0.45 / train/action_mag 3.93 / train/action_max 3.81 / train/action_mean 0.03 / train/action_min -3.66 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 2.01 / train/adv_mag 0.36 / train/adv_max 0.31 / train/adv_mean 4e-4 /
train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.65 / train/dyn_loss_std 6.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.88 / train/extr_critic_max 228.88 / train/extr_critic_mean 218.59 / train/extr_critic_min 164.17 / train/extr_critic_std 12.5 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.83 / train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.24 / train/extr_return_rate 1 / train/extr_return_raw_mag 229.09 / train/extr_return_raw_max 229.09 / train/extr_return_raw_mean 218.61 / train/extr_return_raw_min 
166.99 / train/extr_return_raw_std 12.51 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.93 / train/image_loss_std 0.91 / train/model_loss_mean 3.3 /
train/model_loss_std 4.55 / train/model_opt_grad_norm 8.36 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.34 / train/policy_entropy_max 
4.17 / train/policy_entropy_mean -2.03 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.31 / train/policy_logprob_mag 10.25 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.03 / train/policy_logprob_min -10.25 / train/policy_logprob_std 1.94 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.91 / train/post_ent_max 51.91 / train/post_ent_mean 42.14 / 
train/post_ent_min 21.88 / train/post_ent_std 4.87 / train/prior_ent_mag 82.34 / train/prior_ent_max 82.34 / train/prior_ent_mean 45.75 / train/prior_ent_min 28.21 / train/prior_ent_std 6.46 / train/rep_loss_mean 3.65 / train/rep_loss_std 6.4 / train/reward_avg 0.4 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.4 / train/reward_rate 
0.32 / train_stats/mean_log_entropy -2.25 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 3.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.39 / report/dyn_loss_std 5.94 / report/image_loss_mean 0.85 / report/image_loss_std 0.65 / report/model_loss_mean 3.05 / report/model_loss_std 4.05 / report/post_ent_mag 51.45 / report/post_ent_max 51.45 /
report/post_ent_mean 42.56 / report/post_ent_min 25.67 / report/post_ent_std 4.25 / report/prior_ent_mag 82.63 / report/prior_ent_max 82.63 / report/prior_ent_mean 45.99 / report/prior_ent_min 32.15 / report/prior_ent_std 5.98 / report/rep_loss_mean 3.39 / 
report/rep_loss_std 5.94 / report/reward_avg 0.36 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.29 / report/reward_max_data 1.85 / report/reward_max_pred 1.86 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.36 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.88 / eval/dyn_loss_std 7.38 / eval/image_loss_mean 1.3 / eval/image_loss_std 2.07 / eval/model_loss_mean 4.49 / eval/model_loss_std 6.15 / eval/post_ent_mag 50.31 / eval/post_ent_max 50.31 / eval/post_ent_mean 
41.82 / eval/post_ent_min 22.54 / eval/post_ent_std 4.78 / eval/prior_ent_mag 82.63 / eval/prior_ent_max 82.63 / eval/prior_ent_mean 46.43 / eval/prior_ent_min 30.94 / eval/prior_ent_std 5.78 / eval/rep_loss_mean 4.88 / eval/rep_loss_std 7.38 / eval/reward_avg 0.58 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.53 / eval/reward_max_data 2 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.63 / eval/reward_pred 0.57 / eval/reward_rate 0.4 / 
replay/size 4.7e5 / replay/inserts 3815 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3815 / timer/env.step_total 19.92 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 455.43 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.3e-3 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7322 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.5e-3 
/ timer/dataset_train_count 1907 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.68 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 466500 Counter(466500) 466437
eval_Episode has 500 steps and return 323.5.
Saved chunk: 20230922T074332F738901-47Poifxqv5NVPc3dCghmlu-4U7tzFfXA2uhOKeWdy9Ox0-1024.npz
train_Episode has 500 steps and return 299.9.
Saved chunk: 20230922T074403F458045-6Tl0qVo195v87Y0wk4WoeZ-3DNlcGzxgFG6p1JC7iJ2NR-1024.npz
Starting evaluation at step 467000 Counter(467000) 466937
eval_Episode has 500 steps and return 311.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T074525F264244-3DNlcGzxgFG6p1JC7iJ2NR-0000000000000000000000-457.npz
Saved chunk: 20230922T074452F680705-4U7tzFfXA2uhOKeWdy9Ox0-0000000000000000000000-565.npz
train_Episode has 500 steps and return 309.5.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 467500 Counter(467500) 467437
Saved chunk: 20230922T074452F680705-4U7tzFfXA2uhOKeWdy9Ox0-6AN0Sr97CAhSmHjz815oRH-1024.npz
eval_Episode has 500 steps and return 313.1.
train_Episode has 500 steps and return 311.5.
Saved chunk: 20230922T074525F264244-3DNlcGzxgFG6p1JC7iJ2NR-3hvh0LXHPyGu4XELB2I2Iz-1024.npz
Starting evaluation at step 468000 Counter(468000) 467937
eval_Episode has 500 steps and return 314.0.
train_Episode has 500 steps and return 283.0.
Starting evaluation at step 468500 Counter(468500) 468437
eval_Episode has 500 steps and return 316.3.
Saved chunk: 20230922T074612F403776-6AN0Sr97CAhSmHjz815oRH-6XI2GdrFXBIXU4wcyExkiF-1024.npz
train_Episode has 500 steps and return 285.6.
Starting evaluation at step 469000 Counter(469000) 468937
Saved chunk: 20230922T074646F355775-3hvh0LXHPyGu4XELB2I2Iz-3LgIySCThmpG1y5Rd81dgf-1024.npz
eval_Episode has 500 steps and return 311.5.
train_Episode has 500 steps and return 313.0.
Starting evaluation at step 469500 Counter(469500) 469437
eval_Episode has 500 steps and return 294.2.
train_Episode has 500 steps and return 280.5.
Starting evaluation at step 470000 Counter(470000) 469937
Saved chunk: 20230922T074731F552214-6XI2GdrFXBIXU4wcyExkiF-5wykr9W1QEer64e2zKAllx-1024.npz
eval_Episode has 500 steps and return 313.0.
Saved chunk: 20230922T074807F170272-3LgIySCThmpG1y5Rd81dgf-7fCfUSxU0Uq8oGb5KVXYw2-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 940478 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 313.02 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 280.52 / episode/reward_rate 0.38 / train/action_mag 4 / train/action_max 3.89 / train/action_mean 0.04 / train/action_min -3.7 / train/action_std 
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss 3.33 / train/adv_mag 0.34 / train/adv_max 0.3 / train/adv_mean 2.5e-4 / train/adv_min 
-0.22 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.62 / train/dyn_loss_std 6.3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.3e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 228.92 / train/extr_critic_max 228.92 / train/extr_critic_mean 217.62 / train/extr_critic_min 148.52 / train/extr_critic_std 15.92 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.12 / train/extr_return_raw_max 229.12 / train/extr_return_raw_mean 217.63 / train/extr_return_raw_min
151.54 / train/extr_return_raw_std 15.92 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.92 / train/image_loss_std 0.9 / train/model_loss_mean 3.27 /
train/model_loss_std 4.47 / train/model_opt_grad_norm 8.2 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.58 / train/policy_entropy_max 
4.47 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.42 / train/policy_logprob_mag 10.5 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.5 / train/policy_logprob_std 2.02 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.85 / train/post_ent_max 51.85 / train/post_ent_mean 42.06 / 
train/post_ent_min 21.84 / train/post_ent_std 4.99 / train/prior_ent_mag 82.2 / train/prior_ent_max 82.2 / train/prior_ent_mean 45.64 / train/prior_ent_min 27.62 / train/prior_ent_std 6.57 / train/rep_loss_mean 3.62 / train/rep_loss_std 6.3 / train/reward_avg 0.4 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.4 / train/reward_rate 
0.32 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.24 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.4 / report/dyn_loss_std 6.22 / report/image_loss_mean 0.84 / report/image_loss_std 0.87 / report/model_loss_mean 3.06 / report/model_loss_std 4.38 / report/post_ent_mag 50.99 / report/post_ent_max 50.99 / 
report/post_ent_mean 42.71 / report/post_ent_min 20.8 / report/post_ent_std 4.14 / report/prior_ent_mag 82.1 / report/prior_ent_max 82.1 / report/prior_ent_mean 45.9 / report/prior_ent_min 27.44 / report/prior_ent_std 6.01 / report/rep_loss_mean 3.4 / 
report/rep_loss_std 6.22 / report/reward_avg 0.43 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.28 / report/reward_max_data 1.95 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.43 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.12 / eval/dyn_loss_std 6.65 / eval/image_loss_mean 1.13 / eval/image_loss_std 1.75 / eval/model_loss_mean 3.85 / eval/model_loss_std 5.28 / eval/post_ent_mag 49.96 / eval/post_ent_max 49.96 / eval/post_ent_mean 
42.15 / eval/post_ent_min 18.74 / eval/post_ent_std 4.54 / eval/prior_ent_mag 82.1 / eval/prior_ent_max 82.1 / eval/prior_ent_mean 46.17 / eval/prior_ent_min 27.54 / eval/prior_ent_std 5.71 / eval/rep_loss_mean 4.12 / eval/rep_loss_std 6.65 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.6 / eval/reward_rate 0.45 / 
replay/size 4.7e5 / replay/inserts 3759 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3759 / timer/env.step_total 19.8 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.45 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7767 / timer/agent.policy_total 17.7 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 8.3e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.05 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / 
timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 302.4.
Starting evaluation at step 470500 Counter(470500) 470437
eval_Episode has 500 steps and return 322.0.
train_Episode has 500 steps and return 282.9.
Starting evaluation at step 471000 Counter(471000) 470937
Saved chunk: 20230922T074926F464636-5wykr9W1QEer64e2zKAllx-1OY0tZndjfNiqOwtqLVbEe-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074931F128069-7fCfUSxU0Uq8oGb5KVXYw2-5t7QIKXmVgQyyIDvXKiHIx-1024.npz
train_Episode has 500 steps and return 310.0.
Starting evaluation at step 471500 Counter(471500) 471437
eval_Episode has 500 steps and return 308.6.
train_Episode has 500 steps and return 305.4.
Starting evaluation at step 472000 Counter(472000) 471937
Saved chunk: 20230922T075046F936904-1OY0tZndjfNiqOwtqLVbEe-1Ado22CfK76i8ZonA7VHfX-1024.npz
eval_Episode has 500 steps and return 285.1.
Saved chunk: 20230922T075053F278008-5t7QIKXmVgQyyIDvXKiHIx-47nksgCcyUr4g6rxctPOgo-1024.npz
train_Episode has 500 steps and return 279.3.
Starting evaluation at step 472500 Counter(472500) 472437
eval_Episode has 500 steps and return 307.1.
train_Episode has 500 steps and return 298.1.
Starting evaluation at step 473000 Counter(473000) 472937
Saved chunk: 20230922T075206F231808-1Ado22CfK76i8ZonA7VHfX-1iSrrKV9QuxcfR6WTDoWyt-1024.npz
eval_Episode has 500 steps and return 310.1.
Saved chunk: 20230922T075214F034228-47nksgCcyUr4g6rxctPOgo-3dyop5PLs9odeijBRqyBlL-1024.npz
train_Episode has 500 steps and return 308.3.
Starting evaluation at step 473500 Counter(473500) 473437
eval_Episode has 500 steps and return 336.7.
train_Episode has 500 steps and return 288.2.
Starting evaluation at step 474000 Counter(474000) 473937
Saved chunk: 20230922T075325F220921-1iSrrKV9QuxcfR6WTDoWyt-5hUR4Y9mw5svNbaLXqbtbv-1024.npz
eval_Episode has 500 steps and return 313.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 948002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 288.18 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 313.9 / eval_episode/reward_rate 0.45 / train/action_mag 3.99 / train/action_max 3.88 / train/action_mean 0.03 / train/action_min -3.68 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 2.96 / train/adv_mag 0.39 / train/adv_max 0.31 / train/adv_mean 3e-4 / train/adv_min 
-0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 6.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.01 / train/extr_critic_max 229.01 / train/extr_critic_mean 218.85 / train/extr_critic_min 161.25 / train/extr_critic_std 12.7 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.83 / train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.24 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.23 / train/extr_return_raw_max 229.23 / train/extr_return_raw_mean 218.86 / 
train/extr_return_raw_min 163.83 / train/extr_return_raw_std 12.73 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.92 / train/image_loss_std 0.9 / 
train/model_loss_mean 3.28 / train/model_loss_std 4.47 / train/model_opt_grad_norm 8.26 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.42
/ train/policy_entropy_max 4.29 / train/policy_entropy_mean -2.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.35 / train/policy_logprob_mag 10.36 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.36 / 
train/policy_logprob_std 1.97 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.82 / train/post_ent_max 51.82 / 
train/post_ent_mean 42.27 / train/post_ent_min 22.18 / train/post_ent_std 4.77 / train/prior_ent_mag 82.23 / train/prior_ent_max 82.23 / train/prior_ent_mean 45.86 / train/prior_ent_min 28.3 / train/prior_ent_std 6.36 / train/rep_loss_mean 3.62 / train/rep_loss_std 6.29
/ train/reward_avg 0.41 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.41 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.7e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.56 / report/dyn_loss_std 6.54 / report/image_loss_mean 0.91 / report/image_loss_std 0.93 / report/model_loss_mean 3.25 / report/model_loss_std 4.7 / report/post_ent_mag 51.65
/ report/post_ent_max 51.65 / report/post_ent_mean 42.86 / report/post_ent_min 22.66 / report/post_ent_std 4.27 / report/prior_ent_mag 82.73 / report/prior_ent_max 82.73 / report/prior_ent_mean 46.5 / report/prior_ent_min 27.86 / report/prior_ent_std 5.85 / 
report/rep_loss_mean 3.56 / report/rep_loss_std 6.54 / report/reward_avg 0.46 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.29 / report/reward_max_data 1.91 / report/reward_max_pred 1.89 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.45 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.48 / eval/dyn_loss_std 5.02 / eval/image_loss_mean 0.75 / eval/image_loss_std 0.5 / eval/model_loss_mean 3.1 / eval/model_loss_std 3.44 / eval/post_ent_mag 49.95 / eval/post_ent_max 
49.95 / eval/post_ent_mean 42.75 / eval/post_ent_min 21.82 / eval/post_ent_std 3.43 / eval/prior_ent_mag 82.73 / eval/prior_ent_max 82.73 / eval/prior_ent_mean 46.44 / eval/prior_ent_min 38.19 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 3.48 / eval/rep_loss_std 5.02 
/ eval/reward_avg 0.63 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.91 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.63 / 
eval/reward_rate 0.45 / replay/size 4.7e5 / replay/inserts 3762 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3762 / timer/env.step_total 19.49 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 449.15 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-3 / 
timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7770 / timer/agent.policy_total 17.46 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.02 / timer/dataset_train_count 1881 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.5e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1881 / 
timer/agent.train_total 241.65 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.36 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T075334F574541-3dyop5PLs9odeijBRqyBlL-6m9ko1JUdEpLyCCi4w7VDB-1024.npz
train_Episode has 500 steps and return 292.4.
Starting evaluation at step 474500 Counter(474500) 474437
eval_Episode has 500 steps and return 323.7.
train_Episode has 500 steps and return 309.3.
Starting evaluation at step 475000 Counter(475000) 474937
Saved chunk: 20230922T075444F163505-5hUR4Y9mw5svNbaLXqbtbv-70CYGBDxozRZjQaltIC7ei-1024.npz
eval_Episode has 500 steps and return 324.2.
Saved chunk: 20230922T075456F225577-6m9ko1JUdEpLyCCi4w7VDB-4Se4cdZ3eBqyhhkH4TMLf6-1024.npz
train_Episode has 500 steps and return 281.7.
Starting evaluation at step 475500 Counter(475500) 475437
eval_Episode has 500 steps and return 332.3.
train_Episode has 500 steps and return 305.0.
Starting evaluation at step 476000 Counter(476000) 475937
Saved chunk: 20230922T075604F617577-70CYGBDxozRZjQaltIC7ei-5SQ8bq0W1xyW9sCfXrN5rf-1024.npz
eval_Episode has 500 steps and return 296.2.
Saved chunk: 20230922T075617F221171-4Se4cdZ3eBqyhhkH4TMLf6-3Rqe5JoPphTljfIjILph2d-1024.npz
train_Episode has 500 steps and return 295.8.
Starting evaluation at step 476500 Counter(476500) 476437
eval_Episode has 500 steps and return 324.8.
train_Episode has 500 steps and return 275.5.
Starting evaluation at step 477000 Counter(477000) 476937
Saved chunk: 20230922T075723F945890-5SQ8bq0W1xyW9sCfXrN5rf-5ThoaApX9b0s20j2DBcl12-1024.npz
eval_Episode has 500 steps and return 308.6.
Saved chunk: 20230922T075738F009407-3Rqe5JoPphTljfIjILph2d-6EpUTTiKHvnsrivEb822uy-1024.npz
train_Episode has 500 steps and return 294.9.
Starting evaluation at step 477500 Counter(477500) 477437
eval_Episode has 500 steps and return 327.5.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 955626 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 294.88 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 327.47 / eval_episode/reward_rate 0.45 / train/action_mag 4.02 / train/action_max 3.93 / train/action_mean 0.04 / train/action_min -3.65 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 2.47 / train/adv_mag 0.39 / train/adv_max 0.32 / train/adv_mean 3.5e-4
/ train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.64 / train/dyn_loss_std 6.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.2 / train/extr_critic_max 229.2 / train/extr_critic_mean 218.66 / train/extr_critic_min 159.78 / train/extr_critic_std 13.44 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.41 / train/extr_return_raw_max 229.41 / train/extr_return_raw_mean 218.68 / train/extr_return_raw_min
163.15 / train/extr_return_raw_std 13.43 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.93 / train/image_loss_std 0.92 / train/model_loss_mean 3.3 /
train/model_loss_std 4.54 / train/model_opt_grad_norm 8.63 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 2.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7368.42 / train/policy_entropy_mag 4.45 / 
train/policy_entropy_max 4.33 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.36 / train/policy_logprob_mag 10.44 / train/policy_logprob_max 5.47 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.44 / 
train/policy_logprob_std 1.98 / train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.76 / train/post_ent_max 51.76 / 
train/post_ent_mean 42.19 / train/post_ent_min 21.83 / train/post_ent_std 4.84 / train/prior_ent_mag 82.2 / train/prior_ent_max 82.2 / train/prior_ent_mean 45.79 / train/prior_ent_min 28.11 / train/prior_ent_std 6.43 / train/rep_loss_mean 3.64 / train/rep_loss_std 6.39 
/ train/reward_avg 0.4 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.4
/ train/reward_rate 0.32 / train_stats/mean_log_entropy -2.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.48 / report/dyn_loss_std 5.86 / report/image_loss_mean 0.79 / report/image_loss_std 0.68 / report/model_loss_mean 3.09 / report/model_loss_std 4.12 / report/post_ent_mag 
52.11 / report/post_ent_max 52.11 / report/post_ent_mean 43.53 / report/post_ent_min 23.71 / report/post_ent_std 3.72 / report/prior_ent_mag 82.18 / report/prior_ent_max 82.18 / report/prior_ent_mean 46.92 / report/prior_ent_min 33.79 / report/prior_ent_std 5.43 / 
report/rep_loss_mean 3.48 / report/rep_loss_std 5.86 / report/reward_avg 0.45 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.35 / report/reward_max_data 1.91 / report/reward_max_pred 1.9 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.7e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.59 / report/reward_pred 0.45 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 6.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.12 / eval/dyn_loss_std 6.65 / eval/image_loss_mean 0.96 / eval/image_loss_std 1.27 / eval/model_loss_mean 3.68 / eval/model_loss_std 4.95 / eval/post_ent_mag 49.91 / 
eval/post_ent_max 49.91 / eval/post_ent_mean 42.46 / eval/post_ent_min 22.84 / eval/post_ent_std 3.84 / eval/prior_ent_mag 82.18 / eval/prior_ent_max 82.18 / eval/prior_ent_mean 46.16 / eval/prior_ent_min 34.41 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 4.12 / 
eval/rep_loss_std 6.65 / eval/reward_avg 0.6 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / 
eval/reward_pred 0.6 / eval/reward_rate 0.43 / replay/size 4.8e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3812 / timer/env.step_total 19.92
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.5 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 
7.3e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7319 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.9e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 6.3e-4 / 
timer/agent.train_count 1906 / timer/agent.train_total 244.71 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / 
timer/dataset_eval_max 3.1e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 272.7.
Starting evaluation at step 478000 Counter(478000) 477937
Saved chunk: 20230922T075842F975275-5ThoaApX9b0s20j2DBcl12-4yf2Z1VLPemPkhAY0o38PY-1024.npz
eval_Episode has 500 steps and return 333.4.
Saved chunk: 20230922T075858F571905-6EpUTTiKHvnsrivEb822uy-6biAgHIHUdpGlZ8UCw2smt-1024.npz
train_Episode has 500 steps and return 305.9.
Starting evaluation at step 478500 Counter(478500) 478437
eval_Episode has 500 steps and return 330.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T080020F431724-6biAgHIHUdpGlZ8UCw2smt-0000000000000000000000-592.npz
Saved chunk: 20230922T080003F084891-4yf2Z1VLPemPkhAY0o38PY-0000000000000000000000-824.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 303.9.
Starting evaluation at step 479000 Counter(479000) 478937
Saved chunk: 20230922T080003F084891-4yf2Z1VLPemPkhAY0o38PY-03ogkBWT0qfLDAAxUAmKDG-1024.npz
eval_Episode has 500 steps and return 332.4.
Saved chunk: 20230922T080020F431724-6biAgHIHUdpGlZ8UCw2smt-5mfTNmDxxcSW8tuQBP959w-1024.npz
train_Episode has 500 steps and return 302.0.
Starting evaluation at step 479500 Counter(479500) 479437
eval_Episode has 500 steps and return 334.7.
train_Episode has 500 steps and return 278.5.
Starting evaluation at step 480000 Counter(480000) 479937
Saved chunk: 20230922T080122F686213-03ogkBWT0qfLDAAxUAmKDG-6L37RgizymuY7jYwWtjepI-1024.npz
eval_Episode has 500 steps and return 319.8.
Saved chunk: 20230922T080141F512032-5mfTNmDxxcSW8tuQBP959w-1cD9u49jKgqcWUBDAMMMZb-1024.npz
train_Episode has 500 steps and return 292.0.
Starting evaluation at step 480500 Counter(480500) 480437
eval_Episode has 500 steps and return 322.7.
train_Episode has 500 steps and return 289.1.
Starting evaluation at step 481000 Counter(481000) 480937
Saved chunk: 20230922T080241F894076-6L37RgizymuY7jYwWtjepI-2nuwOx85lmPWzaBHPbLZBI-1024.npz
eval_Episode has 500 steps and return 309.7.
Saved chunk: 20230922T080302F287599-1cD9u49jKgqcWUBDAMMMZb-37VBm1kAU0t3XJV78KO6gR-1024.npz
train_Episode has 500 steps and return 303.5.
Starting evaluation at step 481500 Counter(481500) 481437
eval_Episode has 500 steps and return 338.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 963146 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 303.47 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 338.76 / eval_episode/reward_rate 0.48 / train/action_mag 4.07 / train/action_max 3.99 / train/action_mean 0.04 / train/action_min -3.69 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 0.93 / train/adv_mag 0.38 / train/adv_max 0.32 / train/adv_mean 4.9e-4
/ train/adv_min -0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.63 / train/dyn_loss_std 6.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.38 / train/extr_critic_max 229.38 / train/extr_critic_mean 218.71 / train/extr_critic_min 156.72 / train/extr_critic_std 13.9 / train/extr_return_normed_mag 1.44 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.57 / train/extr_return_raw_max 229.57 / train/extr_return_raw_mean 218.73 / 
train/extr_return_raw_min 157.45 / train/extr_return_raw_std 13.92 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.93 / train/image_loss_std 0.9 / 
train/model_loss_mean 3.28 / train/model_loss_std 4.5 / train/model_opt_grad_norm 8.32 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.87 
/ train/policy_entropy_max 4.81 / train/policy_entropy_mean -1.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.49 / train/policy_logprob_mag 11.06 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.93 / train/policy_logprob_min -11.06 / 
train/policy_logprob_std 2.07 / train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.2e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.89 / train/post_ent_max 51.89 / 
train/post_ent_mean 42.25 / train/post_ent_min 22.08 / train/post_ent_std 4.81 / train/prior_ent_mag 82.06 / train/prior_ent_max 82.06 / train/prior_ent_mean 45.83 / train/prior_ent_min 28.32 / train/prior_ent_std 6.38 / train/rep_loss_mean 3.63 / train/rep_loss_std 
6.35 / train/reward_avg 0.4 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.4 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 4.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.68 / report/dyn_loss_std 6.14 / report/image_loss_mean 0.97 / report/image_loss_std 0.95 / report/model_loss_mean 3.38 / report/model_loss_std 4.4 / 
report/post_ent_mag 50.89 / report/post_ent_max 50.89 / report/post_ent_mean 42.55 / report/post_ent_min 20.13 / report/post_ent_std 4.19 / report/prior_ent_mag 82.09 / report/prior_ent_max 82.09 / report/prior_ent_mean 46.13 / report/prior_ent_min 30.06 / 
report/prior_ent_std 5.71 / report/rep_loss_mean 3.68 / report/rep_loss_std 6.14 / report/reward_avg 0.45 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.29 / report/reward_max_data 1.92 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / 
report/reward_neg_loss 3.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.45 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.52 / eval/dyn_loss_std 7.22 / eval/image_loss_mean 1.21 / eval/image_loss_std 1.77 / eval/model_loss_mean 4.17 / eval/model_loss_std 5.73 / eval/post_ent_mag 51
/ eval/post_ent_max 51 / eval/post_ent_mean 42.12 / eval/post_ent_min 18.14 / eval/post_ent_std 4.5 / eval/prior_ent_mag 82.09 / eval/prior_ent_max 82.09 / eval/prior_ent_mean 46.13 / eval/prior_ent_min 29.8 / eval/prior_ent_std 5.71 / eval/rep_loss_mean 4.52 / 
eval/rep_loss_std 7.22 / eval/reward_avg 0.59 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.35 / eval/reward_max_data 1.91 / eval/reward_max_pred 1.88 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.59 / eval/reward_rate 0.42 / replay/size 4.8e5 / replay/inserts 3760 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.7e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3760 / timer/env.step_total 19.5 /
timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.17 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 
1.4e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7768 / timer/agent.policy_total 
17.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1880 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1880 / timer/agent.train_total 241.67 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / 
timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac
1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 306.4.
Starting evaluation at step 482000 Counter(482000) 481937
Saved chunk: 20230922T080400F916496-2nuwOx85lmPWzaBHPbLZBI-30ZjjxVhZ6YJM8u3reXxOl-1024.npz
eval_Episode has 500 steps and return 321.5.
Saved chunk: 20230922T080422F781678-37VBm1kAU0t3XJV78KO6gR-0MkcofRuZIeM5x20oyTjlC-1024.npz
train_Episode has 500 steps and return 309.7.
Starting evaluation at step 482500 Counter(482500) 482437
eval_Episode has 500 steps and return 328.1.
train_Episode has 500 steps and return 309.5.
Starting evaluation at step 483000 Counter(483000) 482937
Saved chunk: 20230922T080521F096273-30ZjjxVhZ6YJM8u3reXxOl-26VyR65p5fYgqNUZzPlKxX-1024.npz
eval_Episode has 500 steps and return 316.0.
Saved chunk: 20230922T080544F704268-0MkcofRuZIeM5x20oyTjlC-6zImnbxZJZVgWYmijH4j5M-1024.npz
train_Episode has 500 steps and return 296.1.
Starting evaluation at step 483500 Counter(483500) 483437
eval_Episode has 500 steps and return 312.8.
train_Episode has 500 steps and return 312.1.
Starting evaluation at step 484000 Counter(484000) 483937
Saved chunk: 20230922T080640F445015-26VyR65p5fYgqNUZzPlKxX-2gNDnXWWcecgcFbKZXq8E9-1024.npz
eval_Episode has 500 steps and return 330.0.
Saved chunk: 20230922T080705F639745-6zImnbxZJZVgWYmijH4j5M-4PQPT41wRy2ud6pQl4dCpg-1024.npz
train_Episode has 500 steps and return 311.3.
Starting evaluation at step 484500 Counter(484500) 484437
eval_Episode has 500 steps and return 335.7.
train_Episode has 500 steps and return 319.5.
Starting evaluation at step 485000 Counter(485000) 484937
Saved chunk: 20230922T080759F666017-2gNDnXWWcecgcFbKZXq8E9-2T4Jme1t5AL8pQMMps0U8S-1024.npz
eval_Episode has 500 steps and return 325.8.
Saved chunk: 20230922T080826F373264-4PQPT41wRy2ud6pQl4dCpg-1KFz53Kyd0XQt7QXZAzMFU-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 970766 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 319.53 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 325.8 / eval_episode/reward_rate 0.45 / train/action_mag 4.05 / train/action_max 3.93 / train/action_mean 0.04 / train/action_min -3.78 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 3.11 / train/adv_mag 0.31 / train/adv_max 0.24 / train/adv_mean 2.6e-4 / train/adv_min 
-0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 8.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.6 / train/dyn_loss_std 6.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.53 / train/extr_critic_max 229.53 / train/extr_critic_mean 218.6 / train/extr_critic_min 160.52 / train/extr_critic_std 14.25 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.74 / train/extr_return_raw_max 229.74 / train/extr_return_raw_mean 218.61 / 
train/extr_return_raw_min 162.09 / train/extr_return_raw_std 14.23 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.92 / train/image_loss_std 0.9 / 
train/model_loss_mean 3.26 / train/model_loss_std 4.46 / train/model_opt_grad_norm 8.15 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.72
/ train/policy_entropy_max 4.63 / train/policy_entropy_mean -1.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.47 / train/policy_logprob_mag 10.73 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.93 / train/policy_logprob_min -10.73 / 
train/policy_logprob_std 2.06 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.87 / train/post_ent_max 51.87 / 
train/post_ent_mean 42.12 / train/post_ent_min 22.13 / train/post_ent_std 4.9 / train/prior_ent_mag 82.05 / train/prior_ent_max 82.05 / train/prior_ent_mean 45.68 / train/prior_ent_min 27.97 / train/prior_ent_std 6.49 / train/rep_loss_mean 3.6 / train/rep_loss_std 6.27 
/ train/reward_avg 0.41 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.92 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.41 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 5.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.23 / report/dyn_loss_std 5.38 / report/image_loss_mean 0.82 / report/image_loss_std 0.72 / report/model_loss_mean 2.97 / report/model_loss_std 3.76 / report/post_ent_mag 
50.23 / report/post_ent_max 50.23 / report/post_ent_mean 42.81 / report/post_ent_min 20.22 / report/post_ent_std 3.94 / report/prior_ent_mag 81.53 / report/prior_ent_max 81.53 / report/prior_ent_mean 46.04 / report/prior_ent_min 25.28 / report/prior_ent_std 5.65 / 
report/rep_loss_mean 3.23 / report/rep_loss_std 5.38 / report/reward_avg 0.5 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.31 / report/reward_max_data 1.91 / report/reward_max_pred 1.89 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.5 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.67 / eval/dyn_loss_std 5.96 / eval/image_loss_mean 0.88 / eval/image_loss_std 1.06 / eval/model_loss_mean 3.33 / eval/model_loss_std 4.38 / eval/post_ent_mag 50.8 / eval/post_ent_max
50.8 / eval/post_ent_mean 42.75 / eval/post_ent_min 24.27 / eval/post_ent_std 3.73 / eval/prior_ent_mag 81.53 / eval/prior_ent_max 81.53 / eval/prior_ent_mean 46.37 / eval/prior_ent_min 32.53 / eval/prior_ent_std 5.25 / eval/rep_loss_mean 3.67 / eval/rep_loss_std 5.96 /
eval/reward_avg 0.64 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.99 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.64 / 
eval/reward_rate 0.45 / replay/size 4.9e5 / replay/inserts 3810 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3810 / timer/env.step_total 19.75 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 9.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 459.33 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 5.6e-3 / 
timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7317 / timer/agent.policy_total 16.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 8.8e-4 / timer/agent.train_count 1905 / 
timer/agent.train_total 244.77 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 307.3.
Starting evaluation at step 485500 Counter(485500) 485437
eval_Episode has 500 steps and return 306.6.
train_Episode has 500 steps and return 315.4.
Starting evaluation at step 486000 Counter(486000) 485937
Saved chunk: 20230922T080918F806182-2T4Jme1t5AL8pQMMps0U8S-3kifEjGSkWziBrNjdbzZvU-1024.npz
eval_Episode has 500 steps and return 337.4.
Saved chunk: 20230922T080946F944194-1KFz53Kyd0XQt7QXZAzMFU-4n245TmlCL8LQmGrPsRSjH-1024.npz
train_Episode has 500 steps and return 300.2.
Starting evaluation at step 486500 Counter(486500) 486437
eval_Episode has 500 steps and return 313.3.
train_Episode has 500 steps and return 276.6.
Starting evaluation at step 487000 Counter(487000) 486937
Saved chunk: 20230922T081039F120405-3kifEjGSkWziBrNjdbzZvU-4CMj86anRytMqqgXjEWGOd-1024.npz
eval_Episode has 500 steps and return 313.0.
Saved chunk: 20230922T081108F990432-4n245TmlCL8LQmGrPsRSjH-720bIog1VY7Nwea6v2EF8z-1024.npz
train_Episode has 500 steps and return 287.9.
Starting evaluation at step 487500 Counter(487500) 487437
eval_Episode has 500 steps and return 315.2.
train_Episode has 500 steps and return 307.9.
Starting evaluation at step 488000 Counter(488000) 487937
Saved chunk: 20230922T081158F416646-4CMj86anRytMqqgXjEWGOd-5Q2IHE7jEypFq2lrxRKC3x-1024.npz
eval_Episode has 500 steps and return 319.6.
Saved chunk: 20230922T081229F917666-720bIog1VY7Nwea6v2EF8z-2nW2kMykyBMU9NrWFnSfPY-1024.npz
train_Episode has 500 steps and return 307.0.
Starting evaluation at step 488500 Counter(488500) 488437
eval_Episode has 500 steps and return 318.5.
train_Episode has 500 steps and return 299.1.
Starting evaluation at step 489000 Counter(489000) 488937
Saved chunk: 20230922T081317F527173-5Q2IHE7jEypFq2lrxRKC3x-0Q2i5nXGqYrRnl7j4CL2K0-1024.npz
eval_Episode has 500 steps and return 333.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 978294 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 299.06 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 333.89 / eval_episode/reward_rate 0.47 / train/action_mag 4.08 / train/action_max 3.98 / train/action_mean 0.04 / train/action_min -3.76 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 2.92 / train/adv_mag 0.33 / train/adv_max 0.27 / train/adv_mean 2.8e-4
/ train/adv_min -0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 9.3e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 6.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.61 / train/extr_critic_max 229.61 / train/extr_critic_mean 218.44 / train/extr_critic_min 151.89 / train/extr_critic_std 15.61 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.44 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.83 / train/extr_return_raw_max 229.83 / train/extr_return_raw_mean 218.45 / train/extr_return_raw_min
153.76 / train/extr_return_raw_std 15.6 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.92 / train/image_loss_std 0.9 / train/model_loss_mean 3.27 / 
train/model_loss_std 4.49 / train/model_opt_grad_norm 8.25 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.69 / train/policy_entropy_max 
4.62 / train/policy_entropy_mean -1.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.47 / train/policy_logprob_mag 10.7 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.93 / train/policy_logprob_min -10.7 / train/policy_logprob_std 2.05 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.98 / train/post_ent_max 51.98 / train/post_ent_mean 42.19 / 
train/post_ent_min 22.24 / train/post_ent_std 4.89 / train/prior_ent_mag 81.97 / train/prior_ent_max 81.97 / train/prior_ent_mean 45.77 / train/prior_ent_min 28.18 / train/prior_ent_std 6.45 / train/rep_loss_mean 3.62 / train/rep_loss_std 6.31 / train/reward_avg 0.41 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.41 / train/reward_rate 
0.32 / train_stats/mean_log_entropy -2.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.47 / report/dyn_loss_std 6.03 / report/image_loss_mean 0.81 / report/image_loss_std 0.73 / report/model_loss_mean 3.08 / report/model_loss_std 4.23 / report/post_ent_mag 51.66 / report/post_ent_max 51.66 /
report/post_ent_mean 43 / report/post_ent_min 25 / report/post_ent_std 4.32 / report/prior_ent_mag 81.85 / report/prior_ent_max 81.85 / report/prior_ent_mean 46.39 / report/prior_ent_min 28.93 / report/prior_ent_std 5.84 / report/rep_loss_mean 3.47 / report/rep_loss_std
6.03 / report/reward_avg 0.43 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.27 / report/reward_max_data 2 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.53 / 
report/reward_pred 0.42 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 8.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.49 / eval/dyn_loss_std 5.54 / eval/image_loss_mean 0.82 / eval/image_loss_std 0.82 / eval/model_loss_mean 3.16 / eval/model_loss_std 3.93 / eval/post_ent_mag 52.16 / eval/post_ent_max 52.16 / eval/post_ent_mean 41.75 / eval/post_ent_min 21.79 / 
eval/post_ent_std 5.73 / eval/prior_ent_mag 81.85 / eval/prior_ent_max 81.85 / eval/prior_ent_mean 45.32 / eval/prior_ent_min 25.34 / eval/prior_ent_std 7.17 / eval/rep_loss_mean 3.49 / eval/rep_loss_std 5.54 / eval/reward_avg 0.62 / eval/reward_loss_mean 0.24 / 
eval/reward_loss_std 0.31 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.61 / eval/reward_rate 0.42 / replay/size 4.9e5 / 
replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3764 / timer/env.step_total 19.52 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 
4.5e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count
1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1882 / timer/agent.train_total 241.71 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 /
timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 282.9.
Saved chunk: 20230922T081350F395917-2nW2kMykyBMU9NrWFnSfPY-1o1lBne2DLXtG8qMmZtRbS-1024.npz
Starting evaluation at step 489500 Counter(489500) 489437
eval_Episode has 500 steps and return 314.4.
train_Episode has 500 steps and return 313.4.
Starting evaluation at step 490000 Counter(490000) 489937
eval_Episode has 500 steps and return 313.1.
Saved chunk: 20230922T081436F430078-0Q2i5nXGqYrRnl7j4CL2K0-55qKtgKH0wBTqHYjzsYZ0M-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T081556F948543-55qKtgKH0wBTqHYjzsYZ0M-0000000000000000000000-59.npz
Saved chunk: 20230922T081512F122891-1o1lBne2DLXtG8qMmZtRbS-0000000000000000000000-728.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 275.9.
Starting evaluation at step 490500 Counter(490500) 490437
Saved chunk: 20230922T081512F122891-1o1lBne2DLXtG8qMmZtRbS-2hHWRjRVPVqoCRELgIYvaY-1024.npz
eval_Episode has 500 steps and return 294.2.
train_Episode has 500 steps and return 293.9.
Starting evaluation at step 491000 Counter(491000) 490937
eval_Episode has 500 steps and return 332.4.
Saved chunk: 20230922T081556F948543-55qKtgKH0wBTqHYjzsYZ0M-6QaFTdEQ5ytIQ04xm6mrQG-1024.npz
train_Episode has 500 steps and return 307.3.
Starting evaluation at step 491500 Counter(491500) 491437
eval_Episode has 500 steps and return 325.7.
Saved chunk: 20230922T081633F390649-2hHWRjRVPVqoCRELgIYvaY-2yhOID3YLyndllFft5MNbE-1024.npz
train_Episode has 500 steps and return 287.4.
Starting evaluation at step 492000 Counter(492000) 491937
eval_Episode has 500 steps and return 314.8.
Saved chunk: 20230922T081716F558541-6QaFTdEQ5ytIQ04xm6mrQG-61QKoT09vRHLqWEl5nox68-1024.npz
train_Episode has 500 steps and return 258.9.
Starting evaluation at step 492500 Counter(492500) 492437
eval_Episode has 500 steps and return 327.1.
Saved chunk: 20230922T081757F769821-2yhOID3YLyndllFft5MNbE-1P8ftRMDIUaHUGnJZrvtNM-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 985906 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 258.92 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 327.08 / eval_episode/reward_rate 0.45 / train/action_mag 4.03 / train/action_max 3.94 / train/action_mean 0.04 / train/action_min -3.7 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss 3.49 / train/adv_mag 0.42 / train/adv_max 0.33 / train/adv_mean 2.3e-4 / train/adv_min 
-0.31 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 9.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.6 / train/dyn_loss_std 6.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.4e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.65 / train/extr_critic_max 229.65 / train/extr_critic_mean 218.79 / train/extr_critic_min 157.41 / train/extr_critic_std 14.6 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.86 / train/extr_return_raw_max 229.86 / train/extr_return_raw_mean 218.81 / 
train/extr_return_raw_min 158.88 / train/extr_return_raw_std 14.61 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.91 / train/image_loss_std 0.9 / 
train/model_loss_mean 3.26 / train/model_loss_std 4.45 / train/model_opt_grad_norm 8.25 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.49
/ train/policy_entropy_max 4.34 / train/policy_entropy_mean -1.95 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.41 / train/policy_logprob_mag 10.49 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.95 / train/policy_logprob_min -10.49 / 
train/policy_logprob_std 2.02 / train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.85 / train/post_ent_max 51.85 / 
train/post_ent_mean 42.27 / train/post_ent_min 22.27 / train/post_ent_std 4.8 / train/prior_ent_mag 81.89 / train/prior_ent_max 81.89 / train/prior_ent_mean 45.84 / train/prior_ent_min 28.4 / train/prior_ent_std 6.36 / train/rep_loss_mean 3.6 / train/rep_loss_std 6.26 /
train/reward_avg 0.41 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.91 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.41 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 5.88 / report/image_loss_mean 0.81 / report/image_loss_std 0.66 / report/model_loss_mean 3.11 / report/model_loss_std 4.05 / report/post_ent_mag 
51.33 / report/post_ent_max 51.33 / report/post_ent_mean 43.52 / report/post_ent_min 24.8 / report/post_ent_std 3.55 / report/prior_ent_mag 81.74 / report/prior_ent_max 81.74 / report/prior_ent_mean 46.97 / report/prior_ent_min 33.92 / report/prior_ent_std 5.4 / 
report/rep_loss_mean 3.49 / report/rep_loss_std 5.88 / report/reward_avg 0.47 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.31 / report/reward_max_data 1.91 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.47 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.71 / eval/dyn_loss_std 7.57 / eval/image_loss_mean 1.23 / eval/image_loss_std 1.81 / eval/model_loss_mean 4.3 / eval/model_loss_std 5.86 / eval/post_ent_mag 50.62 / eval/post_ent_max
50.62 / eval/post_ent_mean 41.92 / eval/post_ent_min 19.31 / eval/post_ent_std 5.05 / eval/prior_ent_mag 81.74 / eval/prior_ent_max 81.74 / eval/prior_ent_mean 46.15 / eval/prior_ent_min 25.26 / eval/prior_ent_std 6.1 / eval/rep_loss_mean 4.71 / eval/rep_loss_std 7.57 /
eval/reward_avg 0.59 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.95 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.59 / 
eval/reward_rate 0.41 / replay/size 4.9e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3806 / timer/env.step_total 19.9 / timer/env.step_frac 0.07 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.54 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / 
timer/replay._sample_max 0.23 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.59 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.9e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / 
timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.59 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / 
timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac
1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 310.4.
Starting evaluation at step 493000 Counter(493000) 492937
eval_Episode has 500 steps and return 318.4.
train_Episode has 500 steps and return 284.7.
Starting evaluation at step 493500 Counter(493500) 493437
Saved chunk: 20230922T081835F626795-61QKoT09vRHLqWEl5nox68-38x671h3zorAMZOMclVvVf-1024.npz
eval_Episode has 500 steps and return 299.3.
Saved chunk: 20230922T081918F295219-1P8ftRMDIUaHUGnJZrvtNM-1umcBEQ9e8Mf64UQASYCrC-1024.npz
train_Episode has 500 steps and return 312.0.
Starting evaluation at step 494000 Counter(494000) 493937
eval_Episode has 500 steps and return 333.9.
train_Episode has 500 steps and return 295.2.
Starting evaluation at step 494500 Counter(494500) 494437
Saved chunk: 20230922T082031F776709-38x671h3zorAMZOMclVvVf-0QOtDPFApsTAJPNbVErORf-1024.npz
eval_Episode has 500 steps and return 329.4.
Saved chunk: 20230922T082040F224000-1umcBEQ9e8Mf64UQASYCrC-2sAFde7ihNJcPaHOTsJ2zC-1024.npz
train_Episode has 500 steps and return 293.0.
Starting evaluation at step 495000 Counter(495000) 494937
eval_Episode has 500 steps and return 330.8.
train_Episode has 500 steps and return 303.3.
Starting evaluation at step 495500 Counter(495500) 495437
Saved chunk: 20230922T082151F237802-0QOtDPFApsTAJPNbVErORf-6aDjDXiidcDrTi1qHtC8pU-1024.npz
eval_Episode has 500 steps and return 322.7.
Saved chunk: 20230922T082201F247491-2sAFde7ihNJcPaHOTsJ2zC-1MEEhxJhWsc7RiplhD1Wnj-1024.npz
train_Episode has 500 steps and return 296.6.
Starting evaluation at step 496000 Counter(496000) 495937
eval_Episode has 500 steps and return 313.6.
train_Episode has 500 steps and return 296.9.
Starting evaluation at step 496500 Counter(496500) 496437
Saved chunk: 20230922T082310F607463-6aDjDXiidcDrTi1qHtC8pU-04g2gMyQp67tHE5cA3YpJ3-1024.npz
eval_Episode has 500 steps and return 284.5.
Saved chunk: 20230922T082322F170860-1MEEhxJhWsc7RiplhD1Wnj-4IL3voorrOogsTjf1SKUvk-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 993360 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 296.94 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 284.51 / eval_episode/reward_rate 0.42 / train/action_mag 4 / train/action_max 3.89 / train/action_mean 0.04 / train/action_min -3.7 / train/action_std 
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 4.96 / train/adv_mag 0.36 / train/adv_max 0.3 / train/adv_mean 7.6e-5 / train/adv_min 
-0.25 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.64 / train/dyn_loss_std 6.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.76 / train/extr_critic_max 229.76 / train/extr_critic_mean 218.59 / train/extr_critic_min 159.43 / train/extr_critic_std 14.45 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.95 / train/extr_return_raw_max 229.95 / train/extr_return_raw_mean 218.59 / 
train/extr_return_raw_min 161.66 / train/extr_return_raw_std 14.47 / train/extr_reward_mag 1.96 / train/extr_reward_max 1.96 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.64 / train/image_loss_mean 0.93 / train/image_loss_std 0.92 / 
train/model_loss_mean 3.29 / train/model_loss_std 4.54 / train/model_opt_grad_norm 8.22 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.53
/ train/policy_entropy_max 4.41 / train/policy_entropy_mean -1.93 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.43 / train/policy_logprob_mag 10.86 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.93 / train/policy_logprob_min -10.86 / 
train/policy_logprob_std 2.03 / train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.2e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.8 / train/post_ent_max 51.8 / 
train/post_ent_mean 42.16 / train/post_ent_min 21.71 / train/post_ent_std 4.9 / train/prior_ent_mag 81.79 / train/prior_ent_max 81.79 / train/prior_ent_mean 45.75 / train/prior_ent_min 27.7 / train/prior_ent_std 6.45 / train/rep_loss_mean 3.64 / train/rep_loss_std 6.39 
/ train/reward_avg 0.41 / train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.41 / train/reward_rate 0.32 / train_stats/mean_log_entropy -2.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 8.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.76 / report/dyn_loss_std 6.56 / report/image_loss_mean 1.07 / report/image_loss_std 1.1 / report/model_loss_mean 3.49 / report/model_loss_std 4.73 / report/post_ent_mag 50.46
/ report/post_ent_max 50.46 / report/post_ent_mean 41.5 / report/post_ent_min 22.6 / report/post_ent_std 4.91 / report/prior_ent_mag 81.56 / report/prior_ent_max 81.56 / report/prior_ent_mean 45.22 / report/prior_ent_min 27.19 / report/prior_ent_std 6.39 / 
report/rep_loss_mean 3.76 / report/rep_loss_std 6.56 / report/reward_avg 0.41 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 1.97 / report/reward_neg_acc 1 / report/reward_neg_loss 4.2e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.41 / report/reward_rate 0.31 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.79 / eval/dyn_loss_std 6.01 / eval/image_loss_mean 0.88 / eval/image_loss_std 1.01 / eval/model_loss_mean 3.43 / eval/model_loss_std 4.3 / eval/post_ent_mag 50.26 / eval/post_ent_max
50.26 / eval/post_ent_mean 42.5 / eval/post_ent_min 23.14 / eval/post_ent_std 3.9 / eval/prior_ent_mag 81.56 / eval/prior_ent_max 81.56 / eval/prior_ent_mean 46.28 / eval/prior_ent_min 32.05 / eval/prior_ent_std 5.47 / eval/rep_loss_mean 3.79 / eval/rep_loss_std 6.01 / 
eval/reward_avg 0.67 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.97 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.67 / 
eval/reward_rate 0.47 / replay/size 5e5 / replay/inserts 3727 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3727 / timer/env.step_total 19.36 / timer/env.step_frac 0.06
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 443.94 / timer/replay._sample_frac 1.48 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-3 / 
timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7735 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1863 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1863 / 
timer/agent.train_total 241.6 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 2.08 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.2e-5 / timer/dataset_eval_frac 7.5e-8 / timer/dataset_eval_avg 2.2e-5 / timer/dataset_eval_min 2.2e-5 / timer/dataset_eval_max 2.2e-5 / fps 24.85

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 301.8.
Starting evaluation at step 497000 Counter(497000) 496937
eval_Episode has 500 steps and return 305.1.
train_Episode has 500 steps and return 284.2.
Starting evaluation at step 497500 Counter(497500) 497437
Saved chunk: 20230922T082431F751748-04g2gMyQp67tHE5cA3YpJ3-3kA6D8ZqBYqUgekGAakc6x-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082444F799839-4IL3voorrOogsTjf1SKUvk-0ch5hJq18sNzO39SDysu7A-1024.npz
train_Episode has 500 steps and return 284.8.
Starting evaluation at step 498000 Counter(498000) 497937
eval_Episode has 500 steps and return 320.8.
train_Episode has 500 steps and return 298.2.
Starting evaluation at step 498500 Counter(498500) 498437
Saved chunk: 20230922T082552F215726-3kA6D8ZqBYqUgekGAakc6x-57PWRivJfvDHiQY5jPoPSA-1024.npz
eval_Episode has 500 steps and return 319.0.
Saved chunk: 20230922T082606F970129-0ch5hJq18sNzO39SDysu7A-5oYvi9EJ2oQEvMlQEh4SqV-1024.npz
train_Episode has 500 steps and return 289.0.
Starting evaluation at step 499000 Counter(499000) 498937
eval_Episode has 500 steps and return 310.6.
train_Episode has 500 steps and return 302.9.
Starting evaluation at step 499500 Counter(499500) 499437
Saved chunk: 20230922T082711F570737-57PWRivJfvDHiQY5jPoPSA-6BnaRawHjhmGtouXcCCbK0-1024.npz
eval_Episode has 500 steps and return 310.7.
Saved chunk: 20230922T082727F799417-5oYvi9EJ2oQEvMlQEh4SqV-3h7a8qONsvUJx6rALWlQjT-1024.npz
train_Episode has 500 steps and return 270.0.
Starting evaluation at step 500000 Counter(500000) 499937
eval_Episode has 500 steps and return 317.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1000978 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 270.05 / episode/reward_rate 0.37 / eval_episode/length 500 / eval_episode/score 317.2 / eval_episode/reward_rate 0.45 / train/action_mag 4 / train/action_max 3.87 / train/action_mean 0.04 / train/action_min -3.76 / train/action_std 
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 2.86 / train/adv_mag 0.35 / train/adv_max 0.29 / train/adv_mean 2.9e-4 / train/adv_min 
-0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 9.2e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.61 / train/dyn_loss_std 6.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.67 / train/extr_critic_max 229.67 / train/extr_critic_mean 218.07 / train/extr_critic_min 148.4 / train/extr_critic_std 17.24 / train/extr_return_normed_mag 1.52 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.46 / train/extr_return_normed_std 0.32 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.87 / train/extr_return_raw_max 229.87 / train/extr_return_raw_mean 218.08 / 
train/extr_return_raw_min 150.39 / train/extr_return_raw_std 17.25 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.91 / train/image_loss_std 0.89 / 
train/model_loss_mean 3.26 / train/model_loss_std 4.44 / train/model_opt_grad_norm 8.38 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.61
/ train/policy_entropy_max 4.51 / train/policy_entropy_mean -1.95 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.45 / train/policy_logprob_mag 10.73 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.94 / train/policy_logprob_min -10.73 / 
train/policy_logprob_std 2.05 / train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.69 / train/post_ent_max 51.69 / 
train/post_ent_mean 42.21 / train/post_ent_min 21.83 / train/post_ent_std 4.92 / train/prior_ent_mag 81.73 / train/prior_ent_max 81.73 / train/prior_ent_mean 45.79 / train/prior_ent_min 27.55 / train/prior_ent_std 6.46 / train/rep_loss_mean 3.61 / train/rep_loss_std 
6.26 / train/reward_avg 0.42 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.42 / train/reward_rate 0.33 / train_stats/mean_log_entropy -2.2 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 3.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.65 / report/dyn_loss_std 6.53 / report/image_loss_mean 0.9 / report/image_loss_std 0.79 / report/model_loss_mean 3.29 / report/model_loss_std 4.53 / 
report/post_ent_mag 50.78 / report/post_ent_max 50.78 / report/post_ent_mean 42.61 / report/post_ent_min 20.48 / report/post_ent_std 4.32 / report/prior_ent_mag 81.51 / report/prior_ent_max 81.51 / report/prior_ent_mean 46.23 / report/prior_ent_min 31.21 / 
report/prior_ent_std 5.76 / report/rep_loss_mean 3.65 / report/rep_loss_std 6.53 / report/reward_avg 0.47 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.31 / report/reward_max_data 1.89 / report/reward_max_pred 1.88 / report/reward_neg_acc 0.99 / 
report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.47 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.34 / eval/dyn_loss_std 5.12 / eval/image_loss_mean 0.76 / eval/image_loss_std 0.71 / eval/model_loss_mean 3.03 / eval/model_loss_std 3.75 / eval/post_ent_mag 
49.66 / eval/post_ent_max 49.66 / eval/post_ent_mean 43.01 / eval/post_ent_min 28.44 / eval/post_ent_std 3.24 / eval/prior_ent_mag 81.51 / eval/prior_ent_max 81.51 / eval/prior_ent_mean 46.39 / eval/prior_ent_min 40.07 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 3.34
/ eval/rep_loss_std 5.12 / eval/reward_avg 0.65 / eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / 
eval/reward_pred 0.65 / eval/reward_rate 0.47 / replay/size 5e5 / replay/inserts 3809 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3809 / timer/env.step_total 19.73
/ timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 456.74 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7316 / timer/agent.policy_total 16.5 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1905 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.8e-4 / 
timer/agent.train_count 1905 / timer/agent.train_total 244.91 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 
3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / 
timer/dataset_eval_max 2.9e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 254.3.
Starting evaluation at step 500500 Counter(500500) 500437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T082830F685039-6BnaRawHjhmGtouXcCCbK0-0rX9iq7N1zV4Tm5uha5LOW-1024.npz
eval_Episode has 500 steps and return 312.6.
Saved chunk: 20230922T082848F415890-3h7a8qONsvUJx6rALWlQjT-32zuCWuMNvYxuAqcOszgOJ-1024.npz
train_Episode has 500 steps and return 287.8.
Starting evaluation at step 501000 Counter(501000) 500937
eval_Episode has 500 steps and return 322.7.
Starting evaluation at step 501500 Counter(501500) 501437
Saved chunk: 20230922T082950F861401-0rX9iq7N1zV4Tm5uha5LOW-3AJs06nWMQgerLxy986CJd-1024.npz
eval_Episode has 500 steps and return 322.9.
train_Episode has 500 steps and return 280.6.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T083110F542453-3AJs06nWMQgerLxy986CJd-0000000000000000000000-318.npz
Saved chunk: 20230922T083010F441129-32zuCWuMNvYxuAqcOszgOJ-0000000000000000000000-864.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T083010F441129-32zuCWuMNvYxuAqcOszgOJ-1pSXisVpYf7iqOPcm9oNu0-1024.npz
Starting evaluation at step 502000 Counter(502000) 501937
eval_Episode has 500 steps and return 318.1.
train_Episode has 500 steps and return 317.6.
Starting evaluation at step 502500 Counter(502500) 502437
Saved chunk: 20230922T083110F542453-3AJs06nWMQgerLxy986CJd-2PfVKHv5amdSEX6hwhvigy-1024.npz
eval_Episode has 500 steps and return 335.2.
train_Episode has 500 steps and return 291.7.
Saved chunk: 20230922T083131F787556-1pSXisVpYf7iqOPcm9oNu0-3QV39ZxcXyQKJ2j9shNumF-1024.npz
Starting evaluation at step 503000 Counter(503000) 502937
eval_Episode has 500 steps and return 302.1.
train_Episode has 500 steps and return 275.2.
Starting evaluation at step 503500 Counter(503500) 503437
Saved chunk: 20230922T083229F999293-2PfVKHv5amdSEX6hwhvigy-4kfONi9RNiUcu2sZcJPnpk-1024.npz
eval_Episode has 500 steps and return 297.0.
train_Episode has 500 steps and return 302.2.
Saved chunk: 20230922T083252F545683-3QV39ZxcXyQKJ2j9shNumF-077Umgta1j9kxg1DlQms5J-1024.npz
Starting evaluation at step 504000 Counter(504000) 503937
eval_Episode has 500 steps and return 323.2.
train_Episode has 500 steps and return 295.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1008482 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 295.82 / episode/reward_rate 0.4 / eval_episode/length 500 / eval_episode/score 323.19 / eval_episode/reward_rate 0.45 / train/action_mag 3.97 / train/action_max 3.83 / train/action_mean 0.03 / train/action_min -3.75 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 3.04 / train/adv_mag 0.39 / train/adv_max 0.32 / train/adv_mean 2.9e-4 / train/adv_min 
-0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 9.4e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.59 / train/dyn_loss_std 6.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.79 / train/extr_critic_max 229.79 / train/extr_critic_mean 219.18 / train/extr_critic_min 160.09 / train/extr_critic_std 13.88 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 229.99 / train/extr_return_raw_max 229.99 / train/extr_return_raw_mean 219.2 / train/extr_return_raw_min
162.31 / train/extr_return_raw_std 13.9 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.9 / train/image_loss_std 0.88 / train/model_loss_mean 3.24 / 
train/model_loss_std 4.42 / train/model_opt_grad_norm 8.06 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.65 / train/policy_entropy_max 
4.56 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.39 / train/policy_logprob_mag 10.46 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.46 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.71 / train/post_ent_max 51.71 / train/post_ent_mean 42.26 / 
train/post_ent_min 22.14 / train/post_ent_std 4.79 / train/prior_ent_mag 81.68 / train/prior_ent_max 81.68 / train/prior_ent_mean 45.8 / train/prior_ent_min 28.44 / train/prior_ent_std 6.35 / train/rep_loss_mean 3.59 / train/rep_loss_std 6.23 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 
0.33 / train_stats/mean_log_entropy -2.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.87 / report/dyn_loss_std 6.65 / report/image_loss_mean 0.93 / report/image_loss_std 1.18 / report/model_loss_mean 3.47 / report/model_loss_std 4.9 / report/post_ent_mag 53.4 / report/post_ent_max 53.4 / 
report/post_ent_mean 43.12 / report/post_ent_min 23.78 / report/post_ent_std 4.27 / report/prior_ent_mag 81.55 / report/prior_ent_max 81.55 / report/prior_ent_mean 46.75 / report/prior_ent_min 30.15 / report/prior_ent_std 5.66 / report/rep_loss_mean 3.87 / 
report/rep_loss_std 6.65 / report/reward_avg 0.49 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.3 / report/reward_max_data 1.88 / report/reward_max_pred 1.85 / report/reward_neg_acc 1 / report/reward_neg_loss 5.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.49 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.99 / eval/dyn_loss_std 7.96 / eval/image_loss_mean 1.27 / eval/image_loss_std 1.85 / eval/model_loss_mean 4.48 / eval/model_loss_std 6.2 / eval/post_ent_mag 51.16 / eval/post_ent_max 51.16 / eval/post_ent_mean 
40.58 / eval/post_ent_min 22.03 / eval/post_ent_std 6.59 / eval/prior_ent_mag 81.55 / eval/prior_ent_max 81.55 / eval/prior_ent_mean 44.86 / eval/prior_ent_min 24.99 / eval/prior_ent_std 7.61 / eval/rep_loss_mean 4.99 / eval/rep_loss_std 7.96 / eval/reward_avg 0.53 / 
eval/reward_loss_mean 0.22 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.52 / eval/reward_rate 0.38 / 
replay/size 5e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3752 / timer/env.step_total 19.46 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.33 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.9e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.79 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 504500 Counter(504500) 504437
Saved chunk: 20230922T083349F137292-4kfONi9RNiUcu2sZcJPnpk-0rlrldTtsKClqpFIDMv4nR-1024.npz
eval_Episode has 500 steps and return 319.0.
train_Episode has 500 steps and return 239.6.
Saved chunk: 20230922T083413F208993-077Umgta1j9kxg1DlQms5J-595hSfiYgd8KLAJuMU0niU-1024.npz
Starting evaluation at step 505000 Counter(505000) 504937
eval_Episode has 500 steps and return 326.7.
train_Episode has 500 steps and return 309.1.
Starting evaluation at step 505500 Counter(505500) 505437
Saved chunk: 20230922T083509F447421-0rlrldTtsKClqpFIDMv4nR-2h92zfkRkRtyDUBARoBq7O-1024.npz
eval_Episode has 500 steps and return 313.9.
train_Episode has 500 steps and return 296.9.
Saved chunk: 20230922T083535F231053-595hSfiYgd8KLAJuMU0niU-7fAc2p5ewUnZqEI2wYYKVL-1024.npz
Starting evaluation at step 506000 Counter(506000) 505937
eval_Episode has 500 steps and return 311.7.
train_Episode has 500 steps and return 311.0.
Starting evaluation at step 506500 Counter(506500) 506437
Saved chunk: 20230922T083628F774324-2h92zfkRkRtyDUBARoBq7O-2QuM41FuwriyKLbpPz6RdZ-1024.npz
eval_Episode has 500 steps and return 321.2.
train_Episode has 500 steps and return 283.5.
Saved chunk: 20230922T083656F005131-7fAc2p5ewUnZqEI2wYYKVL-5QtcmOibI6bklnTQ2urykH-1024.npz
Starting evaluation at step 507000 Counter(507000) 506937
eval_Episode has 500 steps and return 324.3.
train_Episode has 500 steps and return 297.5.
Starting evaluation at step 507500 Counter(507500) 507437
Saved chunk: 20230922T083747F874409-2QuM41FuwriyKLbpPz6RdZ-1klDnqFzxavuiojj8c6d6r-1024.npz
eval_Episode has 500 steps and return 308.0.
train_Episode has 500 steps and return 300.4.
Saved chunk: 20230922T083816F625263-5QtcmOibI6bklnTQ2urykH-38xeMk2q4yZ1EFGHdCuNhH-1024.npz
Starting evaluation at step 508000 Counter(508000) 507937
eval_Episode has 500 steps and return 310.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1016010 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 310.81 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 300.37 / episode/reward_rate 0.42 / train/action_mag 3.98 / train/action_max 3.83 / train/action_mean 0.03 / train/action_min -3.74 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 2.36 / train/adv_mag 0.37 / train/adv_max 0.28 / train/adv_mean 3.7e-4
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.62 / train/dyn_loss_std 6.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 229.98 / train/extr_critic_max 229.98 / train/extr_critic_mean 219.18 / train/extr_critic_min 160.22 / train/extr_critic_std 14.39 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.18 / train/extr_return_raw_max 230.18 / train/extr_return_raw_mean 219.2 / train/extr_return_raw_min 
160.31 / train/extr_return_raw_std 14.4 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.92 / train/image_loss_std 0.9 / train/model_loss_mean 3.27 / 
train/model_loss_std 4.5 / train/model_opt_grad_norm 8.47 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.63 / train/policy_entropy_max 
4.51 / train/policy_entropy_mean -2.04 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.36 / train/policy_logprob_mag 10.42 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.04 / train/policy_logprob_min -10.42 / train/policy_logprob_std 1.98 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.97 / train/post_ent_max 51.97 / train/post_ent_mean 42.25 / 
train/post_ent_min 21.77 / train/post_ent_std 4.79 / train/prior_ent_mag 81.71 / train/prior_ent_max 81.71 / train/prior_ent_mean 45.82 / train/prior_ent_min 28.05 / train/prior_ent_std 6.33 / train/rep_loss_mean 3.62 / train/rep_loss_std 6.34 / train/reward_avg 0.41 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.41 / train/reward_rate 
0.32 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.28 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.87 / report/dyn_loss_std 6.9 / report/image_loss_mean 0.95 / report/image_loss_std 1.01 / report/model_loss_mean 3.47 / report/model_loss_std 4.97 / report/post_ent_mag 53.31 / report/post_ent_max 53.31 / 
report/post_ent_mean 42.79 / report/post_ent_min 24.13 / report/post_ent_std 4.33 / report/prior_ent_mag 81.98 / report/prior_ent_max 81.98 / report/prior_ent_mean 46.61 / report/prior_ent_min 30.77 / report/prior_ent_std 5.84 / report/rep_loss_mean 3.87 / 
report/rep_loss_std 6.9 / report/reward_avg 0.42 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.33 / report/reward_max_data 1.99 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.58 / report/reward_pred 0.42 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 5.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.26 / eval/dyn_loss_std 5.28 / eval/image_loss_mean 0.71 / eval/image_loss_std 0.54 / eval/model_loss_mean 2.93 / eval/model_loss_std 3.7 / eval/post_ent_mag 50.61 / eval/post_ent_max 50.61 / eval/post_ent_mean 43.22 / 
eval/post_ent_min 27.83 / eval/post_ent_std 3.23 / eval/prior_ent_mag 81.98 / eval/prior_ent_max 81.98 / eval/prior_ent_mean 46.52 / eval/prior_ent_min 40.54 / eval/prior_ent_std 5.07 / eval/rep_loss_mean 3.26 / eval/rep_loss_std 5.28 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 1.96 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.65 / eval/reward_rate 0.46 / 
replay/size 5.1e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3764 / timer/env.step_total 19.45 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.72 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.1e-4 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.34 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.3e-3 
/ timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1882 / timer/agent.train_total 241.91 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.09

train_Episode has 500 steps and return 292.8.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 508500 Counter(508500) 508437
Saved chunk: 20230922T083906F762203-1klDnqFzxavuiojj8c6d6r-7z7bbbQlvkak0RFJcw50nK-1024.npz
eval_Episode has 500 steps and return 333.3.
train_Episode has 500 steps and return 256.6.
Saved chunk: 20230922T083937F142389-38xeMk2q4yZ1EFGHdCuNhH-6QTdcRhTZFfu6kwNBF88Xb-1024.npz
Starting evaluation at step 509000 Counter(509000) 508937
eval_Episode has 500 steps and return 325.7.
train_Episode has 500 steps and return 299.4.
Starting evaluation at step 509500 Counter(509500) 509437
Saved chunk: 20230922T084027F205528-7z7bbbQlvkak0RFJcw50nK-4gKy2Qidsy8N63Uc7WVV8W-1024.npz
eval_Episode has 500 steps and return 322.2.
train_Episode has 500 steps and return 301.1.
Saved chunk: 20230922T084059F247235-6QTdcRhTZFfu6kwNBF88Xb-0OiEQh7d8EdZ4gJab0GDJT-1024.npz
Starting evaluation at step 510000 Counter(510000) 509937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 282.7.
Starting evaluation at step 510500 Counter(510500) 510437
Saved chunk: 20230922T084146F474384-4gKy2Qidsy8N63Uc7WVV8W-0Z5rhiuqv6bTCu71aVHlYj-1024.npz
eval_Episode has 500 steps and return 326.7.
train_Episode has 500 steps and return 294.2.
Saved chunk: 20230922T084220F034624-0OiEQh7d8EdZ4gJab0GDJT-03FkvoXZqDBoqSDYpRmweJ-1024.npz
Starting evaluation at step 511000 Counter(511000) 510937
eval_Episode has 500 steps and return 302.4.
train_Episode has 500 steps and return 303.9.
Starting evaluation at step 511500 Counter(511500) 511437
Saved chunk: 20230922T084305F672278-0Z5rhiuqv6bTCu71aVHlYj-6cPhBlaYA2BGtJROT0WjJT-1024.npz
eval_Episode has 500 steps and return 319.7.
train_Episode has 500 steps and return 291.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1023634 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 291.92 / episode/reward_rate 0.41 / eval_episode/length 500 / eval_episode/score 319.73 / eval_episode/reward_rate 0.47 / train_stats/mean_log_entropy -2.24 / train/action_mag 3.96 / train/action_max 3.79 / train/action_mean 0.03 / 
train/action_min -3.76 / train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss 4.47 / train/adv_mag 0.32 / train/adv_max 
0.25 / train/adv_mean 1.5e-4 / train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 8.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / 
train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 3.56 / train/dyn_loss_std 6.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / 
train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.15 / train/extr_critic_max 230.15 / train/extr_critic_mean 219.54 / train/extr_critic_min 165.05 / train/extr_critic_std 13.77 / 
train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.28 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.32 / 
train/extr_return_raw_max 230.32 / train/extr_return_raw_mean 219.54 / train/extr_return_raw_min 165.33 / train/extr_return_raw_std 13.8 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / 
train/extr_reward_std 0.65 / train/image_loss_mean 0.89 / train/image_loss_std 0.89 / train/model_loss_mean 3.21 / train/model_loss_std 4.39 / train/model_opt_grad_norm 8.02 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 3.2e4 / 
train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.61 / train/policy_entropy_max 4.51 / train/policy_entropy_mean -2.02 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.39 / 
train/policy_logprob_mag 10.53 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.53 / train/policy_logprob_std 2 / train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.16 / 
train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.85 / train/post_ent_max 51.85 / train/post_ent_mean 42.34 / train/post_ent_min 21.95 / train/post_ent_std 4.75 / train/prior_ent_mag 81.59 / train/prior_ent_max 81.59 / 
train/prior_ent_mean 45.85 / train/prior_ent_min 28.17 / train/prior_ent_std 6.29 / train/rep_loss_mean 3.56 / train/rep_loss_std 6.16 / train/reward_avg 0.42 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 
1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / 
report/cont_loss_std 4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.01 / report/dyn_loss_std 5.23 / report/image_loss_mean 0.69 / 
report/image_loss_std 0.6 / report/model_loss_mean 2.72 / report/model_loss_std 3.66 / report/post_ent_mag 51.56 / report/post_ent_max 51.56 / report/post_ent_mean 42.43 / report/post_ent_min 28.79 / report/post_ent_std 4.37 / report/prior_ent_mag 81.56 / 
report/prior_ent_max 81.56 / report/prior_ent_mean 45.55 / report/prior_ent_min 31.95 / report/prior_ent_std 6.19 / report/rep_loss_mean 3.01 / report/rep_loss_std 5.23 / report/reward_avg 0.52 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.33 / 
report/reward_max_data 1.99 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 3.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.57 / report/reward_pred 0.52 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 
1.8e-11 / eval/cont_loss_std 5.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.19 / eval/dyn_loss_std 6.9 / eval/image_loss_mean 1.05 / 
eval/image_loss_std 1.61 / eval/model_loss_mean 3.81 / eval/model_loss_std 5.53 / eval/post_ent_mag 51.14 / eval/post_ent_max 51.14 / eval/post_ent_mean 42.47 / eval/post_ent_min 21.2 / eval/post_ent_std 4.09 / eval/prior_ent_mag 81.56 / eval/prior_ent_max 81.56 / 
eval/prior_ent_mean 46.49 / eval/prior_ent_min 34.65 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 4.19 / eval/rep_loss_std 6.9 / eval/reward_avg 0.63 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.39 / eval/reward_max_data 1.97 / eval/reward_max_pred 1.94 / 
eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.62 / eval/reward_rate 0.45 / replay/size 5.1e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3812 / timer/env.step_total 20.02 / timer/env.step_frac 0.07 / timer/env.step_avg 5.3e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 460.6 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count
7319 / timer/agent.policy_total 16.67 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / 
timer/dataset_train_avg 8.8e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.33 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / 
timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 
4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 512000 Counter(512000) 511937
Saved chunk: 20230922T084340F648088-03FkvoXZqDBoqSDYpRmweJ-4GgrPYcyv4NdvDZeeUVZgW-1024.npz
eval_Episode has 500 steps and return 322.1.
train_Episode has 500 steps and return 283.3.
Starting evaluation at step 512500 Counter(512500) 512437
Saved chunk: 20230922T084424F564564-6cPhBlaYA2BGtJROT0WjJT-0NXccsT4WUyi6v4W1rJqB3-1024.npz
eval_Episode has 500 steps and return 318.6.
train_Episode has 500 steps and return 299.3.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 513000 Counter(513000) 512937
Saved chunk: 20230922T084545F092214-0NXccsT4WUyi6v4W1rJqB3-0000000000000000000000-76.npz
Saved chunk: 20230922T084502F313201-4GgrPYcyv4NdvDZeeUVZgW-0000000000000000000000-1000.npz
eval_Episode has 500 steps and return 333.9.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
train_Episode has 500 steps and return 295.7.
Saved chunk: 20230922T084502F313201-4GgrPYcyv4NdvDZeeUVZgW-5r7UhUWY2x1rFKI73A2lij-1024.npz
Starting evaluation at step 513500 Counter(513500) 513437
eval_Episode has 500 steps and return 316.9.
Saved chunk: 20230922T084545F092214-0NXccsT4WUyi6v4W1rJqB3-2jKfTQg0f5mFeCvv3v94Pw-1024.npz
train_Episode has 500 steps and return 311.6.
Starting evaluation at step 514000 Counter(514000) 513937
eval_Episode has 500 steps and return 332.1.
train_Episode has 500 steps and return 307.3.
Saved chunk: 20230922T084627F388835-5r7UhUWY2x1rFKI73A2lij-2ro8sDkUsuT627foh45liq-1024.npz
Starting evaluation at step 514500 Counter(514500) 514437
eval_Episode has 500 steps and return 324.7.
Saved chunk: 20230922T084704F801391-2jKfTQg0f5mFeCvv3v94Pw-4NHwLL8P8YQWZt11b83xXi-1024.npz
train_Episode has 500 steps and return 286.0.
Starting evaluation at step 515000 Counter(515000) 514937
eval_Episode has 500 steps and return 290.9.
train_Episode has 500 steps and return 280.7.
Saved chunk: 20230922T084748F170471-2ro8sDkUsuT627foh45liq-5PNNL40HvFEZqbjOcQWube-1024.npz
Starting evaluation at step 515500 Counter(515500) 515437
eval_Episode has 500 steps and return 322.1.
Saved chunk: 20230922T084823F845911-4NHwLL8P8YQWZt11b83xXi-6AlSSgKdUnRRHJNALknOej-1024.npz
train_Episode has 500 steps and return 269.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1031146 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 322.1 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 268.97 / episode/reward_rate 0.38 / train/action_mag 3.92 / train/action_max 3.79 / train/action_mean 0.03 / train/action_min -3.7 / train/action_std 
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 2.59 / train/adv_mag 0.36 / train/adv_max 0.28 / train/adv_mean 3.4e-4 / train/adv_min 
-0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.57 / train/dyn_loss_std 6.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.29 / train/extr_critic_max 230.29 / train/extr_critic_mean 219.46 / train/extr_critic_min 159.53 / train/extr_critic_std 14.41 / train/extr_return_normed_mag 1.48 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.48 / train/extr_return_raw_max 230.48 / train/extr_return_raw_mean 219.48 / train/extr_return_raw_min 
160.64 / train/extr_return_raw_std 14.43 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.9 / train/image_loss_std 0.89 / train/model_loss_mean 3.23 /
train/model_loss_std 4.43 / train/model_opt_grad_norm 8.25 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.61 / train/policy_entropy_max 
4.57 / train/policy_entropy_mean -2.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.41 / train/policy_logprob_mag 10.53 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.53 / train/policy_logprob_std 2.01 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.77 / train/post_ent_max 51.77 / train/post_ent_mean 42.34 / 
train/post_ent_min 22.16 / train/post_ent_std 4.69 / train/prior_ent_mag 81.46 / train/prior_ent_max 81.46 / train/prior_ent_mean 45.86 / train/prior_ent_min 28.51 / train/prior_ent_std 6.24 / train/rep_loss_mean 3.57 / train/rep_loss_std 6.24 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.93 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.26 / report/cont_avg 1 / report/cont_loss_mean 1.3e-11 / report/cont_loss_std 3.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.86 / report/dyn_loss_std 6.67 / report/image_loss_mean 1.07 / report/image_loss_std 1.18 / report/model_loss_mean 3.55 / report/model_loss_std 4.93 / report/post_ent_mag 54.17 / report/post_ent_max 54.17 /
report/post_ent_mean 42 / report/post_ent_min 21.76 / report/post_ent_std 4.49 / report/prior_ent_mag 81.58 / report/prior_ent_max 81.58 / report/prior_ent_mean 45.9 / report/prior_ent_min 28.8 / report/prior_ent_std 6.08 / report/rep_loss_mean 3.86 / 
report/rep_loss_std 6.67 / report/reward_avg 0.38 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.26 / report/reward_max_data 1.9 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 2.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.53 / report/reward_pred 0.38 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.51 / eval/dyn_loss_std 5.48 / eval/image_loss_mean 0.83 / eval/image_loss_std 1 / eval/model_loss_mean 3.2 / eval/model_loss_std 4.03 / eval/post_ent_mag 49.76 / eval/post_ent_max 49.76 / eval/post_ent_mean 
42.65 / eval/post_ent_min 22.93 / eval/post_ent_std 3.63 / eval/prior_ent_mag 81.58 / eval/prior_ent_max 81.58 / eval/prior_ent_mean 46.21 / eval/prior_ent_min 30.61 / eval/prior_ent_std 5.44 / eval/rep_loss_mean 3.51 / eval/rep_loss_std 5.48 / eval/reward_avg 0.65 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.65 / eval/reward_rate 0.45 / 
replay/size 5.2e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3756 / timer/env.step_total 19.5 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.96 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 7.9e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7764 / timer/agent.policy_total 18 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.2 / timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 6.8e-4 / timer/agent.train_count 1878 / timer/agent.train_total 241.11 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 516000 Counter(516000) 515937
eval_Episode has 500 steps and return 303.6.
train_Episode has 500 steps and return 300.4.
Saved chunk: 20230922T084908F616837-5PNNL40HvFEZqbjOcQWube-6Oenr5y6SxxPp2QZhjsPs5-1024.npz
Starting evaluation at step 516500 Counter(516500) 516437
eval_Episode has 500 steps and return 325.3.
train_Episode has 500 steps and return 289.2.
Starting evaluation at step 517000 Counter(517000) 516937
Saved chunk: 20230922T084942F726092-6AlSSgKdUnRRHJNALknOej-4qxHsi0aFs3a5umuojoD7G-1024.npz
eval_Episode has 500 steps and return 336.0.
train_Episode has 500 steps and return 314.6.
Saved chunk: 20230922T085030F539712-6Oenr5y6SxxPp2QZhjsPs5-477gMfdZ5j1nXs6JoLb2BX-1024.npz
Starting evaluation at step 517500 Counter(517500) 517437
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 307.2.
Starting evaluation at step 518000 Counter(518000) 517937
Saved chunk: 20230922T085139F405797-4qxHsi0aFs3a5umuojoD7G-4KM8DWJKZNPLuMwWrmXSac-1024.npz
eval_Episode has 500 steps and return 316.0.
train_Episode has 500 steps and return 304.9.
Saved chunk: 20230922T085151F541945-477gMfdZ5j1nXs6JoLb2BX-0YSQKMU0A7d3HLGGTdIU0R-1024.npz
Starting evaluation at step 518500 Counter(518500) 518437
eval_Episode has 500 steps and return 332.5.
train_Episode has 500 steps and return 263.3.
Starting evaluation at step 519000 Counter(519000) 518937
Saved chunk: 20230922T085258F763239-4KM8DWJKZNPLuMwWrmXSac-190MqkR7XwkZwnVwHQt8cW-1024.npz
eval_Episode has 500 steps and return 313.1.
train_Episode has 500 steps and return 282.9.
Saved chunk: 20230922T085312F438628-0YSQKMU0A7d3HLGGTdIU0R-2FiV2mvGHkwtJhwclzSYxL-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1038754 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 313.11 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 282.89 / episode/reward_rate 0.4 / train/action_mag 3.92 / train/action_max 3.74 / train/action_mean 0.03 / train/action_min -3.72 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 3.41 / train/adv_mag 0.27 / train/adv_max 0.2 / train/adv_mean 2.5e-4 / train/adv_min 
-0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
3.59 / train/dyn_loss_std 6.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.51 / train/extr_critic_max 230.51 / train/extr_critic_mean 220.47 / train/extr_critic_min 170.11 / train/extr_critic_std 11.6 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.83 / train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.23 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.7 / train/extr_return_raw_max 230.7 / train/extr_return_raw_mean 220.48 / train/extr_return_raw_min 
170.19 / train/extr_return_raw_std 11.64 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.9 / train/image_loss_std 0.88 / train/model_loss_mean 3.24 /
train/model_loss_std 4.43 / train/model_opt_grad_norm 8.3 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.72 / train/policy_entropy_max 
4.67 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.39 / train/policy_logprob_mag 10.45 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.45 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.91 / train/post_ent_max 51.91 / train/post_ent_mean 42.31 / 
train/post_ent_min 22.26 / train/post_ent_std 4.65 / train/prior_ent_mag 81.5 / train/prior_ent_max 81.5 / train/prior_ent_mean 45.87 / train/prior_ent_min 28.42 / train/prior_ent_std 6.19 / train/rep_loss_mean 3.59 / train/rep_loss_std 6.25 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.18 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.42 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.27 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.99 / report/dyn_loss_std 7.38 / report/image_loss_mean 1.08 / report/image_loss_std 1.25 / report/model_loss_mean 3.65 / report/model_loss_std 5.41 / report/post_ent_mag 53.56 / report/post_ent_max 53.56 /
report/post_ent_mean 41.83 / report/post_ent_min 20.05 / report/post_ent_std 4.76 / report/prior_ent_mag 81.34 / report/prior_ent_max 81.34 / report/prior_ent_mean 45.95 / report/prior_ent_min 27.58 / report/prior_ent_std 6.29 / report/rep_loss_mean 3.99 / 
report/rep_loss_std 7.38 / report/reward_avg 0.36 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.31 / report/reward_max_data 1.96 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 4.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.6 / report/reward_pred 0.37 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 8.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.77 / eval/dyn_loss_std 5.86 / eval/image_loss_mean 0.86 / eval/image_loss_std 0.93 / eval/model_loss_mean 3.37 / eval/model_loss_std 4.25 / eval/post_ent_mag 50.78 / eval/post_ent_max 50.78 / eval/post_ent_mean 
42.74 / eval/post_ent_min 25.72 / eval/post_ent_std 3.56 / eval/prior_ent_mag 81.34 / eval/prior_ent_max 81.34 / eval/prior_ent_mean 46.33 / eval/prior_ent_min 36.9 / eval/prior_ent_std 5.3 / eval/rep_loss_mean 3.77 / eval/rep_loss_std 5.86 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.62 / eval/reward_rate 0.43 / 
replay/size 5.2e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3804 / timer/env.step_total 19.73 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.87 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.8 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.2 / 
timer/dataset_train_count 1902 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.58 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.36

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 519500 Counter(519500) 519437
eval_Episode has 500 steps and return 314.9.
train_Episode has 500 steps and return 312.0.
Starting evaluation at step 520000 Counter(520000) 519937
Saved chunk: 20230922T085417F896020-190MqkR7XwkZwnVwHQt8cW-571vmVL1mkZNQRniDWGrgm-1024.npz
eval_Episode has 500 steps and return 307.3.
train_Episode has 500 steps and return 276.1.
Saved chunk: 20230922T085433F095944-2FiV2mvGHkwtJhwclzSYxL-7Mt8mhvyI0HYQZiILtbds6-1024.npz
Starting evaluation at step 520500 Counter(520500) 520437
eval_Episode has 500 steps and return 326.9.
train_Episode has 500 steps and return 315.5.
Starting evaluation at step 521000 Counter(521000) 520937
Saved chunk: 20230922T085538F496255-571vmVL1mkZNQRniDWGrgm-0LQvScPHi8ArnJ8ArpgSlv-1024.npz
eval_Episode has 500 steps and return 330.8.
train_Episode has 500 steps and return 280.9.
Saved chunk: 20230922T085555F398976-7Mt8mhvyI0HYQZiILtbds6-1CXijrYelzkIvrnRVx66WS-1024.npz
Starting evaluation at step 521500 Counter(521500) 521437
eval_Episode has 500 steps and return 326.7.
train_Episode has 500 steps and return 294.4.
Starting evaluation at step 522000 Counter(522000) 521937
Saved chunk: 20230922T085657F996996-0LQvScPHi8ArnJ8ArpgSlv-1kVgw9eVEjC3Cdt3wBiDBf-1024.npz
eval_Episode has 500 steps and return 327.1.
train_Episode has 500 steps and return 274.5.
Saved chunk: 20230922T085716F402671-1CXijrYelzkIvrnRVx66WS-2TtTuEz07PKWvVU6GlOGvh-1024.npz
Starting evaluation at step 522500 Counter(522500) 522437
eval_Episode has 500 steps and return 335.3.
train_Episode has 500 steps and return 295.1.
Starting evaluation at step 523000 Counter(523000) 522937
Saved chunk: 20230922T085817F187595-1kVgw9eVEjC3Cdt3wBiDBf-0juOWXYsmVuT1iSgCwF2EN-1024.npz
eval_Episode has 500 steps and return 328.5.
train_Episode has 500 steps and return 300.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1046258 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 328.51 / eval_episode/reward_rate 0.47 / episode/length 500 / episode/score 300.75 / episode/reward_rate 0.43 / train/action_mag 4.02 / train/action_max 3.84 / train/action_mean 0.03 / train/action_min -3.82 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 3.78 / train/adv_mag 0.27 / train/adv_max 0.22 / train/adv_mean 1.9e-4
/ train/adv_min -0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.6 / train/dyn_loss_std 6.3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.55 / train/extr_critic_max 230.55 / train/extr_critic_mean 219.32 / train/extr_critic_min 157.66 / train/extr_critic_std 15.38 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.71 / train/extr_return_raw_max 230.71 / train/extr_return_raw_mean 219.33 / 
train/extr_return_raw_min 158.88 / train/extr_return_raw_std 15.39 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.43 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.91 / train/image_loss_std 0.89 / 
train/model_loss_mean 3.26 / train/model_loss_std 4.48 / train/model_opt_grad_norm 8.33 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.91
/ train/policy_entropy_max 4.88 / train/policy_entropy_mean -1.91 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.49 / train/policy_logprob_mag 10.92 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.91 / train/policy_logprob_min -10.92 / 
train/policy_logprob_std 2.07 / train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 1.9e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.95 / train/post_ent_max 51.95 / 
train/post_ent_mean 42.29 / train/post_ent_min 22.06 / train/post_ent_std 4.79 / train/prior_ent_mag 81.4 / train/prior_ent_max 81.4 / train/prior_ent_mean 45.84 / train/prior_ent_min 28.31 / train/prior_ent_std 6.32 / train/rep_loss_mean 3.6 / train/rep_loss_std 6.3 / 
train/reward_avg 0.42 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.42 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.22 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 6.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.66 / report/dyn_loss_std 6.5 / report/image_loss_mean 0.88 / report/image_loss_std 0.84 / report/model_loss_mean 3.27 / report/model_loss_std 4.53 / report/post_ent_mag 51.46
/ report/post_ent_max 51.46 / report/post_ent_mean 42.33 / report/post_ent_min 20.93 / report/post_ent_std 4.61 / report/prior_ent_mag 81.29 / report/prior_ent_max 81.29 / report/prior_ent_mean 45.95 / report/prior_ent_min 28.3 / report/prior_ent_std 6.07 / 
report/rep_loss_mean 3.66 / report/rep_loss_std 6.5 / report/reward_avg 0.45 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.31 / report/reward_max_data 1.94 / report/reward_max_pred 1.9 / report/reward_neg_acc 1 / report/reward_neg_loss 7.4e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.45 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.87 / eval/dyn_loss_std 7.77 / eval/image_loss_mean 1.19 / eval/image_loss_std 1.54 / eval/model_loss_mean 4.36 / eval/model_loss_std 5.83 / eval/post_ent_mag 50.37 / eval/post_ent_max 50.37 / 
eval/post_ent_mean 42.07 / eval/post_ent_min 16.89 / eval/post_ent_std 4.41 / eval/prior_ent_mag 81.29 / eval/prior_ent_max 81.29 / eval/prior_ent_mean 46.49 / eval/prior_ent_min 30.16 / eval/prior_ent_std 5.78 / eval/rep_loss_mean 4.87 / eval/rep_loss_std 7.77 / 
eval/reward_avg 0.56 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.38 / eval/reward_max_data 1.98 / eval/reward_max_pred 1.93 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.61 / eval/reward_pred 0.55 / 
eval/reward_rate 0.4 / replay/size 5.2e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3752 / timer/env.step_total 19.45 / timer/env.step_frac 0.06 / 
timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.84 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 1.5e-3 / 
timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.68 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.2 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.4e-5 / timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1876 / 
timer/agent.train_total 241.5 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T085837F093696-2TtTuEz07PKWvVU6GlOGvh-1RtcbDtlMTCpbsyA13CiwG-1024.npz
Starting evaluation at step 523500 Counter(523500) 523437
eval_Episode has 500 steps and return 314.2.
train_Episode has 500 steps and return 283.4.
Starting evaluation at step 524000 Counter(524000) 523937
Saved chunk: 20230922T085936F349100-0juOWXYsmVuT1iSgCwF2EN-2LQTN0q9o4wXa5HCQpoVLU-1024.npz
eval_Episode has 500 steps and return 336.4.
train_Episode has 500 steps and return 302.3.
Saved chunk: 20230922T085959F015613-1RtcbDtlMTCpbsyA13CiwG-5T1XgFVqQJ9ldpmM9AvllY-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T090120F017065-5T1XgFVqQJ9ldpmM9AvllY-0000000000000000000000-112.npz
Saved chunk: 20230922T090056F891776-2LQTN0q9o4wXa5HCQpoVLU-0000000000000000000000-335.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 524500 Counter(524500) 524437
eval_Episode has 500 steps and return 331.8.
train_Episode has 500 steps and return 310.9.
Starting evaluation at step 525000 Counter(525000) 524937
Saved chunk: 20230922T090056F891776-2LQTN0q9o4wXa5HCQpoVLU-6x6XDEQbsh6y0bRv1CtrUi-1024.npz
eval_Episode has 500 steps and return 314.4.
train_Episode has 500 steps and return 307.4.
Saved chunk: 20230922T090120F017065-5T1XgFVqQJ9ldpmM9AvllY-31ZWCXrxx27XAPKKMAJ6bk-1024.npz
Starting evaluation at step 525500 Counter(525500) 525437
eval_Episode has 500 steps and return 317.9.
train_Episode has 500 steps and return 314.3.
Starting evaluation at step 526000 Counter(526000) 525937
Saved chunk: 20230922T090216F499679-6x6XDEQbsh6y0bRv1CtrUi-5WjvleEzRAFQ7yUYSGInB6-1024.npz
eval_Episode has 500 steps and return 309.4.
train_Episode has 500 steps and return 287.0.
Saved chunk: 20230922T090241F178914-31ZWCXrxx27XAPKKMAJ6bk-7414c569MUTJlO29f6zxgy-1024.npz
Starting evaluation at step 526500 Counter(526500) 526437
eval_Episode has 500 steps and return 318.6.
train_Episode has 500 steps and return 300.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1053870 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 318.55 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 300.07 / episode/reward_rate 0.44 / train/action_mag 3.99 / train/action_max 3.86 / train/action_mean 0.03 / train/action_min -3.74 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 3.5 / train/adv_mag 0.29 / train/adv_max 0.23 / train/adv_mean 2.4e-4 
/ train/adv_min -0.24 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.57 / train/dyn_loss_std 6.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.74 / train/extr_critic_max 230.74 / train/extr_critic_mean 219.42 / train/extr_critic_min 150.69 / train/extr_critic_std 16.8 / train/extr_return_normed_mag 1.54 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.33 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 230.95 / train/extr_return_raw_max 230.95 / train/extr_return_raw_mean 219.43 / train/extr_return_raw_min
150.34 / train/extr_return_raw_std 16.84 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.89 / train/image_loss_std 0.88 / train/model_loss_mean 3.22 
/ train/model_loss_std 4.37 / train/model_opt_grad_norm 8.34 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.83 / train/policy_entropy_max
4.78 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.46 / train/policy_logprob_mag 10.76 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.76 / train/policy_logprob_std 2.05 / 
train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.89 / train/post_ent_max 51.89 / train/post_ent_mean 42.27 / 
train/post_ent_min 22.03 / train/post_ent_std 4.8 / train/prior_ent_mag 81.4 / train/prior_ent_max 81.4 / train/prior_ent_mean 45.81 / train/prior_ent_min 27.96 / train/prior_ent_std 6.34 / train/rep_loss_mean 3.57 / train/rep_loss_std 6.14 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 
0.34 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.26 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 4.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.56 / report/dyn_loss_std 5.48 / report/image_loss_mean 0.84 / report/image_loss_std 0.76 / report/model_loss_mean 3.21 / report/model_loss_std 3.94 / report/post_ent_mag 51.45 / report/post_ent_max 51.45 /
report/post_ent_mean 43.47 / report/post_ent_min 26.5 / report/post_ent_std 3.47 / report/prior_ent_mag 80.95 / report/prior_ent_max 80.95 / report/prior_ent_mean 46.88 / report/prior_ent_min 35.21 / report/prior_ent_std 5.15 / report/rep_loss_mean 3.56 / 
report/rep_loss_std 5.48 / report/reward_avg 0.53 / report/reward_loss_mean 0.24 / report/reward_loss_std 0.33 / report/reward_max_data 1.94 / report/reward_max_pred 1.92 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.54 / report/reward_pred 0.53 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 7.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.65 / eval/dyn_loss_std 5.71 / eval/image_loss_mean 0.88 / eval/image_loss_std 1.09 / eval/model_loss_mean 3.32 / eval/model_loss_std 4.18 / eval/post_ent_mag 49.67 / eval/post_ent_max 49.67 / eval/post_ent_mean 
42.69 / eval/post_ent_min 23.71 / eval/post_ent_std 3.8 / eval/prior_ent_mag 80.95 / eval/prior_ent_max 80.95 / eval/prior_ent_mean 46.3 / eval/prior_ent_min 29.33 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 3.65 / eval/rep_loss_std 5.71 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.61 / eval/reward_rate 0.43 / 
replay/size 5.3e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3806 / timer/env.step_total 19.82 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 462.04 / timer/replay._sample_frac 1.54 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.65 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.6e-5 / timer/dataset_train_min 7.5e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.65 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 527000 Counter(527000) 526937
Saved chunk: 20230922T090335F597994-5WjvleEzRAFQ7yUYSGInB6-2L6qYXVTg8ttOzThpYKJcw-1024.npz
eval_Episode has 500 steps and return 323.5.
train_Episode has 500 steps and return 305.7.
Saved chunk: 20230922T090401F714167-7414c569MUTJlO29f6zxgy-5X1yToDQ6HzaNZP4HKLaxG-1024.npz
Starting evaluation at step 527500 Counter(527500) 527437
eval_Episode has 500 steps and return 288.5.
train_Episode has 500 steps and return 295.4.
Starting evaluation at step 528000 Counter(528000) 527937
Saved chunk: 20230922T090455F681209-2L6qYXVTg8ttOzThpYKJcw-4Bp6HubG00H0pCaoCCPxcS-1024.npz
eval_Episode has 500 steps and return 326.6.
train_Episode has 500 steps and return 303.7.
Saved chunk: 20230922T090523F608267-5X1yToDQ6HzaNZP4HKLaxG-1m7xf9sThTANkmrHTaim70-1024.npz
Starting evaluation at step 528500 Counter(528500) 528437
eval_Episode has 500 steps and return 318.0.
train_Episode has 500 steps and return 285.6.
Starting evaluation at step 529000 Counter(529000) 528937
Saved chunk: 20230922T090615F221029-4Bp6HubG00H0pCaoCCPxcS-5dPxLACy3EiXE4nuPTHQ8f-1024.npz
eval_Episode has 500 steps and return 326.5.
train_Episode has 500 steps and return 289.6.
Saved chunk: 20230922T090644F751844-1m7xf9sThTANkmrHTaim70-5ioHjwQ9dl77Ek0Pqm0Qum-1024.npz
Starting evaluation at step 529500 Counter(529500) 529437
eval_Episode has 500 steps and return 311.0.
train_Episode has 500 steps and return 290.0.
Starting evaluation at step 530000 Counter(530000) 529937
Saved chunk: 20230922T090734F608178-5dPxLACy3EiXE4nuPTHQ8f-0Gc8WH6AIy2LxlsW0WXHXL-1024.npz
eval_Episode has 500 steps and return 329.1.
train_Episode has 500 steps and return 276.7.
Saved chunk: 20230922T090805F618646-5ioHjwQ9dl77Ek0Pqm0Qum-3HzBx3zWXckTSfz0zIKIt0-1024.npz
Starting evaluation at step 530500 Counter(530500) 530437
eval_Episode has 500 steps and return 337.1.
train_Episode has 500 steps and return 293.8.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1061378 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 337.05 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 293.81 / episode/reward_rate 0.41 / train/action_mag 3.95 / train/action_max 3.8 / train/action_mean 0.03 / train/action_min -3.72 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss 3.43 / train/adv_mag 0.33 / train/adv_max 0.25 / train/adv_mean 2.7e-4 / train/adv_min 
-0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.59 / train/dyn_loss_std 6.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.6e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.85 / train/extr_critic_max 230.85 / train/extr_critic_mean 221.08 / train/extr_critic_min 172.34 / train/extr_critic_std 11.44 / train/extr_return_normed_mag 1.3 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.83 / train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.23 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.07 / train/extr_return_raw_max 231.07 / train/extr_return_raw_mean 221.09 / 
train/extr_return_raw_min 172.82 / train/extr_return_raw_std 11.47 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.9 / train/image_loss_std 0.89 / 
train/model_loss_mean 3.24 / train/model_loss_std 4.41 / train/model_opt_grad_norm 8.51 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.47
/ train/policy_entropy_max 4.39 / train/policy_entropy_mean -2.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.32 / train/policy_logprob_mag 10.38 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.06 / train/policy_logprob_min -10.38 / 
train/policy_logprob_std 1.95 / train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.9e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.05 / train/post_ent_max 52.05 / 
train/post_ent_mean 42.41 / train/post_ent_min 22.57 / train/post_ent_std 4.6 / train/prior_ent_mag 81.34 / train/prior_ent_max 81.34 / train/prior_ent_mean 45.96 / train/prior_ent_min 28.79 / train/prior_ent_std 6.13 / train/rep_loss_mean 3.59 / train/rep_loss_std 6.19
/ train/reward_avg 0.42 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.42 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.29 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 5.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.62 / report/dyn_loss_std 6.11 / report/image_loss_mean 0.94 / report/image_loss_std 0.83 / report/model_loss_mean 3.32 / report/model_loss_std 4.35 / report/post_ent_mag 
52.28 / report/post_ent_max 52.28 / report/post_ent_mean 42.92 / report/post_ent_min 24.45 / report/post_ent_std 3.93 / report/prior_ent_mag 81.39 / report/prior_ent_max 81.39 / report/prior_ent_mean 46.54 / report/prior_ent_min 34.6 / report/prior_ent_std 5.52 / 
report/rep_loss_mean 3.62 / report/rep_loss_std 6.11 / report/reward_avg 0.43 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.35 / report/reward_max_data 1.99 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / 
report/reward_pos_acc 0.99 / report/reward_pos_loss 0.59 / report/reward_pred 0.43 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.44 / eval/dyn_loss_std 7.22 / eval/image_loss_mean 1.2 / eval/image_loss_std 1.79 / eval/model_loss_mean 4.11 / eval/model_loss_std 5.73 / eval/post_ent_mag 50.54 / eval/post_ent_max
50.54 / eval/post_ent_mean 42.01 / eval/post_ent_min 21.17 / eval/post_ent_std 4.64 / eval/prior_ent_mag 81.39 / eval/prior_ent_max 81.39 / eval/prior_ent_mean 45.97 / eval/prior_ent_min 27.72 / eval/prior_ent_std 5.89 / eval/rep_loss_mean 4.44 / eval/rep_loss_std 7.22 
/ eval/reward_avg 0.6 / eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.37 / eval/reward_max_data 1.94 / eval/reward_max_pred 1.94 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.6 / 
eval/reward_rate 0.42 / replay/size 5.3e5 / replay/inserts 3754 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3754 / timer/env.step_total 19.69 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.93 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 3.3e-3 / 
timer/replay._sample_max 0.23 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7762 / timer/agent.policy_total 17.61 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.01 / timer/dataset_train_count 1877 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.5e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1877 / 
timer/agent.train_total 241.36 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.02

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 531000 Counter(531000) 530937
Saved chunk: 20230922T090853F790609-0Gc8WH6AIy2LxlsW0WXHXL-5sXx1fe3fnH3ZRoBhFJsVb-1024.npz
eval_Episode has 500 steps and return 329.5.
train_Episode has 500 steps and return 289.9.
Saved chunk: 20230922T090926F254959-3HzBx3zWXckTSfz0zIKIt0-5nEUBjeHAOSCem1zyyBUDb-1024.npz
Starting evaluation at step 531500 Counter(531500) 531437
eval_Episode has 500 steps and return 318.4.
train_Episode has 500 steps and return 286.5.
Starting evaluation at step 532000 Counter(532000) 531937
Saved chunk: 20230922T091014F077730-5sXx1fe3fnH3ZRoBhFJsVb-5RE6XXLEAocb808G0GXEzj-1024.npz
eval_Episode has 500 steps and return 313.2.
train_Episode has 500 steps and return 284.8.
Saved chunk: 20230922T091048F322679-5nEUBjeHAOSCem1zyyBUDb-3DzjvxZHKynppLVqhK7bCx-1024.npz
Starting evaluation at step 532500 Counter(532500) 532437
eval_Episode has 500 steps and return 313.0.
train_Episode has 500 steps and return 295.3.
Starting evaluation at step 533000 Counter(533000) 532937
Saved chunk: 20230922T091133F514208-5RE6XXLEAocb808G0GXEzj-6UOmYRVyA7lvu35F8E8Lsp-1024.npz
eval_Episode has 500 steps and return 303.5.
train_Episode has 500 steps and return 290.9.
Starting evaluation at step 533500 Counter(533500) 533437
eval_Episode has 500 steps and return 321.8.
Saved chunk: 20230922T091209F213531-3DzjvxZHKynppLVqhK7bCx-1MPu95FTGiJcvi3DcN1z0W-1024.npz
train_Episode has 500 steps and return 295.8.
Starting evaluation at step 534000 Counter(534000) 533937
eval_Episode has 500 steps and return 326.1.
Saved chunk: 20230922T091252F688015-6UOmYRVyA7lvu35F8E8Lsp-74Drx7spNEACLglo65HTaB-1024.npz
train_Episode has 500 steps and return 287.9.
Starting evaluation at step 534500 Counter(534500) 534437
eval_Episode has 500 steps and return 321.9.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1069002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 321.91 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 287.86 / episode/reward_rate 0.41 / train/action_mag 3.95 / train/action_max 3.81 / train/action_mean 0.03 / train/action_min -3.74 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 4.26 / train/adv_mag 0.38 / train/adv_max 0.31 / train/adv_mean 1.7e-4
/ train/adv_min -0.26 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.7e-11 / train/cont_loss_std 7.7e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.61 / train/dyn_loss_std 6.3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.94 / train/extr_critic_max 230.94 / train/extr_critic_mean 220.65 / train/extr_critic_min 164.51 / train/extr_critic_std 12.84 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.26 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.15 / train/extr_return_raw_max 231.15 / train/extr_return_raw_mean 220.66 / 
train/extr_return_raw_min 166.2 / train/extr_return_raw_std 12.85 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.91 / train/image_loss_std 0.91 / 
train/model_loss_mean 3.26 / train/model_loss_std 4.48 / train/model_opt_grad_norm 8.52 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.59
/ train/policy_entropy_max 4.55 / train/policy_entropy_mean -2 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.38 / train/policy_logprob_mag 10.42 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2 / train/policy_logprob_min -10.42 / 
train/policy_logprob_std 1.99 / train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.89 / train/post_ent_max 51.89 / 
train/post_ent_mean 42.29 / train/post_ent_min 21.83 / train/post_ent_std 4.73 / train/prior_ent_mag 81.34 / train/prior_ent_max 81.34 / train/prior_ent_mean 45.85 / train/prior_ent_min 27.91 / train/prior_ent_std 6.27 / train/rep_loss_mean 3.61 / train/rep_loss_std 6.3
/ train/reward_avg 0.42 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 
0.42 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.25 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 6.14 / report/image_loss_mean 0.93 / report/image_loss_std 0.85 / report/model_loss_mean 3.22 / report/model_loss_std 4.3 / report/post_ent_mag 52.32
/ report/post_ent_max 52.32 / report/post_ent_mean 42.16 / report/post_ent_min 20.16 / report/post_ent_std 4.77 / report/prior_ent_mag 81.35 / report/prior_ent_max 81.35 / report/prior_ent_mean 45.62 / report/prior_ent_min 28.31 / report/prior_ent_std 5.97 / 
report/rep_loss_mean 3.51 / report/rep_loss_std 6.14 / report/reward_avg 0.41 / report/reward_loss_mean 0.18 / report/reward_loss_std 0.31 / report/reward_max_data 1.93 / report/reward_max_pred 1.93 / report/reward_neg_acc 1 / report/reward_neg_loss 9.3e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.55 / report/reward_pred 0.41 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.04 / eval/dyn_loss_std 8.12 / eval/image_loss_mean 0.99 / eval/image_loss_std 1.8 / eval/model_loss_mean 3.65 / eval/model_loss_std 6.42 / eval/post_ent_mag 51.75 / eval/post_ent_max
51.75 / eval/post_ent_mean 41.33 / eval/post_ent_min 17.88 / eval/post_ent_std 6.19 / eval/prior_ent_mag 81.35 / eval/prior_ent_max 81.35 / eval/prior_ent_mean 44.89 / eval/prior_ent_min 24.79 / eval/prior_ent_std 7.45 / eval/rep_loss_mean 4.04 / eval/rep_loss_std 8.12 
/ eval/reward_avg 0.58 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.92 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.58 / 
eval/reward_rate 0.4 / replay/size 5.3e5 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.51 / timer/env.step_count 3812 / timer/env.step_total 19.75 / timer/env.step_frac 0.07
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.6 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-3 / 
timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7820 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1906 / 
timer/agent.train_total 244.9 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.12

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T091333F317341-1MPu95FTGiJcvi3DcN1z0W-2hAjCKpICQD8VyF3oB3NR8-1024.npz
train_Episode has 500 steps and return 293.4.
Starting evaluation at step 535000 Counter(535000) 534937
Saved chunk: 20230922T091411F505257-74Drx7spNEACLglo65HTaB-15lJkMVxYlW6SF7rvgxREe-1024.npz
eval_Episode has 500 steps and return 314.9.
train_Episode has 500 steps and return 305.3.
Starting evaluation at step 535500 Counter(535500) 535437
eval_Episode has 500 steps and return 321.2.
Saved chunk: 20230922T091454F806691-2hAjCKpICQD8VyF3oB3NR8-0woZCIYTUCcGSbEdngJiyz-1024.npz
train_Episode has 500 steps and return 291.8.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T091615F873731-0woZCIYTUCcGSbEdngJiyz-0000000000000000000000-248.npz
Saved chunk: 20230922T091531F769006-15lJkMVxYlW6SF7rvgxREe-0000000000000000000000-594.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 536000 Counter(536000) 535937
Saved chunk: 20230922T091531F769006-15lJkMVxYlW6SF7rvgxREe-2N60V76gpRWOGBJeInJ7Ys-1024.npz
eval_Episode has 500 steps and return 331.6.
train_Episode has 500 steps and return 286.7.
Starting evaluation at step 536500 Counter(536500) 536437
eval_Episode has 500 steps and return 338.4.
train_Episode has 500 steps and return 305.4.
Saved chunk: 20230922T091615F873731-0woZCIYTUCcGSbEdngJiyz-78dI3EHHLMTX8tMiV14ekJ-1024.npz
Starting evaluation at step 537000 Counter(537000) 536937
eval_Episode has 500 steps and return 319.7.
Saved chunk: 20230922T091651F401293-2N60V76gpRWOGBJeInJ7Ys-78UVmwpOHj3aC60m5OhYTZ-1024.npz
train_Episode has 500 steps and return 308.3.
Starting evaluation at step 537500 Counter(537500) 537437
eval_Episode has 500 steps and return 314.2.
train_Episode has 500 steps and return 319.2.
Saved chunk: 20230922T091736F916170-78dI3EHHLMTX8tMiV14ekJ-586yuq6NjTD3cAx2WD6crv-1024.npz
Starting evaluation at step 538000 Counter(538000) 537937
eval_Episode has 500 steps and return 308.8.
Saved chunk: 20230922T091810F497109-78UVmwpOHj3aC60m5OhYTZ-3bW2Eac4GhJdQGrFOlLBC2-1024.npz
train_Episode has 500 steps and return 303.6.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1076618 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 303.6 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 308.78 / eval_episode/reward_rate 0.44 / train/action_mag 3.98 / train/action_max 3.84 / train/action_mean 0.04 / train/action_min -3.74 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 3 / train/adv_mag 0.36 / train/adv_max 0.3 / train/adv_mean 2.8e-4 / train/adv_min 
-0.29 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
3.54 / train/dyn_loss_std 6.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 230.97 / train/extr_critic_max 230.97 / train/extr_critic_mean 219.94 / train/extr_critic_min 154.62 / train/extr_critic_std 15.62 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.3 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.17 / train/extr_return_raw_max 231.17 / train/extr_return_raw_mean 219.95 / train/extr_return_raw_min
154.78 / train/extr_return_raw_std 15.64 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.88 / train/image_loss_std 0.88 / train/model_loss_mean 3.19 
/ train/model_loss_std 4.36 / train/model_opt_grad_norm 8.35 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.67 / train/policy_entropy_max
4.61 / train/policy_entropy_mean -1.95 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.46 / train/policy_logprob_mag 10.87 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.94 / train/policy_logprob_min -10.87 / train/policy_logprob_std 2.05 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.86 / train/post_ent_max 51.86 / train/post_ent_mean 42.35 / 
train/post_ent_min 22.36 / train/post_ent_std 4.71 / train/prior_ent_mag 81.21 / train/prior_ent_max 81.21 / train/prior_ent_mean 45.85 / train/prior_ent_min 28.17 / train/prior_ent_std 6.23 / train/rep_loss_mean 3.54 / train/rep_loss_std 6.13 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 
0.33 / train_stats/mean_log_entropy -2.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.4e-11 / report/cont_loss_std 6.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.72 / report/dyn_loss_std 6.81 / report/image_loss_mean 1.01 / report/image_loss_std 1.07 / report/model_loss_mean 3.43 / report/model_loss_std 4.88 / report/post_ent_mag 53.23 / report/post_ent_max 53.23 /
report/post_ent_mean 40.81 / report/post_ent_min 21.95 / report/post_ent_std 6.77 / report/prior_ent_mag 81.1 / report/prior_ent_max 81.1 / report/prior_ent_mean 44.51 / report/prior_ent_min 23.42 / report/prior_ent_std 8.09 / report/rep_loss_mean 3.72 / 
report/rep_loss_std 6.81 / report/reward_avg 0.41 / report/reward_loss_mean 0.19 / report/reward_loss_std 0.3 / report/reward_max_data 1.85 / report/reward_max_pred 1.85 / report/reward_neg_acc 1 / report/reward_neg_loss 9.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.56 / report/reward_pred 0.41 / report/reward_rate 0.33 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 6.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.59 / eval/dyn_loss_std 6.37 / eval/image_loss_mean 0.91 / eval/image_loss_std 1.68 / eval/model_loss_mean 3.31 / eval/model_loss_std 5.11 / eval/post_ent_mag 50.85 / eval/post_ent_max 50.85 / eval/post_ent_mean 
41.72 / eval/post_ent_min 21.85 / eval/post_ent_std 5.62 / eval/prior_ent_mag 81.1 / eval/prior_ent_max 81.1 / eval/prior_ent_mean 45.05 / eval/prior_ent_min 24.87 / eval/prior_ent_std 7.14 / eval/rep_loss_mean 3.59 / eval/rep_loss_std 6.37 / eval/reward_avg 0.59 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.89 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / eval/reward_pred 0.59 / eval/reward_rate 0.41 / 
replay/size 5.4e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.97 / timer/env.step_count 3808 / timer/env.step_total 19.93 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 454.76 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.23 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7315 / timer/agent.policy_total 16.45 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.68 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / 
timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 538500 Counter(538500) 538437
eval_Episode has 500 steps and return 308.2.
train_Episode has 500 steps and return 285.1.
Saved chunk: 20230922T091857F424391-586yuq6NjTD3cAx2WD6crv-2VZTcBW9lGnonxYOx273cT-1024.npz
Starting evaluation at step 539000 Counter(539000) 538937
eval_Episode has 500 steps and return 326.6.
Saved chunk: 20230922T091929F378054-3bW2Eac4GhJdQGrFOlLBC2-1GLriTDcbrxZlLfCZiGivr-1024.npz
train_Episode has 500 steps and return 275.5.
Starting evaluation at step 539500 Counter(539500) 539437
eval_Episode has 500 steps and return 332.9.
train_Episode has 500 steps and return 302.5.
Saved chunk: 20230922T092019F199559-2VZTcBW9lGnonxYOx273cT-2YEwYWmfantLAu2McXVEcP-1024.npz
Starting evaluation at step 540000 Counter(540000) 539937
eval_Episode has 500 steps and return 326.5.
train_Episode has 500 steps and return 293.1.
Starting evaluation at step 540500 Counter(540500) 540437
Saved chunk: 20230922T092049F835184-1GLriTDcbrxZlLfCZiGivr-3EwCFGlt2q02wTyedtgeEh-1024.npz
eval_Episode has 500 steps and return 332.0.
train_Episode has 500 steps and return 280.4.
Saved chunk: 20230922T092140F135584-2YEwYWmfantLAu2McXVEcP-3uF5qWcDiyjDFzk1S8NWfg-1024.npz
Starting evaluation at step 541000 Counter(541000) 540937
eval_Episode has 500 steps and return 329.7.
train_Episode has 500 steps and return 292.2.
Starting evaluation at step 541500 Counter(541500) 541437
Saved chunk: 20230922T092245F065281-3EwCFGlt2q02wTyedtgeEh-2sqZ2BCfQlNntDNJ2jtyQj-1024.npz
eval_Episode has 500 steps and return 337.8.
train_Episode has 500 steps and return 279.3.
Saved chunk: 20230922T092300F861500-3uF5qWcDiyjDFzk1S8NWfg-2JsPPNtBmfckMaT7w8IuKH-1024.npz
Starting evaluation at step 542000 Counter(542000) 541937
eval_Episode has 500 steps and return 305.7.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1084146 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 305.65 / eval_episode/reward_rate 0.44 / episode/length 500 / episode/score 279.29 / episode/reward_rate 0.42 / train/action_mag 3.98 / train/action_max 3.87 / train/action_mean 0.03 / train/action_min -3.71 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 4.65 / train/adv_mag 0.27 / train/adv_max 0.21 / train/adv_mean 1.2e-4
/ train/adv_min -0.23 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.53 / train/dyn_loss_std 6.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.09 / train/extr_critic_max 231.09 / train/extr_critic_mean 220.55 / train/extr_critic_min 159.86 / train/extr_critic_std 14.11 / train/extr_return_normed_mag 1.41 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.27 / train/extr_return_raw_max 231.27 / train/extr_return_raw_mean 220.56 / 
train/extr_return_raw_min 159.83 / train/extr_return_raw_std 14.15 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.87 / train/image_loss_std 0.88 / 
train/model_loss_mean 3.18 / train/model_loss_std 4.37 / train/model_opt_grad_norm 8.08 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.73
/ train/policy_entropy_max 4.65 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.43 / train/policy_logprob_mag 10.65 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.65 / 
train/policy_logprob_std 2.03 / train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.75 / train/post_ent_max 51.75 / 
train/post_ent_mean 42.28 / train/post_ent_min 22.38 / train/post_ent_std 4.67 / train/prior_ent_mag 81.07 / train/prior_ent_max 81.07 / train/prior_ent_mean 45.77 / train/prior_ent_min 28.39 / train/prior_ent_std 6.24 / train/rep_loss_mean 3.53 / train/rep_loss_std 
6.15 / train/reward_avg 0.43 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.43 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.24 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.7 / report/dyn_loss_std 6.62 / report/image_loss_mean 0.87 / report/image_loss_std 0.97 / report/model_loss_mean 3.29 / report/model_loss_std 4.78 / 
report/post_ent_mag 51.11 / report/post_ent_max 51.11 / report/post_ent_mean 42.21 / report/post_ent_min 17.92 / report/post_ent_std 5.39 / report/prior_ent_mag 80.59 / report/prior_ent_max 80.59 / report/prior_ent_mean 45.8 / report/prior_ent_min 20 / 
report/prior_ent_std 6.88 / report/rep_loss_mean 3.7 / report/rep_loss_std 6.62 / report/reward_avg 0.49 / report/reward_loss_mean 0.2 / report/reward_loss_std 0.29 / report/reward_max_data 1.89 / report/reward_max_pred 1.88 / report/reward_neg_acc 1 / 
report/reward_neg_loss 1e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.54 / report/reward_pred 0.49 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.38 / eval/dyn_loss_std 5.5 / eval/image_loss_mean 0.74 / eval/image_loss_std 0.89 / eval/model_loss_mean 3.03 / eval/model_loss_std 4.12 / eval/post_ent_mag 
50.39 / eval/post_ent_max 50.39 / eval/post_ent_mean 43.07 / eval/post_ent_min 29.92 / eval/post_ent_std 3.2 / eval/prior_ent_mag 80.59 / eval/prior_ent_max 80.59 / eval/prior_ent_mean 46.41 / eval/prior_ent_min 38.26 / eval/prior_ent_std 4.99 / eval/rep_loss_mean 3.38 
/ eval/rep_loss_std 5.5 / eval/reward_avg 0.65 / eval/reward_loss_mean 0.27 / eval/reward_loss_std 0.37 / eval/reward_max_data 2 / eval/reward_max_pred 1.99 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / 
eval/reward_pred 0.64 / eval/reward_rate 0.46 / replay/size 5.4e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3764 / timer/env.step_total 19.51
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 455.22 / timer/replay._sample_frac 1.52 / timer/replay._sample_avg 0.02 / 
timer/replay._sample_min 6.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7772 / timer/agent.policy_total 17.59 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 
2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.21 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 5.6e-4 / 
timer/agent.train_count 1882 / timer/agent.train_total 241.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 
4.4e-4 / timer/agent.report_avg 0.07 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / 
timer/dataset_eval_max 3.9e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 303.8.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 542500 Counter(542500) 542437
Saved chunk: 20230922T092404F069634-2sqZ2BCfQlNntDNJ2jtyQj-62gVhuostPsVmDCaz4KsWG-1024.npz
eval_Episode has 500 steps and return 331.9.
train_Episode has 500 steps and return 307.2.
Saved chunk: 20230922T092421F354298-2JsPPNtBmfckMaT7w8IuKH-1TXyHgg6eyjzgh1G47pfkq-1024.npz
Starting evaluation at step 543000 Counter(543000) 542937
eval_Episode has 500 steps and return 324.5.
train_Episode has 500 steps and return 298.6.
Starting evaluation at step 543500 Counter(543500) 543437
Saved chunk: 20230922T092524F254811-62gVhuostPsVmDCaz4KsWG-0gX1QuUytJRcASgCCuKABg-1024.npz
eval_Episode has 500 steps and return 304.9.
train_Episode has 500 steps and return 279.5.
Saved chunk: 20230922T092543F321678-1TXyHgg6eyjzgh1G47pfkq-6COr8G1E0Iz8KOhyzboXIP-1024.npz
Starting evaluation at step 544000 Counter(544000) 543937
eval_Episode has 500 steps and return 315.6.
train_Episode has 500 steps and return 309.5.
Starting evaluation at step 544500 Counter(544500) 544437
Saved chunk: 20230922T092643F685926-0gX1QuUytJRcASgCCuKABg-16AnvApjm8TQZHJgcgdc9P-1024.npz
eval_Episode has 500 steps and return 327.8.
train_Episode has 500 steps and return 304.7.
Saved chunk: 20230922T092704F170051-6COr8G1E0Iz8KOhyzboXIP-4Sbd8TDAU4EENGSCupXwVh-1024.npz
Starting evaluation at step 545000 Counter(545000) 544937
eval_Episode has 500 steps and return 326.8.
train_Episode has 500 steps and return 291.0.
Starting evaluation at step 545500 Counter(545500) 545437
Saved chunk: 20230922T092802F733178-16AnvApjm8TQZHJgcgdc9P-5XZxXdS4RUsBSnik90w0Ai-1024.npz
eval_Episode has 500 steps and return 320.3.
train_Episode has 500 steps and return 309.6.
Saved chunk: 20230922T092824F732723-4Sbd8TDAU4EENGSCupXwVh-0xd1yuYhaXwuA748JC74WD-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1091774 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 309.58 / episode/reward_rate 0.43 / eval_episode/length 500 / eval_episode/score 320.34 / eval_episode/reward_rate 0.45 / train/action_mag 3.95 / train/action_max 3.84 / train/action_mean 0.03 / train/action_min -3.67 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 4.06 / train/adv_mag 0.37 / train/adv_max 0.32 / train/adv_mean 1.8e-4
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 8.4e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.57 / train/dyn_loss_std 6.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.12 / train/extr_critic_max 231.12 / train/extr_critic_mean 220.66 / train/extr_critic_min 163.95 / train/extr_critic_std 13.24 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.31 / train/extr_return_raw_max 231.31 / train/extr_return_raw_mean 220.67 / 
train/extr_return_raw_min 164.49 / train/extr_return_raw_std 13.27 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.89 / train/image_loss_std 0.89 / 
train/model_loss_mean 3.22 / train/model_loss_std 4.43 / train/model_opt_grad_norm 8.28 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.8 
/ train/policy_entropy_max 4.75 / train/policy_entropy_mean -1.98 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.44 / train/policy_logprob_mag 10.79 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.98 / train/policy_logprob_min -10.79 / 
train/policy_logprob_std 2.03 / train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.16 / train/post_ent_mag 51.94 / train/post_ent_max 51.94 / 
train/post_ent_mean 42.37 / train/post_ent_min 22.4 / train/post_ent_std 4.62 / train/prior_ent_mag 81.04 / train/prior_ent_max 81.04 / train/prior_ent_mean 45.9 / train/prior_ent_min 28.68 / train/prior_ent_std 6.15 / train/rep_loss_mean 3.57 / train/rep_loss_std 6.22 
/ train/reward_avg 0.43 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred
0.43 / train/reward_rate 0.33 / train_stats/mean_log_entropy -2.25 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.49 / report/dyn_loss_std 6.34 / report/image_loss_mean 0.9 / report/image_loss_std 0.83 / report/model_loss_mean 3.16 / report/model_loss_std 4.4 / report/post_ent_mag 53.72 
/ report/post_ent_max 53.72 / report/post_ent_mean 41.91 / report/post_ent_min 20.76 / report/post_ent_std 4.72 / report/prior_ent_mag 81 / report/prior_ent_max 81 / report/prior_ent_mean 45.34 / report/prior_ent_min 28.58 / report/prior_ent_std 6.21 / 
report/rep_loss_mean 3.49 / report/rep_loss_std 6.34 / report/reward_avg 0.37 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 2 / report/reward_max_pred 1.96 / report/reward_neg_acc 1 / report/reward_neg_loss 6.6e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 0.37 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.8 / eval/dyn_loss_std 6.23 / eval/image_loss_mean 0.91 / eval/image_loss_std 1.21 / eval/model_loss_mean 3.43 / eval/model_loss_std 4.54 / eval/post_ent_mag 50.34 / eval/post_ent_max
50.34 / eval/post_ent_mean 42.55 / eval/post_ent_min 24.61 / eval/post_ent_std 3.8 / eval/prior_ent_mag 81 / eval/prior_ent_max 81 / eval/prior_ent_mean 46.32 / eval/prior_ent_min 34.82 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 3.8 / eval/rep_loss_std 6.23 / 
eval/reward_avg 0.59 / eval/reward_loss_mean 0.24 / eval/reward_loss_std 0.31 / eval/reward_max_data 1.92 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.56 / eval/reward_pred 0.58 / 
eval/reward_rate 0.42 / replay/size 5.5e5 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3814 / timer/env.step_total 19.78 / timer/env.step_frac 0.07 
/ timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 448.43 / timer/replay._sample_frac 1.49 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / 
timer/replay._sample_max 0.24 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7321 / timer/agent.policy_total 16.47 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1907 / 
timer/agent.train_total 244.96 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.34 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 546000 Counter(546000) 545937
eval_Episode has 500 steps and return 324.9.
train_Episode has 500 steps and return 302.3.
Starting evaluation at step 546500 Counter(546500) 546437
Saved chunk: 20230922T092921F583592-5XZxXdS4RUsBSnik90w0Ai-3R5BSSUjYeNz8aCN6oPfNE-1024.npz
eval_Episode has 500 steps and return 312.7.
train_Episode has 500 steps and return 295.1.
Saved chunk: 20230922T092945F198439-0xd1yuYhaXwuA748JC74WD-7p0I1c4RwF40oJ2CurRQgG-1024.npz
Starting evaluation at step 547000 Counter(547000) 546937
eval_Episode has 500 steps and return 310.6.
train_Episode has 500 steps and return 288.2.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T093042F123340-3R5BSSUjYeNz8aCN6oPfNE-0000000000000000000000-853.npz
Saved chunk: 20230922T093107F492973-7p0I1c4RwF40oJ2CurRQgG-0000000000000000000000-384.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 547500 Counter(547500) 547437
Saved chunk: 20230922T093042F123340-3R5BSSUjYeNz8aCN6oPfNE-7h42jUNzdArEpmcdyXMvte-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 299.5.
Saved chunk: 20230922T093107F492973-7p0I1c4RwF40oJ2CurRQgG-38DoFEbtfhgh6hMC5dhNOa-1024.npz
Starting evaluation at step 548000 Counter(548000) 547937
eval_Episode has 500 steps and return 306.0.
train_Episode has 500 steps and return 306.5.
Starting evaluation at step 548500 Counter(548500) 548437
Saved chunk: 20230922T093201F785744-7h42jUNzdArEpmcdyXMvte-1my4HlY6ysnIUnQih71khZ-1024.npz
eval_Episode has 500 steps and return 321.7.
train_Episode has 500 steps and return 289.3.
Saved chunk: 20230922T093228F650582-38DoFEbtfhgh6hMC5dhNOa-7MI351S8tlYlGF4L716kKU-1024.npz
Starting evaluation at step 549000 Counter(549000) 548937
eval_Episode has 500 steps and return 315.7.
train_Episode has 500 steps and return 315.6.
Starting evaluation at step 549500 Counter(549500) 549437
Saved chunk: 20230922T093321F004870-1my4HlY6ysnIUnQih71khZ-6ceu2yraF6fO2zeReGs1f5-1024.npz
eval_Episode has 500 steps and return 302.9.
train_Episode has 500 steps and return 303.3.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1099278 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 302.87 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 303.3 / episode/reward_rate 0.44 / train/action_mag 3.93 / train/action_max 3.77 / train/action_mean 0.03 / train/action_min -3.69 / train/action_std
0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 3.98 / train/adv_mag 0.53 / train/adv_max 0.46 / train/adv_mean 1.9e-4 / train/adv_min 
-0.34 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.59 / train/dyn_loss_std 6.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.16 / train/extr_critic_max 231.16 / train/extr_critic_mean 220.51 / train/extr_critic_min 154.48 / train/extr_critic_std 13.66 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.33 / train/extr_return_raw_max 231.33 / train/extr_return_raw_mean 220.52 / train/extr_return_raw_min
159.54 / train/extr_return_raw_std 13.7 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.65 / train/image_loss_mean 0.9 / train/image_loss_std 0.9 / train/model_loss_mean 3.24 / 
train/model_loss_std 4.44 / train/model_opt_grad_norm 8.43 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.72 / train/policy_entropy_max 
4.66 / train/policy_entropy_mean -1.97 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.42 / train/policy_logprob_mag 10.62 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 1.96 / train/policy_logprob_min -10.62 / train/policy_logprob_std 2.02 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.88 / train/post_ent_max 51.88 / train/post_ent_mean 42.35 / 
train/post_ent_min 22.34 / train/post_ent_std 4.63 / train/prior_ent_mag 81.11 / train/prior_ent_max 81.11 / train/prior_ent_mean 45.9 / train/prior_ent_min 28.68 / train/prior_ent_std 6.16 / train/rep_loss_mean 3.59 / train/rep_loss_std 6.23 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.23 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.94 / report/dyn_loss_std 6.92 / report/image_loss_mean 0.96 / report/image_loss_std 0.97 / report/model_loss_mean 3.49 / report/model_loss_std 4.96 / report/post_ent_mag 51.32 / report/post_ent_max 51.32 /
report/post_ent_mean 41.48 / report/post_ent_min 21.11 / report/post_ent_std 4.9 / report/prior_ent_mag 81.02 / report/prior_ent_max 81.02 / report/prior_ent_mean 45.35 / report/prior_ent_min 27.97 / report/prior_ent_std 6.53 / report/rep_loss_mean 3.94 / 
report/rep_loss_std 6.92 / report/reward_avg 0.38 / report/reward_loss_mean 0.16 / report/reward_loss_std 0.28 / report/reward_max_data 1.92 / report/reward_max_pred 1.91 / report/reward_neg_acc 1 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.38 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.5 / eval/dyn_loss_std 6.08 / eval/image_loss_mean 0.78 / eval/image_loss_std 0.98 / eval/model_loss_mean 3.16 / eval/model_loss_std 4.38 / eval/post_ent_mag 51.35 / eval/post_ent_max 51.35 / eval/post_ent_mean 
42.77 / eval/post_ent_min 19.47 / eval/post_ent_std 3.75 / eval/prior_ent_mag 81.02 / eval/prior_ent_max 81.02 / eval/prior_ent_mean 46.16 / eval/prior_ent_min 25.17 / eval/prior_ent_std 5.3 / eval/rep_loss_mean 3.5 / eval/rep_loss_std 6.08 / eval/reward_avg 0.66 / 
eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.98 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.57 / eval/reward_pred 0.66 / eval/reward_rate 0.48 / 
replay/size 5.5e5 / replay/inserts 3752 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3752 / timer/env.step_total 19.68 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.2 / timer/replay._sample_count 3e4 / timer/replay._sample_total 451.27 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.8e-3 / timer/replay._sample_max 0.05 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7760 / timer/agent.policy_total 17.52 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1876 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 6.1e-4 / timer/agent.train_count 1876 / timer/agent.train_total 241.49 / timer/agent.train_frac 0.8 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 
0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T093349F289446-7MI351S8tlYlGF4L716kKU-44yOW4ZFxYDSKDNwJTMyuj-1024.npz
Starting evaluation at step 550000 Counter(550000) 549937
eval_Episode has 500 steps and return 337.8.
train_Episode has 500 steps and return 293.7.
Starting evaluation at step 550500 Counter(550500) 550437
Saved chunk: 20230922T093440F042621-6ceu2yraF6fO2zeReGs1f5-38VMUeYqCSKGdIhHKpmrjf-1024.npz
eval_Episode has 500 steps and return 327.0.
train_Episode has 500 steps and return 305.4.
Saved chunk: 20230922T093511F266484-44yOW4ZFxYDSKDNwJTMyuj-55TY100NFlkEidGMaQBfsd-1024.npz
Starting evaluation at step 551000 Counter(551000) 550937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 298.6.
Starting evaluation at step 551500 Counter(551500) 551437
Saved chunk: 20230922T093600F779892-38VMUeYqCSKGdIhHKpmrjf-6fSSoM5TWaPO4qv95Oqcl1-1024.npz
eval_Episode has 500 steps and return 324.0.
train_Episode has 500 steps and return 297.8.
Saved chunk: 20230922T093632F358730-55TY100NFlkEidGMaQBfsd-2wpXiFs2JHMUWbgpuSbg0v-1024.npz
Starting evaluation at step 552000 Counter(552000) 551937
eval_Episode has 500 steps and return 316.0.
train_Episode has 500 steps and return 296.1.
Starting evaluation at step 552500 Counter(552500) 552437
Saved chunk: 20230922T093720F169801-6fSSoM5TWaPO4qv95Oqcl1-3bF3Bv1eIaAMW2Uhsu0UOM-1024.npz
eval_Episode has 500 steps and return 304.8.
train_Episode has 500 steps and return 310.9.
Saved chunk: 20230922T093753F261232-2wpXiFs2JHMUWbgpuSbg0v-1if8objCUNLZTg0ds5koXA-1024.npz
Starting evaluation at step 553000 Counter(553000) 552937
eval_Episode has 500 steps and return 326.8.
train_Episode has 500 steps and return 266.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1106890 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 326.83 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 266.18 / episode/reward_rate 0.37 / train/action_mag 3.88 / train/action_max 3.76 / train/action_mean 0.03 / train/action_min -3.65 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 1.84 / train/adv_mag 0.36 / train/adv_max 0.29 / train/adv_mean 4.2e-4
/ train/adv_min -0.28 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.55 / train/dyn_loss_std 6.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.19 / train/extr_critic_max 231.19 / train/extr_critic_mean 221.08 / train/extr_critic_min 168.49 / train/extr_critic_std 12.27 / train/extr_return_normed_mag 1.33 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.25 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.36 / train/extr_return_raw_max 231.36 / train/extr_return_raw_mean 221.1 / train/extr_return_raw_min
168.74 / train/extr_return_raw_std 12.28 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.88 / train/image_loss_std 0.87 / train/model_loss_mean 3.2 /
train/model_loss_std 4.37 / train/model_opt_grad_norm 8.34 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.79 / train/policy_entropy_max 
4.71 / train/policy_entropy_mean -2.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.39 / train/policy_logprob_mag 10.54 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.54 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.9 / train/policy_randomness_max 0.9 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 51.94 / train/post_ent_max 51.94 / train/post_ent_mean 42.41 / 
train/post_ent_min 22.66 / train/post_ent_std 4.55 / train/prior_ent_mag 80.94 / train/prior_ent_max 80.94 / train/prior_ent_mean 45.91 / train/prior_ent_min 29.19 / train/prior_ent_std 6.08 / train/rep_loss_mean 3.55 / train/rep_loss_std 6.17 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 
0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.28 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 6.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 6.66 / report/image_loss_mean 0.93 / report/image_loss_std 1.08 / report/model_loss_mean 3.2 / report/model_loss_std 4.82 / report/post_ent_mag 53.23 / report/post_ent_max 53.23 / 
report/post_ent_mean 42.38 / report/post_ent_min 23.47 / report/post_ent_std 4.28 / report/prior_ent_mag 80.64 / report/prior_ent_max 80.64 / report/prior_ent_mean 45.78 / report/prior_ent_min 31.7 / report/prior_ent_std 6.01 / report/rep_loss_mean 3.51 / 
report/rep_loss_std 6.66 / report/reward_avg 0.39 / report/reward_loss_mean 0.17 / report/reward_loss_std 0.28 / report/reward_max_data 1.97 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.39 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.73 / eval/dyn_loss_std 6.33 / eval/image_loss_mean 0.9 / eval/image_loss_std 1.22 / eval/model_loss_mean 3.38 / eval/model_loss_std 4.61 / eval/post_ent_mag 52.94 / eval/post_ent_max 52.94 / eval/post_ent_mean 
42.57 / eval/post_ent_min 21.7 / eval/post_ent_std 3.87 / eval/prior_ent_mag 80.64 / eval/prior_ent_max 80.64 / eval/prior_ent_mean 46.13 / eval/prior_ent_min 28.47 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 3.73 / eval/rep_loss_std 6.33 / eval/reward_avg 0.61 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.34 / eval/reward_max_data 1.93 / eval/reward_max_pred 1.9 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.61 / eval/reward_rate 0.44 / 
replay/size 5.5e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3806 / timer/env.step_total 19.75 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 452.74 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.05 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7313 / timer/agent.policy_total 16.46 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 
/ timer/dataset_train_count 1903 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.9 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 553500 Counter(553500) 553437
Saved chunk: 20230922T093839F255619-3bF3Bv1eIaAMW2Uhsu0UOM-1i1txslx3EWKgLGAwrD1HO-1024.npz
eval_Episode has 500 steps and return 327.2.
train_Episode has 500 steps and return 303.9.
Saved chunk: 20230922T093913F806000-1if8objCUNLZTg0ds5koXA-3K6kuhPVqrxJTpnsp4YrRM-1024.npz
Starting evaluation at step 554000 Counter(554000) 553937
eval_Episode has 500 steps and return 320.0.
train_Episode has 500 steps and return 311.3.
Starting evaluation at step 554500 Counter(554500) 554437
Saved chunk: 20230922T093959F355375-1i1txslx3EWKgLGAwrD1HO-0Z9QHyTJW5tVEU7vkDQAp3-1024.npz
eval_Episode has 500 steps and return 331.7.
train_Episode has 500 steps and return 299.4.
Starting evaluation at step 555000 Counter(555000) 554937
eval_Episode has 500 steps and return 297.5.
Saved chunk: 20230922T094035F847805-3K6kuhPVqrxJTpnsp4YrRM-03obbxal2oKDMGS9zBUqaC-1024.npz
train_Episode has 500 steps and return 315.3.
Starting evaluation at step 555500 Counter(555500) 555437
Saved chunk: 20230922T094118F942954-0Z9QHyTJW5tVEU7vkDQAp3-4CSztZ9JSSJSmxbFLPqeut-1024.npz
eval_Episode has 500 steps and return 307.1.
train_Episode has 500 steps and return 304.9.
Starting evaluation at step 556000 Counter(556000) 555937
eval_Episode has 500 steps and return 330.6.
Saved chunk: 20230922T094200F384931-03obbxal2oKDMGS9zBUqaC-6FsPC6qrHthytvqQKXhLRg-1024.npz
train_Episode has 500 steps and return 289.2.
Starting evaluation at step 556500 Counter(556500) 556437
Saved chunk: 20230922T094238F209136-4CSztZ9JSSJSmxbFLPqeut-6xeA1hSOgE6WD4KCMqRbEm-1024.npz
eval_Episode has 500 steps and return 329.8.
train_Episode has 500 steps and return 302.6.
Starting evaluation at step 557000 Counter(557000) 556937
eval_Episode has 500 steps and return 311.5.
Saved chunk: 20230922T094321F103187-6FsPC6qrHthytvqQKXhLRg-4uBxestUJj6F8BeRK6DBO1-1024.npz
train_Episode has 500 steps and return 299.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1114402 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 311.53 / eval_episode/reward_rate 0.45 / episode/length 500 / episode/score 299.18 / episode/reward_rate 0.44 / train/action_mag 3.85 / train/action_max 3.72 / train/action_mean 0.03 / train/action_min -3.62 / 
train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 2.32 / train/adv_mag 0.4 / train/adv_max 0.32 / train/adv_mean 3.8e-4 
/ train/adv_min -0.32 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.56 / train/dyn_loss_std 6.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.34 / train/extr_critic_max 231.34 / train/extr_critic_mean 220.79 / train/extr_critic_min 161.13 / train/extr_critic_std 14.1 / train/extr_return_normed_mag 1.4 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.53 / train/extr_return_raw_max 231.53 / train/extr_return_raw_mean 220.81 / 
train/extr_return_raw_min 162.6 / train/extr_return_raw_std 14.1 / train/extr_reward_mag 1.98 / train/extr_reward_max 1.98 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.89 / train/image_loss_std 0.89 / 
train/model_loss_mean 3.21 / train/model_loss_std 4.4 / train/model_opt_grad_norm 8.42 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.26 
/ train/policy_entropy_max 4.06 / train/policy_entropy_mean -2.06 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.29 / train/policy_logprob_mag 10.44 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.06 / train/policy_logprob_min -10.44 / 
train/policy_logprob_std 1.93 / train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 52.03 / train/post_ent_max 52.03 / 
train/post_ent_mean 42.34 / train/post_ent_min 21.96 / train/post_ent_std 4.72 / train/prior_ent_mag 80.98 / train/prior_ent_max 80.98 / train/prior_ent_mean 45.86 / train/prior_ent_min 28.32 / train/prior_ent_std 6.22 / train/rep_loss_mean 3.56 / train/rep_loss_std 
6.19 / train/reward_avg 0.43 / train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.95 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / 
train/reward_pred 0.43 / train/reward_rate 0.33 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.28 / report/cont_avg 1 / report/cont_loss_mean 1.7e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.74 / report/dyn_loss_std 6.36 / report/image_loss_mean 1.02 / report/image_loss_std 1.26 / report/model_loss_mean 3.49 / report/model_loss_std 4.78 / 
report/post_ent_mag 51.71 / report/post_ent_max 51.71 / report/post_ent_mean 42.3 / report/post_ent_min 22.71 / report/post_ent_std 4.7 / report/prior_ent_mag 80.71 / report/prior_ent_max 80.71 / report/prior_ent_mean 45.83 / report/prior_ent_min 30.85 / 
report/prior_ent_std 6.04 / report/rep_loss_mean 3.74 / report/rep_loss_std 6.36 / report/reward_avg 0.47 / report/reward_loss_mean 0.22 / report/reward_loss_std 0.34 / report/reward_max_data 1.93 / report/reward_max_pred 1.92 / report/reward_neg_acc 1 / 
report/reward_neg_loss 6.1e-3 / report/reward_pos_acc 0.99 / report/reward_pos_loss 0.59 / report/reward_pred 0.46 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 7.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / 
eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.29 / eval/dyn_loss_std 4.84 / eval/image_loss_mean 0.7 / eval/image_loss_std 0.57 / eval/model_loss_mean 2.95 / eval/model_loss_std 3.38 / eval/post_ent_mag 
50.47 / eval/post_ent_max 50.47 / eval/post_ent_mean 43.01 / eval/post_ent_min 27.42 / eval/post_ent_std 3.05 / eval/prior_ent_mag 80.71 / eval/prior_ent_max 80.71 / eval/prior_ent_mean 46.26 / eval/prior_ent_min 40.14 / eval/prior_ent_std 4.98 / eval/rep_loss_mean 3.29
/ eval/rep_loss_std 4.84 / eval/reward_avg 0.65 / eval/reward_loss_mean 0.28 / eval/reward_loss_std 0.36 / eval/reward_max_data 1.87 / eval/reward_max_pred 1.87 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.6 / 
eval/reward_pred 0.64 / eval/reward_rate 0.46 / replay/size 5.6e5 / replay/inserts 3756 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / 
eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 3.9e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3756 / timer/env.step_total 19.44
/ timer/env.step_frac 0.06 / timer/env.step_avg 5.2e-3 / timer/env.step_min 4.5e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 450.49 / timer/replay._sample_frac 1.5 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
8e-3 / timer/replay._sample_max 0.24 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7764 / timer/agent.policy_total 17.43 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 
1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1878 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.4e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1878 / 
timer/agent.train_total 241.86 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 
0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.03

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 557500 Counter(557500) 557437
Saved chunk: 20230922T094357F290505-6xeA1hSOgE6WD4KCMqRbEm-5l7dNXGsjm1msKi174bvND-1024.npz
eval_Episode has 500 steps and return 318.2.
train_Episode has 500 steps and return 305.3.
Starting evaluation at step 558000 Counter(558000) 557937
eval_Episode has 500 steps and return 325.3.
Saved chunk: 20230922T094441F725150-4uBxestUJj6F8BeRK6DBO1-65RFJsdZRaKDmA8m5H0y0h-1024.npz
train_Episode has 500 steps and return 273.4.
Starting evaluation at step 558500 Counter(558500) 558437
Saved chunk: 20230922T094517F687997-5l7dNXGsjm1msKi174bvND-5z24tLMZYsiJmmVEoN4DAh-1024.npz
eval_Episode has 500 steps and return 306.1.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Saved chunk: 20230922T094603F950606-65RFJsdZRaKDmA8m5H0y0h-0000000000000000000000-520.npz
Saved chunk: 20230922T094637F144756-5z24tLMZYsiJmmVEoN4DAh-0000000000000000000000-88.npz
train_Episode has 500 steps and return 292.5.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_hopper_hop/6/checkpoint.ckpt
Starting evaluation at step 559000 Counter(559000) 558937
eval_Episode has 500 steps and return 307.4.
Saved chunk: 20230922T094603F950606-65RFJsdZRaKDmA8m5H0y0h-2xLAM7NNlqiieX4TNJKkLA-1024.npz
train_Episode has 500 steps and return 302.6.
Starting evaluation at step 559500 Counter(559500) 559437
Saved chunk: 20230922T094637F144756-5z24tLMZYsiJmmVEoN4DAh-6yohw0Aa6vhyhxP2hksZ30-1024.npz
eval_Episode has 500 steps and return 321.1.
train_Episode has 500 steps and return 300.2.
Starting evaluation at step 560000 Counter(560000) 559937
eval_Episode has 500 steps and return 331.9.
train_Episode has 500 steps and return 293.2.
Saved chunk: 20230922T094724F973673-2xLAM7NNlqiieX4TNJKkLA-16VYjUkyTm1GuXtoQ0f4EW-1024.npz
Starting evaluation at step 560500 Counter(560500) 560437
eval_Episode has 500 steps and return 320.6.
Saved chunk: 20230922T094756F482384-6yohw0Aa6vhyhxP2hksZ30-3A2H0zlLgKxgzP0kMJyAOB-1024.npz
train_Episode has 500 steps and return 305.6.
Starting evaluation at step 561000 Counter(561000) 560937
eval_Episode has 500 steps and return 319.2.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1122002 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 319.17 / eval_episode/reward_rate 0.46 / episode/length 500 / episode/score 305.65 / episode/reward_rate 0.43 / train/action_mag 3.94 / train/action_max 3.81 / train/action_mean 0.03 / train/action_min -3.68 / 
train/action_std 0.92 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 1.89 / train/adv_mag 0.41 / train/adv_max 0.34 / train/adv_mean 4.1e-4
/ train/adv_min -0.27 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.58 / train/dyn_loss_std 6.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.4 / train/extr_critic_max 231.4 / train/extr_critic_mean 220.98 / train/extr_critic_min 159.88 / train/extr_critic_std 14.06 / train/extr_return_normed_mag 1.45 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.82 / train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.27 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.57 / train/extr_return_raw_max 231.57 / train/extr_return_raw_mean 221 / train/extr_return_raw_min 
160.86 / train/extr_return_raw_std 14.06 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.44 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.89 / train/image_loss_std 0.89 / train/model_loss_mean 3.23 
/ train/model_loss_std 4.42 / train/model_opt_grad_norm 8.19 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.62 / train/policy_entropy_max
4.52 / train/policy_entropy_mean -2.01 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.37 / train/policy_logprob_mag 10.37 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.01 / train/policy_logprob_min -10.37 / train/policy_logprob_std 1.98 / 
train/policy_randomness_mag 0.88 / train/policy_randomness_max 0.88 / train/policy_randomness_mean 0.17 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 52.06 / train/post_ent_max 52.06 / train/post_ent_mean 42.37 / 
train/post_ent_min 22.17 / train/post_ent_std 4.69 / train/prior_ent_mag 80.96 / train/prior_ent_max 80.96 / train/prior_ent_mean 45.91 / train/prior_ent_min 28.39 / train/prior_ent_std 6.21 / train/rep_loss_mean 3.58 / train/rep_loss_std 6.23 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.3 / train/reward_max_data 1.94 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 
0.34 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -2.27 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 4.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.43 / report/dyn_loss_std 5.8 / report/image_loss_mean 0.82 / report/image_loss_std 0.61 / report/model_loss_mean 3.11 / report/model_loss_std 3.99 / report/post_ent_mag 52.63 / report/post_ent_max 52.63 / 
report/post_ent_mean 43.3 / report/post_ent_min 26.34 / report/post_ent_std 3.82 / report/prior_ent_mag 80.91 / report/prior_ent_max 80.91 / report/prior_ent_mean 46.73 / report/prior_ent_min 33.47 / report/prior_ent_std 5.34 / report/rep_loss_mean 3.43 / 
report/rep_loss_std 5.8 / report/reward_avg 0.42 / report/reward_loss_mean 0.23 / report/reward_loss_std 0.34 / report/reward_max_data 1.86 / report/reward_max_pred 1.83 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.59 / report/reward_pred 0.43 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.93 / eval/dyn_loss_std 6.14 / eval/image_loss_mean 0.97 / eval/image_loss_std 1.34 / eval/model_loss_mean 3.58 / eval/model_loss_std 4.65 / eval/post_ent_mag 51.05 / eval/post_ent_max 51.05 / eval/post_ent_mean 
42.26 / eval/post_ent_min 21.49 / eval/post_ent_std 4.38 / eval/prior_ent_mag 80.91 / eval/prior_ent_max 80.91 / eval/prior_ent_mean 46.09 / eval/prior_ent_min 28.38 / eval/prior_ent_std 5.62 / eval/rep_loss_mean 3.93 / eval/rep_loss_std 6.14 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.25 / eval/reward_loss_std 0.32 / eval/reward_max_data 1.96 / eval/reward_max_pred 1.95 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.59 / eval/reward_pred 0.6 / eval/reward_rate 0.42 / 
replay/size 5.6e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.23 / timer/env.step_count 3800 / timer/env.step_total 19.72 / timer/env.step_frac 0.07 / timer/env.step_avg 
5.2e-3 / timer/env.step_min 4.4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 463.25 / timer/replay._sample_frac 1.53 / timer/replay._sample_avg 0.02 / timer/replay._sample_min 6.8e-4 / timer/replay._sample_max 0.25 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7808 / timer/agent.policy_total 17.68 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.6e-5 / 
timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.45 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.35 / timer/agent.report_count 2 / timer/agent.report_total 
0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 292.1.
Saved chunk: 20230922T094845F582545-16VYjUkyTm1GuXtoQ0f4EW-46vvMKPevAH9yGKLi3AMCv-1024.npz
Starting evaluation at step 561500 Counter(561500) 561437
eval_Episode has 500 steps and return 332.7.
Saved chunk: 20230922T094915F485350-3A2H0zlLgKxgzP0kMJyAOB-3vVhPpwxtGJSdgcrRrIvzf-1024.npz
train_Episode has 500 steps and return 293.4.
Starting evaluation at step 562000 Counter(562000) 561937
eval_Episode has 500 steps and return 307.2.
train_Episode has 500 steps and return 306.7.
Saved chunk: 20230922T095007F456526-46vvMKPevAH9yGKLi3AMCv-2MKSwJdPJuhoclJnSGb3IK-1024.npz
Starting evaluation at step 562500 Counter(562500) 562437
eval_Episode has 500 steps and return 329.7.
Saved chunk: 20230922T095035F959514-3vVhPpwxtGJSdgcrRrIvzf-63hCrPxSC8RfVJoaGIi40B-1024.npz
train_Episode has 500 steps and return 287.0.
Starting evaluation at step 563000 Counter(563000) 562937
eval_Episode has 500 steps and return 341.0.
train_Episode has 500 steps and return 315.9.
Saved chunk: 20230922T095128F385753-2MKSwJdPJuhoclJnSGb3IK-12DX3KQNLal52StQXvyOok-1024.npz
Starting evaluation at step 563500 Counter(563500) 563437
eval_Episode has 500 steps and return 322.3.
train_Episode has 500 steps and return 291.8.
Starting evaluation at step 564000 Counter(564000) 563937
Saved chunk: 20230922T095155F251047-63hCrPxSC8RfVJoaGIi40B-01KVrzMx66cEQCmSvIb3Aw-1024.npz
eval_Episode has 500 steps and return 327.7.
train_Episode has 500 steps and return 311.4.
Saved chunk: 20230922T095249F230519-12DX3KQNLal52StQXvyOok-75y3kvew4NOPpLE2sRUQsK-1024.npz
Starting evaluation at step 564500 Counter(564500) 564437
eval_Episode has 500 steps and return 302.3.
train_Episode has 500 steps and return 297.1.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1129610 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 297.12 / episode/reward_rate 0.42 / eval_episode/length 500 / eval_episode/score 302.32 / eval_episode/reward_rate 0.43 / train/action_mag 3.9 / train/action_max 3.77 / train/action_mean 0.03 / train/action_min -3.66 / train/action_std
0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss 4.47 / train/adv_mag 0.33 / train/adv_max 0.23 / train/adv_mean 1.6e-4 / train/adv_min 
-0.3 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 3.57 / train/dyn_loss_std 6.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.04 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 231.52 / train/extr_critic_max 231.52 / train/extr_critic_mean 221.22 / train/extr_critic_min 163.31 / train/extr_critic_std 13.71 / train/extr_return_normed_mag 1.49 / train/extr_return_normed_max 1.03 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.29 / train/extr_return_rate 0.99 / train/extr_return_raw_mag 231.69 / train/extr_return_raw_max 231.69 / train/extr_return_raw_mean 221.23 / train/extr_return_raw_min
162.92 / train/extr_return_raw_std 13.74 / train/extr_reward_mag 1.97 / train/extr_reward_max 1.97 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.89 / train/image_loss_std 0.89 / train/model_loss_mean 3.22 
/ train/model_loss_std 4.4 / train/model_opt_grad_norm 8.75 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 3.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 4.9 / train/policy_entropy_max 
4.86 / train/policy_entropy_mean -2.05 / train/policy_entropy_min -3.53 / train/policy_entropy_std 1.4 / train/policy_logprob_mag 10.61 / train/policy_logprob_max 5.48 / train/policy_logprob_mean 2.05 / train/policy_logprob_min -10.61 / train/policy_logprob_std 2 / 
train/policy_randomness_mag 0.91 / train/policy_randomness_max 0.91 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.15 / train/post_ent_mag 52.02 / train/post_ent_max 52.02 / train/post_ent_mean 42.42 / 
train/post_ent_min 21.97 / train/post_ent_std 4.63 / train/prior_ent_mag 80.92 / train/prior_ent_max 80.92 / train/prior_ent_mean 45.94 / train/prior_ent_min 28.43 / train/prior_ent_std 6.14 / train/rep_loss_mean 3.57 / train/rep_loss_std 6.17 / train/reward_avg 0.43 / 
train/reward_loss_mean 0.19 / train/reward_loss_std 0.31 / train/reward_max_data 1.94 / train/reward_max_pred 1.93 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.56 / train/reward_pred 0.43 / train/reward_rate 
0.34 / train_stats/mean_log_entropy -2.27 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 4.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 3.51 / report/dyn_loss_std 6.02 / report/image_loss_mean 0.8 / report/image_loss_std 0.97 / report/model_loss_mean 3.11 / report/model_loss_std 4.38 / report/post_ent_mag 51.22 / report/post_ent_max 51.22 / 
report/post_ent_mean 42.34 / report/post_ent_min 16.93 / report/post_ent_std 5.94 / report/prior_ent_mag 81.15 / report/prior_ent_max 81.15 / report/prior_ent_mean 45.77 / report/prior_ent_min 19.53 / report/prior_ent_std 7.22 / report/rep_loss_mean 3.51 / 
report/rep_loss_std 6.02 / report/reward_avg 0.5 / report/reward_loss_mean 0.21 / report/reward_loss_std 0.3 / report/reward_max_data 1.95 / report/reward_max_pred 1.94 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.55 / report/reward_pred 0.5 / report/reward_rate 0.37 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.77 / eval/dyn_loss_std 6.32 / eval/image_loss_mean 0.91 / eval/image_loss_std 1.13 / eval/model_loss_mean 3.43 / eval/model_loss_std 4.69 / eval/post_ent_mag 51.11 / eval/post_ent_max 51.11 / eval/post_ent_mean 
42.71 / eval/post_ent_min 23.87 / eval/post_ent_std 3.72 / eval/prior_ent_mag 81.15 / eval/prior_ent_max 81.15 / eval/prior_ent_mean 46.15 / eval/prior_ent_min 31.32 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 3.77 / eval/rep_loss_std 6.32 / eval/reward_avg 0.6 / 
eval/reward_loss_mean 0.26 / eval/reward_loss_std 0.33 / eval/reward_max_data 1.9 / eval/reward_max_pred 1.91 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.6 / eval/reward_rate 0.44 / 
replay/size 5.6e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3804 / timer/env.step_total 19.72 / timer/env.step_frac 0.07 / timer/env.step_avg 5.2e-3
/ timer/env.step_min 4.5e-3 / timer/env.step_max 8.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 453.57 / timer/replay._sample_frac 1.51 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.24 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7311 / timer/agent.policy_total 16.51 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1902 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.5e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.7e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.89 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.55 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.7e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.36
