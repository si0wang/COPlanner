Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {}
JAX devices (1): [gpu(id=0)]
Policy devices: gpu:0
Train devices:  gpu:0
Tracing train function.
Optimizer model_opt has 15,685,251 variables.
{'action': Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>, 'deter': Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>, 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>, 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>}
{'action': Traced<ShapedArray(float32[15,1024,1])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,1])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,1]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f139c15d220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c043e50; dead>, <weakref at 0x7f139c043d10; dead>, <weakref at 0x7f139c043cc0; dead>, <weakref at 0x7f139c043f40; dead>, <weakref at 0x7f139c043db0; to 'JaxprTracer' at 0x7f139c043630>, <weakref at 0x7f139c043d60; to 'JaxprTracer' at 0x7f139c043ae0>, <weakref at 0x7f139c043a40; to 'JaxprTracer' at 0x7f139c043c20>, <weakref at 0x7f139c0438b0; to 'JaxprTracer' at 0x7f139c043c70>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f139c0a9cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f139c15d220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c043e50; dead>, <weakref at 0x7f139c043d10; dead>, <weakref at 0x7f139c043cc0; dead>, <weakref at 0x7f139c043f40; dead>, <weakref at 0x7f139c043db0; to 'JaxprTracer' at 0x7f139c043630>, <weakref at 0x7f139c043d60; to 'JaxprTracer' at 0x7f139c043ae0>, <weakref at 0x7f139c043a40; to 'JaxprTracer' at 0x7f139c043c20>, <weakref at 0x7f139c0438b0; to 'JaxprTracer' at 0x7f139c043c70>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f139c0a9cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f139c15d220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c043e50; dead>, <weakref at 0x7f139c043d10; dead>, <weakref at 0x7f139c043cc0; dead>, <weakref at 0x7f139c043f40; dead>, <weakref at 0x7f139c043db0; to 'JaxprTracer' at 0x7f139c043630>, <weakref at 0x7f139c043d60; to 'JaxprTracer' at 0x7f139c043ae0>, <weakref at 0x7f139c043a40; to 'JaxprTracer' at 0x7f139c043c20>, <weakref at 0x7f139c0438b0; to 'JaxprTracer' at 0x7f139c043c70>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f139c0a9cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f139c15d220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c043e50; dead>, <weakref at 0x7f139c043d10; dead>, <weakref at 0x7f139c043cc0; dead>, <weakref at 0x7f139c043f40; dead>, <weakref at 0x7f139c043db0; to 'JaxprTracer' at 0x7f139c043630>, <weakref at 0x7f139c043d60; to 'JaxprTracer' at 0x7f139c043ae0>, <weakref at 0x7f139c043a40; to 'JaxprTracer' at 0x7f139c043c20>, <weakref at 0x7f139c0438b0; to 'JaxprTracer' at 0x7f139c043c70>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f139c0a9cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Optimizer actor_opt has 1,051,650 variables.
Optimizer critic_opt has 1,181,439 variables.
Logdir /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp
Observation space:
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  position         Space(dtype=float64, shape=(3,), low=-inf, high=inf)
  velocity         Space(dtype=float64, shape=(2,), low=-inf, high=inf)
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
Action space:
  reset            Space(dtype=bool, shape=(), low=False, high=True)
  action           Space(dtype=float32, shape=(1,), low=-1.0, high=1.0)
Prefill train dataset.
train_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Prefill eval dataset.
Saved chunk: 20230921T213832F311978-0QbW0zy0JFYSVxbXiaF7x5-2DmcLLcBenB5ug5vrtrp08-1024.npz
eval_Episode has 500 steps and return 0.0.
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213836F542030-5Bqx13peP3tztsqk75yR6z-3y61JSmw0LnxakrcGlBI0K-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2200 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0
warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'


Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100 Counter(1100) 1037
Saved chunk: 20230921T213840F150993-3y61JSmw0LnxakrcGlBI0K-0000000000000000000000-76.npz
Saved chunk: 20230921T213835F914763-2DmcLLcBenB5ug5vrtrp08-0000000000000000000000-76.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Tracing policy function.
Tracing policy function.
eval_Episode has 500 steps and return 0.0.
Tracing policy function.
Tracing train function.
{'action': Traced<ShapedArray(float32[15,1024,1])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,1])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,1]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f13c0550fe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c346090; dead>, <weakref at 0x7f139c346130; dead>, <weakref at 0x7f139c346630; dead>, <weakref at 0x7f139c346040; dead>, <weakref at 0x7f139c3462c0; to 'JaxprTracer' at 0x7f139c0b7ea0>, <weakref at 0x7f139c346bd0; to 'JaxprTracer' at 0x7f139c346d60>, <weakref at 0x7f139c3461d0; to 'JaxprTracer' at 0x7f139c346860>, <weakref at 0x7f139c346d10; to 'JaxprTracer' at 0x7f139c3463b0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f13869646f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f13c0550fe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c346090; dead>, <weakref at 0x7f139c346130; dead>, <weakref at 0x7f139c346630; dead>, <weakref at 0x7f139c346040; dead>, <weakref at 0x7f139c3462c0; to 'JaxprTracer' at 0x7f139c0b7ea0>, <weakref at 0x7f139c346bd0; to 'JaxprTracer' at 0x7f139c346d60>, <weakref at 0x7f139c3461d0; to 'JaxprTracer' at 0x7f139c346860>, <weakref at 0x7f139c346d10; to 'JaxprTracer' at 0x7f139c3463b0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f13869646f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f13c0550fe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c346090; dead>, <weakref at 0x7f139c346130; dead>, <weakref at 0x7f139c346630; dead>, <weakref at 0x7f139c346040; dead>, <weakref at 0x7f139c3462c0; to 'JaxprTracer' at 0x7f139c0b7ea0>, <weakref at 0x7f139c346bd0; to 'JaxprTracer' at 0x7f139c346d60>, <weakref at 0x7f139c3461d0; to 'JaxprTracer' at 0x7f139c346860>, <weakref at 0x7f139c346d10; to 'JaxprTracer' at 0x7f139c3463b0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f13869646f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f13c0550fe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f139c346090; dead>, <weakref at 0x7f139c346130; dead>, <weakref at 0x7f139c346630; dead>, <weakref at 0x7f139c346040; dead>, <weakref at 0x7f139c3462c0; to 'JaxprTracer' at 0x7f139c0b7ea0>, <weakref at 0x7f139c346bd0; to 'JaxprTracer' at 0x7f139c346d60>, <weakref at 0x7f139c3461d0; to 'JaxprTracer' at 0x7f139c346860>, <weakref at 0x7f139c346d10; to 'JaxprTracer' at 0x7f139c3463b0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f13869646f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Tracing report function.
Tracing report function.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2202 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.01 / train/action_max 4.01 / train/action_mean 0.3 / train/action_min -3.49 / train/action_std 1.03 / train/actor_opt_actor_opt_grad_overflow 0 / 
train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.5e-5 / train/actor_opt_grad_steps 1 / train/actor_opt_loss -0.28 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 
1.41 / train/cont_loss_std 0.49 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 0.06 / train/cont_pos_loss 1.41 / train/cont_pred 0.27 / train/cont_rate 1 / train/dyn_loss_mean 7.07 / train/dyn_loss_std 0.32 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.15 / train/extr_critic_critic_opt_grad_steps 1 / train/extr_critic_critic_opt_loss 8020.99 / train/extr_critic_mag 0
/ train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 0 / train/extr_return_normed_max -inf / train/extr_return_normed_mean 0 / train/extr_return_normed_min 0 / 
train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / 
train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2722.21 / train/image_loss_std 31.22 / train/model_loss_mean 2733.4 / train/model_loss_std 31.24 / train/model_opt_grad_norm nan / train/model_opt_grad_steps 0 / 
train/model_opt_loss 2.7e7 / train/model_opt_model_opt_grad_overflow 1 / train/model_opt_model_opt_grad_scale 5000 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / train/policy_entropy_mean 1.31 / train/policy_entropy_min 0.59 / train/policy_entropy_std 
0.08 / train/policy_logprob_mag 8.97 / train/policy_logprob_max -0.23 / train/policy_logprob_mean -1.31 / train/policy_logprob_min -8.97 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.95 / 
train/policy_randomness_min 0.64 / train/policy_randomness_std 0.03 / train/post_ent_mag 107.94 / train/post_ent_max 107.94 / train/post_ent_mean 107.55 / train/post_ent_min 107.25 / train/post_ent_std 0.1 / train/prior_ent_mag 107.85 / train/prior_ent_max 107.85 / 
train/prior_ent_mean 107.23 / train/prior_ent_min 106.54 / train/prior_ent_std 0.22 / train/rep_loss_mean 7.07 / train/rep_loss_std 0.32 / train/reward_avg 0 / train/reward_loss_mean 5.54 / train/reward_loss_std 9.5e-7 / train/reward_max_data 0 / train/reward_max_pred 0 /
train/reward_neg_acc 1 / train/reward_neg_loss 5.54 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train/params_agent/wm/model_opt 1.6e7 / train/params_agent/task_behavior/critic/critic_opt 1.2e6 / 
train/params_agent/task_behavior/ac/actor_opt 1.1e6 / report/cont_avg 1 / report/cont_loss_mean 1.46 / report/cont_loss_std 0.49 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 0.04 / report/cont_pos_loss 1.46 / report/cont_pred 0.26 / 
report/cont_rate 1 / report/dyn_loss_mean 7.05 / report/dyn_loss_std 0.31 / report/image_loss_mean 2725.85 / report/image_loss_std 30.42 / report/model_loss_mean 2737.09 / report/model_loss_std 30.45 / report/post_ent_mag 107.96 / report/post_ent_max 107.96 / 
report/post_ent_mean 107.55 / report/post_ent_min 107.17 / report/post_ent_std 0.1 / report/prior_ent_mag 107.96 / report/prior_ent_max 107.96 / report/prior_ent_mean 107.23 / report/prior_ent_min 106.51 / report/prior_ent_std 0.23 / report/rep_loss_mean 7.05 / 
report/rep_loss_std 0.31 / report/reward_avg 0 / report/reward_loss_mean 5.54 / report/reward_loss_std 9.5e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 5.54 / report/reward_pos_acc nan / report/reward_pos_loss
nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.43 / eval/cont_loss_std 0.51 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 0.05 / eval/cont_pos_loss 1.43 / eval/cont_pred 0.27 / eval/cont_rate 1 / 
eval/dyn_loss_mean 7.01 / eval/dyn_loss_std 0.29 / eval/image_loss_mean 2723.77 / eval/image_loss_std 28.75 / eval/model_loss_mean 2734.95 / eval/model_loss_std 28.76 / eval/post_ent_mag 107.88 / eval/post_ent_max 107.88 / eval/post_ent_mean 107.59 / eval/post_ent_min 
107.24 / eval/post_ent_std 0.1 / eval/prior_ent_mag 107.81 / eval/prior_ent_max 107.81 / eval/prior_ent_mean 107.24 / eval/prior_ent_min 106.5 / eval/prior_ent_std 0.21 / eval/rep_loss_mean 7.01 / eval/rep_loss_std 0.29 / eval/reward_avg 0 / eval/reward_loss_mean 5.54 / 
eval/reward_loss_std 9.5e-7 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.54 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1038 / replay/inserts 1038 / 
replay/samples 112 / replay/insert_wait_avg 2.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1538 / eval_replay/inserts 1538 / eval_replay/samples 112 / eval_replay/insert_wait_avg 2.3e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 145.22 / timer/env.step_count 1101 / timer/env.step_total 4.61 / timer/env.step_frac 0.03 / timer/env.step_avg 4.2e-3 / timer/env.step_min 3e-3 / 
timer/env.step_max 0.96 / timer/replay._sample_count 112 / timer/replay._sample_total 23.48 / timer/replay._sample_frac 0.16 / timer/replay._sample_avg 0.21 / timer/replay._sample_min 4.7e-4 / timer/replay._sample_max 1.37 / timer/agent.save_count 1 / 
timer/agent.save_total 0.23 / timer/agent.save_frac 1.6e-3 / timer/agent.save_avg 0.23 / timer/agent.save_min 0.23 / timer/agent.save_max 0.23 / timer/agent.policy_count 502 / timer/agent.policy_total 48.74 / timer/agent.policy_frac 0.34 / timer/agent.policy_avg 0.1 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 46.33 / timer/dataset_train_count 1 / timer/dataset_train_total 2.3e-5 / timer/dataset_train_frac 1.6e-7 / timer/dataset_train_avg 2.3e-5 / timer/dataset_train_min 2.3e-5 / timer/dataset_train_max 2.3e-5 / 
timer/agent.train_count 1 / timer/agent.train_total 74.98 / timer/agent.train_frac 0.52 / timer/agent.train_avg 74.98 / timer/agent.train_min 74.98 / timer/agent.train_max 74.98 / timer/agent.report_count 2 / timer/agent.report_total 9.31 / timer/agent.report_frac 0.06 / 
timer/agent.report_avg 4.66 / timer/agent.report_min 0.07 / timer/agent.report_max 9.25 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 2.5e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max
3.7e-5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 1500 Counter(1500) 1437
Saved chunk: 20230921T213840F150993-3y61JSmw0LnxakrcGlBI0K-113jDSuWVGFIdhDv16fnFR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 2000 Counter(2000) 1937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213835F914763-2DmcLLcBenB5ug5vrtrp08-5kYAaHDsH7ijygA1EoM2VX-1024.npz
Starting evaluation at step 2500 Counter(2500) 2437
Saved chunk: 20230921T214127F359983-113jDSuWVGFIdhDv16fnFR-4nqRUM2ftKyIBwv9HYus82-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 3000 Counter(3000) 2937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214209F210135-5kYAaHDsH7ijygA1EoM2VX-5pjrrd0UQwDeMTGLVEN4EW-1024.npz
Starting evaluation at step 3500 Counter(3500) 3437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214243F902558-4nqRUM2ftKyIBwv9HYus82-0w85bnksz6GyAF7726kJds-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 4000 Counter(4000) 3937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214327F518456-5pjrrd0UQwDeMTGLVEN4EW-5SMhDtgorvn2Zo4pGMfeI3-1024.npz
Starting evaluation at step 4500 Counter(4500) 4437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 9836 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.65 / train/action_mean 0.64 / train/action_min -3.37 / train/action_std 1.01 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.7e-5 / train/actor_opt_grad_steps 955 / train/actor_opt_loss -4.14 / train/adv_mag 2.2e-7 / train/adv_max 1.9e-7 / train/adv_mean -8e-9 / train/adv_min 
-2.2e-7 / train/adv_std 5.4e-8 / train/cont_avg 1 / train/cont_loss_mean 7.3e-3 / train/cont_loss_std 2.7e-3 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.3e-3 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.64 / train/dyn_loss_std 1.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.28 / train/extr_critic_critic_opt_grad_steps 955 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 1.8e-7 / train/extr_critic_max -inf / train/extr_critic_mean 6e-9 / train/extr_critic_min -2.6e-8 / train/extr_critic_std 4.1e-8 / train/extr_return_normed_mag 2.2e-7 / train/extr_return_normed_max 2e-7 / 
train/extr_return_normed_mean 2.9e-8 / train/extr_return_normed_min -2.3e-8 / train/extr_return_normed_std 3.4e-8 / train/extr_return_rate 0 / train/extr_return_raw_mag 2.1e-7 / train/extr_return_raw_max 1.7e-7 / train/extr_return_raw_mean -2e-9 / 
train/extr_return_raw_min -5.4e-8 / train/extr_return_raw_std 3.4e-8 / train/extr_reward_mag 8.2e-9 / train/extr_reward_max -inf / train/extr_reward_mean -1.5e-9 / train/extr_reward_min -8.2e-9 / train/extr_reward_std 2.2e-9 / train/image_loss_mean 36.1 / 
train/image_loss_std 9.02 / train/model_loss_mean 37.28 / train/model_loss_std 9.29 / train/model_opt_grad_norm 113.65 / train/model_opt_grad_steps 946 / train/model_opt_loss 805.29 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 28.78 /
train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.41 / train/policy_entropy_min 1.37 / train/policy_entropy_std 2.4e-3 / train/policy_logprob_mag 9.47 / train/policy_logprob_max -0.89 / train/policy_logprob_mean -1.41 / 
train/policy_logprob_min -9.47 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 1e-3 / train/post_ent_mag 67.49 / 
train/post_ent_max 67.49 / train/post_ent_mean 58.93 / train/post_ent_min 53.05 / train/post_ent_std 2.59 / train/prior_ent_mag 71.56 / train/prior_ent_max 71.56 / train/prior_ent_mean 62.83 / train/prior_ent_min 58.67 / train/prior_ent_std 2.44 / train/rep_loss_mean 1.64
/ train/rep_loss_std 1.35 / train/reward_avg 0 / train/reward_loss_mean 0.19 / train/reward_loss_std 4.3e-4 / train/reward_max_data 0 / train/reward_max_pred 8.8e-9 / train/reward_neg_acc 1 / train/reward_neg_loss 0.19 / train/reward_pos_acc nan / train/reward_pos_loss 
nan / train/reward_pred -8.6e-10 / train/reward_rate 0 / train_stats/mean_log_entropy 1.41 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.3e-6 / report/cont_loss_std 6.7e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / 
report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-6 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2 / report/dyn_loss_std 2.89 / report/image_loss_mean 4.99 / report/image_loss_std 5.04 / report/model_loss_mean 6.19 / report/model_loss_std 5.63 / 
report/post_ent_mag 50.18 / report/post_ent_max 50.18 / report/post_ent_mean 28.95 / report/post_ent_min 22.4 / report/post_ent_std 4.93 / report/prior_ent_mag 57.3 / report/prior_ent_max 57.3 / report/prior_ent_mean 32.25 / report/prior_ent_min 25.52 / 
report/prior_ent_std 5.73 / report/rep_loss_mean 2 / report/rep_loss_std 2.89 / report/reward_avg 0 / report/reward_loss_mean 1.2e-3 / report/reward_loss_std 1.3e-5 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 
1.2e-3 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-5 / eval/cont_loss_std 1e-5 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.1e-5 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.55 / eval/dyn_loss_std 3.97 / eval/image_loss_mean 12.31 / eval/image_loss_std 6.51 / eval/model_loss_mean 13.85 / eval/model_loss_std 7.29 / eval/post_ent_mag 54.01 / eval/post_ent_max
54.01 / eval/post_ent_mean 36.63 / eval/post_ent_min 22.79 / eval/post_ent_std 7.74 / eval/prior_ent_mag 56.23 / eval/prior_ent_max 56.23 / eval/prior_ent_mean 39.54 / eval/prior_ent_min 26.01 / eval/prior_ent_std 8.17 / eval/rep_loss_mean 2.55 / eval/rep_loss_std 3.97 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.2e-3 / eval/reward_loss_std 1.8e-5 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / 
eval/reward_rate 0 / replay/size 4855 / replay/inserts 3817 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 5045 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 290.82 / timer/env.step_count 3817 / timer/env.step_total 18.99 / timer/env.step_frac 0.07 /
timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 369.11 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 9.7e-4 / timer/replay._sample_max
0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7324 / timer/agent.policy_total 15.68 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 
0.01 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.13 / timer/dataset_train_frac 4.6e-4 / timer/dataset_train_avg 7.1e-5 / timer/dataset_train_min 6.1e-5 / timer/dataset_train_max 3e-4 / timer/agent.train_count 1908 / timer/agent.train_total 238.26 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.12 / timer/agent.train_min 0.12 / timer/agent.train_max 0.18 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 26.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 5000 Counter(5000) 4937
Saved chunk: 20230921T214400F757567-0w85bnksz6GyAF7726kJds-0U1tgrKw2o8HjnRNe0gCQo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214446F103844-5SMhDtgorvn2Zo4pGMfeI3-0lR6dhCtcrDdOBCInacJq8-1024.npz
Starting evaluation at step 5500 Counter(5500) 5437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 6000 Counter(6000) 5937
Saved chunk: 20230921T214553F584885-0U1tgrKw2o8HjnRNe0gCQo-7Enj732U2YeuBxUgkva30Y-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214605F360953-0lR6dhCtcrDdOBCInacJq8-63HTWOKFm2POMrc9yJQJOZ-1024.npz
Starting evaluation at step 6500 Counter(6500) 6437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 7000 Counter(7000) 6937
Saved chunk: 20230921T214711F009894-7Enj732U2YeuBxUgkva30Y-4rhPOfEVnwU1SHpVUBSfb0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214724F292636-63HTWOKFm2POMrc9yJQJOZ-3iWVFXfKXa0zPNi9sesHEF-1024.npz
Starting evaluation at step 7500 Counter(7500) 7437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 8000 Counter(8000) 7937
Saved chunk: 20230921T214828F269770-4rhPOfEVnwU1SHpVUBSfb0-53Pv7C3d0yYg4k4T59oMjo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214843F064807-3iWVFXfKXa0zPNi9sesHEF-1QCPkcF8Yly8xzt0gdSCZ8-1024.npz
Starting evaluation at step 8500 Counter(8500) 8437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 17578 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.53 / train/action_max 4.5 / train/action_mean 0.31 / train/action_min -3.95 / train/action_std 1.06 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.3e-5 / train/actor_opt_grad_steps 2875 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 2.1e-6 / train/cont_loss_std 1.7e-6 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-6 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.08 / train/dyn_loss_std 
3.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 2875 / train/extr_critic_critic_opt_loss 108.87 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 4e-16 / train/extr_return_normed_max 4e-16 / train/extr_return_normed_mean 4e-16 / 
train/extr_return_normed_min 4e-16 / train/extr_return_normed_std 1.9e-23 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / 
train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 3.39 / train/image_loss_std 3.44 / train/model_loss_mean 4.64 / train/model_loss_std 4.48 / 
train/model_opt_grad_norm 20.22 / train/model_opt_grad_steps 2866 / train/model_opt_loss 485.27 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 109.33 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.38 / train/policy_entropy_std 2.7e-3 / train/policy_logprob_mag 9.66 / train/policy_logprob_max -0.89 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.66 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 1.2e-3 / train/post_ent_mag 38.33 / train/post_ent_max 38.33 / train/post_ent_mean 22.59 / train/post_ent_min 
16.15 / train/post_ent_std 3.87 / train/prior_ent_mag 48.78 / train/prior_ent_max 48.78 / train/prior_ent_mean 25.72 / train/prior_ent_min 19.07 / train/prior_ent_std 5.04 / train/rep_loss_mean 2.08 / train/rep_loss_std 3.49 / train/reward_avg 0 / train/reward_loss_mean 
5.9e-4 / train/reward_loss_std 5.2e-6 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 5.9e-4 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 1.1e-6 / report/cont_loss_std 1.2e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-6 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 2.16 / report/dyn_loss_std 4.03 / report/image_loss_mean 2.99 / report/image_loss_std 2.57 / report/model_loss_mean 4.29 / report/model_loss_std 3.77 / report/post_ent_mag 35.06 / report/post_ent_max 35.06 / 
report/post_ent_mean 20.26 / report/post_ent_min 13.46 / report/post_ent_std 3.84 / report/prior_ent_mag 48.85 / report/prior_ent_max 48.85 / report/prior_ent_mean 23.41 / report/prior_ent_min 14.69 / report/prior_ent_std 5.5 / report/rep_loss_mean 2.16 / 
report/rep_loss_std 4.03 / report/reward_avg 0 / report/reward_loss_mean 2.6e-4 / report/reward_loss_std 2.7e-6 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-4 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-6 / eval/cont_loss_std 1.4e-6 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-6 / eval/cont_pred 1 / 
eval/cont_rate 1 / eval/dyn_loss_mean 3.45 / eval/dyn_loss_std 5.52 / eval/image_loss_mean 7.22 / eval/image_loss_std 5.93 / eval/model_loss_mean 9.29 / eval/model_loss_std 7.62 / eval/post_ent_mag 44.02 / eval/post_ent_max 44.02 / eval/post_ent_mean 25.12 / 
eval/post_ent_min 13.63 / eval/post_ent_std 6.22 / eval/prior_ent_mag 48.85 / eval/prior_ent_max 48.85 / eval/prior_ent_mean 27.72 / eval/prior_ent_min 15.28 / eval/prior_ent_std 6.51 / eval/rep_loss_mean 3.45 / eval/rep_loss_std 5.52 / eval/reward_avg 0 / 
eval/reward_loss_mean 2.6e-4 / eval/reward_loss_std 4.3e-6 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 
8726 / replay/inserts 3871 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 9053 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3871 / timer/env.step_total 19.23 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 7.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 380.1 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.08 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7879 / timer/agent.policy_total 16.73 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.6e-3 / 
timer/dataset_train_count 1936 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.3e-5 / timer/dataset_train_min 6.5e-5 / timer/dataset_train_max 3e-4 / timer/agent.train_count 1936 / timer/agent.train_total 243.72 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.8

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 9000 Counter(9000) 8937
Saved chunk: 20230921T214945F586638-53Pv7C3d0yYg4k4T59oMjo-6hAtrQaeAlmdZHFGF8z2iW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215001F859769-1QCPkcF8Yly8xzt0gdSCZ8-64oNb62drGYvoJRTqD6Qsd-1024.npz
Starting evaluation at step 9500 Counter(9500) 9437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 10000 Counter(10000) 9937
Saved chunk: 20230921T215103F355419-6hAtrQaeAlmdZHFGF8z2iW-32ord8jHn72Oe2CsZ3NyXs-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215121F379925-64oNb62drGYvoJRTqD6Qsd-6jeadxqEzEfnSJUchJFaAK-1024.npz
Starting evaluation at step 10500 Counter(10500) 10437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 11000 Counter(11000) 10937
Saved chunk: 20230921T215220F999061-32ord8jHn72Oe2CsZ3NyXs-0PMwNTiZiMI41EzoSgyToW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T215338F474890-0PMwNTiZiMI41EzoSgyToW-0000000000000000000000-357.npz
Saved chunk: 20230921T215240F493154-6jeadxqEzEfnSJUchJFaAK-0000000000000000000000-860.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T215240F493154-6jeadxqEzEfnSJUchJFaAK-3opKITBnaaqlmFCTwsWV0r-1024.npz
Starting evaluation at step 11500 Counter(11500) 11437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 12000 Counter(12000) 11937
Saved chunk: 20230921T215338F474890-0PMwNTiZiMI41EzoSgyToW-5srPz2XIfQBJBCAEGDokP6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215359F722500-3opKITBnaaqlmFCTwsWV0r-2rM42f3M8dq6Ri6iKG7WBx-1024.npz
Starting evaluation at step 12500 Counter(12500) 12437
eval_Episode has 500 steps and return 1.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 25294 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 1 / eval_episode/reward_rate 2e-3 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.53 / train/action_max 4.46 / train/action_mean 0.16 / train/action_min -4.19 / train/action_std 1.11 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.2e-5 / train/actor_opt_grad_steps 4810 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 4.2e-7 / train/cont_loss_std 4.1e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.26 / train/dyn_loss_std 
4.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 4810 / train/extr_critic_critic_opt_loss 27.3 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 1.4e-24 / train/extr_return_normed_max 1.4e-24 / train/extr_return_normed_mean 1.4e-24 / 
train/extr_return_normed_min 1.4e-24 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 
0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2.36 / train/image_loss_std 2.67 / train/model_loss_mean 3.72 / train/model_loss_std 4.12 / train/model_opt_grad_norm 18 / 
train/model_opt_grad_steps 4801 / train/model_opt_loss 1554.99 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 421.79 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.36 / train/policy_entropy_std 3e-3 / train/policy_logprob_mag 9.36 / train/policy_logprob_max -0.88 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.36 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.97 / train/policy_randomness_std 1.3e-3 / train/post_ent_mag 35.46 / train/post_ent_max 35.46 / train/post_ent_mean 20.18 / train/post_ent_min 12.88 / train/post_ent_std 3.44 / 
train/prior_ent_mag 49.63 / train/prior_ent_max 49.63 / train/prior_ent_mean 23.16 / train/prior_ent_min 15.09 / train/prior_ent_std 5.09 / train/rep_loss_mean 2.26 / train/rep_loss_std 4.05 / train/reward_avg 0 / train/reward_loss_mean 1.5e-4 / train/reward_loss_std 
1.6e-6 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-4 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 1.7e-7 / report/cont_loss_std 1.5e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-7 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 2.26 / report/dyn_loss_std 4.11 / report/image_loss_mean 2.17 / report/image_loss_std 2.61 / report/model_loss_mean 3.53 / report/model_loss_std 4.15 / report/post_ent_mag 35.22 / report/post_ent_max 35.22 / report/post_ent_mean 20.12 / 
report/post_ent_min 12.56 / report/post_ent_std 3 / report/prior_ent_mag 50.22 / report/prior_ent_max 50.22 / report/prior_ent_mean 23.59 / report/prior_ent_min 14.92 / report/prior_ent_std 4.76 / report/rep_loss_mean 2.26 / report/rep_loss_std 4.11 / report/reward_avg 0 
/ report/reward_loss_mean 8e-5 / report/reward_loss_std 8.5e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 8e-5 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / 
report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-7 / eval/cont_loss_std 3e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-7 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.91 / 
eval/dyn_loss_std 5.73 / eval/image_loss_mean 5.01 / eval/image_loss_std 4.86 / eval/model_loss_mean 7.35 / eval/model_loss_std 6.99 / eval/post_ent_mag 39.33 / eval/post_ent_max 39.33 / eval/post_ent_mean 22.8 / eval/post_ent_min 13.96 / eval/post_ent_std 4.18 / 
eval/prior_ent_mag 50.22 / eval/prior_ent_max 50.22 / eval/prior_ent_mean 26.06 / eval/prior_ent_min 15.62 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 3.91 / eval/rep_loss_std 5.73 / eval/reward_avg 0 / eval/reward_loss_mean 8.1e-5 / eval/reward_loss_std 1.4e-6 / 
eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.1e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.3e4 / replay/inserts 3858 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.3e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3858 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 382.21 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7866 / timer/agent.policy_total 16.83 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.11 / timer/dataset_train_count 1929 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1929 / 
timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.71

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 13000 Counter(13000) 12937
Saved chunk: 20230921T215456F150045-5srPz2XIfQBJBCAEGDokP6-3DUA0c5KUHq3bnwn0FwfYW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215518F655682-2rM42f3M8dq6Ri6iKG7WBx-0UEMm3xEUiglHWJtzDmF8o-1024.npz
Starting evaluation at step 13500 Counter(13500) 13437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 14000 Counter(14000) 13937
Saved chunk: 20230921T215614F119790-3DUA0c5KUHq3bnwn0FwfYW-7oPjIwkpx3N9OL85kVYRjb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215638F313760-0UEMm3xEUiglHWJtzDmF8o-4wnDjsCpUb3qHbHncw7lK9-1024.npz
Starting evaluation at step 14500 Counter(14500) 14437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 3.0.
Starting evaluation at step 15000 Counter(15000) 14937
Saved chunk: 20230921T215731F791906-7oPjIwkpx3N9OL85kVYRjb-11N3AhiCIQ8mAqqYpA0QK0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215757F454808-4wnDjsCpUb3qHbHncw7lK9-3CNWIEfXzFSY8wi8XmfEAU-1024.npz
Starting evaluation at step 15500 Counter(15500) 15437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 16000 Counter(16000) 15937
Saved chunk: 20230921T215849F233879-11N3AhiCIQ8mAqqYpA0QK0-2Y5opWUQWJTKwKiZ88Puaz-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215916F459679-3CNWIEfXzFSY8wi8XmfEAU-7sqX9McdgCkmEQjdmqVKDR-1024.npz
Starting evaluation at step 16500 Counter(16500) 16437
eval_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 33010 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.09 / train/action_mean -0.32 / train/action_min -4.6 / train/action_std 1.11 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.2e-4 / train/actor_opt_grad_steps 6740 / train/actor_opt_loss -6.54 / train/adv_mag 0.08 / train/adv_max 0.08 / train/adv_mean 2.4e-4 / train/adv_min -1.4e-3
/ train/adv_std 2.6e-3 / train/cont_avg 1 / train/cont_loss_mean 1e-7 / train/cont_loss_std 1.3e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.45 / 
train/dyn_loss_std 4.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 6740 / train/extr_critic_critic_opt_loss 
196.57 / train/extr_critic_mag 3.5e-3 / train/extr_critic_max -inf / train/extr_critic_mean 1.8e-4 / train/extr_critic_min 1.2e-4 / train/extr_critic_std 1.9e-4 / train/extr_return_normed_mag 0.08 / train/extr_return_normed_max 0.08 / train/extr_return_normed_mean 3.2e-4 
/ train/extr_return_normed_min 2.4e-5 / train/extr_return_normed_std 2.8e-3 / train/extr_return_rate 1e-4 / train/extr_return_raw_mag 0.08 / train/extr_return_raw_max 0.08 / train/extr_return_raw_mean 4.2e-4 / train/extr_return_raw_min 1.3e-4 / train/extr_return_raw_std 
2.8e-3 / train/extr_reward_mag 0.04 / train/extr_reward_max -inf / train/extr_reward_mean 3.6e-5 / train/extr_reward_min 4.4e-6 / train/extr_reward_std 6.9e-4 / train/image_loss_mean 1.95 / train/image_loss_std 2.16 / train/model_loss_mean 3.42 / train/model_loss_std 4.02
/ train/model_opt_grad_norm 16.48 / train/model_opt_grad_steps 6731 / train/model_opt_loss 5395.34 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1619.17 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.33 / train/policy_entropy_std 3.7e-3 / train/policy_logprob_mag 9.39 / train/policy_logprob_max -0.87 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.39 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.96 / train/policy_randomness_std 1.6e-3 / train/post_ent_mag 36.78 / train/post_ent_max 36.78 / train/post_ent_mean 20.97 / train/post_ent_min 
13.19 / train/post_ent_std 3.4 / train/prior_ent_mag 52.44 / train/prior_ent_max 52.44 / train/prior_ent_mean 23.99 / train/prior_ent_min 15.19 / train/prior_ent_std 5.31 / train/rep_loss_mean 2.45 / train/rep_loss_std 4.51 / train/reward_avg 6.1e-5 / 
train/reward_loss_mean 1.8e-4 / train/reward_loss_std 2.2e-3 / train/reward_max_data 0.04 / train/reward_max_pred 0.02 / train/reward_neg_acc 1 / train/reward_neg_loss 1e-4 / train/reward_pos_acc 1 / train/reward_pos_loss 1.84 / train/reward_pred 4.9e-5 / 
train/reward_rate 4e-5 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 6.1e-8 / report/cont_loss_std 8.7e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
6.1e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.65 / report/dyn_loss_std 4.75 / report/image_loss_mean 2.18 / report/image_loss_std 2.25 / report/model_loss_mean 3.77 / report/model_loss_std 4.19 / report/post_ent_mag 36.93 / report/post_ent_max 
36.93 / report/post_ent_mean 20.8 / report/post_ent_min 13.31 / report/post_ent_std 3.37 / report/prior_ent_mag 54.51 / report/prior_ent_max 54.51 / report/prior_ent_mean 24.07 / report/prior_ent_min 15.44 / report/prior_ent_std 5.72 / report/rep_loss_mean 2.65 / 
report/rep_loss_std 4.75 / report/reward_avg 0 / report/reward_loss_mean 3.4e-5 / report/reward_loss_std 1.3e-6 / report/reward_max_data 0 / report/reward_max_pred 1.5e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 3.4e-5 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 7.5e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-8 / eval/cont_loss_std 1.1e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-8 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 5.98 / eval/dyn_loss_std 8.37 / eval/image_loss_mean 4.18 / eval/image_loss_std 4.75 / eval/model_loss_mean 7.76 / eval/model_loss_std 9.1 / eval/post_ent_mag 54.44 / eval/post_ent_max 54.44 / eval/post_ent_mean 22.67 / 
eval/post_ent_min 12.47 / eval/post_ent_std 7.11 / eval/prior_ent_mag 54.51 / eval/prior_ent_max 54.51 / eval/prior_ent_mean 26.11 / eval/prior_ent_min 16.28 / eval/prior_ent_std 7.12 / eval/rep_loss_mean 5.98 / eval/rep_loss_std 8.37 / eval/reward_avg 0 / 
eval/reward_loss_mean 3.7e-5 / eval/reward_loss_std 3.1e-5 / eval/reward_max_data 0 / eval/reward_max_pred 6.1e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.7e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 8.9e-6 / eval/reward_rate 0 / 
replay/size 1.6e4 / replay/inserts 3858 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3858 / timer/env.step_total 19.13 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 382.55 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7866 / timer/agent.policy_total 16.77 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.06 / 
timer/dataset_train_count 1929 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1929 / timer/agent.train_total 243.76 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.18 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.72

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 17000 Counter(17000) 16937
Saved chunk: 20230921T220006F721137-2Y5opWUQWJTKwKiZ88Puaz-2OfQDlDfctc2CRQdb4ZFLP-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220035F429473-7sqX9McdgCkmEQjdmqVKDR-0GoTkShET8DUFyoiMBJxk9-1024.npz
Starting evaluation at step 17500 Counter(17500) 17437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 18000 Counter(18000) 17937
Saved chunk: 20230921T220124F766978-2OfQDlDfctc2CRQdb4ZFLP-7uNRusMv2VNLNvVfVxbos0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220155F180394-0GoTkShET8DUFyoiMBJxk9-5wxCH8m5oE5OwEDurEfbfH-1024.npz
Starting evaluation at step 18500 Counter(18500) 18437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 19000 Counter(19000) 18937
Saved chunk: 20230921T220242F405119-7uNRusMv2VNLNvVfVxbos0-4Gl0iEEctsSPO8WPyZFWKp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220314F330396-5wxCH8m5oE5OwEDurEfbfH-6pxkgWgB9yAMUkcjdNlRH2-1024.npz
Starting evaluation at step 19500 Counter(19500) 19437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 20000 Counter(20000) 19937
Saved chunk: 20230921T220359F959540-4Gl0iEEctsSPO8WPyZFWKp-0l18RD9t7A4e1yBnCcvSnJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 40822 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.78 / train/action_max 2.81 / train/action_mean -0.99 / train/action_min -4.78 / train/action_std 0.84 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.9e-3 / train/actor_opt_grad_steps 8680 / train/actor_opt_loss -31.69 / train/adv_mag 0.65 / train/adv_max 0.64 / train/adv_mean 2.9e-3 / train/adv_min -0.12 
/ train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3e-8 / train/cont_loss_std 4.6e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.28 / 
train/dyn_loss_std 4.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 8680 / train/extr_critic_critic_opt_loss 
6512.25 / train/extr_critic_mag 0.23 / train/extr_critic_max 0.23 / train/extr_critic_mean 0.03 / train/extr_critic_min 2.8e-3 / train/extr_critic_std 0.03 / train/extr_return_normed_mag 0.77 / train/extr_return_normed_max 0.77 / train/extr_return_normed_mean 0.03 / 
train/extr_return_normed_min -7.4e-4 / train/extr_return_normed_std 0.05 / train/extr_return_rate 1.4e-3 / train/extr_return_raw_mag 0.78 / train/extr_return_raw_max 0.78 / train/extr_return_raw_mean 0.03 / train/extr_return_raw_min 3.1e-3 / train/extr_return_raw_std 0.05
/ train/extr_reward_mag 0.35 / train/extr_reward_max 0.35 / train/extr_reward_mean 2.2e-4 / train/extr_reward_min 2.7e-6 / train/extr_reward_std 6.7e-3 / train/image_loss_mean 1.27 / train/image_loss_std 1.38 / train/model_loss_mean 2.64 / train/model_loss_std 3.52 / 
train/model_opt_grad_norm 14.2 / train/model_opt_grad_steps 8670.31 / train/model_opt_loss 8755.27 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3320.51 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.06 / train/policy_entropy_min -0.65 / train/policy_entropy_std 0.47 / train/policy_logprob_mag 9.26 / train/policy_logprob_max 1.11 / train/policy_logprob_mean -1.06 / train/policy_logprob_min -9.26 / train/policy_logprob_std 0.87 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.84 / train/policy_randomness_min 0.1 / train/policy_randomness_std 0.2 / train/post_ent_mag 39.16 / train/post_ent_max 39.16 / train/post_ent_mean 21.78 / train/post_ent_min 
14.05 / train/post_ent_std 3.4 / train/prior_ent_mag 54.22 / train/prior_ent_max 54.22 / train/prior_ent_mean 24.47 / train/prior_ent_min 15.95 / train/prior_ent_std 5.27 / train/rep_loss_mean 2.28 / train/rep_loss_std 4.53 / train/reward_avg 1.2e-4 / 
train/reward_loss_mean 1.3e-4 / train/reward_loss_std 2.4e-3 / train/reward_max_data 0.08 / train/reward_max_pred 0.05 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-5 / train/reward_pos_acc 1 / train/reward_pos_loss 1.18 / train/reward_pred 1.1e-4 / 
train/reward_rate 8e-5 / train_stats/mean_log_entropy 1.37 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-8 / report/cont_loss_std 1.5e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
1.5e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.05 / report/dyn_loss_std 4.17 / report/image_loss_mean 0.9 / report/image_loss_std 0.92 / report/model_loss_mean 2.13 / report/model_loss_std 2.99 / report/post_ent_mag 41.08 / report/post_ent_max 
41.08 / report/post_ent_mean 21.24 / report/post_ent_min 13.7 / report/post_ent_std 3.45 / report/prior_ent_mag 54.97 / report/prior_ent_max 54.97 / report/prior_ent_mean 23.7 / report/prior_ent_min 15.45 / report/prior_ent_std 5.24 / report/rep_loss_mean 2.05 / 
report/rep_loss_std 4.17 / report/reward_avg 0 / report/reward_loss_mean 1.1e-5 / report/reward_loss_std 5.4e-6 / report/reward_max_data 0 / report/reward_max_pred 1.3e-5 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-5 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 1.3e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-8 / eval/cont_loss_std 3.2e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-8 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 6.95 / eval/dyn_loss_std 9.43 / eval/image_loss_mean 3.6 / eval/image_loss_std 4.58 / eval/model_loss_mean 7.77 / eval/model_loss_std 9.56 / eval/post_ent_mag 47.34 / eval/post_ent_max 47.34 / eval/post_ent_mean 22.87 / 
eval/post_ent_min 12.34 / eval/post_ent_std 5.44 / eval/prior_ent_mag 54.97 / eval/prior_ent_max 54.97 / eval/prior_ent_mean 26.59 / eval/prior_ent_min 16.3 / eval/prior_ent_std 5.98 / eval/rep_loss_mean 6.95 / eval/rep_loss_std 9.43 / eval/reward_avg 0 / 
eval/reward_loss_mean 1e-5 / eval/reward_loss_std 1.5e-6 / eval/reward_max_data 0 / eval/reward_max_pred 4.6e-6 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.3e-6 / eval/reward_rate 0 / 
replay/size 2e4 / replay/inserts 3906 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.1e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3906 / timer/env.step_total 19.48 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.92 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7413 / timer/agent.policy_total 15.83 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1953 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1953 / timer/agent.train_total 246.68 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 26.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T220433F372794-6pxkgWgB9yAMUkcjdNlRH2-0Z9X2nJCdNQPtQGX9LJ9bq-1024.npz
Starting evaluation at step 20500 Counter(20500) 20437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21000 Counter(21000) 20937
Saved chunk: 20230921T220517F314111-0l18RD9t7A4e1yBnCcvSnJ-4Txs6LFPfYnQoXZWpQIGza-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 3.0.
Starting evaluation at step 21500 Counter(21500) 21437
eval_Episode has 500 steps and return 6.0.
Saved chunk: 20230921T220552F797068-0Z9X2nJCdNQPtQGX9LJ9bq-6xzr9poE2SQ4gskO5CB2rU-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22000 Counter(22000) 21937
Saved chunk: 20230921T220635F571356-4Txs6LFPfYnQoXZWpQIGza-45ZuSkx4SYBlDUKjLFkWzK-1024.npz
eval_Episode has 500 steps and return 12.0.
train_Episode has 500 steps and return 8.0.
Starting evaluation at step 22500 Counter(22500) 22437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220715F546359-6xzr9poE2SQ4gskO5CB2rU-3Vog9b1Ka2klWRCVcBnshx-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T220834F645084-3Vog9b1Ka2klWRCVcBnshx-0000000000000000000000-272.npz
Saved chunk: 20230921T220753F186811-45ZuSkx4SYBlDUKjLFkWzK-0000000000000000000000-616.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 23000 Counter(23000) 22937
Saved chunk: 20230921T220753F186811-45ZuSkx4SYBlDUKjLFkWzK-2x7HdiAoS5w4vsDOayhI2J-1024.npz
eval_Episode has 500 steps and return 8.0.
train_Episode has 500 steps and return 3.0.
Starting evaluation at step 23500 Counter(23500) 23437
eval_Episode has 500 steps and return 10.0.
train_Episode has 500 steps and return 7.0.
Saved chunk: 20230921T220834F645084-3Vog9b1Ka2klWRCVcBnshx-3esLWyeJl9jb5bkX4VFbYn-1024.npz
Starting evaluation at step 24000 Counter(24000) 23937
Saved chunk: 20230921T220910F846018-2x7HdiAoS5w4vsDOayhI2J-3WVbtKhS5J2ZGtaWOAjxx3-1024.npz
eval_Episode has 500 steps and return 16.0.
train_Episode has 500 steps and return 7.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 48530 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 16 / eval_episode/reward_rate 0.02 / episode/length 500 / episode/score 7 / episode/reward_rate 8e-3 / train/action_mag 4.16 / train/action_max 3.98 / train/action_mean 0.08 / train/action_min -3.07 / train/action_std 1.03 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.02 / train/actor_opt_grad_steps 1.1e4 / train/actor_opt_loss -117.06 / train/adv_mag 1.21 / train/adv_max 1.19 / train/adv_mean 0.01 / train/adv_min -0.29 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.2e-8 / train/cont_loss_std 2.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.36 / 
train/dyn_loss_std 4.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.28 / train/extr_critic_critic_opt_grad_steps 1.1e4 / train/extr_critic_critic_opt_loss 
9773.54 / train/extr_critic_mag 0.64 / train/extr_critic_max 0.64 / train/extr_critic_mean 0.21 / train/extr_critic_min 0.08 / train/extr_critic_std 0.08 / train/extr_return_normed_mag 1.5 / train/extr_return_normed_max 1.5 / train/extr_return_normed_mean 0.13 / 
train/extr_return_normed_min -5.4e-3 / train/extr_return_normed_std 0.11 / train/extr_return_rate 0.04 / train/extr_return_raw_mag 1.6 / train/extr_return_raw_max 1.6 / train/extr_return_raw_mean 0.22 / train/extr_return_raw_min 0.09 / train/extr_return_raw_std 0.11 / 
train/extr_reward_mag 0.5 / train/extr_reward_max 0.5 / train/extr_reward_mean 4.8e-4 / train/extr_reward_min 2.1e-6 / train/extr_reward_std 0.01 / train/image_loss_mean 1.01 / train/image_loss_std 1.23 / train/model_loss_mean 2.43 / train/model_loss_std 3.62 / 
train/model_opt_grad_norm 13.87 / train/model_opt_grad_steps 1.1e4 / train/model_opt_loss 6390.52 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 2629.53 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / 
train/policy_entropy_mean 0.22 / train/policy_entropy_min -0.86 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.47 / train/policy_logprob_max 1.34 / train/policy_logprob_mean -0.22 / train/policy_logprob_min -8.47 / train/policy_logprob_std 1.01 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 0.01 / train/policy_randomness_std 0.31 / train/post_ent_mag 42.11 / train/post_ent_max 42.11 / train/post_ent_mean 23.06 / 
train/post_ent_min 14.83 / train/post_ent_std 3.51 / train/prior_ent_mag 56.42 / train/prior_ent_max 56.42 / train/prior_ent_mean 25.76 / train/prior_ent_min 17.13 / train/prior_ent_std 5.45 / train/rep_loss_mean 2.36 / train/rep_loss_std 4.78 / train/reward_avg 7.2e-4 / 
train/reward_loss_mean 9e-4 / train/reward_loss_std 0.02 / train/reward_max_data 0.3 / train/reward_max_pred 0.2 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-4 / train/reward_pos_acc 0.84 / train/reward_pos_loss 1.78 / train/reward_pred 5.1e-4 / train/reward_rate
4.3e-4 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.3 / report/cont_avg 1 / report/cont_loss_mean 5.4e-9 / report/cont_loss_std 7e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.4e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.26 / report/dyn_loss_std 4.86 / report/image_loss_mean 0.77 / report/image_loss_std 1.02 / report/model_loss_mean 2.13 / report/model_loss_std 3.51 / report/post_ent_mag 40.07 / report/post_ent_max 40.07 / 
report/post_ent_mean 23.95 / report/post_ent_min 15.82 / report/post_ent_std 3.61 / report/prior_ent_mag 57.61 / report/prior_ent_max 57.61 / report/prior_ent_mean 26.96 / report/prior_ent_min 17.71 / report/prior_ent_std 5.36 / report/rep_loss_mean 2.26 / 
report/rep_loss_std 4.86 / report/reward_avg 0 / report/reward_loss_mean 1.2e-5 / report/reward_loss_std 3.8e-5 / report/reward_max_data 0 / report/reward_max_pred 8.6e-4 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-5 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 6.6e-6 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-8 / eval/cont_loss_std 4.5e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-8 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 3.92 / eval/dyn_loss_std 6.35 / eval/image_loss_mean 1.66 / eval/image_loss_std 1.75 / eval/model_loss_mean 4.01 / eval/model_loss_std 5.01 / eval/post_ent_mag 43.43 / eval/post_ent_max 43.43 / eval/post_ent_mean 23.5 / 
eval/post_ent_min 15.06 / eval/post_ent_std 4.18 / eval/prior_ent_mag 57.61 / eval/prior_ent_max 57.61 / eval/prior_ent_mean 27.28 / eval/prior_ent_min 17.41 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 3.92 / eval/rep_loss_std 6.35 / eval/reward_avg 0 / 
eval/reward_loss_mean 9.7e-6 / eval/reward_loss_std 2.6e-5 / eval/reward_max_data 0 / eval/reward_max_pred 7e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.7e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 4.9e-6 / eval/reward_rate 0 / 
replay/size 2.4e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3854 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 380.38 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.83 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1927 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.6e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1927 / timer/agent.train_total 243.75 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / 
timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 24500 Counter(24500) 24437
eval_Episode has 500 steps and return 22.0.
train_Episode has 500 steps and return 13.0.
Saved chunk: 20230921T220953F778466-3esLWyeJl9jb5bkX4VFbYn-55NfwXjbcEPZ5eMUeHUhlK-1024.npz
Starting evaluation at step 25000 Counter(25000) 24937
Saved chunk: 20230921T221028F291690-3WVbtKhS5J2ZGtaWOAjxx3-37HWbASus9NWn4SMu2PK4U-1024.npz
eval_Episode has 500 steps and return 24.0.
train_Episode has 500 steps and return 10.0.
Starting evaluation at step 25500 Counter(25500) 25437
eval_Episode has 500 steps and return 8.0.
train_Episode has 500 steps and return 22.0.
Saved chunk: 20230921T221113F962020-55NfwXjbcEPZ5eMUeHUhlK-1yKjXBUYDLqyo0TOcfGavw-1024.npz
Starting evaluation at step 26000 Counter(26000) 25937
Saved chunk: 20230921T221147F035100-37HWbASus9NWn4SMu2PK4U-6DXNHtuxwhwKokM0gQC95x-1024.npz
eval_Episode has 500 steps and return 5.0.
train_Episode has 500 steps and return 10.0.
Starting evaluation at step 26500 Counter(26500) 26437
eval_Episode has 500 steps and return 20.0.
train_Episode has 500 steps and return 24.0.
Saved chunk: 20230921T221233F190954-1yKjXBUYDLqyo0TOcfGavw-0xgS4fL3NISsMhNNeCJ5gC-1024.npz
Starting evaluation at step 27000 Counter(27000) 26937
eval_Episode has 500 steps and return 32.0.
Saved chunk: 20230921T221304F545016-6DXNHtuxwhwKokM0gQC95x-6pw2qZAACMCH53m0ttrI1W-1024.npz
train_Episode has 500 steps and return 31.0.
Starting evaluation at step 27500 Counter(27500) 27437
eval_Episode has 500 steps and return 30.0.
train_Episode has 500 steps and return 38.0.
Saved chunk: 20230921T221352F116062-0xgS4fL3NISsMhNNeCJ5gC-2EMmWlsGxILTNflNldB09q-1024.npz
Starting evaluation at step 28000 Counter(28000) 27937
eval_Episode has 500 steps and return 27.0.
train_Episode has 500 steps and return 26.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 56238 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 27 / eval_episode/reward_rate 0.05 / episode/length 500 / episode/score 26 / episode/reward_rate 0.04 / train/action_mag 3.03 / train/action_max 3.03 / train/action_mean 0.21 / train/action_min -2.12 / train/action_std 0.96 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.3e4 / train/actor_opt_loss -437.6 / train/adv_mag 3.76 / train/adv_max 3.75 / train/adv_mean 0.04 / train/adv_min -1.03 / 
train/adv_std 0.19 / train/cont_avg 1 / train/cont_loss_mean 4.6e-9 / train/cont_loss_std 8.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.66 / 
train/dyn_loss_std 5.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.55 / train/extr_critic_critic_opt_grad_steps 1.3e4 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 2.12 / train/extr_critic_max 2.12 / train/extr_critic_mean 0.89 / train/extr_critic_min 0.47 / train/extr_critic_std 0.27 / train/extr_return_normed_mag 4.93 / train/extr_return_normed_max 4.93 / train/extr_return_normed_mean 0.36 / 
train/extr_return_normed_min -0.03 / train/extr_return_normed_std 0.35 / train/extr_return_rate 0.83 / train/extr_return_raw_mag 5.95 / train/extr_return_raw_max 5.95 / train/extr_return_raw_mean 0.94 / train/extr_return_raw_min 0.51 / train/extr_return_raw_std 0.39 / 
train/extr_reward_mag 1.54 / train/extr_reward_max 1.54 / train/extr_reward_mean 4.3e-3 / train/extr_reward_min 1e-6 / train/extr_reward_std 0.06 / train/image_loss_mean 1.06 / train/image_loss_std 1.18 / train/model_loss_mean 2.66 / train/model_loss_std 3.87 / 
train/model_opt_grad_norm 14.09 / train/model_opt_grad_steps 1.3e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4766.84 / train/policy_entropy_mag 1.25 / train/policy_entropy_max 1.25 / 
train/policy_entropy_mean -0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.48 / train/policy_logprob_mag 7.91 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.41 / train/policy_logprob_min -7.91 / train/policy_logprob_std 0.86 / 
train/policy_randomness_mag 0.93 / train/policy_randomness_max 0.93 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 1.5e-3 / train/policy_randomness_std 0.21 / train/post_ent_mag 44.95 / train/post_ent_max 44.95 / train/post_ent_mean 24.32 / 
train/post_ent_min 15.51 / train/post_ent_std 3.41 / train/prior_ent_mag 59.94 / train/prior_ent_max 59.94 / train/prior_ent_mean 27.28 / train/prior_ent_min 18.26 / train/prior_ent_std 5.65 / train/rep_loss_mean 2.66 / train/rep_loss_std 5.18 / train/reward_avg 4.6e-3 / 
train/reward_loss_mean 3.6e-3 / train/reward_loss_std 0.06 / train/reward_max_data 1.22 / train/reward_max_pred 1.03 / train/reward_neg_acc 1 / train/reward_neg_loss 7.3e-4 / train/reward_pos_acc 0.97 / train/reward_pos_loss 1.11 / train/reward_pred 4.3e-3 / 
train/reward_rate 2.9e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.58 / report/cont_avg 1 / report/cont_loss_mean 3.6e-9 / report/cont_loss_std 4.8e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.6e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.52 / report/dyn_loss_std 4.89 / report/image_loss_mean 1.09 / report/image_loss_std 0.84 / report/model_loss_mean 2.62 / report/model_loss_std 3.43 / report/post_ent_mag 47.35 /
report/post_ent_max 47.35 / report/post_ent_mean 23.67 / report/post_ent_min 15.4 / report/post_ent_std 3.47 / report/prior_ent_mag 61.37 / report/prior_ent_max 61.37 / report/prior_ent_mean 26.99 / report/prior_ent_min 19.91 / report/prior_ent_std 5.69 / 
report/rep_loss_mean 2.52 / report/rep_loss_std 4.89 / report/reward_avg 0.02 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.2 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / 
report/reward_pos_acc 0.83 / report/reward_pos_loss 0.98 / report/reward_pred 0.02 / report/reward_rate 0.01 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-9 / eval/cont_loss_std 3.7e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 1.7e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.06 / eval/dyn_loss_std 3.94 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.66 / eval/model_loss_mean 1.68 / eval/model_loss_std 2.79 / eval/post_ent_mag 45.98 / eval/post_ent_max 
45.98 / eval/post_ent_mean 25.68 / eval/post_ent_min 16.65 / eval/post_ent_std 3.87 / eval/prior_ent_mag 61.37 / eval/prior_ent_max 61.37 / eval/prior_ent_mean 28.56 / eval/prior_ent_min 19.34 / eval/prior_ent_std 5.64 / eval/rep_loss_mean 2.06 / eval/rep_loss_std 3.94 / 
eval/reward_avg 0 / eval/reward_loss_mean 9.2e-6 / eval/reward_loss_std 1e-4 / eval/reward_max_data 0 / eval/reward_max_pred 2.3e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.2e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 5.7e-6 / 
eval/reward_rate 0 / replay/size 2.8e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.9e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3854 / timer/env.step_total 19.09 / timer/env.step_frac 0.06 / 
timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 7.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 380.86 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / 
timer/replay._sample_max 0.09 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.6 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 0.02 / timer/dataset_train_count 1927 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.5e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1927 / 
timer/agent.train_total 243.66 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 28500 Counter(28500) 28437
Saved chunk: 20230921T221421F901690-6pw2qZAACMCH53m0ttrI1W-6CYGLZHYB0HhqvPjsSYweA-1024.npz
eval_Episode has 500 steps and return 27.0.
train_Episode has 500 steps and return 30.0.
Saved chunk: 20230921T221510F998061-2EMmWlsGxILTNflNldB09q-1F7WoAX5UnZnq4vrMfOQPk-1024.npz
Starting evaluation at step 29000 Counter(29000) 28937
eval_Episode has 500 steps and return 27.0.
train_Episode has 500 steps and return 26.0.
Starting evaluation at step 29500 Counter(29500) 29437
Saved chunk: 20230921T221615F302263-6CYGLZHYB0HhqvPjsSYweA-62c3KmfDZUHxf6CNx1CcUE-1024.npz
eval_Episode has 500 steps and return 30.0.
train_Episode has 500 steps and return 26.0.
Saved chunk: 20230921T221630F729298-1F7WoAX5UnZnq4vrMfOQPk-4tKJd73M2FL6ZSpy1C29ES-1024.npz
Starting evaluation at step 30000 Counter(30000) 29937
eval_Episode has 500 steps and return 29.0.
train_Episode has 500 steps and return 23.0.
Starting evaluation at step 30500 Counter(30500) 30437
Saved chunk: 20230921T221733F086968-62c3KmfDZUHxf6CNx1CcUE-1ZTuYuEIDPFRaNOSE3zmoV-1024.npz
eval_Episode has 500 steps and return 29.0.
train_Episode has 500 steps and return 33.0.
Saved chunk: 20230921T221750F054309-4tKJd73M2FL6ZSpy1C29ES-67J8Ldy04Mxr747h3aMfcV-1024.npz
Starting evaluation at step 31000 Counter(31000) 30937
eval_Episode has 500 steps and return 25.0.
train_Episode has 500 steps and return 32.0.
Starting evaluation at step 31500 Counter(31500) 31437
Saved chunk: 20230921T221850F830667-1ZTuYuEIDPFRaNOSE3zmoV-6TWBIAV0skcxOqg7W601ul-1024.npz
eval_Episode has 500 steps and return 18.0.
train_Episode has 500 steps and return 28.0.
Saved chunk: 20230921T221909F304903-67J8Ldy04Mxr747h3aMfcV-5fytYKjAnUrqMNFjTGsmwx-1024.npz
Starting evaluation at step 32000 Counter(32000) 31937
eval_Episode has 500 steps and return 29.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 64002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 29 / eval_episode/reward_rate 0.04 / episode/length 500 / episode/score 28 / episode/reward_rate 0.04 / train/action_mag 3.16 / train/action_max 3.16 / train/action_mean 0.15 / train/action_min -1.99 / train/action_std 0.96 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 1.4e4 / train/actor_opt_loss -477.28 / train/adv_mag 2.22 / train/adv_max 2.2 / train/adv_mean 0.05 / train/adv_min -0.95 / 
train/adv_std 0.13 / train/cont_avg 1 / train/cont_loss_mean 2.5e-9 / train/cont_loss_std 4.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.66 / 
train/dyn_loss_std 5.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.75 / train/extr_critic_critic_opt_grad_steps 1.4e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 5.61 / train/extr_critic_max 5.61 / train/extr_critic_mean 3.03 / train/extr_critic_min 1.61 / train/extr_critic_std 0.83 / train/extr_return_normed_mag 3.22 / train/extr_return_normed_max 3.22 / train/extr_return_normed_mean 0.46 / 
train/extr_return_normed_min -0.03 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 10.33 / train/extr_return_raw_max 10.33 / train/extr_return_raw_mean 3.16 / train/extr_return_raw_min 1.8 / train/extr_return_raw_std 0.98 / 
train/extr_reward_mag 1.92 / train/extr_reward_max 1.92 / train/extr_reward_mean 0.01 / train/extr_reward_min 2.4e-7 / train/extr_reward_std 0.12 / train/image_loss_mean 0.99 / train/image_loss_std 1.01 / train/model_loss_mean 2.6 / train/model_loss_std 3.86 / 
train/model_opt_grad_norm 12.66 / train/model_opt_grad_steps 1.4e4 / train/model_opt_loss 9531.34 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 3672.68 / train/policy_entropy_mag 1.3 / train/policy_entropy_max 1.3 / 
train/policy_entropy_mean -0.54 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.44 / train/policy_logprob_mag 7.47 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.54 / train/policy_logprob_min -7.47 / train/policy_logprob_std 0.83 / 
train/policy_randomness_mag 0.95 / train/policy_randomness_max 0.95 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 8.5e-4 / train/policy_randomness_std 0.19 / train/post_ent_mag 47.21 / train/post_ent_max 47.21 / train/post_ent_mean 25.28 / 
train/post_ent_min 15.94 / train/post_ent_std 3.39 / train/prior_ent_mag 62.72 / train/prior_ent_max 62.72 / train/prior_ent_mean 28.19 / train/prior_ent_min 19.49 / train/prior_ent_std 5.63 / train/rep_loss_mean 2.66 / train/rep_loss_std 5.36 / train/reward_avg 0.01 / 
train/reward_loss_mean 8.2e-3 / train/reward_loss_std 0.1 / train/reward_max_data 1.74 / train/reward_max_pred 1.67 / train/reward_neg_acc 1 / train/reward_neg_loss 1.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.87 / train/reward_pred 0.01 / 
train/reward_rate 7.6e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.63 / report/cont_avg 1 / report/cont_loss_mean 1.4e-9 / report/cont_loss_std 1.8e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.4e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.4 / report/dyn_loss_std 4.76 / report/image_loss_mean 0.75 / report/image_loss_std 0.85 / report/model_loss_mean 2.19 / report/model_loss_std 3.42 / report/post_ent_mag 49.45 / 
report/post_ent_max 49.45 / report/post_ent_mean 26.46 / report/post_ent_min 15.95 / report/post_ent_std 3.79 / report/prior_ent_mag 63.52 / report/prior_ent_max 63.52 / report/prior_ent_mean 29.15 / report/prior_ent_min 20.15 / report/prior_ent_std 6.08 / 
report/rep_loss_mean 2.4 / report/rep_loss_std 4.76 / report/reward_avg 7.8e-3 / report/reward_loss_mean 2.9e-3 / report/reward_loss_std 0.04 / report/reward_max_data 2 / report/reward_max_pred 1.98 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.56 / report/reward_pred 6.9e-3 / report/reward_rate 4.9e-3 / eval/cont_avg 1 / eval/cont_loss_mean 8.2e-10 / eval/cont_loss_std 8.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 8.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.17 / eval/dyn_loss_std 4.81 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.66 / eval/model_loss_mean 1.75 / eval/model_loss_std 3.33 / eval/post_ent_mag 50.74 / eval/post_ent_max 
50.74 / eval/post_ent_mean 27.17 / eval/post_ent_min 18.23 / eval/post_ent_std 3.23 / eval/prior_ent_mag 63.52 / eval/prior_ent_max 63.52 / eval/prior_ent_mean 29.73 / eval/prior_ent_min 21.81 / eval/prior_ent_std 5.53 / eval/rep_loss_mean 2.17 / eval/rep_loss_std 4.81 / 
eval/reward_avg 0 / eval/reward_loss_mean 7.4e-7 / eval/reward_loss_std 8e-6 / eval/reward_max_data 0 / eval/reward_max_pred 1.9e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.4e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 4.9e-7 / 
eval/reward_rate 0 / replay/size 3.2e4 / replay/inserts 3882 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.3e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.36 / timer/env.step_count 3882 / timer/env.step_total 19.28 / timer/env.step_frac 0.06 /
timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.91 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-4 / 
timer/replay._sample_max 0.09 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7890 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 8.9e-3 / timer/dataset_train_count 1941 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 3.4e-4 / timer/agent.train_count 1941 / 
timer/agent.train_total 245.83 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 24.0.
Starting evaluation at step 32500 Counter(32500) 32437
Saved chunk: 20230921T222008F321663-6TWBIAV0skcxOqg7W601ul-2c770EbLubXyjNxtaiIji0-1024.npz
eval_Episode has 500 steps and return 31.0.
train_Episode has 500 steps and return 27.0.
Saved chunk: 20230921T222028F348633-5fytYKjAnUrqMNFjTGsmwx-7CiqvxHC3MuZ80rl5tgqx4-1024.npz
Starting evaluation at step 33000 Counter(33000) 32937
eval_Episode has 500 steps and return 24.0.
train_Episode has 500 steps and return 30.0.
Starting evaluation at step 33500 Counter(33500) 33437
Saved chunk: 20230921T222126F669298-2c770EbLubXyjNxtaiIji0-6s7UTpFmfWWTJdW6K9lrY5-1024.npz
eval_Episode has 500 steps and return 29.0.
train_Episode has 500 steps and return 31.0.
Saved chunk: 20230921T222148F317319-7CiqvxHC3MuZ80rl5tgqx4-0dzDS5PeeNxt55glmsJSbo-1024.npz
Starting evaluation at step 34000 Counter(34000) 33937
eval_Episode has 500 steps and return 31.0.
train_Episode has 500 steps and return 67.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T222244F343552-6s7UTpFmfWWTJdW6K9lrY5-0000000000000000000000-875.npz
Saved chunk: 20230921T222307F522799-0dzDS5PeeNxt55glmsJSbo-0000000000000000000000-608.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 34500 Counter(34500) 34437
Saved chunk: 20230921T222244F343552-6s7UTpFmfWWTJdW6K9lrY5-21y50ED6jsUBCOWcKIE6j2-1024.npz
eval_Episode has 500 steps and return 33.0.
train_Episode has 500 steps and return 24.0.
Saved chunk: 20230921T222307F522799-0dzDS5PeeNxt55glmsJSbo-4yOwx09lm5CbPlbdjfTskm-1024.npz
Starting evaluation at step 35000 Counter(35000) 34937
eval_Episode has 500 steps and return 32.0.
train_Episode has 500 steps and return 30.0.
Starting evaluation at step 35500 Counter(35500) 35437
Saved chunk: 20230921T222402F152230-21y50ED6jsUBCOWcKIE6j2-1quIDw1qdbGx16MZOwXehF-1024.npz
eval_Episode has 500 steps and return 31.0.
train_Episode has 500 steps and return 33.0.
Saved chunk: 20230921T222426F878405-4yOwx09lm5CbPlbdjfTskm-04xPsIb6DhTahZfs1Cc59l-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 71798 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 33 / episode/reward_rate 0.05 / eval_episode/length 500 / eval_episode/score 31 / eval_episode/reward_rate 0.05 / train/action_mag 3.07 / train/action_max 3.07 / train/action_mean 0.13 / train/action_min -1.99 / train/action_std 0.96 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.6e4 / train/actor_opt_loss -383.97 / train/adv_mag 1.62 / train/adv_max 1.6 / train/adv_mean 0.04 / train/adv_min -0.69 / 
train/adv_std 0.1 / train/cont_avg 1 / train/cont_loss_mean 1.6e-9 / train/cont_loss_std 2.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.65 / 
train/dyn_loss_std 5.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.62 / train/extr_critic_critic_opt_grad_steps 1.6e4 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 10 / train/extr_critic_max 10 / train/extr_critic_mean 6.82 / train/extr_critic_min 3.31 / train/extr_critic_std 1.33 / train/extr_return_normed_mag 2.48 / train/extr_return_normed_max 2.48 / train/extr_return_normed_mean 0.48 / 
train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 15.61 / train/extr_return_raw_max 15.61 / train/extr_return_raw_mean 6.99 / train/extr_return_raw_min 4.09 / train/extr_return_raw_std 1.47 / 
train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.02 / train/extr_reward_min 0 / train/extr_reward_std 0.15 / train/image_loss_mean 0.9 / train/image_loss_std 0.92 / train/model_loss_mean 2.5 / train/model_loss_std 3.91 / 
train/model_opt_grad_norm 11.8 / train/model_opt_grad_steps 1.6e4 / train/model_opt_loss 9386.14 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3769.23 / train/policy_entropy_mag 1.29 / train/policy_entropy_max 1.29 / 
train/policy_entropy_mean -0.57 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.4 / train/policy_logprob_mag 7.45 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.57 / train/policy_logprob_min -7.45 / train/policy_logprob_std 0.81 / 
train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 5.6e-4 / train/policy_randomness_std 0.17 / train/post_ent_mag 49.76 / train/post_ent_max 49.76 / train/post_ent_mean 26.23 / 
train/post_ent_min 16.46 / train/post_ent_std 3.53 / train/prior_ent_mag 64.54 / train/prior_ent_max 64.54 / train/prior_ent_mean 29.1 / train/prior_ent_min 19.91 / train/prior_ent_std 5.75 / train/rep_loss_mean 2.65 / train/rep_loss_std 5.52 / train/reward_avg 0.02 / 
train/reward_loss_mean 0.01 / train/reward_loss_std 0.11 / train/reward_max_data 1.9 / train/reward_max_pred 1.87 / train/reward_neg_acc 1 / train/reward_neg_loss 1.9e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.75 / train/reward_pred 0.02 / train/reward_rate 
0.01 / train_stats/mean_log_entropy -0.61 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.3e-9 / report/cont_loss_std 1.8e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.39 / report/dyn_loss_std 4.76 / report/image_loss_mean 0.86 / report/image_loss_std 0.68 / report/model_loss_mean 2.31 / report/model_loss_std 3.21 / report/post_ent_mag 52.68 / report/post_ent_max 52.68 / 
report/post_ent_mean 27.28 / report/post_ent_min 15.48 / report/post_ent_std 3.87 / report/prior_ent_mag 65.6 / report/prior_ent_max 65.6 / report/prior_ent_mean 29.84 / report/prior_ent_min 19.71 / report/prior_ent_std 5.89 / report/rep_loss_mean 2.39 / 
report/rep_loss_std 4.76 / report/reward_avg 0.04 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.57 / report/reward_pred 0.04 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-10 / eval/cont_loss_std 8.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.83 / eval/dyn_loss_std 7.51 / eval/image_loss_mean 1.06 / eval/image_loss_std 2.44 / eval/model_loss_mean 3.36 / eval/model_loss_std 6.56 / eval/post_ent_mag 51.47 / eval/post_ent_max 51.47 / eval/post_ent_mean 
27.39 / eval/post_ent_min 11.66 / eval/post_ent_std 4.61 / eval/prior_ent_mag 65.6 / eval/prior_ent_max 65.6 / eval/prior_ent_mean 30.69 / eval/prior_ent_min 21.79 / eval/prior_ent_std 5.96 / eval/rep_loss_mean 3.83 / eval/rep_loss_std 7.51 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.1e-7 / eval/reward_loss_std 1.1e-6 / eval/reward_max_data 0 / eval/reward_max_pred 2e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.1e-7 / eval/reward_rate 0 / 
replay/size 3.6e4 / replay/inserts 3898 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.6e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3898 / timer/env.step_total 19.37 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.23 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7405 / timer/agent.policy_total 16.04 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1949 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1949 / timer/agent.train_total 246.58 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.98

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 36000 Counter(36000) 35937
eval_Episode has 500 steps and return 32.0.
train_Episode has 500 steps and return 37.0.
Starting evaluation at step 36500 Counter(36500) 36437
Saved chunk: 20230921T222519F626260-1quIDw1qdbGx16MZOwXehF-0mskhe37o0RInlwgun9wJU-1024.npz
eval_Episode has 500 steps and return 32.0.
train_Episode has 500 steps and return 27.0.
Saved chunk: 20230921T222545F843877-04xPsIb6DhTahZfs1Cc59l-2zJIw0mKCpPZjbuZJu7xDR-1024.npz
Starting evaluation at step 37000 Counter(37000) 36937
eval_Episode has 500 steps and return 33.0.
train_Episode has 500 steps and return 41.0.
Starting evaluation at step 37500 Counter(37500) 37437
Saved chunk: 20230921T222637F909114-0mskhe37o0RInlwgun9wJU-4n6bWhRP2GsNHV5P7iPGGY-1024.npz
eval_Episode has 500 steps and return 34.0.
train_Episode has 500 steps and return 37.0.
Saved chunk: 20230921T222705F786506-2zJIw0mKCpPZjbuZJu7xDR-089Px2R1guVkSMJuLdmQyJ-1024.npz
Starting evaluation at step 38000 Counter(38000) 37937
eval_Episode has 500 steps and return 33.0.
train_Episode has 500 steps and return 38.0.
Starting evaluation at step 38500 Counter(38500) 38437
Saved chunk: 20230921T222755F605715-4n6bWhRP2GsNHV5P7iPGGY-3RNY7rFxuWA6Z2Jq415uu3-1024.npz
eval_Episode has 500 steps and return 32.0.
train_Episode has 500 steps and return 27.0.
Saved chunk: 20230921T222824F962922-089Px2R1guVkSMJuLdmQyJ-0ZVq7bEO2vwLANnkTZjaLK-1024.npz
Starting evaluation at step 39000 Counter(39000) 38937
eval_Episode has 500 steps and return 35.0.
train_Episode has 500 steps and return 34.0.
Starting evaluation at step 39500 Counter(39500) 39437
Saved chunk: 20230921T222913F088975-3RNY7rFxuWA6Z2Jq415uu3-6Obtack01nuSCj4DMsvgHP-1024.npz
eval_Episode has 500 steps and return 34.0.
train_Episode has 500 steps and return 36.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 79510 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 34 / eval_episode/reward_rate 0.05 / episode/length 500 / episode/score 36 / episode/reward_rate 0.05 / train/action_mag 2.88 / train/action_max 2.85 / train/action_mean 0.11 / train/action_min -2.19 / train/action_std 0.95 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 1.8e4 / train/actor_opt_loss -327.57 / train/adv_mag 1.8 / train/adv_max 1.78 / train/adv_mean 0.03 / train/adv_min -0.7 / 
train/adv_std 0.11 / train/cont_avg 1 / train/cont_loss_mean 9.3e-10 / train/cont_loss_std 1.6e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.64 / 
train/dyn_loss_std 5.69 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.52 / train/extr_critic_critic_opt_grad_steps 1.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 15.13 / train/extr_critic_max 15.13 / train/extr_critic_mean 10.9 / train/extr_critic_min 4.76 / train/extr_critic_std 1.67 / train/extr_return_normed_mag 2.74 / train/extr_return_normed_max 2.74 / train/extr_return_normed_mean 0.5 / 
train/extr_return_normed_min -0.59 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 22.47 / train/extr_return_raw_max 22.47 / train/extr_return_raw_mean 11.07 / train/extr_return_raw_min 5.52 / train/extr_return_raw_std 1.83 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.02 / train/extr_reward_min 0 / train/extr_reward_std 0.17 / train/image_loss_mean 0.82 / train/image_loss_std 0.83 / train/model_loss_mean 2.41 / train/model_loss_std 3.97 / 
train/model_opt_grad_norm 12.28 / train/model_opt_grad_steps 1.8e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 5937.5 / train/policy_entropy_mag 1.27 / train/policy_entropy_max 1.27 / 
train/policy_entropy_mean -0.54 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.39 / train/policy_logprob_mag 7.49 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.54 / train/policy_logprob_min -7.49 / train/policy_logprob_std 0.81 / 
train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 7e-4 / train/policy_randomness_std 0.17 / train/post_ent_mag 51.34 / train/post_ent_max 51.34 / train/post_ent_mean 27.18 / 
train/post_ent_min 16.51 / train/post_ent_std 3.67 / train/prior_ent_mag 66.04 / train/prior_ent_max 66.04 / train/prior_ent_mean 30.03 / train/prior_ent_min 20.26 / train/prior_ent_std 5.83 / train/rep_loss_mean 2.64 / train/rep_loss_std 5.69 / train/reward_avg 0.02 / 
train/reward_loss_mean 0.01 / train/reward_loss_std 0.12 / train/reward_max_data 1.95 / train/reward_max_pred 1.92 / train/reward_neg_acc 1 / train/reward_neg_loss 1.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.73 / train/reward_pred 0.02 / train/reward_rate
0.02 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.46 / report/cont_avg 1 / report/cont_loss_mean 6.1e-10 / report/cont_loss_std 8.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.54 / report/dyn_loss_std 5.83 / report/image_loss_mean 0.7 / report/image_loss_std 0.67 / report/model_loss_mean 2.23 / report/model_loss_std 3.93 / report/post_ent_mag 53.28 / report/post_ent_max 53.28 / 
report/post_ent_mean 28.27 / report/post_ent_min 16.33 / report/post_ent_std 3.49 / report/prior_ent_mag 67.08 / report/prior_ent_max 67.08 / report/prior_ent_mean 31.04 / report/prior_ent_min 20.48 / report/prior_ent_std 5.67 / report/rep_loss_mean 2.54 / 
report/rep_loss_std 5.83 / report/reward_avg 0.02 / report/reward_loss_mean 5.3e-3 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 1.99 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.36 / report/reward_pred 0.02 / report/reward_rate 0.01 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-10 / eval/cont_loss_std 6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.29 / eval/dyn_loss_std 7.2 / eval/image_loss_mean 1.29 / eval/image_loss_std 2.61 / eval/model_loss_mean 3.87 / eval/model_loss_std 6.36 / eval/post_ent_mag 53.74 / eval/post_ent_max 53.74 / eval/post_ent_mean 27.48 / 
eval/post_ent_min 11.49 / eval/post_ent_std 4.35 / eval/prior_ent_mag 67.08 / eval/prior_ent_max 67.08 / eval/prior_ent_mean 31.47 / eval/prior_ent_min 23.07 / eval/prior_ent_std 5.37 / eval/rep_loss_mean 4.29 / eval/rep_loss_std 7.2 / eval/reward_avg 9.8e-4 / 
eval/reward_loss_mean 8.5e-4 / eval/reward_loss_std 0.03 / eval/reward_max_data 1 / eval/reward_max_pred 1.1 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.8 / eval/reward_pred 1.1e-3 / eval/reward_rate 9.8e-4 / 
replay/size 4e4 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3856 / timer/env.step_total 19.15 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.62 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7864 / timer/agent.policy_total 16.73 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1928 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1928 / timer/agent.train_total 243.81 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T222943F944428-0ZVq7bEO2vwLANnkTZjaLK-5PfDi52tUBzxHhejkSsAwU-1024.npz
Starting evaluation at step 40000 Counter(40000) 39937
eval_Episode has 500 steps and return 36.0.
train_Episode has 500 steps and return 43.0.
Starting evaluation at step 40500 Counter(40500) 40437
Saved chunk: 20230921T223030F437321-6Obtack01nuSCj4DMsvgHP-3JPe59DBxtP1yFOFoIyJtl-1024.npz
eval_Episode has 500 steps and return 38.0.
train_Episode has 500 steps and return 37.0.
Saved chunk: 20230921T223103F482326-5PfDi52tUBzxHhejkSsAwU-47wVZVk2dTuSXlQlea0lMS-1024.npz
Starting evaluation at step 41000 Counter(41000) 40937
eval_Episode has 500 steps and return 35.0.
train_Episode has 500 steps and return 39.0.
Starting evaluation at step 41500 Counter(41500) 41437
Saved chunk: 20230921T223148F811444-3JPe59DBxtP1yFOFoIyJtl-7FHneOFMp2Ld2amvvWtmvp-1024.npz
eval_Episode has 500 steps and return 54.0.
train_Episode has 500 steps and return 45.0.
Saved chunk: 20230921T223222F889955-47wVZVk2dTuSXlQlea0lMS-4dFdMtmDQWY4S8QVlOoiux-1024.npz
Starting evaluation at step 42000 Counter(42000) 41937
eval_Episode has 500 steps and return 43.0.
train_Episode has 500 steps and return 45.0.
Starting evaluation at step 42500 Counter(42500) 42437
Saved chunk: 20230921T223306F503858-7FHneOFMp2Ld2amvvWtmvp-0BwcpTCbGwlpAjmVg3HXSg-1024.npz
eval_Episode has 500 steps and return 35.0.
train_Episode has 500 steps and return 42.0.
Starting evaluation at step 43000 Counter(43000) 42937
eval_Episode has 500 steps and return 50.0.
Saved chunk: 20230921T223342F018993-4dFdMtmDQWY4S8QVlOoiux-64dxteZF5X2gdEya6mbNTJ-1024.npz
train_Episode has 500 steps and return 60.0.
Starting evaluation at step 43500 Counter(43500) 43437
Saved chunk: 20230921T223423F961959-0BwcpTCbGwlpAjmVg3HXSg-6xPrGOydQPX1eDqR3Ib157-1024.npz
eval_Episode has 500 steps and return 46.0.
train_Episode has 500 steps and return 46.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 87226 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 46 / eval_episode/reward_rate 0.06 / episode/length 500 / episode/score 46 / episode/reward_rate 0.06 / train/action_mag 2.87 / train/action_max 2.79 / train/action_mean 0.09 / train/action_min -2.38 / train/action_std 0.95 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2e4 / train/actor_opt_loss -272.12 / train/adv_mag 1.57 / train/adv_max 1.56 / train/adv_mean 0.03 / train/adv_min -0.62 / 
train/adv_std 0.1 / train/cont_avg 1 / train/cont_loss_mean 6.6e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.6 / 
train/dyn_loss_std 5.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.39 / train/extr_critic_critic_opt_grad_steps 2e4 / train/extr_critic_critic_opt_loss 1e4 /
train/extr_critic_mag 20.15 / train/extr_critic_max 20.15 / train/extr_critic_mean 15.05 / train/extr_critic_min 9.07 / train/extr_critic_std 1.87 / train/extr_return_normed_mag 2.58 / train/extr_return_normed_max 2.58 / train/extr_return_normed_mean 0.53 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 27.24 / train/extr_return_raw_max 27.24 / train/extr_return_raw_mean 15.21 / train/extr_return_raw_min 10.18 / train/extr_return_raw_std 2.03 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.03 / train/extr_reward_min 0 / train/extr_reward_std 0.2 / train/image_loss_mean 0.74 / train/image_loss_std 0.77 / train/model_loss_mean 2.32 / train/model_loss_std 3.96 / 
train/model_opt_grad_norm 11.03 / train/model_opt_grad_steps 2e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5466.32 / train/policy_entropy_mag 1.26 / train/policy_entropy_max 1.26 / 
train/policy_entropy_mean -0.53 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.41 / train/policy_logprob_mag 7.62 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.53 / train/policy_logprob_min -7.62 / train/policy_logprob_std 0.82 / 
train/policy_randomness_mag 0.93 / train/policy_randomness_max 0.93 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 5.9e-4 / train/policy_randomness_std 0.18 / train/post_ent_mag 53.23 / train/post_ent_max 53.23 / train/post_ent_mean 28.4 / 
train/post_ent_min 16.96 / train/post_ent_std 3.84 / train/prior_ent_mag 67.21 / train/prior_ent_max 67.21 / train/prior_ent_mean 31.17 / train/prior_ent_min 20.9 / train/prior_ent_std 5.9 / train/rep_loss_mean 2.6 / train/rep_loss_std 5.71 / train/reward_avg 0.03 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 1.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.7 / train/reward_pred 0.03 / train/reward_rate 
0.02 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.57 / report/cont_avg 1 / report/cont_loss_mean 5.1e-10 / report/cont_loss_std 7.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.46 / report/dyn_loss_std 5.66 / report/image_loss_mean 0.65 / report/image_loss_std 0.75 / report/model_loss_mean 2.15 / report/model_loss_std 3.96 / report/post_ent_mag 55.57 / report/post_ent_max 55.57 / 
report/post_ent_mean 28.85 / report/post_ent_min 16.27 / report/post_ent_std 3.99 / report/prior_ent_mag 67.6 / report/prior_ent_max 67.6 / report/prior_ent_mean 31.71 / report/prior_ent_min 22.28 / report/prior_ent_std 6.08 / report/rep_loss_mean 2.46 / 
report/rep_loss_std 5.66 / report/reward_avg 0.02 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.85 / report/reward_pred 0.02 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-10 / eval/cont_loss_std 4.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.86 / eval/dyn_loss_std 5.79 / eval/image_loss_mean 0.6 / eval/image_loss_std 1.69 / eval/model_loss_mean 2.32 / eval/model_loss_std 4.73 / eval/post_ent_mag 54.72 / eval/post_ent_max 54.72 / eval/post_ent_mean 
28.79 / eval/post_ent_min 16.17 / eval/post_ent_std 3.83 / eval/prior_ent_mag 67.6 / eval/prior_ent_max 67.6 / eval/prior_ent_mean 31.52 / eval/prior_ent_min 23.64 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 2.86 / eval/rep_loss_std 5.79 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.9e-5 / eval/reward_loss_std 5.9e-4 / eval/reward_max_data 0 / eval/reward_max_pred 0.01 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.4e-5 / eval/reward_rate 0 / 
replay/size 4.4e4 / replay/inserts 3858 / replay/samples 3.1e4 / replay/insert_wait_avg 3.1e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3858 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.67 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7866 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1929 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1929 / timer/agent.train_total 243.88 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.71

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 44000 Counter(44000) 43937
eval_Episode has 500 steps and return 52.0.
Saved chunk: 20230921T223504F154693-64dxteZF5X2gdEya6mbNTJ-4Eh3RsLdC4abai2nBD9Hse-1024.npz
train_Episode has 500 steps and return 51.0.
Starting evaluation at step 44500 Counter(44500) 44437
Saved chunk: 20230921T223541F125692-6xPrGOydQPX1eDqR3Ib157-44c9EEHntBaRdSYzSK0c9I-1024.npz
eval_Episode has 500 steps and return 69.0.
train_Episode has 500 steps and return 54.0.
Starting evaluation at step 45000 Counter(45000) 44937
eval_Episode has 500 steps and return 48.0.
Saved chunk: 20230921T223623F809363-4Eh3RsLdC4abai2nBD9Hse-64muEJvSbGpBaQhSE4F0lK-1024.npz
train_Episode has 500 steps and return 69.0.
Starting evaluation at step 45500 Counter(45500) 45437
Saved chunk: 20230921T223659F403206-44c9EEHntBaRdSYzSK0c9I-6cyVY6WPVFZKplT4wEbUys-1024.npz
eval_Episode has 500 steps and return 88.0.
train_Episode has 500 steps and return 95.0.
Starting evaluation at step 46000 Counter(46000) 45937
eval_Episode has 500 steps and return 56.0.
Saved chunk: 20230921T223742F924134-64muEJvSbGpBaQhSE4F0lK-7LWzuxxNzsGvbu8AuVKo9r-1024.npz
train_Episode has 500 steps and return 55.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T223901F917805-7LWzuxxNzsGvbu8AuVKo9r-0000000000000000000000-20.npz
Saved chunk: 20230921T223816F909720-6cyVY6WPVFZKplT4wEbUys-0000000000000000000000-611.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 46500 Counter(46500) 46437
Saved chunk: 20230921T223816F909720-6cyVY6WPVFZKplT4wEbUys-5NuRMcXRohcEooCnQAWma8-1024.npz
eval_Episode has 500 steps and return 51.0.
train_Episode has 500 steps and return 63.0.
Starting evaluation at step 47000 Counter(47000) 46937
eval_Episode has 500 steps and return 103.0.
train_Episode has 500 steps and return 155.0.
Saved chunk: 20230921T223901F917805-7LWzuxxNzsGvbu8AuVKo9r-3vBgvgcBZTMGSN35YDwbUI-1024.npz
Starting evaluation at step 47500 Counter(47500) 47437
Saved chunk: 20230921T223934F458929-5NuRMcXRohcEooCnQAWma8-4zv6DFY8MSVUeCGFb8yaUY-1024.npz
eval_Episode has 500 steps and return 149.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 95002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 149 / eval_episode/reward_rate 0.15 / episode/length 500 / episode/score 155 / episode/reward_rate 0.16 / train/action_mag 3.47 / train/action_max 3.47 / train/action_mean 0.08 / train/action_min -2.22 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2.2e4 / train/actor_opt_loss -213.22 / train/adv_mag 1.31 / train/adv_max 1.28 / train/adv_mean 0.02 / train/adv_min -0.63 / 
train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 5.9e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.6 / 
train/dyn_loss_std 5.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.47 / train/extr_critic_critic_opt_grad_steps 2.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 25.67 / train/extr_critic_max 25.67 / train/extr_critic_mean 19 / train/extr_critic_min 9.12 / train/extr_critic_std 2.52 / train/extr_return_normed_mag 2.31 / train/extr_return_normed_max 2.31 / train/extr_return_normed_mean 0.57 / 
train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 33.51 / train/extr_return_raw_max 33.51 / train/extr_return_raw_mean 19.19 / train/extr_return_raw_min 9.68 / train/extr_return_raw_std 2.7 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.04 / train/extr_reward_min 0 / train/extr_reward_std 0.23 / train/image_loss_mean 0.7 / train/image_loss_std 0.73 / train/model_loss_mean 2.28 / train/model_loss_std 3.98 / 
train/model_opt_grad_norm 10.53 / train/model_opt_grad_steps 2.2e4 / train/model_opt_loss 8482.39 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3717.95 / train/policy_entropy_mag 1.36 / train/policy_entropy_max 1.36 / 
train/policy_entropy_mean -0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.51 / train/policy_logprob_mag 7.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.44 / train/policy_logprob_min -7.75 / train/policy_logprob_std 0.88 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.19 / train/policy_randomness_min 7.2e-4 / train/policy_randomness_std 0.22 / train/post_ent_mag 54.12 / train/post_ent_max 54.12 / train/post_ent_mean 29.9 / 
train/post_ent_min 17.25 / train/post_ent_std 4.17 / train/prior_ent_mag 68.12 / train/prior_ent_max 68.12 / train/prior_ent_mean 32.63 / train/prior_ent_min 21.88 / train/prior_ent_std 5.94 / train/rep_loss_mean 2.6 / train/rep_loss_std 5.78 / train/reward_avg 0.03 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.14 / train/reward_max_data 1.99 / train/reward_max_pred 1.99 / train/reward_neg_acc 1 / train/reward_neg_loss 2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.63 / train/reward_pred 0.03 / train/reward_rate 
0.02 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.59 / report/cont_avg 1 / report/cont_loss_mean 5e-10 / report/cont_loss_std 8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.47 / report/dyn_loss_std 5.35 / report/image_loss_mean 0.61 / report/image_loss_std 0.56 / report/model_loss_mean 2.1 / report/model_loss_std 3.54 / report/post_ent_mag 53.23 / report/post_ent_max 53.23 / 
report/post_ent_mean 30.57 / report/post_ent_min 17.6 / report/post_ent_std 4.29 / report/prior_ent_mag 68.44 / report/prior_ent_max 68.44 / report/prior_ent_mean 33.11 / report/prior_ent_min 23.4 / report/prior_ent_std 6.34 / report/rep_loss_mean 2.47 / 
report/rep_loss_std 5.35 / report/reward_avg 0.03 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.62 / report/reward_pred 0.02 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 3e-10 / eval/cont_loss_std 4.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-10 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 3.13 / eval/dyn_loss_std 6.21 / eval/image_loss_mean 0.78 / eval/image_loss_std 1.36 / eval/model_loss_mean 2.68 / eval/model_loss_std 4.77 / eval/post_ent_mag 55.8 / eval/post_ent_max 55.8 / eval/post_ent_mean 30.03 / 
eval/post_ent_min 14.78 / eval/post_ent_std 4.41 / eval/prior_ent_mag 68.44 / eval/prior_ent_max 68.44 / eval/prior_ent_mean 33.13 / eval/prior_ent_min 23.12 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 3.13 / eval/rep_loss_std 6.21 / eval/reward_avg 5.9e-3 / 
eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 0.75 / eval/reward_pos_loss 3.02 / eval/reward_pred 6.5e-3 / eval/reward_rate 3.9e-3 / 
replay/size 4.7e4 / replay/inserts 3888 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.21 / timer/env.step_count 3888 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 3.9e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.32 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7896 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1944 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 3.7e-4 / timer/agent.train_count 1944 / timer/agent.train_total 245.91 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / 
timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.73

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 99.0.
Starting evaluation at step 48000 Counter(48000) 47937
eval_Episode has 500 steps and return 97.0.
train_Episode has 500 steps and return 162.0.
Saved chunk: 20230921T224020F924377-3vBgvgcBZTMGSN35YDwbUI-3KwpYXUeZduane0AShsmZB-1024.npz
Starting evaluation at step 48500 Counter(48500) 48437
Saved chunk: 20230921T224051F799486-4zv6DFY8MSVUeCGFb8yaUY-5LD4KnV845SjKpfam5o1ce-1024.npz
eval_Episode has 500 steps and return 106.0.
train_Episode has 500 steps and return 108.0.
Starting evaluation at step 49000 Counter(49000) 48937
eval_Episode has 500 steps and return 102.0.
train_Episode has 500 steps and return 73.0.
Saved chunk: 20230921T224140F888955-3KwpYXUeZduane0AShsmZB-1V8EzlJ8ghrFh7CTZ6Xwxu-1024.npz
Starting evaluation at step 49500 Counter(49500) 49437
Saved chunk: 20230921T224210F315623-5LD4KnV845SjKpfam5o1ce-33moHVAGYKnvSsGdbD2T5G-1024.npz
eval_Episode has 500 steps and return 184.0.
train_Episode has 500 steps and return 58.0.
Starting evaluation at step 50000 Counter(50000) 49937
eval_Episode has 500 steps and return 94.0.
train_Episode has 500 steps and return 151.0.
Saved chunk: 20230921T224300F152635-1V8EzlJ8ghrFh7CTZ6Xwxu-1k8fkleGe0KlPdcTdtO3JA-1024.npz
Starting evaluation at step 50500 Counter(50500) 50437
eval_Episode has 500 steps and return 245.0.
Saved chunk: 20230921T224327F990706-33moHVAGYKnvSsGdbD2T5G-7IqWSfH2TIXloQUfBlKM1C-1024.npz
train_Episode has 500 steps and return 120.0.
Starting evaluation at step 51000 Counter(51000) 50937
eval_Episode has 500 steps and return 373.0.
train_Episode has 500 steps and return 146.0.
Saved chunk: 20230921T224419F312878-1k8fkleGe0KlPdcTdtO3JA-6TbyBNGDBBVcecFKFfRxZ1-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 102798 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 146 / episode/reward_rate 0.15 / eval_episode/length 500 / eval_episode/score 373 / eval_episode/reward_rate 0.38 / train/action_mag 2.96 / train/action_max 2.95 / train/action_mean 0.14 / train/action_min -2.03 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 2.4e4 / train/actor_opt_loss -235.43 / train/adv_mag 1.34 / train/adv_max 1.33 / train/adv_mean 0.02 / train/adv_min -0.58 / 
train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 5.4e-10 / train/cont_loss_std 9.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.56 / 
train/dyn_loss_std 5.78 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.4 / train/extr_critic_critic_opt_grad_steps 2.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 34.06 / train/extr_critic_max 34.06 / train/extr_critic_mean 23.88 / train/extr_critic_min 16.66 / train/extr_critic_std 3.15 / train/extr_return_normed_mag 2.45 / train/extr_return_normed_max 2.45 / train/extr_return_normed_mean 0.51 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 44.3 / train/extr_return_raw_max 44.3 / train/extr_return_raw_mean 24.13 / train/extr_return_raw_min 17.37 / train/extr_return_raw_std 3.51 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.05 / train/extr_reward_min 0 / train/extr_reward_std 0.28 / train/image_loss_mean 0.65 / train/image_loss_std 0.7 / train/model_loss_mean 2.21 / train/model_loss_std 3.98 / 
train/model_opt_grad_norm 11.12 / train/model_opt_grad_steps 2.4e4 / train/model_opt_loss 8178.95 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3717.95 / train/policy_entropy_mag 1.29 / train/policy_entropy_max 1.29 / 
train/policy_entropy_mean -0.54 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.42 / train/policy_logprob_mag 7.52 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.54 / train/policy_logprob_min -7.52 / train/policy_logprob_std 0.83 / 
train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 6.2e-4 / train/policy_randomness_std 0.18 / train/post_ent_mag 54.84 / train/post_ent_max 54.84 / train/post_ent_mean 31.43 / 
train/post_ent_min 17.52 / train/post_ent_std 4.53 / train/prior_ent_mag 69.08 / train/prior_ent_max 69.08 / train/prior_ent_mean 34.12 / train/prior_ent_min 22.71 / train/prior_ent_std 6.05 / train/rep_loss_mean 2.56 / train/rep_loss_std 5.78 / train/reward_avg 0.05 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.55 / train/reward_pred 0.05 / train/reward_rate 0.03 
/ train_stats/mean_log_entropy -0.68 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.4e-10 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.37 / report/dyn_loss_std 5.41 / report/image_loss_mean 0.54 / report/image_loss_std 0.7 / report/model_loss_mean 1.99 / report/model_loss_std 3.78 / report/post_ent_mag 56.81 / report/post_ent_max 56.81 / 
report/post_ent_mean 31.68 / report/post_ent_min 17.11 / report/post_ent_std 4.37 / report/prior_ent_mag 69.66 / report/prior_ent_max 69.66 / report/prior_ent_mean 34.38 / report/prior_ent_min 24.27 / report/prior_ent_std 5.73 / report/rep_loss_mean 2.37 / 
report/rep_loss_std 5.41 / report/reward_avg 0.04 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.2 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 0.96 / 
report/reward_pos_loss 0.79 / report/reward_pred 0.04 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-10 / eval/cont_loss_std 5.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.02 / eval/dyn_loss_std 5.58 / eval/image_loss_mean 0.69 / eval/image_loss_std 1.15 / eval/model_loss_mean 2.5 / eval/model_loss_std 4.24 / eval/post_ent_mag 57.4 / eval/post_ent_max 57.4 / eval/post_ent_mean 30.78
/ eval/post_ent_min 19.45 / eval/post_ent_std 4.27 / eval/prior_ent_mag 69.66 / eval/prior_ent_max 69.66 / eval/prior_ent_mean 34.06 / eval/prior_ent_min 25.51 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 3.02 / eval/rep_loss_std 5.58 / eval/reward_avg 0 / 
eval/reward_loss_mean 5.7e-5 / eval/reward_loss_std 1.8e-3 / eval/reward_max_data 0 / eval/reward_max_pred 0.05 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.7e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 4.7e-5 / eval/reward_rate 0 / 
replay/size 5.1e4 / replay/inserts 3898 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.2e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3898 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.92 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7405 / timer/agent.policy_total 15.95 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1949 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1949 / timer/agent.train_total 246.72 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.98

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 51500 Counter(51500) 51437
eval_Episode has 500 steps and return 108.0.
train_Episode has 500 steps and return 129.0.
Starting evaluation at step 52000 Counter(52000) 51937
Saved chunk: 20230921T224445F509028-7IqWSfH2TIXloQUfBlKM1C-5BGigHWi1SegCU5hiqycGU-1024.npz
eval_Episode has 500 steps and return 81.0.
train_Episode has 500 steps and return 160.0.
Saved chunk: 20230921T224538F284853-6TbyBNGDBBVcecFKFfRxZ1-6Sg7BqLvdHmBRK5JbgV9Ch-1024.npz
Starting evaluation at step 52500 Counter(52500) 52437
eval_Episode has 500 steps and return 158.0.
train_Episode has 500 steps and return 110.0.
Starting evaluation at step 53000 Counter(53000) 52937
Saved chunk: 20230921T224639F262038-5BGigHWi1SegCU5hiqycGU-6Sxgpz40WwrlSuDZowAYV4-1024.npz
eval_Episode has 500 steps and return 104.0.
train_Episode has 500 steps and return 241.0.
Saved chunk: 20230921T224658F312877-6Sg7BqLvdHmBRK5JbgV9Ch-7MMEhoq0CEsuGLAuTLhMpB-1024.npz
Starting evaluation at step 53500 Counter(53500) 53437
eval_Episode has 500 steps and return 347.0.
train_Episode has 500 steps and return 149.0.
Starting evaluation at step 54000 Counter(54000) 53937
Saved chunk: 20230921T224756F965607-6Sxgpz40WwrlSuDZowAYV4-2IDNA1DKbl9xSwogA9kLRT-1024.npz
eval_Episode has 500 steps and return 193.0.
train_Episode has 500 steps and return 325.0.
Saved chunk: 20230921T224817F527116-7MMEhoq0CEsuGLAuTLhMpB-3ApAWzb0ZQttl0YKH41gxz-1024.npz
Starting evaluation at step 54500 Counter(54500) 54437
eval_Episode has 500 steps and return 181.0.
train_Episode has 500 steps and return 457.0.
Starting evaluation at step 55000 Counter(55000) 54937
Saved chunk: 20230921T224914F513966-2IDNA1DKbl9xSwogA9kLRT-4blqN8Z0lTmeW8o5sXrmp9-1024.npz
eval_Episode has 500 steps and return 160.0.
train_Episode has 500 steps and return 349.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 110506 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 160 / eval_episode/reward_rate 0.16 / episode/length 500 / episode/score 349 / episode/reward_rate 0.35 / train/action_mag 3 / train/action_max 2.98 / train/action_mean 0.17 / train/action_min -2.25 / train/action_std 0.92 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 2.6e4 / train/actor_opt_loss -233.53 / train/adv_mag 1.21 / train/adv_max 1.2 / train/adv_mean 0.02 / train/adv_min -0.59 / 
train/adv_std 0.09 / train/cont_avg 1 / train/cont_loss_mean 4.7e-10 / train/cont_loss_std 9.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.56 / 
train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.51 / train/extr_critic_critic_opt_grad_steps 2.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 47.41 / train/extr_critic_max 47.41 / train/extr_critic_mean 29.86 / train/extr_critic_min 19.19 / train/extr_critic_std 4.93 / train/extr_return_normed_mag 2.25 / train/extr_return_normed_max 2.25 / train/extr_return_normed_mean 0.46 / 
train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 58.93 / train/extr_return_raw_max 58.93 / train/extr_return_raw_mean 30.25 / train/extr_return_raw_min 20.01 / train/extr_return_raw_std 5.56 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.07 / train/extr_reward_min 0 / train/extr_reward_std 0.33 / train/image_loss_mean 0.63 / train/image_loss_std 0.68 / train/model_loss_mean 2.18 / train/model_loss_std 4.01 / 
train/model_opt_grad_norm 10.63 / train/model_opt_grad_steps 2.6e4 / train/model_opt_loss 9003.65 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4127.6 / train/policy_entropy_mag 1.3 / train/policy_entropy_max 1.3 / 
train/policy_entropy_mean -0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.44 / train/policy_logprob_mag 7.74 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.51 / train/policy_logprob_min -7.74 / train/policy_logprob_std 0.84 / 
train/policy_randomness_mag 0.95 / train/policy_randomness_max 0.95 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 9.3e-4 / train/policy_randomness_std 0.19 / train/post_ent_mag 55.56 / train/post_ent_max 55.56 / train/post_ent_mean 32.7 / 
train/post_ent_min 18.02 / train/post_ent_std 4.91 / train/prior_ent_mag 69.79 / train/prior_ent_max 69.79 / train/prior_ent_mean 35.35 / train/prior_ent_min 23.27 / train/prior_ent_std 6.24 / train/rep_loss_mean 2.56 / train/rep_loss_std 5.84 / train/reward_avg 0.07 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.49 / train/reward_pred 0.07 / train/reward_rate 0.04 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.69 / report/cont_avg 1 / report/cont_loss_mean 3.5e-10 / report/cont_loss_std 5.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.49 / report/dyn_loss_std 5.64 / report/image_loss_mean 0.57 / report/image_loss_std 0.69 / report/model_loss_mean 2.07 / report/model_loss_std 3.83 / report/post_ent_mag 58.51 / report/post_ent_max 58.51 / 
report/post_ent_mean 33.09 / report/post_ent_min 11.19 / report/post_ent_std 5.02 / report/prior_ent_mag 70.24 / report/prior_ent_max 70.24 / report/prior_ent_mean 35.47 / report/prior_ent_min 25.7 / report/prior_ent_std 6.09 / report/rep_loss_mean 2.49 / 
report/rep_loss_std 5.64 / report/reward_avg 0.03 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.45 / report/reward_pred 0.03 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-10 / eval/cont_loss_std 5.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.47 / eval/dyn_loss_std 4.83 / eval/image_loss_mean 0.58 / eval/image_loss_std 0.63 / eval/model_loss_mean 2.08 / eval/model_loss_std 3.27 / eval/post_ent_mag 58.54 / eval/post_ent_max 58.54 / eval/post_ent_mean 
32.62 / eval/post_ent_min 19.5 / eval/post_ent_std 4.71 / eval/prior_ent_mag 70.24 / eval/prior_ent_max 70.24 / eval/prior_ent_mean 35.29 / eval/prior_ent_min 25.77 / eval/prior_ent_std 5.97 / eval/rep_loss_mean 2.47 / eval/rep_loss_std 4.83 / eval/reward_avg 0.04 / 
eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.04 / eval/reward_rate 0.02 / 
replay/size 5.5e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.6e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3854 / timer/env.step_total 19.09 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.44 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.84 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.07 / 
timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1927 / timer/agent.train_total 243.69 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.69

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T224936F603128-3ApAWzb0ZQttl0YKH41gxz-43cqzp22OkodGMwQPwRfxb-1024.npz
Starting evaluation at step 55500 Counter(55500) 55437
eval_Episode has 500 steps and return 331.0.
train_Episode has 500 steps and return 273.0.
Starting evaluation at step 56000 Counter(56000) 55937
Saved chunk: 20230921T225031F902687-4blqN8Z0lTmeW8o5sXrmp9-1hrvumOSC1pJ5wichjIJle-1024.npz
eval_Episode has 500 steps and return 406.0.
train_Episode has 500 steps and return 271.0.
Saved chunk: 20230921T225056F041842-43cqzp22OkodGMwQPwRfxb-57z4ZQMpLCWF1CrOMWXgvQ-1024.npz
Starting evaluation at step 56500 Counter(56500) 56437
eval_Episode has 500 steps and return 281.0.
train_Episode has 500 steps and return 120.0.
Starting evaluation at step 57000 Counter(57000) 56937
Saved chunk: 20230921T225150F256544-1hrvumOSC1pJ5wichjIJle-6hpd07mZqbZCfQTb3SH96M-1024.npz
eval_Episode has 500 steps and return 275.0.
train_Episode has 500 steps and return 178.0.
Saved chunk: 20230921T225215F561927-57z4ZQMpLCWF1CrOMWXgvQ-48992QNnXiOJofgVMOG7jG-1024.npz
Starting evaluation at step 57500 Counter(57500) 57437
eval_Episode has 500 steps and return 191.0.
train_Episode has 500 steps and return 177.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T225334F710837-48992QNnXiOJofgVMOG7jG-0000000000000000000000-456.npz
Saved chunk: 20230921T225307F966679-6hpd07mZqbZCfQTb3SH96M-0000000000000000000000-870.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 58000 Counter(58000) 57937
Saved chunk: 20230921T225307F966679-6hpd07mZqbZCfQTb3SH96M-6hinXsGaZxEL7MU0tKCBOo-1024.npz
eval_Episode has 500 steps and return 206.0.
train_Episode has 500 steps and return 379.0.
Saved chunk: 20230921T225334F710837-48992QNnXiOJofgVMOG7jG-4QBOLz8YHFm5siTzGTQ4D7-1024.npz
Starting evaluation at step 58500 Counter(58500) 58437
eval_Episode has 500 steps and return 200.0.
train_Episode has 500 steps and return 219.0.
Starting evaluation at step 59000 Counter(59000) 58937
Saved chunk: 20230921T225425F664949-6hinXsGaZxEL7MU0tKCBOo-3tZWlTLQxDMnxoQCAGglsi-1024.npz
eval_Episode has 500 steps and return 192.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 118210 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 192 / eval_episode/reward_rate 0.2 / episode/length 500 / episode/score 219 / episode/reward_rate 0.22 / train/action_mag 3.26 / train/action_max 3.25 / train/action_mean 0.15 / train/action_min -2.34 / train/action_std 0.92 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 2.8e4 / train/actor_opt_loss -224.97 / train/adv_mag 1.04 / train/adv_max 1.03 / train/adv_mean 0.02 / train/adv_min -0.57 / 
train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 4.2e-10 / train/cont_loss_std 8.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.54 / 
train/dyn_loss_std 5.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.64 / train/extr_critic_critic_opt_grad_steps 2.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 67.8 / train/extr_critic_max 67.8 / train/extr_critic_mean 39.36 / train/extr_critic_min 20.1 / train/extr_critic_std 8.26 / train/extr_return_normed_mag 1.89 / train/extr_return_normed_max 1.89 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 81.09 / train/extr_return_raw_max 81.09 / train/extr_return_raw_mean 40.01 / train/extr_return_raw_min 21.34 / train/extr_return_raw_std 9.18 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.1 / train/extr_reward_min 0 / train/extr_reward_std 0.4 / train/image_loss_mean 0.6 / train/image_loss_std 0.65 / train/model_loss_mean 2.14 / train/model_loss_std 4.01 / 
train/model_opt_grad_norm 10.82 / train/model_opt_grad_steps 2.8e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4702.07 / train/policy_entropy_mag 1.35 / train/policy_entropy_max 1.35 / 
train/policy_entropy_mean -0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.49 / train/policy_logprob_mag 7.75 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.41 / train/policy_logprob_min -7.75 / train/policy_logprob_std 0.86 / 
train/policy_randomness_mag 0.97 / train/policy_randomness_max 0.97 / train/policy_randomness_mean 0.2 / train/policy_randomness_min 2.1e-3 / train/policy_randomness_std 0.21 / train/post_ent_mag 56.34 / train/post_ent_max 56.34 / train/post_ent_mean 34.04 / 
train/post_ent_min 18.41 / train/post_ent_std 5.21 / train/prior_ent_mag 70.68 / train/prior_ent_max 70.68 / train/prior_ent_mean 36.65 / train/prior_ent_min 24.1 / train/prior_ent_std 6.37 / train/rep_loss_mean 2.54 / train/rep_loss_std 5.87 / train/reward_avg 0.1 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.42 / train/reward_pred 0.09 / train/reward_rate 0.05 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.63 / report/cont_avg 1 / report/cont_loss_mean 3.6e-10 / report/cont_loss_std 7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.33 / report/dyn_loss_std 5.33 / report/image_loss_mean 0.54 / report/image_loss_std 0.57 / report/model_loss_mean 1.96 / report/model_loss_std 3.59 / report/post_ent_mag 57.9 / report/post_ent_max 57.9 / 
report/post_ent_mean 34.67 / report/post_ent_min 19.51 / report/post_ent_std 5.92 / report/prior_ent_mag 70.75 / report/prior_ent_max 70.75 / report/prior_ent_mean 37.43 / report/prior_ent_min 23.64 / report/prior_ent_std 6.54 / report/rep_loss_mean 2.33 / 
report/rep_loss_std 5.33 / report/reward_avg 0.12 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.26 / report/reward_pred 0.12 / report/reward_rate 0.07 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-10 / eval/cont_loss_std 7.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 3.85 / eval/dyn_loss_std 7.57 / eval/image_loss_mean 0.85 / eval/image_loss_std 1.52 / eval/model_loss_mean 3.18 / eval/model_loss_std 5.74 / eval/post_ent_mag 58.17 / eval/post_ent_max 58.17 / eval/post_ent_mean 32.57 / eval/post_ent_min 18.04 / 
eval/post_ent_std 5.3 / eval/prior_ent_mag 70.75 / eval/prior_ent_max 70.75 / eval/prior_ent_mean 36.55 / eval/prior_ent_min 24.34 / eval/prior_ent_std 5.81 / eval/rep_loss_mean 3.85 / eval/rep_loss_std 7.57 / eval/reward_avg 0.02 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.98 / eval/reward_pred 0.02 / eval/reward_rate 0.02 / replay/size 5.9e4 / replay/inserts 3852 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 6e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3852 / timer/env.step_total 19.18 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.68 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.09 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7860 / timer/agent.policy_total 16.85 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1926 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4e-4 / 
timer/agent.train_count 1926 / timer/agent.train_total 243.66 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 106.0.
Saved chunk: 20230921T225453F931929-4QBOLz8YHFm5siTzGTQ4D7-5TvGRb191TwYuI451otpYj-1024.npz
Starting evaluation at step 59500 Counter(59500) 59437
eval_Episode has 500 steps and return 360.0.
train_Episode has 500 steps and return 198.0.
Starting evaluation at step 60000 Counter(60000) 59937
Saved chunk: 20230921T225542F988236-3tZWlTLQxDMnxoQCAGglsi-6nUtZZmu9QfWbIq0SrK5ji-1024.npz
eval_Episode has 500 steps and return 169.0.
train_Episode has 500 steps and return 343.0.
Saved chunk: 20230921T225613F483632-5TvGRb191TwYuI451otpYj-3IkHmXQ3XYZBOQ4kgXtQKU-1024.npz
Starting evaluation at step 60500 Counter(60500) 60437
eval_Episode has 500 steps and return 295.0.
train_Episode has 500 steps and return 303.0.
Starting evaluation at step 61000 Counter(61000) 60937
Saved chunk: 20230921T225702F070273-6nUtZZmu9QfWbIq0SrK5ji-2IQv8Uo0DGymKn9WF3mYRM-1024.npz
eval_Episode has 500 steps and return 136.0.
train_Episode has 500 steps and return 182.0.
Saved chunk: 20230921T225733F533543-3IkHmXQ3XYZBOQ4kgXtQKU-2AE8wZRTzOTPDyAhFkZAFt-1024.npz
Starting evaluation at step 61500 Counter(61500) 61437
eval_Episode has 500 steps and return 331.0.
train_Episode has 500 steps and return 215.0.
Starting evaluation at step 62000 Counter(62000) 61937
Saved chunk: 20230921T225819F677860-2IQv8Uo0DGymKn9WF3mYRM-3mAkbzimxzWQgrF2zFPTtD-1024.npz
eval_Episode has 500 steps and return 238.0.
train_Episode has 500 steps and return 118.0.
Saved chunk: 20230921T225852F673349-2AE8wZRTzOTPDyAhFkZAFt-69OLGmRnTvQviyiPvxTQOh-1024.npz
Starting evaluation at step 62500 Counter(62500) 62437
eval_Episode has 500 steps and return 321.0.
train_Episode has 500 steps and return 331.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 125994 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 331 / episode/reward_rate 0.34 / eval_episode/length 500 / eval_episode/score 321 / eval_episode/reward_rate 0.33 / train_stats/mean_log_entropy -0.63 / train/action_mag 3.05 / train/action_max 3.04 / train/action_mean 0.14 / 
train/action_min -2.23 / train/action_std 0.91 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 3e4 / train/actor_opt_loss -197.98 / train/adv_mag 0.99 / train/adv_max 0.99
/ train/adv_mean 0.02 / train/adv_min -0.52 / train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 3.7e-10 / train/cont_loss_std 8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-10 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 2.54 / train/dyn_loss_std 5.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.66 / 
train/extr_critic_critic_opt_grad_steps 3e4 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 90.34 / train/extr_critic_max 90.34 / train/extr_critic_mean 53.04 / train/extr_critic_min 29.82 / train/extr_critic_std 10.84 / train/extr_return_normed_mag 1.74
/ train/extr_return_normed_max 1.74 / train/extr_return_normed_mean 0.44 / train/extr_return_normed_min -0.09 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 103.39 / train/extr_return_raw_max 103.39 / train/extr_return_raw_mean 
53.82 / train/extr_return_raw_min 33.34 / train/extr_return_raw_std 11.81 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.13 / train/extr_reward_min 0 / train/extr_reward_std 0.45 / train/image_loss_mean 0.58 / train/image_loss_std 0.66 / 
train/model_loss_mean 2.14 / train/model_loss_std 4.02 / train/model_opt_grad_norm 9.95 / train/model_opt_grad_steps 3e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 5360.82 / train/policy_entropy_mag
1.33 / train/policy_entropy_max 1.33 / train/policy_entropy_mean -0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.44 / train/policy_logprob_mag 7.67 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.46 / train/policy_logprob_min -7.67 / 
train/policy_logprob_std 0.84 / train/policy_randomness_mag 0.96 / train/policy_randomness_max 0.96 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 2e-3 / train/policy_randomness_std 0.19 / train/post_ent_mag 56.41 / train/post_ent_max 56.41 / 
train/post_ent_mean 35.24 / train/post_ent_min 18.69 / train/post_ent_std 5.5 / train/prior_ent_mag 71.3 / train/prior_ent_max 71.3 / train/prior_ent_mean 37.82 / train/prior_ent_min 24.47 / train/prior_ent_std 6.51 / train/rep_loss_mean 2.54 / train/rep_loss_std 5.89 / 
train/reward_avg 0.12 / train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.38 / train/reward_pred 0.12 / 
train/reward_rate 0.07 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-10 / report/cont_loss_std 5.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-10 / report/cont_pred 1 / 
report/cont_rate 1 / report/dyn_loss_mean 2.65 / report/dyn_loss_std 6.07 / report/image_loss_mean 0.62 / report/image_loss_std 0.84 / report/model_loss_mean 2.24 / report/model_loss_std 4.27 / report/post_ent_mag 47.51 / report/post_ent_max 47.51 / report/post_ent_mean 
36.24 / report/post_ent_min 17.95 / report/post_ent_std 5.61 / report/prior_ent_mag 71.93 / report/prior_ent_max 71.93 / report/prior_ent_mean 39.1 / report/prior_ent_min 24.71 / report/prior_ent_std 6.54 / report/rep_loss_mean 2.65 / report/rep_loss_std 6.07 / 
report/reward_avg 0.09 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.39 / 
report/reward_pred 0.09 / report/reward_rate 0.05 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-10 / eval/cont_loss_std 7.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.38 / eval/dyn_loss_std 7.17 / eval/image_loss_mean 1.02 / eval/image_loss_std 2.97 / eval/model_loss_mean 3.06 / eval/model_loss_std 6.47 / eval/post_ent_mag 59.38 / eval/post_ent_max 59.38 / eval/post_ent_mean 32.15 / eval/post_ent_min 14.22 / 
eval/post_ent_std 4.91 / eval/prior_ent_mag 71.93 / eval/prior_ent_max 71.93 / eval/prior_ent_mean 35.65 / eval/prior_ent_min 24.61 / eval/prior_ent_std 6.14 / eval/rep_loss_mean 3.38 / eval/rep_loss_std 7.17 / eval/reward_avg 0.01 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.23 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.9e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 1.59 / eval/reward_pred 0.01 / eval/reward_rate 0.01 / replay/size 6.3e4 / replay/inserts 3892 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3892 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 8.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.88 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7399 / timer/agent.policy_total 16.64 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.65 / timer/dataset_train_count 
1946 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1946 / timer/agent.train_total 245.99 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.94

Starting evaluation at step 63000 Counter(63000) 62937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T225937F138195-3mAkbzimxzWQgrF2zFPTtD-4rwu9S2MxwHrqWcAaDUOGf-1024.npz
eval_Episode has 500 steps and return 286.0.
train_Episode has 500 steps and return 295.0.
Saved chunk: 20230921T230011F628818-69OLGmRnTvQviyiPvxTQOh-2NeHQvA4GHW0qtJn9uWdfM-1024.npz
Starting evaluation at step 63500 Counter(63500) 63437
eval_Episode has 500 steps and return 326.0.
train_Episode has 500 steps and return 122.0.
Starting evaluation at step 64000 Counter(64000) 63937
Saved chunk: 20230921T230055F215773-4rwu9S2MxwHrqWcAaDUOGf-5tnwFGKoRs32y4P8zVxbMu-1024.npz
eval_Episode has 500 steps and return 320.0.
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 64500 Counter(64500) 64437
eval_Episode has 500 steps and return 325.0.
Saved chunk: 20230921T230131F546901-2NeHQvA4GHW0qtJn9uWdfM-4CiPIJsOBERZSUR6MJTgfQ-1024.npz
train_Episode has 500 steps and return 407.0.
Starting evaluation at step 65000 Counter(65000) 64937
Saved chunk: 20230921T230213F106695-5tnwFGKoRs32y4P8zVxbMu-7nfnEExlvSnP3pOKn8ENZq-1024.npz
eval_Episode has 500 steps and return 361.0.
train_Episode has 500 steps and return 197.0.
Starting evaluation at step 65500 Counter(65500) 65437
eval_Episode has 500 steps and return 345.0.
Saved chunk: 20230921T230254F190444-4CiPIJsOBERZSUR6MJTgfQ-0W7mdGyv8ZZoIiOk6kPc1p-1024.npz
train_Episode has 500 steps and return 262.0.
Starting evaluation at step 66000 Counter(66000) 65937
Saved chunk: 20230921T230330F735068-7nfnEExlvSnP3pOKn8ENZq-0aeo626eYIDOLXI3uuK3jY-1024.npz
eval_Episode has 500 steps and return 274.0.
train_Episode has 500 steps and return 324.0.
Starting evaluation at step 66500 Counter(66500) 66437
eval_Episode has 500 steps and return 199.0.
Saved chunk: 20230921T230413F169965-0W7mdGyv8ZZoIiOk6kPc1p-0UuqMvEw6TGkKSEVBRsSg4-1024.npz
train_Episode has 500 steps and return 338.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 133702 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 199 / eval_episode/reward_rate 0.21 / episode/length 500 / episode/score 338 / episode/reward_rate 0.34 / train/action_mag 3 / train/action_max 2.99 / train/action_mean 0.12 / train/action_min -2.17 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 3.2e4 / train/actor_opt_loss -192.51 / train/adv_mag 1.04 / train/adv_max 1.03 / train/adv_mean 0.02 / train/adv_min -0.52 / 
train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 3.4e-10 / train/cont_loss_std 8.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.51 / 
train/dyn_loss_std 5.87 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.72 / train/extr_critic_critic_opt_grad_steps 3.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 114.92 / train/extr_critic_max 114.92 / train/extr_critic_mean 68.7 / train/extr_critic_min 35.02 / train/extr_critic_std 13.65 / train/extr_return_normed_mag 1.68 / train/extr_return_normed_max 1.68 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 127.52 / train/extr_return_raw_max 127.52 / train/extr_return_raw_mean 69.62 / train/extr_return_raw_min 41.95 / train/extr_return_raw_std 14.74 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.15 / train/extr_reward_min 0 / train/extr_reward_std 0.5 / train/image_loss_mean 0.57 / train/image_loss_std 0.65 / train/model_loss_mean 2.1 / train/model_loss_std 4.01 / 
train/model_opt_grad_norm 10.42 / train/model_opt_grad_steps 3.2e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 5777.2 / train/policy_entropy_mag 1.31 / train/policy_entropy_max 1.31 / 
train/policy_entropy_mean -0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.43 / train/policy_logprob_mag 7.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.47 / train/policy_logprob_min -7.72 / train/policy_logprob_std 0.83 / 
train/policy_randomness_mag 0.95 / train/policy_randomness_max 0.95 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 1.9e-3 / train/policy_randomness_std 0.19 / train/post_ent_mag 57.35 / train/post_ent_max 57.35 / train/post_ent_mean 36.3 / 
train/post_ent_min 19.23 / train/post_ent_std 5.69 / train/prior_ent_mag 71.95 / train/prior_ent_max 71.95 / train/prior_ent_mean 38.82 / train/prior_ent_min 25.07 / train/prior_ent_std 6.57 / train/rep_loss_mean 2.51 / train/rep_loss_std 5.87 / train/reward_avg 0.15 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.34 / train/reward_pred 0.15 / train/reward_rate 0.08 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.63 / report/cont_avg 1 / report/cont_loss_mean 3.8e-10 / report/cont_loss_std 7.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.39 / report/dyn_loss_std 5.51 / report/image_loss_mean 0.48 / report/image_loss_std 0.51 / report/model_loss_mean 1.95 / report/model_loss_std 3.74 / report/post_ent_mag 56.65 / report/post_ent_max 56.65 / 
report/post_ent_mean 38.67 / report/post_ent_min 21.39 / report/post_ent_std 6.04 / report/prior_ent_mag 72.07 / report/prior_ent_max 72.07 / report/prior_ent_mean 40.99 / report/prior_ent_min 25.99 / report/prior_ent_std 6.63 / report/rep_loss_mean 2.39 / 
report/rep_loss_std 5.51 / report/reward_avg 0.36 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.21 / report/reward_pred 0.36 / report/reward_rate 0.19 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-10 / eval/cont_loss_std 5.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.14 / eval/dyn_loss_std 6.23 / eval/image_loss_mean 0.69 / eval/image_loss_std 0.94 / eval/model_loss_mean 2.59 / eval/model_loss_std 4.31 / eval/post_ent_mag 59.73 / eval/post_ent_max 59.73 / eval/post_ent_mean 
34.96 / eval/post_ent_min 20.31 / eval/post_ent_std 5.7 / eval/prior_ent_mag 72.07 / eval/prior_ent_max 72.07 / eval/prior_ent_mean 37.95 / eval/prior_ent_min 25.85 / eval/prior_ent_std 6.46 / eval/rep_loss_mean 3.14 / eval/rep_loss_std 6.23 / eval/reward_avg 0.03 / 
eval/reward_loss_mean 0.01 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.58 / eval/reward_pred 0.03 / eval/reward_rate 0.02 / replay/size
6.7e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3854 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.1e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.88 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8e-3 / 
timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 2.2e-4 / timer/agent.train_count 1927 / timer/agent.train_total 243.32 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.69

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 67000 Counter(67000) 66937
Saved chunk: 20230921T230448F103979-0aeo626eYIDOLXI3uuK3jY-42ejhdTAl4cb2Wo8QSc5FD-1024.npz
eval_Episode has 500 steps and return 204.0.
train_Episode has 500 steps and return 314.0.
Starting evaluation at step 67500 Counter(67500) 67437
eval_Episode has 500 steps and return 134.0.
Saved chunk: 20230921T230532F138107-0UuqMvEw6TGkKSEVBRsSg4-76tZchNOIBlwp7tQOed58B-1024.npz
train_Episode has 500 steps and return 240.0.
Starting evaluation at step 68000 Counter(68000) 67937
Saved chunk: 20230921T230606F226309-42ejhdTAl4cb2Wo8QSc5FD-65gTKeSuX0kJzx6nNP1045-1024.npz
eval_Episode has 500 steps and return 292.0.
train_Episode has 500 steps and return 304.0.
Starting evaluation at step 68500 Counter(68500) 68437
eval_Episode has 500 steps and return 86.0.
Saved chunk: 20230921T230652F099869-76tZchNOIBlwp7tQOed58B-5nHDNQvWPOHocZIIXqBrDW-1024.npz
train_Episode has 500 steps and return 263.0.
Starting evaluation at step 69000 Counter(69000) 68937
Saved chunk: 20230921T230724F109846-65gTKeSuX0kJzx6nNP1045-2lh3EHRSoc8wsri0bqWRMt-1024.npz
eval_Episode has 500 steps and return 194.0.
train_Episode has 500 steps and return 159.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T230841F728514-2lh3EHRSoc8wsri0bqWRMt-0000000000000000000000-105.npz
Saved chunk: 20230921T230811F369048-5nHDNQvWPOHocZIIXqBrDW-0000000000000000000000-793.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 69500 Counter(69500) 69437
eval_Episode has 500 steps and return 190.0.
Saved chunk: 20230921T230811F369048-5nHDNQvWPOHocZIIXqBrDW-67knUBLGPy6tuQc9qMlBIa-1024.npz
train_Episode has 500 steps and return 158.0.
Starting evaluation at step 70000 Counter(70000) 69937
Saved chunk: 20230921T230841F728514-2lh3EHRSoc8wsri0bqWRMt-6IFwZUHzW1cqiTeQ8g8igw-1024.npz
eval_Episode has 500 steps and return 295.0.
train_Episode has 500 steps and return 265.0.
Starting evaluation at step 70500 Counter(70500) 70437
eval_Episode has 500 steps and return 229.0.
train_Episode has 500 steps and return 175.0.
Saved chunk: 20230921T230930F755373-67knUBLGPy6tuQc9qMlBIa-06G5z1CluVZLZmfHyWhXuA-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 141398 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 229 / eval_episode/reward_rate 0.23 / episode/length 500 / episode/score 175 / episode/reward_rate 0.18 / train/action_mag 2.99 / train/action_max 2.98 / train/action_mean 0.11 / train/action_min -2.18 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 3.4e4 / train/actor_opt_loss -169.1 / train/adv_mag 1.16 / train/adv_max 1.16 / train/adv_mean 0.02 / train/adv_min -0.5 / 
train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 2.9e-10 / train/cont_loss_std 6.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.48 / 
train/dyn_loss_std 5.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.71 / train/extr_critic_critic_opt_grad_steps 3.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 139.34 / train/extr_critic_max 139.34 / train/extr_critic_mean 83.57 / train/extr_critic_min 42.46 / train/extr_critic_std 15.91 / train/extr_return_normed_mag 1.63 / train/extr_return_normed_max 1.63 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 151.29 / train/extr_return_raw_max 151.29 / train/extr_return_raw_mean 84.54 / train/extr_return_raw_min 52.96 / train/extr_return_raw_std 17.13 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.17 / train/extr_reward_min 0 / train/extr_reward_std 0.52 / train/image_loss_mean 0.53 / train/image_loss_std 0.63 / train/model_loss_mean 2.05 / train/model_loss_std 3.98 / 
train/model_opt_grad_norm 9.96 / train/model_opt_grad_steps 3.4e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5181.35 / train/policy_entropy_mag 1.3 / train/policy_entropy_max 1.3 / 
train/policy_entropy_mean -0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.46 / train/policy_logprob_mag 7.67 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.41 / train/policy_logprob_min -7.67 / train/policy_logprob_std 0.84 / 
train/policy_randomness_mag 0.95 / train/policy_randomness_max 0.95 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 2.1e-3 / train/policy_randomness_std 0.2 / train/post_ent_mag 57.58 / train/post_ent_max 57.58 / train/post_ent_mean 37.18 / 
train/post_ent_min 19.72 / train/post_ent_std 5.69 / train/prior_ent_mag 72.45 / train/prior_ent_max 72.45 / train/prior_ent_mean 39.63 / train/prior_ent_min 25.69 / train/prior_ent_std 6.54 / train/rep_loss_mean 2.48 / train/rep_loss_std 5.84 / train/reward_avg 0.17 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.32 / train/reward_pred 0.16 / train/reward_rate 0.09 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.57 / report/cont_avg 1 / report/cont_loss_mean 3.3e-10 / report/cont_loss_std 5.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.44 / report/dyn_loss_std 5.87 / report/image_loss_mean 0.52 / report/image_loss_std 0.75 / report/model_loss_mean 2.01 / report/model_loss_std 4.09 / report/post_ent_mag 60.48 / report/post_ent_max 60.48 / 
report/post_ent_mean 36.47 / report/post_ent_min 20.17 / report/post_ent_std 5.73 / report/prior_ent_mag 72.67 / report/prior_ent_max 72.67 / report/prior_ent_mean 39.42 / report/prior_ent_min 22.71 / report/prior_ent_std 6.36 / report/rep_loss_mean 2.44 / 
report/rep_loss_std 5.87 / report/reward_avg 0.13 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.23 / report/reward_pred 0.13 / report/reward_rate 0.07 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-10 / eval/cont_loss_std 4.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.37 / eval/dyn_loss_std 5.18 / eval/image_loss_mean 0.42 / eval/image_loss_std 0.54 / eval/model_loss_mean 1.87 / eval/model_loss_std 3.51 / eval/post_ent_mag 58 / eval/post_ent_max 58 / eval/post_ent_mean 35.63 / 
eval/post_ent_min 22.59 / eval/post_ent_std 5.13 / eval/prior_ent_mag 72.67 / eval/prior_ent_max 72.67 / eval/prior_ent_mean 38.46 / eval/prior_ent_min 27.64 / eval/prior_ent_std 6.32 / eval/rep_loss_mean 2.37 / eval/rep_loss_std 5.18 / eval/reward_avg 0.04 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.3e-3 / eval/reward_pos_acc 0.96 / eval/reward_pos_loss 0.85 / eval/reward_pred 0.03 / eval/reward_rate 0.03 / 
replay/size 7.1e4 / replay/inserts 3848 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3848 / timer/env.step_total 19.2 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 3.7e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.87 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.2e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7856 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1924 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1924 / timer/agent.train_total 243.38 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.64

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 71000 Counter(71000) 70937
Saved chunk: 20230921T230959F483577-6IFwZUHzW1cqiTeQ8g8igw-6aBCBUf080pxD60mg851mM-1024.npz
eval_Episode has 500 steps and return 211.0.
train_Episode has 500 steps and return 252.0.
Starting evaluation at step 71500 Counter(71500) 71437
eval_Episode has 500 steps and return 205.0.
train_Episode has 500 steps and return 166.0.
Saved chunk: 20230921T231049F746322-06G5z1CluVZLZmfHyWhXuA-28YGJJSuqlHDwj5J4e0ONP-1024.npz
Starting evaluation at step 72000 Counter(72000) 71937
Saved chunk: 20230921T231117F713424-6aBCBUf080pxD60mg851mM-0X8LVO4yAHMRWvK2ChLEgk-1024.npz
eval_Episode has 500 steps and return 275.0.
train_Episode has 500 steps and return 425.0.
Starting evaluation at step 72500 Counter(72500) 72437
eval_Episode has 500 steps and return 260.0.
train_Episode has 500 steps and return 160.0.
Saved chunk: 20230921T231209F819103-28YGJJSuqlHDwj5J4e0ONP-57yjXADWr4pJPq1hrpV7W3-1024.npz
Starting evaluation at step 73000 Counter(73000) 72937
eval_Episode has 500 steps and return 153.0.
Saved chunk: 20230921T231235F596323-0X8LVO4yAHMRWvK2ChLEgk-6ZgK9McBe18GrFKznsctgZ-1024.npz
train_Episode has 500 steps and return 229.0.
Starting evaluation at step 73500 Counter(73500) 73437
eval_Episode has 500 steps and return 269.0.
train_Episode has 500 steps and return 242.0.
Saved chunk: 20230921T231328F999005-57yjXADWr4pJPq1hrpV7W3-24mR4teHMnCTIx0tZVwivX-1024.npz
Starting evaluation at step 74000 Counter(74000) 73937
eval_Episode has 500 steps and return 152.0.
train_Episode has 500 steps and return 246.0.
Starting evaluation at step 74500 Counter(74500) 74437
Saved chunk: 20230921T231353F191020-6ZgK9McBe18GrFKznsctgZ-23KmI00CmUulTRMdW1gtg4-1024.npz
eval_Episode has 500 steps and return 195.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 149102 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 195 / eval_episode/reward_rate 0.2 / episode/length 500 / episode/score 246 / episode/reward_rate 0.25 / train/action_mag 2.78 / train/action_max 2.74 / train/action_mean 0.08 / train/action_min -2.26 / train/action_std 0.89 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 3.6e4 / train/actor_opt_loss -130.43 / train/adv_mag 0.94 / train/adv_max 0.94 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 2.8e-10 / train/cont_loss_std 6.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.46 / 
train/dyn_loss_std 5.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.73 / train/extr_critic_critic_opt_grad_steps 3.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 162.36 / train/extr_critic_max 162.36 / train/extr_critic_mean 97.1 / train/extr_critic_min 50.78 / train/extr_critic_std 18.68 / train/extr_return_normed_mag 1.57 / train/extr_return_normed_max 1.57 / train/extr_return_normed_mean 0.43 / 
train/extr_return_normed_min -0.12 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 172.96 / train/extr_return_raw_max 172.96 / train/extr_return_raw_mean 97.98 / train/extr_return_raw_min 61.63 / train/extr_return_raw_std 19.88 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.18 / train/extr_reward_min 0 / train/extr_reward_std 0.54 / train/image_loss_mean 0.52 / train/image_loss_std 0.61 / train/model_loss_mean 2.03 / train/model_loss_std 3.93 / 
train/model_opt_grad_norm 9.12 / train/model_opt_grad_steps 3.6e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0.01 / train/model_opt_model_opt_grad_scale 5286.46 / train/policy_entropy_mag 1.25 / train/policy_entropy_max 1.25 / 
train/policy_entropy_mean -0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.44 / train/policy_logprob_mag 7.47 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.41 / train/policy_logprob_min -7.47 / train/policy_logprob_std 0.83 / 
train/policy_randomness_mag 0.93 / train/policy_randomness_max 0.93 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 2.3e-3 / train/policy_randomness_std 0.19 / train/post_ent_mag 58.4 / train/post_ent_max 58.4 / train/post_ent_mean 37.95 / 
train/post_ent_min 19.96 / train/post_ent_std 5.67 / train/prior_ent_mag 72.81 / train/prior_ent_max 72.81 / train/prior_ent_mean 40.38 / train/prior_ent_min 26.34 / train/prior_ent_std 6.46 / train/rep_loss_mean 2.46 / train/rep_loss_std 5.77 / train/reward_avg 0.18 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.3 / train/reward_pred 0.18 / train/reward_rate 0.09 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.59 / report/cont_avg 1 / report/cont_loss_mean 3.3e-10 / report/cont_loss_std 5.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.44 / report/dyn_loss_std 5.43 / report/image_loss_mean 0.51 / report/image_loss_std 0.54 / report/model_loss_mean 2.02 / report/model_loss_std 3.69 / report/post_ent_mag 51.68 / report/post_ent_max 51.68 / 
report/post_ent_mean 40.58 / report/post_ent_min 21.25 / report/post_ent_std 5.51 / report/prior_ent_mag 73.07 / report/prior_ent_max 73.07 / report/prior_ent_mean 42.86 / report/prior_ent_min 29.66 / report/prior_ent_std 6 / report/rep_loss_mean 2.44 / 
report/rep_loss_std 5.43 / report/reward_avg 0.32 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.23 / report/reward_pred 0.31 / report/reward_rate 0.17 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.8 / eval/dyn_loss_std 5.63 / eval/image_loss_mean 0.59 / eval/image_loss_std 0.91 / eval/model_loss_mean 2.29 / eval/model_loss_std 3.91 / eval/post_ent_mag 61.59 / eval/post_ent_max 61.59 / eval/post_ent_mean 
37.18 / eval/post_ent_min 19.34 / eval/post_ent_std 5.4 / eval/prior_ent_mag 73.07 / eval/prior_ent_max 73.07 / eval/prior_ent_mean 39.95 / eval/prior_ent_min 27.29 / eval/prior_ent_std 6.32 / eval/rep_loss_mean 2.8 / eval/rep_loss_std 5.63 / eval/reward_avg 0.04 / 
eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.18 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.43 / eval/reward_pred 0.04 / eval/reward_rate 0.02 / replay/size
7.4e4 / replay/inserts 3852 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3852 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 3.8e-3 / timer/env.step_max 8.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.67 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7860 / timer/agent.policy_total 16.8 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1926 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1926 / timer/agent.train_total 243.88 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 247.0.
Saved chunk: 20230921T231448F146591-24mR4teHMnCTIx0tZVwivX-5fSqap7YFrH06KpSAmF46O-1024.npz
Starting evaluation at step 75000 Counter(75000) 74937
eval_Episode has 500 steps and return 194.0.
train_Episode has 500 steps and return 181.0.
Starting evaluation at step 75500 Counter(75500) 75437
Saved chunk: 20230921T231546F020182-23KmI00CmUulTRMdW1gtg4-66TFfMDJp8SYkzDNZ6zawY-1024.npz
eval_Episode has 500 steps and return 243.0.
train_Episode has 500 steps and return 167.0.
Saved chunk: 20230921T231607F849187-5fSqap7YFrH06KpSAmF46O-6KD8BvGZCtwhFMwVHQF1m1-1024.npz
Starting evaluation at step 76000 Counter(76000) 75937
eval_Episode has 500 steps and return 308.0.
train_Episode has 500 steps and return 228.0.
Starting evaluation at step 76500 Counter(76500) 76437
Saved chunk: 20230921T231704F587476-66TFfMDJp8SYkzDNZ6zawY-781qaPnRau9yIJlE9S2OMi-1024.npz
eval_Episode has 500 steps and return 308.0.
train_Episode has 500 steps and return 179.0.
Saved chunk: 20230921T231727F331065-6KD8BvGZCtwhFMwVHQF1m1-7yQSkzyy4MZ34m51m6cAaV-1024.npz
Starting evaluation at step 77000 Counter(77000) 76937
eval_Episode has 500 steps and return 157.0.
train_Episode has 500 steps and return 238.0.
Starting evaluation at step 77500 Counter(77500) 77437
Saved chunk: 20230921T231822F366707-781qaPnRau9yIJlE9S2OMi-5ZF0VXrOmE62mPBgrG61Eq-1024.npz
eval_Episode has 500 steps and return 266.0.
train_Episode has 500 steps and return 141.0.
Saved chunk: 20230921T231846F616937-7yQSkzyy4MZ34m51m6cAaV-7MqaaxJsJgMtRE0rAYk0Hn-1024.npz
Starting evaluation at step 78000 Counter(78000) 77937
eval_Episode has 500 steps and return 141.0.
train_Episode has 500 steps and return 284.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 156894 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 284 / episode/reward_rate 0.29 / eval_episode/length 500 / eval_episode/score 141 / eval_episode/reward_rate 0.15 / train/action_mag 2.94 / train/action_max 2.86 / train/action_mean 0.06 / train/action_min -2.5 / train/action_std 0.89 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 3.8e4 / train/actor_opt_loss -124.88 / train/adv_mag 0.9 / train/adv_max 0.89 / train/adv_mean 0.01 / train/adv_min -0.49 / 
train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 2.6e-10 / train/cont_loss_std 6.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.44 / 
train/dyn_loss_std 5.79 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.73 / train/extr_critic_critic_opt_grad_steps 3.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 184.6 / train/extr_critic_max 184.6 / train/extr_critic_mean 112.27 / train/extr_critic_min 59.84 / train/extr_critic_std 21.95 / train/extr_return_normed_mag 1.54 / train/extr_return_normed_max 1.54 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 195.34 / train/extr_return_raw_max 195.34 / train/extr_return_raw_mean 113.23 / train/extr_return_raw_min 70.45 / train/extr_return_raw_std 23.11 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.21 / train/extr_reward_min 0 / train/extr_reward_std 0.58 / train/image_loss_mean 0.51 / train/image_loss_std 0.6 / train/model_loss_mean 2.01 / train/model_loss_std 3.92 / 
train/model_opt_grad_norm 9.76 / train/model_opt_grad_steps 3.8e4 / train/model_opt_loss 8765.84 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4371.79 / train/policy_entropy_mag 1.29 / train/policy_entropy_max 1.29 / 
train/policy_entropy_mean -0.38 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.48 / train/policy_logprob_mag 7.86 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.38 / train/policy_logprob_min -7.86 / train/policy_logprob_std 0.86 / 
train/policy_randomness_mag 0.94 / train/policy_randomness_max 0.94 / train/policy_randomness_mean 0.22 / train/policy_randomness_min 2.2e-3 / train/policy_randomness_std 0.21 / train/post_ent_mag 58.52 / train/post_ent_max 58.52 / train/post_ent_mean 38.64 / 
train/post_ent_min 19.96 / train/post_ent_std 5.74 / train/prior_ent_mag 73.25 / train/prior_ent_max 73.25 / train/prior_ent_mean 41.04 / train/prior_ent_min 26.55 / train/prior_ent_std 6.46 / train/rep_loss_mean 2.44 / train/rep_loss_std 5.79 / train/reward_avg 0.2 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.27 / train/reward_pred 0.2 / train/reward_rate 0.11 / 
train_stats/mean_log_entropy -0.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.2e-10 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.35 / report/dyn_loss_std 5.67 / report/image_loss_mean 0.51 / report/image_loss_std 0.59 / report/model_loss_mean 1.94 / report/model_loss_std 3.86 / report/post_ent_mag 61.51 / report/post_ent_max 61.51 / 
report/post_ent_mean 38.14 / report/post_ent_min 12.49 / report/post_ent_std 5.78 / report/prior_ent_mag 73.28 / report/prior_ent_max 73.28 / report/prior_ent_mean 40.56 / report/prior_ent_min 23.51 / report/prior_ent_std 6.52 / report/rep_loss_mean 2.35 / 
report/rep_loss_std 5.67 / report/reward_avg 0.08 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.3 / report/reward_pred 0.08 / report/reward_rate 0.04 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-10 / eval/cont_loss_std 5.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 4 / eval/dyn_loss_std 7.69 / eval/image_loss_mean 1 / eval/image_loss_std 1.99 / eval/model_loss_mean 3.44 / eval/model_loss_std 6.14 / eval/post_ent_mag 59.47 / eval/post_ent_max 59.47 / eval/post_ent_mean 36.16 / 
eval/post_ent_min 18.51 / eval/post_ent_std 6.66 / eval/prior_ent_mag 73.28 / eval/prior_ent_max 73.28 / eval/prior_ent_mean 39.89 / eval/prior_ent_min 26.37 / eval/prior_ent_std 6.76 / eval/rep_loss_mean 4 / eval/rep_loss_std 7.69 / eval/reward_avg 0.22 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.24 / eval/reward_pred 0.22 / eval/reward_rate 0.12 / 
replay/size 7.8e4 / replay/inserts 3896 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.9e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3896 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.74 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7403 / timer/agent.policy_total 15.96 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1948 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1948 / timer/agent.train_total 246.78 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 5e-5 / timer/dataset_eval_frac 1.7e-7 / timer/dataset_eval_avg 5e-5 / timer/dataset_eval_min 5e-5 / timer/dataset_eval_max 5e-5 / fps 25.96

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 78500 Counter(78500) 78437
Saved chunk: 20230921T231939F969442-5ZF0VXrOmE62mPBgrG61Eq-5rWaeXr6nxttH2byEBAt7C-1024.npz
eval_Episode has 500 steps and return 171.0.
train_Episode has 500 steps and return 235.0.
Saved chunk: 20230921T232005F720703-7MqaaxJsJgMtRE0rAYk0Hn-3BqLcRIpEkpxbHesNQrZ5c-1024.npz
Starting evaluation at step 79000 Counter(79000) 78937
eval_Episode has 500 steps and return 704.0.
train_Episode has 500 steps and return 544.0.
Starting evaluation at step 79500 Counter(79500) 79437
Saved chunk: 20230921T232057F953838-5rWaeXr6nxttH2byEBAt7C-4uEBsSTxDDdVINZr1izkli-1024.npz
eval_Episode has 500 steps and return 429.0.
train_Episode has 500 steps and return 574.0.
Saved chunk: 20230921T232125F530838-3BqLcRIpEkpxbHesNQrZ5c-4Kvcp2mgB27Rk4PirCRqZY-1024.npz
Starting evaluation at step 80000 Counter(80000) 79937
eval_Episode has 500 steps and return 218.0.
train_Episode has 500 steps and return 218.0.
Starting evaluation at step 80500 Counter(80500) 80437
Saved chunk: 20230921T232215F990892-4uEBsSTxDDdVINZr1izkli-0hs7dCcvaoWAAsn6vUATAf-1024.npz
eval_Episode has 500 steps and return 471.0.
train_Episode has 500 steps and return 390.0.
Saved chunk: 20230921T232244F970887-4Kvcp2mgB27Rk4PirCRqZY-5oOr3pVDYSDGpUW8P8m0By-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 81000 Counter(81000) 80937
Saved chunk: 20230921T232404F153692-5oOr3pVDYSDGpUW8P8m0By-0000000000000000000000-104.npz
Saved chunk: 20230921T232333F768124-0hs7dCcvaoWAAsn6vUATAf-0000000000000000000000-364.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
eval_Episode has 500 steps and return 586.0.
train_Episode has 500 steps and return 421.0.
Starting evaluation at step 81500 Counter(81500) 81437
Saved chunk: 20230921T232333F768124-0hs7dCcvaoWAAsn6vUATAf-0Flr1NkT6MpvFg1XXknUqo-1024.npz
eval_Episode has 500 steps and return 201.0.
train_Episode has 500 steps and return 494.0.
Saved chunk: 20230921T232404F153692-5oOr3pVDYSDGpUW8P8m0By-1DAWdxjYLGWogfrzakFIZE-1024.npz
Starting evaluation at step 82000 Counter(82000) 81937
eval_Episode has 500 steps and return 427.0.
train_Episode has 500 steps and return 152.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 164586 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 427 / eval_episode/reward_rate 0.43 / episode/length 500 / episode/score 152 / episode/reward_rate 0.16 / train/action_mag 3.35 / train/action_max 3.29 / train/action_mean 6.5e-3 / train/action_min -2.71 / train/action_std 0.89
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 4e4 / train/actor_opt_loss -131.88 / train/adv_mag 0.87 / train/adv_max 0.86 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 2.5e-10 / train/cont_loss_std 5.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.43 / 
train/dyn_loss_std 5.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.77 / train/extr_critic_critic_opt_grad_steps 4e4 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 207 / train/extr_critic_max 207 / train/extr_critic_mean 128.76 / train/extr_critic_min 64.87 / train/extr_critic_std 24.53 / train/extr_return_normed_mag 1.43 / train/extr_return_normed_max 1.43 / train/extr_return_normed_mean 0.45 / 
train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 215.96 / train/extr_return_raw_max 215.96 / train/extr_return_raw_mean 129.94 / train/extr_return_raw_min 76.38 / train/extr_return_raw_std 25.87 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.23 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 0.5 / train/image_loss_std 0.61 / train/model_loss_mean 1.99 / train/model_loss_std 3.92 / 
train/model_opt_grad_norm 9.6 / train/model_opt_grad_steps 4e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5911.46 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / 
train/policy_entropy_mean -0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.52 / train/policy_logprob_mag 7.83 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.39 / train/policy_logprob_min -7.83 / train/policy_logprob_std 0.88 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 2e-3 / train/policy_randomness_std 0.23 / train/post_ent_mag 59.19 / train/post_ent_max 59.19 / train/post_ent_mean 39.41 / 
train/post_ent_min 20.49 / train/post_ent_std 5.69 / train/prior_ent_mag 73.51 / train/prior_ent_max 73.51 / train/prior_ent_mean 41.77 / train/prior_ent_min 27.26 / train/prior_ent_std 6.39 / train/rep_loss_mean 2.43 / train/rep_loss_std 5.76 / train/reward_avg 0.23 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.27 / train/reward_pred 0.23 / train/reward_rate 0.12 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.62 / report/cont_avg 1 / report/cont_loss_mean 2.7e-10 / report/cont_loss_std 5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.44 / report/dyn_loss_std 6.1 / report/image_loss_mean 0.52 / report/image_loss_std 0.74 / report/model_loss_mean 2.03 / report/model_loss_std 4.22 / report/post_ent_mag 53.93 / report/post_ent_max 53.93 / 
report/post_ent_mean 39.64 / report/post_ent_min 19.41 / report/post_ent_std 6.11 / report/prior_ent_mag 73.17 / report/prior_ent_max 73.17 / report/prior_ent_mean 41.83 / report/prior_ent_min 23.97 / report/prior_ent_std 6.78 / report/rep_loss_mean 2.44 / 
report/rep_loss_std 6.1 / report/reward_avg 0.3 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.21 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss
0.23 / report/reward_pred 0.31 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-10 / eval/cont_loss_std 9.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 2.65 / eval/dyn_loss_std 5.73 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.57 / eval/model_loss_mean 2.06 / eval/model_loss_std 3.84 / eval/post_ent_mag 59.53 / eval/post_ent_max 59.53 / eval/post_ent_mean 37.55 / eval/post_ent_min 21.48 / 
eval/post_ent_std 6.09 / eval/prior_ent_mag 73.17 / eval/prior_ent_max 73.17 / eval/prior_ent_mean 40.03 / eval/prior_ent_min 27.9 / eval/prior_ent_std 6.81 / eval/rep_loss_mean 2.65 / eval/rep_loss_std 5.73 / eval/reward_avg 0.09 / eval/reward_loss_mean 0.04 / 
eval/reward_loss_std 0.21 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.5 / eval/reward_pred 0.09 / eval/reward_rate 0.05 / replay/size 8.2e4 / replay/inserts 
3846 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.3e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3846 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 7.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.68 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7854 / timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.1e-4 / 
timer/agent.train_count 1923 / timer/agent.train_total 243.51 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / 
timer/dataset_eval_max 3.9e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 82500 Counter(82500) 82437
Saved chunk: 20230921T232451F499821-0Flr1NkT6MpvFg1XXknUqo-07IaeHqzuLoYHP0UzisEZ5-1024.npz
eval_Episode has 500 steps and return 314.0.
train_Episode has 500 steps and return 415.0.
Saved chunk: 20230921T232523F442052-1DAWdxjYLGWogfrzakFIZE-58C7x5Sn4dh8IjnJYws0qz-1024.npz
Starting evaluation at step 83000 Counter(83000) 82937
eval_Episode has 500 steps and return 446.0.
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 83500 Counter(83500) 83437
Saved chunk: 20230921T232609F651029-07IaeHqzuLoYHP0UzisEZ5-4ZHsVJvh6XyGLVpDYOvLTY-1024.npz
eval_Episode has 500 steps and return 425.0.
train_Episode has 500 steps and return 440.0.
Saved chunk: 20230921T232643F330039-58C7x5Sn4dh8IjnJYws0qz-7kDFASZ5MTif5YliHNoIHI-1024.npz
Starting evaluation at step 84000 Counter(84000) 83937
eval_Episode has 500 steps and return 383.0.
train_Episode has 500 steps and return 607.0.
Starting evaluation at step 84500 Counter(84500) 84437
Saved chunk: 20230921T232727F373764-4ZHsVJvh6XyGLVpDYOvLTY-32CkdmPx33JXc90r1WP8YI-1024.npz
eval_Episode has 500 steps and return 292.0.
train_Episode has 500 steps and return 608.0.
Saved chunk: 20230921T232802F492320-7kDFASZ5MTif5YliHNoIHI-2DqkmwpSkCCYaEO7nAiC9F-1024.npz
Starting evaluation at step 85000 Counter(85000) 84937
eval_Episode has 500 steps and return 554.0.
train_Episode has 500 steps and return 444.0.
Starting evaluation at step 85500 Counter(85500) 85437
Saved chunk: 20230921T232844F866889-32CkdmPx33JXc90r1WP8YI-3FLMhXIqB9A0hR3AXxvxfa-1024.npz
eval_Episode has 500 steps and return 154.0.
train_Episode has 500 steps and return 452.0.
Starting evaluation at step 86000 Counter(86000) 85937
eval_Episode has 500 steps and return 337.0.
Saved chunk: 20230921T232921F514021-2DqkmwpSkCCYaEO7nAiC9F-0iZWveSGALDZSipFXExD12-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 172298 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 337 / eval_episode/reward_rate 0.34 / episode/length 500 / episode/score 452 / episode/reward_rate 0.46 / train/action_mag 3.46 / train/action_max 3.43 / train/action_mean 0.07 / train/action_min -2.67 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 4.2e4 / train/actor_opt_loss -127.44 / train/adv_mag 0.92 / train/adv_max 0.91 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.4e-10 / train/cont_loss_std 5.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.4 / 
train/dyn_loss_std 5.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.73 / train/extr_critic_critic_opt_grad_steps 4.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 240.52 / train/extr_critic_max 240.52 / train/extr_critic_mean 150.04 / train/extr_critic_min 69.91 / train/extr_critic_std 31.54 / train/extr_return_normed_mag 1.32 / train/extr_return_normed_max 1.32 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 249.61 / train/extr_return_raw_max 249.61 / train/extr_return_raw_mean 151.51 / train/extr_return_raw_min 82.5 / train/extr_return_raw_std 33.13 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.25 / train/extr_reward_min -1.9e-9 / train/extr_reward_std 0.63 / train/image_loss_mean 0.48 / train/image_loss_std 0.59 / train/model_loss_mean 1.96 / train/model_loss_std 3.87 / 
train/model_opt_grad_norm 9.78 / train/model_opt_grad_steps 4.2e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5336.79 / train/policy_entropy_mag 1.38 / train/policy_entropy_max 1.38 / 
train/policy_entropy_mean -0.34 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.53 / train/policy_logprob_mag 7.92 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.34 / train/policy_logprob_min -7.92 / train/policy_logprob_std 0.88 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.24 / train/policy_randomness_min 2.8e-3 / train/policy_randomness_std 0.23 / train/post_ent_mag 59.41 / train/post_ent_max 59.41 / train/post_ent_mean 39.79 / 
train/post_ent_min 20.52 / train/post_ent_std 5.74 / train/prior_ent_mag 73.79 / train/prior_ent_max 73.79 / train/prior_ent_mean 42.13 / train/prior_ent_min 27.05 / train/prior_ent_std 6.41 / train/rep_loss_mean 2.4 / train/rep_loss_std 5.7 / train/reward_avg 0.25 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.25 / train/reward_pred 0.25 / train/reward_rate 0.13 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.55 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-10 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 2.42 / report/dyn_loss_std 5.69 / report/image_loss_mean 0.49 / report/image_loss_std 0.55 / report/model_loss_mean 1.96 / report/model_loss_std 3.84 / report/post_ent_mag 62.15 / report/post_ent_max 62.15 / 
report/post_ent_mean 39.09 / report/post_ent_min 18.68 / report/post_ent_std 5.39 / report/prior_ent_mag 73.82 / report/prior_ent_max 73.82 / report/prior_ent_mean 41.22 / report/prior_ent_min 23.08 / report/prior_ent_std 6.48 / report/rep_loss_mean 2.42 / 
report/rep_loss_std 5.69 / report/reward_avg 0.14 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.26 / report/reward_pred 0.14 / report/reward_rate 0.07 / eval/cont_avg 1 / eval/cont_loss_mean 2e-10 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-10 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 2.24 / eval/dyn_loss_std 5.39 / eval/image_loss_mean 0.45 / eval/image_loss_std 0.57 / eval/model_loss_mean 1.83 / eval/model_loss_std 3.69 / eval/post_ent_mag 62.43 / eval/post_ent_max 62.43 / eval/post_ent_mean 40.32 / 
eval/post_ent_min 24.91 / eval/post_ent_std 5.27 / eval/prior_ent_mag 73.82 / eval/prior_ent_max 73.82 / eval/prior_ent_mean 42.29 / eval/prior_ent_min 29.83 / eval/prior_ent_std 6.03 / eval/rep_loss_mean 2.24 / eval/rep_loss_std 5.39 / eval/reward_avg 0.22 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.2 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.26 / eval/reward_pred 0.22 / eval/reward_rate 0.12 / replay/size 
8.6e4 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3856 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.76 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7864 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.4e-3 / 
timer/dataset_train_count 1928 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1928 / timer/agent.train_total 243.94 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 463.0.
Starting evaluation at step 86500 Counter(86500) 86437
Saved chunk: 20230921T233002F351952-3FLMhXIqB9A0hR3AXxvxfa-7FFTQYifCeXpq89uZQlSYI-1024.npz
eval_Episode has 500 steps and return 728.0.
train_Episode has 500 steps and return 716.0.
Starting evaluation at step 87000 Counter(87000) 86937
eval_Episode has 500 steps and return 744.0.
Saved chunk: 20230921T233043F805102-0iZWveSGALDZSipFXExD12-20J1BGyHxmxCIH8SH8fq95-1024.npz
train_Episode has 500 steps and return 568.0.
Starting evaluation at step 87500 Counter(87500) 87437
Saved chunk: 20230921T233120F506355-7FFTQYifCeXpq89uZQlSYI-3tLVNp0AXTBslb2DO1ZiFB-1024.npz
eval_Episode has 500 steps and return 738.0.
train_Episode has 500 steps and return 750.0.
Starting evaluation at step 88000 Counter(88000) 87937
eval_Episode has 500 steps and return 739.0.
Saved chunk: 20230921T233203F684364-20J1BGyHxmxCIH8SH8fq95-1hxBn5C5jMywSireVE9xyp-1024.npz
train_Episode has 500 steps and return 605.0.
Starting evaluation at step 88500 Counter(88500) 88437
Saved chunk: 20230921T233238F127431-3tLVNp0AXTBslb2DO1ZiFB-4r7347WV383V6Os5wG8lZH-1024.npz
eval_Episode has 500 steps and return 733.0.
train_Episode has 500 steps and return 578.0.
Starting evaluation at step 89000 Counter(89000) 88937
eval_Episode has 500 steps and return 739.0.
Saved chunk: 20230921T233322F727721-1hxBn5C5jMywSireVE9xyp-7luvRSYE5Us20sx550REEw-1024.npz
train_Episode has 500 steps and return 720.0.
Starting evaluation at step 89500 Counter(89500) 89437
Saved chunk: 20230921T233355F673303-4r7347WV383V6Os5wG8lZH-1eNDZc3OUtuvK6RlVoO9FF-1024.npz
eval_Episode has 500 steps and return 739.0.
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 90000 Counter(90000) 89937
eval_Episode has 500 steps and return 740.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 180010 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 746 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 740 / eval_episode/reward_rate 0.74 / train/action_mag 3.25 / train/action_max 3.23 / train/action_mean 0.06 / train/action_min -2.49 / train/action_std 0.89 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.29 / train/actor_opt_grad_steps 4.3e4 / train/actor_opt_loss -134.14 / train/adv_mag 0.91 / train/adv_max 0.9 / train/adv_mean 0.01 / train/adv_min -0.49 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.2e-10 / train/cont_loss_std 6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.39 / 
train/dyn_loss_std 5.67 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.73 / train/extr_critic_critic_opt_grad_steps 4.3e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 282.5 / train/extr_critic_max 282.5 / train/extr_critic_mean 177.66 / train/extr_critic_min 87 / train/extr_critic_std 38.07 / train/extr_return_normed_mag 1.25 / train/extr_return_normed_max 1.25 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 291.18 / train/extr_return_raw_max 291.18 / train/extr_return_raw_mean 179.56 / train/extr_return_raw_min 100.99 / train/extr_return_raw_std 39.97
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.3 / train/extr_reward_min -4.3e-9 / train/extr_reward_std 0.68 / train/image_loss_mean 0.48 / train/image_loss_std 0.6 / train/model_loss_mean 1.94 / train/model_loss_std 3.86 / 
train/model_opt_grad_norm 9.91 / train/model_opt_grad_steps 4.3e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5569.95 / train/policy_entropy_mag 1.35 / train/policy_entropy_max 1.35 / 
train/policy_entropy_mean -0.32 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.49 / train/policy_logprob_mag 7.66 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.32 / train/policy_logprob_min -7.66 / train/policy_logprob_std 0.86 / 
train/policy_randomness_mag 0.97 / train/policy_randomness_max 0.97 / train/policy_randomness_mean 0.24 / train/policy_randomness_min 2.3e-3 / train/policy_randomness_std 0.21 / train/post_ent_mag 59.12 / train/post_ent_max 59.12 / train/post_ent_mean 40.34 / 
train/post_ent_min 20.94 / train/post_ent_std 5.6 / train/prior_ent_mag 74.01 / train/prior_ent_max 74.01 / train/prior_ent_mean 42.61 / train/prior_ent_min 27.69 / train/prior_ent_std 6.28 / train/rep_loss_mean 2.39 / train/rep_loss_std 5.67 / train/reward_avg 0.3 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.22 / train/reward_pred 0.3 / train/reward_rate 0.16 /
train_stats/mean_log_entropy -0.19 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-10 / report/cont_loss_std 8.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.29 / report/dyn_loss_std 5.59 / report/image_loss_mean 0.39 / report/image_loss_std 0.52 / report/model_loss_mean 1.78 / report/model_loss_std 3.75 / report/post_ent_mag 63.98 / report/post_ent_max 63.98 / 
report/post_ent_mean 38.68 / report/post_ent_min 19.93 / report/post_ent_std 5.9 / report/prior_ent_mag 73.92 / report/prior_ent_max 73.92 / report/prior_ent_mean 40.86 / report/prior_ent_min 24.26 / report/prior_ent_std 6.76 / report/rep_loss_mean 2.29 / 
report/rep_loss_std 5.59 / report/reward_avg 0.19 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.21 / report/reward_pred 0.19 / report/reward_rate 0.1 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-10 / eval/cont_loss_std 4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-10 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 4.49 / eval/dyn_loss_std 10.62 / eval/image_loss_mean 0.95 / eval/image_loss_std 2.31 / eval/model_loss_mean 3.68 / eval/model_loss_std 8.44 / eval/post_ent_mag 63.98 / eval/post_ent_max 63.98 / eval/post_ent_mean 40.17 / 
eval/post_ent_min 12.24 / eval/post_ent_std 6.85 / eval/prior_ent_mag 73.92 / eval/prior_ent_max 73.92 / eval/prior_ent_mean 43.01 / eval/prior_ent_min 29.75 / eval/prior_ent_std 5.87 / eval/rep_loss_mean 4.49 / eval/rep_loss_std 10.62 / eval/reward_avg 0.17 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.7e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.33 / eval/reward_pred 0.17 / eval/reward_rate 0.1 / 
replay/size 9e4 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3856 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.36 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7864 / timer/agent.policy_total 16.88 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1928 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1928 / timer/agent.train_total 243.9 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.9e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.9e-5 / timer/dataset_eval_min 4.9e-5 / timer/dataset_eval_max 4.9e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T233441F858028-7luvRSYE5Us20sx550REEw-74NxZbJtmu4pZCk3gd7AF6-1024.npz
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 90500 Counter(90500) 90437
Saved chunk: 20230921T233513F165303-1eNDZc3OUtuvK6RlVoO9FF-19Q6p61dbrC9njeDfbLI75-1024.npz
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 578.0.
Starting evaluation at step 91000 Counter(91000) 90937
eval_Episode has 500 steps and return 738.0.
Saved chunk: 20230921T233601F379172-74NxZbJtmu4pZCk3gd7AF6-7AQ93mg0JV35vxUa7b2bBA-1024.npz
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 91500 Counter(91500) 91437
Saved chunk: 20230921T233631F342774-19Q6p61dbrC9njeDfbLI75-0YapgSk6O7RpJ41PdIGJBN-1024.npz
eval_Episode has 500 steps and return 726.0.
train_Episode has 500 steps and return 715.0.
Starting evaluation at step 92000 Counter(92000) 91937
eval_Episode has 500 steps and return 739.0.
Saved chunk: 20230921T233720F784273-7AQ93mg0JV35vxUa7b2bBA-7DzkCIOFQrv0zqr3V9YV33-1024.npz
train_Episode has 500 steps and return 729.0.
Starting evaluation at step 92500 Counter(92500) 92437
Saved chunk: 20230921T233749F039001-0YapgSk6O7RpJ41PdIGJBN-6W44X6A4jlPlCiUMXrXSs9-1024.npz
eval_Episode has 500 steps and return 713.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T233906F466367-6W44X6A4jlPlCiUMXrXSs9-0000000000000000000000-100.npz
Saved chunk: 20230921T233839F821002-7DzkCIOFQrv0zqr3V9YV33-0000000000000000000000-440.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 93000 Counter(93000) 92937
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 740.0.
Saved chunk: 20230921T233839F821002-7DzkCIOFQrv0zqr3V9YV33-0dqNKZJw14TcoTixWOznwe-1024.npz
Starting evaluation at step 93500 Counter(93500) 93437
Saved chunk: 20230921T233906F466367-6W44X6A4jlPlCiUMXrXSs9-6ic8UdKcyQgKd7zNqOpCK9-1024.npz
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 709.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 187810 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 709 / episode/reward_rate 0.71 / eval_episode/length 500 / eval_episode/score 742 / eval_episode/reward_rate 0.74 / train/action_mag 3.3 / train/action_max 3.27 / train/action_mean 0.07 / train/action_min -2.69 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.3 / train/actor_opt_grad_steps 4.5e4 / train/actor_opt_loss -133.09 / train/adv_mag 0.87 / train/adv_max 0.86 / train/adv_mean 0.01 / train/adv_min -0.52 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.1e-10 / train/cont_loss_std 5.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.37 / 
train/dyn_loss_std 5.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.81 / train/extr_critic_critic_opt_grad_steps 4.5e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 336.35 / train/extr_critic_max 336.35 / train/extr_critic_mean 210.57 / train/extr_critic_min 95.12 / train/extr_critic_std 50.11 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.17 / train/extr_return_normed_mean 0.42 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 343.83 / train/extr_return_raw_max 343.83 / train/extr_return_raw_mean 212.98 / train/extr_return_raw_min 111.15 / train/extr_return_raw_std 52.31 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.33 / train/extr_reward_min -4.9e-9 / train/extr_reward_std 0.71 / train/image_loss_mean 0.46 / train/image_loss_std 0.58 / train/model_loss_mean 1.92 / train/model_loss_std 3.83 / 
train/model_opt_grad_norm 8.64 / train/model_opt_grad_steps 4.5e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6179.49 / train/policy_entropy_mag 1.36 / train/policy_entropy_max 1.36 / 
train/policy_entropy_mean -0.25 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.54 / train/policy_logprob_mag 7.99 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.25 / train/policy_logprob_min -7.99 / train/policy_logprob_std 0.89 / 
train/policy_randomness_mag 0.97 / train/policy_randomness_max 0.97 / train/policy_randomness_mean 0.28 / train/policy_randomness_min 1.8e-3 / train/policy_randomness_std 0.24 / train/post_ent_mag 60.29 / train/post_ent_max 60.29 / train/post_ent_mean 40.69 / 
train/post_ent_min 20.97 / train/post_ent_std 5.52 / train/prior_ent_mag 74.08 / train/prior_ent_max 74.08 / train/prior_ent_mean 42.94 / train/prior_ent_min 27.6 / train/prior_ent_std 6.18 / train/rep_loss_mean 2.37 / train/rep_loss_std 5.63 / train/reward_avg 0.33 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.21 / train/reward_pred 0.33 / train/reward_rate 0.17 / 
train_stats/mean_log_entropy 0.1 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 8.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.47 / report/dyn_loss_std 6.07 / report/image_loss_mean 0.46 / report/image_loss_std 0.56 / report/model_loss_mean 1.97 / report/model_loss_std 4.09 / report/post_ent_mag 63.34 / report/post_ent_max 63.34 / 
report/post_ent_mean 39.71 / report/post_ent_min 19.94 / report/post_ent_std 6 / report/prior_ent_mag 74.6 / report/prior_ent_max 74.6 / report/prior_ent_mean 41.89 / report/prior_ent_min 23.77 / report/prior_ent_std 6.76 / report/rep_loss_mean 2.47 / report/rep_loss_std 
6.07 / report/reward_avg 0.23 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.22 / 
report/reward_pred 0.23 / report/reward_rate 0.12 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-10 / eval/cont_loss_std 4.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.18 / eval/dyn_loss_std 6.27 / eval/image_loss_mean 0.73 / eval/image_loss_std 1.51 / eval/model_loss_mean 2.66 / eval/model_loss_std 4.89 / eval/post_ent_mag 64.11 / eval/post_ent_max 64.11 / eval/post_ent_mean 40.18 / eval/post_ent_min 19.16 / 
eval/post_ent_std 6.07 / eval/prior_ent_mag 74.6 / eval/prior_ent_max 74.6 / eval/prior_ent_mean 43.31 / eval/prior_ent_min 33.58 / eval/prior_ent_std 5.78 / eval/rep_loss_mean 3.18 / eval/rep_loss_std 6.27 / eval/reward_avg 0.09 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.29 / eval/reward_pred 0.09 / eval/reward_rate 0.05 / replay/size 9.4e4 / replay/inserts 
3900 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.4e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3900 / timer/env.step_total 19.29 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.2 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / 
timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7407 / timer/agent.policy_total 16.19 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1950 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.9e-4 / 
timer/agent.train_count 1950 / timer/agent.train_total 246.62 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / 
timer/dataset_eval_max 3.9e-5 / fps 26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 94000 Counter(94000) 93937
eval_Episode has 500 steps and return 734.0.
train_Episode has 500 steps and return 734.0.
Saved chunk: 20230921T233959F046011-0dqNKZJw14TcoTixWOznwe-4qaIOMJi2vl6YWTngaeDdA-1024.npz
Starting evaluation at step 94500 Counter(94500) 94437
Saved chunk: 20230921T234024F172083-6ic8UdKcyQgKd7zNqOpCK9-7FrpHSiw1T2rIg1K3VmGu2-1024.npz
eval_Episode has 500 steps and return 735.0.
train_Episode has 500 steps and return 729.0.
Starting evaluation at step 95000 Counter(95000) 94937
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 736.0.
Saved chunk: 20230921T234118F827956-4qaIOMJi2vl6YWTngaeDdA-36RksXmtdKr9bnanTp9kHY-1024.npz
Starting evaluation at step 95500 Counter(95500) 95437
Saved chunk: 20230921T234142F543841-7FrpHSiw1T2rIg1K3VmGu2-1YpXjMceBoVHK8lHIrgh84-1024.npz
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 96000 Counter(96000) 95937
eval_Episode has 500 steps and return 696.0.
train_Episode has 500 steps and return 737.0.
Saved chunk: 20230921T234238F064594-36RksXmtdKr9bnanTp9kHY-4n8AZToHEbrLx81pVTltzd-1024.npz
Starting evaluation at step 96500 Counter(96500) 96437
eval_Episode has 500 steps and return 743.0.
Saved chunk: 20230921T234300F168486-1YpXjMceBoVHK8lHIrgh84-1k2f1JLB7WKIoFTQ6O8nm3-1024.npz
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 97000 Counter(97000) 96937
eval_Episode has 500 steps and return 744.0.
train_Episode has 500 steps and return 757.0.
Saved chunk: 20230921T234357F232195-4n8AZToHEbrLx81pVTltzd-73PI4YKxwQQYlOeUKVLoUB-1024.npz
Starting evaluation at step 97500 Counter(97500) 97437
eval_Episode has 500 steps and return 737.0.
train_Episode has 500 steps and return 752.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 195518 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 737 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 752 / episode/reward_rate 0.75 / train/action_mag 3.44 / train/action_max 3.36 / train/action_mean 0.08 / train/action_min -2.98 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 4.7e4 / train/actor_opt_loss -135.3 / train/adv_mag 0.84 / train/adv_max 0.83 / train/adv_mean 0.01 / train/adv_min -0.51 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.9e-10 / train/cont_loss_std 4.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.31 / 
train/dyn_loss_std 5.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.8 / train/extr_critic_critic_opt_grad_steps 4.7e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 404.62 / train/extr_critic_max 404.62 / train/extr_critic_mean 256.26 / train/extr_critic_min 110.67 / train/extr_critic_std 66.54 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.44 / 
train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 410.35 / train/extr_return_raw_max 410.35 / train/extr_return_raw_mean 259.36 / train/extr_return_raw_min 130.69 / train/extr_return_raw_std 69.04
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.39 / train/extr_reward_min -4.9e-9 / train/extr_reward_std 0.76 / train/image_loss_mean 0.44 / train/image_loss_std 0.56 / train/model_loss_mean 1.87 / train/model_loss_std 3.74 / 
train/model_opt_grad_norm 9.04 / train/model_opt_grad_steps 4.7e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7409.33 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / 
train/policy_entropy_mean -0.2 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.2 / train/policy_logprob_min -8.04 / train/policy_logprob_std 0.92 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.29 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.25 / train/post_ent_mag 59.84 / train/post_ent_max 59.84 / train/post_ent_mean 41.11 / 
train/post_ent_min 21.15 / train/post_ent_std 5.48 / train/prior_ent_mag 74.09 / train/prior_ent_max 74.09 / train/prior_ent_mean 43.27 / train/prior_ent_min 28.26 / train/prior_ent_std 6.14 / train/rep_loss_mean 2.31 / train/rep_loss_std 5.51 / train/reward_avg 0.41 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.19 / train/reward_pred 0.41 / train/reward_rate 0.21 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.12 / report/cont_avg 1 / report/cont_loss_mean 2.6e-10 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.18 / report/dyn_loss_std 5.29 / report/image_loss_mean 0.4 / report/image_loss_std 0.41 / report/model_loss_mean 1.76 / report/model_loss_std 3.47 / report/post_ent_mag 60.79 / report/post_ent_max 60.79 / 
report/post_ent_mean 42.87 / report/post_ent_min 24.4 / report/post_ent_std 4.84 / report/prior_ent_mag 73.91 / report/prior_ent_max 73.91 / report/prior_ent_mean 44.72 / report/prior_ent_min 30.13 / report/prior_ent_std 5.47 / report/rep_loss_mean 2.18 / 
report/rep_loss_std 5.29 / report/reward_avg 0.54 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.16 / report/reward_pred 0.54 / report/reward_rate 0.28 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 5.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.47 / eval/dyn_loss_std 6.02 / eval/image_loss_mean 0.48 / eval/image_loss_std 0.5 / eval/model_loss_mean 1.99 / eval/model_loss_std 3.97 / eval/post_ent_mag 62.82 / eval/post_ent_max 62.82 / eval/post_ent_mean 
41.53 / eval/post_ent_min 22.47 / eval/post_ent_std 5.04 / eval/prior_ent_mag 73.91 / eval/prior_ent_max 73.91 / eval/prior_ent_mean 43.65 / eval/prior_ent_min 30.72 / eval/prior_ent_std 5.8 / eval/rep_loss_mean 2.47 / eval/rep_loss_std 6.02 / eval/reward_avg 0.14 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.21 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.3 / eval/reward_pred 0.14 / eval/reward_rate 0.07 / 
replay/size 9.8e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3854 / timer/env.step_total 18.99 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.74 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.09 / 
timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1927 / timer/agent.train_total 243.76 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.69

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 98000 Counter(98000) 97937
Saved chunk: 20230921T234417F730869-1k2f1JLB7WKIoFTQ6O8nm3-089khTKBWZf9yGX3oBzhtU-1024.npz
eval_Episode has 500 steps and return 737.0.
train_Episode has 500 steps and return 616.0.
Saved chunk: 20230921T234516F114201-73PI4YKxwQQYlOeUKVLoUB-6XD4ZwfKSleNlcdnBK2YNt-1024.npz
Starting evaluation at step 98500 Counter(98500) 98437
eval_Episode has 500 steps and return 610.0.
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 99000 Counter(99000) 98937
Saved chunk: 20230921T234611F103724-089khTKBWZf9yGX3oBzhtU-78FVLXG2HfhOVxP2xVusWD-1024.npz
eval_Episode has 500 steps and return 749.0.
train_Episode has 500 steps and return 728.0.
Saved chunk: 20230921T234635F945120-6XD4ZwfKSleNlcdnBK2YNt-3FY4k26SSnIkKNvORlptFt-1024.npz
Starting evaluation at step 99500 Counter(99500) 99437
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 100000 Counter(100000) 99937
Saved chunk: 20230921T234728F902691-78FVLXG2HfhOVxP2xVusWD-1UMHAcHT2fLQjJxm4k6eFI-1024.npz
eval_Episode has 500 steps and return 744.0.
train_Episode has 500 steps and return 587.0.
Saved chunk: 20230921T234755F177597-3FY4k26SSnIkKNvORlptFt-05zkEPFuCNRmMe6PaITaMh-1024.npz
Starting evaluation at step 100500 Counter(100500) 100437
eval_Episode has 500 steps and return 697.0.
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 101000 Counter(101000) 100937
Saved chunk: 20230921T234846F378562-1UMHAcHT2fLQjJxm4k6eFI-1TJwntEuxJ79Ch5p2JNdS1-1024.npz
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 755.0.
Saved chunk: 20230921T234914F211918-05zkEPFuCNRmMe6PaITaMh-5StpEmcu7XfkRPEWx3bErq-1024.npz
Starting evaluation at step 101500 Counter(101500) 101437
eval_Episode has 500 steps and return 744.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 203226 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 744 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 755 / episode/reward_rate 0.76 / train/action_mag 3.42 / train/action_max 3.28 / train/action_mean 0.07 / train/action_min -3.06 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 4.9e4 / train/actor_opt_loss -132.9 / train/adv_mag 0.78 / train/adv_max 0.78 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.8e-10 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.3 / 
train/dyn_loss_std 5.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.85 / train/extr_critic_critic_opt_grad_steps 4.9e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 474.93 / train/extr_critic_max 474.93 / train/extr_critic_mean 308.11 / train/extr_critic_min 131.27 / train/extr_critic_std 79.6 / train/extr_return_normed_mag 1.07 / train/extr_return_normed_max 1.07 / train/extr_return_normed_mean 0.45 / 
train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 478.28 / train/extr_return_raw_max 478.28 / train/extr_return_raw_mean 311.72 / train/extr_return_raw_min 153.93 / train/extr_return_raw_std 81.86
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.39 / train/extr_reward_min -1.2e-8 / train/extr_reward_std 0.76 / train/image_loss_mean 0.44 / train/image_loss_std 0.56 / train/model_loss_mean 1.86 / train/model_loss_std 3.74 / 
train/model_opt_grad_norm 8.89 / train/model_opt_grad_steps 4.9e4 / train/model_opt_loss 9774.78 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5260.42 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / 
train/policy_entropy_mean -0.23 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 8.08 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.23 / train/policy_logprob_min -8.08 / train/policy_logprob_std 0.92 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.28 / train/policy_randomness_min 7.3e-4 / train/policy_randomness_std 0.26 / train/post_ent_mag 60.32 / train/post_ent_max 60.32 / train/post_ent_mean 41.49 / 
train/post_ent_min 21.45 / train/post_ent_std 5.38 / train/prior_ent_mag 73.99 / train/prior_ent_max 73.99 / train/prior_ent_mean 43.64 / train/prior_ent_min 28.41 / train/prior_ent_std 5.99 / train/rep_loss_mean 2.3 / train/rep_loss_std 5.51 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.19 / train/reward_pred 0.41 / train/reward_rate 0.21 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.27 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 4.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.24 / report/dyn_loss_std 5.3 / report/image_loss_mean 0.43 / report/image_loss_std 0.48 / report/model_loss_mean 1.82 / report/model_loss_std 3.55 / report/post_ent_mag 60.79 / report/post_ent_max 60.79 / 
report/post_ent_mean 40.66 / report/post_ent_min 21.85 / report/post_ent_std 5.55 / report/prior_ent_mag 74.4 / report/prior_ent_max 74.4 / report/prior_ent_mean 42.98 / report/prior_ent_min 30.57 / report/prior_ent_std 6.24 / report/rep_loss_mean 2.24 / 
report/rep_loss_std 5.3 / report/reward_avg 0.2 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.25 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.3 / report/reward_pred 0.2 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-10 / eval/cont_loss_std 5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-10 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 3.62 / eval/dyn_loss_std 7.5 / eval/image_loss_mean 0.81 / eval/image_loss_std 1.81 / eval/model_loss_mean 3.02 / eval/model_loss_std 5.9 / eval/post_ent_mag 63.21 / eval/post_ent_max 63.21 / eval/post_ent_mean 39.75 / 
eval/post_ent_min 17.04 / eval/post_ent_std 6.37 / eval/prior_ent_mag 74.4 / eval/prior_ent_max 74.4 / eval/prior_ent_mean 42.95 / eval/prior_ent_min 29.84 / eval/prior_ent_std 5.98 / eval/rep_loss_mean 3.62 / eval/rep_loss_std 7.5 / eval/reward_avg 0.22 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.29 / eval/reward_pred 0.21 / eval/reward_rate 0.12 / replay/size
1e5 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3854 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.32 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.2e-3 / 
timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1927 / timer/agent.train_total 243.91 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 102000 Counter(102000) 101937
Saved chunk: 20230921T235003F965097-1TJwntEuxJ79Ch5p2JNdS1-6QzPGR9l49WldS4itOCsKO-1024.npz
eval_Episode has 500 steps and return 738.0.
train_Episode has 500 steps and return 744.0.
Saved chunk: 20230921T235033F373039-5StpEmcu7XfkRPEWx3bErq-3yjx1pVUGVxo2XKFtJnWS9-1024.npz
Starting evaluation at step 102500 Counter(102500) 102437
eval_Episode has 500 steps and return 749.0.
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 103000 Counter(103000) 102937
Saved chunk: 20230921T235123F005469-6QzPGR9l49WldS4itOCsKO-2uLf8wtdZY1HVEYXxyF4Qs-1024.npz
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 731.0.
Saved chunk: 20230921T235154F096047-3yjx1pVUGVxo2XKFtJnWS9-6C4agJEjmhVrlNXkwUmvi8-1024.npz
Starting evaluation at step 103500 Counter(103500) 103437
eval_Episode has 500 steps and return 749.0.
train_Episode has 500 steps and return 706.0.
Starting evaluation at step 104000 Counter(104000) 103937
Saved chunk: 20230921T235240F740112-2uLf8wtdZY1HVEYXxyF4Qs-4nH72mRfmkMwqheWEtQPyn-1024.npz
eval_Episode has 500 steps and return 746.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T235358F275650-4nH72mRfmkMwqheWEtQPyn-0000000000000000000000-359.npz
Saved chunk: 20230921T235313F252713-6C4agJEjmhVrlNXkwUmvi8-0000000000000000000000-776.npz
train_Episode has 500 steps and return 739.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230921T235313F252713-6C4agJEjmhVrlNXkwUmvi8-4MUz7MbN0IhPVlOjdUWO7p-1024.npz
Starting evaluation at step 104500 Counter(104500) 104437
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 105000 Counter(105000) 104937
Saved chunk: 20230921T235358F275650-4nH72mRfmkMwqheWEtQPyn-5cTzmIifFDU42BeYXZ1nWn-1024.npz
eval_Episode has 500 steps and return 741.0.
train_Episode has 500 steps and return 689.0.
Saved chunk: 20230921T235432F623164-4MUz7MbN0IhPVlOjdUWO7p-5bJhp8gSPiky1qfJsIrqbq-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 210998 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 689 / episode/reward_rate 0.69 / eval_episode/length 500 / eval_episode/score 741 / eval_episode/reward_rate 0.74 / train/action_mag 3.37 / train/action_max 3.25 / train/action_mean 0.08 / train/action_min -2.97 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 5.1e4 / train/actor_opt_loss -119.9 / train/adv_mag 0.69 / train/adv_max 0.68 / train/adv_mean 0.01 / train/adv_min -0.49 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.7e-10 / train/cont_loss_std 4.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.3 / 
train/dyn_loss_std 5.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.72 / train/extr_critic_critic_opt_grad_steps 5.1e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 542.74 / train/extr_critic_max 542.74 / train/extr_critic_mean 370.45 / train/extr_critic_min 164.08 / train/extr_critic_std 91.17 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.48 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 544.91 / train/extr_return_raw_max 544.91 / train/extr_return_raw_mean 374.08 / train/extr_return_raw_min 187.79 / train/extr_return_raw_std 93.09
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.44 / train/extr_reward_min -1.3e-8 / train/extr_reward_std 0.79 / train/image_loss_mean 0.43 / train/image_loss_std 0.57 / train/model_loss_mean 1.85 / train/model_loss_std 3.72 / 
train/model_opt_grad_norm 9.2 / train/model_opt_grad_steps 5.1e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5846.15 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / 
train/policy_entropy_mean -0.22 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.59 / train/policy_logprob_mag 7.98 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.22 / train/policy_logprob_min -7.98 / train/policy_logprob_std 0.92 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.29 / train/policy_randomness_min 9.8e-4 / train/policy_randomness_std 0.26 / train/post_ent_mag 59.75 / train/post_ent_max 59.75 / train/post_ent_mean 41.79 / 
train/post_ent_min 21.67 / train/post_ent_std 5.32 / train/prior_ent_mag 74.04 / train/prior_ent_max 74.04 / train/prior_ent_mean 43.9 / train/prior_ent_min 28.81 / train/prior_ent_std 5.95 / train/rep_loss_mean 2.3 / train/rep_loss_std 5.47 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.18 / train/reward_pred 0.45 / train/reward_rate 0.23 
/ train_stats/mean_log_entropy 0.31 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.7e-10 / report/cont_loss_std 4.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.32 / report/dyn_loss_std 5.5 / report/image_loss_mean 0.4 / report/image_loss_std 0.49 / report/model_loss_mean 1.84 / report/model_loss_std 3.69 / report/post_ent_mag 63.44 / report/post_ent_max 63.44 / 
report/post_ent_mean 41.51 / report/post_ent_min 20.05 / report/post_ent_std 5.83 / report/prior_ent_mag 73.78 / report/prior_ent_max 73.78 / report/prior_ent_mean 43.77 / report/prior_ent_min 27.16 / report/prior_ent_std 6.22 / report/rep_loss_mean 2.32 / 
report/rep_loss_std 5.5 / report/reward_avg 0.24 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.27 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.3 / report/reward_pred 0.25 / report/reward_rate 0.13 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-10 / eval/cont_loss_std 3.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.15 / eval/dyn_loss_std 5.98 / eval/image_loss_mean 0.62 / eval/image_loss_std 0.89 / eval/model_loss_mean 2.54 / eval/model_loss_std 4.28 / eval/post_ent_mag 63.44 / eval/post_ent_max 63.44 / eval/post_ent_mean 39.86 / 
eval/post_ent_min 19.65 / eval/post_ent_std 6.1 / eval/prior_ent_mag 73.78 / eval/prior_ent_max 73.78 / eval/prior_ent_mean 42.85 / eval/prior_ent_min 29.73 / eval/prior_ent_std 6.05 / eval/rep_loss_mean 3.15 / eval/rep_loss_std 5.98 / eval/reward_avg 0.28 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.23 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.21 / eval/reward_pred 0.28 / eval/reward_rate 0.15 / replay/size
1.1e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3886 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.6 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7393 / timer/agent.policy_total 15.99 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.88 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.94 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.9

Starting evaluation at step 105500 Counter(105500) 105437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 106000 Counter(106000) 105937
Saved chunk: 20230921T235516F027827-5cTzmIifFDU42BeYXZ1nWn-5Qj0foo6nIPAkYpDDM5Ul5-1024.npz
eval_Episode has 500 steps and return 748.0.
train_Episode has 500 steps and return 742.0.
Saved chunk: 20230921T235551F587794-5bJhp8gSPiky1qfJsIrqbq-0C3oXwzJLHg0NKU2mUQUmh-1024.npz
Starting evaluation at step 106500 Counter(106500) 106437
eval_Episode has 500 steps and return 753.0.
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 107000 Counter(107000) 106937
Saved chunk: 20230921T235634F595078-5Qj0foo6nIPAkYpDDM5Ul5-6MaEmtHFDvVQcOMnmlGFiN-1024.npz
eval_Episode has 500 steps and return 744.0.
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 107500 Counter(107500) 107437
eval_Episode has 500 steps and return 750.0.
Saved chunk: 20230921T235711F942789-0C3oXwzJLHg0NKU2mUQUmh-2WV4bK3qtLboo3q4MTNGeG-1024.npz
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 108000 Counter(108000) 107937
Saved chunk: 20230921T235752F518822-6MaEmtHFDvVQcOMnmlGFiN-1PQ7CAbAYFyEX2v1Dg6APo-1024.npz
eval_Episode has 500 steps and return 744.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 108500 Counter(108500) 108437
eval_Episode has 500 steps and return 738.0.
Saved chunk: 20230921T235834F763448-2WV4bK3qtLboo3q4MTNGeG-1Yg24ORqFCe8gfj3m9PliQ-1024.npz
train_Episode has 500 steps and return 726.0.
Starting evaluation at step 109000 Counter(109000) 108937
Saved chunk: 20230921T235910F233473-1PQ7CAbAYFyEX2v1Dg6APo-3JMNitwjEBi61bjU3Dv8zT-1024.npz
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 742.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 218682 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 742 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 742 / episode/reward_rate 0.74 / eval_stats/mean_log_entropy 0 / train/action_mag 3.43 / train/action_max 3.33 / train/action_mean 0.08 / train/action_min
-3.07 / train/action_std 0.9 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 5.3e4 / train/actor_opt_loss -102.46 / train/adv_mag 0.63 / train/adv_max 0.6 / train/adv_mean
0.01 / train/adv_min -0.48 / train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 
/ train/dyn_loss_mean 2.24 / train/dyn_loss_std 5.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.63 / train/extr_critic_critic_opt_grad_steps 5.3e4 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 606.45 / train/extr_critic_max 606.45 / train/extr_critic_mean 432.24 / train/extr_critic_min 201.21 / train/extr_critic_std 97.24 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.05 / 
train/extr_return_normed_mean 0.51 / train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 605.54 / train/extr_return_raw_max 605.54 / train/extr_return_raw_mean 435.5 / train/extr_return_raw_min 
230.04 / train/extr_return_raw_std 98.71 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.48 / train/extr_reward_min -5.6e-9 / train/extr_reward_std 0.82 / train/image_loss_mean 0.41 / train/image_loss_std 0.54 / train/model_loss_mean 1.81 / 
train/model_loss_std 3.61 / train/model_opt_grad_norm 8.75 / train/model_opt_grad_steps 5.3e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5937.5 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 
1.37 / train/policy_entropy_mean -0.2 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.2 / train/policy_logprob_min -8.13 / train/policy_logprob_std 0.94 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.3 / train/policy_randomness_min 8.3e-4 / train/policy_randomness_std 0.27 / train/post_ent_mag 59.71 / train/post_ent_max 59.71 / train/post_ent_mean 42.04 / 
train/post_ent_min 22.11 / train/post_ent_std 5.18 / train/prior_ent_mag 74.01 / train/prior_ent_max 74.01 / train/prior_ent_mean 44.09 / train/prior_ent_min 28.77 / train/prior_ent_std 5.85 / train/rep_loss_mean 2.24 / train/rep_loss_std 5.33 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.18 / train/reward_pred 0.5 / train/reward_rate 0.25 / 
train_stats/mean_log_entropy 0.43 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 1.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 2.33 / report/dyn_loss_std 5.91 / report/image_loss_mean 0.42 / report/image_loss_std 0.55 / report/model_loss_mean 1.85 / report/model_loss_std 3.97 / report/post_ent_mag 60.81 / report/post_ent_max 60.81 / report/post_ent_mean 40.56 / 
report/post_ent_min 23.22 / report/post_ent_std 5.8 / report/prior_ent_mag 73.9 / report/prior_ent_max 73.9 / report/prior_ent_mean 42.91 / report/prior_ent_min 28.79 / report/prior_ent_std 6.51 / report/rep_loss_mean 2.33 / report/rep_loss_std 5.91 / report/reward_avg 
0.38 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.18 / report/reward_pred 0.38 / 
report/reward_rate 0.2 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-10 / eval/cont_loss_std 4.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.9 / 
eval/dyn_loss_std 6.14 / eval/image_loss_mean 0.57 / eval/image_loss_std 1.06 / eval/model_loss_mean 2.34 / eval/model_loss_std 4.54 / eval/post_ent_mag 63.56 / eval/post_ent_max 63.56 / eval/post_ent_mean 40.23 / eval/post_ent_min 20.44 / eval/post_ent_std 5.89 / 
eval/prior_ent_mag 73.9 / eval/prior_ent_max 73.9 / eval/prior_ent_mean 43.07 / eval/prior_ent_min 27.12 / eval/prior_ent_std 6.06 / eval/rep_loss_mean 2.9 / eval/rep_loss_std 6.14 / eval/reward_avg 0.29 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.15 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.22 / eval/reward_pred 0.29 / eval/reward_rate 0.16 / replay/size 1.1e5 / replay/inserts 3842 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3842 / timer/env.step_total 18.96 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.02 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.91 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1921 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 2.6e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.09 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.16 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 109500 Counter(109500) 109437
eval_Episode has 500 steps and return 743.0.
Saved chunk: 20230921T235953F898146-1Yg24ORqFCe8gfj3m9PliQ-2wvnu400paCTeeLGRHfO2l-1024.npz
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 110000 Counter(110000) 109937
Saved chunk: 20230922T000027F785063-3JMNitwjEBi61bjU3Dv8zT-32MCnkHPFBPUukM1ZdUBzC-1024.npz
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 110500 Counter(110500) 110437
eval_Episode has 500 steps and return 751.0.
Saved chunk: 20230922T000113F788967-2wvnu400paCTeeLGRHfO2l-0ixPug2Xb2GrT1sTeWITTS-1024.npz
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 111000 Counter(111000) 110937
Saved chunk: 20230922T000146F369754-32MCnkHPFBPUukM1ZdUBzC-3XiHYhATtZEUbCZSsTI0JM-1024.npz
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 111500 Counter(111500) 111437
eval_Episode has 500 steps and return 745.0.
Saved chunk: 20230922T000233F235626-0ixPug2Xb2GrT1sTeWITTS-4rTIrza3mnQPED7jG1ylTV-1024.npz
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 112000 Counter(112000) 111937
Saved chunk: 20230922T000304F092310-3XiHYhATtZEUbCZSsTI0JM-0W2Dwst3ddsEav7czWmp2p-1024.npz
eval_Episode has 500 steps and return 748.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 112500 Counter(112500) 112437
eval_Episode has 500 steps and return 744.0.
Saved chunk: 20230922T000352F449435-4rTIrza3mnQPED7jG1ylTV-55HhIHVGk8TIHW32xIsJhb-1024.npz
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 113000 Counter(113000) 112937
Saved chunk: 20230922T000421F746124-0W2Dwst3ddsEav7czWmp2p-6m1qon89G6b4e0ywkuFxXW-1024.npz
eval_Episode has 500 steps and return 750.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 226374 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 750 / eval_episode/reward_rate 0.75 / episode/length 500 / episode/score 746 / episode/reward_rate 0.74 / train/action_mag 3.59 / train/action_max 3.35 / train/action_mean 0.08 / train/action_min -3.4 / train/action_std 0.91 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 5.5e4 / train/actor_opt_loss -65.3 / train/adv_mag 0.61 / train/adv_max 0.54 / train/adv_mean 6.7e-3 / train/adv_min -0.5 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 6.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.22 / 
train/dyn_loss_std 5.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.49 / train/extr_critic_critic_opt_grad_steps 5.5e4 / train/extr_critic_critic_opt_loss 
8859.15 / train/extr_critic_mag 634.55 / train/extr_critic_max 634.55 / train/extr_critic_mean 488.46 / train/extr_critic_min 250.8 / train/extr_critic_std 100.15 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.54 
/ train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 635.15 / train/extr_return_raw_max 635.15 / train/extr_return_raw_mean 490.56 / train/extr_return_raw_min 276.31 / train/extr_return_raw_std 
100.57 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.5 / train/extr_reward_min -4.3e-9 / train/extr_reward_std 0.83 / train/image_loss_mean 0.4 / train/image_loss_std 0.54 / train/model_loss_mean 1.78 / train/model_loss_std 3.56 / 
train/model_opt_grad_norm 8.44 / train/model_opt_grad_steps 5.5e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6666.67 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.14 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.67 / train/policy_logprob_mag 8.25 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.14 / train/policy_logprob_min -8.25 / train/policy_logprob_std 0.97 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.32 / train/policy_randomness_min 8.8e-4 / train/policy_randomness_std 0.29 / train/post_ent_mag 59.61 / train/post_ent_max 59.61 / train/post_ent_mean 42.06 / 
train/post_ent_min 22.06 / train/post_ent_std 5.17 / train/prior_ent_mag 73.84 / train/prior_ent_max 73.84 / train/prior_ent_mean 44.09 / train/prior_ent_min 28.76 / train/prior_ent_std 5.83 / train/rep_loss_mean 2.22 / train/rep_loss_std 5.25 / train/reward_avg 0.52 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.17 / train/reward_pred 0.52 / train/reward_rate 0.27 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.49 / report/cont_avg 1 / report/cont_loss_mean 1.7e-10 / report/cont_loss_std 5.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.38 / report/dyn_loss_std 5.82 / report/image_loss_mean 0.42 / report/image_loss_std 0.53 / report/model_loss_mean 1.88 / report/model_loss_std 3.92 / report/post_ent_mag 61.2 / report/post_ent_max 61.2 / 
report/post_ent_mean 39.99 / report/post_ent_min 24.41 / report/post_ent_std 5.31 / report/prior_ent_mag 73.83 / report/prior_ent_max 73.83 / report/prior_ent_mean 42.22 / report/prior_ent_min 28.8 / report/prior_ent_std 6.17 / report/rep_loss_mean 2.38 / 
report/rep_loss_std 5.82 / report/reward_avg 0.31 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.16 / report/reward_pred 0.31 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.26 / eval/dyn_loss_std 4.58 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.57 / eval/model_loss_mean 1.83 / eval/model_loss_std 3.18 / eval/post_ent_mag 61.2 / eval/post_ent_max 61.2 / eval/post_ent_mean 42 /
eval/post_ent_min 24.45 / eval/post_ent_std 5.55 / eval/prior_ent_mag 73.83 / eval/prior_ent_max 73.83 / eval/prior_ent_mean 44.16 / eval/prior_ent_min 29.78 / eval/prior_ent_std 6.04 / eval/rep_loss_mean 2.26 / eval/rep_loss_std 4.58 / eval/reward_avg 0.27 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.24 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.25 / eval/reward_pred 0.27 / eval/reward_rate 0.14 / 
replay/size 1.1e5 / replay/inserts 3846 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3846 / timer/env.step_total 18.94 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.94 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7854 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.7e-3 / 
timer/dataset_train_count 1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.5e-4 / timer/agent.train_count 1923 / timer/agent.train_total 243.72 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 113500 Counter(113500) 113437
eval_Episode has 500 steps and return 742.0.
Saved chunk: 20230922T000511F634294-55HhIHVGk8TIHW32xIsJhb-31JFOWKUxY6QgQ3y0npHor-1024.npz
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 114000 Counter(114000) 113937
Saved chunk: 20230922T000539F336867-6m1qon89G6b4e0ywkuFxXW-1Y4xad08vxrsZB0x4SimFm-1024.npz
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 114500 Counter(114500) 114437
eval_Episode has 500 steps and return 739.0.
Saved chunk: 20230922T000631F682842-31JFOWKUxY6QgQ3y0npHor-7pHduZp3egCeS6ciJuuzZX-1024.npz
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 115000 Counter(115000) 114937
Saved chunk: 20230922T000657F977563-1Y4xad08vxrsZB0x4SimFm-6b5KglTn8omVCCZ1UU35Rq-1024.npz
eval_Episode has 500 steps and return 748.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 115500 Counter(115500) 115437
eval_Episode has 500 steps and return 746.0.
Saved chunk: 20230922T000751F108765-7pHduZp3egCeS6ciJuuzZX-69hzoynPyWSABuVVlSog66-1024.npz
train_Episode has 500 steps and return 747.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T000815F782460-6b5KglTn8omVCCZ1UU35Rq-0000000000000000000000-618.npz
Saved chunk: 20230922T000910F392287-69hzoynPyWSABuVVlSog66-0000000000000000000000-88.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 116000 Counter(116000) 115937
Saved chunk: 20230922T000815F782460-6b5KglTn8omVCCZ1UU35Rq-5CRr7yeTEbqJ0BbxKyi4u6-1024.npz
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 116500 Counter(116500) 116437
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 741.0.
Saved chunk: 20230922T000910F392287-69hzoynPyWSABuVVlSog66-6lhxCBchIvID15kdx2BXkO-1024.npz
Starting evaluation at step 117000 Counter(117000) 116937
Saved chunk: 20230922T000933F756301-5CRr7yeTEbqJ0BbxKyi4u6-2Ykz0GLCwbKEDWjZ9hAt7n-1024.npz
eval_Episode has 500 steps and return 750.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 234054 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 741 / episode/reward_rate 0.74 / eval_episode/length 500 / eval_episode/score 750 / eval_episode/reward_rate 0.75 / train/action_mag 3.59 / train/action_max 3.41 / train/action_mean 0.07 / train/action_min -3.27 / train/action_std 0.91 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 5.7e4 / train/actor_opt_loss -41.12 / train/adv_mag 0.58 / train/adv_max 0.5 / train/adv_mean 4.2e-3 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.5e-10 / train/cont_loss_std 6.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.21 / 
train/dyn_loss_std 5.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.37 / train/extr_critic_critic_opt_grad_steps 5.7e4 / train/extr_critic_critic_opt_loss 
8446.97 / train/extr_critic_mag 645.4 / train/extr_critic_max 645.4 / train/extr_critic_mean 520.49 / train/extr_critic_min 270.95 / train/extr_critic_std 90.92 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.58 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 643.59 / train/extr_return_raw_max 643.59 / train/extr_return_raw_mean 521.68 / train/extr_return_raw_min 293.92 / train/extr_return_raw_std 91.18
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.54 / train/extr_reward_min -1.9e-9 / train/extr_reward_std 0.85 / train/image_loss_mean 0.4 / train/image_loss_std 0.53 / train/model_loss_mean 1.77 / train/model_loss_std 3.55 / 
train/model_opt_grad_norm 8.82 / train/model_opt_grad_steps 5.7e4 / train/model_opt_loss 9933.44 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5625 / train/policy_entropy_mag 1.38 / train/policy_entropy_max 1.38 / 
train/policy_entropy_mean -0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.67 / train/policy_logprob_mag 8.09 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.16 / train/policy_logprob_min -8.09 / train/policy_logprob_std 0.97 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.31 / train/policy_randomness_min 6.2e-4 / train/policy_randomness_std 0.29 / train/post_ent_mag 59.61 / train/post_ent_max 59.61 / train/post_ent_mean 42.23 / 
train/post_ent_min 22.17 / train/post_ent_std 4.94 / train/prior_ent_mag 73.81 / train/prior_ent_max 73.81 / train/prior_ent_mean 44.23 / train/prior_ent_min 29.05 / train/prior_ent_std 5.66 / train/rep_loss_mean 2.21 / train/rep_loss_std 5.24 / train/reward_avg 0.56 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.16 / train/reward_pred 0.56 / train/reward_rate 0.29 / 
train_stats/mean_log_entropy 0.51 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.26 / report/dyn_loss_std 5.68 / report/image_loss_mean 0.4 / report/image_loss_std 0.5 / report/model_loss_mean 1.79 / report/model_loss_std 3.8 / report/post_ent_mag 49.97 / report/post_ent_max 49.97 / 
report/post_ent_mean 42.04 / report/post_ent_min 20.11 / report/post_ent_std 4.51 / report/prior_ent_mag 73.63 / report/prior_ent_max 73.63 / report/prior_ent_mean 44.21 / report/prior_ent_min 32.98 / report/prior_ent_std 5.24 / report/rep_loss_mean 2.26 / 
report/rep_loss_std 5.68 / report/reward_avg 0.53 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.53 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.35 / eval/dyn_loss_std 5.76 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.69 / eval/model_loss_mean 1.89 / eval/model_loss_std 3.98 / eval/post_ent_mag 64 / eval/post_ent_max 64 / eval/post_ent_mean 42.83 / 
eval/post_ent_min 18.81 / eval/post_ent_std 4.69 / eval/prior_ent_mag 73.63 / eval/prior_ent_max 73.63 / eval/prior_ent_mean 45.02 / eval/prior_ent_min 30.24 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 2.35 / eval/rep_loss_std 5.76 / eval/reward_avg 0.39 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.18 / eval/reward_pred 0.39 / eval/reward_rate 0.2 / replay/size 
1.2e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3840 / timer/env.step_total 18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4.1e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.81 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.44 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 117500 Counter(117500) 117437
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 745.0.
Saved chunk: 20230922T001029F774509-6lhxCBchIvID15kdx2BXkO-5g8zmOcc19FbCpkDbWDjWi-1024.npz
Starting evaluation at step 118000 Counter(118000) 117937
Saved chunk: 20230922T001051F240526-2Ykz0GLCwbKEDWjZ9hAt7n-1LxjVFqT8S3Il7OhGIP2RC-1024.npz
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 750.0.
Starting evaluation at step 118500 Counter(118500) 118437
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 750.0.
Saved chunk: 20230922T001149F928684-5g8zmOcc19FbCpkDbWDjWi-5LLmqut90JpkdgQRIKTKXU-1024.npz
Starting evaluation at step 119000 Counter(119000) 118937
Saved chunk: 20230922T001209F974994-1LxjVFqT8S3Il7OhGIP2RC-0mz6gtwho1sgbj26XRQQ5H-1024.npz
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 748.0.
Starting evaluation at step 119500 Counter(119500) 119437
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 744.0.
Saved chunk: 20230922T001309F281697-5LLmqut90JpkdgQRIKTKXU-5t1oR874Plkq90kGd9jaMD-1024.npz
Starting evaluation at step 120000 Counter(120000) 119937
eval_Episode has 500 steps and return 740.0.
Saved chunk: 20230922T001327F811016-0mz6gtwho1sgbj26XRQQ5H-5Y8gNbwGwAvSCk8sFgijDG-1024.npz
train_Episode has 500 steps and return 748.0.
Starting evaluation at step 120500 Counter(120500) 120437
eval_Episode has 500 steps and return 739.0.
train_Episode has 500 steps and return 745.0.
Saved chunk: 20230922T001428F562632-5t1oR874Plkq90kGd9jaMD-4lunmgaDtcP22PWk3ntTNz-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 241834 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 745 / episode/reward_rate 0.74 / eval_episode/length 500 / eval_episode/score 739 / eval_episode/reward_rate 0.74 / train/action_mag 3.41 / train/action_max 3.32 / train/action_mean 0.08 / train/action_min -2.97 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 5.9e4 / train/actor_opt_loss -29.94 / train/adv_mag 0.62 / train/adv_max 0.55 / train/adv_mean 3.1e-3 / train/adv_min -0.49 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.4e-10 / train/cont_loss_std 4.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.19 / 
train/dyn_loss_std 5.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.36 / train/extr_critic_critic_opt_grad_steps 5.9e4 / train/extr_critic_critic_opt_loss 
9617.65 / train/extr_critic_mag 672.91 / train/extr_critic_max 672.91 / train/extr_critic_mean 534.74 / train/extr_critic_min 293.57 / train/extr_critic_std 90.77 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.55 
/ train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 666.83 / train/extr_return_raw_max 666.83 / train/extr_return_raw_mean 535.59 / train/extr_return_raw_min 320.62 / train/extr_return_raw_std 
91.31 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.54 / train/extr_reward_min -4.9e-9 / train/extr_reward_std 0.85 / train/image_loss_mean 0.39 / train/image_loss_std 0.52 / train/model_loss_mean 1.76 / train/model_loss_std 3.52 / 
train/model_opt_grad_norm 8.42 / train/model_opt_grad_steps 5.9e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6726.8 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / 
train/policy_entropy_mean -0.21 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.62 / train/policy_logprob_mag 8.18 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.21 / train/policy_logprob_min -8.18 / train/policy_logprob_std 0.94 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.29 / train/policy_randomness_min 6.2e-4 / train/policy_randomness_std 0.27 / train/post_ent_mag 59.51 / train/post_ent_max 59.51 / train/post_ent_mean 42.19 / 
train/post_ent_min 22.54 / train/post_ent_std 4.86 / train/prior_ent_mag 73.84 / train/prior_ent_max 73.84 / train/prior_ent_mean 44.19 / train/prior_ent_min 28.93 / train/prior_ent_std 5.63 / train/rep_loss_mean 2.19 / train/rep_loss_std 5.2 / train/reward_avg 0.56 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.17 / train/reward_pred 0.56 / train/reward_rate 0.28 
/ train_stats/mean_log_entropy 0.34 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-10 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.19 / report/dyn_loss_std 5.66 / report/image_loss_mean 0.41 / report/image_loss_std 0.52 / report/model_loss_mean 1.78 / report/model_loss_std 3.82 / report/post_ent_mag 57.01 / report/post_ent_max 57.01 / 
report/post_ent_mean 43.63 / report/post_ent_min 23.51 / report/post_ent_std 3.92 / report/prior_ent_mag 73.4 / report/prior_ent_max 73.4 / report/prior_ent_mean 45.62 / report/prior_ent_min 33.24 / report/prior_ent_std 4.68 / report/rep_loss_mean 2.19 / 
report/rep_loss_std 5.66 / report/reward_avg 0.72 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.15 / report/reward_pred 0.72 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 2.31 / eval/dyn_loss_std 4.83 / eval/image_loss_mean 0.46 / eval/image_loss_std 0.52 / eval/model_loss_mean 1.87 / eval/model_loss_std 3.28 / eval/post_ent_mag 64.64 / eval/post_ent_max 64.64 / eval/post_ent_mean 41.83 / eval/post_ent_min 25.22 / 
eval/post_ent_std 4.15 / eval/prior_ent_mag 73.4 / eval/prior_ent_max 73.4 / eval/prior_ent_mean 44.13 / eval/prior_ent_min 32.87 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 2.31 / eval/rep_loss_std 4.83 / eval/reward_avg 0.21 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.17 / eval/reward_pred 0.22 / eval/reward_rate 0.11 / replay/size 1.2e5 / replay/inserts 3890 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3890 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.05 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.1 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.2e-3 / timer/dataset_train_count 
1945 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.63 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.92

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 121000 Counter(121000) 120937
eval_Episode has 500 steps and return 746.0.
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 121500 Counter(121500) 121437
Saved chunk: 20230922T001445F448222-5Y8gNbwGwAvSCk8sFgijDG-4YEoBfu88QOItL2raXmC90-1024.npz
eval_Episode has 500 steps and return 745.0.
train_Episode has 500 steps and return 734.0.
Saved chunk: 20230922T001547F742420-4lunmgaDtcP22PWk3ntTNz-6W7tts14geA65UlNVnkFWs-1024.npz
Starting evaluation at step 122000 Counter(122000) 121937
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 748.0.
Starting evaluation at step 122500 Counter(122500) 122437
Saved chunk: 20230922T001639F451013-4YEoBfu88QOItL2raXmC90-5wVOlyUyMTURzfF9ypf3OA-1024.npz
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 740.0.
Saved chunk: 20230922T001707F988999-6W7tts14geA65UlNVnkFWs-7HggLQFcrmX0G9gSZvjT33-1024.npz
Starting evaluation at step 123000 Counter(123000) 122937
eval_Episode has 500 steps and return 748.0.
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 123500 Counter(123500) 123437
Saved chunk: 20230922T001757F355276-5wVOlyUyMTURzfF9ypf3OA-1srshDJ12NHO0X4WSq1g1w-1024.npz
eval_Episode has 500 steps and return 749.0.
train_Episode has 500 steps and return 742.0.
Saved chunk: 20230922T001827F432478-7HggLQFcrmX0G9gSZvjT33-2xxagN5853ejBEoTi1rNdL-1024.npz
Starting evaluation at step 124000 Counter(124000) 123937
eval_Episode has 500 steps and return 731.0.
train_Episode has 500 steps and return 713.0.
Starting evaluation at step 124500 Counter(124500) 124437
Saved chunk: 20230922T001915F179528-1srshDJ12NHO0X4WSq1g1w-2qfMoEKk4JF1AM1lzFjYO1-1024.npz
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 730.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 249510 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 742 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 730 / episode/reward_rate 0.73 / train/action_mag 3.47 / train/action_max 3.29 / train/action_mean 0.07 / train/action_min -3.2 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 6.1e4 / train/actor_opt_loss -24.72 / train/adv_mag 0.66 / train/adv_max 0.59 / train/adv_mean 2.6e-3 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.4e-10 / train/cont_loss_std 5.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.17 / 
train/dyn_loss_std 5.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.35 / train/extr_critic_critic_opt_grad_steps 6.1e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 684.85 / train/extr_critic_max 684.85 / train/extr_critic_mean 551.96 / train/extr_critic_min 293.97 / train/extr_critic_std 90.96 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.57 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 677.18 / train/extr_return_raw_max 677.18 / train/extr_return_raw_mean 552.66 / train/extr_return_raw_min 326.63 / train/extr_return_raw_std 91.26
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.6 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.38 / train/image_loss_std 0.52 / train/model_loss_mean 1.73 / train/model_loss_std 3.5 / 
train/model_opt_grad_norm 8.39 / train/model_opt_grad_steps 6.1e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5781.25 / train/policy_entropy_mag 1.38 / train/policy_entropy_max 1.38 / 
train/policy_entropy_mean -0.18 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.64 / train/policy_logprob_mag 8.05 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.18 / train/policy_logprob_min -8.05 / train/policy_logprob_std 0.95 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.3 / train/policy_randomness_min 7.5e-4 / train/policy_randomness_std 0.28 / train/post_ent_mag 59.83 / train/post_ent_max 59.83 / train/post_ent_mean 42.38 / 
train/post_ent_min 22.52 / train/post_ent_std 4.71 / train/prior_ent_mag 73.77 / train/prior_ent_max 73.77 / train/prior_ent_mean 44.33 / train/prior_ent_min 29.38 / train/prior_ent_std 5.51 / train/rep_loss_mean 2.17 / train/rep_loss_std 5.16 / train/reward_avg 0.61 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.61 / train/reward_rate 0.31 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.4 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.99 / report/dyn_loss_std 4.77 / report/image_loss_mean 0.35 / report/image_loss_std 0.4 / report/model_loss_mean 1.6 / report/model_loss_std 3.19 / report/post_ent_mag 59.17 / report/post_ent_max 59.17 / 
report/post_ent_mean 42.92 / report/post_ent_min 20.35 / report/post_ent_std 4.32 / report/prior_ent_mag 74.1 / report/prior_ent_max 74.1 / report/prior_ent_mean 44.75 / report/prior_ent_min 29.24 / report/prior_ent_std 5.32 / report/rep_loss_mean 1.99 / 
report/rep_loss_std 4.77 / report/reward_avg 0.69 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.69 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.31 / eval/dyn_loss_std 5.34 / eval/image_loss_mean 0.42 / eval/image_loss_std 0.73 / eval/model_loss_mean 1.87 / eval/model_loss_std 3.77 / eval/post_ent_mag 63.71 / eval/post_ent_max 63.71 / eval/post_ent_mean 
42.83 / eval/post_ent_min 20.79 / eval/post_ent_std 4.54 / eval/prior_ent_mag 74.1 / eval/prior_ent_max 74.1 / eval/prior_ent_mean 44.93 / eval/prior_ent_min 28.49 / eval/prior_ent_std 5 / eval/rep_loss_mean 2.31 / eval/rep_loss_std 5.34 / eval/reward_avg 0.73 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.15 / eval/reward_pred 0.73 / eval/reward_rate 0.37 / replay/size
1.2e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3838 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.43 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.55 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T001946F804767-2xxagN5853ejBEoTi1rNdL-7iFq3wc7mR2PJCtkSzigZr-1024.npz
Starting evaluation at step 125000 Counter(125000) 124937
eval_Episode has 500 steps and return 754.0.
train_Episode has 500 steps and return 731.0.
Starting evaluation at step 125500 Counter(125500) 125437
Saved chunk: 20230922T002032F927897-2qfMoEKk4JF1AM1lzFjYO1-4WhRKUgTMRjnnLVjcoLyMs-1024.npz
eval_Episode has 500 steps and return 741.0.
train_Episode has 500 steps and return 744.0.
Saved chunk: 20230922T002106F717164-7iFq3wc7mR2PJCtkSzigZr-4uY2yH8XAaiMArgm0l0q5S-1024.npz
Starting evaluation at step 126000 Counter(126000) 125937
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 126500 Counter(126500) 126437
Saved chunk: 20230922T002151F622191-4WhRKUgTMRjnnLVjcoLyMs-6iEYkD8T0ozsZUsX8fGSoL-1024.npz
eval_Episode has 500 steps and return 746.0.
train_Episode has 500 steps and return 741.0.
Saved chunk: 20230922T002226F469850-4uY2yH8XAaiMArgm0l0q5S-4cABHPNrhHJSHXwNX4h8CE-1024.npz
Starting evaluation at step 127000 Counter(127000) 126937
eval_Episode has 500 steps and return 748.0.
train_Episode has 500 steps and return 746.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T002345F853400-4cABHPNrhHJSHXwNX4h8CE-0000000000000000000000-424.npz
Saved chunk: 20230922T002309F583801-6iEYkD8T0ozsZUsX8fGSoL-0000000000000000000000-877.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 127500 Counter(127500) 127437
Saved chunk: 20230922T002309F583801-6iEYkD8T0ozsZUsX8fGSoL-1E8WiWFXrqS9FkEN2SNl0v-1024.npz
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 128000 Counter(128000) 127937
Saved chunk: 20230922T002345F853400-4cABHPNrhHJSHXwNX4h8CE-6bD0OPFjdpT5sKEY1jw0Ji-1024.npz
eval_Episode has 500 steps and return 753.0.
train_Episode has 500 steps and return 745.0.
Starting evaluation at step 128500 Counter(128500) 128437
Saved chunk: 20230922T002427F524016-1E8WiWFXrqS9FkEN2SNl0v-13VXg4PWBogVeJOx1ekuk9-1024.npz
eval_Episode has 500 steps and return 751.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 257176 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 751 / eval_episode/reward_rate 0.75 / episode/length 500 / episode/score 745 / episode/reward_rate 0.74 / train/action_mag 3.53 / train/action_max 3.4 / train/action_mean 0.06 / train/action_min -3.17 / train/action_std 0.89 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 6.3e4 / train/actor_opt_loss -14.11 / train/adv_mag 0.57 / train/adv_max 0.49 / train/adv_mean 1.5e-3 / train/adv_min -0.48 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.14 / 
train/dyn_loss_std 5.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.31 / train/extr_critic_critic_opt_grad_steps 6.3e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 683.59 / train/extr_critic_max 683.59 / train/extr_critic_mean 560 / train/extr_critic_min 327.2 / train/extr_critic_std 87.34 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.59 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 677.33 / train/extr_return_raw_max 677.33 / train/extr_return_raw_mean 560.39 / train/extr_return_raw_min 344.14 / train/extr_return_raw_std 87.64
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.63 / train/extr_reward_min -6.2e-9 / train/extr_reward_std 0.89 / train/image_loss_mean 0.38 / train/image_loss_std 0.52 / train/model_loss_mean 1.71 / train/model_loss_std 3.44 / 
train/model_opt_grad_norm 9.04 / train/model_opt_grad_steps 6.3e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7005.21 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.65 / train/policy_logprob_mag 8 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.16 / train/policy_logprob_min -8 / train/policy_logprob_std 0.96 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.32 / train/policy_randomness_min 5.9e-4 / train/policy_randomness_std 0.28 / train/post_ent_mag 59.9 / train/post_ent_max 59.9 / train/post_ent_mean 42.44 / 
train/post_ent_min 22.96 / train/post_ent_std 4.47 / train/prior_ent_mag 73.7 / train/prior_ent_max 73.7 / train/prior_ent_mean 44.34 / train/prior_ent_min 29.88 / train/prior_ent_std 5.33 / train/rep_loss_mean 2.14 / train/rep_loss_std 5.07 / train/reward_avg 0.64 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.64 / train/reward_rate 0.32 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.3 / report/cont_avg 1 / report/cont_loss_mean 9.3e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.29 / report/dyn_loss_std 5.17 / report/image_loss_mean 0.42 / report/image_loss_std 0.67 / report/model_loss_mean 1.84 / report/model_loss_std 3.62 / report/post_ent_mag 55.49 / report/post_ent_max 55.49 / 
report/post_ent_mean 41.69 / report/post_ent_min 21.74 / report/post_ent_std 4.57 / report/prior_ent_mag 73.43 / report/prior_ent_max 73.43 / report/prior_ent_mean 43.75 / report/prior_ent_min 28.28 / report/prior_ent_std 5.44 / report/rep_loss_mean 2.29 / 
report/rep_loss_std 5.17 / report/reward_avg 0.68 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.68 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.27 / eval/dyn_loss_std 5.86 / eval/image_loss_mean 0.39 / eval/image_loss_std 0.53 / eval/model_loss_mean 1.8 / eval/model_loss_std 3.91 / eval/post_ent_mag 53.84 / eval/post_ent_max 53.84 / eval/post_ent_mean 
42.49 / eval/post_ent_min 23.26 / eval/post_ent_std 4.86 / eval/prior_ent_mag 73.43 / eval/prior_ent_max 73.43 / eval/prior_ent_mean 44.52 / eval/prior_ent_min 28.76 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 2.27 / eval/rep_loss_std 5.86 / eval/reward_avg 0.5 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.7e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.49 / eval/reward_rate 0.25 / replay/size
1.3e5 / replay/inserts 3833 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3833 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.59 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7841 / timer/agent.policy_total 17.15 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.38 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / 
timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 129000 Counter(129000) 128937
eval_Episode has 500 steps and return 747.0.
Saved chunk: 20230922T002505F461721-6bD0OPFjdpT5sKEY1jw0Ji-13o4ImIwNrX7tZYUI9HRN3-1024.npz
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 129500 Counter(129500) 129437
Saved chunk: 20230922T002545F366471-13VXg4PWBogVeJOx1ekuk9-4DQkygYBH56O4yMUxqTD9s-1024.npz
eval_Episode has 500 steps and return 751.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 130000 Counter(130000) 129937
eval_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T002628F963521-13o4ImIwNrX7tZYUI9HRN3-4ENUbDfTQG8n0lrJJQrUuH-1024.npz
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 130500 Counter(130500) 130437
Saved chunk: 20230922T002704F112421-4DQkygYBH56O4yMUxqTD9s-2i17She4ifTbPokYAFHo1P-1024.npz
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 131000 Counter(131000) 130937
eval_Episode has 500 steps and return 748.0.
Saved chunk: 20230922T002748F531262-4ENUbDfTQG8n0lrJJQrUuH-17l2KLCaZImrRn0WFAi1oW-1024.npz
train_Episode has 500 steps and return 750.0.
Starting evaluation at step 131500 Counter(131500) 131437
Saved chunk: 20230922T002821F994299-2i17She4ifTbPokYAFHo1P-3oeBGLoLUqcyhTTkCOWpSI-1024.npz
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 132000 Counter(132000) 131937
eval_Episode has 500 steps and return 751.0.
Saved chunk: 20230922T002907F822588-17l2KLCaZImrRn0WFAi1oW-7BiZLrA71LUjgFKfbfb9MU-1024.npz
train_Episode has 500 steps and return 748.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 264946 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 748 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 751 / eval_episode/reward_rate 0.75 / train/action_mag 3.39 / train/action_max 3.32 / train/action_mean 0.06 / train/action_min -2.98 / train/action_std 0.88 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 6.5e4 / train/actor_opt_loss -10.25 / train/adv_mag 0.55 / train/adv_max 0.46 / train/adv_mean 1.1e-3 / train/adv_min -0.47 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.11 / 
train/dyn_loss_std 4.96 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.29 / train/extr_critic_critic_opt_grad_steps 6.5e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 681.8 / train/extr_critic_max 681.8 / train/extr_critic_mean 564.23 / train/extr_critic_min 345.85 / train/extr_critic_std 86.13 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.02 / train/extr_return_normed_mean 0.59 / 
train/extr_return_normed_min -0.19 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 675.99 / train/extr_return_raw_max 675.99 / train/extr_return_raw_mean 564.52 / train/extr_return_raw_min 361.88 / train/extr_return_raw_std 86.44
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.65 / train/extr_reward_min -5.5e-9 / train/extr_reward_std 0.9 / train/image_loss_mean 0.36 / train/image_loss_std 0.5 / train/model_loss_mean 1.68 / train/model_loss_std 3.36 / 
train/model_opt_grad_norm 8.38 / train/model_opt_grad_steps 6.5e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6572.16 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.17 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.64 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.17 / train/policy_logprob_min -8.04 / train/policy_logprob_std 0.96 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.31 / train/policy_randomness_min 5.9e-4 / train/policy_randomness_std 0.28 / train/post_ent_mag 59.85 / train/post_ent_max 59.85 / train/post_ent_mean 42.28 / 
train/post_ent_min 22.93 / train/post_ent_std 4.44 / train/prior_ent_mag 73.65 / train/prior_ent_max 73.65 / train/prior_ent_mean 44.16 / train/prior_ent_min 29.62 / train/prior_ent_std 5.36 / train/rep_loss_mean 2.11 / train/rep_loss_std 4.96 / train/reward_avg 0.66 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.66 / train/reward_rate 0.33 / 
train_stats/mean_log_entropy 0.33 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 2.14 / report/dyn_loss_std 5 / report/image_loss_mean 0.34 / report/image_loss_std 0.5 / report/model_loss_mean 1.67 / report/model_loss_std 3.35 / report/post_ent_mag 65.44 / report/post_ent_max 65.44 / report/post_ent_mean 
41.27 / report/post_ent_min 22.52 / report/post_ent_std 4.68 / report/prior_ent_mag 74.06 / report/prior_ent_max 74.06 / report/prior_ent_mean 43.14 / report/prior_ent_min 28.16 / report/prior_ent_std 5.67 / report/rep_loss_mean 2.14 / report/rep_loss_std 5 / 
report/reward_avg 0.6 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.3e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 
0.6 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.68 / 
eval/dyn_loss_std 6.15 / eval/image_loss_mean 0.46 / eval/image_loss_std 0.87 / eval/model_loss_mean 2.13 / eval/model_loss_std 4.32 / eval/post_ent_mag 50.78 / eval/post_ent_max 50.78 / eval/post_ent_mean 41.8 / eval/post_ent_min 18.98 / eval/post_ent_std 5.44 / 
eval/prior_ent_mag 74.06 / eval/prior_ent_max 74.06 / eval/prior_ent_mean 43.97 / eval/prior_ent_min 27.26 / eval/prior_ent_std 5.71 / eval/rep_loss_mean 2.68 / eval/rep_loss_std 6.15 / eval/reward_avg 0.86 / eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.17 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.86 / eval/reward_rate 0.44 / replay/size 1.3e5 / replay/inserts 3885 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3885 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.47 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7392 / timer/agent.policy_total 16.11 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1943 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.67 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 132500 Counter(132500) 132437
Saved chunk: 20230922T002939F745388-3oeBGLoLUqcyhTTkCOWpSI-5hk5EAE3anQP6krUK6Gkwf-1024.npz
eval_Episode has 500 steps and return 754.0.
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 133000 Counter(133000) 132937
eval_Episode has 500 steps and return 743.0.
Saved chunk: 20230922T003027F100767-7BiZLrA71LUjgFKfbfb9MU-77IZJP9TT4vlyoRNFMFeCc-1024.npz
train_Episode has 500 steps and return 739.0.
Starting evaluation at step 133500 Counter(133500) 133437
Saved chunk: 20230922T003058F101161-5hk5EAE3anQP6krUK6Gkwf-37Abk3NF63ACJpKHd7Ph06-1024.npz
eval_Episode has 500 steps and return 754.0.
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 134000 Counter(134000) 133937
eval_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T003147F366866-77IZJP9TT4vlyoRNFMFeCc-2OVASDINy8IQkiTbWMFmfe-1024.npz
train_Episode has 500 steps and return 753.0.
Starting evaluation at step 134500 Counter(134500) 134437
Saved chunk: 20230922T003216F225185-37Abk3NF63ACJpKHd7Ph06-3Q61mHjnnI45KhgDl8lO1U-1024.npz
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 748.0.
Starting evaluation at step 135000 Counter(135000) 134937
eval_Episode has 500 steps and return 752.0.
Saved chunk: 20230922T003306F798256-2OVASDINy8IQkiTbWMFmfe-3k1llIWf2vFsuGWr2oQPA7-1024.npz
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 135500 Counter(135500) 135437
Saved chunk: 20230922T003334F060726-3Q61mHjnnI45KhgDl8lO1U-3KhZazSZtAs0g6K1RzaNUG-1024.npz
eval_Episode has 500 steps and return 754.0.
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 136000 Counter(136000) 135937
eval_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T003426F116734-3k1llIWf2vFsuGWr2oQPA7-4qTSMI6YLwTrfHF8EmkLjF-1024.npz
train_Episode has 500 steps and return 747.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 272626 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 755 / eval_episode/reward_rate 0.75 / episode/length 500 / episode/score 747 / episode/reward_rate 0.75 / train/action_mag 3.51 / train/action_max 3.42 / train/action_mean 0.05 / train/action_min -3.15 / train/action_std 0.89 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 6.7e4 / train/actor_opt_loss -9.56 / train/adv_mag 0.56 / train/adv_max 0.47 / train/adv_mean 1e-3 / train/adv_min -0.45 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.08 / 
train/dyn_loss_std 4.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.26 / train/extr_critic_critic_opt_grad_steps 6.7e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 682.1 / train/extr_critic_max 682.1 / train/extr_critic_mean 567.88 / train/extr_critic_min 347.55 / train/extr_critic_std 87.43 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.59 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 677.31 / train/extr_return_raw_max 677.31 / train/extr_return_raw_mean 568.14 / train/extr_return_raw_min 361.91 / train/extr_return_raw_std 87.76
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.68 / train/extr_reward_min -3.7e-9 / train/extr_reward_std 0.91 / train/image_loss_mean 0.35 / train/image_loss_std 0.49 / train/model_loss_mean 1.65 / train/model_loss_std 3.31 / 
train/model_opt_grad_norm 8.37 / train/model_opt_grad_steps 6.7e4 / train/model_opt_loss 9382.93 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 5625 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.13 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.67 / train/policy_logprob_mag 8.11 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.13 / train/policy_logprob_min -8.11 / train/policy_logprob_std 0.98 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.33 / train/policy_randomness_min 7.5e-4 / train/policy_randomness_std 0.29 / train/post_ent_mag 60.25 / train/post_ent_max 60.25 / train/post_ent_mean 42.11 / 
train/post_ent_min 23.14 / train/post_ent_std 4.34 / train/prior_ent_mag 73.62 / train/prior_ent_max 73.62 / train/prior_ent_mean 43.96 / train/prior_ent_min 29.94 / train/prior_ent_std 5.34 / train/rep_loss_mean 2.08 / train/rep_loss_std 4.89 / train/reward_avg 0.69 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.69 / train/reward_rate 0.35 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.18 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2 / report/dyn_loss_std 4.57 / report/image_loss_mean 0.33 / report/image_loss_std 0.71 / report/model_loss_mean 1.58 / report/model_loss_std 3.28 / report/post_ent_mag 63.97 / report/post_ent_max 63.97 / 
report/post_ent_mean 41.38 / report/post_ent_min 18.86 / report/post_ent_std 4.61 / report/prior_ent_mag 73.63 / report/prior_ent_max 73.63 / report/prior_ent_mean 43.19 / report/prior_ent_min 30.12 / report/prior_ent_std 5.47 / report/rep_loss_mean 2 / 
report/rep_loss_std 4.57 / report/reward_avg 0.64 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.64 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.15 / eval/dyn_loss_std 5.29 / eval/image_loss_mean 0.37 / eval/image_loss_std 0.57 / eval/model_loss_mean 1.71 / eval/model_loss_std 3.61 / eval/post_ent_mag 61 / eval/post_ent_max 61 / eval/post_ent_mean 42.7 / 
eval/post_ent_min 22.97 / eval/post_ent_std 4.28 / eval/prior_ent_mag 73.63 / eval/prior_ent_max 73.63 / eval/prior_ent_mean 44.55 / eval/prior_ent_min 31.09 / eval/prior_ent_std 5.02 / eval/rep_loss_mean 2.15 / eval/rep_loss_std 5.29 / eval/reward_avg 0.51 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.17 / eval/reward_pred 0.51 / eval/reward_rate 0.26 / replay/size
1.4e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3840 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.57 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.02 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.7 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 136500 Counter(136500) 136437
Saved chunk: 20230922T003451F805313-3KhZazSZtAs0g6K1RzaNUG-6ftP3gRnUk7ycl8dJR59OP-1024.npz
eval_Episode has 500 steps and return 744.0.
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 137000 Counter(137000) 136937
eval_Episode has 500 steps and return 753.0.
Saved chunk: 20230922T003545F353792-4qTSMI6YLwTrfHF8EmkLjF-204XGA5rGw92wfQz9CqIw6-1024.npz
train_Episode has 500 steps and return 745.0.
Starting evaluation at step 137500 Counter(137500) 137437
Saved chunk: 20230922T003610F236516-6ftP3gRnUk7ycl8dJR59OP-3AeYTJGWSHxx4Ttkel6AV2-1024.npz
eval_Episode has 500 steps and return 751.0.
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 138000 Counter(138000) 137937
eval_Episode has 500 steps and return 754.0.
Saved chunk: 20230922T003705F613983-204XGA5rGw92wfQz9CqIw6-3fJIgdRjVo2dhBUbxsTKcz-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 138500 Counter(138500) 138437
Saved chunk: 20230922T003728F269914-3AeYTJGWSHxx4Ttkel6AV2-3asY5iKwdq7NF7NAlNX0Sx-1024.npz
eval_Episode has 500 steps and return 755.0.
train_Episode has 500 steps and return 751.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 139000 Counter(139000) 138937
Saved chunk: 20230922T003825F035165-3fJIgdRjVo2dhBUbxsTKcz-0000000000000000000000-760.npz
Saved chunk: 20230922T003846F059849-3asY5iKwdq7NF7NAlNX0Sx-0000000000000000000000-112.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
eval_Episode has 500 steps and return 752.0.
Saved chunk: 20230922T003825F035165-3fJIgdRjVo2dhBUbxsTKcz-4BgnIhI74UmtbgIDiRhnOt-1024.npz
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 139500 Counter(139500) 139437
Saved chunk: 20230922T003846F059849-3asY5iKwdq7NF7NAlNX0Sx-47oE9Jsh7RIgexh9katsxT-1024.npz
eval_Episode has 500 steps and return 755.0.
train_Episode has 500 steps and return 750.0.
Starting evaluation at step 140000 Counter(140000) 139937
eval_Episode has 500 steps and return 751.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 280302 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 751 / eval_episode/reward_rate 0.75 / episode/length 500 / episode/score 750 / episode/reward_rate 0.75 / train/action_mag 3.5 / train/action_max 3.43 / train/action_mean 0.04 / train/action_min -3.07 / train/action_std 0.89 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 6.9e4 / train/actor_opt_loss -9.72 / train/adv_mag 0.57 / train/adv_max 0.49 / train/adv_mean 1e-3 / train/adv_min -0.47 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.09 / 
train/dyn_loss_std 4.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.29 / train/extr_critic_critic_opt_grad_steps 6.9e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 683.48 / train/extr_critic_max 683.48 / train/extr_critic_mean 572.11 / train/extr_critic_min 332.01 / train/extr_critic_std 88.51 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.6 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 678.51 / train/extr_return_raw_max 678.51 / train/extr_return_raw_mean 572.38 / train/extr_return_raw_min 350.52 / train/extr_return_raw_std 88.78
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.7 / train/extr_reward_min -8.1e-9 / train/extr_reward_std 0.92 / train/image_loss_mean 0.35 / train/image_loss_std 0.49 / train/model_loss_mean 1.66 / train/model_loss_std 3.31 / 
train/model_opt_grad_norm 8.63 / train/model_opt_grad_steps 6.9e4 / train/model_opt_loss 9405.18 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5703.12 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.15 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.66 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.15 / train/policy_logprob_min -8.13 / train/policy_logprob_std 0.97 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.32 / train/policy_randomness_min 7e-4 / train/policy_randomness_std 0.29 / train/post_ent_mag 60.1 / train/post_ent_max 60.1 / train/post_ent_mean 42.16 / 
train/post_ent_min 23.02 / train/post_ent_std 4.24 / train/prior_ent_mag 73.68 / train/prior_ent_max 73.68 / train/prior_ent_mean 43.98 / train/prior_ent_min 29.96 / train/prior_ent_std 5.28 / train/rep_loss_mean 2.09 / train/rep_loss_std 4.9 / train/reward_avg 0.71 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.71 / train/reward_rate 0.36 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.19 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.86 / report/dyn_loss_std 4.33 / report/image_loss_mean 0.29 / report/image_loss_std 0.47 / report/model_loss_mean 1.48 / report/model_loss_std 2.98 / report/post_ent_mag 51.83 / report/post_ent_max 51.83 / 
report/post_ent_mean 42.78 / report/post_ent_min 25.92 / report/post_ent_std 3.99 / report/prior_ent_mag 73.61 / report/prior_ent_max 73.61 / report/prior_ent_mean 44.44 / report/prior_ent_min 28.16 / report/prior_ent_std 5.05 / report/rep_loss_mean 1.86 / 
report/rep_loss_std 4.33 / report/reward_avg 1.23 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 7.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.23 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 1e-10 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-10 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 2.67 / eval/dyn_loss_std 5.62 / eval/image_loss_mean 0.55 / eval/image_loss_std 1.09 / eval/model_loss_mean 2.2 / eval/model_loss_std 4.09 / eval/post_ent_mag 58.34 / eval/post_ent_max 58.34 / eval/post_ent_mean 42.89 / 
eval/post_ent_min 19.67 / eval/post_ent_std 4.69 / eval/prior_ent_mag 73.61 / eval/prior_ent_max 73.61 / eval/prior_ent_mean 45.5 / eval/prior_ent_min 31.32 / eval/prior_ent_std 4.62 / eval/rep_loss_mean 2.67 / eval/rep_loss_std 5.62 / eval/reward_avg 0.53 / 
eval/reward_loss_mean 0.05 / eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.53 / eval/reward_rate 0.27 / 
replay/size 1.4e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3838 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.3 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.6e-3 / timer/replay._sample_max 0.12 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.48 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 747.0.
Saved chunk: 20230922T003944F606336-4BgnIhI74UmtbgIDiRhnOt-41G0XkPEPNxq5jZ73QTmZj-1024.npz
Starting evaluation at step 140500 Counter(140500) 140437
Saved chunk: 20230922T004004F002456-47oE9Jsh7RIgexh9katsxT-7z5zrQX3vDCO1BdOcDjEM9-1024.npz
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 750.0.
Starting evaluation at step 141000 Counter(141000) 140937
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 751.0.
Saved chunk: 20230922T004104F385390-41G0XkPEPNxq5jZ73QTmZj-3OjThkbEnxYIACmOBrq3bY-1024.npz
Starting evaluation at step 141500 Counter(141500) 141437
Saved chunk: 20230922T004122F409082-7z5zrQX3vDCO1BdOcDjEM9-2IMc9jlUdktwpRe4I5XoYB-1024.npz
eval_Episode has 500 steps and return 754.0.
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 142000 Counter(142000) 141937
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 754.0.
Saved chunk: 20230922T004223F940913-3OjThkbEnxYIACmOBrq3bY-6KL5Xc2bOrHLCoZShd7V5E-1024.npz
Starting evaluation at step 142500 Counter(142500) 142437
eval_Episode has 500 steps and return 758.0.
Saved chunk: 20230922T004240F338058-2IMc9jlUdktwpRe4I5XoYB-5jVPaS9ygWHYlXZ67ogZZ0-1024.npz
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 143000 Counter(143000) 142937
eval_Episode has 500 steps and return 753.0.
train_Episode has 500 steps and return 754.0.
Saved chunk: 20230922T004343F269186-6KL5Xc2bOrHLCoZShd7V5E-1UPTmu5NIjAbZzM1ez9WHG-1024.npz
Starting evaluation at step 143500 Counter(143500) 143437
eval_Episode has 500 steps and return 757.0.
Saved chunk: 20230922T004358F142146-5jVPaS9ygWHYlXZ67ogZZ0-77iFmKr55UGf0NPqueIV2g-1024.npz
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 144000 Counter(144000) 143937
eval_Episode has 500 steps and return 761.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 288002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 752 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 761 / eval_episode/reward_rate 0.76 / train/action_mag 3.51 / train/action_max 3.43 / train/action_mean 0.07 / train/action_min -3.19 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 7e4 / train/actor_opt_loss -5.92 / train/adv_mag 0.57 / train/adv_max 0.49 / train/adv_mean 6.2e-4 / train/adv_min -0.48 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.06 / 
train/dyn_loss_std 4.83 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.25 / train/extr_critic_critic_opt_grad_steps 7e4 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 680.29 / train/extr_critic_max 680.29 / train/extr_critic_mean 576.41 / train/extr_critic_min 354.29 / train/extr_critic_std 86.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.62 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 675.59 / train/extr_return_raw_max 675.59 / train/extr_return_raw_mean 576.57 / train/extr_return_raw_min 364.79 / train/extr_return_raw_std 87.16
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.75 / train/extr_reward_min -4.3e-9 / train/extr_reward_std 0.94 / train/image_loss_mean 0.34 / train/image_loss_std 0.48 / train/model_loss_mean 1.63 / train/model_loss_std 3.27 / 
train/model_opt_grad_norm 8.05 / train/model_opt_grad_steps 7e4 / train/model_opt_loss 8243.53 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5103.63 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.05 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.14 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.05 / train/policy_logprob_min -8.14 / train/policy_logprob_std 1 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.36 / train/policy_randomness_min 7.5e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 59.27 / train/post_ent_max 59.27 / train/post_ent_mean 42.06 / 
train/post_ent_min 23.48 / train/post_ent_std 4.16 / train/prior_ent_mag 73.52 / train/prior_ent_max 73.52 / train/prior_ent_mean 43.86 / train/prior_ent_min 30.05 / train/prior_ent_std 5.25 / train/rep_loss_mean 2.06 / train/rep_loss_std 4.83 / train/reward_avg 0.76 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.76 / train/reward_rate 0.38 / 
train_stats/mean_log_entropy 0.43 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-10 / report/cont_loss_std 7.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.09 / report/dyn_loss_std 4.93 / report/image_loss_mean 0.35 / report/image_loss_std 0.41 / report/model_loss_mean 1.66 / report/model_loss_std 3.3 / report/post_ent_mag 56.88 / report/post_ent_max 56.88 / 
report/post_ent_mean 42.91 / report/post_ent_min 22.4 / report/post_ent_std 3.35 / report/prior_ent_mag 73.15 / report/prior_ent_max 73.15 / report/prior_ent_mean 44.74 / report/prior_ent_min 32.65 / report/prior_ent_std 4.52 / report/rep_loss_mean 2.09 / 
report/rep_loss_std 4.93 / report/reward_avg 0.71 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.23 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.71 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.09 / eval/dyn_loss_std 5.16 / eval/image_loss_mean 0.31 / eval/image_loss_std 0.41 / eval/model_loss_mean 1.63 / eval/model_loss_std 3.44 / eval/post_ent_mag 56.68 / eval/post_ent_max 56.68 / eval/post_ent_mean 
42.81 / eval/post_ent_min 26.87 / eval/post_ent_std 3.18 / eval/prior_ent_mag 73.15 / eval/prior_ent_max 73.15 / eval/prior_ent_mean 44.62 / eval/prior_ent_min 33.75 / eval/prior_ent_std 4.64 / eval/rep_loss_mean 2.09 / eval/rep_loss_std 5.16 / eval/reward_avg 0.95 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 0.95 / eval/reward_rate 0.48 / 
replay/size 1.4e5 / replay/inserts 3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.67 / timer/env.step_count 3850 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.76 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7858 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1925 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1925 / timer/agent.train_total 244.07 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T004502F576217-1UPTmu5NIjAbZzM1ez9WHG-6s0peMQXTYYV8iwre8acLL-1024.npz
Starting evaluation at step 144500 Counter(144500) 144437
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 145000 Counter(145000) 144937
Saved chunk: 20230922T004515F830735-77iFmKr55UGf0NPqueIV2g-240WPEqLD7ph0NWjrcq5yM-1024.npz
eval_Episode has 500 steps and return 759.0.
train_Episode has 500 steps and return 754.0.
Saved chunk: 20230922T004622F565824-6s0peMQXTYYV8iwre8acLL-5dck2ti7wVARYAJ1EcCguf-1024.npz
Starting evaluation at step 145500 Counter(145500) 145437
eval_Episode has 500 steps and return 758.0.
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 146000 Counter(146000) 145937
Saved chunk: 20230922T004709F979682-240WPEqLD7ph0NWjrcq5yM-6J9AzbMypXN6WQsp7XG1CQ-1024.npz
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 756.0.
Saved chunk: 20230922T004742F225938-5dck2ti7wVARYAJ1EcCguf-5brA6aOXfyHMIpROFTMrgq-1024.npz
Starting evaluation at step 146500 Counter(146500) 146437
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 147000 Counter(147000) 146937
Saved chunk: 20230922T004827F861732-6J9AzbMypXN6WQsp7XG1CQ-07Q81rt5ruJXaJH8Ikt9Ko-1024.npz
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 754.0.
Saved chunk: 20230922T004901F662962-5brA6aOXfyHMIpROFTMrgq-0BL7sVaZsFqKrx5K9ka751-1024.npz
Starting evaluation at step 147500 Counter(147500) 147437
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 759.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 295774 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 760 / eval_episode/reward_rate 0.76 / train/action_mag 3.59 / train/action_max 3.54 / train/action_mean 0.07 / train/action_min -3.16 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 7.2e4 / train/actor_opt_loss -6.25 / train/adv_mag 0.52 / train/adv_max 0.43 / train/adv_mean 6.6e-4 / train/adv_min -0.45 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.05 / 
train/dyn_loss_std 4.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.25 / train/extr_critic_critic_opt_grad_steps 7.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 678.8 / train/extr_critic_max 678.8 / train/extr_critic_mean 576.86 / train/extr_critic_min 353.27 / train/extr_critic_std 86.13 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.62 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 674.73 / train/extr_return_raw_max 674.73 / train/extr_return_raw_mean 577.03 / train/extr_return_raw_min 360.12 / train/extr_return_raw_std 86.4 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.74 / train/extr_reward_min -1.8e-9 / train/extr_reward_std 0.93 / train/image_loss_mean 0.34 / train/image_loss_std 0.48 / train/model_loss_mean 1.63 / train/model_loss_std 3.26 / 
train/model_opt_grad_norm 8.35 / train/model_opt_grad_steps 7.2e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6237.11 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.1 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.09 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.1 / train/policy_logprob_min -8.09 / train/policy_logprob_std 0.99 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.34 / train/policy_randomness_min 8.3e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 59.71 / train/post_ent_max 59.71 / train/post_ent_mean 42.05 / 
train/post_ent_min 23.49 / train/post_ent_std 4.02 / train/prior_ent_mag 73.41 / train/prior_ent_max 73.41 / train/prior_ent_mean 43.83 / train/prior_ent_min 30.18 / train/prior_ent_std 5.17 / train/rep_loss_mean 2.05 / train/rep_loss_std 4.82 / train/reward_avg 0.74 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.74 / train/reward_rate 0.38 
/ train_stats/mean_log_entropy 0.37 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.85 / report/dyn_loss_std 4 / report/image_loss_mean 0.31 / report/image_loss_std 0.48 / report/model_loss_mean 1.48 / report/model_loss_std 2.76 / report/post_ent_mag 64.65 / report/post_ent_max 64.65 / 
report/post_ent_mean 42.34 / report/post_ent_min 23.01 / report/post_ent_std 3.81 / report/prior_ent_mag 73.5 / report/prior_ent_max 73.5 / report/prior_ent_mean 44.04 / report/prior_ent_min 26.3 / report/prior_ent_std 4.96 / report/rep_loss_mean 1.85 / 
report/rep_loss_std 4 / report/reward_avg 0.92 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 0.92 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-10 / eval/cont_loss_std 8.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-10 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 2.26 / eval/dyn_loss_std 5.4 / eval/image_loss_mean 0.4 / eval/image_loss_std 0.8 / eval/model_loss_mean 1.82 / eval/model_loss_std 3.83 / eval/post_ent_mag 56.3 / eval/post_ent_max 56.3 / eval/post_ent_mean 42.14 / eval/post_ent_min 20.64 / 
eval/post_ent_std 3.47 / eval/prior_ent_mag 73.5 / eval/prior_ent_max 73.5 / eval/prior_ent_mean 44.23 / eval/prior_ent_min 33.76 / eval/prior_ent_std 4.63 / eval/rep_loss_mean 2.26 / eval/rep_loss_std 5.4 / eval/reward_avg 0.85 / eval/reward_loss_mean 0.06 / 
eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 0.85 / eval/reward_rate 0.43 / replay/size 1.5e5 / replay/inserts 3886 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3886 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.07 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.15 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 7.5e-3 / timer/dataset_train_count 
1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.57 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.91

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 148000 Counter(148000) 147937
Saved chunk: 20230922T004945F650812-07Q81rt5ruJXaJH8Ikt9Ko-578y4VCJhOMUTdRIfYItyA-1024.npz
eval_Episode has 500 steps and return 755.0.
train_Episode has 500 steps and return 753.0.
Saved chunk: 20230922T005020F874743-0BL7sVaZsFqKrx5K9ka751-2rHR8ovFLINKz2hhBUsJ8A-1024.npz
Starting evaluation at step 148500 Counter(148500) 148437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 149000 Counter(149000) 148937
Saved chunk: 20230922T005103F959150-578y4VCJhOMUTdRIfYItyA-069vHoNc9pmWi2gdQC8lVS-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 149500 Counter(149500) 149437
eval_Episode has 500 steps and return 758.0.
Saved chunk: 20230922T005141F030239-2rHR8ovFLINKz2hhBUsJ8A-1CdCXJ0KTeEOrhVTi8t7EO-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 150000 Counter(150000) 149937
Saved chunk: 20230922T005222F075187-069vHoNc9pmWi2gdQC8lVS-0euqroelBXMRhEWVZck5Gr-1024.npz
eval_Episode has 500 steps and return 759.0.
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 150500 Counter(150500) 150437
eval_Episode has 500 steps and return 758.0.
Saved chunk: 20230922T005303F835529-1CdCXJ0KTeEOrhVTi8t7EO-15EB16gkYmeaOUy7qlqWEh-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T005423F225224-15EB16gkYmeaOUy7qlqWEh-0000000000000000000000-73.npz
Saved chunk: 20230922T005339F896040-0euqroelBXMRhEWVZck5Gr-0000000000000000000000-872.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 151000 Counter(151000) 150937
Saved chunk: 20230922T005339F896040-0euqroelBXMRhEWVZck5Gr-3KdnLec0u2GkmoIttBjAdq-1024.npz
eval_Episode has 500 steps and return 758.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 151500 Counter(151500) 151437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T005423F225224-15EB16gkYmeaOUy7qlqWEh-3Kb97lylWWnOFPqNRXn0BP-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 303442 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 761 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / train/action_mag 3.55 / train/action_max 3.47 / train/action_mean 0.07 / train/action_min -3.16 / train/action_std 0.89 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 7.4e4 / train/actor_opt_loss -5.51 / train/adv_mag 0.53 / train/adv_max 0.44 / train/adv_mean 5.9e-4 / train/adv_min -0.47 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 3.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.04 / 
train/dyn_loss_std 4.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 7.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 680.41 / train/extr_critic_max 680.41 / train/extr_critic_mean 582.88 / train/extr_critic_min 363.84 / train/extr_critic_std 84.33 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.63 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 676.64 / train/extr_return_raw_max 676.64 / train/extr_return_raw_mean 583.03 / train/extr_return_raw_min 372.32 / train/extr_return_raw_std 84.56
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.78 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.34 / train/image_loss_std 0.48 / train/model_loss_mean 1.62 / train/model_loss_std 3.22 / 
train/model_opt_grad_norm 7.64 / train/model_opt_grad_steps 7.4e4 / train/model_opt_loss 9683.93 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6015.62 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.11 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.68 / train/policy_logprob_mag 8.13 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.11 / train/policy_logprob_min -8.13 / train/policy_logprob_std 0.98 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.34 / train/policy_randomness_min 8.5e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 59.52 / train/post_ent_max 59.52 / train/post_ent_mean 41.92 / 
train/post_ent_min 23.45 / train/post_ent_std 3.97 / train/prior_ent_mag 73.23 / train/prior_ent_max 73.23 / train/prior_ent_mean 43.69 / train/prior_ent_min 30.25 / train/prior_ent_std 5.15 / train/rep_loss_mean 2.04 / train/rep_loss_std 4.75 / train/reward_avg 0.78 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.78 / train/reward_rate 0.39 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.3 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 4.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.1 / report/dyn_loss_std 4.87 / report/image_loss_mean 0.36 / report/image_loss_std 0.52 / report/model_loss_mean 1.67 / report/model_loss_std 3.36 / report/post_ent_mag 57.64 / report/post_ent_max 57.64 / 
report/post_ent_mean 42.04 / report/post_ent_min 23.87 / report/post_ent_std 3.85 / report/prior_ent_mag 72.74 / report/prior_ent_max 72.74 / report/prior_ent_mean 43.91 / report/prior_ent_min 27.35 / report/prior_ent_std 5.1 / report/rep_loss_mean 2.1 / 
report/rep_loss_std 4.87 / report/reward_avg 0.57 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.18 / report/reward_pred 0.56 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-10 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.21 / eval/dyn_loss_std 5.13 / eval/image_loss_mean 0.36 / eval/image_loss_std 0.51 / eval/model_loss_mean 1.75 / eval/model_loss_std 3.5 / eval/post_ent_mag 56.57 / eval/post_ent_max 56.57 / eval/post_ent_mean 42.87 / 
eval/post_ent_min 26.18 / eval/post_ent_std 3.29 / eval/prior_ent_mag 72.74 / eval/prior_ent_max 72.74 / eval/prior_ent_mean 44.87 / eval/prior_ent_min 34.79 / eval/prior_ent_std 4.45 / eval/rep_loss_mean 2.21 / eval/rep_loss_std 5.13 / eval/reward_avg 0.83 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.21 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.15 / eval/reward_pred 0.83 / eval/reward_rate 0.42 / replay/size
1.5e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3834 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.31 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.5e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.39 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 
3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 152000 Counter(152000) 151937
Saved chunk: 20230922T005457F974449-3KdnLec0u2GkmoIttBjAdq-4kfx037gUuvtYQ7X4rRAPr-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 753.0.
Starting evaluation at step 152500 Counter(152500) 152437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T005542F780368-3Kb97lylWWnOFPqNRXn0BP-1KCngJv1HwKAb0k4djc6h4-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 153000 Counter(153000) 152937
Saved chunk: 20230922T005616F479662-4kfx037gUuvtYQ7X4rRAPr-6QDLWiDH0EozqGW6tRZdrz-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 153500 Counter(153500) 153437
eval_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T005703F043667-1KCngJv1HwKAb0k4djc6h4-6SV7SZYiAj66u77bN5n56c-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 154000 Counter(154000) 153937
Saved chunk: 20230922T005734F549832-6QDLWiDH0EozqGW6tRZdrz-7JSPFdon3b544OXJT6LJbO-1024.npz
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 154500 Counter(154500) 154437
eval_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T005822F514469-6SV7SZYiAj66u77bN5n56c-1YU8FLmrvhvs7YxAnF7qDZ-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 155000 Counter(155000) 154937
Saved chunk: 20230922T005853F358356-7JSPFdon3b544OXJT6LJbO-4lFUzbHxGCmevaPoMn8jT5-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 155500 Counter(155500) 155437
eval_Episode has 500 steps and return 759.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 311090 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 759 / eval_episode/reward_rate 0.76 / train/action_mag 3.58 / train/action_max 3.49 / train/action_mean 0.07 / train/action_min -3.2 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 7.6e4 / train/actor_opt_loss -1.6 / train/adv_mag 0.49 / train/adv_max 0.4 / train/adv_mean 1.9e-4 / train/adv_min -0.44 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.5e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.02 / 
train/dyn_loss_std 4.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 7.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 678.34 / train/extr_critic_max 678.34 / train/extr_critic_mean 584.95 / train/extr_critic_min 379.19 / train/extr_critic_std 82.2 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.64 / 
train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 674.94 / train/extr_return_raw_max 674.94 / train/extr_return_raw_mean 584.99 / train/extr_return_raw_min 387.75 / train/extr_return_raw_std 82.43
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.8 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.33 / train/image_loss_std 0.47 / train/model_loss_mean 1.59 / train/model_loss_std 3.19 / 
train/model_opt_grad_norm 7.56 / train/model_opt_grad_steps 7.6e4 / train/model_opt_loss 8911.7 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 5575.92 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.1 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 8.06 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.1 / train/policy_logprob_min -8.06 / train/policy_logprob_std 0.99 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.34 / train/policy_randomness_min 8.3e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 58.75 / train/post_ent_max 58.75 / train/post_ent_mean 41.84 / 
train/post_ent_min 23.9 / train/post_ent_std 3.99 / train/prior_ent_mag 73.2 / train/prior_ent_max 73.2 / train/prior_ent_mean 43.58 / train/prior_ent_min 30.5 / train/prior_ent_std 5.18 / train/rep_loss_mean 2.02 / train/rep_loss_std 4.7 / train/reward_avg 0.79 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.79 / train/reward_rate 0.4 / 
train_stats/mean_log_entropy 0.38 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.09 / report/dyn_loss_std 4.75 / report/image_loss_mean 0.34 / report/image_loss_std 0.48 / report/model_loss_mean 1.65 / report/model_loss_std 3.23 / report/post_ent_mag 57.46 / report/post_ent_max 57.46 / 
report/post_ent_mean 42.04 / report/post_ent_min 24.13 / report/post_ent_std 3.4 / report/prior_ent_mag 73.42 / report/prior_ent_max 73.42 / report/prior_ent_mean 43.78 / report/prior_ent_min 31.31 / report/prior_ent_std 5.11 / report/rep_loss_mean 2.09 / 
report/rep_loss_std 4.75 / report/reward_avg 0.77 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.77 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 9.3e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.81 / eval/image_loss_mean 0.28 / eval/image_loss_std 0.34 / eval/model_loss_mean 1.39 / eval/model_loss_std 2.55 / eval/post_ent_mag 51.57 / eval/post_ent_max 51.57 / eval/post_ent_mean 
42.47 / eval/post_ent_min 28.68 / eval/post_ent_std 2.75 / eval/prior_ent_mag 73.42 / eval/prior_ent_max 73.42 / eval/prior_ent_mean 43.87 / eval/prior_ent_min 36.19 / eval/prior_ent_std 4.52 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.81 / eval/reward_avg 1.22 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.21 / eval/reward_rate 0.61 / replay/size
1.6e5 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3824 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.04 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7832 / timer/agent.policy_total 16.9 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.5e-3 / 
timer/dataset_train_count 1912 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1912 / timer/agent.train_total 243.82 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.12 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.49

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T005942F787750-1YU8FLmrvhvs7YxAnF7qDZ-2hL35q42QhseqNQ83X8TVQ-1024.npz
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 156000 Counter(156000) 155937
Saved chunk: 20230922T010011F043395-4lFUzbHxGCmevaPoMn8jT5-4UglQ5uA6WjiV2hfQxvetT-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 156500 Counter(156500) 156437
eval_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T010102F779865-2hL35q42QhseqNQ83X8TVQ-2FkaPBMZIytgE56X6iGkqT-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 157000 Counter(157000) 156937
Saved chunk: 20230922T010129F586937-4UglQ5uA6WjiV2hfQxvetT-361X5cVMKcHUG5CEItt3Q9-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 157500 Counter(157500) 157437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T010222F213721-2FkaPBMZIytgE56X6iGkqT-6pWSBuFfwYbMecsMh8HWHl-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 158000 Counter(158000) 157937
Saved chunk: 20230922T010247F443145-361X5cVMKcHUG5CEItt3Q9-0IXlsaLXHGV0eXucoYo6tT-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 158500 Counter(158500) 158437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T010341F602399-6pWSBuFfwYbMecsMh8HWHl-0geRGtKIIa6udQXFuG52XC-1024.npz
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 159000 Counter(159000) 158937
Saved chunk: 20230922T010405F217122-0IXlsaLXHGV0eXucoYo6tT-463xO3E7u3JkMZVa2QM1JT-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 759.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 318870 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 761 / eval_episode/reward_rate 0.76 / train/action_mag 3.67 / train/action_max 3.63 / train/action_mean 0.07 / train/action_min -3.18 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 7.8e4 / train/actor_opt_loss -4.71 / train/adv_mag 0.52 / train/adv_max 0.42 / train/adv_mean 5e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2 / 
train/dyn_loss_std 4.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 7.8e4 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 676.23 / train/extr_critic_max 676.23 / train/extr_critic_mean 584.9 / train/extr_critic_min 370.03 / train/extr_critic_std 82.98 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.64 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 672.94 / train/extr_return_raw_max 672.94 / train/extr_return_raw_mean 585.02 / train/extr_return_raw_min 379.1 / train/extr_return_raw_std 83.16 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.82 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.32 / train/image_loss_std 0.45 / train/model_loss_mean 1.58 / train/model_loss_std 3.11 / 
train/model_opt_grad_norm 7.5 / train/model_opt_grad_steps 7.8e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6443.3 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.07 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.4 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.07 / train/policy_logprob_min -8.4 / train/policy_logprob_std 1 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.35 / train/policy_randomness_min 9.5e-4 / train/policy_randomness_std 0.31 / train/post_ent_mag 59.36 / train/post_ent_max 59.36 / train/post_ent_mean 41.68 / 
train/post_ent_min 23.74 / train/post_ent_std 3.93 / train/prior_ent_mag 73.06 / train/prior_ent_max 73.06 / train/prior_ent_mean 43.39 / train/prior_ent_min 30.46 / train/prior_ent_std 5.18 / train/rep_loss_mean 2 / train/rep_loss_std 4.6 / train/reward_avg 0.81 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.81 / train/reward_rate 0.41 / 
train_stats/mean_log_entropy 0.4 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-10 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 1.88 / report/dyn_loss_std 4.84 / report/image_loss_mean 0.26 / report/image_loss_std 0.43 / report/model_loss_mean 1.47 / report/model_loss_std 3.24 / report/post_ent_mag 57.5 / report/post_ent_max 57.5 / report/post_ent_mean
41.56 / report/post_ent_min 24.88 / report/post_ent_std 3.32 / report/prior_ent_mag 72.71 / report/prior_ent_max 72.71 / report/prior_ent_mean 43.02 / report/prior_ent_min 33.69 / report/prior_ent_std 4.89 / report/rep_loss_mean 1.88 / report/rep_loss_std 4.84 / 
report/reward_avg 1.22 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 
1.22 / report/reward_rate 0.61 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.96 
/ eval/dyn_loss_std 5.15 / eval/image_loss_mean 0.31 / eval/image_loss_std 0.54 / eval/model_loss_mean 1.55 / eval/model_loss_std 3.52 / eval/post_ent_mag 53.09 / eval/post_ent_max 53.09 / eval/post_ent_mean 42.45 / eval/post_ent_min 22.37 / eval/post_ent_std 3.56 / 
eval/prior_ent_mag 72.71 / eval/prior_ent_max 72.71 / eval/prior_ent_mean 44.07 / eval/prior_ent_min 36.13 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 1.96 / eval/rep_loss_std 5.15 / eval/reward_avg 0.86 / eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.25 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 0.86 / eval/reward_rate 0.43 / replay/size 1.6e5 / replay/inserts 3890 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3890 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.02 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.86 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.08 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1945 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.72 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.93

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 159500 Counter(159500) 159437
eval_Episode has 500 steps and return 758.0.
Saved chunk: 20230922T010500F905615-0geRGtKIIa6udQXFuG52XC-6H8xpSVyz4CWno9LuFis2Z-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 160000 Counter(160000) 159937
Saved chunk: 20230922T010522F873286-463xO3E7u3JkMZVa2QM1JT-42SIn05VuL6LPJLr1ruWqa-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 160500 Counter(160500) 160437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T010620F873791-6H8xpSVyz4CWno9LuFis2Z-39UcLXgu8DlVqy2AYzRC1H-1024.npz
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 161000 Counter(161000) 160937
Saved chunk: 20230922T010641F464923-42SIn05VuL6LPJLr1ruWqa-7HrRM2wZ2YQEfg0j02NoZ4-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 161500 Counter(161500) 161437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T010740F416734-39UcLXgu8DlVqy2AYzRC1H-4EGp8qDsRRAczAPZmgqMTI-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 162000 Counter(162000) 161937
Saved chunk: 20230922T010759F375689-7HrRM2wZ2YQEfg0j02NoZ4-31VXFFo9satdhEWUGHNRFG-1024.npz
eval_Episode has 500 steps and return 765.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T010917F065362-31VXFFo9satdhEWUGHNRFG-0000000000000000000000-107.npz
Saved chunk: 20230922T010859F681208-4EGp8qDsRRAczAPZmgqMTI-0000000000000000000000-408.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 162500 Counter(162500) 162437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T010859F681208-4EGp8qDsRRAczAPZmgqMTI-3v6uIAmonxekuPnbHOOfvd-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 163000 Counter(163000) 162937
Saved chunk: 20230922T010917F065362-31VXFFo9satdhEWUGHNRFG-6qdJEvJbHKOYp16E6GPu8W-1024.npz
eval_Episode has 500 steps and return 764.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 326550 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 764 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / train/action_mag 3.7 / train/action_max 3.6 / train/action_mean 0.07 / train/action_min -3.39 / train/action_std 0.92 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 8e4 / train/actor_opt_loss -3.83 / train/adv_mag 0.52 / train/adv_max 0.44 / train/adv_mean 4e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2 / 
train/dyn_loss_std 4.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 8e4 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 673.83 / train/extr_critic_max 673.83 / train/extr_critic_mean 582.71 / train/extr_critic_min 369.95 / train/extr_critic_std 81.81 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.64 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.79 / train/extr_return_raw_max 670.79 / train/extr_return_raw_mean 582.8 / train/extr_return_raw_min 381.23 / train/extr_return_raw_std 81.97 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.81 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.32 / train/image_loss_std 0.46 / train/model_loss_mean 1.58 / train/model_loss_std 3.15 / 
train/model_opt_grad_norm 7.86 / train/model_opt_grad_steps 8e4 / train/model_opt_loss 9959.44 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6328.12 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / 
train/policy_entropy_mean -0.05 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.73 / train/policy_logprob_mag 8.39 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.05 / train/policy_logprob_min -8.39 / train/policy_logprob_std 1.02 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.36 / train/policy_randomness_min 9e-4 / train/policy_randomness_std 0.32 / train/post_ent_mag 59.83 / train/post_ent_max 59.83 / train/post_ent_mean 41.59 / 
train/post_ent_min 23.91 / train/post_ent_std 3.94 / train/prior_ent_mag 73.01 / train/prior_ent_max 73.01 / train/prior_ent_mean 43.3 / train/prior_ent_min 30.83 / train/prior_ent_std 5.2 / train/rep_loss_mean 2 / train/rep_loss_std 4.64 / train/reward_avg 0.8 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.8 / train/reward_rate 0.4 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.55 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.17 / report/image_loss_mean 0.25 / report/image_loss_std 0.36 / report/model_loss_mean 1.3 / report/model_loss_std 2.17 / report/post_ent_mag 64.88 / report/post_ent_max 64.88 / 
report/post_ent_mean 41.69 / report/post_ent_min 25.93 / report/post_ent_std 3.61 / report/prior_ent_mag 73.16 / report/prior_ent_max 73.16 / report/prior_ent_mean 43.04 / report/prior_ent_min 32.12 / report/prior_ent_std 4.91 / report/rep_loss_mean 1.63 / 
report/rep_loss_std 3.17 / report/reward_avg 1.13 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.13 / report/reward_rate 0.57 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.93 / eval/dyn_loss_std 4.52 / eval/image_loss_mean 0.3 / eval/image_loss_std 0.37 / eval/model_loss_mean 1.52 / eval/model_loss_std 3.02 / eval/post_ent_mag 58.59 / eval/post_ent_max 58.59 / eval/post_ent_mean 
42.71 / eval/post_ent_min 26.47 / eval/post_ent_std 3.32 / eval/prior_ent_mag 73.16 / eval/prior_ent_max 73.16 / eval/prior_ent_mean 44.34 / eval/prior_ent_min 36.41 / eval/prior_ent_std 4.81 / eval/rep_loss_mean 1.93 / eval/rep_loss_std 4.52 / eval/reward_avg 0.84 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 0.84 / eval/reward_rate 0.42 / replay/size
1.6e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3840 / timer/env.step_total 19.02 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.9 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-4 / timer/replay._sample_max 0.13 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.57 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 163500 Counter(163500) 163437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 758.0.
Saved chunk: 20230922T011019F137530-3v6uIAmonxekuPnbHOOfvd-3v5Qq4bxEXX0fcvD2RR7Pt-1024.npz
Starting evaluation at step 164000 Counter(164000) 163937
Saved chunk: 20230922T011034F915717-6qdJEvJbHKOYp16E6GPu8W-4PtyUxGI2PvHSdr1EFYe7E-1024.npz
eval_Episode has 500 steps and return 756.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 164500 Counter(164500) 164437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T011139F277710-3v5Qq4bxEXX0fcvD2RR7Pt-60G1LhyDZyzAFV0k8kk7M2-1024.npz
Starting evaluation at step 165000 Counter(165000) 164937
Saved chunk: 20230922T011153F578985-4PtyUxGI2PvHSdr1EFYe7E-70J8u8ljqFEfunzRnNwJWj-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 165500 Counter(165500) 165437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T011258F796589-60G1LhyDZyzAFV0k8kk7M2-1W3IwHlR0pXzSsYZnYDQFR-1024.npz
Starting evaluation at step 166000 Counter(166000) 165937
eval_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T011311F502929-70J8u8ljqFEfunzRnNwJWj-4c80vBrdbrHUs7obWzgiYG-1024.npz
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 166500 Counter(166500) 166437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 757.0.
Saved chunk: 20230922T011418F180699-1W3IwHlR0pXzSsYZnYDQFR-0NPJ44sfD8nf48jXm2GWjf-1024.npz
Starting evaluation at step 167000 Counter(167000) 166937
eval_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 334226 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 757 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 763 / eval_episode/reward_rate 0.76 / train/action_mag 3.86 / train/action_max 3.73 / train/action_mean 0.06 / train/action_min -3.61 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 8.2e4 / train/actor_opt_loss -4.24 / train/adv_mag 0.51 / train/adv_max 0.43 / train/adv_mean 4.3e-4 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.97 / 
train/dyn_loss_std 4.56 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.21 / train/extr_critic_critic_opt_grad_steps 8.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.51 / train/extr_critic_max 672.51 / train/extr_critic_mean 586.48 / train/extr_critic_min 378.08 / train/extr_critic_std 82.18 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.65 / 
train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.7 / train/extr_return_raw_max 669.7 / train/extr_return_raw_mean 586.58 / train/extr_return_raw_min 387.26 / train/extr_return_raw_std 82.36 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.87 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.31 / train/image_loss_std 0.46 / train/model_loss_mean 1.55 / train/model_loss_std 3.08 / 
train/model_opt_grad_norm 7.54 / train/model_opt_grad_steps 8.2e4 / train/model_opt_loss 8975.24 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5807.29 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / 
train/policy_entropy_mean 6.7e-4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.78 / train/policy_logprob_mag 8.47 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -4.8e-4 / train/policy_logprob_min -8.47 / train/policy_logprob_std 1.05 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.38 / train/policy_randomness_min 7.7e-4 / train/policy_randomness_std 0.34 / train/post_ent_mag 59.02 / train/post_ent_max 59.02 / train/post_ent_mean 41.6 / 
train/post_ent_min 24.17 / train/post_ent_std 3.82 / train/prior_ent_mag 72.91 / train/prior_ent_max 72.91 / train/prior_ent_mean 43.26 / train/prior_ent_min 31.18 / train/prior_ent_std 5.16 / train/rep_loss_mean 1.97 / train/rep_loss_std 4.56 / train/reward_avg 0.87 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.87 / train/reward_rate 0.44 / 
train_stats/mean_log_entropy 0.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.91 / report/dyn_loss_std 4.07 / report/image_loss_mean 0.28 / report/image_loss_std 0.33 / report/model_loss_mean 1.5 / report/model_loss_std 2.68 / report/post_ent_mag 63.76 / report/post_ent_max 63.76 / 
report/post_ent_mean 41.87 / report/post_ent_min 22.96 / report/post_ent_std 3.84 / report/prior_ent_mag 72.91 / report/prior_ent_max 72.91 / report/prior_ent_mean 43.35 / report/prior_ent_min 32.09 / report/prior_ent_std 5.08 / report/rep_loss_mean 1.91 / 
report/rep_loss_std 4.07 / report/reward_avg 1 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.2e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.13 / report/reward_pred 1 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.88 / eval/dyn_loss_std 4.59 / eval/image_loss_mean 0.32 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.52 / eval/model_loss_std 3.05 / eval/post_ent_mag 57.2 / eval/post_ent_max 57.2 / eval/post_ent_mean 42.39 / eval/post_ent_min 27.9 / 
eval/post_ent_std 3.38 / eval/prior_ent_mag 72.91 / eval/prior_ent_max 72.91 / eval/prior_ent_mean 43.91 / eval/prior_ent_min 35.18 / eval/prior_ent_std 4.8 / eval/rep_loss_mean 1.88 / eval/rep_loss_std 4.59 / eval/reward_avg 0.99 / eval/reward_loss_mean 0.07 / 
eval/reward_loss_std 0.19 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1 / eval/reward_rate 0.5 / replay/size 1.7e5 / replay/inserts 3838 /
replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3838 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.61 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 
1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.77 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 167500 Counter(167500) 167437
Saved chunk: 20230922T011429F347236-4c80vBrdbrHUs7obWzgiYG-508hR5uuLl83q8BAm4Llbw-1024.npz
eval_Episode has 500 steps and return 759.0.
train_Episode has 500 steps and return 757.0.
Saved chunk: 20230922T011537F419478-0NPJ44sfD8nf48jXm2GWjf-1bU3HDkbA8zzxpAtdh3o4s-1024.npz
Starting evaluation at step 168000 Counter(168000) 167937
eval_Episode has 500 steps and return 752.0.
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 168500 Counter(168500) 168437
Saved chunk: 20230922T011623F359184-508hR5uuLl83q8BAm4Llbw-6m5TMpgH02g2SKmrfpC5RM-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 756.0.
Saved chunk: 20230922T011657F787940-1bU3HDkbA8zzxpAtdh3o4s-5dfcEcYeatrJp68yWZ4GVl-1024.npz
Starting evaluation at step 169000 Counter(169000) 168937
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 169500 Counter(169500) 169437
Saved chunk: 20230922T011741F408098-6m5TMpgH02g2SKmrfpC5RM-2wjC2LiMt71oRF2E6HE5r7-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T011817F259609-5dfcEcYeatrJp68yWZ4GVl-1tkbSKnKn1uEBfdq2R9271-1024.npz
Starting evaluation at step 170000 Counter(170000) 169937
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 170500 Counter(170500) 170437
Saved chunk: 20230922T011859F266037-2wjC2LiMt71oRF2E6HE5r7-0IWBiS2iVIhGs217hYEL6t-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 760.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 341990 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 760 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 761 / eval_episode/reward_rate 0.76 / train/action_mag 3.81 / train/action_max 3.72 / train/action_mean 0.05 / train/action_min -3.54 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 8.4e4 / train/actor_opt_loss -5.7 / train/adv_mag 0.53 / train/adv_max 0.44 / train/adv_mean 5.8e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.97 / 
train/dyn_loss_std 4.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 8.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.71 / train/extr_critic_max 671.71 / train/extr_critic_mean 586.81 / train/extr_critic_min 370.56 / train/extr_critic_std 80.74 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.65 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.07 / train/extr_return_raw_max 669.07 / train/extr_return_raw_mean 586.94 / train/extr_return_raw_min 383.56 / train/extr_return_raw_std 80.86
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.87 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.31 / train/image_loss_std 0.44 / train/model_loss_mean 1.55 / train/model_loss_std 3.08 / 
train/model_opt_grad_norm 7.7 / train/model_opt_grad_steps 8.4e4 / train/model_opt_loss 9948.39 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6417.53 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.01 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.77 / train/policy_logprob_mag 8.28 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.01 / train/policy_logprob_min -8.28 / train/policy_logprob_std 1.04 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.38 / train/policy_randomness_min 8.2e-4 / train/policy_randomness_std 0.33 / train/post_ent_mag 58.66 / train/post_ent_max 58.66 / train/post_ent_mean 41.47 / 
train/post_ent_min 24.54 / train/post_ent_std 3.87 / train/prior_ent_mag 72.72 / train/prior_ent_max 72.72 / train/prior_ent_mean 43.14 / train/prior_ent_min 30.97 / train/prior_ent_std 5.19 / train/rep_loss_mean 1.97 / train/rep_loss_std 4.57 / train/reward_avg 0.86 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.86 / train/reward_rate 0.44 / 
train_stats/mean_log_entropy 0.45 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.86 / report/dyn_loss_std 4.17 / report/image_loss_mean 0.3 / report/image_loss_std 0.4 / report/model_loss_mean 1.48 / report/model_loss_std 2.81 / report/post_ent_mag 56.73 / report/post_ent_max 56.73 / 
report/post_ent_mean 41.86 / report/post_ent_min 25.88 / report/post_ent_std 3.45 / report/prior_ent_mag 73.03 / report/prior_ent_max 73.03 / report/prior_ent_mean 43.49 / report/prior_ent_min 33.79 / report/prior_ent_std 4.85 / report/rep_loss_mean 1.86 / 
report/rep_loss_std 4.17 / report/reward_avg 0.9 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.9 / report/reward_rate 0.45 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.81 / eval/dyn_loss_std 3.77 / eval/image_loss_mean 0.29 / eval/image_loss_std 0.52 / eval/model_loss_mean 1.45 / eval/model_loss_std 2.65 / eval/post_ent_mag 54.04 / eval/post_ent_max 54.04 / eval/post_ent_mean 41.91 / 
eval/post_ent_min 28.81 / eval/post_ent_std 3.15 / eval/prior_ent_mag 73.03 / eval/prior_ent_max 73.03 / eval/prior_ent_mean 43.4 / eval/prior_ent_min 35.96 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 1.81 / eval/rep_loss_std 3.77 / eval/reward_avg 1.14 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.14 / eval/reward_rate 0.57 / replay/size
1.7e5 / replay/inserts 3882 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3882 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.79 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7389 / timer/agent.policy_total 16.17 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / 
timer/dataset_train_count 1941 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1941 / timer/agent.train_total 246.63 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.87

Starting evaluation at step 171000 Counter(171000) 170937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T011936F664803-1tkbSKnKn1uEBfdq2R9271-0KUwjuCev3iYTZdX9rrbCd-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 171500 Counter(171500) 171437
Saved chunk: 20230922T012017F107763-0IWBiS2iVIhGs217hYEL6t-5Jk7aT1w5DYO1Sr0ZwffLb-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 172000 Counter(172000) 171937
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T012100F269387-0KUwjuCev3iYTZdX9rrbCd-39QtOh1Y1SGFIoCcnOMXdb-1024.npz
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 172500 Counter(172500) 172437
Saved chunk: 20230922T012136F006315-5Jk7aT1w5DYO1Sr0ZwffLb-2WmtpguYuacskT0NCHbNmm-1024.npz
eval_Episode has 500 steps and return 758.0.
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 173000 Counter(173000) 172937
eval_Episode has 500 steps and return 529.0.
Saved chunk: 20230922T012220F029252-39QtOh1Y1SGFIoCcnOMXdb-22nfREhuhsERrz7uUd81AA-1024.npz
train_Episode has 500 steps and return 611.0.
Starting evaluation at step 173500 Counter(173500) 173437
Saved chunk: 20230922T012254F071203-2WmtpguYuacskT0NCHbNmm-2LAOaAHoSeU7atMBsRT6Vb-1024.npz
eval_Episode has 500 steps and return 733.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T012411F875720-2LAOaAHoSeU7atMBsRT6Vb-0000000000000000000000-366.npz
Saved chunk: 20230922T012339F468564-22nfREhuhsERrz7uUd81AA-0000000000000000000000-745.npz
train_Episode has 500 steps and return 597.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 174000 Counter(174000) 173937
eval_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T012339F468564-22nfREhuhsERrz7uUd81AA-76BQL8dpyRBTEEsMvsXZ4U-1024.npz
train_Episode has 500 steps and return 374.0.
Starting evaluation at step 174500 Counter(174500) 174437
Saved chunk: 20230922T012411F875720-2LAOaAHoSeU7atMBsRT6Vb-3TJmN93J03v21y4ow1CxDA-1024.npz
eval_Episode has 500 steps and return 760.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 349646 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 760 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 374 / episode/reward_rate 0.38 / train/action_mag 3.72 / train/action_max 3.61 / train/action_mean 0.09 / train/action_min -3.46 / train/action_std 0.92 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 8.6e4 / train/actor_opt_loss 0.3 / train/adv_mag 0.53 / train/adv_max 0.44 / train/adv_mean -3.8e-5 / train/adv_min -0.44 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.96 / 
train/dyn_loss_std 4.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 8.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.48 / train/extr_critic_max 671.48 / train/extr_critic_mean 583.62 / train/extr_critic_min 378.86 / train/extr_critic_std 84.15 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.64 / 
train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.86 / train/extr_return_raw_max 668.86 / train/extr_return_raw_mean 583.62 / train/extr_return_raw_min 389.73 / train/extr_return_raw_std 84.47 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.86 / train/extr_reward_min -6.2e-10 / train/extr_reward_std 0.96 / train/image_loss_mean 0.3 / train/image_loss_std 0.44 / train/model_loss_mean 1.54 / train/model_loss_std 3.03 / 
train/model_opt_grad_norm 7.82 / train/model_opt_grad_steps 8.6e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7161.46 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean 0.02 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.75 / train/policy_logprob_mag 8.31 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.02 / train/policy_logprob_min -8.31 / train/policy_logprob_std 1.03 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.39 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.33 / train/post_ent_mag 58.99 / train/post_ent_max 58.99 / train/post_ent_mean 41.36 / 
train/post_ent_min 24.42 / train/post_ent_std 3.9 / train/prior_ent_mag 72.86 / train/prior_ent_max 72.86 / train/prior_ent_mean 43.01 / train/prior_ent_min 30.81 / train/prior_ent_std 5.25 / train/rep_loss_mean 1.96 / train/rep_loss_std 4.49 / train/reward_avg 0.86 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.86 / train/reward_rate 0.43 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.25 / report/cont_avg 1 / report/cont_loss_mean 7.7e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.94 / report/dyn_loss_std 4.71 / report/image_loss_mean 0.31 / report/image_loss_std 0.53 / report/model_loss_mean 1.54 / report/model_loss_std 3.26 / report/post_ent_mag 53.51 / report/post_ent_max 53.51 / 
report/post_ent_mean 40.57 / report/post_ent_min 22.41 / report/post_ent_std 3.44 / report/prior_ent_mag 73.05 / report/prior_ent_max 73.05 / report/prior_ent_mean 42.15 / report/prior_ent_min 28.12 / report/prior_ent_std 4.9 / report/rep_loss_mean 1.94 / 
report/rep_loss_std 4.71 / report/reward_avg 0.98 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.5e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.98 / report/reward_rate 0.49 / eval/cont_avg 1 / eval/cont_loss_mean 1e-10 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-10 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.78 / eval/dyn_loss_std 3.57 / eval/image_loss_mean 0.26 / eval/image_loss_std 0.42 / eval/model_loss_mean 1.42 / eval/model_loss_std 2.48 / eval/post_ent_mag 56.58 / eval/post_ent_max 56.58 / eval/post_ent_mean 41.64 / 
eval/post_ent_min 25.26 / eval/post_ent_std 3.32 / eval/prior_ent_mag 73.05 / eval/prior_ent_max 73.05 / eval/prior_ent_mean 43.16 / eval/prior_ent_min 35.6 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 1.78 / eval/rep_loss_std 3.57 / eval/reward_avg 1.2 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.36 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 1.19 / eval/reward_rate 0.6 / replay/size 
1.7e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3828 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.98 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7836 / timer/agent.policy_total 17.42 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.6e-4 / timer/agent.train_count 1914 / timer/agent.train_total 242.92 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 175000 Counter(175000) 174937
eval_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T012459F140274-76BQL8dpyRBTEEsMvsXZ4U-7y1lfkH1pFDiLUtERVFzeu-1024.npz
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 175500 Counter(175500) 175437
Saved chunk: 20230922T012530F021448-3TJmN93J03v21y4ow1CxDA-4Qv0BP7XwPpax5GoULSUtC-1024.npz
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 748.0.
Starting evaluation at step 176000 Counter(176000) 175937
eval_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T012619F473168-7y1lfkH1pFDiLUtERVFzeu-63gQuBV2xqhDQS1cHNYSSp-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 176500 Counter(176500) 176437
Saved chunk: 20230922T012648F888966-4Qv0BP7XwPpax5GoULSUtC-6Tpx4ryU03SiDLh4SjcLQX-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 550.0.
Starting evaluation at step 177000 Counter(177000) 176937
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T012739F043584-63gQuBV2xqhDQS1cHNYSSp-02ExX9M0hTfmPGub7HDLNr-1024.npz
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 177500 Counter(177500) 177437
Saved chunk: 20230922T012806F882810-6Tpx4ryU03SiDLh4SjcLQX-4eXinNDz0Z5ClMhDcxzssQ-1024.npz
eval_Episode has 500 steps and return 758.0.
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 178000 Counter(178000) 177937
eval_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T012858F562566-02ExX9M0hTfmPGub7HDLNr-3aXc3nsDmK0qvEjbtAlQd5-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 178500 Counter(178500) 178437
Saved chunk: 20230922T012924F708972-4eXinNDz0Z5ClMhDcxzssQ-68SF9YzQxbDrhMsrCaq39H-1024.npz
eval_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 357318 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 760 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 763 / eval_episode/reward_rate 0.76 / train/action_mag 3.75 / train/action_max 3.57 / train/action_mean 0.06 / train/action_min -3.58 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 8.8e4 / train/actor_opt_loss -6.18 / train/adv_mag 0.53 / train/adv_max 0.43 / train/adv_mean 6.1e-4 / train/adv_min -0.45 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 3.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.95 / 
train/dyn_loss_std 4.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 8.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.85 / train/extr_critic_max 671.85 / train/extr_critic_mean 590.01 / train/extr_critic_min 383.18 / train/extr_critic_std 79.34 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.66 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.91 / train/extr_return_raw_max 668.91 / train/extr_return_raw_mean 590.15 / train/extr_return_raw_min 391.99 / train/extr_return_raw_std 79.44
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.89 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.3 / train/image_loss_std 0.44 / train/model_loss_mean 1.54 / train/model_loss_std 3.02 / 
train/model_opt_grad_norm 7.06 / train/model_opt_grad_steps 8.8e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6770.83 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean 0.06 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.77 / train/policy_logprob_mag 8.51 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.06 / train/policy_logprob_min -8.51 / train/policy_logprob_std 1.05 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.41 / train/policy_randomness_min 1.2e-3 / train/policy_randomness_std 0.34 / train/post_ent_mag 58.32 / train/post_ent_max 58.32 / train/post_ent_mean 41.19 / 
train/post_ent_min 24.59 / train/post_ent_std 3.88 / train/prior_ent_mag 72.66 / train/prior_ent_max 72.66 / train/prior_ent_mean 42.83 / train/prior_ent_min 31.2 / train/prior_ent_std 5.27 / train/rep_loss_mean 1.95 / train/rep_loss_std 4.46 / train/reward_avg 0.88 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.88 / train/reward_rate 0.44 / 
train_stats/mean_log_entropy 0.32 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.3e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.95 / report/dyn_loss_std 4.55 / report/image_loss_mean 0.31 / report/image_loss_std 0.51 / report/model_loss_mean 1.54 / report/model_loss_std 3.16 / report/post_ent_mag 56.64 / report/post_ent_max 56.64 / 
report/post_ent_mean 41.8 / report/post_ent_min 27.66 / report/post_ent_std 3.91 / report/prior_ent_mag 72.77 / report/prior_ent_max 72.77 / report/prior_ent_mean 43.38 / report/prior_ent_min 34.02 / report/prior_ent_std 5.22 / report/rep_loss_mean 1.95 / 
report/rep_loss_std 4.55 / report/reward_avg 0.74 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.3e-4 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.16 / report/reward_pred 0.73 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.85 / eval/dyn_loss_std 4.09 / eval/image_loss_mean 0.3 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.47 / eval/model_loss_std 2.72 / eval/post_ent_mag 53.39 / eval/post_ent_max 53.39 / eval/post_ent_mean 
42.15 / eval/post_ent_min 28.41 / eval/post_ent_std 3.41 / eval/prior_ent_mag 72.77 / eval/prior_ent_max 72.77 / eval/prior_ent_mean 43.59 / eval/prior_ent_min 35.63 / eval/prior_ent_std 4.89 / eval/rep_loss_mean 1.85 / eval/rep_loss_std 4.09 / eval/reward_avg 0.96 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.7e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 0.96 / eval/reward_rate 0.48 / replay/size
1.8e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3836 / timer/env.step_total 18.94 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.86 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.64 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 179000 Counter(179000) 178937
eval_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T013017F772061-3aXc3nsDmK0qvEjbtAlQd5-1hTLFBBBLf2dykmK5Yumse-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 179500 Counter(179500) 179437
Saved chunk: 20230922T013042F362255-68SF9YzQxbDrhMsrCaq39H-27swP1K6LlYiZzx8PNC9HV-1024.npz
eval_Episode has 500 steps and return 759.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 180000 Counter(180000) 179937
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T013138F021262-1hTLFBBBLf2dykmK5Yumse-2wcJI5jYgHNreplCrXyFJn-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 180500 Counter(180500) 180437
Saved chunk: 20230922T013201F104780-27swP1K6LlYiZzx8PNC9HV-4oZzd8s1Sd0SsfEwHnzdcj-1024.npz
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 181000 Counter(181000) 180937
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T013257F479861-2wcJI5jYgHNreplCrXyFJn-6eJXnjxKhOgy7D40vGFreo-1024.npz
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 181500 Counter(181500) 181437
Saved chunk: 20230922T013318F963416-4oZzd8s1Sd0SsfEwHnzdcj-2mPRjbEQ0lxFBBtyeY1RJK-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 182000 Counter(182000) 181937
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T013416F759652-6eJXnjxKhOgy7D40vGFreo-32BjMRvebXc8FZR8UQEUCJ-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 182500 Counter(182500) 182437
Saved chunk: 20230922T013436F698014-2mPRjbEQ0lxFBBtyeY1RJK-6VEO1Hr9O7guxwgmmN0njb-1024.npz
eval_Episode has 500 steps and return 762.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 365002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 762 / eval_episode/reward_rate 0.76 / train/action_mag 3.86 / train/action_max 3.67 / train/action_mean 0.06 / train/action_min -3.68 / train/action_std 0.95 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 9e4 / train/actor_opt_loss -10.16 / train/adv_mag 0.61 / train/adv_max 0.5 / train/adv_mean 1e-3 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 9.4e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.94 / 
train/dyn_loss_std 4.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 9e4 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 672.08 / train/extr_critic_max 672.08 / train/extr_critic_mean 588.6 / train/extr_critic_min 357.15 / train/extr_critic_std 80.34 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.65 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.18 / train/extr_return_raw_max 669.18 / train/extr_return_raw_mean 588.83 / train/extr_return_raw_min 375.48 / train/extr_return_raw_std 80.33
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.89 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.3 / train/image_loss_std 0.44 / train/model_loss_mean 1.52 / train/model_loss_std 2.99 / 
train/model_opt_grad_norm 7.67 / train/model_opt_grad_steps 9e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8255.21 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / 
train/policy_entropy_mean 0.1 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.65 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.1 / train/policy_logprob_min -8.65 / train/policy_logprob_std 1.08 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.43 / train/policy_randomness_min 1.2e-3 / train/policy_randomness_std 0.35 / train/post_ent_mag 58.91 / train/post_ent_max 58.91 / train/post_ent_mean 40.92 / 
train/post_ent_min 24.44 / train/post_ent_std 3.98 / train/prior_ent_mag 72.61 / train/prior_ent_max 72.61 / train/prior_ent_mean 42.56 / train/prior_ent_min 31.05 / train/prior_ent_std 5.37 / train/rep_loss_mean 1.94 / train/rep_loss_std 4.43 / train/reward_avg 0.88 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.88 / train/reward_rate 0.45 / 
train_stats/mean_log_entropy 0.3 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.4e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.1 / report/dyn_loss_std 4.89 / report/image_loss_mean 0.31 / report/image_loss_std 0.5 / report/model_loss_mean 1.63 / report/model_loss_std 3.33 / report/post_ent_mag 60.23 / report/post_ent_max 60.23 / 
report/post_ent_mean 41.57 / report/post_ent_min 25.94 / report/post_ent_std 3.8 / report/prior_ent_mag 72.23 / report/prior_ent_max 72.23 / report/prior_ent_mean 43.27 / report/prior_ent_min 26.9 / report/prior_ent_std 5.16 / report/rep_loss_mean 2.1 / 
report/rep_loss_std 4.89 / report/reward_avg 0.91 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.9 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 9.7e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.7e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 3.48 / eval/image_loss_mean 0.22 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.28 / eval/model_loss_std 2.31 / eval/post_ent_mag 56.98 / eval/post_ent_max 56.98 / eval/post_ent_mean 40.68 / 
eval/post_ent_min 29.29 / eval/post_ent_std 3.03 / eval/prior_ent_mag 72.23 / eval/prior_ent_max 72.23 / eval/prior_ent_mean 41.96 / eval/prior_ent_min 36.66 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.48 / eval/reward_avg 1.46 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.46 / eval/reward_rate 0.73 / replay/size
1.8e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.3 / timer/env.step_count 3842 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.89 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.05 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.92 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 183000 Counter(183000) 182937
eval_Episode has 500 steps and return 465.0.
Saved chunk: 20230922T013536F025501-32BjMRvebXc8FZR8UQEUCJ-4apl7hoaJYzbVNAPwpX8p9-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 183500 Counter(183500) 183437
Saved chunk: 20230922T013554F442104-6VEO1Hr9O7guxwgmmN0njb-3OtuH4ioqfRzddt9Z2G3SF-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 184000 Counter(184000) 183937
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T013656F378621-4apl7hoaJYzbVNAPwpX8p9-2PgpbdpOJ6eONXyHoHDnlN-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 184500 Counter(184500) 184437
Saved chunk: 20230922T013713F196595-3OtuH4ioqfRzddt9Z2G3SF-7xB0d1HCWoS2tDXPtkmv7p-1024.npz
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 185000 Counter(185000) 184937
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T013815F717161-2PgpbdpOJ6eONXyHoHDnlN-1FFMXqJwYhEJtdT0yaqVqL-1024.npz
train_Episode has 500 steps and return 759.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T013934F933711-1FFMXqJwYhEJtdT0yaqVqL-0000000000000000000000-56.npz
Saved chunk: 20230922T013830F992316-7xB0d1HCWoS2tDXPtkmv7p-0000000000000000000000-625.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 185500 Counter(185500) 185437
Saved chunk: 20230922T013830F992316-7xB0d1HCWoS2tDXPtkmv7p-3Eey063YxVAaQQtz2nA1cR-1024.npz
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 186000 Counter(186000) 185937
eval_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T013934F933711-1FFMXqJwYhEJtdT0yaqVqL-4RpqWTvIKWfCfyQO2Yn3zS-1024.npz
train_Episode has 500 steps and return 759.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 372774 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 763 / eval_episode/reward_rate 0.76 / train/action_mag 3.96 / train/action_max 3.74 / train/action_mean 0.06 / train/action_min -3.83 / train/action_std 0.95 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 9.2e4 / train/actor_opt_loss -2.93 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 2.6e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 9.2e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.93 / 
train/dyn_loss_std 4.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.18 / train/extr_critic_critic_opt_grad_steps 9.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.89 / train/extr_critic_max 672.89 / train/extr_critic_mean 593.84 / train/extr_critic_min 390.66 / train/extr_critic_std 77.8 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.66 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.12 / train/extr_return_raw_max 670.12 / train/extr_return_raw_mean 593.9 / train/extr_return_raw_min 396.23 / train/extr_return_raw_std 78.02 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.93 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.29 / train/image_loss_std 0.43 / train/model_loss_mean 1.51 / train/model_loss_std 2.94 / 
train/model_opt_grad_norm 7.34 / train/model_opt_grad_steps 9.2e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7551.55 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.14 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.83 / train/policy_logprob_mag 8.6 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.14 / train/policy_logprob_min -8.6 / train/policy_logprob_std 1.09 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.36 / train/post_ent_mag 58.18 / train/post_ent_max 58.18 / train/post_ent_mean 40.98 / 
train/post_ent_min 24.85 / train/post_ent_std 3.89 / train/prior_ent_mag 72.29 / train/prior_ent_max 72.29 / train/prior_ent_mean 42.59 / train/prior_ent_min 32.16 / train/prior_ent_std 5.32 / train/rep_loss_mean 1.93 / train/rep_loss_std 4.36 / train/reward_avg 0.92 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.92 / train/reward_rate 0.46 / 
train_stats/mean_log_entropy 0.15 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / report/dyn_loss_std 4.46 / report/image_loss_mean 0.24 / report/image_loss_std 0.33 / report/model_loss_mean 1.41 / report/model_loss_std 2.92 / report/post_ent_mag 56.67 / report/post_ent_max 56.67 / 
report/post_ent_mean 39.67 / report/post_ent_min 28.32 / report/post_ent_std 3.35 / report/prior_ent_mag 72.39 / report/prior_ent_max 72.39 / report/prior_ent_mean 41.32 / report/prior_ent_min 33.35 / report/prior_ent_std 5.33 / report/rep_loss_mean 1.84 / 
report/rep_loss_std 4.46 / report/reward_avg 1.22 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.22 / report/reward_rate 0.61 / eval/cont_avg 1 / eval/cont_loss_mean 9.3e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.9 / eval/dyn_loss_std 4.08 / eval/image_loss_mean 0.29 / eval/image_loss_std 0.38 / eval/model_loss_mean 1.49 / eval/model_loss_std 2.71 / eval/post_ent_mag 53.35 / eval/post_ent_max 53.35 / eval/post_ent_mean 41.8 / eval/post_ent_min 28.37 / 
eval/post_ent_std 3.7 / eval/prior_ent_mag 72.39 / eval/prior_ent_max 72.39 / eval/prior_ent_mean 43.33 / eval/prior_ent_min 35.59 / eval/prior_ent_std 5.3 / eval/rep_loss_mean 1.9 / eval/rep_loss_std 4.08 / eval/reward_avg 0.91 / eval/reward_loss_mean 0.06 / 
eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 0.91 / eval/reward_rate 0.46 / replay/size 1.9e5 / replay/inserts 
3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3886 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.89 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.16 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1943 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.8e-4 / 
timer/agent.train_count 1943 / timer/agent.train_total 246.64 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / 
timer/dataset_eval_max 3.2e-5 / fps 25.91

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 186500 Counter(186500) 186437
Saved chunk: 20230922T013948F826446-3Eey063YxVAaQQtz2nA1cR-68eWF8uDIIis7maDKmGOd3-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 187000 Counter(187000) 186937
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T014054F336096-4RpqWTvIKWfCfyQO2Yn3zS-7GOh4X25lOKwk0RbKd3Eok-1024.npz
Starting evaluation at step 187500 Counter(187500) 187437
Saved chunk: 20230922T014107F285022-68eWF8uDIIis7maDKmGOd3-0mqlGkciJKFKtwL0XmFNQt-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 188000 Counter(188000) 187937
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T014214F750005-7GOh4X25lOKwk0RbKd3Eok-0mIh9mLu6Ps0lpTPCZjvsR-1024.npz
Starting evaluation at step 188500 Counter(188500) 188437
eval_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T014225F366333-0mqlGkciJKFKtwL0XmFNQt-1jjuGA61oMVZH46csKrCIq-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 189000 Counter(189000) 188937
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T014334F167984-0mIh9mLu6Ps0lpTPCZjvsR-6uQHwURmurbv3AJcpkTwc7-1024.npz
Starting evaluation at step 189500 Counter(189500) 189437
eval_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T014343F194757-1jjuGA61oMVZH46csKrCIq-4zJqBHiRuy60vrPjgqHo0L-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 190000 Counter(190000) 189937
eval_Episode has 500 steps and return 764.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 380446 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 764 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / train/action_mag 4.05 / train/action_max 3.85 / train/action_mean 0.07 / train/action_min -3.91 / train/action_std 0.97 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 9.4e4 / train/actor_opt_loss -3.08 / train/adv_mag 0.49 / train/adv_max 0.42 / train/adv_mean 2.5e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 8.3e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.94 / 
train/dyn_loss_std 4.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 9.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.4 / train/extr_critic_max 672.4 / train/extr_critic_mean 590.83 / train/extr_critic_min 393.93 / train/extr_critic_std 80.89 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.65 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.81 / train/extr_return_raw_max 669.81 / train/extr_return_raw_mean 590.89 / train/extr_return_raw_min 397.02 / train/extr_return_raw_std 81.13
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.93 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.29 / train/image_loss_std 0.44 / train/model_loss_mean 1.52 / train/model_loss_std 2.98 / 
train/model_opt_grad_norm 7.03 / train/model_opt_grad_steps 9.4e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8463.54 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.21 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.59 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.21 / train/policy_logprob_min -8.59 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.47 / train/policy_randomness_min 8.4e-4 / train/policy_randomness_std 0.37 / train/post_ent_mag 58.64 / train/post_ent_max 58.64 / train/post_ent_mean 40.68 / train/post_ent_min
24.31 / train/post_ent_std 4.09 / train/prior_ent_mag 72.36 / train/prior_ent_max 72.36 / train/prior_ent_mean 42.3 / train/prior_ent_min 30.59 / train/prior_ent_std 5.48 / train/rep_loss_mean 1.94 / train/rep_loss_std 4.41 / train/reward_avg 0.92 / train/reward_loss_mean
0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.92 / train/reward_rate 0.46 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.39 / report/cont_avg 1 / report/cont_loss_mean 6.3e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.15 / report/image_loss_mean 0.23 / report/image_loss_std 0.34 / report/model_loss_mean 1.31 / report/model_loss_std 2.13 / report/post_ent_mag 55.69 / report/post_ent_max 55.69 / 
report/post_ent_mean 39.68 / report/post_ent_min 21.99 / report/post_ent_std 4.24 / report/prior_ent_mag 72.28 / report/prior_ent_max 72.28 / report/prior_ent_mean 41.04 / report/prior_ent_min 25.21 / report/prior_ent_std 5.9 / report/rep_loss_mean 1.67 / 
report/rep_loss_std 3.15 / report/reward_avg 1.27 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.27 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 9.8e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.88 / eval/dyn_loss_std 3.92 / eval/image_loss_mean 0.29 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.5 / eval/model_loss_std 2.63 / eval/post_ent_mag 52.9 / eval/post_ent_max 52.9 / eval/post_ent_mean 41.1 
/ eval/post_ent_min 27.57 / eval/post_ent_std 3.66 / eval/prior_ent_mag 72.28 / eval/prior_ent_max 72.28 / eval/prior_ent_mean 42.65 / eval/prior_ent_min 34.8 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 1.88 / eval/rep_loss_std 3.92 / eval/reward_avg 1.08 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.07 / eval/reward_rate 0.54 / 
replay/size 1.9e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3836 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.22 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.65 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T014453F559411-6uQHwURmurbv3AJcpkTwc7-0ivi0Cl4Qj889pA7DUZIHb-1024.npz
Starting evaluation at step 190500 Counter(190500) 190437
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 191000 Counter(191000) 190937
Saved chunk: 20230922T014501F027969-4zJqBHiRuy60vrPjgqHo0L-4CXXrmthEIp8VUin7jDSpZ-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T014613F633375-0ivi0Cl4Qj889pA7DUZIHb-3wNoD0qvF3cXDFLqvghMgf-1024.npz
Starting evaluation at step 191500 Counter(191500) 191437
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 192000 Counter(192000) 191937
Saved chunk: 20230922T014655F374433-4CXXrmthEIp8VUin7jDSpZ-69MXE8Xa7p79K0UQFtskaf-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 192500 Counter(192500) 192437
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T014733F404506-3wNoD0qvF3cXDFLqvghMgf-2oPKC2Mhu1fC0tpFgeHSPr-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 193000 Counter(193000) 192937
Saved chunk: 20230922T014813F257044-69MXE8Xa7p79K0UQFtskaf-15s4QF8oCYO3JqQ7V89b5c-1024.npz
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 193500 Counter(193500) 193437
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T014856F132622-2oPKC2Mhu1fC0tpFgeHSPr-0OZ2KHhHTQCv964QcpxlnQ-1024.npz
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 194000 Counter(194000) 193937
Saved chunk: 20230922T014931F009544-15s4QF8oCYO3JqQ7V89b5c-2smLjVyb1AcB26972DRQYI-1024.npz
eval_Episode has 500 steps and return 765.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 388122 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 751 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 765 / eval_episode/reward_rate 0.76 / train/action_mag 4.09 / train/action_max 3.89 / train/action_mean 0.05 / train/action_min -3.94 / train/action_std 0.97 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 9.6e4 / train/actor_opt_loss -5.19 / train/adv_mag 0.53 / train/adv_max 0.44 / train/adv_mean 4.7e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.8e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.92 / 
train/dyn_loss_std 4.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 9.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.01 / train/extr_critic_max 672.01 / train/extr_critic_mean 590.74 / train/extr_critic_min 380 / train/extr_critic_std 79.5 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.65 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.37 / train/extr_return_raw_max 669.37 / train/extr_return_raw_mean 590.85 / train/extr_return_raw_min 388.93 / train/extr_return_raw_std 79.63
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.92 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.29 / train/image_loss_std 0.44 / train/model_loss_mean 1.51 / train/model_loss_std 2.95 / 
train/model_opt_grad_norm 7.28 / train/model_opt_grad_steps 9.5e4 / train/model_opt_loss 9600.05 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6406.25 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.19 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.61 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.19 / train/policy_logprob_min -8.61 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.47 / train/policy_randomness_min 9.1e-4 / train/policy_randomness_std 0.37 / train/post_ent_mag 58.28 / train/post_ent_max 58.28 / train/post_ent_mean 40.72 / train/post_ent_min
24.83 / train/post_ent_std 4.09 / train/prior_ent_mag 72.15 / train/prior_ent_max 72.15 / train/prior_ent_mean 42.33 / train/prior_ent_min 31.29 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.92 / train/rep_loss_std 4.35 / train/reward_avg 0.9 / train/reward_loss_mean
0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.9 / train/reward_rate 0.45 / 
train_stats/mean_log_entropy 0.44 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.8e-11 / report/cont_loss_std 4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.15 / report/dyn_loss_std 5 / report/image_loss_mean 0.35 / report/image_loss_std 0.53 / report/model_loss_mean 1.69 / report/model_loss_std 3.41 / report/post_ent_mag 61.1 / report/post_ent_max 61.1 / 
report/post_ent_mean 41.76 / report/post_ent_min 24.22 / report/post_ent_std 4.37 / report/prior_ent_mag 72.51 / report/prior_ent_max 72.51 / report/prior_ent_mean 43.57 / report/prior_ent_min 28.29 / report/prior_ent_std 5.39 / report/rep_loss_mean 2.15 / 
report/rep_loss_std 5 / report/reward_avg 0.5 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.18 / report/reward_pred 0.5 / report/reward_rate 0.26 / eval/cont_avg 1 / eval/cont_loss_mean 8.3e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.31 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.56 / eval/post_ent_mag 54.12 / eval/post_ent_max 54.12 / eval/post_ent_mean 39.61 / eval/post_ent_min 31.75 / 
eval/post_ent_std 2.95 / eval/prior_ent_mag 72.51 / eval/prior_ent_max 72.51 / eval/prior_ent_mean 40.8 / eval/prior_ent_min 37.06 / eval/prior_ent_std 4.93 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.31 / eval/reward_avg 1.68 / eval/reward_loss_mean 0.11 / 
eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.68 / eval/reward_rate 0.84 / replay/size 1.9e5 / replay/inserts 
3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3838 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 7.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.49 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.8e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.6e-3 / timer/dataset_train_count 
1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.54 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 194500 Counter(194500) 194437
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T015015F327704-0OZ2KHhHTQCv964QcpxlnQ-5zLzH9a706HNLeIFFRGs60-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 195000 Counter(195000) 194937
Saved chunk: 20230922T015048F617975-2smLjVyb1AcB26972DRQYI-3NCEN2ERhp8kGtOrn6D2qC-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 195500 Counter(195500) 195437
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T015135F492431-5zLzH9a706HNLeIFFRGs60-6DfArr2t5qjLmyvOtydENP-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 196000 Counter(196000) 195937
Saved chunk: 20230922T015207F445572-3NCEN2ERhp8kGtOrn6D2qC-6Ez5rTrDfZ1mQ9JDbzaXZg-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 196500 Counter(196500) 196437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T015254F984762-6DfArr2t5qjLmyvOtydENP-2sSvHjKUxhaMwZQSJPgKhS-1024.npz
train_Episode has 500 steps and return 761.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 197000 Counter(197000) 196937
Saved chunk: 20230922T015325F244785-6Ez5rTrDfZ1mQ9JDbzaXZg-0000000000000000000000-884.npz
Saved chunk: 20230922T015414F349477-2sSvHjKUxhaMwZQSJPgKhS-0000000000000000000000-392.npz
Saved chunk: 20230922T015325F244785-6Ez5rTrDfZ1mQ9JDbzaXZg-4raEHnEZfNj52GOC8YdIip-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 197500 Counter(197500) 197437
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T015414F349477-2sSvHjKUxhaMwZQSJPgKhS-66a26lRi7hEe7QNvZWJVL3-1024.npz
train_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 395890 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 765 / eval_episode/reward_rate 0.76 / train/action_mag 4.15 / train/action_max 3.87 / train/action_mean 0.06 / train/action_min -4.03 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 9.7e4 / train/actor_opt_loss -4.2 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 3.6e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 8.3e-11 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.91 / 
train/dyn_loss_std 4.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.18 / train/extr_critic_critic_opt_grad_steps 9.7e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.74 / train/extr_critic_max 671.74 / train/extr_critic_mean 594.7 / train/extr_critic_min 387.03 / train/extr_critic_std 79.58 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.01 / train/extr_return_raw_max 669.01 / train/extr_return_raw_mean 594.77 / train/extr_return_raw_min 391.3 / train/extr_return_raw_std 79.75 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.97 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.29 / train/image_loss_std 0.43 / train/model_loss_mean 1.5 / train/model_loss_std 2.93 / 
train/model_opt_grad_norm 7.29 / train/model_opt_grad_steps 9.7e4 / train/model_opt_loss 1.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9793.81 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.22 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.59 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.22 / train/policy_logprob_min -8.59 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 7.2e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 58.27 / train/post_ent_max 58.27 / train/post_ent_mean 40.66 / train/post_ent_min
24.6 / train/post_ent_std 4.08 / train/prior_ent_mag 72.02 / train/prior_ent_max 72.02 / train/prior_ent_mean 42.24 / train/prior_ent_min 31.67 / train/prior_ent_std 5.48 / train/rep_loss_mean 1.91 / train/rep_loss_std 4.32 / train/reward_avg 0.95 / train/reward_loss_mean
0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.95 / train/reward_rate 0.48 / 
train_stats/mean_log_entropy 0.55 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.7e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.81 / report/dyn_loss_std 3.81 / report/image_loss_mean 0.25 / report/image_loss_std 0.41 / report/model_loss_mean 1.4 / report/model_loss_std 2.64 / report/post_ent_mag 59.3 / report/post_ent_max 59.3 / 
report/post_ent_mean 40.45 / report/post_ent_min 24.36 / report/post_ent_std 4.1 / report/prior_ent_mag 71.95 / report/prior_ent_max 71.95 / report/prior_ent_mean 41.96 / report/prior_ent_min 28.72 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.81 / 
report/rep_loss_std 3.81 / report/reward_avg 1.16 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.16 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.69 / eval/image_loss_mean 0.27 / eval/image_loss_std 0.47 / eval/model_loss_mean 1.38 / eval/model_loss_std 2.59 / eval/post_ent_mag 56.88 / eval/post_ent_max 56.88 / eval/post_ent_mean 
41.06 / eval/post_ent_min 29.88 / eval/post_ent_std 3.8 / eval/prior_ent_mag 71.95 / eval/prior_ent_max 71.95 / eval/prior_ent_mean 42.51 / eval/prior_ent_min 34.82 / eval/prior_ent_std 5.44 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.69 / eval/reward_avg 1.2 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.2 / eval/reward_rate 0.6 / replay/size 
2e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3884 / timer/env.step_total 19.15 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.2 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.26 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.36 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 198000 Counter(198000) 197937
Saved chunk: 20230922T015443F180422-4raEHnEZfNj52GOC8YdIip-5t5iriVnB3KS0D8merSl7A-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 198500 Counter(198500) 198437
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T015533F800530-66a26lRi7hEe7QNvZWJVL3-08WmztuQcYgiQC3lsCj7pD-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 199000 Counter(199000) 198937
Saved chunk: 20230922T015601F676540-5t5iriVnB3KS0D8merSl7A-3yrjNj5BDwt1xodTOjaXk2-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 199500 Counter(199500) 199437
eval_Episode has 500 steps and return 666.0.
Saved chunk: 20230922T015654F109891-08WmztuQcYgiQC3lsCj7pD-7JkOapdqzBZhqh211KqwYT-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 200000 Counter(200000) 199937
Saved chunk: 20230922T015719F782256-3yrjNj5BDwt1xodTOjaXk2-0gKvcaQ4uHe04DuYHTssHU-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 745.0.
Starting evaluation at step 200500 Counter(200500) 200437
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T015813F532553-7JkOapdqzBZhqh211KqwYT-40gxvuwIE28o3brUGPwPg3-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 201000 Counter(201000) 200937
Saved chunk: 20230922T015837F587166-0gKvcaQ4uHe04DuYHTssHU-1qpdXk5WKkhgpk4Q3Mt1tr-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 201500 Counter(201500) 201437
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T015932F831863-40gxvuwIE28o3brUGPwPg3-4fkhku0qxvNdu8JcJn0PxV-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 403562 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 760 / episode/reward_rate 0.76 / train/action_mag 4.17 / train/action_max 3.95 / train/action_mean 0.06 / train/action_min -4.02 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 9.9e4 / train/actor_opt_loss -4.09 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 3.3e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.6e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.89 / 
train/dyn_loss_std 4.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.17 / train/extr_critic_critic_opt_grad_steps 9.9e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.38 / train/extr_critic_max 671.38 / train/extr_critic_mean 596.62 / train/extr_critic_min 389.87 / train/extr_critic_std 77.96 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.65 / train/extr_return_raw_max 668.65 / train/extr_return_raw_mean 596.69 / train/extr_return_raw_min 394.65 / train/extr_return_raw_std 78.1 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.99 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.28 / train/image_loss_std 0.42 / train/model_loss_mean 1.47 / train/model_loss_std 2.86 / 
train/model_opt_grad_norm 7.29 / train/model_opt_grad_steps 9.9e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.28 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.29 / train/policy_logprob_min -8.69 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 7.9e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 58.44 / train/post_ent_max 58.44 / train/post_ent_mean 40.59 / train/post_ent_min
25.12 / train/post_ent_std 4.01 / train/prior_ent_mag 71.98 / train/prior_ent_max 71.98 / train/prior_ent_mean 42.15 / train/prior_ent_min 31.61 / train/prior_ent_std 5.44 / train/rep_loss_mean 1.89 / train/rep_loss_std 4.23 / train/reward_avg 0.98 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.98 / train/reward_rate 0.49 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.61 / report/cont_avg 1 / report/cont_loss_mean 7.2e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.93 / report/dyn_loss_std 4.42 / report/image_loss_mean 0.27 / report/image_loss_std 0.32 / report/model_loss_mean 1.49 / report/model_loss_std 2.89 / report/post_ent_mag 63.03 / report/post_ent_max 63.03 / 
report/post_ent_mean 40.77 / report/post_ent_min 24.35 / report/post_ent_std 4.15 / report/prior_ent_mag 72.34 / report/prior_ent_max 72.34 / report/prior_ent_mean 42.3 / report/prior_ent_min 27.08 / report/prior_ent_std 5.48 / report/rep_loss_mean 1.93 / 
report/rep_loss_std 4.42 / report/reward_avg 0.83 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.83 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.69 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.2 / eval/model_loss_std 1.83 / eval/post_ent_mag 52.37 / eval/post_ent_max 52.37 / eval/post_ent_mean 
39.36 / eval/post_ent_min 28.4 / eval/post_ent_std 2.91 / eval/prior_ent_mag 72.34 / eval/prior_ent_max 72.34 / eval/prior_ent_mean 40.56 / eval/prior_ent_min 34.95 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.69 / eval/reward_avg 1.64 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.5e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.63 / eval/reward_rate 0.82 / replay/size 
2e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3836 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.94 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.59 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 202000 Counter(202000) 201937
Saved chunk: 20230922T015955F307325-1qpdXk5WKkhgpk4Q3Mt1tr-1mJw20mDkHT47xByy29fbf-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 202500 Counter(202500) 202437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T020052F185204-4fkhku0qxvNdu8JcJn0PxV-4965uw9a0RIUyHa51WTE8m-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 203000 Counter(203000) 202937
Saved chunk: 20230922T020113F983812-1mJw20mDkHT47xByy29fbf-0xzPoSmrdR63jr7jfuPExb-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 203500 Counter(203500) 203437
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T020212F564666-4965uw9a0RIUyHa51WTE8m-6txARmmBrZXT3ljsHb6UnI-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 204000 Counter(204000) 203937
Saved chunk: 20230922T020232F014786-0xzPoSmrdR63jr7jfuPExb-3744HqseCu5EqhwJIywxJm-1024.npz
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 204500 Counter(204500) 204437
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T020331F911981-6txARmmBrZXT3ljsHb6UnI-6vczWyvALZkeeviAHlXkOp-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 205000 Counter(205000) 204937
Saved chunk: 20230922T020349F771754-3744HqseCu5EqhwJIywxJm-14a1pv5nyM5N2RuybDNR06-1024.npz
eval_Episode has 500 steps and return 759.0.
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 205500 Counter(205500) 205437
eval_Episode has 500 steps and return 764.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 411242 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 757 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 764 / eval_episode/reward_rate 0.76 / train/action_mag 4.27 / train/action_max 4.1 / train/action_mean 0.05 / train/action_min -4.06 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -4.12 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean 3.4e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 7.4e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.9 / 
train/dyn_loss_std 4.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.18 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.02 / train/extr_critic_max 671.02 / train/extr_critic_mean 597.36 / train/extr_critic_min 393.69 / train/extr_critic_std 77.51 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.68 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.52 / train/extr_return_raw_max 668.52 / train/extr_return_raw_mean 597.43 / train/extr_return_raw_min 398.56 / train/extr_return_raw_std 77.63
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.99 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.28 / train/image_loss_std 0.42 / train/model_loss_mean 1.49 / train/model_loss_std 2.91 / 
train/model_opt_grad_norm 7.59 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8072.92 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.67 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.67 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 5.8e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.9 / train/post_ent_max 57.9 / train/post_ent_mean 40.65 / train/post_ent_min 
25.01 / train/post_ent_std 4 / train/prior_ent_mag 71.86 / train/prior_ent_max 71.86 / train/prior_ent_mean 42.22 / train/prior_ent_min 31.6 / train/prior_ent_std 5.43 / train/rep_loss_mean 1.9 / train/rep_loss_std 4.31 / train/reward_avg 0.97 / train/reward_loss_mean 
0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.97 / train/reward_rate 0.49 / 
train_stats/mean_log_entropy 0.66 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.8e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.97 / report/dyn_loss_std 4.32 / report/image_loss_mean 0.3 / report/image_loss_std 0.56 / report/model_loss_mean 1.54 / report/model_loss_std 3.05 / report/post_ent_mag 56.3 / report/post_ent_max 56.3 / 
report/post_ent_mean 40.99 / report/post_ent_min 25.28 / report/post_ent_std 4.13 / report/prior_ent_mag 71.57 / report/prior_ent_max 71.57 / report/prior_ent_mean 42.62 / report/prior_ent_min 31.96 / report/prior_ent_std 5.62 / report/rep_loss_mean 1.97 / 
report/rep_loss_std 4.32 / report/reward_avg 0.78 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.1e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 0.78 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 7.5e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 3.09 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.24 / eval/model_loss_std 2 / eval/post_ent_mag 53.32 / eval/post_ent_max 53.32 / eval/post_ent_mean 40.11 / eval/post_ent_min 21.48 / 
eval/post_ent_std 2.99 / eval/prior_ent_mag 71.57 / eval/prior_ent_max 71.57 / eval/prior_ent_mean 41.34 / eval/prior_ent_min 35.66 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 3.09 / eval/reward_avg 1.42 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.42 / eval/reward_rate 0.71 / replay/size 2.1e5 / replay/inserts 3840 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3840 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.76 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 16.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 
1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.74 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T020451F122331-6vczWyvALZkeeviAHlXkOp-4is2cn86wf5qJotvhgILVS-1024.npz
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 206000 Counter(206000) 205937
Saved chunk: 20230922T020507F389667-14a1pv5nyM5N2RuybDNR06-6PW5u1ydyTLgpBakYczcP5-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 206500 Counter(206500) 206437
eval_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T020611F108022-4is2cn86wf5qJotvhgILVS-7HbHsn0h1tGV0FLktzGZpw-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 207000 Counter(207000) 206937
Saved chunk: 20230922T020625F919702-6PW5u1ydyTLgpBakYczcP5-1tlKyqitQ4YJlQQ9jtAtl6-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 207500 Counter(207500) 207437
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T020730F629733-7HbHsn0h1tGV0FLktzGZpw-01m6P3KxXxsvvpLxpZWGO9-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 208000 Counter(208000) 207937
Saved chunk: 20230922T020743F821709-1tlKyqitQ4YJlQQ9jtAtl6-2VtbgadVS8BkaRjTrqwTNI-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 208500 Counter(208500) 208437
eval_Episode has 500 steps and return 763.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T020901F623078-2VtbgadVS8BkaRjTrqwTNI-0000000000000000000000-620.npz
Saved chunk: 20230922T020849F924207-01m6P3KxXxsvvpLxpZWGO9-0000000000000000000000-728.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T020849F924207-01m6P3KxXxsvvpLxpZWGO9-6IfOorLjLrlmRFa0sA22lS-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 209000 Counter(209000) 208937
Saved chunk: 20230922T020901F623078-2VtbgadVS8BkaRjTrqwTNI-51utBofpBtkC27rJXizDoU-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 209500 Counter(209500) 209437
eval_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 419002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / train/action_mag 4.25 / train/action_max 4.06 / train/action_mean 0.06 / train/action_min -4.1 / train/action_std 1.01 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -5.2 / train/adv_mag 0.54 / train/adv_max 0.41 / train/adv_mean 4.4e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 8.1e-11 / train/cont_loss_std 5.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.89 / 
train/dyn_loss_std 4.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.18 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 670.74 / train/extr_critic_max 670.74 / train/extr_critic_mean 596.18 / train/extr_critic_min 392.86 / train/extr_critic_std 78.01 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.55 / train/extr_return_raw_max 668.55 / train/extr_return_raw_mean 596.27 / train/extr_return_raw_min 398.9 / train/extr_return_raw_std 78.11 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.99 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.28 / train/image_loss_std 0.43 / train/model_loss_mean 1.47 / train/model_loss_std 2.88 / 
train/model_opt_grad_norm 7.4 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 9956.84 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6752.58 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.29 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.29 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 58.26 / train/post_ent_max 58.26 / train/post_ent_mean 40.43 / train/post_ent_min
25.06 / train/post_ent_std 4.06 / train/prior_ent_mag 71.62 / train/prior_ent_max 71.62 / train/prior_ent_mean 41.99 / train/prior_ent_min 31.58 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.89 / train/rep_loss_std 4.26 / train/reward_avg 0.98 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.98 / train/reward_rate 0.49 / 
train_stats/mean_log_entropy 0.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.7e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.95 / report/dyn_loss_std 4.31 / report/image_loss_mean 0.26 / report/image_loss_std 0.47 / report/model_loss_mean 1.49 / report/model_loss_std 2.97 / report/post_ent_mag 59.61 / report/post_ent_max 59.61 / 
report/post_ent_mean 39.26 / report/post_ent_min 24.6 / report/post_ent_std 4.51 / report/prior_ent_mag 71.29 / report/prior_ent_max 71.29 / report/prior_ent_mean 40.97 / report/prior_ent_min 29.38 / report/prior_ent_std 5.82 / report/rep_loss_mean 1.95 / 
report/rep_loss_std 4.31 / report/reward_avg 0.99 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 0.99 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 6.4e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.4e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.42 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.28 / eval/model_loss_std 2.34 / eval/post_ent_mag 57.13 / eval/post_ent_max 57.13 / eval/post_ent_mean 39.32 / 
eval/post_ent_min 28.21 / eval/post_ent_std 3.54 / eval/prior_ent_mag 71.29 / eval/prior_ent_max 71.29 / eval/prior_ent_mean 40.57 / eval/prior_ent_min 34.81 / eval/prior_ent_std 5.22 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.42 / eval/reward_avg 1.53 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / 
replay/size 2.1e5 / replay/inserts 3880 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.93 / timer/env.step_count 3880 / timer/env.step_total 19.18 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.2 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7888 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1940 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1940 / timer/agent.train_total 246.16 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.4e-8 / timer/dataset_eval_avg 2.6e-5 / 
timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T021009F447867-6IfOorLjLrlmRFa0sA22lS-4GOziPUJiRqJglVcJcgJkm-1024.npz
Starting evaluation at step 210000 Counter(210000) 209937
Saved chunk: 20230922T021019F489420-51utBofpBtkC27rJXizDoU-0ehyxOSIVXFkevqO9GRzdw-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 210500 Counter(210500) 210437
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T021129F512629-4GOziPUJiRqJglVcJcgJkm-1rC6JQzzRaYThePe23zGJz-1024.npz
Starting evaluation at step 211000 Counter(211000) 210937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T021138F054903-0ehyxOSIVXFkevqO9GRzdw-5j1C43RBVfeSwG5YSRyVxf-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 211500 Counter(211500) 211437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T021250F143814-1rC6JQzzRaYThePe23zGJz-3rPTqI82T1lzKOqvrFdvbR-1024.npz
Starting evaluation at step 212000 Counter(212000) 211937
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T021257F085308-5j1C43RBVfeSwG5YSRyVxf-6DBM0M7zCjWcHCvlReWuwj-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 212500 Counter(212500) 212437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T021409F450325-3rPTqI82T1lzKOqvrFdvbR-0DWDoBmnG7gZ0sb7PKl3K9-1024.npz
Starting evaluation at step 213000 Counter(213000) 212937
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T021414F833363-6DBM0M7zCjWcHCvlReWuwj-1owYJ7Dblf9FysyzFlYTIS-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 426746 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 766 / eval_episode/reward_rate 0.77 / train/action_mag 4.26 / train/action_max 4.11 / train/action_mean 0.06 / train/action_min -4.04 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.5 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 2.8e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.8e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.88 / 
train/dyn_loss_std 4.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.8 / train/extr_critic_max 670.8 / train/extr_critic_mean 598.25 / train/extr_critic_min 400.46 / train/extr_critic_std 76.64 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.45 / train/extr_return_raw_max 668.45 / train/extr_return_raw_mean 598.31 / train/extr_return_raw_min 404.08 / train/extr_return_raw_std 76.82
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.27 / train/image_loss_std 0.42 / train/model_loss_mean 1.47 / train/model_loss_std 2.85 / 
train/model_opt_grad_norm 7.17 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7409.33 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 4.2e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 58.1 / train/post_ent_max 58.1 / train/post_ent_mean 40.33 / train/post_ent_min 
24.58 / train/post_ent_std 4.1 / train/prior_ent_mag 71.45 / train/prior_ent_max 71.45 / train/prior_ent_mean 41.87 / train/prior_ent_min 31.34 / train/prior_ent_std 5.5 / train/rep_loss_mean 1.88 / train/rep_loss_std 4.22 / train/reward_avg 0.99 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.99 / train/reward_rate 0.5 / 
train_stats/mean_log_entropy 0.72 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 7.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.86 / report/dyn_loss_std 4.13 / report/image_loss_mean 0.28 / report/image_loss_std 0.55 / report/model_loss_mean 1.44 / report/model_loss_std 2.92 / report/post_ent_mag 61.65 / report/post_ent_max 61.65 / 
report/post_ent_mean 40.66 / report/post_ent_min 24.65 / report/post_ent_std 4.36 / report/prior_ent_mag 71.55 / report/prior_ent_max 71.55 / report/prior_ent_mean 42.2 / report/prior_ent_min 33.11 / report/prior_ent_std 5.72 / report/rep_loss_mean 1.86 / 
report/rep_loss_std 4.13 / report/reward_avg 0.71 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.71 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 7.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.26 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.1 / eval/post_ent_mag 55.04 / eval/post_ent_max 55.04 / eval/post_ent_mean 
39.72 / eval/post_ent_min 30.69 / eval/post_ent_std 3.32 / eval/prior_ent_mag 71.55 / eval/prior_ent_max 71.55 / eval/prior_ent_mean 40.95 / eval/prior_ent_min 34.45 / eval/prior_ent_std 5.12 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.26 / eval/reward_avg 1.44 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.44 / eval/reward_rate 0.72 / replay/size
2.1e5 / replay/inserts 3872 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3872 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.28 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7379 / timer/agent.policy_total 15.97 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1936 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1936 / timer/agent.train_total 246.96 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.81

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 213500 Counter(213500) 213437
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 214000 Counter(214000) 213937
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T021528F705367-0DWDoBmnG7gZ0sb7PKl3K9-5t1vQzRuyo6r5eDP59HPKi-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 214500 Counter(214500) 214437
Saved chunk: 20230922T021532F535979-1owYJ7Dblf9FysyzFlYTIS-1ObHztsXIuFsPYrtWZSi4h-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 215000 Counter(215000) 214937
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T021652F376516-5t1vQzRuyo6r5eDP59HPKi-3bReAzykZ8HrRvJrdLiU0E-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 215500 Counter(215500) 215437
Saved chunk: 20230922T021726F834600-1ObHztsXIuFsPYrtWZSi4h-4h2WiEhR42W8NFE48J8Eoq-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 216000 Counter(216000) 215937
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T021811F740771-3bReAzykZ8HrRvJrdLiU0E-2SehYjwjzikF5FYXhA7wpd-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 216500 Counter(216500) 216437
Saved chunk: 20230922T021844F589992-4h2WiEhR42W8NFE48J8Eoq-2CsH4DT6qvFde8Jll7Pll0-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 217000 Counter(217000) 216937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T021931F063837-2SehYjwjzikF5FYXhA7wpd-0JUS7w84p9CDuqcOiX9jQB-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 434422 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / train/action_mag 4.27 / train/action_max 4.06 / train/action_mean 0.06 / train/action_min -4.07 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.42 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 2.7e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.5e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.85 / 
train/dyn_loss_std 4.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.97 / train/extr_critic_max 670.97 / train/extr_critic_mean 600.54 / train/extr_critic_min 402.68 / train/extr_critic_std 76 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.68 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.45 / train/extr_return_raw_max 668.45 / train/extr_return_raw_mean 600.6 / train/extr_return_raw_min 407.41 / train/extr_return_raw_std 76.12 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.02 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.27 / train/image_loss_std 0.4 / train/model_loss_mean 1.44 / train/model_loss_std 2.77 / 
train/model_opt_grad_norm 6.94 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 3.7e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.93 / train/post_ent_max 57.93 / train/post_ent_mean 40.22 / train/post_ent_min 
25.17 / train/post_ent_std 4.16 / train/prior_ent_mag 71.24 / train/prior_ent_max 71.24 / train/prior_ent_mean 41.74 / train/prior_ent_min 31.42 / train/prior_ent_std 5.55 / train/rep_loss_mean 1.85 / train/rep_loss_std 4.12 / train/reward_avg 1.01 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.01 / train/reward_rate 0.51 / 
train_stats/mean_log_entropy 0.65 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 2.34 / report/dyn_loss_std 6.01 / report/image_loss_mean 0.38 / report/image_loss_std 0.62 / report/model_loss_mean 1.83 / report/model_loss_std 4.11 / report/post_ent_mag 55.9 / report/post_ent_max 55.9 / report/post_ent_mean
40.84 / report/post_ent_min 23.7 / report/post_ent_std 4.59 / report/prior_ent_mag 70.82 / report/prior_ent_max 70.82 / report/prior_ent_mean 42.89 / report/prior_ent_min 30.4 / report/prior_ent_std 5.66 / report/rep_loss_mean 2.34 / report/rep_loss_std 6.01 / 
report/reward_avg 0.67 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred
0.66 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 7.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 
/ eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.45 / eval/model_loss_mean 1.22 / eval/model_loss_std 1.85 / eval/post_ent_mag 55.71 / eval/post_ent_max 55.71 / eval/post_ent_mean 38.74 / eval/post_ent_min 30.66 / eval/post_ent_std 3.05 / 
eval/prior_ent_mag 70.82 / eval/prior_ent_max 70.82 / eval/prior_ent_mean 39.95 / eval/prior_ent_min 36.16 / eval/prior_ent_std 5.1 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.6 / eval/reward_avg 1.6 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.4e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.6 / eval/reward_rate 0.8 / replay/size 2.2e5 / replay/inserts 3838 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3838 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.5e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.38 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1919 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.64 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 217500 Counter(217500) 217437
Saved chunk: 20230922T022002F365541-2CsH4DT6qvFde8Jll7Pll0-3kR5VCubYAsmvsdpqlFgvN-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 218000 Counter(218000) 217937
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T022050F334045-0JUS7w84p9CDuqcOiX9jQB-1TuDF0I1J8b9gvIqJJkK5u-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 218500 Counter(218500) 218437
Saved chunk: 20230922T022120F909176-3kR5VCubYAsmvsdpqlFgvN-0G25Cby9Bk208Tkv3QeORM-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 219000 Counter(219000) 218937
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T022210F654912-1TuDF0I1J8b9gvIqJJkK5u-2GET7qfZE0AFoVU2a2J5yz-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 219500 Counter(219500) 219437
Saved chunk: 20230922T022238F902230-0G25Cby9Bk208Tkv3QeORM-7A5UmVdyxwwiIn8eO97PEx-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 220000 Counter(220000) 219937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T022330F077556-2GET7qfZE0AFoVU2a2J5yz-7orEqZA3FVw4fbBbR6nGHu-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T022356F670165-7A5UmVdyxwwiIn8eO97PEx-0000000000000000000000-879.npz
Saved chunk: 20230922T022449F259670-7orEqZA3FVw4fbBbR6nGHu-0000000000000000000000-40.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 220500 Counter(220500) 220437
Saved chunk: 20230922T022356F670165-7A5UmVdyxwwiIn8eO97PEx-1vNNBlJSiRkpXcXsZKR4Ei-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 221000 Counter(221000) 220937
eval_Episode has 500 steps and return 769.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 442098 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / train/action_mag 4.32 / train/action_max 4.17 / train/action_mean 0.07 / train/action_min -4.06 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.64 / train/adv_mag 0.52 / train/adv_max 0.41 / train/adv_mean 2.8e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6.1e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / 
train/dyn_loss_std 4.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.59 / train/extr_critic_max 670.59 / train/extr_critic_mean 600.02 / train/extr_critic_min 406.02 / train/extr_critic_std 76.44 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.68 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.52 / train/extr_return_raw_max 668.52 / train/extr_return_raw_mean 600.08 / train/extr_return_raw_min 407.38 / train/extr_return_raw_std 76.56
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.03 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.4 / train/model_loss_mean 1.43 / train/model_loss_std 2.75 / 
train/model_opt_grad_norm 6.99 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.29 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.29 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 5.7e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 58.24 / train/post_ent_max 58.24 / train/post_ent_mean 40.06 / train/post_ent_min
25.08 / train/post_ent_std 4.18 / train/prior_ent_mag 71.36 / train/prior_ent_max 71.36 / train/prior_ent_mean 41.56 / train/prior_ent_min 31.67 / train/prior_ent_std 5.62 / train/rep_loss_mean 1.84 / train/rep_loss_std 4.08 / train/reward_avg 1.02 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.02 / train/reward_rate 0.51 / 
train_stats/mean_log_entropy 0.68 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6.2e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.28 / report/dyn_loss_std 5.34 / report/image_loss_mean 0.34 / report/image_loss_std 0.51 / report/model_loss_mean 1.75 / report/model_loss_std 3.61 / report/post_ent_mag 52.83 / report/post_ent_max 52.83 / 
report/post_ent_mean 40.53 / report/post_ent_min 21.79 / report/post_ent_std 4.78 / report/prior_ent_mag 70.8 / report/prior_ent_max 70.8 / report/prior_ent_mean 42.53 / report/prior_ent_min 28.18 / report/prior_ent_std 5.68 / report/rep_loss_mean 2.28 / 
report/rep_loss_std 5.34 / report/reward_avg 0.58 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.16 / report/reward_pred 0.58 / report/reward_rate 0.3 / eval/cont_avg 1 / eval/cont_loss_mean 6.1e-11 / eval/cont_loss_std 8.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.52 / eval/dyn_loss_std 2.86 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.82 / eval/post_ent_mag 56.56 / eval/post_ent_max 56.56 / eval/post_ent_mean 39.85 / eval/post_ent_min 31.17 / 
eval/post_ent_std 3.4 / eval/prior_ent_mag 70.8 / eval/prior_ent_max 70.8 / eval/prior_ent_mean 41.04 / eval/prior_ent_min 35.57 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 1.52 / eval/rep_loss_std 2.86 / eval/reward_avg 1.44 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.44 / eval/reward_rate 0.72 / replay/size 2.2e5 / replay/inserts 3838 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3838 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.04 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1919 / timer/agent.train_total 243.48 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / 
timer/dataset_eval_max 3.8e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T022449F259670-7orEqZA3FVw4fbBbR6nGHu-3lda3wQPQJQ3IMLBTD26Gx-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 221500 Counter(221500) 221437
Saved chunk: 20230922T022514F526263-1vNNBlJSiRkpXcXsZKR4Ei-5gnrFcVg2AK2hBuj4vdP6I-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 222000 Counter(222000) 221937
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T022609F460605-3lda3wQPQJQ3IMLBTD26Gx-0bvfCoQNpVzymO5q3h7NVi-1024.npz
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 222500 Counter(222500) 222437
Saved chunk: 20230922T022633F117149-5gnrFcVg2AK2hBuj4vdP6I-0B2gJZLpcLogFKbKEptK51-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 223000 Counter(223000) 222937
eval_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T022728F956766-0bvfCoQNpVzymO5q3h7NVi-2XOcodPgYs45E4cP27JZF5-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 223500 Counter(223500) 223437
Saved chunk: 20230922T022750F994686-0B2gJZLpcLogFKbKEptK51-2zt7sjkWcyT2OyZUoQKELS-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 224000 Counter(224000) 223937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T022848F231677-2XOcodPgYs45E4cP27JZF5-4Gs1Es3YMQUlnrf1jLUQ67-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 224500 Counter(224500) 224437
Saved chunk: 20230922T022908F628199-2zt7sjkWcyT2OyZUoQKELS-5JV2T1kmxGJB1FddB28Z9J-1024.npz
eval_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 449878 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 767 / eval_episode/reward_rate 0.77 / train/action_mag 4.33 / train/action_max 4.22 / train/action_mean 0.07 / train/action_min -4.07 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.48 / train/adv_mag 0.51 / train/adv_max 0.41 / train/adv_mean 3.7e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.85 / 
train/dyn_loss_std 4.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.45 / train/extr_critic_max 670.45 / train/extr_critic_mean 601.44 / train/extr_critic_min 403.6 / train/extr_critic_std 75.72 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.41 / train/extr_return_raw_max 668.41 / train/extr_return_raw_mean 601.52 / train/extr_return_raw_min 408.48 / train/extr_return_raw_std 75.81
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.04 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.39 / train/model_loss_mean 1.44 / train/model_loss_std 2.76 / 
train/model_opt_grad_norm 7.66 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7025.64 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.29 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.81 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.29 / train/policy_logprob_min -8.81 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 6e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.75 / train/post_ent_max 57.75 / train/post_ent_mean 39.87 / train/post_ent_min 
25.15 / train/post_ent_std 4.27 / train/prior_ent_mag 71.17 / train/prior_ent_max 71.17 / train/prior_ent_mean 41.37 / train/prior_ent_min 31.4 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.85 / train/rep_loss_std 4.1 / train/reward_avg 1.02 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.02 / train/reward_rate 0.51 / 
train_stats/mean_log_entropy 0.68 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.3e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.78 / report/image_loss_mean 0.23 / report/image_loss_std 0.35 / report/model_loss_mean 1.36 / report/model_loss_std 2.52 / report/post_ent_mag 56.17 / report/post_ent_max 56.17 / 
report/post_ent_mean 39.62 / report/post_ent_min 16.4 / report/post_ent_std 4.7 / report/prior_ent_mag 71.28 / report/prior_ent_max 71.28 / report/prior_ent_mean 41.12 / report/prior_ent_min 29.57 / report/prior_ent_std 5.93 / report/rep_loss_mean 1.76 / 
report/rep_loss_std 3.78 / report/reward_avg 1.08 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 9.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.09 / report/reward_rate 0.54 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 7.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.67 / eval/dyn_loss_std 3.65 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.29 / eval/model_loss_std 2.38 / eval/post_ent_mag 54.81 / eval/post_ent_max 54.81 / eval/post_ent_mean 38.74 / 
eval/post_ent_min 26.17 / eval/post_ent_std 3.75 / eval/prior_ent_mag 71.28 / eval/prior_ent_max 71.28 / eval/prior_ent_mean 39.95 / eval/prior_ent_min 31.24 / eval/prior_ent_std 5.55 / eval/rep_loss_mean 1.67 / eval/rep_loss_std 3.65 / eval/reward_avg 1.43 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.9e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.43 / eval/reward_rate 0.71 / replay/size
2.2e5 / replay/inserts 3890 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3890 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.59 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.04 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / 
timer/dataset_train_count 1945 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.77 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.93

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 767.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 225000 Counter(225000) 224937
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T023007F450650-4Gs1Es3YMQUlnrf1jLUQ67-1tlTEgyak44YTNNx8YuDF6-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 225500 Counter(225500) 225437
Saved chunk: 20230922T023026F317547-5JV2T1kmxGJB1FddB28Z9J-478XeV2gQZmkHuvzUcAmXH-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 226000 Counter(226000) 225937
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T023127F535599-1tlTEgyak44YTNNx8YuDF6-5496FGphOIOCd1K2hbgfuc-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 226500 Counter(226500) 226437
Saved chunk: 20230922T023144F883393-478XeV2gQZmkHuvzUcAmXH-7fzVMgpzt0M4h0GkyLBNMK-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 227000 Counter(227000) 226937
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T023247F036940-5496FGphOIOCd1K2hbgfuc-6crZe6pTcg3waVwXAI3DHB-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 227500 Counter(227500) 227437
Saved chunk: 20230922T023302F817716-7fzVMgpzt0M4h0GkyLBNMK-2BnQMnvPkqX1fvXlAjAA8H-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 228000 Counter(228000) 227937
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T023406F406532-6crZe6pTcg3waVwXAI3DHB-2OjmBl15yOO91kjULP2Ife-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 228500 Counter(228500) 228437
Saved chunk: 20230922T023420F552635-2BnQMnvPkqX1fvXlAjAA8H-26P6Rq6ZgPJBrzWxk8V8OG-1024.npz
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 457562 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train_stats/mean_log_entropy 0.73 / train/action_mag 4.29 / train/action_max 4.15 / train/action_mean 0.08 / 
train/action_min -4.08 / train/action_std 1.01 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -2.56 / train/adv_mag 0.52 / train/adv_max 0.4 
/ train/adv_mean 1.7e-4 / train/adv_min -0.45 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 6e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6e-11 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 1.86 / train/dyn_loss_std 4.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / 
train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 670.3 / train/extr_critic_max 670.3 / train/extr_critic_mean 601.41 / train/extr_critic_min 403.41 / train/extr_critic_std 75.39 / train/extr_return_normed_mag 
1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.18 / train/extr_return_raw_max 668.18 / 
train/extr_return_raw_mean 601.45 / train/extr_return_raw_min 407.19 / train/extr_return_raw_std 75.56 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.03 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / 
train/image_loss_std 0.4 / train/model_loss_mean 1.44 / train/model_loss_std 2.78 / train/model_opt_grad_norm 6.98 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 7895.57 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5468.75 
/ train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 0.3 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.7 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.3 / 
train/policy_logprob_min -8.7 / train/policy_logprob_std 1.12 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 6.8e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.67 / 
train/post_ent_max 57.67 / train/post_ent_mean 39.93 / train/post_ent_min 24.87 / train/post_ent_std 4.33 / train/prior_ent_mag 71.16 / train/prior_ent_max 71.16 / train/prior_ent_mean 41.44 / train/prior_ent_min 32.1 / train/prior_ent_std 5.74 / train/rep_loss_mean 1.86 
/ train/rep_loss_std 4.12 / train/reward_avg 1.01 / train/reward_loss_mean 0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 /
train/reward_pred 1.01 / train/reward_rate 0.51 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.82 / report/dyn_loss_std 4.08 / report/image_loss_mean 0.29 / report/image_loss_std 0.53 / report/model_loss_mean 1.42 / report/model_loss_std 2.87 / report/post_ent_mag 60.23 / report/post_ent_max 60.23 / 
report/post_ent_mean 40.89 / report/post_ent_min 23.52 / report/post_ent_std 4.52 / report/prior_ent_mag 71.32 / report/prior_ent_max 71.32 / report/prior_ent_mean 42.36 / report/prior_ent_min 30.57 / report/prior_ent_std 5.67 / report/rep_loss_mean 1.82 / 
report/rep_loss_std 4.08 / report/reward_avg 0.75 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.75 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 6.6e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 3.03 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.23 / eval/model_loss_std 2.03 / eval/post_ent_mag 58.44 / eval/post_ent_max 58.44 / eval/post_ent_mean 
39.34 / eval/post_ent_min 25.04 / eval/post_ent_std 3.94 / eval/prior_ent_mag 71.32 / eval/prior_ent_max 71.32 / eval/prior_ent_mean 40.49 / eval/prior_ent_min 35.44 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 3.03 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / 
replay/size 2.3e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3842 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.31 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 16.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 3.7e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.73 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 229000 Counter(229000) 228937
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T023525F564366-2OjmBl15yOO91kjULP2Ife-4D7tcsKa5NZAIKFtRP8C0f-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 229500 Counter(229500) 229437
Saved chunk: 20230922T023538F148500-26P6Rq6ZgPJBrzWxk8V8OG-648dioecZmbDytSNkKfF6q-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 230000 Counter(230000) 229937
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T023645F723935-4D7tcsKa5NZAIKFtRP8C0f-7lpRVrwcuMZecOr9Uj8DKp-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 230500 Counter(230500) 230437
Saved chunk: 20230922T023656F819081-648dioecZmbDytSNkKfF6q-2VlQSy0n47ebBuRktgXmZO-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 231000 Counter(231000) 230937
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T023805F115037-7lpRVrwcuMZecOr9Uj8DKp-02GlK8bLEpa0GeohLPch4N-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 231500 Counter(231500) 231437
Saved chunk: 20230922T023814F638759-2VlQSy0n47ebBuRktgXmZO-4CBievQxFMxe3UHbeKYKMC-1024.npz
eval_Episode has 500 steps and return 769.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T023924F446830-02GlK8bLEpa0GeohLPch4N-0000000000000000000000-376.npz
Saved chunk: 20230922T023932F400890-4CBievQxFMxe3UHbeKYKMC-0000000000000000000000-114.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 232000 Counter(232000) 231937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T023924F446830-02GlK8bLEpa0GeohLPch4N-0u7Rrcg1rMzG27ZnDqSRZI-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 232500 Counter(232500) 232437
Saved chunk: 20230922T023932F400890-4CBievQxFMxe3UHbeKYKMC-583KlMwD2xdr86IrBdBW7u-1024.npz
eval_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 465238 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 766 / eval_episode/reward_rate 0.77 / train/action_mag 4.28 / train/action_max 4.13 / train/action_mean 0.07 / train/action_min -4.07 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.77 / train/adv_mag 0.49 / train/adv_max 0.39 / train/adv_mean 3.9e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / 
train/dyn_loss_std 4.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.35 / train/extr_critic_max 670.35 / train/extr_critic_mean 602.57 / train/extr_critic_min 410.89 / train/extr_critic_std 74.79 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.48 / train/extr_return_raw_max 668.48 / train/extr_return_raw_mean 602.65 / train/extr_return_raw_min 415.2 / train/extr_return_raw_std 74.86 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.05 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.4 / train/model_loss_mean 1.43 / train/model_loss_std 2.76 / 
train/model_opt_grad_norm 7.13 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7135.42 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.31 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.54 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.31 / train/policy_logprob_min -8.54 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 6.5e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.45 / train/post_ent_max 57.45 / train/post_ent_mean 39.7 / train/post_ent_min 
25.52 / train/post_ent_std 4.41 / train/prior_ent_mag 71.14 / train/prior_ent_max 71.14 / train/prior_ent_mean 41.19 / train/prior_ent_min 31.52 / train/prior_ent_std 5.83 / train/rep_loss_mean 1.84 / train/rep_loss_std 4.1 / train/reward_avg 1.04 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.03 / train/reward_rate 0.52 / 
train_stats/mean_log_entropy 0.62 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3e-10 / report/cont_loss_std 8.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-10 / report/cont_pred 1
/ report/cont_rate 1 / report/dyn_loss_mean 2.01 / report/dyn_loss_std 5.21 / report/image_loss_mean 0.34 / report/image_loss_std 0.64 / report/model_loss_mean 1.58 / report/model_loss_std 3.65 / report/post_ent_mag 52.88 / report/post_ent_max 52.88 / report/post_ent_mean
41.13 / report/post_ent_min 22.65 / report/post_ent_std 4.3 / report/prior_ent_mag 71.45 / report/prior_ent_max 71.45 / report/prior_ent_mean 42.8 / report/prior_ent_min 28.63 / report/prior_ent_std 5.49 / report/rep_loss_mean 2.01 / report/rep_loss_std 5.21 / 
report/reward_avg 0.58 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred
0.58 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 6.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.41 
/ eval/dyn_loss_std 2.34 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.1 / eval/model_loss_std 1.54 / eval/post_ent_mag 55.16 / eval/post_ent_max 55.16 / eval/post_ent_mean 36.86 / eval/post_ent_min 31.53 / eval/post_ent_std 3.16 / 
eval/prior_ent_mag 71.45 / eval/prior_ent_max 71.45 / eval/prior_ent_mean 37.89 / eval/prior_ent_min 34.92 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 1.41 / eval/rep_loss_std 2.34 / eval/reward_avg 1.86 / eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.08 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.04 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.86 / eval/reward_rate 0.93 / replay/size 2.3e5 / replay/inserts 3838 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3838 / timer/env.step_total 18.96 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.5e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.55 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.18 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1919 / 
timer/agent.train_total 243.44 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 753.0.
Starting evaluation at step 233000 Counter(233000) 232937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T024043F882733-0u7Rrcg1rMzG27ZnDqSRZI-1Jt97CatnMdbu6a7dTZHVf-1024.npz
Starting evaluation at step 233500 Counter(233500) 233437
Saved chunk: 20230922T024050F278700-583KlMwD2xdr86IrBdBW7u-4Lg8ky43wW1yWDMXkdgwQC-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 234000 Counter(234000) 233937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T024204F259914-1Jt97CatnMdbu6a7dTZHVf-61BSkPy8DvAAcjOdXatoiy-1024.npz
Starting evaluation at step 234500 Counter(234500) 234437
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T024209F095987-4Lg8ky43wW1yWDMXkdgwQC-4VpTJxgr0ftt7P4gOGjZD2-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 235000 Counter(235000) 234937
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 235500 Counter(235500) 235437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T024326F832226-4VpTJxgr0ftt7P4gOGjZD2-4YCjyxOdhKjwMicmBn8AdW-1024.npz
Saved chunk: 20230922T024323F539702-61BSkPy8DvAAcjOdXatoiy-7vFnakjktR3f1OSbNASGua-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 236000 Counter(236000) 235937
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 236500 Counter(236500) 236437
eval_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 473002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 760 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 763 / eval_episode/reward_rate 0.76 / train/action_mag 4.34 / train/action_max 4.12 / train/action_mean 0.06 / train/action_min -4.16 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.27 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 3.4e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / 
train/dyn_loss_std 4.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.48 / train/extr_critic_max 670.48 / train/extr_critic_mean 603.59 / train/extr_critic_min 404.55 / train/extr_critic_std 74.56 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.04 / train/extr_return_raw_max 668.04 / train/extr_return_raw_mean 603.66 / train/extr_return_raw_min 409.09 / train/extr_return_raw_std 74.67
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.06 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.4 / train/model_loss_mean 1.43 / train/model_loss_std 2.76 / 
train/model_opt_grad_norm 7.11 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 9244.04 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6469.07 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.32 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.58 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.32 / train/policy_logprob_min -8.58 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 6.3e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.49 / train/post_ent_max 57.49 / train/post_ent_mean 39.61 / train/post_ent_min
25.1 / train/post_ent_std 4.47 / train/prior_ent_mag 70.93 / train/prior_ent_max 70.93 / train/prior_ent_mean 41.1 / train/prior_ent_min 31.58 / train/prior_ent_std 5.89 / train/rep_loss_mean 1.84 / train/rep_loss_std 4.09 / train/reward_avg 1.04 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.04 / train/reward_rate 0.52 / 
train_stats/mean_log_entropy 0.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / report/cont_pred 1 
/ report/cont_rate 1 / report/dyn_loss_mean 1.81 / report/dyn_loss_std 4.18 / report/image_loss_mean 0.22 / report/image_loss_std 0.26 / report/model_loss_mean 1.4 / report/model_loss_std 2.71 / report/post_ent_mag 56.98 / report/post_ent_max 56.98 / report/post_ent_mean 
39.64 / report/post_ent_min 26.2 / report/post_ent_std 4.53 / report/prior_ent_mag 71.59 / report/prior_ent_max 71.59 / report/prior_ent_mean 41.05 / report/prior_ent_min 31.33 / report/prior_ent_std 6.03 / report/rep_loss_mean 1.81 / report/rep_loss_std 4.18 / 
report/reward_avg 1.06 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.24 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / report/reward_pos_loss 0.15 / 
report/reward_pred 1.07 / report/reward_rate 0.54 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.37 / eval/dyn_loss_std 1.82 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.13 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.18 / eval/post_ent_mag 57.08 / eval/post_ent_max 57.08 / eval/post_ent_mean 36.74 / eval/post_ent_min 30.92 / 
eval/post_ent_std 3.25 / eval/prior_ent_mag 71.59 / eval/prior_ent_max 71.59 / eval/prior_ent_mean 37.69 / eval/prior_ent_min 34.72 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 1.37 / eval/rep_loss_std 1.82 / eval/reward_avg 1.85 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.03 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.85 / eval/reward_rate 0.92 / replay/size 2.4e5 / replay/inserts 3882 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.9 / timer/env.step_count 3882 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.62 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7890 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1941
/ timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1941 / timer/agent.train_total 246.21 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.63

Saved chunk: 20230922T024444F541740-4YCjyxOdhKjwMicmBn8AdW-0uQIHbNItP0UhrvglSxUwR-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T024446F159964-7vFnakjktR3f1OSbNASGua-5eb0xFW94AoiijxSa5MEt9-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 237000 Counter(237000) 236937
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 237500 Counter(237500) 237437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T024606F116362-5eb0xFW94AoiijxSa5MEt9-1AplRlR2jygBYC45MPFVH1-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 238000 Counter(238000) 237937
Saved chunk: 20230922T024602F117351-0uQIHbNItP0UhrvglSxUwR-3lKycekQiPOFYAUQDWvsg2-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 238500 Counter(238500) 238437
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T024725F797668-1AplRlR2jygBYC45MPFVH1-1sgQDBXcBk2HTqk2qm4pMZ-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 239000 Counter(239000) 238937
Saved chunk: 20230922T024756F645982-3lKycekQiPOFYAUQDWvsg2-36lPvt1BgbQsxuJZd5mLUS-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 239500 Counter(239500) 239437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T024845F249075-1sgQDBXcBk2HTqk2qm4pMZ-497Mg3BXTVnSGf8VHUMkmy-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 240000 Counter(240000) 239937
Saved chunk: 20230922T024914F428402-36lPvt1BgbQsxuJZd5mLUS-6Z4N7VJ8Wl4WHId6Ad2332-1024.npz
eval_Episode has 500 steps and return 765.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 480770 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 765 / eval_episode/reward_rate 0.77 / train/action_mag 4.32 / train/action_max 4.16 / train/action_mean 0.06 / train/action_min -4.1 / train/action_std 1.02 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -2.35 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean 1.4e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.4e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.83 / 
train/dyn_loss_std 4.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.2 / train/extr_critic_max 670.2 / train/extr_critic_mean 605.13 / train/extr_critic_min 415.31 / train/extr_critic_std 73.48 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.88 / train/extr_return_raw_max 667.88 / train/extr_return_raw_mean 605.16 / train/extr_return_raw_min 418.14 / train/extr_return_raw_std 73.63
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.07 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.41 / train/model_loss_mean 1.42 / train/model_loss_std 2.76 / 
train/model_opt_grad_norm 7 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7113.4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.33 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.71 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.33 / train/policy_logprob_min -8.71 / train/policy_logprob_std 1.14 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 5.4e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.23 / train/post_ent_max 57.23 / train/post_ent_mean 39.48 / train/post_ent_min 25.11 / train/post_ent_std 4.5 
/ train/prior_ent_mag 71.01 / train/prior_ent_max 71.01 / train/prior_ent_mean 40.96 / train/prior_ent_min 31.65 / train/prior_ent_std 5.92 / train/rep_loss_mean 1.83 / train/rep_loss_std 4.09 / train/reward_avg 1.06 / train/reward_loss_mean 0.07 / train/reward_loss_std 
0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.06 / train/reward_rate 0.53 / train_stats/mean_log_entropy 0.71 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.6 / report/dyn_loss_std 3.29 / report/image_loss_mean 0.21 / report/image_loss_std 0.3 / report/model_loss_mean 1.25 / report/model_loss_std 2.2 / report/post_ent_mag 53.85 / report/post_ent_max 53.85 / report/post_ent_mean 38.73 / 
report/post_ent_min 31.23 / report/post_ent_std 3.61 / report/prior_ent_mag 70.56 / report/prior_ent_max 70.56 / report/prior_ent_mean 39.89 / report/prior_ent_min 31.53 / report/prior_ent_std 5.22 / report/rep_loss_mean 1.6 / report/rep_loss_std 3.29 / report/reward_avg 
1.43 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.43 / 
report/reward_rate 0.72 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / 
eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.74 / eval/post_ent_mag 57.18 / eval/post_ent_max 57.18 / eval/post_ent_mean 37.92 / eval/post_ent_min 31.5 / eval/post_ent_std 3.61 / 
eval/prior_ent_mag 70.56 / eval/prior_ent_max 70.56 / eval/prior_ent_mean 39.07 / eval/prior_ent_min 34.89 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.6 / eval/reward_avg 1.68 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.68 / eval/reward_rate 0.84 / replay/size 2.4e5 / replay/inserts 3884 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3884 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.5e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.48 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.14 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1942 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.59 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 240500 Counter(240500) 240437
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T025004F592539-497Mg3BXTVnSGf8VHUMkmy-2ZSZszejqPtW63AMIuycFj-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 241000 Counter(241000) 240937
Saved chunk: 20230922T025032F190064-6Z4N7VJ8Wl4WHId6Ad2332-0WYHfDE7CbxM2mzWzg5Zek-1024.npz
eval_Episode has 500 steps and return 754.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 241500 Counter(241500) 241437
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T025124F710392-2ZSZszejqPtW63AMIuycFj-27rQAs0nzkyaMEwC34Ivwf-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 242000 Counter(242000) 241937
Saved chunk: 20230922T025150F913253-0WYHfDE7CbxM2mzWzg5Zek-1QzVQlDm51OH3Nr0R7JaqO-1024.npz
eval_Episode has 500 steps and return 759.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 242500 Counter(242500) 242437
eval_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T025244F209787-27rQAs0nzkyaMEwC34Ivwf-0QtOfxMK3AXasEb44Jn7n1-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 243000 Counter(243000) 242937
Saved chunk: 20230922T025308F726789-1QzVQlDm51OH3Nr0R7JaqO-0dskOhMeP71jzdk1puZs8m-1024.npz
eval_Episode has 500 steps and return 769.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T025403F504199-0QtOfxMK3AXasEb44Jn7n1-0000000000000000000000-712.npz
Saved chunk: 20230922T025426F456863-0dskOhMeP71jzdk1puZs8m-0000000000000000000000-373.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 243500 Counter(243500) 243437
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T025403F504199-0QtOfxMK3AXasEb44Jn7n1-4Is5WshFIGZotcRoWT4bhI-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 244000 Counter(244000) 243937
Saved chunk: 20230922T025426F456863-0dskOhMeP71jzdk1puZs8m-5aHx6JiK4gSX6Eu830dTgO-1024.npz
eval_Episode has 500 steps and return 768.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 488442 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 762 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / train/action_mag 4.34 / train/action_max 4.11 / train/action_mean 0.07 / train/action_min -4.17 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.35 / train/adv_mag 0.49 / train/adv_max 0.39 / train/adv_mean 3.5e-4 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.5e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.82 / 
train/dyn_loss_std 4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 670.45 / train/extr_critic_max 670.45 / train/extr_critic_mean 604.32 / train/extr_critic_min 415.48 / train/extr_critic_std 74.04 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.88 / train/extr_return_raw_max 667.88 / train/extr_return_raw_mean 604.39 / train/extr_return_raw_min 417.61 / train/extr_return_raw_std 74.17
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.06 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.38 / train/model_loss_mean 1.41 / train/model_loss_std 2.69 / 
train/model_opt_grad_norm 7.16 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8515.62 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.31 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.31 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 6.1e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.13 / train/post_ent_max 57.13 / train/post_ent_mean 39.53 / train/post_ent_min
25.67 / train/post_ent_std 4.51 / train/prior_ent_mag 70.62 / train/prior_ent_max 70.62 / train/prior_ent_mean 41 / train/prior_ent_min 31.93 / train/prior_ent_std 5.9 / train/rep_loss_mean 1.82 / train/rep_loss_std 4 / train/reward_avg 1.05 / train/reward_loss_mean 0.07 
/ train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.04 / train/reward_rate 0.53 / train_stats/mean_log_entropy 
0.71 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.5e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.5e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.74 / report/dyn_loss_std 3.96 / report/image_loss_mean 0.22 / report/image_loss_std 0.27 / report/model_loss_mean 1.34 / report/model_loss_std 2.56 / report/post_ent_mag 60.41 / report/post_ent_max 60.41 / report/post_ent_mean 39.48 / 
report/post_ent_min 20.92 / report/post_ent_std 4.16 / report/prior_ent_mag 70.47 / report/prior_ent_max 70.47 / report/prior_ent_mean 40.93 / report/prior_ent_min 31.75 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.74 / report/rep_loss_std 3.96 / report/reward_avg 
1.17 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.2e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.17 / 
report/reward_rate 0.59 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / 
eval/dyn_loss_std 2.47 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.69 / eval/post_ent_mag 54.02 / eval/post_ent_max 54.02 / eval/post_ent_mean 37.01 / eval/post_ent_min 29.96 / eval/post_ent_std 3.23 / 
eval/prior_ent_mag 70.47 / eval/prior_ent_max 70.47 / eval/prior_ent_mean 38.12 / eval/prior_ent_min 34.67 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.47 / eval/reward_avg 1.84 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.04 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.84 / eval/reward_rate 0.92 / replay/size 2.4e5 / replay/inserts 3836 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3836 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.03 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.82 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.1 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1918 / 
timer/agent.train_total 243.44 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 244500 Counter(244500) 244437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T025522F995624-4Is5WshFIGZotcRoWT4bhI-42qV4i0Yw1KX9YE4Dbu4QM-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 245000 Counter(245000) 244937
Saved chunk: 20230922T025544F433581-5aHx6JiK4gSX6Eu830dTgO-0M55OUMofE1LqzcOYdE72q-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 245500 Counter(245500) 245437
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T025643F295961-42qV4i0Yw1KX9YE4Dbu4QM-4eBgdtAUsCV9r79ssOYVYD-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 246000 Counter(246000) 245937
Saved chunk: 20230922T025703F284512-0M55OUMofE1LqzcOYdE72q-7HggchafjvDVB06CKNidph-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 246500 Counter(246500) 246437
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T025802F782989-4eBgdtAUsCV9r79ssOYVYD-7pGVSZVb3az0cwW6MyQq3e-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 247000 Counter(247000) 246937
Saved chunk: 20230922T025821F148413-7HggchafjvDVB06CKNidph-7vYKPNvah5wFT3052mPiqj-1024.npz
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 247500 Counter(247500) 247437
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T025922F220882-7pGVSZVb3az0cwW6MyQq3e-5nHXzlTZU7B2sPx4HovUH3-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 248000 Counter(248000) 247937
Saved chunk: 20230922T025938F989476-7vYKPNvah5wFT3052mPiqj-3tG9NOTWBwi6q3rj2HBErN-1024.npz
eval_Episode has 500 steps and return 765.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 496114 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 765 / eval_episode/reward_rate 0.76 / train/action_mag 4.34 / train/action_max 4.15 / train/action_mean 0.06 / train/action_min -4.16 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -3.63 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 2.7e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.2e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.83 / 
train/dyn_loss_std 4.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.32 / train/extr_critic_max 670.32 / train/extr_critic_mean 605.89 / train/extr_critic_min 411.77 / train/extr_critic_std 73.72 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.91 / train/extr_return_raw_max 667.91 / train/extr_return_raw_mean 605.95 / train/extr_return_raw_min 413.05 / train/extr_return_raw_std 73.82
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.08 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.4 / train/model_loss_mean 1.42 / train/model_loss_std 2.74 / 
train/model_opt_grad_norm 7.2 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 9049.42 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6387.43 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.32 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.84 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.32 / train/policy_logprob_min -8.84 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 5.4e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.3 / train/post_ent_max 57.3 / train/post_ent_mean 39.4 / train/post_ent_min 
25.33 / train/post_ent_std 4.52 / train/prior_ent_mag 70.56 / train/prior_ent_max 70.56 / train/prior_ent_mean 40.86 / train/prior_ent_min 31.56 / train/prior_ent_std 5.91 / train/rep_loss_mean 1.83 / train/rep_loss_std 4.06 / train/reward_avg 1.06 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.06 / train/reward_rate 0.54 / 
train_stats/mean_log_entropy 0.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.06 / report/dyn_loss_std 4.92 / report/image_loss_mean 0.29 / report/image_loss_std 0.45 / report/model_loss_mean 1.58 / report/model_loss_std 3.3 / report/post_ent_mag 56.45 / report/post_ent_max 56.45 / 
report/post_ent_mean 39.86 / report/post_ent_min 24.48 / report/post_ent_std 5.19 / report/prior_ent_mag 70.89 / report/prior_ent_max 70.89 / report/prior_ent_mean 41.54 / report/prior_ent_min 27.03 / report/prior_ent_std 6.41 / report/rep_loss_mean 2.06 / 
report/rep_loss_std 4.92 / report/reward_avg 0.74 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.75 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.46 / eval/dyn_loss_std 2.39 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.14 / eval/model_loss_std 1.62 / eval/post_ent_mag 56.81 / eval/post_ent_max 56.81 / eval/post_ent_mean 
37.09 / eval/post_ent_min 32.4 / eval/post_ent_std 3.59 / eval/prior_ent_mag 70.89 / eval/prior_ent_max 70.89 / eval/prior_ent_mean 38.16 / eval/prior_ent_min 34.18 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.39 / eval/reward_avg 1.72 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.72 / eval/reward_rate 0.86 / 
replay/size 2.5e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3836 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.41 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-4 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.65 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 248500 Counter(248500) 248437
eval_Episode has 500 steps and return 542.0.
Saved chunk: 20230922T030041F522931-5nHXzlTZU7B2sPx4HovUH3-2GSCHuplwhRIvcOKvhY8XZ-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 249000 Counter(249000) 248937
Saved chunk: 20230922T030056F714001-3tG9NOTWBwi6q3rj2HBErN-0mup4Qqn91CykV1HMKY6bK-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 249500 Counter(249500) 249437
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T030201F772508-2GSCHuplwhRIvcOKvhY8XZ-5umTENuXJEnGyFdzl5yWYy-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 250000 Counter(250000) 249937
Saved chunk: 20230922T030215F450977-0mup4Qqn91CykV1HMKY6bK-7v64Q2uuOXfkbQJbdNcO6K-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 250500 Counter(250500) 250437
eval_Episode has 500 steps and return 596.0.
Saved chunk: 20230922T030321F183639-5umTENuXJEnGyFdzl5yWYy-10yST2XmKNC690FFl3GzVl-1024.npz
Starting evaluation at step 251000 Counter(251000) 250937
Saved chunk: 20230922T030333F367267-7v64Q2uuOXfkbQJbdNcO6K-1WJ2ezK1WAKTKNoyVdDRUA-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 251500 Counter(251500) 251437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T030440F576918-10yST2XmKNC690FFl3GzVl-37zHaZGn9qoMcRAPQ3N9bj-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 503886 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / train/action_mag 4.33 / train/action_max 4.11 / train/action_mean 0.06 / train/action_min -4.17 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.59 / train/adv_mag 0.51 / train/adv_max 0.43 / train/adv_mean 3.7e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.8e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / 
train/dyn_loss_std 3.97 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.04 / train/extr_critic_max 670.04 / train/extr_critic_mean 604.93 / train/extr_critic_min 396.55 / train/extr_critic_std 74.6 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.14 / train/extr_return_raw_max 668.14 / train/extr_return_raw_mean 605.01 / train/extr_return_raw_min 400.42 / train/extr_return_raw_std 74.73 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.08 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.38 / train/model_loss_mean 1.4 / train/model_loss_std 2.66 / 
train/model_opt_grad_norm 6.84 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8564.1 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.31 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.31 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 5.1e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.07 / train/post_ent_max 57.07 / train/post_ent_mean 39.25 / train/post_ent_min
25.83 / train/post_ent_std 4.55 / train/prior_ent_mag 70.59 / train/prior_ent_max 70.59 / train/prior_ent_mean 40.7 / train/prior_ent_min 31.57 / train/prior_ent_std 5.95 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.97 / train/reward_avg 1.06 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.06 / train/reward_rate 0.53 / 
train_stats/mean_log_entropy 0.67 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.8e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.73 / report/dyn_loss_std 3.93 / report/image_loss_mean 0.22 / report/image_loss_std 0.38 / report/model_loss_mean 1.34 / report/model_loss_std 2.7 / report/post_ent_mag 57.39 / report/post_ent_max 57.39 / 
report/post_ent_mean 38.21 / report/post_ent_min 21.94 / report/post_ent_std 4.47 / report/prior_ent_mag 70.83 / report/prior_ent_max 70.83 / report/prior_ent_mean 39.52 / report/prior_ent_min 32.18 / report/prior_ent_std 6.04 / report/rep_loss_mean 1.73 / 
report/rep_loss_std 3.93 / report/reward_avg 1.26 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.26 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 6.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 3.11 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.03 / eval/post_ent_mag 57.24 / eval/post_ent_max 57.24 / eval/post_ent_mean 38.82 / eval/post_ent_min 30.02 / 
eval/post_ent_std 4.26 / eval/prior_ent_mag 70.83 / eval/prior_ent_max 70.83 / eval/prior_ent_mean 39.99 / eval/prior_ent_min 34.04 / eval/prior_ent_std 5.87 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 3.11 / eval/reward_avg 1.29 / eval/reward_loss_mean 0.07 / 
eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.29 / eval/reward_rate 0.64 / replay/size 2.5e5 / replay/inserts 3886 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3886 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.59 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 
1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.54 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 252000 Counter(252000) 251937
Saved chunk: 20230922T030451F083855-1WJ2ezK1WAKTKNoyVdDRUA-0EAGMRuIkaLlSP0VdFAtPI-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 252500 Counter(252500) 252437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T030559F782429-37zHaZGn9qoMcRAPQ3N9bj-2L9EOD2ul6Xh9FWXIQbjxP-1024.npz
Starting evaluation at step 253000 Counter(253000) 252937
Saved chunk: 20230922T030609F597140-0EAGMRuIkaLlSP0VdFAtPI-1vyT17n2pBR8J2Ya94fgcj-1024.npz
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 253500 Counter(253500) 253437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T030720F402382-2L9EOD2ul6Xh9FWXIQbjxP-3x4RcVx6n8WX4fBkOfNjo7-1024.npz
Starting evaluation at step 254000 Counter(254000) 253937
Saved chunk: 20230922T030727F860556-1vyT17n2pBR8J2Ya94fgcj-5EW4waVNc2XXMGHFjtraIm-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 254500 Counter(254500) 254437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T030839F853343-3x4RcVx6n8WX4fBkOfNjo7-08Fe35ro2xFOAJBO9n3eaw-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 255000 Counter(255000) 254937
Saved chunk: 20230922T030959F232449-08Fe35ro2xFOAJBO9n3eaw-0000000000000000000000-24.npz
Saved chunk: 20230922T030845F728949-5EW4waVNc2XXMGHFjtraIm-0000000000000000000000-632.npz
Saved chunk: 20230922T030845F728949-5EW4waVNc2XXMGHFjtraIm-4OvrzhJWW6fdcem7FN7Fs9-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 255500 Counter(255500) 255437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 511542 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / train/action_mag 4.35 / train/action_max 4.18 / train/action_mean 0.07 / train/action_min -4.17 / train/action_std 1.03 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.24 / train/adv_mag 0.51 / train/adv_max 0.42 / train/adv_mean 3.2e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.77 / train/extr_critic_max 669.77 / train/extr_critic_mean 606.63 / train/extr_critic_min 377.15 / train/extr_critic_std 75.19 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.13 / train/extr_return_raw_max 668.13 / train/extr_return_raw_mean 606.7 / train/extr_return_raw_min 378.75 / train/extr_return_raw_std 75.28 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.11 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.37 / train/model_loss_mean 1.39 / train/model_loss_std 2.65 / 
train/model_opt_grad_norm 6.72 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 9356.46 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6727.75 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.37 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.71 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.37 / train/policy_logprob_min -8.71 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 5.7e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 56.91 / train/post_ent_max 56.91 / train/post_ent_mean 39.14 / train/post_ent_min
25.67 / train/post_ent_std 4.52 / train/prior_ent_mag 70.29 / train/prior_ent_max 70.29 / train/prior_ent_mean 40.56 / train/prior_ent_min 31.73 / train/prior_ent_std 5.92 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.95 / train/reward_avg 1.09 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.09 / train/reward_rate 0.55 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.7 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 3.84 / report/image_loss_mean 0.26 / report/image_loss_std 0.41 / report/model_loss_mean 1.4 / report/model_loss_std 2.69 / report/post_ent_mag 57.57 / report/post_ent_max 57.57 / 
report/post_ent_mean 40.91 / report/post_ent_min 26.08 / report/post_ent_std 4.18 / report/prior_ent_mag 70.12 / report/prior_ent_max 70.12 / report/prior_ent_mean 42.32 / report/prior_ent_min 34.45 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.79 / 
report/rep_loss_std 3.84 / report/reward_avg 0.82 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.21 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.83 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.61 / eval/dyn_loss_std 3.26 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.24 / eval/model_loss_std 2.12 / eval/post_ent_mag 57.57 / eval/post_ent_max 57.57 / eval/post_ent_mean 
37.97 / eval/post_ent_min 29.49 / eval/post_ent_std 4.09 / eval/prior_ent_mag 70.12 / eval/prior_ent_max 70.12 / eval/prior_ent_mean 39.23 / eval/prior_ent_min 34.27 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 1.61 / eval/rep_loss_std 3.26 / eval/reward_avg 1.59 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.59 / eval/reward_rate 0.8 / 
replay/size 2.6e5 / replay/inserts 3828 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3828 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.48 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7836 / timer/agent.policy_total 17.3 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1914 / timer/agent.train_total 243.11 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 256000 Counter(256000) 255937
Saved chunk: 20230922T030959F232449-08Fe35ro2xFOAJBO9n3eaw-42NbAaWu4fz6ISsW06WOF6-1024.npz
Saved chunk: 20230922T031003F872202-4OvrzhJWW6fdcem7FN7Fs9-3QkQMO2py5h8A3ihO3ym3A-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 256500 Counter(256500) 256437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 257000 Counter(257000) 256937
Saved chunk: 20230922T031122F547794-3QkQMO2py5h8A3ihO3ym3A-5halfXFGMkiQRPYAvCvO7h-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T031119F770460-42NbAaWu4fz6ISsW06WOF6-4p7A25oHtpCJdFeCFurdIi-1024.npz
Starting evaluation at step 257500 Counter(257500) 257437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 258000 Counter(258000) 257937
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T031240F566295-5halfXFGMkiQRPYAvCvO7h-2ZD6oNBsbSr9IIm3wKbFkD-1024.npz
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T031242F749500-4p7A25oHtpCJdFeCFurdIi-05AsRSDlsfozCyv2Icedig-1024.npz
Starting evaluation at step 258500 Counter(258500) 258437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 259000 Counter(259000) 258937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T031358F338712-2ZD6oNBsbSr9IIm3wKbFkD-6GEEfp72TnzdL1LJrZvLbS-1024.npz
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T031402F038476-05AsRSDlsfozCyv2Icedig-5GMNMyiBIJvkUuwaIDUYRs-1024.npz
Starting evaluation at step 259500 Counter(259500) 259437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 764.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 519218 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 767 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / train/action_mag 4.36 / train/action_max 4.18 / train/action_mean 0.07 / train/action_min -4.14 / train/action_std 1.03 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.89 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 3.8e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.07 / train/extr_critic_max 670.07 / train/extr_critic_mean 607.62 / train/extr_critic_min 399.95 / train/extr_critic_std 72.78 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.13 / train/extr_return_raw_max 668.13 / train/extr_return_raw_mean 607.7 / train/extr_return_raw_min 401.18 / train/extr_return_raw_std 72.84 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.09 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.38 / train/model_loss_mean 1.39 / train/model_loss_std 2.65 / 
train/model_opt_grad_norm 6.77 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 7950.32 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5729.17 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 56.7 / train/post_ent_max 56.7 / train/post_ent_mean 39.15 / train/post_ent_min 
25.51 / train/post_ent_std 4.58 / train/prior_ent_mag 70.21 / train/prior_ent_max 70.21 / train/prior_ent_mean 40.58 / train/prior_ent_min 31.65 / train/prior_ent_std 5.95 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.95 / train/reward_avg 1.07 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.07 / train/reward_rate 0.54 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.7 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / report/dyn_loss_std 4.07 / report/image_loss_mean 0.26 / report/image_loss_std 0.42 / report/model_loss_mean 1.44 / report/model_loss_std 2.79 / report/post_ent_mag 55.25 / report/post_ent_max 55.25 / 
report/post_ent_mean 39.62 / report/post_ent_min 26.49 / report/post_ent_std 4.05 / report/prior_ent_mag 70.37 / report/prior_ent_max 70.37 / report/prior_ent_mean 41.14 / report/prior_ent_min 34.08 / report/prior_ent_std 5.47 / report/rep_loss_mean 1.84 / 
report/rep_loss_std 4.07 / report/reward_avg 1.13 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 1.12 / report/reward_rate 0.57 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 3.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 3.02 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.95 / eval/post_ent_mag 56.19 / eval/post_ent_max 56.19 / eval/post_ent_mean 
37.57 / eval/post_ent_min 32.03 / eval/post_ent_std 4.28 / eval/prior_ent_mag 70.37 / eval/prior_ent_max 70.37 / eval/prior_ent_mean 38.68 / eval/prior_ent_min 33.88 / eval/prior_ent_std 5.95 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 3.02 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / replay/size 
2.6e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3838 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 7.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.03 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 16.92 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8e-3 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.6e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.72 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 260000 Counter(260000) 259937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T031521F305305-5GMNMyiBIJvkUuwaIDUYRs-019OKKn0g9mxA5VCvfYFeC-1024.npz
Starting evaluation at step 260500 Counter(260500) 260437
Saved chunk: 20230922T031516F062426-6GEEfp72TnzdL1LJrZvLbS-4uIIhOgTMjjqZEkRQ7col9-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 261000 Counter(261000) 260937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T031641F499660-019OKKn0g9mxA5VCvfYFeC-2PPVR0cs8etPShBjVxcz3T-1024.npz
Starting evaluation at step 261500 Counter(261500) 261437
Saved chunk: 20230922T031710F285494-4uIIhOgTMjjqZEkRQ7col9-0vfePUJZ7BPSK2CqEuzZDD-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 262000 Counter(262000) 261937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T031801F002863-2PPVR0cs8etPShBjVxcz3T-7ddw0WZWRM8qah07pJt5MR-1024.npz
Starting evaluation at step 262500 Counter(262500) 262437
Saved chunk: 20230922T031828F082719-0vfePUJZ7BPSK2CqEuzZDD-6pBD2kiBU5AtmVa8p0MdFH-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 263000 Counter(263000) 262937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T031920F241903-7ddw0WZWRM8qah07pJt5MR-4nqm9jFMjiGPLB690ZFLJQ-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 526994 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 761 / episode/reward_rate 0.76 / train/action_mag 4.36 / train/action_max 4.19 / train/action_mean 0.08 / train/action_min -4.17 / train/action_std 1.04 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -1.75 / train/adv_mag 0.48 / train/adv_max 0.4 / train/adv_mean 5.5e-5 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.6e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.33 / train/extr_critic_max 670.33 / train/extr_critic_mean 608.55 / train/extr_critic_min 408.33 / train/extr_critic_std 71.6 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.87 / train/extr_return_raw_max 667.87 / train/extr_return_raw_mean 608.56 / train/extr_return_raw_min 412.63 / train/extr_return_raw_std 71.74
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.11 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.38 / train/model_loss_mean 1.39 / train/model_loss_std 2.64 / 
train/model_opt_grad_norm 6.8 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 9942.21 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7139.18 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.71 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.71 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.62 / train/post_ent_max 56.62 / train/post_ent_mean 39.13 / train/post_ent_min
25.85 / train/post_ent_std 4.56 / train/prior_ent_mag 70.13 / train/prior_ent_max 70.13 / train/prior_ent_mean 40.55 / train/prior_ent_min 31.54 / train/prior_ent_std 5.95 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.93 / train/reward_avg 1.08 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.08 / train/reward_rate 0.55 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.73 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 2.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / report/dyn_loss_std 3.98 / report/image_loss_mean 0.23 / report/image_loss_std 0.35 / report/model_loss_mean 1.38 / report/model_loss_std 2.66 / report/post_ent_mag 51.17 / report/post_ent_max 51.17 / 
report/post_ent_mean 39.15 / report/post_ent_min 27.25 / report/post_ent_std 4.53 / report/prior_ent_mag 70.34 / report/prior_ent_max 70.34 / report/prior_ent_mean 40.56 / report/prior_ent_min 34.03 / report/prior_ent_std 6.01 / report/rep_loss_mean 1.77 / 
report/rep_loss_std 3.98 / report/reward_avg 1.24 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.24 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.52 / eval/dyn_loss_std 2.88 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.18 / eval/model_loss_std 1.88 / eval/post_ent_mag 56.03 / eval/post_ent_max 56.03 / eval/post_ent_mean 
37.59 / eval/post_ent_min 30.91 / eval/post_ent_std 4 / eval/prior_ent_mag 70.34 / eval/prior_ent_max 70.34 / eval/prior_ent_mean 38.75 / eval/prior_ent_min 34.02 / eval/prior_ent_std 5.72 / eval/rep_loss_mean 1.52 / eval/rep_loss_std 2.88 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / replay/size 
2.6e5 / replay/inserts 3888 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3888 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.56 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.6e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7395 / timer/agent.policy_total 16.01 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.4e-3 / 
timer/dataset_train_count 1944 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1944 / timer/agent.train_total 246.61 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.91

Starting evaluation at step 263500 Counter(263500) 263437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T031945F817023-6pBD2kiBU5AtmVa8p0MdFH-0jELiKI4P40frsVHsZ6yxw-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 264000 Counter(264000) 263937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T032039F487065-4nqm9jFMjiGPLB690ZFLJQ-5kMRMxJtIe33p7DyE9bPqU-1024.npz
Starting evaluation at step 264500 Counter(264500) 264437
Saved chunk: 20230922T032104F073916-0jELiKI4P40frsVHsZ6yxw-11ko8vJQe2goCpYfLLJPD4-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 756.0.
Starting evaluation at step 265000 Counter(265000) 264937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T032159F999146-5kMRMxJtIe33p7DyE9bPqU-4055eFITfFGi2ZnHwzuu95-1024.npz
Starting evaluation at step 265500 Counter(265500) 265437
Saved chunk: 20230922T032222F475324-11ko8vJQe2goCpYfLLJPD4-31STzGEIqkj1qo7cJvHkuB-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 266000 Counter(266000) 265937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T032319F510974-4055eFITfFGi2ZnHwzuu95-250R9HBpd46L3yX85h6F4l-1024.npz
Starting evaluation at step 266500 Counter(266500) 266437
Saved chunk: 20230922T032340F442095-31STzGEIqkj1qo7cJvHkuB-6LiEOyUoNKuOy1pkUgIl2d-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T032458F225826-6LiEOyUoNKuOy1pkUgIl2d-0000000000000000000000-368.npz
Saved chunk: 20230922T032438F899380-250R9HBpd46L3yX85h6F4l-0000000000000000000000-360.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 267000 Counter(267000) 266937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T032438F899380-250R9HBpd46L3yX85h6F4l-6RSN4MS2dImw5GqStLi3s1-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 534654 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 761 / episode/reward_rate 0.76 / train/action_mag 4.36 / train/action_max 4.19 / train/action_mean 0.06 / train/action_min -4.2 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -3.67 / train/adv_mag 0.48 / train/adv_max 0.41 / train/adv_mean 2.5e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.5e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.94 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.2 / train/extr_critic_max 670.2 / train/extr_critic_mean 608.84 / train/extr_critic_min 414.32 / train/extr_critic_std 71.83 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.94 / train/extr_return_raw_max 667.94 / train/extr_return_raw_mean 608.89 / train/extr_return_raw_min 417.84 / train/extr_return_raw_std 71.92
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.11 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.37 / train/model_loss_mean 1.38 / train/model_loss_std 2.64 / 
train/model_opt_grad_norm 6.62 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9166.67 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.88 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.88 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.03 / train/post_ent_max 57.03 / train/post_ent_mean 39.09 / train/post_ent_min
25.99 / train/post_ent_std 4.51 / train/prior_ent_mag 70.3 / train/prior_ent_max 70.3 / train/prior_ent_mean 40.5 / train/prior_ent_min 31.51 / train/prior_ent_std 5.94 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.94 / train/reward_avg 1.09 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.09 / train/reward_rate 0.55 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.7 / report/cont_avg 1 / report/cont_loss_mean 5e-11 / report/cont_loss_std 5.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5e-11 / report/cont_pred 1
/ report/cont_rate 1 / report/dyn_loss_mean 1.73 / report/dyn_loss_std 3.97 / report/image_loss_mean 0.23 / report/image_loss_std 0.48 / report/model_loss_mean 1.35 / report/model_loss_std 2.79 / report/post_ent_mag 55.7 / report/post_ent_max 55.7 / report/post_ent_mean 
37.69 / report/post_ent_min 19.07 / report/post_ent_std 4.81 / report/prior_ent_mag 69.94 / report/prior_ent_max 69.94 / report/prior_ent_mean 39.06 / report/prior_ent_min 27.56 / report/prior_ent_std 6.22 / report/rep_loss_mean 1.73 / report/rep_loss_std 3.97 / 
report/reward_avg 1.34 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred
1.34 / report/reward_rate 0.67 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 
/ eval/dyn_loss_std 3.59 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.24 / eval/model_loss_std 2.36 / eval/post_ent_mag 56.56 / eval/post_ent_max 56.56 / eval/post_ent_mean 38.13 / eval/post_ent_min 28.82 / eval/post_ent_std 3.59 / 
eval/prior_ent_mag 69.94 / eval/prior_ent_max 69.94 / eval/prior_ent_mean 39.29 / eval/prior_ent_min 34.13 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.59 / eval/reward_avg 1.58 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.58 / eval/reward_rate 0.79 / replay/size 2.7e5 / replay/inserts 3830 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3830 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.98 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7838 / timer/agent.policy_total 17.66 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.18 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 2.3e-4 / timer/agent.train_count 1915 / 
timer/agent.train_total 242.88 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 267500 Counter(267500) 267437
Saved chunk: 20230922T032458F225826-6LiEOyUoNKuOy1pkUgIl2d-2fWHwGyVIrnUkq29gqe6kC-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 268000 Counter(268000) 267937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T032558F370680-6RSN4MS2dImw5GqStLi3s1-4rZaBd7Mc06BstiQ8f3U68-1024.npz
Starting evaluation at step 268500 Counter(268500) 268437
Saved chunk: 20230922T032617F008630-2fWHwGyVIrnUkq29gqe6kC-3GeZN1LHDZIrFbxO9wLPbB-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 269000 Counter(269000) 268937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T032718F772645-4rZaBd7Mc06BstiQ8f3U68-6ZlyWzmEYgf2eMGwNWJSKf-1024.npz
Starting evaluation at step 269500 Counter(269500) 269437
Saved chunk: 20230922T032735F033237-3GeZN1LHDZIrFbxO9wLPbB-3S3od4U0u0vDnBE67KYuhh-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 270000 Counter(270000) 269937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T032838F087090-6ZlyWzmEYgf2eMGwNWJSKf-0WAXxY8zY3fP66XD7BdCgU-1024.npz
Starting evaluation at step 270500 Counter(270500) 270437
Saved chunk: 20230922T032852F816846-3S3od4U0u0vDnBE67KYuhh-5KYawaJYFswhBTHkkmATvh-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 271000 Counter(271000) 270937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 542334 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / train/action_mag 4.34 / train/action_max 4.16 / train/action_mean 0.06 / train/action_min -4.19 / train/action_std 1.04 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.88 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 3.8e-4 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.11 / train/extr_critic_max 670.11 / train/extr_critic_mean 609.91 / train/extr_critic_min 415.73 / train/extr_critic_std 70.51 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.73 / train/extr_return_raw_max 667.73 / train/extr_return_raw_mean 609.98 / train/extr_return_raw_min 420.56 / train/extr_return_raw_std 70.56
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.12 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.37 / train/model_loss_std 2.6 / 
train/model_opt_grad_norm 6.64 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 7893.12 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5781.25 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.67 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.67 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.63 / train/post_ent_max 56.63 / train/post_ent_mean 39.1 / train/post_ent_min 
25.96 / train/post_ent_std 4.47 / train/prior_ent_mag 70.12 / train/prior_ent_max 70.12 / train/prior_ent_mean 40.5 / train/prior_ent_min 31.71 / train/prior_ent_std 5.87 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.89 / train/reward_avg 1.1 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.1 / train/reward_rate 0.55 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.72 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / report/dyn_loss_std 2.8 / report/image_loss_mean 0.2 / report/image_loss_std 0.19 / report/model_loss_mean 1.23 / report/model_loss_std 1.8 / report/post_ent_mag 60.72 / report/post_ent_max 60.72 / 
report/post_ent_mean 39.4 / report/post_ent_min 28.83 / report/post_ent_std 4.36 / report/prior_ent_mag 70.11 / report/prior_ent_max 70.11 / report/prior_ent_mean 40.65 / report/prior_ent_min 33.73 / report/prior_ent_std 5.72 / report/rep_loss_mean 1.6 / 
report/rep_loss_std 2.8 / report/reward_avg 1.22 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.22 / report/reward_rate 0.61 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 5.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.91 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.18 / eval/model_loss_std 1.9 / eval/post_ent_mag 54.15 / eval/post_ent_max 54.15 / eval/post_ent_mean 38.5 / eval/post_ent_min 29.85 / 
eval/post_ent_std 3.81 / eval/prior_ent_mag 70.11 / eval/prior_ent_max 70.11 / eval/prior_ent_mean 39.65 / eval/prior_ent_min 34.04 / eval/prior_ent_std 5.49 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.91 / eval/reward_avg 1.43 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.43 / eval/reward_rate 0.71 / replay/size 2.7e5 / replay/inserts 3840 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3840 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.68 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.72 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T032957F387108-0WAXxY8zY3fP66XD7BdCgU-7IhafAA30OkoRg3witF9Gn-1024.npz
Starting evaluation at step 271500 Counter(271500) 271437
Saved chunk: 20230922T033010F510212-5KYawaJYFswhBTHkkmATvh-7xxQtL6ZRBlm3pdXEydGZ2-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 272000 Counter(272000) 271937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T033118F724307-7IhafAA30OkoRg3witF9Gn-3wmrteqKphHv2PCprPR1i9-1024.npz
Starting evaluation at step 272500 Counter(272500) 272437
Saved chunk: 20230922T033130F299133-7xxQtL6ZRBlm3pdXEydGZ2-7COONhDEnjrCjbXHys49ye-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 273000 Counter(273000) 272937
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T033238F146752-3wmrteqKphHv2PCprPR1i9-1dWZeuXVBojNHRjdNgZlSO-1024.npz
Starting evaluation at step 273500 Counter(273500) 273437
Saved chunk: 20230922T033248F118419-7COONhDEnjrCjbXHys49ye-4UwKSdKdXn19LNXcyPV4Eu-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 274000 Counter(274000) 273937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T033357F399113-1dWZeuXVBojNHRjdNgZlSO-7m13Uddy004Nm6xSZ1RaYW-1024.npz
Starting evaluation at step 274500 Counter(274500) 274437
Saved chunk: 20230922T033405F871614-4UwKSdKdXn19LNXcyPV4Eu-1DlfkH9QMbWVUUdz79MW8u-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 275000 Counter(275000) 274937
eval_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 550002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 763 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.34 / train/action_max 4.16 / train/action_mean 0.06 / train/action_min -4.17 / train/action_std 1.05 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -2.84 / train/adv_mag 0.48 / train/adv_max 0.38 / train/adv_mean 1.6e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.02 / train/extr_critic_max 670.02 / train/extr_critic_mean 611 / train/extr_critic_min 416.61 / train/extr_critic_std 71.32 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.82 / train/extr_return_raw_max 667.82 / train/extr_return_raw_mean 611.03 / train/extr_return_raw_min 419.54 / train/extr_return_raw_std 71.42
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.14 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.37 / train/model_loss_mean 1.37 / train/model_loss_std 2.61 / 
train/model_opt_grad_norm 6.54 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9843.75 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.45 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.45 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 3.5e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.18 / train/post_ent_max 56.18 / train/post_ent_mean 38.93 / train/post_ent_min
26.01 / train/post_ent_std 4.48 / train/prior_ent_mag 69.92 / train/prior_ent_max 69.92 / train/prior_ent_mean 40.34 / train/prior_ent_min 31.41 / train/prior_ent_std 5.89 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.89 / train/reward_avg 1.12 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.12 / train/reward_rate 0.56 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.7 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.72 / report/image_loss_mean 0.21 / report/image_loss_std 0.25 / report/model_loss_mean 1.31 / report/model_loss_std 2.4 / report/post_ent_mag 52.26 / report/post_ent_max 52.26 / 
report/post_ent_mean 39.01 / report/post_ent_min 25.76 / report/post_ent_std 4.19 / report/prior_ent_mag 69.97 / report/prior_ent_max 69.97 / report/prior_ent_mean 40.37 / report/prior_ent_min 33.75 / report/prior_ent_std 5.52 / report/rep_loss_mean 1.72 / 
report/rep_loss_std 3.72 / report/reward_avg 1.16 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.16 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.55 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.79 / eval/post_ent_mag 52.73 / eval/post_ent_max 52.73 / eval/post_ent_mean 36.95 / 
eval/post_ent_min 29.46 / eval/post_ent_std 3.91 / eval/prior_ent_mag 69.97 / eval/prior_ent_max 69.97 / eval/prior_ent_mean 38.06 / eval/prior_ent_min 33.9 / eval/prior_ent_std 5.51 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.55 / eval/reward_avg 1.62 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.1e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size 
2.7e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.57 / timer/env.step_count 3834 / timer/env.step_total 18.84 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 3.9e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.27 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 16.87 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.16 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.07 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 756.0.
Saved chunk: 20230922T033516F546953-7m13Uddy004Nm6xSZ1RaYW-6bS7zjWUj4mbpLZdLtROtV-1024.npz
Starting evaluation at step 275500 Counter(275500) 275437
Saved chunk: 20230922T033523F427523-1DlfkH9QMbWVUUdz79MW8u-6KaLUUZSrzJosuFrHYfQlj-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 276000 Counter(276000) 275937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T033636F707179-6bS7zjWUj4mbpLZdLtROtV-3lrm1FWuBFiw3dGH8eSzXM-1024.npz
Starting evaluation at step 276500 Counter(276500) 276437
Saved chunk: 20230922T033642F092176-6KaLUUZSrzJosuFrHYfQlj-1zkgEZhUUOXvTpMSf5UAvS-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 277000 Counter(277000) 276937
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 277500 Counter(277500) 277437
Saved chunk: 20230922T033759F966252-1zkgEZhUUOXvTpMSf5UAvS-10faNe52WkNHBWnakscoyG-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T033756F195969-3lrm1FWuBFiw3dGH8eSzXM-4Wy1F21V6DHIZZ2ujZyH0v-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 278000 Counter(278000) 277937
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 766.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T033917F687631-10faNe52WkNHBWnakscoyG-0000000000000000000000-627.npz
Saved chunk: 20230922T033918F862835-4Wy1F21V6DHIZZ2ujZyH0v-0000000000000000000000-696.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 278500 Counter(278500) 278437
Saved chunk: 20230922T033917F687631-10faNe52WkNHBWnakscoyG-7aotsxBxSiZSUdva3vq7Iu-1024.npz
eval_Episode has 500 steps and return 801.0.
Saved chunk: 20230922T033918F862835-4Wy1F21V6DHIZZ2ujZyH0v-274tvLEDn8L2c4wH5Vt8HP-1024.npz
train_Episode has 500 steps and return 759.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 557770 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 759 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 801 / eval_episode/reward_rate 0.8 / train/action_mag 4.33 / train/action_max 4.15 / train/action_mean 0.07 / train/action_min -4.18 / train/action_std 1.03 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -2.11 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 1e-4 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.85 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.03 / train/extr_critic_max 670.03 / train/extr_critic_mean 608.79 / train/extr_critic_min 421.06 / train/extr_critic_std 72.88 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.24 / train/extr_return_raw_max 668.24 / train/extr_return_raw_mean 608.81 / train/extr_return_raw_min 422.17 / train/extr_return_raw_std 73.04
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.13 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.37 / train/model_loss_std 2.58 / 
train/model_opt_grad_norm 6.95 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.38 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.74 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.38 / train/policy_logprob_min -8.74 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 3.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.39 / train/post_ent_max 56.39 / train/post_ent_mean 38.86 / train/post_ent_min 
25.56 / train/post_ent_std 4.47 / train/prior_ent_mag 69.85 / train/prior_ent_max 69.85 / train/prior_ent_mean 40.27 / train/prior_ent_min 31.55 / train/prior_ent_std 5.89 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.85 / train/reward_avg 1.11 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.11 / train/reward_rate 0.56 / 
train_stats/mean_log_entropy 0.59 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.47 / report/image_loss_mean 0.25 / report/image_loss_std 0.42 / report/model_loss_mean 1.33 / report/model_loss_std 2.37 / report/post_ent_mag 55.59 / report/post_ent_max 55.59 / 
report/post_ent_mean 39.13 / report/post_ent_min 25.45 / report/post_ent_std 4.51 / report/prior_ent_mag 69.67 / report/prior_ent_max 69.67 / report/prior_ent_mean 40.56 / report/prior_ent_min 34.09 / report/prior_ent_std 6.19 / report/rep_loss_mean 1.69 / 
report/rep_loss_std 3.47 / report/reward_avg 1.08 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.08 / report/reward_rate 0.54 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 6.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.85 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.82 / eval/post_ent_mag 55.6 / eval/post_ent_max 55.6 / eval/post_ent_mean 
38.05 / eval/post_ent_min 25.07 / eval/post_ent_std 4.08 / eval/prior_ent_mag 69.67 / eval/prior_ent_max 69.67 / eval/prior_ent_mean 39.24 / eval/prior_ent_min 34.1 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.85 / eval/reward_avg 1.39 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.39 / eval/reward_rate 0.7 / replay/size 
2.8e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3884 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.81 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.7e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.2e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.34 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.3 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 279000 Counter(279000) 278937
eval_Episode has 500 steps and return 728.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 279500 Counter(279500) 279437
Saved chunk: 20230922T034035F539665-7aotsxBxSiZSUdva3vq7Iu-2dwxLK4cZeWpfqUSlZT6no-1024.npz
eval_Episode has 500 steps and return 741.0.
Saved chunk: 20230922T034038F254914-274tvLEDn8L2c4wH5Vt8HP-3b5TOk9elP0P6BaikZ9AjQ-1024.npz
train_Episode has 500 steps and return 754.0.
Starting evaluation at step 280000 Counter(280000) 279937
eval_Episode has 500 steps and return 801.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 280500 Counter(280500) 280437
Saved chunk: 20230922T034154F466808-2dwxLK4cZeWpfqUSlZT6no-75zjhk25Yjdq3ym980lJBj-1024.npz
eval_Episode has 500 steps and return 668.0.
train_Episode has 500 steps and return 694.0.
Saved chunk: 20230922T034158F749218-3b5TOk9elP0P6BaikZ9AjQ-28lFRHcNOz9eJX2hIU8cy2-1024.npz
Starting evaluation at step 281000 Counter(281000) 280937
eval_Episode has 500 steps and return 801.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 281500 Counter(281500) 281437
Saved chunk: 20230922T034312F306348-75zjhk25Yjdq3ym980lJBj-7z0pZ0Y5JqXgVzBVaSJnS8-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T034318F121408-28lFRHcNOz9eJX2hIU8cy2-1lNuMv1BxPhZvJw6tbPCFj-1024.npz
Starting evaluation at step 282000 Counter(282000) 281937
eval_Episode has 500 steps and return 724.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 282500 Counter(282500) 282437
eval_Episode has 500 steps and return 725.0.
Saved chunk: 20230922T034430F170858-7z0pZ0Y5JqXgVzBVaSJnS8-2aYN8ThrmtRhYpPZfGLLpE-1024.npz
train_Episode has 500 steps and return 750.0.
Saved chunk: 20230922T034437F553916-1lNuMv1BxPhZvJw6tbPCFj-6aQQYfxKtI3r8tUEK5iJ1S-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 565438 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 725 / eval_episode/reward_rate 0.72 / episode/length 500 / episode/score 750 / episode/reward_rate 0.75 / train/action_mag 4.29 / train/action_max 4.2 / train/action_mean 0.08 / train/action_min -3.79 / train/action_std 0.97 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -6.82 / train/adv_mag 0.46 / train/adv_max 0.36 / train/adv_mean 6.3e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.86 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.33 / train/extr_critic_max 671.33 / train/extr_critic_mean 610.7 / train/extr_critic_min 411.49 / train/extr_critic_std 74.28 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.17 / train/extr_return_raw_max 670.17 / train/extr_return_raw_mean 610.83 / train/extr_return_raw_min 414.23 / train/extr_return_raw_std 74.38
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.15 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.37 / train/model_loss_mean 1.37 / train/model_loss_std 2.59 / 
train/model_opt_grad_norm 6.81 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.2 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.53 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.2 / train/policy_logprob_min -8.53 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.47 / train/policy_randomness_min 3.6e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 56.18 / train/post_ent_max 56.18 / train/post_ent_mean 38.86 / train/post_ent_min
26.2 / train/post_ent_std 4.43 / train/prior_ent_mag 69.69 / train/prior_ent_max 69.69 / train/prior_ent_mean 40.26 / train/prior_ent_min 32.1 / train/prior_ent_std 5.85 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.86 / train/reward_avg 1.13 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.12 / train/reward_rate 0.57 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.1 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.85 / report/dyn_loss_std 3.77 / report/image_loss_mean 0.25 / report/image_loss_std 0.32 / report/model_loss_mean 1.41 / report/model_loss_std 2.51 / report/post_ent_mag 61.68 / report/post_ent_max 61.68 / 
report/post_ent_mean 40.36 / report/post_ent_min 23.14 / report/post_ent_std 3.94 / report/prior_ent_mag 69.5 / report/prior_ent_max 69.5 / report/prior_ent_mean 41.88 / report/prior_ent_min 32.89 / report/prior_ent_std 5.38 / report/rep_loss_mean 1.85 / 
report/rep_loss_std 3.77 / report/reward_avg 0.71 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.71 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 6.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 3.52 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.3 / eval/model_loss_std 2.38 / eval/post_ent_mag 53.74 / eval/post_ent_max 53.74 / eval/post_ent_mean 37.75 / 
eval/post_ent_min 27.42 / eval/post_ent_std 3.47 / eval/prior_ent_mag 69.5 / eval/prior_ent_max 69.5 / eval/prior_ent_mean 39.01 / eval/prior_ent_min 34.34 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 3.52 / eval/reward_avg 1.68 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.18 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.68 / eval/reward_rate 0.84 / replay/size 
2.8e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3834 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.71 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.66 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 283000 Counter(283000) 282937
eval_Episode has 500 steps and return 753.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 283500 Counter(283500) 283437
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T034556F839320-6aQQYfxKtI3r8tUEK5iJ1S-7jFdzvQ5km4T0tDKxq8ib0-1024.npz
Starting evaluation at step 284000 Counter(284000) 283937
Saved chunk: 20230922T034547F913444-2aYN8ThrmtRhYpPZfGLLpE-033XMreCtikOiPVnQyNSmy-1024.npz
eval_Episode has 500 steps and return 734.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 284500 Counter(284500) 284437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T034717F404316-7jFdzvQ5km4T0tDKxq8ib0-0fuT7ZxJVhw7PXDRFSRYfD-1024.npz
Starting evaluation at step 285000 Counter(285000) 284937
Saved chunk: 20230922T034742F407470-033XMreCtikOiPVnQyNSmy-5lUylm9J2ZGeBSjS1Vbaua-1024.npz
eval_Episode has 500 steps and return 644.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 285500 Counter(285500) 285437
eval_Episode has 500 steps and return 775.0.
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T034836F689827-0fuT7ZxJVhw7PXDRFSRYfD-22UH0KXs2JOBVJMysZijaD-1024.npz
Starting evaluation at step 286000 Counter(286000) 285937
Saved chunk: 20230922T034900F155454-5lUylm9J2ZGeBSjS1Vbaua-3wOeXjONA9PfSgi0KnKmkT-1024.npz
eval_Episode has 500 steps and return 705.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 286500 Counter(286500) 286437
eval_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 573114 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 766 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / train/action_mag 4.3 / train/action_max 4.21 / train/action_mean 0.05 / train/action_min -3.95 / train/action_std 1.01 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -3.92 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 3.2e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 674.95 / train/extr_critic_max 674.95 / train/extr_critic_mean 615.38 / train/extr_critic_min 424 / train/extr_critic_std 71.79 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 673.19 / train/extr_return_raw_max 673.19 / train/extr_return_raw_mean 615.45 / train/extr_return_raw_min 426.58 / train/extr_return_raw_std 71.9 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.15 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.36 / train/model_loss_std 2.53 / 
train/model_opt_grad_norm 6.67 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.28 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.62 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.28 / train/policy_logprob_min -8.62 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 2.7e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.4 / train/post_ent_max 56.4 / train/post_ent_mean 38.8 / train/post_ent_min 
26.25 / train/post_ent_std 4.48 / train/prior_ent_mag 69.74 / train/prior_ent_max 69.74 / train/prior_ent_mean 40.18 / train/prior_ent_min 31.87 / train/prior_ent_std 5.89 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.77 / train/reward_avg 1.13 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.13 / train/reward_rate 0.57 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.39 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 6.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 1.87 / report/dyn_loss_std 4.39 / report/image_loss_mean 0.25 / report/image_loss_std 0.43 / report/model_loss_mean 1.43 / report/model_loss_std 2.99 / report/post_ent_mag 60.77 / report/post_ent_max 60.77 / 
report/post_ent_mean 38.82 / report/post_ent_min 13.08 / report/post_ent_std 4.72 / report/prior_ent_mag 69.16 / report/prior_ent_max 69.16 / report/prior_ent_mean 40.3 / report/prior_ent_min 28.03 / report/prior_ent_std 5.97 / report/rep_loss_mean 1.87 / 
report/rep_loss_std 4.39 / report/reward_avg 0.98 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 0.98 / report/reward_rate 0.49 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 3.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.6 / eval/dyn_loss_std 3.53 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.24 / eval/model_loss_std 2.3 / eval/post_ent_mag 54.87 / eval/post_ent_max 54.87 / eval/post_ent_mean 37.93
/ eval/post_ent_min 28.41 / eval/post_ent_std 4.49 / eval/prior_ent_mag 69.16 / eval/prior_ent_max 69.16 / eval/prior_ent_mean 39.13 / eval/prior_ent_min 34.23 / eval/prior_ent_std 5.92 / eval/rep_loss_mean 1.6 / eval/rep_loss_std 3.53 / eval/reward_avg 1.3 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.3 / eval/reward_rate 0.65 / replay/size
2.9e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3838 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.06 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.6e-3 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.76 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 762.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T034955F965605-22UH0KXs2JOBVJMysZijaD-74lPvvVsaL2uS7flUcClMc-1024.npz
Starting evaluation at step 287000 Counter(287000) 286937
Saved chunk: 20230922T035017F841684-3wOeXjONA9PfSgi0KnKmkT-5DWghXbGZmOXvsmcpXFq8P-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 287500 Counter(287500) 287437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T035116F138699-74lPvvVsaL2uS7flUcClMc-5u3hTvJ79bygQN29Z3qOxX-1024.npz
Starting evaluation at step 288000 Counter(288000) 287937
Saved chunk: 20230922T035136F599918-5DWghXbGZmOXvsmcpXFq8P-00RktqKGJTubpbrQjTCPZs-1024.npz
eval_Episode has 500 steps and return 758.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 288500 Counter(288500) 288437
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T035235F731540-5u3hTvJ79bygQN29Z3qOxX-4ldFo6T5fKzUUeqArv7efy-1024.npz
Starting evaluation at step 289000 Counter(289000) 288937
Saved chunk: 20230922T035254F526697-00RktqKGJTubpbrQjTCPZs-1vH8SRHoqN4P2lNW55yRhA-1024.npz
eval_Episode has 500 steps and return 704.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 289500 Counter(289500) 289437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T035355F052780-4ldFo6T5fKzUUeqArv7efy-0RgN4ym3tYVbduGLBwlCxs-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T035514F361067-0RgN4ym3tYVbduGLBwlCxs-0000000000000000000000-8.npz
Saved chunk: 20230922T035412F276620-1vH8SRHoqN4P2lNW55yRhA-0000000000000000000000-886.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 290000 Counter(290000) 289937
Saved chunk: 20230922T035412F276620-1vH8SRHoqN4P2lNW55yRhA-7De3jQCygSpoHpW8uLTT6o-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 601.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 580882 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 601 / episode/reward_rate 0.6 / eval_episode/length 500 / eval_episode/score 766 / eval_episode/reward_rate 0.77 / train/action_mag 4.26 / train/action_max 4.19 / train/action_mean 0.07 / train/action_min -3.86 / train/action_std 0.98 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -0.74 / train/adv_mag 0.51 / train/adv_max 0.39 / train/adv_mean 2.1e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.82 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 674.6 / train/extr_critic_max 674.6 / train/extr_critic_mean 612.91 / train/extr_critic_min 412.94 / train/extr_critic_std 74.57 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 672.9 / train/extr_return_raw_max 672.9 / train/extr_return_raw_mean 612.92 / train/extr_return_raw_min 421.96 / train/extr_return_raw_std 74.74 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.13 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.36 / train/model_loss_std 2.57 / 
train/model_opt_grad_norm 6.71 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 8800.34 / train/model_opt_model_opt_grad_overflow 5.1e-3 / train/model_opt_model_opt_grad_scale 6435.9 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.19 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.19 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.46 / train/policy_randomness_min 1.9e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.17 / train/post_ent_max 56.17 / train/post_ent_mean 38.84 / train/post_ent_min
26.07 / train/post_ent_std 4.44 / train/prior_ent_mag 69.52 / train/prior_ent_max 69.52 / train/prior_ent_mean 40.22 / train/prior_ent_min 31.85 / train/prior_ent_std 5.84 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.82 / train/reward_avg 1.11 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.11 / train/reward_rate 0.56 / 
train_stats/mean_log_entropy -0.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 6.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.81 / report/dyn_loss_std 4.02 / report/image_loss_mean 0.22 / report/image_loss_std 0.35 / report/model_loss_mean 1.38 / report/model_loss_std 2.65 / report/post_ent_mag 54.95 / report/post_ent_max 54.95 / 
report/post_ent_mean 38.01 / report/post_ent_min 25.33 / report/post_ent_std 4.3 / report/prior_ent_mag 69.58 / report/prior_ent_max 69.58 / report/prior_ent_mean 39.48 / report/prior_ent_min 28.03 / report/prior_ent_std 5.97 / report/rep_loss_mean 1.81 / 
report/rep_loss_std 4.02 / report/reward_avg 1.27 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.27 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 5.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.34 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.15 / eval/post_ent_mag 53.71 / eval/post_ent_max 53.71 / eval/post_ent_mean 38.94 / 
eval/post_ent_min 26.39 / eval/post_ent_std 4.14 / eval/prior_ent_mag 69.58 / eval/prior_ent_max 69.58 / eval/prior_ent_mean 40.13 / eval/prior_ent_min 34.38 / eval/prior_ent_std 5.62 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.34 / eval/reward_avg 1.14 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.7e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.13 / eval/reward_rate 0.57 / replay/size
2.9e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3884 / timer/env.step_total 19.2 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.7 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.1 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.55 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.88

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 290500 Counter(290500) 290437
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T035514F361067-0RgN4ym3tYVbduGLBwlCxs-4pHbfkjsTDDX9KPHkv0N1C-1024.npz
Starting evaluation at step 291000 Counter(291000) 290937
Saved chunk: 20230922T035530F198225-7De3jQCygSpoHpW8uLTT6o-5e7dRgosK5MNgNvAVyK2V7-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 291500 Counter(291500) 291437
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T035634F849102-4pHbfkjsTDDX9KPHkv0N1C-6q7SincSu1eKjbgXggAAZU-1024.npz
Starting evaluation at step 292000 Counter(292000) 291937
Saved chunk: 20230922T035649F101080-5e7dRgosK5MNgNvAVyK2V7-0Di7Ux3XaDLLVhl3cUAqlM-1024.npz
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 292500 Counter(292500) 292437
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T035754F363105-6q7SincSu1eKjbgXggAAZU-7KZ4k1mgXHusaMnjAgLnV0-1024.npz
Starting evaluation at step 293000 Counter(293000) 292937
Saved chunk: 20230922T035806F993476-0Di7Ux3XaDLLVhl3cUAqlM-1GWl12ecACel3Kzf89FKxX-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 293500 Counter(293500) 293437
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T035913F791084-7KZ4k1mgXHusaMnjAgLnV0-6eiICzrBnLOs08U7Ot6gOT-1024.npz
Starting evaluation at step 294000 Counter(294000) 293937
Saved chunk: 20230922T035924F783650-1GWl12ecACel3Kzf89FKxX-6LKVqiohXuXyz41j8HeORF-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 588554 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / train/action_mag 4.31 / train/action_max 4.17 / train/action_mean 0.07 / train/action_min -4.03 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -4.7 / train/adv_mag 0.51 / train/adv_max 0.43 / train/adv_mean 4e-4 / train/adv_min -0.42 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.75 / 
train/dyn_loss_std 3.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 674.78 / train/extr_critic_max 674.78 / train/extr_critic_mean 612.4 / train/extr_critic_min 388.1 / train/extr_critic_std 79.48 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 672.82 / train/extr_return_raw_max 672.82 / train/extr_return_raw_mean 612.49 / train/extr_return_raw_min 395.26 / train/extr_return_raw_std 79.59
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.17 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.35 / train/model_loss_mean 1.35 / train/model_loss_std 2.52 / 
train/model_opt_grad_norm 6.27 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8376.96 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.24 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.24 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.49 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.59 / train/post_ent_max 56.59 / train/post_ent_mean 38.7 / train/post_ent_min 
26.26 / train/post_ent_std 4.41 / train/prior_ent_mag 69.54 / train/prior_ent_max 69.54 / train/prior_ent_mean 40.08 / train/prior_ent_min 32.12 / train/prior_ent_std 5.82 / train/rep_loss_mean 1.75 / train/rep_loss_std 3.76 / train/reward_avg 1.15 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.15 / train/reward_rate 0.58 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.37 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / report/dyn_loss_std 3.98 / report/image_loss_mean 0.25 / report/image_loss_std 0.47 / report/model_loss_mean 1.42 / report/model_loss_std 2.73 / report/post_ent_mag 54.86 / report/post_ent_max 54.86 / 
report/post_ent_mean 39.45 / report/post_ent_min 25.52 / report/post_ent_std 4.66 / report/prior_ent_mag 69.61 / report/prior_ent_max 69.61 / report/prior_ent_mean 40.9 / report/prior_ent_min 34.41 / report/prior_ent_std 6.02 / report/rep_loss_mean 1.84 / 
report/rep_loss_std 3.98 / report/reward_avg 1 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.13 / report/reward_pred 1 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / eval/cont_loss_std 3.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.45 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.6 / eval/post_ent_mag 55.82 / eval/post_ent_max 55.82 / eval/post_ent_mean 37.14 / eval/post_ent_min 32.52 / 
eval/post_ent_std 3.38 / eval/prior_ent_mag 69.61 / eval/prior_ent_max 69.61 / eval/prior_ent_mean 38.19 / eval/prior_ent_min 34.41 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.45 / eval/reward_avg 1.66 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.66 / eval/reward_rate 0.83 / replay/size 2.9e5 / replay/inserts 3836 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3836 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.31 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.4e-3 / timer/dataset_train_count 
1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 294500 Counter(294500) 294437
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T040033F086351-6eiICzrBnLOs08U7Ot6gOT-6eCpJMrRkWsIoF8P0DIrd2-1024.npz
Starting evaluation at step 295000 Counter(295000) 294937
Saved chunk: 20230922T040042F529310-6LKVqiohXuXyz41j8HeORF-21oOFj586eeahd10bXkYIg-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 295500 Counter(295500) 295437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T040153F523924-6eCpJMrRkWsIoF8P0DIrd2-5BAoc9ECJfDH96EGcQcNxN-1024.npz
Starting evaluation at step 296000 Counter(296000) 295937
Saved chunk: 20230922T040201F446997-21oOFj586eeahd10bXkYIg-0qpZ8JGIVOgYeoD8bIwLTg-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 296500 Counter(296500) 296437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T040313F007338-5BAoc9ECJfDH96EGcQcNxN-0r2fbKqTsgvqGv2WkRWDoV-1024.npz
Starting evaluation at step 297000 Counter(297000) 296937
Saved chunk: 20230922T040319F332305-0qpZ8JGIVOgYeoD8bIwLTg-3CeFzk94daqvfJA6Z1OrZm-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 297500 Counter(297500) 297437
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T040432F449289-0r2fbKqTsgvqGv2WkRWDoV-5sxRqwbKivhtygfRGg4L2n-1024.npz
Starting evaluation at step 298000 Counter(298000) 297937
Saved chunk: 20230922T040437F241290-3CeFzk94daqvfJA6Z1OrZm-18YozuZtNLz9gZUDT9zLG1-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 596222 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 767 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / train/action_mag 4.2 / train/action_max 4.05 / train/action_mean 0.05 / train/action_min -3.99 / train/action_std 0.96 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -1.5 / train/adv_mag 0.46 / train/adv_max 0.37 / train/adv_mean 1.2e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.75 / 
train/dyn_loss_std 3.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 673.11 / train/extr_critic_max 673.11 / train/extr_critic_mean 615.03 / train/extr_critic_min 427.69 / train/extr_critic_std 69.33 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 671.11 / train/extr_return_raw_max 671.11 / train/extr_return_raw_mean 615.06 / train/extr_return_raw_min 429.42 / train/extr_return_raw_std 69.4 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.13 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.35 / train/model_loss_std 2.56 / 
train/model_opt_grad_norm 6.84 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 9997.31 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.12 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.52 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.12 / train/policy_logprob_min -8.52 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 2.5e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.82 / train/post_ent_max 56.82 / train/post_ent_mean 38.88 / train/post_ent_min
26.07 / train/post_ent_std 4.39 / train/prior_ent_mag 69.69 / train/prior_ent_max 69.69 / train/prior_ent_mean 40.25 / train/prior_ent_min 32.1 / train/prior_ent_std 5.81 / train/rep_loss_mean 1.75 / train/rep_loss_std 3.8 / train/reward_avg 1.1 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.1 / train/reward_rate 0.55 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.46 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 9.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.83 / report/dyn_loss_std 4.44 / report/image_loss_mean 0.26 / report/image_loss_std 0.53 / report/model_loss_mean 1.41 / report/model_loss_std 3.1 / report/post_ent_mag 60.67 / report/post_ent_max 60.67 / 
report/post_ent_mean 38.92 / report/post_ent_min 27.7 / report/post_ent_std 4.76 / report/prior_ent_mag 69.93 / report/prior_ent_max 69.93 / report/prior_ent_mean 40.38 / report/prior_ent_min 33.11 / report/prior_ent_std 6.17 / report/rep_loss_mean 1.83 / 
report/rep_loss_std 4.44 / report/reward_avg 0.93 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.6e-8 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.93 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 5.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.74 / eval/post_ent_mag 54.86 / eval/post_ent_max 54.86 / eval/post_ent_mean 
36.83 / eval/post_ent_min 30.97 / eval/post_ent_std 4.01 / eval/prior_ent_mag 69.93 / eval/prior_ent_max 69.93 / eval/prior_ent_mean 37.92 / eval/prior_ent_min 34.28 / eval/prior_ent_std 5.67 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.6 / eval/reward_avg 1.66 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.66 / eval/reward_rate 0.83 / replay/size 
3e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3834 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.36 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.7 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 298500 Counter(298500) 298437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 299000 Counter(299000) 298937
Saved chunk: 20230922T040554F911837-18YozuZtNLz9gZUDT9zLG1-5yqZ8YnSDQuQoGLN6L5Jgr-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T040551F702795-5sxRqwbKivhtygfRGg4L2n-0pPHOMePindOPyQbbVe0Vj-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 299500 Counter(299500) 299437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 300000 Counter(300000) 299937
Saved chunk: 20230922T040713F772312-5yqZ8YnSDQuQoGLN6L5Jgr-4Xu4o83MhyBKYkk0MAi4wa-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T040715F486564-0pPHOMePindOPyQbbVe0Vj-7LzsCFbCQmWrMN7fGcqEyf-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 300500 Counter(300500) 300437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 301000 Counter(301000) 300937
Saved chunk: 20230922T040831F656754-4Xu4o83MhyBKYkk0MAi4wa-4U5szWPgJOrKxgXSSAriPg-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T040834F917398-7LzsCFbCQmWrMN7fGcqEyf-2hT2QvmS4tDNjhHtS6lPJN-1024.npz
train_Episode has 500 steps and return 766.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T040949F444625-4U5szWPgJOrKxgXSSAriPg-0000000000000000000000-121.npz
Saved chunk: 20230922T040954F245329-2hT2QvmS4tDNjhHtS6lPJN-0000000000000000000000-344.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 301500 Counter(301500) 301437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 603982 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.26 / train/action_max 4.14 / train/action_mean 0.04 / train/action_min -3.98 / train/action_std 0.98 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -0.34 / train/adv_mag 0.53 / train/adv_max 0.41 / train/adv_mean -2e-5 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.75 / 
train/dyn_loss_std 3.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.54 / train/extr_critic_max 672.54 / train/extr_critic_mean 615 / train/extr_critic_min 420.36 / train/extr_critic_std 70.89 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.61 / train/extr_return_raw_max 670.61 / train/extr_return_raw_mean 615 / train/extr_return_raw_min 423.38 / train/extr_return_raw_std 70.98 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.16 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.35 / train/model_loss_std 2.52 / 
train/model_opt_grad_norm 6.68 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 9992.68 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.18 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.57 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.18 / train/policy_logprob_min -8.57 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.46 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.98 / train/post_ent_max 56.98 / train/post_ent_mean 38.73 / train/post_ent_min
26.06 / train/post_ent_std 4.36 / train/prior_ent_mag 69.56 / train/prior_ent_max 69.56 / train/prior_ent_mean 40.1 / train/prior_ent_min 31.89 / train/prior_ent_std 5.79 / train/rep_loss_mean 1.75 / train/rep_loss_std 3.75 / train/reward_avg 1.14 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.14 / train/reward_rate 0.57 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.34 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 4.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 2.71 / report/image_loss_mean 0.18 / report/image_loss_std 0.28 / report/model_loss_mean 1.2 / report/model_loss_std 1.87 / report/post_ent_mag 60.12 / report/post_ent_max 60.12 / 
report/post_ent_mean 37.75 / report/post_ent_min 27.61 / report/post_ent_std 3.82 / report/prior_ent_mag 69.79 / report/prior_ent_max 69.79 / report/prior_ent_mean 38.99 / report/prior_ent_min 28.32 / report/prior_ent_std 5.38 / report/rep_loss_mean 1.54 / 
report/rep_loss_std 2.71 / report/reward_avg 1.54 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.54 / report/reward_rate 0.77 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 4.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.43 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.64 / eval/post_ent_mag 58.09 / eval/post_ent_max 58.09 / eval/post_ent_mean 
38.05 / eval/post_ent_min 30.81 / eval/post_ent_std 3.92 / eval/prior_ent_mag 69.79 / eval/prior_ent_max 69.79 / eval/prior_ent_mean 39.16 / eval/prior_ent_min 34.63 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.43 / eval/reward_avg 1.4 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.4 / eval/reward_rate 0.7 / replay/size 3e5
/ replay/inserts 3880 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3880 / timer/env.step_total 19.15 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 
4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.42 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7387 / timer/agent.policy_total 16.28 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1940 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.3e-4 / 
timer/agent.train_count 1940 / timer/agent.train_total 246.47 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 
4e-5 / fps 25.86

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 302000 Counter(302000) 301937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T040949F444625-4U5szWPgJOrKxgXSSAriPg-54ds1B9jRhqLOUctwVw2tI-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T040954F245329-2hT2QvmS4tDNjhHtS6lPJN-3K1IprE3Ah69tXGH7GvWMF-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 302500 Counter(302500) 302437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 303000 Counter(303000) 302937
Saved chunk: 20230922T041108F340741-54ds1B9jRhqLOUctwVw2tI-0sACfAL6Q0OaV16BYhhF76-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T041114F788806-3K1IprE3Ah69tXGH7GvWMF-7HjH3rWXNlQ3TGwNV635Ss-1024.npz
Starting evaluation at step 303500 Counter(303500) 303437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 304000 Counter(304000) 303937
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T041226F490673-0sACfAL6Q0OaV16BYhhF76-6xi4TRiW6yoHNrhGAjDvg3-1024.npz
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T041234F433139-7HjH3rWXNlQ3TGwNV635Ss-6TJselezTPstcJDa9jWVk3-1024.npz
Starting evaluation at step 304500 Counter(304500) 304437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 305000 Counter(305000) 304937
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T041344F339901-6xi4TRiW6yoHNrhGAjDvg3-3qQxOylXpI2UfWyxqBAX55-1024.npz
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T041353F825455-6TJselezTPstcJDa9jWVk3-5dMDizwLLEsIjMB5bQCCYx-1024.npz
Starting evaluation at step 305500 Counter(305500) 305437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 611650 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.16 / train/action_max 4 / train/action_mean 0.03 / train/action_min -3.92 / train/action_std 0.97 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -2.48 / train/adv_mag 0.46 / train/adv_max 0.36 / train/adv_mean 2.1e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.95 / train/extr_critic_max 671.95 / train/extr_critic_mean 617.09 / train/extr_critic_min 430.99 / train/extr_critic_std 68.02 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.25 / train/extr_return_raw_max 670.25 / train/extr_return_raw_mean 617.13 / train/extr_return_raw_min 430.86 / train/extr_return_raw_std 68.06
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.16 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.23 / train/image_loss_std 0.35 / train/model_loss_mean 1.34 / train/model_loss_std 2.53 / 
train/model_opt_grad_norm 6.66 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.14 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.14 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 56.9 / train/post_ent_max 56.9 / train/post_ent_mean 38.85 / train/post_ent_min 
26.08 / train/post_ent_std 4.34 / train/prior_ent_mag 69.47 / train/prior_ent_max 69.47 / train/prior_ent_mean 40.21 / train/prior_ent_min 32.38 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.77 / train/reward_avg 1.13 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.13 / train/reward_rate 0.57 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.41 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 8.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.81 / report/dyn_loss_std 4.12 / report/image_loss_mean 0.24 / report/image_loss_std 0.38 / report/model_loss_mean 1.41 / report/model_loss_std 2.78 / report/post_ent_mag 58.8 / report/post_ent_max 58.8 / 
report/post_ent_mean 38.63 / report/post_ent_min 25.38 / report/post_ent_std 4.47 / report/prior_ent_mag 69.19 / report/prior_ent_max 69.19 / report/prior_ent_mean 40.05 / report/prior_ent_min 34.49 / report/prior_ent_std 5.87 / report/rep_loss_mean 1.81 / 
report/rep_loss_std 4.12 / report/reward_avg 1.22 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.22 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 5.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.4 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.25 / eval/model_loss_std 2.35 / eval/post_ent_mag 58.28 / eval/post_ent_max 58.28 / eval/post_ent_mean 
38.39 / eval/post_ent_min 28.41 / eval/post_ent_std 3.94 / eval/prior_ent_mag 69.19 / eval/prior_ent_max 69.19 / eval/prior_ent_mean 39.61 / eval/prior_ent_min 34.67 / eval/prior_ent_std 5.56 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.4 / eval/reward_avg 1.25 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.23 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.95 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.25 / eval/reward_rate 0.63 / replay/size
3.1e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3834 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.8 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.3 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 306000 Counter(306000) 305937
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T041502F150912-3qQxOylXpI2UfWyxqBAX55-2AVu2WWbmeDf0qNgZFUQd6-1024.npz
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T041513F146746-5dMDizwLLEsIjMB5bQCCYx-4UGSKpoG7rCEtcLZ9ymV5b-1024.npz
Starting evaluation at step 306500 Counter(306500) 306437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 307000 Counter(307000) 306937
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T041633F412752-4UGSKpoG7rCEtcLZ9ymV5b-1MX6qREXezW0BnBKH7ePYe-1024.npz
Starting evaluation at step 307500 Counter(307500) 307437
Saved chunk: 20230922T041620F771665-2AVu2WWbmeDf0qNgZFUQd6-3xs706i5VYx5eAAMMrzpHx-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 308000 Counter(308000) 307937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T041752F867515-1MX6qREXezW0BnBKH7ePYe-6yzKvonzpFmT2YumbMgcmb-1024.npz
Starting evaluation at step 308500 Counter(308500) 308437
Saved chunk: 20230922T041814F290846-3xs706i5VYx5eAAMMrzpHx-1bt7Hw5w8hrbIzBz3zbTVo-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 659.0.
Starting evaluation at step 309000 Counter(309000) 308937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 693.0.
Saved chunk: 20230922T041912F153580-6yzKvonzpFmT2YumbMgcmb-7zfuw1jj36UXjFhDiwwsJ9-1024.npz
Starting evaluation at step 309500 Counter(309500) 309437
Saved chunk: 20230922T041931F923195-1bt7Hw5w8hrbIzBz3zbTVo-1KlraMCh2ihpiQWlLpfDse-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 752.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 619326 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 752 / episode/reward_rate 0.75 / train/action_mag 4.21 / train/action_max 4.07 / train/action_mean 0.03 / train/action_min -4 / train/action_std 0.99 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -1.15 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 4.7e-5 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.7 / train/extr_critic_max 671.7 / train/extr_critic_mean 616.4 / train/extr_critic_min 433.82 / train/extr_critic_std 68.6 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.66 / train/extr_return_raw_max 669.66 / train/extr_return_raw_mean 616.41 / train/extr_return_raw_min 434.7 / train/extr_return_raw_std 68.69 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.19 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.35 / train/model_loss_mean 1.33 / train/model_loss_std 2.45 / 
train/model_opt_grad_norm 6.67 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.24 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.24 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.49 / train/policy_randomness_min 2.7e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.45 / train/post_ent_max 57.45 / train/post_ent_mean 38.61 / train/post_ent_min
26.24 / train/post_ent_std 4.29 / train/prior_ent_mag 69.2 / train/prior_ent_max 69.2 / train/prior_ent_mean 39.95 / train/prior_ent_min 32.03 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.66 / train/reward_avg 1.16 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.16 / train/reward_rate 0.58 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.43 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.8 / report/dyn_loss_std 3.85 / report/image_loss_mean 0.24 / report/image_loss_std 0.36 / report/model_loss_mean 1.4 / report/model_loss_std 2.6 / report/post_ent_mag 56.2 / report/post_ent_max 56.2 / 
report/post_ent_mean 38.88 / report/post_ent_min 29.75 / report/post_ent_std 4.15 / report/prior_ent_mag 68.98 / report/prior_ent_max 68.98 / report/prior_ent_mean 40.23 / report/prior_ent_min 34.56 / report/prior_ent_std 5.68 / report/rep_loss_mean 1.8 / 
report/rep_loss_std 3.85 / report/reward_avg 1.24 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.24 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 5.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.91 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.91 / eval/post_ent_mag 55.65 / eval/post_ent_max 55.65 / eval/post_ent_mean 
38.01 / eval/post_ent_min 30.25 / eval/post_ent_std 3.67 / eval/prior_ent_mag 68.98 / eval/prior_ent_max 68.98 / eval/prior_ent_mean 39.13 / eval/prior_ent_min 34.58 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.91 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / replay/size 
3.1e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3838 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.88 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.7 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 310000 Counter(310000) 309937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T042031F471353-7zfuw1jj36UXjFhDiwwsJ9-60jRRK7U2TCnaY1fn8jwwF-1024.npz
Starting evaluation at step 310500 Counter(310500) 310437
Saved chunk: 20230922T042049F655817-1KlraMCh2ihpiQWlLpfDse-30zmDj8aWXxwFKYFLxxcUu-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 311000 Counter(311000) 310937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T042151F809602-60jRRK7U2TCnaY1fn8jwwF-6zQzIVx4GBQIg2Ycsc1wNk-1024.npz
Starting evaluation at step 311500 Counter(311500) 311437
Saved chunk: 20230922T042208F539496-30zmDj8aWXxwFKYFLxxcUu-0U3fNUZn1BkvloKid3yIOV-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 312000 Counter(312000) 311937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 754.0.
Saved chunk: 20230922T042311F188171-6zQzIVx4GBQIg2Ycsc1wNk-1jjXpHNH3HlHEYKqcWjxS9-1024.npz
Starting evaluation at step 312500 Counter(312500) 312437
Saved chunk: 20230922T042326F322896-0U3fNUZn1BkvloKid3yIOV-6DGWkjZJXxbhNMgQlsFle8-1024.npz
eval_Episode has 500 steps and return 497.0.
train_Episode has 500 steps and return 487.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 313000 Counter(313000) 312937
Saved chunk: 20230922T042443F878370-6DGWkjZJXxbhNMgQlsFle8-0000000000000000000000-380.npz
Saved chunk: 20230922T042430F335918-1jjXpHNH3HlHEYKqcWjxS9-0000000000000000000000-680.npz
eval_Episode has 500 steps and return 769.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T042430F335918-1jjXpHNH3HlHEYKqcWjxS9-2KAYhPPffKCp2IuYMgZHTd-1024.npz
Starting evaluation at step 313500 Counter(313500) 313437
Saved chunk: 20230922T042443F878370-6DGWkjZJXxbhNMgQlsFle8-2JRampMKBzh3mNOYukhNiW-1024.npz
eval_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 627002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / train/action_mag 4.22 / train/action_max 4.04 / train/action_mean 0.05 / train/action_min -4 / train/action_std 0.98 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -1.81 / train/adv_mag 0.47 / train/adv_max 0.36 / train/adv_mean 1.3e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.56 / train/extr_critic_max 671.56 / train/extr_critic_mean 614.64 / train/extr_critic_min 427.81 / train/extr_critic_std 69.96 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.9 / train/extr_return_raw_max 669.9 / train/extr_return_raw_mean 614.66 / train/extr_return_raw_min 429.21 / train/extr_return_raw_std 70.07 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.16 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.22 / train/image_loss_std 0.35 / train/model_loss_mean 1.34 / train/model_loss_std 2.48 / 
train/model_opt_grad_norm 6.88 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.19 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.52 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.19 / train/policy_logprob_min -8.52 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.47 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.44 / train/post_ent_max 57.44 / train/post_ent_mean 38.77 / train/post_ent_min
26.13 / train/post_ent_std 4.31 / train/prior_ent_mag 69.36 / train/prior_ent_max 69.36 / train/prior_ent_mean 40.11 / train/prior_ent_min 31.82 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.7 / train/reward_avg 1.14 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.13 / train/reward_rate 0.57 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.35 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.36 / report/image_loss_mean 0.22 / report/image_loss_std 0.29 / report/model_loss_mean 1.31 / report/model_loss_std 2.26 / report/post_ent_mag 58.47 / report/post_ent_max 58.47 / 
report/post_ent_mean 39.47 / report/post_ent_min 21.56 / report/post_ent_std 4.28 / report/prior_ent_mag 69.36 / report/prior_ent_max 69.36 / report/prior_ent_mean 40.78 / report/prior_ent_min 34.54 / report/prior_ent_std 5.78 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.36 / report/reward_avg 1.16 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.23 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 8.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.16 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 3.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 3.36 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.33 / eval/model_loss_std 2.32 / eval/post_ent_mag 55.6 / eval/post_ent_max 55.6 / eval/post_ent_mean 
37.81 / eval/post_ent_min 31.42 / eval/post_ent_std 3.63 / eval/prior_ent_mag 69.36 / eval/prior_ent_max 69.36 / eval/prior_ent_mean 39.09 / eval/prior_ent_min 34.61 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 3.36 / eval/reward_avg 1.47 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.19 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.95 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.47 / eval/reward_rate 0.74 / 
replay/size 3.1e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3838 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.46 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.35 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.29 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 314000 Counter(314000) 313937
eval_Episode has 500 steps and return 270.0.
train_Episode has 500 steps and return 739.0.
Saved chunk: 20230922T042549F754780-2KAYhPPffKCp2IuYMgZHTd-7kr3VWNdp14cfQhFbqOcj1-1024.npz
Starting evaluation at step 314500 Counter(314500) 314437
Saved chunk: 20230922T042601F726046-2JRampMKBzh3mNOYukhNiW-3oPmNi1y6fXojh5NvvyRzp-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 315000 Counter(315000) 314937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T042710F127543-7kr3VWNdp14cfQhFbqOcj1-7gi6TTiurgWS8WbaHxikFC-1024.npz
Starting evaluation at step 315500 Counter(315500) 315437
Saved chunk: 20230922T042720F613390-3oPmNi1y6fXojh5NvvyRzp-3XeKlYIjTzvVC8OfbDzPgQ-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 316000 Counter(316000) 315937
eval_Episode has 500 steps and return 554.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T042829F464919-7gi6TTiurgWS8WbaHxikFC-5pIdGifH9WD0npUklyEtNL-1024.npz
Starting evaluation at step 316500 Counter(316500) 316437
Saved chunk: 20230922T042838F403750-3XeKlYIjTzvVC8OfbDzPgQ-07tSMF1HFXraAbqsIQx1NM-1024.npz
eval_Episode has 500 steps and return 424.0.
train_Episode has 500 steps and return 712.0.
Starting evaluation at step 317000 Counter(317000) 316937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 768.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 634774 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.28 / train/action_max 4.07 / train/action_mean 0.04 / train/action_min -4.1 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -1.4 / train/adv_mag 0.46 / train/adv_max 0.36 / train/adv_mean 5.9e-5 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / 
train/dyn_loss_std 3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.11 / train/extr_critic_max 671.11 / train/extr_critic_mean 617.61 / train/extr_critic_min 436.67 / train/extr_critic_std 67.13 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.21 / train/extr_return_raw_max 669.21 / train/extr_return_raw_mean 617.62 / train/extr_return_raw_min 434.6 / train/extr_return_raw_std 67.19 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.18 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.22 / train/image_loss_std 0.34 / train/model_loss_mean 1.33 / train/model_loss_std 2.44 / 
train/model_opt_grad_norm 6.34 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 9859.14 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.28 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.28 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.71 / train/post_ent_max 57.71 / train/post_ent_mean 38.75 / train/post_ent_min
26.98 / train/post_ent_std 4.24 / train/prior_ent_mag 69.36 / train/prior_ent_max 69.36 / train/prior_ent_mean 40.07 / train/prior_ent_min 32.67 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.65 / train/reward_avg 1.16 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.16 / train/reward_rate 0.58 / 
train_stats/mean_log_entropy -0.35 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 4.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / report/dyn_loss_std 3.19 / report/image_loss_mean 0.19 / report/image_loss_std 0.39 / report/model_loss_mean 1.24 / report/model_loss_std 2.22 / report/post_ent_mag 52.05 / report/post_ent_max 52.05 / 
report/post_ent_mean 37.85 / report/post_ent_min 28.05 / report/post_ent_std 3.89 / report/prior_ent_mag 69.63 / report/prior_ent_max 69.63 / report/prior_ent_mean 39.13 / report/prior_ent_min 34.17 / report/prior_ent_std 5.59 / report/rep_loss_mean 1.6 / 
report/rep_loss_std 3.19 / report/reward_avg 1.44 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.45 / report/reward_rate 0.72 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 3.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.92 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.18 / eval/model_loss_std 1.97 / eval/post_ent_mag 58.25 / eval/post_ent_max 58.25 / eval/post_ent_mean 38.12 / 
eval/post_ent_min 30.85 / eval/post_ent_std 4.2 / eval/prior_ent_mag 69.63 / eval/prior_ent_max 69.63 / eval/prior_ent_mean 39.36 / eval/prior_ent_min 34.59 / eval/prior_ent_std 5.88 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.92 / eval/reward_avg 1.32 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 1.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.31 / eval/reward_rate 0.66 / 
replay/size 3.2e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3886 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 8.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.9 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.1e-4 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.12 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.57 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T042948F758347-5pIdGifH9WD0npUklyEtNL-0DfwoHMHGm3fyXPPIbEAJ5-1024.npz
Starting evaluation at step 317500 Counter(317500) 317437
Saved chunk: 20230922T042956F108279-07tSMF1HFXraAbqsIQx1NM-0l3NNKKyUyAcGXtk2OgDkU-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 318000 Counter(318000) 317937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T043108F838224-0DfwoHMHGm3fyXPPIbEAJ5-6cEkSSIFe7G7Mrx12petvv-1024.npz
Starting evaluation at step 318500 Counter(318500) 318437
Saved chunk: 20230922T043114F690989-0l3NNKKyUyAcGXtk2OgDkU-35URTwmGHZQhdOnatXwVA1-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 319000 Counter(319000) 318937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T043228F490836-6cEkSSIFe7G7Mrx12petvv-0WHOeuyyIyTwbclYU4nSvc-1024.npz
Starting evaluation at step 319500 Counter(319500) 319437
Saved chunk: 20230922T043232F720354-35URTwmGHZQhdOnatXwVA1-0qhwxecKO9vXprZqAQVIGG-1024.npz
eval_Episode has 500 steps and return 474.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 320000 Counter(320000) 319937
eval_Episode has 500 steps and return 381.0.
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 320500 Counter(320500) 320437
Saved chunk: 20230922T043350F553318-0qhwxecKO9vXprZqAQVIGG-131hDIYohyojARJMZvkiLF-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T043347F873882-0WHOeuyyIyTwbclYU4nSvc-1uzI0pE4DSVOOQZAk9Lwc8-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 321000 Counter(321000) 320937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 642454 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.3 / train/action_max 4.05 / train/action_mean 0.04 / train/action_min -4.2 / train/action_std 1.03 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -0.79 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean -2.5e-5 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.13 / train/extr_critic_max 670.13 / train/extr_critic_mean 615.87 / train/extr_critic_min 431.64 / train/extr_critic_std 68.01 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.23 / train/extr_return_raw_max 668.23 / train/extr_return_raw_mean 615.86 / train/extr_return_raw_min 430.89 / train/extr_return_raw_std 68.11
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.18 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.35 / train/model_loss_mean 1.33 / train/model_loss_std 2.46 / 
train/model_opt_grad_norm 6.76 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.36 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.36 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 58.18 / train/post_ent_max 58.18 / train/post_ent_mean 38.67 / train/post_ent_min
26.37 / train/post_ent_std 4.2 / train/prior_ent_mag 69.12 / train/prior_ent_max 69.12 / train/prior_ent_mean 40.01 / train/prior_ent_min 32.23 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.66 / train/reward_avg 1.16 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.16 / train/reward_rate 0.58 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.07 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.81 / report/image_loss_mean 0.19 / report/image_loss_std 0.26 / report/model_loss_mean 1.31 / report/model_loss_std 2.5 / report/post_ent_mag 52.03 / report/post_ent_max 52.03 / 
report/post_ent_mean 38.45 / report/post_ent_min 30.71 / report/post_ent_std 3.73 / report/prior_ent_mag 69.18 / report/prior_ent_max 69.18 / report/prior_ent_mean 39.61 / report/prior_ent_min 34.62 / report/prior_ent_std 5.31 / report/rep_loss_mean 1.7 / 
report/rep_loss_std 3.81 / report/reward_avg 1.43 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.03 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.43 / report/reward_rate 0.72 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 4.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.73 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.77 / eval/post_ent_mag 57.85 / eval/post_ent_max 57.85 / eval/post_ent_mean 
37.6 / eval/post_ent_min 27.57 / eval/post_ent_std 3.82 / eval/prior_ent_mag 69.18 / eval/prior_ent_max 69.18 / eval/prior_ent_mean 38.76 / eval/prior_ent_min 34.65 / eval/prior_ent_std 5.48 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.73 / eval/reward_avg 1.49 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / replay/size 
3.2e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3840 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.33 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.63 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 321500 Counter(321500) 321437
Saved chunk: 20230922T043508F267267-131hDIYohyojARJMZvkiLF-7f5gnrcsGHGTP8pinJBMBz-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T043510F503146-1uzI0pE4DSVOOQZAk9Lwc8-7D8nlxezK4JAdtx1hAJyTq-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 322000 Counter(322000) 321937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 322500 Counter(322500) 322437
Saved chunk: 20230922T043626F857381-7f5gnrcsGHGTP8pinJBMBz-3Oj9hAt28aBVNhM43rMJkm-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T043630F661726-7D8nlxezK4JAdtx1hAJyTq-4kmpb508G8vyn1ponsjRvk-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 323000 Counter(323000) 322937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 323500 Counter(323500) 323437
Saved chunk: 20230922T043744F811845-3Oj9hAt28aBVNhM43rMJkm-15EGPjLhxgV9ubA8DKx0wB-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T043750F156464-4kmpb508G8vyn1ponsjRvk-1W2nG8XT4TZpvLW0ZWcnWn-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 324000 Counter(324000) 323937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 324500 Counter(324500) 324437
Saved chunk: 20230922T043902F573494-15EGPjLhxgV9ubA8DKx0wB-69mZA8RzLPhk2IbfH5RCpO-1024.npz
eval_Episode has 500 steps and return 768.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T044020F334010-69mZA8RzLPhk2IbfH5RCpO-0000000000000000000000-116.npz
Saved chunk: 20230922T043909F489524-1W2nG8XT4TZpvLW0ZWcnWn-0000000000000000000000-1016.npz
Saved chunk: 20230922T043909F489524-1W2nG8XT4TZpvLW0ZWcnWn-7rEzWlfG2fmMzOmmdO471I-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 325000 Counter(325000) 324937
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 650124 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / train/action_mag 4.44 / train/action_max 4.18 / train/action_mean 0.04 / train/action_min -4.35 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -1.62 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean 2.3e-5 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / 
train/dyn_loss_std 3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.95 / train/extr_critic_max 669.95 / train/extr_critic_mean 615.52 / train/extr_critic_min 431.26 / train/extr_critic_std 67.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.7 / train/extr_return_raw_max 667.7 / train/extr_return_raw_mean 615.52 / train/extr_return_raw_min 431.67 / train/extr_return_raw_std 68.04 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.19 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.35 / train/model_loss_mean 1.32 / train/model_loss_std 2.45 / 
train/model_opt_grad_norm 6.29 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 9768.11 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.9 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.9 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 2.2e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 58.05 / train/post_ent_max 58.05 / train/post_ent_mean 38.67 / train/post_ent_min 
26.57 / train/post_ent_std 4.19 / train/prior_ent_mag 69.12 / train/prior_ent_max 69.12 / train/prior_ent_mean 40 / train/prior_ent_min 32.09 / train/prior_ent_std 5.63 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.65 / train/reward_avg 1.16 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.16 / train/reward_rate 0.58 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.82 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 6.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 2.71 / report/image_loss_mean 0.15 / report/image_loss_std 0.19 / report/model_loss_mean 1.18 / report/model_loss_std 1.85 / report/post_ent_mag 50.79 / report/post_ent_max 50.79 / 
report/post_ent_mean 37.15 / report/post_ent_min 30.68 / report/post_ent_std 3.3 / report/prior_ent_mag 69.05 / report/prior_ent_max 69.05 / report/prior_ent_mean 38.35 / report/prior_ent_min 34.69 / report/prior_ent_std 5.18 / report/rep_loss_mean 1.53 / 
report/rep_loss_std 2.71 / report/reward_avg 1.73 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.23 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.97 / report/reward_neg_loss 0.06 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.73 / report/reward_rate 0.87 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.6 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.24 / eval/model_loss_std 1.77 / eval/post_ent_mag 57.32 / eval/post_ent_max 57.32 / eval/post_ent_mean 
38.52 / eval/post_ent_min 31.6 / eval/post_ent_std 4.03 / eval/prior_ent_mag 69.05 / eval/prior_ent_max 69.05 / eval/prior_ent_mean 39.85 / eval/prior_ent_min 34.65 / eval/prior_ent_std 5.63 / eval/rep_loss_mean 1.6 / eval/rep_loss_std 2.75 / eval/reward_avg 1.25 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.25 / eval/reward_rate 0.63 / replay/size 
3.2e5 / replay/inserts 3835 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3835 / timer/env.step_total 18.87 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.36 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7843 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.45 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.4e-8 / timer/dataset_eval_avg 2.8e-5 / 
timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 325500 Counter(325500) 325437
Saved chunk: 20230922T044020F334010-69mZA8RzLPhk2IbfH5RCpO-21a4QfCQyIP4ByoC7f2aj6-1024.npz
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T044028F876690-7rEzWlfG2fmMzOmmdO471I-0JJYLuR2nhz3vjF1G1tFwl-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 326000 Counter(326000) 325937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 326500 Counter(326500) 326437
Saved chunk: 20230922T044139F235794-21a4QfCQyIP4ByoC7f2aj6-1Cbh9DGO6TUbjMcbLvjq4R-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T044149F323219-0JJYLuR2nhz3vjF1G1tFwl-2P9X0ZPWLq5jXu0X8pdLDf-1024.npz
Starting evaluation at step 327000 Counter(327000) 326937
eval_Episode has 500 steps and return 748.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 327500 Counter(327500) 327437
Saved chunk: 20230922T044257F155966-1Cbh9DGO6TUbjMcbLvjq4R-6UqCnYrgFcxAEGvc2S4iSL-1024.npz
eval_Episode has 500 steps and return 755.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T044308F741627-2P9X0ZPWLq5jXu0X8pdLDf-7KyluCGeeqeXjazwDSR9fQ-1024.npz
Starting evaluation at step 328000 Counter(328000) 327937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 328500 Counter(328500) 328437
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T044414F999802-6UqCnYrgFcxAEGvc2S4iSL-4NPyimhvPiWeo3PozqI94n-1024.npz
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T044428F093531-7KyluCGeeqeXjazwDSR9fQ-6LbfCGcXEjQZNWLk6mZhwd-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 657890 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.42 / train/action_max 4.2 / train/action_mean 0.06 / train/action_min -4.29 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -2.51 / train/adv_mag 0.48 / train/adv_max 0.36 / train/adv_mean 1.3e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.5 / train/extr_critic_max 669.5 / train/extr_critic_mean 615.28 / train/extr_critic_min 436.58 / train/extr_critic_std 67.52 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.43 / train/extr_return_raw_max 667.43 / train/extr_return_raw_mean 615.3 / train/extr_return_raw_min 435.87 / train/extr_return_raw_std 67.62 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.18 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.33 / train/model_loss_mean 1.31 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 6.47 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.92 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.92 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.41 / train/post_ent_mag 57.35 / train/post_ent_max 57.35 / train/post_ent_mean 38.62 / train/post_ent_min
26.39 / train/post_ent_std 4.19 / train/prior_ent_mag 68.98 / train/prior_ent_max 68.98 / train/prior_ent_mean 39.93 / train/prior_ent_min 32.05 / train/prior_ent_std 5.61 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.6 / train/reward_avg 1.15 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.15 / train/reward_rate 0.58 / 
train_stats/mean_log_entropy 0.8 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 /
report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.17 / report/image_loss_mean 0.18 / report/image_loss_std 0.44 / report/model_loss_mean 1.25 / report/model_loss_std 2.26 / report/post_ent_mag 53.56 / report/post_ent_max 53.56 / report/post_ent_mean 
36.63 / report/post_ent_min 27.29 / report/post_ent_std 3.28 / report/prior_ent_mag 68.62 / report/prior_ent_max 68.62 / report/prior_ent_mean 37.89 / report/prior_ent_min 28.65 / report/prior_ent_std 5.2 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.17 / 
report/reward_avg 1.6 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 
1.6 / report/reward_rate 0.8 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-11 / eval/cont_loss_std 4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / 
eval/dyn_loss_std 2.4 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.6 / eval/post_ent_mag 56.29 / eval/post_ent_max 56.29 / eval/post_ent_mean 37.36 / eval/post_ent_min 28.22 / eval/post_ent_std 3.53 / 
eval/prior_ent_mag 68.62 / eval/prior_ent_max 68.62 / eval/prior_ent_mean 38.44 / eval/prior_ent_min 34.71 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.4 / eval/reward_avg 1.59 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.12 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.59 / eval/reward_rate 0.79 / replay/size 3.3e5 / replay/inserts 3883 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3883 / timer/env.step_total 19.11 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.8e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.94 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7390 / timer/agent.policy_total 16.07 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1942 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.81 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.88

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 329000 Counter(329000) 328937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 329500 Counter(329500) 329437
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T044532F724079-4NPyimhvPiWeo3PozqI94n-3KoCowEOKVsNBNPFO41cPw-1024.npz
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T044547F355028-6LbfCGcXEjQZNWLk6mZhwd-6iUeIvfuWJRyEghPjUP9LS-1024.npz
Starting evaluation at step 330000 Counter(330000) 329937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 330500 Counter(330500) 330437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T044707F946345-6iUeIvfuWJRyEghPjUP9LS-3OOLv638kKhqZ1ukMADV7C-1024.npz
Starting evaluation at step 331000 Counter(331000) 330937
Saved chunk: 20230922T044651F664115-3KoCowEOKVsNBNPFO41cPw-1uFrIHGfBdpf1C00kNjGWT-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 331500 Counter(331500) 331437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T044827F354652-3OOLv638kKhqZ1ukMADV7C-3v1BDgyoqoxw4ZhorQKj4N-1024.npz
Starting evaluation at step 332000 Counter(332000) 331937
Saved chunk: 20230922T044845F062205-1uFrIHGfBdpf1C00kNjGWT-1Fh8e62hD8HOs67J75SeLM-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 332500 Counter(332500) 332437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 665562 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / train/action_mag 4.38 / train/action_max 4.11 / train/action_mean 0.04 / train/action_min -4.28 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -2.46 / train/adv_mag 0.44 / train/adv_max 0.32 / train/adv_mean 1.1e-4 / train/adv_min -0.38 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.54 / train/extr_critic_max 669.54 / train/extr_critic_mean 615.43 / train/extr_critic_min 429.6 / train/extr_critic_std 68.42 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.29 / train/extr_return_raw_max 667.29 / train/extr_return_raw_mean 615.45 / train/extr_return_raw_min 428.71 / train/extr_return_raw_std 68.48
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.2 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.31 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 7.04 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.92 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.92 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 57.68 / train/post_ent_max 57.68 / train/post_ent_mean 38.5 / train/post_ent_min 
26.39 / train/post_ent_std 4.2 / train/prior_ent_mag 68.94 / train/prior_ent_max 68.94 / train/prior_ent_mean 39.82 / train/prior_ent_min 32.29 / train/prior_ent_std 5.62 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.59 / train/reward_avg 1.17 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.17 / train/reward_rate 0.59 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.69 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 7.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 3.72 / report/image_loss_mean 0.24 / report/image_loss_std 0.28 / report/model_loss_mean 1.36 / report/model_loss_std 2.43 / report/post_ent_mag 59.94 / report/post_ent_max 59.94 / 
report/post_ent_mean 39.76 / report/post_ent_min 26.87 / report/post_ent_std 4.28 / report/prior_ent_mag 69.12 / report/prior_ent_max 69.12 / report/prior_ent_mean 41.24 / report/prior_ent_min 30.78 / report/prior_ent_std 5.62 / report/rep_loss_mean 1.79 / 
report/rep_loss_std 3.72 / report/reward_avg 0.92 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 0.92 / report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.67 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.21 / eval/model_loss_std 1.79 / eval/post_ent_mag 57.24 / eval/post_ent_max 57.24 / eval/post_ent_mean 37.2 / eval/post_ent_min 29.36 / 
eval/post_ent_std 3.66 / eval/prior_ent_mag 69.12 / eval/prior_ent_max 69.12 / eval/prior_ent_mean 38.43 / eval/prior_ent_min 34.7 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.67 / eval/reward_avg 1.54 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.54 / eval/reward_rate 0.77 / replay/size 3.3e5 / replay/inserts 3836 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3836 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.51 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 / timer/dataset_train_count 
1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.62 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T044946F656634-3v1BDgyoqoxw4ZhorQKj4N-2xLL3PKUcCzWXJSPYbBrvz-1024.npz
Starting evaluation at step 333000 Counter(333000) 332937
Saved chunk: 20230922T045002F848981-1Fh8e62hD8HOs67J75SeLM-4yPRUIYiiJk32T5NBXtaCp-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 333500 Counter(333500) 333437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T045106F713430-2xLL3PKUcCzWXJSPYbBrvz-1HHbNLPcp0qaCmVJCHQlNH-1024.npz
Starting evaluation at step 334000 Counter(334000) 333937
Saved chunk: 20230922T045121F440513-4yPRUIYiiJk32T5NBXtaCp-52xGhcjlYTuWCQVA7hT2Rg-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 334500 Counter(334500) 334437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T045226F439746-1HHbNLPcp0qaCmVJCHQlNH-1lV34vNG9hAjjDsFRO5Zs9-1024.npz
Starting evaluation at step 335000 Counter(335000) 334937
Saved chunk: 20230922T045239F486144-52xGhcjlYTuWCQVA7hT2Rg-3a72DkEPDnCX3UIQwnONyi-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 335500 Counter(335500) 335437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T045345F837315-1lV34vNG9hAjjDsFRO5Zs9-5k5HKkH06uSEVxRkTYAQTr-1024.npz
Starting evaluation at step 336000 Counter(336000) 335937
Saved chunk: 20230922T045357F318282-3a72DkEPDnCX3UIQwnONyi-2umSWtDlmnyP7ZRhVIPp4i-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 766.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T045514F995482-2umSWtDlmnyP7ZRhVIPp4i-0000000000000000000000-375.npz
Saved chunk: 20230922T045505F098962-5k5HKkH06uSEVxRkTYAQTr-0000000000000000000000-328.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 336500 Counter(336500) 336437
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 673230 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / train/action_mag 4.41 / train/action_max 4.15 / train/action_mean 0.04 / train/action_min -4.3 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -1.45 / train/adv_mag 0.46 / train/adv_max 0.33 / train/adv_mean 6.7e-6 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 9.5e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.37 / train/extr_critic_max 669.37 / train/extr_critic_mean 616.94 / train/extr_critic_min 431.64 / train/extr_critic_std 67.04 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.03 / train/extr_return_raw_max 667.03 / train/extr_return_raw_mean 616.94 / train/extr_return_raw_min 431.16 / train/extr_return_raw_std 67.15
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.22 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.34 / train/model_loss_mean 1.31 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 6.24 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 9671.28 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.92 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -8.92 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 57.77 / train/post_ent_max 57.77 / train/post_ent_mean 38.41 / train/post_ent_min 
26.2 / train/post_ent_std 4.21 / train/prior_ent_mag 68.82 / train/prior_ent_max 68.82 / train/prior_ent_mean 39.72 / train/prior_ent_min 32.21 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.59 / train/reward_avg 1.2 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.2 / train/reward_rate 0.6 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.76 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 3.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 4.12 / report/image_loss_mean 0.25 / report/image_loss_std 0.37 / report/model_loss_mean 1.38 / report/model_loss_std 2.72 / report/post_ent_mag 56.95 / report/post_ent_max 56.95 / 
report/post_ent_mean 39.66 / report/post_ent_min 24.27 / report/post_ent_std 4.49 / report/prior_ent_mag 68.38 / report/prior_ent_max 68.38 / report/prior_ent_mean 41 / report/prior_ent_min 28.45 / report/prior_ent_std 5.86 / report/rep_loss_mean 1.79 / 
report/rep_loss_std 4.12 / report/reward_avg 0.72 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.72 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.76 / eval/dyn_loss_std 3.75 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.46 / eval/model_loss_mean 1.36 / eval/model_loss_std 2.62 / eval/post_ent_mag 56.73 / eval/post_ent_max 56.73 / eval/post_ent_mean 38.24 / 
eval/post_ent_min 30.71 / eval/post_ent_std 4.25 / eval/prior_ent_mag 68.38 / eval/prior_ent_max 68.38 / eval/prior_ent_mean 39.64 / eval/prior_ent_min 34.48 / eval/prior_ent_std 5.83 / eval/rep_loss_mean 1.76 / eval/rep_loss_std 3.75 / eval/reward_avg 1.25 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.25 / eval/reward_rate 0.63 / replay/size
3.4e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3834 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.31 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.42 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T045505F098962-5k5HKkH06uSEVxRkTYAQTr-23fxw7lGsD4p8KhziPbhUt-1024.npz
Starting evaluation at step 337000 Counter(337000) 336937
Saved chunk: 20230922T045514F995482-2umSWtDlmnyP7ZRhVIPp4i-06FOHGK2Yy0fzyM5gYKJb8-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 337500 Counter(337500) 337437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T045625F546004-23fxw7lGsD4p8KhziPbhUt-3WP7hxIruf5crGz55g8FKr-1024.npz
Starting evaluation at step 338000 Counter(338000) 337937
Saved chunk: 20230922T045633F979101-06FOHGK2Yy0fzyM5gYKJb8-4XinBEy7okQbC7F3HE6nP6-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 338500 Counter(338500) 338437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T045746F683355-3WP7hxIruf5crGz55g8FKr-1X7IKbZQQJOWZwkfqOd9gT-1024.npz
Starting evaluation at step 339000 Counter(339000) 338937
Saved chunk: 20230922T045753F535600-4XinBEy7okQbC7F3HE6nP6-5ZPOtvztfCfUxm9OFZd7Ob-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 339500 Counter(339500) 339437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T045906F126071-1X7IKbZQQJOWZwkfqOd9gT-3pg2Q8dZwZQ8gjPcj5zVLr-1024.npz
Starting evaluation at step 340000 Counter(340000) 339937
Saved chunk: 20230922T045911F379794-5ZPOtvztfCfUxm9OFZd7Ob-2vdxDdnxKJMJK17EcOy4RI-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 680954 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / train/action_mag 4.42 / train/action_max 4.18 / train/action_mean 0.05 / train/action_min -4.3 / train/action_std 1.06 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -3.11 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean 1.8e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / 
train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.45 / train/extr_critic_max 669.45 / train/extr_critic_mean 617.88 / train/extr_critic_min 434.59 / train/extr_critic_std 66.73 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.02 / train/extr_return_raw_max 667.02 / train/extr_return_raw_mean 617.91 / train/extr_return_raw_min 434.7 / train/extr_return_raw_std 66.81 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.22 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.3 / train/model_loss_std 2.36 / 
train/model_opt_grad_norm 6.14 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 57.42 / train/post_ent_max 57.42 / train/post_ent_mean 38.33 / train/post_ent_min 
26.67 / train/post_ent_std 4.22 / train/prior_ent_mag 68.8 / train/prior_ent_max 68.8 / train/prior_ent_mean 39.62 / train/prior_ent_min 32.4 / train/prior_ent_std 5.66 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.52 / train/reward_avg 1.2 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 7.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.2 / train/reward_rate 0.6 / 
train_stats/mean_log_entropy 0.77 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / report/dyn_loss_std 4.12 / report/image_loss_mean 0.22 / report/image_loss_std 0.31 / report/model_loss_mean 1.38 / report/model_loss_std 2.69 / report/post_ent_mag 60.71 / report/post_ent_max 60.71 / 
report/post_ent_mean 38.4 / report/post_ent_min 24.14 / report/post_ent_std 4.72 / report/prior_ent_mag 69.08 / report/prior_ent_max 69.08 / report/prior_ent_mean 39.93 / report/prior_ent_min 29.79 / report/prior_ent_std 5.91 / report/rep_loss_mean 1.84 / 
report/rep_loss_std 4.12 / report/reward_avg 0.86 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.4e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.86 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 4.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 3.24 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.17 / eval/post_ent_mag 55.67 / eval/post_ent_max 55.67 / eval/post_ent_mean 
37.86 / eval/post_ent_min 27.77 / eval/post_ent_std 3.94 / eval/prior_ent_mag 69.08 / eval/prior_ent_max 69.08 / eval/prior_ent_mean 39.11 / eval/prior_ent_min 34.61 / eval/prior_ent_std 5.55 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.24 / eval/reward_avg 1.34 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.31 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.92 / eval/reward_neg_loss 0.08 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.36 / eval/reward_rate 0.67 / 
replay/size 3.4e5 / replay/inserts 3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3862 / timer/env.step_total 19.02 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.08 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.4e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7369 / timer/agent.policy_total 16.08 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / 
timer/dataset_train_count 1931 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1931 / timer/agent.train_total 246.8 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.62 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.74

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 340500 Counter(340500) 340437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T050025F341776-3pg2Q8dZwZQ8gjPcj5zVLr-4LNmJDMMxWKZqQgBzZ1SjF-1024.npz
Starting evaluation at step 341000 Counter(341000) 340937
Saved chunk: 20230922T050029F026610-2vdxDdnxKJMJK17EcOy4RI-52T5Ve56Tu0sGHaEgkHVs5-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 341500 Counter(341500) 341437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 342000 Counter(342000) 341937
Saved chunk: 20230922T050147F844235-52T5Ve56Tu0sGHaEgkHVs5-5PjLsmN9IYdxG0ITKPkseQ-1024.npz
eval_Episode has 500 steps and return 697.0.
Saved chunk: 20230922T050145F697935-4LNmJDMMxWKZqQgBzZ1SjF-7FD6uVRI5gSY6pHNbguSK0-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 342500 Counter(342500) 342437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 343000 Counter(343000) 342937
Saved chunk: 20230922T050305F850523-5PjLsmN9IYdxG0ITKPkseQ-6aZxSGdYKZE6uT48CL49rc-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T050308F634964-7FD6uVRI5gSY6pHNbguSK0-2EVgRVclDz5TAhv7mGWkbV-1024.npz
train_Episode has 500 steps and return 711.0.
Starting evaluation at step 343500 Counter(343500) 343437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 344000 Counter(344000) 343937
Saved chunk: 20230922T050423F571222-6aZxSGdYKZE6uT48CL49rc-269fwJfEOoiNpKpHofR3xz-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T050427F910223-2EVgRVclDz5TAhv7mGWkbV-21SXDKBdT2LLdZmfzyiyqi-1024.npz
train_Episode has 500 steps and return 760.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 688630 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 760 / episode/reward_rate 0.76 / train/action_mag 4.43 / train/action_max 4.2 / train/action_mean 0.04 / train/action_min -4.29 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -2.58 / train/adv_mag 0.51 / train/adv_max 0.37 / train/adv_mean 1.3e-4 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.7 / train/extr_critic_max 669.7 / train/extr_critic_mean 618.41 / train/extr_critic_min 437.75 / train/extr_critic_std 65.32 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.34 / train/extr_return_raw_max 667.34 / train/extr_return_raw_mean 618.43 / train/extr_return_raw_min 438.59 / train/extr_return_raw_std 65.42
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.22 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.3 / train/model_loss_std 2.38 / 
train/model_opt_grad_norm 6.21 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 9611.38 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.74 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.45 / train/policy_logprob_min -8.74 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.41 / train/post_ent_mag 57.07 / train/post_ent_max 57.07 / train/post_ent_mean 38.35 / train/post_ent_min
26.71 / train/post_ent_std 4.26 / train/prior_ent_mag 68.69 / train/prior_ent_max 68.69 / train/prior_ent_mean 39.65 / train/prior_ent_min 32.15 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.57 / train/reward_avg 1.19 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.19 / train/reward_rate 0.6 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.59 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 2.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 3.02 / report/image_loss_mean 0.18 / report/image_loss_std 0.25 / report/model_loss_mean 1.2 / report/model_loss_std 2.01 / report/post_ent_mag 54.37 / report/post_ent_max 54.37 / 
report/post_ent_mean 37.43 / report/post_ent_min 29.45 / report/post_ent_std 4.04 / report/prior_ent_mag 68.5 / report/prior_ent_max 68.5 / report/prior_ent_mean 38.67 / report/prior_ent_min 34.41 / report/prior_ent_std 5.54 / report/rep_loss_mean 1.55 / 
report/rep_loss_std 3.02 / report/reward_avg 1.49 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.49 / report/reward_rate 0.75 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 7.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.93 / eval/dyn_loss_std 4.38 / eval/image_loss_mean 0.27 / eval/image_loss_std 0.43 / eval/model_loss_mean 1.49 / eval/model_loss_std 2.96 / eval/post_ent_mag 57.44 / eval/post_ent_max 57.44 / eval/post_ent_mean 
39.13 / eval/post_ent_min 27.79 / eval/post_ent_std 4.49 / eval/prior_ent_mag 68.5 / eval/prior_ent_max 68.5 / eval/prior_ent_mean 40.76 / eval/prior_ent_min 34.7 / eval/prior_ent_std 5.81 / eval/rep_loss_mean 1.93 / eval/rep_loss_std 4.38 / eval/reward_avg 0.92 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.2e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 0.92 / eval/reward_rate 0.46 / replay/size
3.4e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3838 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.05 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.15 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.31 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 344500 Counter(344500) 344437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 345000 Counter(345000) 344937
Saved chunk: 20230922T050541F165225-269fwJfEOoiNpKpHofR3xz-7jKvGIP0oJ87yk5IzhzLBZ-1024.npz
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T050547F029959-21SXDKBdT2LLdZmfzyiyqi-2XJPm8FKGoSaLWgf1dyHbJ-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 345500 Counter(345500) 345437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 346000 Counter(346000) 345937
Saved chunk: 20230922T050700F096050-7jKvGIP0oJ87yk5IzhzLBZ-5dVX6RNuZ3eY7YSesRylx4-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T050707F567542-2XJPm8FKGoSaLWgf1dyHbJ-3O228XnaQ8S4tRRokdNZvg-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 346500 Counter(346500) 346437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 720.0.
Starting evaluation at step 347000 Counter(347000) 346937
Saved chunk: 20230922T050817F962666-5dVX6RNuZ3eY7YSesRylx4-6kTRYEUaIw2spt0QW0wgNO-1024.npz
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T050826F953052-3O228XnaQ8S4tRRokdNZvg-1j2d4pKrcb6nd5FrxzXd3U-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 347500 Counter(347500) 347437
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 765.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T050935F782042-6kTRYEUaIw2spt0QW0wgNO-0000000000000000000000-634.npz
Saved chunk: 20230922T050946F317794-1j2d4pKrcb6nd5FrxzXd3U-0000000000000000000000-665.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 348000 Counter(348000) 347937
Saved chunk: 20230922T050935F782042-6kTRYEUaIw2spt0QW0wgNO-4RQS5TIeXSwktkUJG2Ry9U-1024.npz
eval_Episode has 500 steps and return 768.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 696294 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / train/action_mag 4.41 / train/action_max 4.19 / train/action_mean 0.05 / train/action_min -4.27 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -3.47 / train/adv_mag 0.45 / train/adv_max 0.35 / train/adv_mean 2.2e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.24 / train/extr_critic_max 669.24 / train/extr_critic_mean 617.22 / train/extr_critic_min 432.46 / train/extr_critic_std 67.46 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.27 / train/extr_return_raw_max 667.27 / train/extr_return_raw_mean 617.26 / train/extr_return_raw_min 431.91 / train/extr_return_raw_std 67.54
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.21 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.34 / train/model_loss_mean 1.32 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 6.39 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8854.17 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.93 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.93 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.41 / train/post_ent_mag 56.91 / train/post_ent_max 56.91 / train/post_ent_mean 38.32 / train/post_ent_min 
26.62 / train/post_ent_std 4.24 / train/prior_ent_mag 68.83 / train/prior_ent_max 68.83 / train/prior_ent_mean 39.64 / train/prior_ent_min 32.45 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.59 / train/reward_avg 1.19 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.19 / train/reward_rate 0.6 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.76 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 6.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.89 / report/dyn_loss_std 4.06 / report/image_loss_mean 0.21 / report/image_loss_std 0.37 / report/model_loss_mean 1.4 / report/model_loss_std 2.72 / report/post_ent_mag 59.69 / report/post_ent_max 59.69 / 
report/post_ent_mean 38.21 / report/post_ent_min 21.52 / report/post_ent_std 4.23 / report/prior_ent_mag 68.74 / report/prior_ent_max 68.74 / report/prior_ent_mean 39.8 / report/prior_ent_min 27.98 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.89 / 
report/rep_loss_std 4.06 / report/reward_avg 0.97 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.97 / report/reward_rate 0.49 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 1 / 
eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.09 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.02 / eval/post_ent_mag 56.78 / eval/post_ent_max 56.78 / eval/post_ent_mean 37.88 / 
eval/post_ent_min 31.85 / eval/post_ent_std 4.12 / eval/prior_ent_mag 68.74 / eval/prior_ent_max 68.74 / eval/prior_ent_mean 39.1 / eval/prior_ent_min 34.73 / eval/prior_ent_std 5.64 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.09 / eval/reward_avg 1.35 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.35 / eval/reward_rate 0.68 / 
replay/size 3.5e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3832 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.89 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.18 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.46 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T050946F317794-1j2d4pKrcb6nd5FrxzXd3U-5hokpuACFt2WLAVoGEb7Pg-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 348500 Counter(348500) 348437
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 349000 Counter(349000) 348937
Saved chunk: 20230922T051053F624074-4RQS5TIeXSwktkUJG2Ry9U-7Egs5qwU2nSQo9ExC8GLJU-1024.npz
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T051106F389738-5hokpuACFt2WLAVoGEb7Pg-0Zv7c5KpwRKfqYUaZeJbWY-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 349500 Counter(349500) 349437
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 350000 Counter(350000) 349937
Saved chunk: 20230922T051212F502443-7Egs5qwU2nSQo9ExC8GLJU-6b1ahYHvOycKjm21nlYwvN-1024.npz
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T051226F154071-0Zv7c5KpwRKfqYUaZeJbWY-5MZ1ysN6hpTjFTovyzp80F-1024.npz
Starting evaluation at step 350500 Counter(350500) 350437
eval_Episode has 500 steps and return 731.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 351000 Counter(351000) 350937
eval_Episode has 500 steps and return 756.0.
Saved chunk: 20230922T051330F335840-6b1ahYHvOycKjm21nlYwvN-6KH4NEsU64NEZibxqIiZuP-1024.npz
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T051345F536641-5MZ1ysN6hpTjFTovyzp80F-7AobQT5B8JgdtteZQTmwEm-1024.npz
Starting evaluation at step 351500 Counter(351500) 351437
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 690.0.
Starting evaluation at step 352000 Counter(352000) 351937
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T051448F077395-6KH4NEsU64NEZibxqIiZuP-1QDqZUR0yUeTTdv4GtbFFz-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 704002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 690 / episode/reward_rate 0.69 / eval_episode/length 500 / eval_episode/score 764 / eval_episode/reward_rate 0.76 / train/action_mag 4.3 / train/action_max 4.03 / train/action_mean 0.08 / train/action_min -4.21 / train/action_std 1.04 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -0.14 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean -1.1e-4 / train/adv_min -0.38 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.44 / train/extr_critic_max 669.44 / train/extr_critic_mean 616.59 / train/extr_critic_min 426.71 / train/extr_critic_std 68.9 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.37 / train/extr_return_raw_max 667.37 / train/extr_return_raw_mean 616.57 / train/extr_return_raw_min 429.89 / train/extr_return_raw_std 69.07
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.23 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.34 / train/model_loss_mean 1.31 / train/model_loss_std 2.37 / 
train/model_opt_grad_norm 6.18 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8549.22 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.8 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.8 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.84 / train/post_ent_max 56.84 / train/post_ent_mean 38.22 / train/post_ent_min 
26.62 / train/post_ent_std 4.27 / train/prior_ent_mag 68.56 / train/prior_ent_max 68.56 / train/prior_ent_mean 39.52 / train/prior_ent_min 32.48 / train/prior_ent_std 5.7 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.52 / train/reward_avg 1.2 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.2 / train/reward_rate 0.6 / 
train_stats/mean_log_entropy 0.16 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.34 / report/image_loss_mean 0.17 / report/image_loss_std 0.33 / report/model_loss_mean 1.24 / report/model_loss_std 2.28 / report/post_ent_mag 56.09 / report/post_ent_max 56.09 / 
report/post_ent_mean 36.88 / report/post_ent_min 22.83 / report/post_ent_std 3.7 / report/prior_ent_mag 68.23 / report/prior_ent_max 68.23 / report/prior_ent_mean 38.11 / report/prior_ent_min 33.82 / report/prior_ent_std 5.24 / report/rep_loss_mean 1.62 / 
report/rep_loss_std 3.34 / report/reward_avg 1.61 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.61 / report/reward_rate 0.81 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.68 / eval/dyn_loss_std 3.18 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.31 / eval/model_loss_std 2.13 / eval/post_ent_mag 57.24 / eval/post_ent_max 57.24 / eval/post_ent_mean 
38.43 / eval/post_ent_min 28.26 / eval/post_ent_std 4.31 / eval/prior_ent_mag 68.23 / eval/prior_ent_max 68.23 / eval/prior_ent_mean 39.74 / eval/prior_ent_min 34.6 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 1.68 / eval/rep_loss_std 3.18 / eval/reward_avg 1.11 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.11 / eval/reward_rate 0.56 / replay/size
3.5e5 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.2 / timer/env.step_count 3854 / timer/env.step_total 19 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / 
timer/env.step_min 4.2e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.61 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.4e-3 / 
timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1927 / timer/agent.train_total 244.71 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 698.0.
Saved chunk: 20230922T051504F798636-7AobQT5B8JgdtteZQTmwEm-6stNAczsVCulMFtGBxcX8L-1024.npz
Starting evaluation at step 352500 Counter(352500) 352437
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 711.0.
Starting evaluation at step 353000 Counter(353000) 352937
eval_Episode has 500 steps and return 752.0.
Saved chunk: 20230922T051605F729318-1QDqZUR0yUeTTdv4GtbFFz-1ZTcQC6nDbUiQ1xtUZETAD-1024.npz
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T051625F019482-6stNAczsVCulMFtGBxcX8L-0ttBdDnsqlPJ3TpRR4Al1x-1024.npz
Starting evaluation at step 353500 Counter(353500) 353437
eval_Episode has 500 steps and return 537.0.
train_Episode has 500 steps and return 675.0.
Starting evaluation at step 354000 Counter(354000) 353937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 727.0.
Saved chunk: 20230922T051744F573908-0ttBdDnsqlPJ3TpRR4Al1x-7w7vAeHYqiYJ2t7PIxImhe-1024.npz
Starting evaluation at step 354500 Counter(354500) 354437
Saved chunk: 20230922T051724F694380-1ZTcQC6nDbUiQ1xtUZETAD-603RmW8Dahrm1ft09xAX0K-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 355000 Counter(355000) 354937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T051903F921619-7w7vAeHYqiYJ2t7PIxImhe-1boZnWS2lSPoALc7huUyKD-1024.npz
Starting evaluation at step 355500 Counter(355500) 355437
Saved chunk: 20230922T051917F938990-603RmW8Dahrm1ft09xAX0K-5WdzSPWbOqnUrUKPLHNs1o-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 711774 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / train/action_mag 4.32 / train/action_max 4.1 / train/action_mean 0.04 / train/action_min -4.19 / train/action_std 1.04 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.13 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean 3e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.63 / train/extr_critic_max 669.63 / train/extr_critic_mean 618.89 / train/extr_critic_min 435.01 / train/extr_critic_std 66.69 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.23 / train/extr_return_raw_max 667.23 / train/extr_return_raw_mean 618.95 / train/extr_return_raw_min 435.91 / train/extr_return_raw_std 66.71
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.24 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.29 / train/model_loss_std 2.32 / 
train/model_opt_grad_norm 6.38 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 9583 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.39 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 57.33 / train/post_ent_max 57.33 / train/post_ent_mean 38.02 / train/post_ent_min 
26.36 / train/post_ent_std 4.29 / train/prior_ent_mag 68.48 / train/prior_ent_max 68.48 / train/prior_ent_mean 39.31 / train/prior_ent_min 32.07 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.46 / train/reward_avg 1.22 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.22 / train/reward_rate 0.61 / 
train_stats/mean_log_entropy -0.19 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.86 / report/image_loss_mean 0.24 / report/image_loss_std 0.26 / report/model_loss_mean 1.33 / report/model_loss_std 2.49 / report/post_ent_mag 56.13 / report/post_ent_max 56.13 / 
report/post_ent_mean 40.13 / report/post_ent_min 27.74 / report/post_ent_std 4.47 / report/prior_ent_mag 68.25 / report/prior_ent_max 68.25 / report/prior_ent_mean 41.52 / report/prior_ent_min 34.3 / report/prior_ent_std 5.67 / report/rep_loss_mean 1.76 / 
report/rep_loss_std 3.86 / report/reward_avg 0.67 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.67 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / eval/cont_loss_std 3.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.82 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.18 / eval/model_loss_std 1.86 / eval/post_ent_mag 57.21 / eval/post_ent_max 57.21 / eval/post_ent_mean 
37.57 / eval/post_ent_min 27.27 / eval/post_ent_std 4.07 / eval/prior_ent_mag 68.25 / eval/prior_ent_max 68.25 / eval/prior_ent_mean 38.72 / eval/prior_ent_min 32.81 / eval/prior_ent_std 5.7 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.82 / eval/reward_avg 1.42 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.41 / eval/reward_rate 0.71 / replay/size
3.6e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3886 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.74 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.2 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.62 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 356000 Counter(356000) 355937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T052023F105755-1boZnWS2lSPoALc7huUyKD-4ISZHnQfQZFyABI7Yfhzvt-1024.npz
Starting evaluation at step 356500 Counter(356500) 356437
Saved chunk: 20230922T052035F574009-5WdzSPWbOqnUrUKPLHNs1o-64AftUlIJJQbWKeE0RbjYq-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 357000 Counter(357000) 356937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T052143F512324-4ISZHnQfQZFyABI7Yfhzvt-399VQFG3bXlfPnOpedcywk-1024.npz
Starting evaluation at step 357500 Counter(357500) 357437
Saved chunk: 20230922T052154F522262-64AftUlIJJQbWKeE0RbjYq-08YcnyyfedKeeYGTfmlXPT-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 358000 Counter(358000) 357937
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T052303F068738-399VQFG3bXlfPnOpedcywk-0OoXYdlE9NoS0eOuYCKDYv-1024.npz
Starting evaluation at step 358500 Counter(358500) 358437
Saved chunk: 20230922T052312F501668-08YcnyyfedKeeYGTfmlXPT-5TZrrA8oc6aBCEHgDtePgu-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 359000 Counter(359000) 358937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 765.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T052422F515414-0OoXYdlE9NoS0eOuYCKDYv-0000000000000000000000-1000.npz
Saved chunk: 20230922T052430F316360-5TZrrA8oc6aBCEHgDtePgu-0000000000000000000000-893.npz
Saved chunk: 20230922T052422F515414-0OoXYdlE9NoS0eOuYCKDYv-0avN6dAmZnzXSWMVw18tdI-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 359500 Counter(359500) 359437
Saved chunk: 20230922T052430F316360-5TZrrA8oc6aBCEHgDtePgu-48TpZFoQeQz9F747aPF4gs-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 719438 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 765 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / train/action_mag 4.39 / train/action_max 4.13 / train/action_mean 0.07 / train/action_min -4.26 / train/action_std 1.05 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 1.54 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean -2.9e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.28 / train/extr_critic_max 669.28 / train/extr_critic_mean 616.99 / train/extr_critic_min 426.05 / train/extr_critic_std 69.46 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.08 / train/extr_return_raw_max 667.08 / train/extr_return_raw_mean 616.94 / train/extr_return_raw_min 429.38 / train/extr_return_raw_std 69.7 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.23 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.3 / train/model_loss_std 2.37 / 
train/model_opt_grad_norm 6.51 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 8190.04 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6302.08 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.45 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.87 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.44 / train/policy_logprob_min -8.87 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.4e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.95 / train/post_ent_max 56.95 / train/post_ent_mean 38.1 / train/post_ent_min 
26.74 / train/post_ent_std 4.28 / train/prior_ent_mag 68.42 / train/prior_ent_max 68.42 / train/prior_ent_mean 39.4 / train/prior_ent_min 32.31 / train/prior_ent_std 5.71 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.53 / train/reward_avg 1.21 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.21 / train/reward_rate 0.61 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.51 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.38 / report/image_loss_mean 0.2 / report/image_loss_std 0.41 / report/model_loss_mean 1.27 / report/model_loss_std 2.32 / report/post_ent_mag 55.69 / report/post_ent_max 55.69 / 
report/post_ent_mean 37.5 / report/post_ent_min 27.58 / report/post_ent_std 4.43 / report/prior_ent_mag 68.42 / report/prior_ent_max 68.42 / report/prior_ent_mean 38.81 / report/prior_ent_min 33.19 / report/prior_ent_std 5.98 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.38 / report/reward_avg 1.3 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.3 / report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 1.6e-11 / eval/cont_loss_std 2.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.48 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.25 / eval/model_loss_std 2.31 / eval/post_ent_mag 56.12 / eval/post_ent_max 56.12 / eval/post_ent_mean 37.25 / eval/post_ent_min 31.73 / 
eval/post_ent_std 3.71 / eval/prior_ent_mag 68.42 / eval/prior_ent_max 68.42 / eval/prior_ent_mean 38.49 / eval/prior_ent_min 34.16 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.48 / eval/reward_avg 1.45 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.45 / eval/reward_rate 0.73 / replay/size 3.6e5 / replay/inserts 3832 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3832 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.24 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.2 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / 
timer/agent.train_count 1916 / timer/agent.train_total 243.45 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max
3.1e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 360000 Counter(360000) 359937
eval_Episode has 500 steps and return 762.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T052541F942412-0avN6dAmZnzXSWMVw18tdI-5lZ5giXP1fxWkG7sBY4RvP-1024.npz
Starting evaluation at step 360500 Counter(360500) 360437
Saved chunk: 20230922T052548F180896-48TpZFoQeQz9F747aPF4gs-3iDQGxdZTPTQLRwiG1nCwL-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 361000 Counter(361000) 360937
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T052702F392545-5lZ5giXP1fxWkG7sBY4RvP-0UT9IItj0xw25tMA2xw5sl-1024.npz
Starting evaluation at step 361500 Counter(361500) 361437
Saved chunk: 20230922T052707F112468-3iDQGxdZTPTQLRwiG1nCwL-35dbvvwF5d3DXZ29Dmia3n-1024.npz
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 362000 Counter(362000) 361937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 362500 Counter(362500) 362437
Saved chunk: 20230922T052821F918544-0UT9IItj0xw25tMA2xw5sl-4LLMMzfTZ9wjiku8jMLwLs-1024.npz
Saved chunk: 20230922T052825F075084-35dbvvwF5d3DXZ29Dmia3n-5r21qhZAzn7JLxTnMNLbI1-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 363000 Counter(363000) 362937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 363500 Counter(363500) 363437
Saved chunk: 20230922T052942F909108-5r21qhZAzn7JLxTnMNLbI1-7gS5aNqoq9aUWF4ItJaWrn-1024.npz
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T052941F314800-4LLMMzfTZ9wjiku8jMLwLs-0hIzzyR1kWvuWbki1KK8QZ-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 727110 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 766 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / train/action_mag 4.41 / train/action_max 4.18 / train/action_mean 0.07 / train/action_min -4.27 / train/action_std 1.06 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -5.78 / train/adv_mag 0.46 / train/adv_max 0.37 / train/adv_mean 4.5e-4 / train/adv_min -0.38 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.27 / train/extr_critic_max 669.27 / train/extr_critic_mean 617.16 / train/extr_critic_min 414.27 / train/extr_critic_std 70.88 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.13 / train/extr_return_raw_max 667.13 / train/extr_return_raw_mean 617.25 / train/extr_return_raw_min 422.66 / train/extr_return_raw_std 70.87
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.26 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.2 / train/image_loss_std 0.33 / train/model_loss_mean 1.29 / train/model_loss_std 2.33 / 
train/model_opt_grad_norm 6.4 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 8647.76 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6701.57 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.86 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -8.86 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 2.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.92 / train/post_ent_max 56.92 / train/post_ent_mean 38 / train/post_ent_min 
26.71 / train/post_ent_std 4.25 / train/prior_ent_mag 68.4 / train/prior_ent_max 68.4 / train/prior_ent_mean 39.28 / train/prior_ent_min 32.25 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.48 / train/reward_avg 1.24 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.43 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.25 / report/image_loss_mean 0.17 / report/image_loss_std 0.24 / report/model_loss_mean 1.26 / report/model_loss_std 2.12 / report/post_ent_mag 56.92 / report/post_ent_max 56.92 / 
report/post_ent_mean 37.43 / report/post_ent_min 25.25 / report/post_ent_std 4.44 / report/prior_ent_mag 67.92 / report/prior_ent_max 67.92 / report/prior_ent_mean 38.65 / report/prior_ent_min 28.74 / report/prior_ent_std 5.79 / report/rep_loss_mean 1.69 / 
report/rep_loss_std 3.25 / report/reward_avg 1.33 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.33 / report/reward_rate 0.67 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / eval/cont_loss_std 5.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.43 / eval/dyn_loss_std 2.63 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.77 / eval/post_ent_mag 56.6 / eval/post_ent_max 56.6 / eval/post_ent_mean 
36.69 / eval/post_ent_min 31.47 / eval/post_ent_std 3.54 / eval/prior_ent_mag 67.92 / eval/prior_ent_max 67.92 / eval/prior_ent_mean 37.62 / eval/prior_ent_min 33.77 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 1.43 / eval/rep_loss_std 2.63 / eval/reward_avg 1.7 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.7 / eval/reward_rate 0.85 / replay/size 
3.6e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3836 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 7.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.13 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.9e-3 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.7e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.65 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 364000 Counter(364000) 363937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 364500 Counter(364500) 364437
Saved chunk: 20230922T053100F512578-7gS5aNqoq9aUWF4ItJaWrn-3NP52GF278t8j6MLbnXbHd-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T053103F828954-0hIzzyR1kWvuWbki1KK8QZ-4ACJ8oClt3Y9GNCKwu7oND-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 365000 Counter(365000) 364937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 365500 Counter(365500) 365437
Saved chunk: 20230922T053219F449181-3NP52GF278t8j6MLbnXbHd-5OToS1F9KKi3A8kVRWTphg-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T053224F353849-4ACJ8oClt3Y9GNCKwu7oND-6hk4m9HpFcSElxEfSF7GLY-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 366000 Counter(366000) 365937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 366500 Counter(366500) 366437
Saved chunk: 20230922T053337F245911-5OToS1F9KKi3A8kVRWTphg-6EWodOgs8cjf5649GPNVQ5-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T053343F679123-6hk4m9HpFcSElxEfSF7GLY-5TkuFf98U9FMOcSv61hvhK-1024.npz
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 367000 Counter(367000) 366937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 763.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 734882 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 767 / eval_episode/reward_rate 0.77 / train/action_mag 4.3 / train/action_max 4.1 / train/action_mean 0.04 / train/action_min -4.18 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss 0.22 / train/adv_mag 0.46 / train/adv_max 0.34 / train/adv_mean -1.5e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.82 / train/extr_critic_max 669.82 / train/extr_critic_mean 618.48 / train/extr_critic_min 432.85 / train/extr_critic_std 67.63 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.35 / train/extr_return_raw_max 667.35 / train/extr_return_raw_mean 618.45 / train/extr_return_raw_min 434.47 / train/extr_return_raw_std 67.8 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.24 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.32 / train/model_loss_mean 1.29 / train/model_loss_std 2.33 / 
train/model_opt_grad_norm 6.12 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8641.03 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.58 / train/post_ent_max 56.58 / train/post_ent_mean 38.05 / train/post_ent_min 
26.91 / train/post_ent_std 4.34 / train/prior_ent_mag 68.44 / train/prior_ent_max 68.44 / train/prior_ent_mean 39.34 / train/prior_ent_min 32 / train/prior_ent_std 5.77 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.48 / train/reward_avg 1.21 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.21 / train/reward_rate 0.61 / 
train_stats/mean_log_entropy 0.58 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 3.03 / report/image_loss_mean 0.16 / report/image_loss_std 0.19 / report/model_loss_mean 1.17 / report/model_loss_std 1.97 / report/post_ent_mag 57.6 / report/post_ent_max 57.6 / 
report/post_ent_mean 37.3 / report/post_ent_min 29.06 / report/post_ent_std 4.02 / report/prior_ent_mag 68.5 / report/prior_ent_max 68.5 / report/prior_ent_mean 38.42 / report/prior_ent_min 33.24 / report/prior_ent_std 5.75 / report/rep_loss_mean 1.55 / 
report/rep_loss_std 3.03 / report/reward_avg 1.34 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.33 / report/reward_rate 0.67 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 4.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.05 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.12 / eval/post_ent_mag 58.05 / eval/post_ent_max 58.05 / eval/post_ent_mean 
38.51 / eval/post_ent_min 27.52 / eval/post_ent_std 3.86 / eval/prior_ent_mag 68.5 / eval/prior_ent_max 68.5 / eval/prior_ent_mean 39.76 / eval/prior_ent_min 33.62 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.05 / eval/reward_avg 1.17 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.21 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.17 / eval/reward_rate 0.59 / 
replay/size 3.7e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3886 / timer/env.step_total 19.13 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.87 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.8e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.11 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.57 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.91

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 367500 Counter(367500) 367437
Saved chunk: 20230922T053454F943502-6EWodOgs8cjf5649GPNVQ5-2ZQmiMWvCWzHD5CiJOVdeN-1024.npz
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T053502F926929-5TkuFf98U9FMOcSv61hvhK-0Ly1Y2b93vJxL1bNUGBnfU-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 368000 Counter(368000) 367937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 739.0.
Starting evaluation at step 368500 Counter(368500) 368437
Saved chunk: 20230922T053613F482743-2ZQmiMWvCWzHD5CiJOVdeN-6JtFfoirbVvHCsgSGIelo7-1024.npz
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T053623F096561-0Ly1Y2b93vJxL1bNUGBnfU-7BH9arqoBt2hd8ELu0T8VG-1024.npz
train_Episode has 500 steps and return 720.0.
Starting evaluation at step 369000 Counter(369000) 368937
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 369500 Counter(369500) 369437
Saved chunk: 20230922T053731F551084-6JtFfoirbVvHCsgSGIelo7-6jySfD9zu3NHCZc0qHtkCz-1024.npz
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T053742F687598-7BH9arqoBt2hd8ELu0T8VG-03Wnl0ZEQZBq4rtxR052LE-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 370000 Counter(370000) 369937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 370500 Counter(370500) 370437
Saved chunk: 20230922T053849F473795-6jySfD9zu3NHCZc0qHtkCz-2U4BLRz12t0VKKXP0IE9oY-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T053902F090570-03Wnl0ZEQZBq4rtxR052LE-4PjFfEpfcIhoBdf0HGzqdF-1024.npz
train_Episode has 500 steps and return 765.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 371000 Counter(371000) 370937
Saved chunk: 20230922T054007F173226-2U4BLRz12t0VKKXP0IE9oY-0000000000000000000000-128.npz
Saved chunk: 20230922T054021F341246-4PjFfEpfcIhoBdf0HGzqdF-0000000000000000000000-312.npz
eval_Episode has 500 steps and return 770.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 768.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 742544 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / train/action_mag 4.34 / train/action_max 4.12 / train/action_mean 0.07 / train/action_min -4.19 / train/action_std 1.05 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -5.22 / train/adv_mag 0.44 / train/adv_max 0.35 / train/adv_mean 4.1e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 9.2e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / 
train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.55 / train/extr_critic_max 669.55 / train/extr_critic_mean 616.32 / train/extr_critic_min 420.66 / train/extr_critic_std 69.73 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.25 / train/extr_return_raw_max 667.25 / train/extr_return_raw_mean 616.4 / train/extr_return_raw_min 426.28 / train/extr_return_raw_std 69.72 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.21 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.29 / train/model_loss_std 2.37 / 
train/model_opt_grad_norm 6.55 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7931.94 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.92 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.92 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.49 / train/post_ent_max 56.49 / train/post_ent_mean 38.15 / train/post_ent_min 
26.62 / train/post_ent_std 4.33 / train/prior_ent_mag 68.21 / train/prior_ent_max 68.21 / train/prior_ent_mean 39.44 / train/prior_ent_min 32.07 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.52 / train/reward_avg 1.19 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.19 / train/reward_rate 0.6 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.51 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 3.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.42 / report/dyn_loss_std 2.18 / report/image_loss_mean 0.15 / report/image_loss_std 0.14 / report/model_loss_mean 1.09 / report/model_loss_std 1.45 / report/post_ent_mag 57.34 / report/post_ent_max 57.34 / 
report/post_ent_mean 37.32 / report/post_ent_min 30.43 / report/post_ent_std 4.15 / report/prior_ent_mag 68.25 / report/prior_ent_max 68.25 / report/prior_ent_mean 38.37 / report/prior_ent_min 33.4 / report/prior_ent_std 5.78 / report/rep_loss_mean 1.42 / 
report/rep_loss_std 2.18 / report/reward_avg 1.46 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.8e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.46 / report/reward_rate 0.73 / eval/cont_avg 1 / eval/cont_loss_mean 1.6e-11 / eval/cont_loss_std 2.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.08 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.14 / eval/model_loss_mean 1.14 / eval/model_loss_std 1.38 / eval/post_ent_mag 57.99 / eval/post_ent_max 57.99 / eval/post_ent_mean 
37.1 / eval/post_ent_min 30.61 / eval/post_ent_std 3.57 / eval/prior_ent_mag 68.25 / eval/prior_ent_max 68.25 / eval/prior_ent_mean 38.2 / eval/prior_ent_min 33.54 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.08 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.28 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.15 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / 
replay/size 3.7e5 / replay/inserts 3831 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3831 / timer/env.step_total 18.87 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.16 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7839 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.31 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 371500 Counter(371500) 371437
Saved chunk: 20230922T054007F173226-2U4BLRz12t0VKKXP0IE9oY-3WDslWNxB0C6zmaR2aYIN4-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T054021F341246-4PjFfEpfcIhoBdf0HGzqdF-1y7hptMMcaMJtbF3sNiyZ0-1024.npz
train_Episode has 500 steps and return 714.0.
Starting evaluation at step 372000 Counter(372000) 371937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 372500 Counter(372500) 372437
Saved chunk: 20230922T054126F253203-3WDslWNxB0C6zmaR2aYIN4-6YLXTvpeuPXDcq5bkL9s5j-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T054142F086252-1y7hptMMcaMJtbF3sNiyZ0-3nYcBtyFbSw6dlVa6H88mk-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 373000 Counter(373000) 372937
eval_Episode has 500 steps and return 723.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 373500 Counter(373500) 373437
Saved chunk: 20230922T054244F253918-6YLXTvpeuPXDcq5bkL9s5j-73eLBlaNvRbuFKDhBfS3BR-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T054301F579209-3nYcBtyFbSw6dlVa6H88mk-66f60leLv1ianxAGzBCHWx-1024.npz
Starting evaluation at step 374000 Counter(374000) 373937
eval_Episode has 500 steps and return 495.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 374500 Counter(374500) 374437
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T054402F082704-73eLBlaNvRbuFKDhBfS3BR-4qD9m0MyeqtOgSMnMMmWIB-1024.npz
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T054420F954952-66f60leLv1ianxAGzBCHWx-7eHGYGeCubQweTAnjiqWCl-1024.npz
Starting evaluation at step 375000 Counter(375000) 374937
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 750214 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / train/action_mag 4.37 / train/action_max 4.16 / train/action_mean 0.07 / train/action_min -4.21 / train/action_std 1.05 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -0.21 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean -1.1e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.39 / train/extr_critic_max 669.39 / train/extr_critic_mean 617.93 / train/extr_critic_min 415.08 / train/extr_critic_std 69.17 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.13 / train/extr_return_raw_max 667.13 / train/extr_return_raw_mean 617.91 / train/extr_return_raw_min 419.7 / train/extr_return_raw_std 69.34 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.25 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.2 / train/image_loss_std 0.34 / train/model_loss_mean 1.29 / train/model_loss_std 2.35 / 
train/model_opt_grad_norm 6.22 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 9518.01 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.44 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.44 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.19 / train/post_ent_max 56.19 / train/post_ent_mean 37.99 / train/post_ent_min 
26.16 / train/post_ent_std 4.29 / train/prior_ent_mag 68.06 / train/prior_ent_max 68.06 / train/prior_ent_mean 39.26 / train/prior_ent_min 31.84 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.49 / train/reward_avg 1.22 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.22 / train/reward_rate 0.61 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.37 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / report/dyn_loss_std 3.88 / report/image_loss_mean 0.28 / report/image_loss_std 0.48 / report/model_loss_mean 1.44 / report/model_loss_std 2.72 / report/post_ent_mag 52.65 / report/post_ent_max 52.65 / 
report/post_ent_mean 39.56 / report/post_ent_min 28.48 / report/post_ent_std 4.66 / report/prior_ent_mag 67.98 / report/prior_ent_max 67.98 / report/prior_ent_mean 40.97 / report/prior_ent_min 32.95 / report/prior_ent_std 5.75 / report/rep_loss_mean 1.84 / 
report/rep_loss_std 3.88 / report/reward_avg 0.83 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 0.83 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.55 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.47 / eval/model_loss_mean 1.22 / eval/model_loss_std 1.87 / eval/post_ent_mag 55.37 / eval/post_ent_max 55.37 / eval/post_ent_mean 37.39 / eval/post_ent_min 27.09 / 
eval/post_ent_std 3.57 / eval/prior_ent_mag 67.98 / eval/prior_ent_max 67.98 / eval/prior_ent_mean 38.46 / eval/prior_ent_min 31.55 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.55 / eval/reward_avg 1.57 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.57 / eval/reward_rate 0.79 / replay/size 3.8e5 / replay/inserts 3835 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3835 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 8.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.87 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7843 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.15 / timer/dataset_train_count 
1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.57 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 375500 Counter(375500) 375437
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T054519F776163-4qD9m0MyeqtOgSMnMMmWIB-0E4frTmr4nIUw0pLCb9LsT-1024.npz
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T054540F148821-7eHGYGeCubQweTAnjiqWCl-6rzxpvIotfLqUQ2qXDNXwk-1024.npz
Starting evaluation at step 376000 Counter(376000) 375937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 376500 Counter(376500) 376437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T054700F551350-6rzxpvIotfLqUQ2qXDNXwk-1zu3udxEUpDDm4aNIH03fa-1024.npz
Starting evaluation at step 377000 Counter(377000) 376937
Saved chunk: 20230922T054638F519833-0E4frTmr4nIUw0pLCb9LsT-1cXU7R48UCHbtSmiezAjI4-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 377500 Counter(377500) 377437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T054819F956326-1zu3udxEUpDDm4aNIH03fa-5Z8LUloLvDg7WoP1YswLwN-1024.npz
Starting evaluation at step 378000 Counter(378000) 377937
Saved chunk: 20230922T054831F894659-1cXU7R48UCHbtSmiezAjI4-4EIlIFJVHgPaibb0GBTktC-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 378500 Counter(378500) 378437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T054939F243550-5Z8LUloLvDg7WoP1YswLwN-7nI2NGAVNZ3rJlhXJhllrp-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 757986 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 767 / eval_episode/reward_rate 0.77 / train/action_mag 4.41 / train/action_max 4.16 / train/action_mean 0.07 / train/action_min -4.27 / train/action_std 1.06 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -3.34 / train/adv_mag 0.45 / train/adv_max 0.35 / train/adv_mean 2.1e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.29 / train/extr_critic_max 669.29 / train/extr_critic_mean 618.78 / train/extr_critic_min 413.17 / train/extr_critic_std 69.16 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.3 / train/extr_return_raw_max 667.3 / train/extr_return_raw_mean 618.82 / train/extr_return_raw_min 419.11 / train/extr_return_raw_std 69.21 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.26 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.28 / train/model_loss_std 2.32 / 
train/model_opt_grad_norm 6.42 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.45 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.81 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.45 / train/policy_logprob_min -8.81 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.3e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.98 / train/post_ent_max 55.98 / train/post_ent_mean 38.04 / train/post_ent_min 
26.93 / train/post_ent_std 4.27 / train/prior_ent_mag 68.08 / train/prior_ent_max 68.08 / train/prior_ent_mean 39.3 / train/prior_ent_min 31.97 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.47 / train/reward_avg 1.23 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.23 / train/reward_rate 0.62 / 
train_stats/mean_log_entropy 0.64 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 6.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.81 / report/dyn_loss_std 4.45 / report/image_loss_mean 0.23 / report/image_loss_std 0.35 / report/model_loss_mean 1.39 / report/model_loss_std 2.94 / report/post_ent_mag 52.99 / report/post_ent_max 52.99 / 
report/post_ent_mean 38.36 / report/post_ent_min 25.74 / report/post_ent_std 4.38 / report/prior_ent_mag 68.2 / report/prior_ent_max 68.2 / report/prior_ent_mean 39.85 / report/prior_ent_min 33.47 / report/prior_ent_std 5.63 / report/rep_loss_mean 1.81 / 
report/rep_loss_std 4.45 / report/reward_avg 1.04 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.04 / report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 4.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.6 / eval/dyn_loss_std 2.92 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.26 / eval/model_loss_std 1.91 / eval/post_ent_mag 53.11 / eval/post_ent_max 53.11 / eval/post_ent_mean 
37.28 / eval/post_ent_min 30.18 / eval/post_ent_std 3.26 / eval/prior_ent_mag 68.2 / eval/prior_ent_max 68.2 / eval/prior_ent_mean 38.51 / eval/prior_ent_min 34.1 / eval/prior_ent_std 5.02 / eval/rep_loss_mean 1.6 / eval/rep_loss_std 2.92 / eval/reward_avg 1.58 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.27 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.58 / eval/reward_rate 0.8 / replay/size
3.8e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3886 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.56 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.1 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.63 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 379000 Counter(379000) 378937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T054949F650947-4EIlIFJVHgPaibb0GBTktC-4tm1CnTedrHHUDqF4iUErE-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 379500 Counter(379500) 379437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T055058F369237-7nI2NGAVNZ3rJlhXJhllrp-0fmZTsSJIPTeVTGhDtzA19-1024.npz
Starting evaluation at step 380000 Counter(380000) 379937
Saved chunk: 20230922T055107F939221-4tm1CnTedrHHUDqF4iUErE-4POozBeGmW3BodHGEDxXRi-1024.npz
eval_Episode has 500 steps and return 728.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 380500 Counter(380500) 380437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T055219F047863-0fmZTsSJIPTeVTGhDtzA19-4PCUqvopxGtpNnVvOavtdw-1024.npz
Starting evaluation at step 381000 Counter(381000) 380937
Saved chunk: 20230922T055226F324437-4POozBeGmW3BodHGEDxXRi-4KojnwkRnvW1XgYMqmrlqK-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 381500 Counter(381500) 381437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T055338F347615-4PCUqvopxGtpNnVvOavtdw-6nCi41MTPfwFeHqTJPW3tk-1024.npz
Starting evaluation at step 382000 Counter(382000) 381937
Saved chunk: 20230922T055344F074364-4KojnwkRnvW1XgYMqmrlqK-1lTVJdik80eoSeWPsdj2FC-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 382500 Counter(382500) 382437
eval_Episode has 500 steps and return 769.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T055501F799023-1lTVJdik80eoSeWPsdj2FC-0000000000000000000000-888.npz
Saved chunk: 20230922T055457F635311-6nCi41MTPfwFeHqTJPW3tk-0000000000000000000000-648.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 765650 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.31 / train/action_max 4.06 / train/action_mean 0.08 / train/action_min -4.18 / train/action_std 1.04 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -3.9 / train/adv_mag 0.45 / train/adv_max 0.34 / train/adv_mean 2.8e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / 
train/dyn_loss_std 3.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.35 / train/extr_critic_max 669.35 / train/extr_critic_mean 616.28 / train/extr_critic_min 414.37 / train/extr_critic_std 69.7 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.46 / train/extr_return_raw_max 667.46 / train/extr_return_raw_mean 616.33 / train/extr_return_raw_min 418.83 / train/extr_return_raw_std 69.78
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.22 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.29 / train/model_loss_std 2.36 / 
train/model_opt_grad_norm 6.01 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.39 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.26 / train/post_ent_max 56.26 / train/post_ent_mean 38.15 / train/post_ent_min 
26.44 / train/post_ent_std 4.32 / train/prior_ent_mag 68.03 / train/prior_ent_max 68.03 / train/prior_ent_mean 39.44 / train/prior_ent_min 32.18 / train/prior_ent_std 5.71 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.51 / train/reward_avg 1.19 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.19 / train/reward_rate 0.6 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.65 / report/cont_avg 1 / report/cont_loss_mean 5.2e-11 / report/cont_loss_std 8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / report/dyn_loss_std 2.94 / report/image_loss_mean 0.16 / report/image_loss_std 0.16 / report/model_loss_mean 1.21 / report/model_loss_std 1.86 / report/post_ent_mag 60.54 / report/post_ent_max 60.54 / 
report/post_ent_mean 37.46 / report/post_ent_min 28.42 / report/post_ent_std 4.24 / report/prior_ent_mag 68.06 / report/prior_ent_max 68.06 / report/prior_ent_mean 38.69 / report/prior_ent_min 33.43 / report/prior_ent_std 5.72 / report/rep_loss_mean 1.6 / 
report/rep_loss_std 2.94 / report/reward_avg 1.4 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.39 / report/reward_rate 0.7 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 3.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.56 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.69 / eval/post_ent_mag 56.39 / eval/post_ent_max 56.39 / eval/post_ent_mean 36.82 / 
eval/post_ent_min 31.67 / eval/post_ent_std 3.49 / eval/prior_ent_mag 68.06 / eval/prior_ent_max 68.06 / eval/prior_ent_mean 37.87 / eval/prior_ent_min 32.53 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.56 / eval/reward_avg 1.59 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.59 / eval/reward_rate 0.8 / replay/size
3.8e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3832 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.95 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.24 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1916 / timer/agent.train_total 242.9 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5
/ timer/dataset_eval_max 3e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T055457F635311-6nCi41MTPfwFeHqTJPW3tk-02nVYKWmC9vFA4jEHLSPWt-1024.npz
Starting evaluation at step 383000 Counter(383000) 382937
Saved chunk: 20230922T055501F799023-1lTVJdik80eoSeWPsdj2FC-4wSKofXGBvg4uDtpwEb89j-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 383500 Counter(383500) 383437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 384000 Counter(384000) 383937
Saved chunk: 20230922T055618F155337-02nVYKWmC9vFA4jEHLSPWt-6WMO7CYnpXSHRcSCEigLsc-1024.npz
Saved chunk: 20230922T055620F847118-4wSKofXGBvg4uDtpwEb89j-29VBMACvxyXhHzvbiPXFCQ-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 384500 Counter(384500) 384437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 385000 Counter(385000) 384937
Saved chunk: 20230922T055738F959199-29VBMACvxyXhHzvbiPXFCQ-1YWSyD7uEltWHwAigePwzF-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T055737F902872-6WMO7CYnpXSHRcSCEigLsc-2gFxbj1JHv8Z8f0BXNCUU9-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 385500 Counter(385500) 385437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 386000 Counter(386000) 385937
Saved chunk: 20230922T055856F741537-1YWSyD7uEltWHwAigePwzF-2Eu5WaXZ8QR3tGy2N5BMYb-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T055900F652397-2gFxbj1JHv8Z8f0BXNCUU9-2qB4Ysvu6XDfifApKY4ElV-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 386500 Counter(386500) 386437
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 773318 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / train/action_mag 4.35 / train/action_max 4.1 / train/action_mean 0.06 / train/action_min -4.25 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.05 / train/adv_mag 0.48 / train/adv_max 0.36 / train/adv_mean 2.7e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.63 / train/extr_critic_max 669.63 / train/extr_critic_mean 620.66 / train/extr_critic_min 413.31 / train/extr_critic_std 66.37 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.43 / train/extr_return_raw_max 667.43 / train/extr_return_raw_mean 620.71 / train/extr_return_raw_min 415.46 / train/extr_return_raw_std 66.42
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.26 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.27 / train/model_loss_std 2.27 / 
train/model_opt_grad_norm 6.27 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 7869.83 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6197.92 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.84 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.84 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.39 / train/post_ent_max 56.39 / train/post_ent_mean 37.93 / train/post_ent_min 
27.24 / train/post_ent_std 4.24 / train/prior_ent_mag 67.96 / train/prior_ent_max 67.96 / train/prior_ent_mean 39.18 / train/prior_ent_min 32.15 / train/prior_ent_std 5.66 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.39 / train/reward_avg 1.24 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.38 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.75 / report/image_loss_mean 0.22 / report/image_loss_std 0.42 / report/model_loss_mean 1.32 / report/model_loss_std 2.64 / report/post_ent_mag 59.48 / report/post_ent_max 59.48 / 
report/post_ent_mean 38.99 / report/post_ent_min 26.24 / report/post_ent_std 4.67 / report/prior_ent_mag 68.14 / report/prior_ent_max 68.14 / report/prior_ent_mean 40.21 / report/prior_ent_min 29.73 / report/prior_ent_std 5.95 / report/rep_loss_mean 1.7 / 
report/rep_loss_std 3.75 / report/reward_avg 0.99 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.99 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 5.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.92 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.91 / eval/post_ent_mag 55.01 / eval/post_ent_max 55.01 / eval/post_ent_mean 36.56 / 
eval/post_ent_min 26.97 / eval/post_ent_std 3.37 / eval/prior_ent_mag 68.14 / eval/prior_ent_max 68.14 / eval/prior_ent_mean 37.65 / eval/prior_ent_min 33.3 / eval/prior_ent_std 5.11 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.92 / eval/reward_avg 1.72 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.18 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.72 / eval/reward_rate 0.86 / 
replay/size 3.9e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3834 / timer/env.step_total 18.87 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 3.7e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.88 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.15 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.39 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 387000 Counter(387000) 386937
Saved chunk: 20230922T060014F454332-2Eu5WaXZ8QR3tGy2N5BMYb-5W0ttVx4c4mpNMl4cQimBo-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T060019F874014-2qB4Ysvu6XDfifApKY4ElV-2iuSDj3HfKskS7S9OcJ8x0-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 387500 Counter(387500) 387437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 388000 Counter(388000) 387937
Saved chunk: 20230922T060133F261385-5W0ttVx4c4mpNMl4cQimBo-1HQPJ9zHLs5DCjY6iXNb1X-1024.npz
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T060140F264483-2iuSDj3HfKskS7S9OcJ8x0-286fUic1Ma3XItu8HHRksc-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 388500 Counter(388500) 388437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 389000 Counter(389000) 388937
Saved chunk: 20230922T060251F240497-1HQPJ9zHLs5DCjY6iXNb1X-0CAURdxyAHX0EOELgxVOvU-1024.npz
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T060259F802785-286fUic1Ma3XItu8HHRksc-1RHdrqVybNtJswl26IpEPH-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 389500 Counter(389500) 389437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 390000 Counter(390000) 389937
Saved chunk: 20230922T060409F051939-0CAURdxyAHX0EOELgxVOvU-4dwXzh0VvPaM8VEHVibgzi-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T060419F126362-1RHdrqVybNtJswl26IpEPH-27x7RzbwteMNXEPd2QGJ6B-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 390500 Counter(390500) 390437
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 781002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.36 / train/action_max 4.14 / train/action_mean 0.06 / train/action_min -4.23 / train/action_std 1.06 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -3.68 / train/adv_mag 0.48 / train/adv_max 0.4 / train/adv_mean 2.4e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.48 / train/extr_critic_max 669.48 / train/extr_critic_mean 619.04 / train/extr_critic_min 417.42 / train/extr_critic_std 66.58 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.48 / train/extr_return_raw_max 667.48 / train/extr_return_raw_mean 619.08 / train/extr_return_raw_min 420.18 / train/extr_return_raw_std 66.63
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.23 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.2 / train/image_loss_std 0.33 / train/model_loss_mean 1.28 / train/model_loss_std 2.32 / 
train/model_opt_grad_norm 6.39 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8593.75 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.89 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.89 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.17 / train/post_ent_max 56.17 / train/post_ent_mean 38.04 / train/post_ent_min 
26.65 / train/post_ent_std 4.27 / train/prior_ent_mag 67.86 / train/prior_ent_max 67.86 / train/prior_ent_mean 39.3 / train/prior_ent_min 32.06 / train/prior_ent_std 5.67 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.46 / train/reward_avg 1.21 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.21 / train/reward_rate 0.61 / 
train_stats/mean_log_entropy 0.72 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 1 
/ report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.99 / report/image_loss_mean 0.17 / report/image_loss_std 0.24 / report/model_loss_mean 1.29 / report/model_loss_std 2.55 / report/post_ent_mag 55.99 / report/post_ent_max 55.99 / report/post_ent_mean
36.85 / report/post_ent_min 26.63 / report/post_ent_std 3.89 / report/prior_ent_mag 67.8 / report/prior_ent_max 67.8 / report/prior_ent_mean 38.07 / report/prior_ent_min 33.58 / report/prior_ent_std 5.65 / report/rep_loss_mean 1.72 / report/rep_loss_std 3.99 / 
report/reward_avg 1.45 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.5e-6 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred
1.45 / report/reward_rate 0.73 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 7.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 
/ eval/dyn_loss_std 2.18 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.14 / eval/model_loss_mean 1.1 / eval/model_loss_std 1.4 / eval/post_ent_mag 54.81 / eval/post_ent_max 54.81 / eval/post_ent_mean 36.64 / eval/post_ent_min 28.41 / eval/post_ent_std 3.44 / 
eval/prior_ent_mag 67.8 / eval/prior_ent_max 67.8 / eval/prior_ent_mean 37.61 / eval/prior_ent_min 33.61 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.18 / eval/reward_avg 1.59 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.59 / eval/reward_rate 0.79 / replay/size 3.9e5 / replay/inserts 3842 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.43 / timer/env.step_count 3842 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.18 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1921 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1921 / timer/agent.train_total 244.04 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 391000 Counter(391000) 390937
Saved chunk: 20230922T060526F755095-4dwXzh0VvPaM8VEHVibgzi-3cYLnLNQBix0PXzv73jY2H-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T060538F353509-27x7RzbwteMNXEPd2QGJ6B-04H4LYvpXsz5F96NE2cZc4-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 391500 Counter(391500) 391437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 392000 Counter(392000) 391937
Saved chunk: 20230922T060645F566165-3cYLnLNQBix0PXzv73jY2H-1WFb6gTXs4nFk9CDHiBGwN-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T060658F821875-04H4LYvpXsz5F96NE2cZc4-1xKOi0Ny5e7vHGDcKdL1W3-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 392500 Counter(392500) 392437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 393000 Counter(393000) 392937
Saved chunk: 20230922T060803F541164-1WFb6gTXs4nFk9CDHiBGwN-2sRe9Gnfiya5r5i7ZIvDAY-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T060818F258904-1xKOi0Ny5e7vHGDcKdL1W3-3scklYqKopaIPRpaIUOKB0-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 393500 Counter(393500) 393437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 394000 Counter(394000) 393937
Saved chunk: 20230922T060921F374312-2sRe9Gnfiya5r5i7ZIvDAY-0DOB1jcYp5sJTZpEUtctNC-1024.npz
eval_Episode has 500 steps and return 771.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T060937F651390-3scklYqKopaIPRpaIUOKB0-0000000000000000000000-984.npz
Saved chunk: 20230922T061039F093874-0DOB1jcYp5sJTZpEUtctNC-0000000000000000000000-123.npz
Saved chunk: 20230922T060937F651390-3scklYqKopaIPRpaIUOKB0-60Xi4FTw6OB6Y83fz8Xc2e-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 766.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 788758 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.4 / train/action_max 4.15 / train/action_mean 0.06 / train/action_min -4.31 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -3.86 / train/adv_mag 0.46 / train/adv_max 0.37 / train/adv_mean 2.4e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 669.67 / train/extr_critic_max 669.67 / train/extr_critic_mean 621.39 / train/extr_critic_min 420.02 / train/extr_critic_std 65.39 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.37 / train/extr_return_raw_max 668.37 / train/extr_return_raw_mean 621.44 / train/extr_return_raw_min 422.49 / train/extr_return_raw_std 65.46
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.27 / train/model_loss_std 2.29 / 
train/model_opt_grad_norm 6.12 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.49 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.87 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.49 / train/policy_logprob_min -8.87 / train/policy_logprob_std 1.17 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.59 / train/post_ent_max 55.59 / train/post_ent_mean 37.85 / train/post_ent_min 26.83 / train/post_ent_std 4.25 /
train/prior_ent_mag 67.57 / train/prior_ent_max 67.57 / train/prior_ent_mean 39.1 / train/prior_ent_min 32.15 / train/prior_ent_std 5.63 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.41 / train/reward_avg 1.24 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.12
/ train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / train_stats/mean_log_entropy 0.55 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.44 / report/dyn_loss_std 2.6 / report/image_loss_mean 0.14 / report/image_loss_std 0.17 / report/model_loss_mean 1.1 / report/model_loss_std 1.67 / report/post_ent_mag 54.38 / report/post_ent_max 54.38 / report/post_ent_mean 36.45 / 
report/post_ent_min 28.38 / report/post_ent_std 4.08 / report/prior_ent_mag 67.71 / report/prior_ent_max 67.71 / report/prior_ent_mean 37.52 / report/prior_ent_min 33.3 / report/prior_ent_std 5.54 / report/rep_loss_mean 1.44 / report/rep_loss_std 2.6 / report/reward_avg 
1.56 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.4e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.11 / report/reward_pred 1.56 / 
report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 8.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.46 / 
eval/dyn_loss_std 2.76 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.86 / eval/post_ent_mag 52.88 / eval/post_ent_max 52.88 / eval/post_ent_mean 37.42 / eval/post_ent_min 31.18 / eval/post_ent_std 3.88 / 
eval/prior_ent_mag 67.71 / eval/prior_ent_max 67.71 / eval/prior_ent_mean 38.43 / eval/prior_ent_min 33.29 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.76 / eval/reward_avg 1.39 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.13 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.39 / eval/reward_rate 0.7 / replay/size 3.9e5 / replay/inserts 3878 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3878 / timer/env.step_total 19.36 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.15 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.03 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7385 / timer/agent.policy_total 16.37 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.15 / timer/dataset_train_count 1939 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1939 / 
timer/agent.train_total 246.14 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.85

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 394500 Counter(394500) 394437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 395000 Counter(395000) 394937
Saved chunk: 20230922T061039F093874-0DOB1jcYp5sJTZpEUtctNC-7LT7pS9kg2J7FYhtSQ8AX3-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T061057F143838-60Xi4FTw6OB6Y83fz8Xc2e-4r426215ZO0nydcfRIzGMh-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 395500 Counter(395500) 395437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 396000 Counter(396000) 395937
Saved chunk: 20230922T061158F365055-7LT7pS9kg2J7FYhtSQ8AX3-60jAO6TgrfUuFzYVZUW79B-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T061217F814389-4r426215ZO0nydcfRIzGMh-0h1domWkkmW812EjLY47YB-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 396500 Counter(396500) 396437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 397000 Counter(397000) 396937
Saved chunk: 20230922T061316F311639-60jAO6TgrfUuFzYVZUW79B-0Z5qFfYpbn0faekgFqCADo-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T061337F312558-0h1domWkkmW812EjLY47YB-2gYo87mn0aavxdgLg006ge-1024.npz
Starting evaluation at step 397500 Counter(397500) 397437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 398000 Counter(398000) 397937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T061434F189517-0Z5qFfYpbn0faekgFqCADo-1EZS1LqITd5BrFNUttgLb7-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 796418 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / train/action_mag 4.33 / train/action_max 4.02 / train/action_mean 0.08 / train/action_min -4.24 / train/action_std 1.06 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -3.12 / train/adv_mag 0.43 / train/adv_max 0.33 / train/adv_mean 1.9e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.44 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 670.75 / train/extr_critic_max 670.75 / train/extr_critic_mean 620.81 / train/extr_critic_min 433.27 / train/extr_critic_std 65.83 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.88 / train/extr_return_raw_max 669.88 / train/extr_return_raw_mean 620.85 / train/extr_return_raw_min 434.42 / train/extr_return_raw_std 65.93
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.25 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.33 / train/model_loss_mean 1.28 / train/model_loss_std 2.32 / 
train/model_opt_grad_norm 6.13 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.44 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.93 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.44 / train/policy_logprob_min -8.93 / train/policy_logprob_std 1.16 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.69 / train/post_ent_max 55.69 / train/post_ent_mean 37.8 / train/post_ent_min 26.61 / train/post_ent_std 4.33 /
train/prior_ent_mag 67.63 / train/prior_ent_max 67.63 / train/prior_ent_mean 39.06 / train/prior_ent_min 32.1 / train/prior_ent_std 5.71 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.44 / train/reward_avg 1.23 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.12
/ train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.23 / train/reward_rate 0.62 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 0.08 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.81 / report/dyn_loss_std 4.06 / report/image_loss_mean 0.21 / report/image_loss_std 0.41 / report/model_loss_mean 1.39 / report/model_loss_std 2.76 / report/post_ent_mag 53.82 / report/post_ent_max 53.82 / report/post_ent_mean 37.3 / 
report/post_ent_min 27.37 / report/post_ent_std 3.81 / report/prior_ent_mag 67.88 / report/prior_ent_max 67.88 / report/prior_ent_mean 38.74 / report/prior_ent_min 32.22 / report/prior_ent_std 5.52 / report/rep_loss_mean 1.81 / report/rep_loss_std 4.06 / report/reward_avg
1.48 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.48 / 
report/reward_rate 0.75 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / 
eval/dyn_loss_std 2.99 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.98 / eval/post_ent_mag 54.55 / eval/post_ent_max 54.55 / eval/post_ent_mean 37.18 / eval/post_ent_min 29.06 / eval/post_ent_std 3.59 / 
eval/prior_ent_mag 67.88 / eval/prior_ent_max 67.88 / eval/prior_ent_mean 38.35 / eval/prior_ent_min 33.55 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.99 / eval/reward_avg 1.53 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.13 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / replay/size 4e5 / replay/inserts 3830 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3830 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.3e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.07 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7838 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1915 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.47 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T061456F688411-2gYo87mn0aavxdgLg006ge-3Tb6Y9PqQoAEta4lvppjCn-1024.npz
Starting evaluation at step 398500 Counter(398500) 398437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 399000 Counter(399000) 398937
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T061551F974156-1EZS1LqITd5BrFNUttgLb7-3vhMauFUMD9lTglP0HHGib-1024.npz
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T061616F988112-3Tb6Y9PqQoAEta4lvppjCn-54W9hhe0i8w2wsHPiBL0uX-1024.npz
Starting evaluation at step 399500 Counter(399500) 399437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 400000 Counter(400000) 399937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T061736F552741-54W9hhe0i8w2wsHPiBL0uX-3z8a5pxkF2KajhdolZaIWe-1024.npz
Starting evaluation at step 400500 Counter(400500) 400437
Saved chunk: 20230922T061710F913044-3vhMauFUMD9lTglP0HHGib-21sZYdhKmDxgknpIvrgvyi-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 401000 Counter(401000) 400937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T061855F985692-3z8a5pxkF2KajhdolZaIWe-5EFcpD8Q6il4wBjiHmQXgh-1024.npz
Starting evaluation at step 401500 Counter(401500) 401437
Saved chunk: 20230922T061904F264902-21sZYdhKmDxgknpIvrgvyi-7CBJKxDrkMDuqbwwxM0rq1-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 402000 Counter(402000) 401937
eval_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 804094 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / train/action_mag 4.42 / train/action_max 4.08 / train/action_mean 0.07 / train/action_min -4.34 / train/action_std 1.08 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -5.94 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean 4.6e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.45 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 672.27 / train/extr_critic_max 672.27 / train/extr_critic_mean 622.28 / train/extr_critic_min 430.65 / train/extr_critic_std 67.03 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.34 / train/extr_return_raw_max 670.34 / train/extr_return_raw_mean 622.36 / train/extr_return_raw_min 434.8 / train/extr_return_raw_std 67.06 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.28 / train/model_loss_std 2.31 / 
train/model_opt_grad_norm 6.15 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8255.21 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 9.05 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -9.05 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.66 / train/post_ent_max 55.66 / train/post_ent_mean 37.71 / train/post_ent_min 
26.39 / train/post_ent_std 4.33 / train/prior_ent_mag 67.71 / train/prior_ent_max 67.71 / train/prior_ent_mean 38.98 / train/prior_ent_min 31.87 / train/prior_ent_std 5.74 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.45 / train/reward_avg 1.24 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
train_stats/mean_log_entropy 0.55 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 5.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.2 / report/image_loss_mean 0.2 / report/image_loss_std 0.38 / report/model_loss_mean 1.24 / report/model_loss_std 2.16 / report/post_ent_mag 53.15 / report/post_ent_max 53.15 / report/post_ent_mean
38.11 / report/post_ent_min 28.58 / report/post_ent_std 4.44 / report/prior_ent_mag 67.29 / report/prior_ent_max 67.29 / report/prior_ent_mean 39.25 / report/prior_ent_min 33.02 / report/prior_ent_std 5.84 / report/rep_loss_mean 1.61 / report/rep_loss_std 3.2 / 
report/reward_avg 1.23 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred
1.23 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 7.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.6 /
eval/dyn_loss_std 3.16 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.08 / eval/post_ent_mag 54.79 / eval/post_ent_max 54.79 / eval/post_ent_mean 38.08 / eval/post_ent_min 32.04 / eval/post_ent_std 3.86 / 
eval/prior_ent_mag 67.29 / eval/prior_ent_max 67.29 / eval/prior_ent_mean 39.26 / eval/prior_ent_min 33.19 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 1.6 / eval/rep_loss_std 3.16 / eval/reward_avg 1.22 / eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.08 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.3e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.22 / eval/reward_rate 0.61 / replay/size 4e5 / replay/inserts 3838 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3838 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 7.3e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.52 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1919 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.62 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T062015F213730-5EFcpD8Q6il4wBjiHmQXgh-1CoBrRmYeqW0sPzDpHyD2P-1024.npz
Starting evaluation at step 402500 Counter(402500) 402437
Saved chunk: 20230922T062021F950749-7CBJKxDrkMDuqbwwxM0rq1-5FiMOLqZUB7PuoC476CoGy-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 403000 Counter(403000) 402937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T062135F464207-1CoBrRmYeqW0sPzDpHyD2P-31knAmeSMv7NGRfspF5F1y-1024.npz
Starting evaluation at step 403500 Counter(403500) 403437
Saved chunk: 20230922T062140F676727-5FiMOLqZUB7PuoC476CoGy-7KM8iWXDpbVTazRAHwtpAc-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 404000 Counter(404000) 403937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T062255F001078-31knAmeSMv7NGRfspF5F1y-3l3zhYHzccUwp8zNGuF6dt-1024.npz
Starting evaluation at step 404500 Counter(404500) 404437
Saved chunk: 20230922T062258F640215-7KM8iWXDpbVTazRAHwtpAc-5r3TeANv1x5obPxmIPFgIT-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 405000 Counter(405000) 404937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 405500 Counter(405500) 405437
Saved chunk: 20230922T062416F373078-5r3TeANv1x5obPxmIPFgIT-4pKNXNIeP3mlVeAOEDtHDo-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T062414F304388-3l3zhYHzccUwp8zNGuF6dt-0xEyKy4YkkzFwqOu5DSgTE-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T062536F786720-0xEyKy4YkkzFwqOu5DSgTE-0000000000000000000000-296.npz
Saved chunk: 20230922T062533F921218-4pKNXNIeP3mlVeAOEDtHDo-0000000000000000000000-382.npz
train_Episode has 500 steps and return 763.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 811862 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 763 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / train/action_mag 4.42 / train/action_max 4.11 / train/action_mean 0.05 / train/action_min -4.33 / train/action_std 1.08 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -0.38 / train/adv_mag 0.46 / train/adv_max 0.35 / train/adv_mean -1e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 672.04 / train/extr_critic_max 672.04 / train/extr_critic_mean 623.43 / train/extr_critic_min 435.77 / train/extr_critic_std 64.5 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.52 / train/extr_return_raw_max 669.52 / train/extr_return_raw_mean 623.42 / train/extr_return_raw_min 441.8 / train/extr_return_raw_std 64.62 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.19 / train/image_loss_std 0.31 / train/model_loss_mean 1.27 / train/model_loss_std 2.29 / 
train/model_opt_grad_norm 5.81 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 8350.1 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6572.16 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.96 / train/post_ent_max 54.96 / train/post_ent_mean 37.68 / train/post_ent_min
26.36 / train/post_ent_std 4.35 / train/prior_ent_mag 67.62 / train/prior_ent_max 67.62 / train/prior_ent_mean 38.94 / train/prior_ent_min 32.06 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.41 / train/reward_avg 1.24 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
train_stats/mean_log_entropy 0.65 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.86 / report/image_loss_mean 0.21 / report/image_loss_std 0.54 / report/model_loss_mean 1.31 / report/model_loss_std 2.77 / report/post_ent_mag 56.15 / report/post_ent_max 56.15 / 
report/post_ent_mean 37.62 / report/post_ent_min 25.45 / report/post_ent_std 4.41 / report/prior_ent_mag 67.45 / report/prior_ent_max 67.45 / report/prior_ent_mean 38.94 / report/prior_ent_min 33.06 / report/prior_ent_std 5.62 / report/rep_loss_mean 1.72 / 
report/rep_loss_std 3.86 / report/reward_avg 1.1 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 1.09 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.04 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.35 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.09 / eval/post_ent_mag 55.05 / eval/post_ent_max 55.05 / eval/post_ent_mean 36.61 / eval/post_ent_min 25.2 / 
eval/post_ent_std 3.63 / eval/prior_ent_mag 67.45 / eval/prior_ent_max 67.45 / eval/prior_ent_mean 37.8 / eval/prior_ent_min 33.15 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.04 / eval/reward_avg 1.65 / eval/reward_loss_mean 0.11 / 
eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.65 / eval/reward_rate 0.83 / replay/size 4.1e5 / replay/inserts 
3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3884 / timer/env.step_total 19.24 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 400.2 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 1 / 
timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.34 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.8e-4 / 
timer/agent.train_count 1942 / timer/agent.train_total 246.37 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / 
timer/dataset_eval_max 3.6e-5 / fps 25.88

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 406000 Counter(406000) 405937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 406500 Counter(406500) 406437
Saved chunk: 20230922T062533F921218-4pKNXNIeP3mlVeAOEDtHDo-5bJmI189GHa63CzsJlZMfZ-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T062536F786720-0xEyKy4YkkzFwqOu5DSgTE-70LtFkbci7rczY8PMhZQND-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 407000 Counter(407000) 406937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 407500 Counter(407500) 407437
Saved chunk: 20230922T062653F103238-5bJmI189GHa63CzsJlZMfZ-2pfJwvRv70v6UdroLcFRRg-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T062657F552075-70LtFkbci7rczY8PMhZQND-04hBYf2ElffxNiKwzAErQj-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 408000 Counter(408000) 407937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 408500 Counter(408500) 408437
Saved chunk: 20230922T062810F932046-2pfJwvRv70v6UdroLcFRRg-3NPgFo1IBX2ElJiPLUhP4g-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T062816F902638-04hBYf2ElffxNiKwzAErQj-7Gyu3oVCb5vcsPaD8q96VK-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 409000 Counter(409000) 408937
eval_Episode has 500 steps and return 521.0.
train_Episode has 500 steps and return 727.0.
Starting evaluation at step 409500 Counter(409500) 409437
Saved chunk: 20230922T062928F725754-3NPgFo1IBX2ElJiPLUhP4g-1KaJzIYbZlmPQapGwKFiNb-1024.npz
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T062936F228375-7Gyu3oVCb5vcsPaD8q96VK-7ex0wZdDowh8yPYUq0Pcph-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 819534 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 766 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 727 / episode/reward_rate 0.73 / train/action_mag 4.37 / train/action_max 4.05 / train/action_mean 0.06 / train/action_min -4.31 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -2.55 / train/adv_mag 0.42 / train/adv_max 0.32 / train/adv_mean 1.2e-4 / train/adv_min -0.38 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 671.08 / train/extr_critic_max 671.08 / train/extr_critic_mean 622.24 / train/extr_critic_min 436.95 / train/extr_critic_std 65.5 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.86 / train/extr_return_raw_max 668.86 / train/extr_return_raw_mean 622.26 / train/extr_return_raw_min 437.98 / train/extr_return_raw_std 65.55
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.28 / train/model_loss_std 2.31 / 
train/model_opt_grad_norm 6.03 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 9443.6 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7369.79 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.05 / train/post_ent_max 55.05 / train/post_ent_mean 37.66 / train/post_ent_min 
26.52 / train/post_ent_std 4.35 / train/prior_ent_mag 67.48 / train/prior_ent_max 67.48 / train/prior_ent_mean 38.93 / train/prior_ent_min 31.85 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.46 / train/reward_avg 1.24 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.5 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 3.13 / report/image_loss_mean 0.18 / report/image_loss_std 0.23 / report/model_loss_mean 1.21 / report/model_loss_std 2.04 / report/post_ent_mag 52.86 / report/post_ent_max 52.86 / 
report/post_ent_mean 37.77 / report/post_ent_min 30.05 / report/post_ent_std 4.18 / report/prior_ent_mag 67.59 / report/prior_ent_max 67.59 / report/prior_ent_mean 38.97 / report/prior_ent_min 32.7 / report/prior_ent_std 5.49 / report/rep_loss_mean 1.59 / 
report/rep_loss_std 3.13 / report/reward_avg 1.25 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.25 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.55 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.65 / eval/post_ent_mag 52.93 / eval/post_ent_max 52.93 / eval/post_ent_mean 
36.89 / eval/post_ent_min 30.57 / eval/post_ent_std 3.86 / eval/prior_ent_mag 67.59 / eval/prior_ent_max 67.59 / eval/prior_ent_mean 38.05 / eval/prior_ent_min 32.68 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.55 / eval/reward_avg 1.51 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.51 / eval/reward_rate 0.75 / 
replay/size 4.1e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3836 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.73 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.44 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 410000 Counter(410000) 409937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 410500 Counter(410500) 410437
Saved chunk: 20230922T063046F389820-1KaJzIYbZlmPQapGwKFiNb-4T9JdmzFwV5kQSsVr5v1Ht-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T063055F426806-7ex0wZdDowh8yPYUq0Pcph-0WMr1tqOC0r8oVnEkS3NXI-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 411000 Counter(411000) 410937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 411500 Counter(411500) 411437
Saved chunk: 20230922T063205F318307-4T9JdmzFwV5kQSsVr5v1Ht-3FATg72iebW1S4Mc4xzVDD-1024.npz
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T063215F973262-0WMr1tqOC0r8oVnEkS3NXI-6nEbehC3id7VAeNbeovOK2-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 412000 Counter(412000) 411937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 412500 Counter(412500) 412437
Saved chunk: 20230922T063324F830175-3FATg72iebW1S4Mc4xzVDD-6EESgddxjCnf1anWcYvG9u-1024.npz
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T063337F009012-6nEbehC3id7VAeNbeovOK2-1t9HPvCt09EOR9IGXyf0HG-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 413000 Counter(413000) 412937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 413500 Counter(413500) 413437
Saved chunk: 20230922T063442F654760-6EESgddxjCnf1anWcYvG9u-074bKC2gA9uxtApzLLMfgx-1024.npz
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 827154 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.39 / train/action_max 4.05 / train/action_mean 0.05 / train/action_min -4.31 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -3.04 / train/adv_mag 0.46 / train/adv_max 0.33 / train/adv_mean 1.6e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.94 / train/extr_critic_max 670.94 / train/extr_critic_mean 624.23 / train/extr_critic_min 437.77 / train/extr_critic_std 64.16 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.76 / train/extr_return_raw_max 668.76 / train/extr_return_raw_mean 624.26 / train/extr_return_raw_min 438.91 / train/extr_return_raw_std 64.19
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.31 / train/model_loss_mean 1.26 / train/model_loss_std 2.26 / 
train/model_opt_grad_norm 6 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.16 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.7 / train/post_ent_max 54.7 / train/post_ent_mean 37.56 / train/post_ent_min 26.71 / train/post_ent_std 4.38 / 
train/prior_ent_mag 67.29 / train/prior_ent_max 67.29 / train/prior_ent_mean 38.81 / train/prior_ent_min 31.61 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.37 / train/reward_avg 1.26 / train/reward_loss_mean 0.08 / train/reward_loss_std 
0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.26 / train/reward_rate 0.63 / train_stats/mean_log_entropy 0.41 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 4.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.95 / report/image_loss_mean 0.19 / report/image_loss_std 0.3 / report/model_loss_mean 1.3 / report/model_loss_std 2.63 / report/post_ent_mag 51.16 / report/post_ent_max 51.16 / report/post_ent_mean 37.98 / 
report/post_ent_min 27.94 / report/post_ent_std 4.12 / report/prior_ent_mag 67.06 / report/prior_ent_max 67.06 / report/prior_ent_mean 39.22 / report/prior_ent_min 32.62 / report/prior_ent_std 5.43 / report/rep_loss_mean 1.7 / report/rep_loss_std 3.95 / report/reward_avg 
1.36 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.36 / 
report/reward_rate 0.68 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 6.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / 
eval/dyn_loss_std 2.37 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.14 / eval/model_loss_std 1.56 / eval/post_ent_mag 55.27 / eval/post_ent_max 55.27 / eval/post_ent_mean 37.1 / eval/post_ent_min 29.09 / eval/post_ent_std 4.14 / 
eval/prior_ent_mag 67.06 / eval/prior_ent_max 67.06 / eval/prior_ent_mean 38.25 / eval/prior_ent_min 32.57 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.37 / eval/reward_avg 1.45 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.13 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.45 / eval/reward_rate 0.73 / replay/size 4.1e5 / replay/inserts 3810 / replay/samples 3e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3810 / timer/env.step_total 18.78 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / 
timer/replay._sample_count 3e4 / timer/replay._sample_total 393.71 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7818 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.9e-3 / timer/dataset_train_count 1905 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1905 / timer/agent.train_total 243.88 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.8 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T063456F418659-1t9HPvCt09EOR9IGXyf0HG-2pmixqCrKeYZLIXbpEN4wO-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 414000 Counter(414000) 413937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 414500 Counter(414500) 414437
Saved chunk: 20230922T063600F467735-074bKC2gA9uxtApzLLMfgx-43ds8O3EtaaaU5XE9NrrUr-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T063616F682782-2pmixqCrKeYZLIXbpEN4wO-2zHyg2etGbFu1Ax55ujGur-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 415000 Counter(415000) 414937
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 415500 Counter(415500) 415437
Saved chunk: 20230922T063719F410815-43ds8O3EtaaaU5XE9NrrUr-3QCRzsSGjmIcAOwsk2C5gg-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T063736F275562-2zHyg2etGbFu1Ax55ujGur-4ZAZ0l2oZCJDm4GbHLqQWX-1024.npz
train_Episode has 500 steps and return 715.0.
Starting evaluation at step 416000 Counter(416000) 415937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 416500 Counter(416500) 416437
Saved chunk: 20230922T063837F239673-3QCRzsSGjmIcAOwsk2C5gg-0R0KAUPivihZcVDYS2qVfN-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T063855F639211-4ZAZ0l2oZCJDm4GbHLqQWX-3KIUOpnjdmTIgHj6TpIjyb-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 417000 Counter(417000) 416937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T063954F984718-0R0KAUPivihZcVDYS2qVfN-0000000000000000000000-641.npz
Saved chunk: 20230922T064014F881528-3KIUOpnjdmTIgHj6TpIjyb-0000000000000000000000-632.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 834918 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / train/action_mag 4.34 / train/action_max 4.02 / train/action_mean 0.04 / train/action_min -4.27 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -1.08 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean -2.8e-5 / train/adv_min -0.39 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.84 / train/extr_critic_max 670.84 / train/extr_critic_mean 623.71 / train/extr_critic_min 440.85 / train/extr_critic_std 63.68 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.6 / train/extr_return_raw_max 668.6 / train/extr_return_raw_mean 623.71 / train/extr_return_raw_min 439.66 / train/extr_return_raw_std 63.79 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.28 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.27 / train/model_loss_std 2.29 / 
train/model_opt_grad_norm 5.95 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 9293.46 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7307.69 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.88 / train/post_ent_max 54.88 / train/post_ent_mean 37.65 / train/post_ent_min 
26.69 / train/post_ent_std 4.33 / train/prior_ent_mag 67.11 / train/prior_ent_max 67.11 / train/prior_ent_mean 38.9 / train/prior_ent_min 31.55 / train/prior_ent_std 5.7 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.41 / train/reward_avg 1.25 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.25 / train/reward_rate 0.63 / 
train_stats/mean_log_entropy 0.49 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 8.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.78 / report/dyn_loss_std 3.59 / report/image_loss_mean 0.22 / report/image_loss_std 0.22 / report/model_loss_mean 1.34 / report/model_loss_std 2.28 / report/post_ent_mag 52.91 / report/post_ent_max 52.91 / 
report/post_ent_mean 38.87 / report/post_ent_min 11.92 / report/post_ent_std 5.12 / report/prior_ent_mag 67.17 / report/prior_ent_max 67.17 / report/prior_ent_mean 40.22 / report/prior_ent_min 32.6 / report/prior_ent_std 6.16 / report/rep_loss_mean 1.78 / 
report/rep_loss_std 3.59 / report/reward_avg 0.93 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.93 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.95 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.18 / eval/model_loss_std 1.94 / eval/post_ent_mag 54.02 / eval/post_ent_max 54.02 / eval/post_ent_mean 
37.76 / eval/post_ent_min 29.53 / eval/post_ent_std 4.05 / eval/prior_ent_mag 67.17 / eval/prior_ent_max 67.17 / eval/prior_ent_mean 38.83 / eval/prior_ent_min 32.13 / eval/prior_ent_std 5.53 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.95 / eval/reward_avg 1.43 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.43 / eval/reward_rate 0.72 / 
replay/size 4.2e5 / replay/inserts 3882 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3882 / timer/env.step_total 19.23 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.22 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7389 / timer/agent.policy_total 16.18 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1941 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1941 / timer/agent.train_total 246.43 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.87

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 417500 Counter(417500) 417437
Saved chunk: 20230922T063954F984718-0R0KAUPivihZcVDYS2qVfN-47qTj7lp5ZXHmo6ncydcaZ-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T064014F881528-3KIUOpnjdmTIgHj6TpIjyb-0kNpnpnQFfCR7YMpjDa6P3-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 418000 Counter(418000) 417937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 418500 Counter(418500) 418437
Saved chunk: 20230922T064113F878613-47qTj7lp5ZXHmo6ncydcaZ-7bYLqBcmiWWxCyAiMxrZI0-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T064135F585569-0kNpnpnQFfCR7YMpjDa6P3-2GvD9ITZ28TpajPc4JTU2w-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 419000 Counter(419000) 418937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 419500 Counter(419500) 419437
Saved chunk: 20230922T064232F060469-7bYLqBcmiWWxCyAiMxrZI0-2JnjJi2uUBhKzL8Mc6Yxqm-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T064255F089533-2GvD9ITZ28TpajPc4JTU2w-7Et5jvpx1kQYR0t2Rqz498-1024.npz
Starting evaluation at step 420000 Counter(420000) 419937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 420500 Counter(420500) 420437
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T064349F737883-2JnjJi2uUBhKzL8Mc6Yxqm-5Odc6jO5w6ji4QdnlTo1M2-1024.npz
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T064414F338416-7Et5jvpx1kQYR0t2Rqz498-12fCVq1av520C3EqnKuwft-1024.npz
Starting evaluation at step 421000 Counter(421000) 420937
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 842594 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.43 / train/action_max 4.15 / train/action_mean 0.05 / train/action_min -4.35 / train/action_std 1.08 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -3.84 / train/adv_mag 0.42 / train/adv_max 0.33 / train/adv_mean 2.5e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.72 / train/extr_critic_max 670.72 / train/extr_critic_mean 623.87 / train/extr_critic_min 431.38 / train/extr_critic_std 64.07 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.75 / train/extr_return_raw_max 668.75 / train/extr_return_raw_mean 623.91 / train/extr_return_raw_min 433.24 / train/extr_return_raw_std 64.13
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.28 / train/model_loss_std 2.3 / 
train/model_opt_grad_norm 5.82 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 9579.67 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7513.09 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.93 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.93 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 9.5e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.96 / train/post_ent_max 54.96 / train/post_ent_mean 37.7 / train/post_ent_min 
26.42 / train/post_ent_std 4.36 / train/prior_ent_mag 67.24 / train/prior_ent_max 67.24 / train/prior_ent_mean 38.96 / train/prior_ent_min 31.78 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.42 / train/reward_avg 1.24 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.44 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.51 / report/dyn_loss_std 2.7 / report/image_loss_mean 0.17 / report/image_loss_std 0.24 / report/model_loss_mean 1.17 / report/model_loss_std 1.81 / report/post_ent_mag 53.69 / report/post_ent_max 53.69 / 
report/post_ent_mean 36.29 / report/post_ent_min 25.33 / report/post_ent_std 4.38 / report/prior_ent_mag 67.52 / report/prior_ent_max 67.52 / report/prior_ent_mean 37.43 / report/prior_ent_min 32.66 / report/prior_ent_std 5.86 / report/rep_loss_mean 1.51 / 
report/rep_loss_std 2.7 / report/reward_avg 1.56 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.7e-7 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 1.56 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 4.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.84 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.94 / eval/post_ent_mag 55.97 / eval/post_ent_max 55.97 / eval/post_ent_mean 38.22 / eval/post_ent_min 30.63 / 
eval/post_ent_std 3.93 / eval/prior_ent_mag 67.52 / eval/prior_ent_max 67.52 / eval/prior_ent_mean 39.37 / eval/prior_ent_min 32.59 / eval/prior_ent_std 5.48 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.84 / eval/reward_avg 1.28 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.28 / eval/reward_rate 0.64 / replay/size 4.2e5 / replay/inserts 
3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3838 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.53 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 7e-3 / timer/dataset_train_count 
1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 8.1e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.52 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 421500 Counter(421500) 421437
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T064507F420025-5Odc6jO5w6ji4QdnlTo1M2-6WS57W8WtnXGcxG9HXCzUH-1024.npz
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T064533F511937-12fCVq1av520C3EqnKuwft-4rOkVTEj6X9yubgbWxGPeo-1024.npz
Starting evaluation at step 422000 Counter(422000) 421937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 422500 Counter(422500) 422437
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T064626F114813-6WS57W8WtnXGcxG9HXCzUH-4PpmWK7gYk2HpuPyJl9p3G-1024.npz
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T064654F065919-4rOkVTEj6X9yubgbWxGPeo-3SM4IGc7ZR1LpWBkkoFlUh-1024.npz
Starting evaluation at step 423000 Counter(423000) 422937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 758.0.
Starting evaluation at step 423500 Counter(423500) 423437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T064813F587581-3SM4IGc7ZR1LpWBkkoFlUh-3Cn1DJXyUUg4T1NEqMSmCE-1024.npz
Starting evaluation at step 424000 Counter(424000) 423937
Saved chunk: 20230922T064744F291209-4PpmWK7gYk2HpuPyJl9p3G-0QYmq0eP5g8OdZdrUUvqJj-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 424500 Counter(424500) 424437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T064932F894208-3Cn1DJXyUUg4T1NEqMSmCE-6T84PTl9TGtVzWTUnIM0U6-1024.npz
Starting evaluation at step 425000 Counter(425000) 424937
Saved chunk: 20230922T064937F532893-0QYmq0eP5g8OdZdrUUvqJj-1vi1Qkovmt1mj6Aw7omlMK-1024.npz
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 850258 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.4 / train/action_max 4.12 / train/action_mean 0.04 / train/action_min -4.32 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -3.09 / train/adv_mag 0.45 / train/adv_max 0.32 / train/adv_mean 1.7e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.83 / train/extr_critic_max 670.83 / train/extr_critic_mean 624.61 / train/extr_critic_min 439.09 / train/extr_critic_std 62.67 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.32 / train/extr_return_raw_max 669.32 / train/extr_return_raw_mean 624.64 / train/extr_return_raw_min 441.63 / train/extr_return_raw_std 62.72
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.31 / train/model_loss_mean 1.25 / train/model_loss_std 2.24 / 
train/model_opt_grad_norm 6.21 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8802.08 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.46 / train/post_ent_max 55.46 / train/post_ent_mean 37.57 / train/post_ent_min 
26.91 / train/post_ent_std 4.36 / train/prior_ent_mag 67.3 / train/prior_ent_max 67.3 / train/prior_ent_mean 38.81 / train/prior_ent_min 31.7 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.35 / train/reward_avg 1.26 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.26 / train/reward_rate 0.63 / 
train_stats/mean_log_entropy 0.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.8 / report/dyn_loss_std 4.26 / report/image_loss_mean 0.22 / report/image_loss_std 0.38 / report/model_loss_mean 1.37 / report/model_loss_std 2.87 / report/post_ent_mag 55.8 / report/post_ent_max 55.8 / 
report/post_ent_mean 37.61 / report/post_ent_min 25.41 / report/post_ent_std 4.56 / report/prior_ent_mag 67.1 / report/prior_ent_max 67.1 / report/prior_ent_mean 38.96 / report/prior_ent_min 27.2 / report/prior_ent_std 5.88 / report/rep_loss_mean 1.8 / report/rep_loss_std
4.26 / report/reward_avg 1.2 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / 
report/reward_pred 1.2 / report/reward_rate 0.6 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 3.13 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.17 / eval/model_loss_std 2.02 / eval/post_ent_mag 55.09 / eval/post_ent_max 55.09 / eval/post_ent_mean 38.57 / eval/post_ent_min 30.67 / 
eval/post_ent_std 3.86 / eval/prior_ent_mag 67.1 / eval/prior_ent_max 67.1 / eval/prior_ent_mean 39.67 / eval/prior_ent_min 32.75 / eval/prior_ent_std 5.3 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 3.13 / eval/reward_avg 1.26 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.26 / eval/reward_rate 0.63 / replay/size 4.3e5 / replay/inserts 3832 /
replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3832 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.13 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 
1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.67 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 425500 Counter(425500) 425437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 757.0.
Saved chunk: 20230922T065052F257193-6T84PTl9TGtVzWTUnIM0U6-2zhR9iBjt0yWJMK3bfGgvF-1024.npz
Starting evaluation at step 426000 Counter(426000) 425937
Saved chunk: 20230922T065055F328872-1vi1Qkovmt1mj6Aw7omlMK-3BnkNsu6bBOIsJZjyOK5rZ-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 426500 Counter(426500) 426437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 427000 Counter(427000) 426937
Saved chunk: 20230922T065214F363371-3BnkNsu6bBOIsJZjyOK5rZ-4nAferDFNT65UBMKy4UScb-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T065212F839278-2zhR9iBjt0yWJMK3bfGgvF-1lyQaZ71K8wEPzkPwBED8Z-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 427500 Counter(427500) 427437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 428000 Counter(428000) 427937
Saved chunk: 20230922T065332F286052-4nAferDFNT65UBMKy4UScb-3O4V6mlIJzBFYDfwHezAfQ-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T065335F713991-1lyQaZ71K8wEPzkPwBED8Z-3yNPEOSCTk7NYAsDUhO4Zs-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 428500 Counter(428500) 428437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 769.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 429000 Counter(429000) 428937
Saved chunk: 20230922T065455F013470-3yNPEOSCTk7NYAsDUhO4Zs-0000000000000000000000-968.npz
Saved chunk: 20230922T065450F047097-3O4V6mlIJzBFYDfwHezAfQ-0000000000000000000000-900.npz
Saved chunk: 20230922T065450F047097-3O4V6mlIJzBFYDfwHezAfQ-7zu89nRBf5FWYmz0OnKPyI-1024.npz
eval_Episode has 500 steps and return 765.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 858002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 765 / eval_episode/reward_rate 0.77 / train/action_mag 4.42 / train/action_max 4.07 / train/action_mean 0.05 / train/action_min -4.33 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -2.25 / train/adv_mag 0.43 / train/adv_max 0.33 / train/adv_mean 9.9e-5 / train/adv_min -0.38 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.38 / train/extr_critic_max 671.38 / train/extr_critic_mean 623.65 / train/extr_critic_min 447.37 / train/extr_critic_std 63.41 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.84 / train/extr_return_raw_max 669.84 / train/extr_return_raw_mean 623.67 / train/extr_return_raw_min 445.77 / train/extr_return_raw_std 63.5 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.26 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.27 / train/model_loss_std 2.29 / 
train/model_opt_grad_norm 6.06 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8608.25 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.87 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.87 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 9.4e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.1 / train/post_ent_max 55.1 / train/post_ent_mean 37.7 / train/post_ent_min 
26.41 / train/post_ent_std 4.35 / train/prior_ent_mag 67.09 / train/prior_ent_max 67.09 / train/prior_ent_mean 38.96 / train/prior_ent_min 31.52 / train/prior_ent_std 5.7 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.42 / train/reward_avg 1.23 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.23 / train/reward_rate 0.62 / 
train_stats/mean_log_entropy 0.36 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 2.79 / report/image_loss_mean 0.18 / report/image_loss_std 0.2 / report/model_loss_mean 1.17 / report/model_loss_std 1.8 / report/post_ent_mag 58.98 / report/post_ent_max 58.98 / 
report/post_ent_mean 37.96 / report/post_ent_min 28.74 / report/post_ent_std 4.75 / report/prior_ent_mag 67.37 / report/prior_ent_max 67.37 / report/prior_ent_mean 39.07 / report/prior_ent_min 32.3 / report/prior_ent_std 5.95 / report/rep_loss_mean 1.53 / 
report/rep_loss_std 2.79 / report/reward_avg 1.17 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.17 / report/reward_rate 0.59 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.86 / eval/post_ent_mag 54.75 / eval/post_ent_max 54.75 / eval/post_ent_mean 
37.15 / eval/post_ent_min 27.81 / eval/post_ent_std 4.33 / eval/prior_ent_mag 67.37 / eval/prior_ent_max 67.37 / eval/prior_ent_mean 38.14 / eval/prior_ent_min 32.28 / eval/prior_ent_std 5.8 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.75 / eval/reward_avg 1.44 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.44 / eval/reward_rate 0.72 / 
replay/size 4.3e5 / replay/inserts 3872 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.02 / timer/env.step_count 3872 / timer/env.step_total 19.26 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.51 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7880 / timer/agent.policy_total 17.37 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1936 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1936 / timer/agent.train_total 245.73 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T065455F013470-3yNPEOSCTk7NYAsDUhO4Zs-0cIXOP1wIT59HojLrZXMBe-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 429500 Counter(429500) 429437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 430000 Counter(430000) 429937
Saved chunk: 20230922T065607F778742-7zu89nRBf5FWYmz0OnKPyI-7gAy2CenS9OMPa7xouMMGF-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T065615F444078-0cIXOP1wIT59HojLrZXMBe-6iGhV0gn4fMZ8aKusZIg3g-1024.npz
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 430500 Counter(430500) 430437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 431000 Counter(431000) 430937
Saved chunk: 20230922T065727F070541-7gAy2CenS9OMPa7xouMMGF-3WeGBA18pbQAeVGvlFWmgs-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T065735F110371-6iGhV0gn4fMZ8aKusZIg3g-0LIz1g0dBlP3GToChWYC3W-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 431500 Counter(431500) 431437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 432000 Counter(432000) 431937
Saved chunk: 20230922T065844F854121-3WeGBA18pbQAeVGvlFWmgs-45v5W6p1Y3hWwQ4WYT6pfR-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T065854F450889-0LIz1g0dBlP3GToChWYC3W-1VuYiZLkV3hQFJEZxZ3fmh-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 432500 Counter(432500) 432437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 758.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 865774 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 758 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / train/action_mag 4.42 / train/action_max 4.11 / train/action_mean 0.05 / train/action_min -4.34 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.1 / train/adv_mag 0.43 / train/adv_max 0.33 / train/adv_mean 2.7e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.84 / train/extr_critic_max 671.84 / train/extr_critic_mean 625.83 / train/extr_critic_min 448.81 / train/extr_critic_std 62.22 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.88 / train/extr_return_raw_max 669.88 / train/extr_return_raw_mean 625.88 / train/extr_return_raw_min 448.13 / train/extr_return_raw_std 62.28
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.28 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.31 / train/model_loss_mean 1.25 / train/model_loss_std 2.22 / 
train/model_opt_grad_norm 6.1 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean
0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.17 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.77 / train/post_ent_max 54.77 / train/post_ent_mean 37.61 / train/post_ent_min 27.07 / train/post_ent_std 4.39 
/ train/prior_ent_mag 67.21 / train/prior_ent_max 67.21 / train/prior_ent_mean 38.85 / train/prior_ent_min 31.5 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.32 / train/reward_avg 1.25 / train/reward_loss_mean 0.08 / train/reward_loss_std 
0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.25 / train/reward_rate 0.63 / train_stats/mean_log_entropy 0.58 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.6 / report/dyn_loss_std 3.38 / report/image_loss_mean 0.19 / report/image_loss_std 0.32 / report/model_loss_mean 1.24 / report/model_loss_std 2.29 / report/post_ent_mag 53.57 / report/post_ent_max 53.57 / report/post_ent_mean 37.57 / 
report/post_ent_min 29.01 / report/post_ent_std 4.72 / report/prior_ent_mag 66.97 / report/prior_ent_max 66.97 / report/prior_ent_mean 38.74 / report/prior_ent_min 31.94 / report/prior_ent_std 6.06 / report/rep_loss_mean 1.6 / report/rep_loss_std 3.38 / report/reward_avg 
1.35 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 3.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.35 / 
report/reward_rate 0.68 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 5.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / 
eval/dyn_loss_std 2.65 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.75 / eval/post_ent_mag 52.85 / eval/post_ent_max 52.85 / eval/post_ent_mean 37.82 / eval/post_ent_min 29.54 / eval/post_ent_std 4.15 / 
eval/prior_ent_mag 66.97 / eval/prior_ent_max 66.97 / eval/prior_ent_mean 38.91 / eval/prior_ent_min 31.96 / eval/prior_ent_std 5.55 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.65 / eval/reward_avg 1.34 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.18 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.34 / eval/reward_rate 0.67 / replay/size 4.3e5 / replay/inserts 3886 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3886 / timer/env.step_total 19.09 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 3.9e-3 / timer/env.step_max 6.8e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.81 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.06 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1943 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1943 / timer/agent.train_total 247 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.9e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.9e-5 / timer/dataset_eval_min 4.9e-5 / timer/dataset_eval_max 4.9e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 433000 Counter(433000) 432937
Saved chunk: 20230922T070002F541050-45v5W6p1Y3hWwQ4WYT6pfR-33Y6G6X4UNIpVbZ0xrtVZb-1024.npz
eval_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T070013F591919-1VuYiZLkV3hQFJEZxZ3fmh-7obdsW2xKmlItUvOXY9zzQ-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 433500 Counter(433500) 433437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 434000 Counter(434000) 433937
Saved chunk: 20230922T070121F189929-33Y6G6X4UNIpVbZ0xrtVZb-6G442Lf55F5f0jvp7Dyuvi-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T070133F998511-7obdsW2xKmlItUvOXY9zzQ-4cZoCIjs7BgO5cFeCKgVfu-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 434500 Counter(434500) 434437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 435000 Counter(435000) 434937
Saved chunk: 20230922T070239F318906-6G442Lf55F5f0jvp7Dyuvi-0PlriNUDGR56fbGoBdQCNs-1024.npz
eval_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T070253F621051-4cZoCIjs7BgO5cFeCKgVfu-6rXE6TilLGmESH57xhzIfk-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 435500 Counter(435500) 435437
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 436000 Counter(436000) 435937
Saved chunk: 20230922T070357F218410-0PlriNUDGR56fbGoBdQCNs-497Y1wmJ8ueV27tWKiZFbT-1024.npz
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T070413F032532-6rXE6TilLGmESH57xhzIfk-4c1jtqdJiAnJ03D1AWQ1aQ-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 436500 Counter(436500) 436437
eval_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 873436 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.36 / train/action_max 4.18 / train/action_mean 0.05 / train/action_min -4.2 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -0.67 / train/adv_mag 0.44 / train/adv_max 0.32 / train/adv_mean -4.9e-5 / train/adv_min -0.39 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.22 / train/extr_critic_max 671.22 / train/extr_critic_mean 625.88 / train/extr_critic_min 445.74 / train/extr_critic_std 61.26 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.67 / train/extr_return_raw_max 669.67 / train/extr_return_raw_mean 625.87 / train/extr_return_raw_min 446.7 / train/extr_return_raw_std 61.32 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.26 / train/model_loss_std 2.26 / 
train/model_opt_grad_norm 5.99 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9764.4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.71 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.39 / train/policy_logprob_min -8.71 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.85 / train/post_ent_max 54.85 / train/post_ent_mean 37.61 / train/post_ent_min 
26.96 / train/post_ent_std 4.44 / train/prior_ent_mag 67.05 / train/prior_ent_max 67.05 / train/prior_ent_mean 38.84 / train/prior_ent_min 31.43 / train/prior_ent_std 5.78 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.39 / train/reward_avg 1.24 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.63 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.7 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.72 / report/image_loss_mean 0.18 / report/image_loss_std 0.33 / report/model_loss_mean 1.18 / report/model_loss_std 1.87 / report/post_ent_mag 59.45 / report/post_ent_max 59.45 / 
report/post_ent_mean 36.23 / report/post_ent_min 27.86 / report/post_ent_std 4.35 / report/prior_ent_mag 66.65 / report/prior_ent_max 66.65 / report/prior_ent_mean 37.35 / report/prior_ent_min 31.73 / report/prior_ent_std 5.8 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 2.72 / report/reward_avg 1.48 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.48 / report/reward_rate 0.74 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 8.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.67 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.77 / eval/post_ent_mag 51.2 / eval/post_ent_max 51.2 / eval/post_ent_mean 
36.64 / eval/post_ent_min 30.27 / eval/post_ent_std 3.61 / eval/prior_ent_mag 66.65 / eval/prior_ent_max 66.65 / eval/prior_ent_mean 37.58 / eval/prior_ent_min 32.12 / eval/prior_ent_std 5.12 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.67 / eval/reward_avg 1.71 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.71 / eval/reward_rate 0.85 / 
replay/size 4.4e5 / replay/inserts 3831 / replay/samples 3.1e4 / replay/insert_wait_avg 3.4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3831 / timer/env.step_total 18.83 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.86 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7839 / timer/agent.policy_total 17.21 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.5 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 437000 Counter(437000) 436937
Saved chunk: 20230922T070515F015409-497Y1wmJ8ueV27tWKiZFbT-17DGRsAM8lHohsGV4P1MOe-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T070532F363286-4c1jtqdJiAnJ03D1AWQ1aQ-3FVeUvMqmXljnQFk0K3Rog-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 437500 Counter(437500) 437437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 438000 Counter(438000) 437937
Saved chunk: 20230922T070633F893250-17DGRsAM8lHohsGV4P1MOe-5gehz1WPOtePolJWGzKm9y-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T070652F927880-3FVeUvMqmXljnQFk0K3Rog-2exotJVlVn3yKVl1cFXpjw-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 438500 Counter(438500) 438437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 439000 Counter(439000) 438937
Saved chunk: 20230922T070751F949985-5gehz1WPOtePolJWGzKm9y-2YyH462CuLAeD6QJ4GnW77-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T070812F504151-2exotJVlVn3yKVl1cFXpjw-46N9kkhKJjK4CWrDtBXHqz-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 439500 Counter(439500) 439437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 440000 Counter(440000) 439937
Saved chunk: 20230922T070909F856558-2YyH462CuLAeD6QJ4GnW77-1G0BULwpSZLQSCquKRKSpX-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T070931F914562-46N9kkhKJjK4CWrDtBXHqz-3YAEKpYMQ0bkR2FR1dhVG0-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 440500 Counter(440500) 440437
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 881102 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.44 / train/action_max 4.17 / train/action_mean 0.05 / train/action_min -4.32 / train/action_std 1.06 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -0.83 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean -5.6e-5 / train/adv_min -0.38 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.78 / train/extr_critic_max 670.78 / train/extr_critic_mean 626.15 / train/extr_critic_min 449.66 / train/extr_critic_std 61.37 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.82 / train/extr_return_raw_max 669.82 / train/extr_return_raw_mean 626.14 / train/extr_return_raw_min 449.76 / train/extr_return_raw_std 61.46
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.3 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.25 / train/model_loss_std 2.21 / 
train/model_opt_grad_norm 5.81 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 9265.49 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.88 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -8.88 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 55.26 / train/post_ent_max 55.26 / train/post_ent_mean 37.52 / train/post_ent_min
26.98 / train/post_ent_std 4.42 / train/prior_ent_mag 66.92 / train/prior_ent_max 66.92 / train/prior_ent_mean 38.74 / train/prior_ent_min 31.25 / train/prior_ent_std 5.76 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.31 / train/reward_avg 1.27 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.52 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.58 / report/image_loss_mean 0.18 / report/image_loss_std 0.27 / report/model_loss_mean 1.26 / report/model_loss_std 2.36 / report/post_ent_mag 51.88 / report/post_ent_max 51.88 / 
report/post_ent_mean 37.4 / report/post_ent_min 19.54 / report/post_ent_std 4.48 / report/prior_ent_mag 66.91 / report/prior_ent_max 66.91 / report/prior_ent_mean 38.61 / report/prior_ent_min 31.88 / report/prior_ent_std 5.83 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 3.58 / report/reward_avg 1.29 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.29 / report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.81 / eval/post_ent_mag 54.65 / eval/post_ent_max 54.65 / eval/post_ent_mean 36.69 / 
eval/post_ent_min 28.05 / eval/post_ent_std 3.54 / eval/prior_ent_mag 66.91 / eval/prior_ent_max 66.91 / eval/prior_ent_mean 37.73 / eval/prior_ent_min 32.22 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.75 / eval/reward_avg 1.7 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 1.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.7 / eval/reward_rate 0.85 / 
replay/size 4.4e5 / replay/inserts 3833 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3833 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.97 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7841 / timer/agent.policy_total 17.02 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.7e-3 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.34 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T071050F956713-3YAEKpYMQ0bkR2FR1dhVG0-0000000000000000000000-280.npz
Saved chunk: 20230922T071027F451699-1G0BULwpSZLQSCquKRKSpX-0000000000000000000000-636.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 441000 Counter(441000) 440937
Saved chunk: 20230922T071027F451699-1G0BULwpSZLQSCquKRKSpX-30fjEPjj2zxcDB2ulPKj7N-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T071050F956713-3YAEKpYMQ0bkR2FR1dhVG0-6Bp9MVXrOphX8uVtdPpSUZ-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 441500 Counter(441500) 441437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 757.0.
Starting evaluation at step 442000 Counter(442000) 441937
Saved chunk: 20230922T071146F482268-30fjEPjj2zxcDB2ulPKj7N-1UX9EZ1RdGHuDj0wHScZB7-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T071211F688000-6Bp9MVXrOphX8uVtdPpSUZ-40UknlKVTs0UQ9DoEhzC0e-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 442500 Counter(442500) 442437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 443000 Counter(443000) 442937
Saved chunk: 20230922T071304F398392-1UX9EZ1RdGHuDj0wHScZB7-0xQylU0r0rY7XEyJjId35A-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T071331F082904-40UknlKVTs0UQ9DoEhzC0e-10P2Dqgr7Yg9BWyZZ34aVe-1024.npz
Starting evaluation at step 443500 Counter(443500) 443437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 444000 Counter(444000) 443937
Saved chunk: 20230922T071422F154417-0xQylU0r0rY7XEyJjId35A-5r2E5Jy3wMcWOEIjavaRK0-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T071450F396365-10P2Dqgr7Yg9BWyZZ34aVe-6Fs3MGBy1mynzBtD2YFWyx-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 888866 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 764 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 769 / eval_episode/reward_rate 0.77 / train/action_mag 4.35 / train/action_max 3.81 / train/action_mean 0.03 / train/action_min -4.32 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -4.65 / train/adv_mag 0.43 / train/adv_max 0.32 / train/adv_mean 3.5e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.02 / train/extr_critic_max 672.02 / train/extr_critic_mean 627.02 / train/extr_critic_min 446.05 / train/extr_critic_std 62.27 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.38 / train/extr_return_raw_max 670.38 / train/extr_return_raw_mean 627.08 / train/extr_return_raw_min 445.87 / train/extr_return_raw_std 62.35
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.31 / train/model_loss_mean 1.25 / train/model_loss_std 2.23 / 
train/model_opt_grad_norm 6.03 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 9578.58 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7654.64 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.42 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 54.8 / train/post_ent_max 54.8 / train/post_ent_mean 37.56 / train/post_ent_min 
26.58 / train/post_ent_std 4.39 / train/prior_ent_mag 67.02 / train/prior_ent_max 67.02 / train/prior_ent_mean 38.79 / train/prior_ent_min 31.3 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.34 / train/reward_avg 1.26 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.26 / train/reward_rate 0.63 / 
train_stats/mean_log_entropy 0.48 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.07 / report/image_loss_mean 0.17 / report/image_loss_std 0.21 / report/model_loss_mean 1.22 / report/model_loss_std 1.99 / report/post_ent_mag 59.32 / report/post_ent_max 59.32 / 
report/post_ent_mean 37.63 / report/post_ent_min 28.7 / report/post_ent_std 4.25 / report/prior_ent_mag 66.78 / report/prior_ent_max 66.78 / report/prior_ent_mean 38.81 / report/prior_ent_min 30.58 / report/prior_ent_std 5.57 / report/rep_loss_mean 1.61 / 
report/rep_loss_std 3.07 / report/reward_avg 1.21 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.21 / report/reward_rate 0.61 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 8.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.32 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.53 / eval/post_ent_mag 53.03 / eval/post_ent_max 53.03 / eval/post_ent_mean 37.21 / eval/post_ent_min 30.98 / 
eval/post_ent_std 3.77 / eval/prior_ent_mag 66.78 / eval/prior_ent_max 66.78 / eval/prior_ent_mean 38.26 / eval/prior_ent_min 32.13 / eval/prior_ent_std 5.35 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.32 / eval/reward_avg 1.56 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.56 / eval/reward_rate 0.78 / replay/size 4.4e5 / replay/inserts 3882 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3882 / timer/env.step_total 19.13 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.06 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7389 / timer/agent.policy_total 16.25 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1941 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / 
timer/agent.train_count 1941 / timer/agent.train_total 246.36 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / 
timer/dataset_eval_max 3.2e-5 / fps 25.88

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 444500 Counter(444500) 444437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 445000 Counter(445000) 444937
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T071539F844580-5r2E5Jy3wMcWOEIjavaRK0-556qIY8t4NebOwToBvo6TU-1024.npz
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T071609F525024-6Fs3MGBy1mynzBtD2YFWyx-1UafoTZED6A3CEFvIfc9yN-1024.npz
Starting evaluation at step 445500 Counter(445500) 445437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 446000 Counter(446000) 445937
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T071658F748129-556qIY8t4NebOwToBvo6TU-2KOGjzzPb9vEYIlndTOVV5-1024.npz
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T071730F221177-1UafoTZED6A3CEFvIfc9yN-3jh0iUOb9OaO94AI1bEb9t-1024.npz
Starting evaluation at step 446500 Counter(446500) 446437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 447000 Counter(447000) 446937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T071849F599094-3jh0iUOb9OaO94AI1bEb9t-6IfvmDWKsxIBT3imMml21z-1024.npz
Starting evaluation at step 447500 Counter(447500) 447437
Saved chunk: 20230922T071816F671032-2KOGjzzPb9vEYIlndTOVV5-07hdM3l7jsL2UqmWDngBjM-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 448000 Counter(448000) 447937
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 896534 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / train/action_mag 4.39 / train/action_max 4.23 / train/action_mean 0.05 / train/action_min -4.22 / train/action_std 1.08 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -1.89 / train/adv_mag 0.41 / train/adv_max 0.31 / train/adv_mean 3.2e-5 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.78 / train/extr_critic_max 671.78 / train/extr_critic_mean 625.34 / train/extr_critic_min 445.88 / train/extr_critic_std 62.52 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.49 / train/extr_return_raw_max 669.49 / train/extr_return_raw_mean 625.35 / train/extr_return_raw_min 445.5 / train/extr_return_raw_std 62.52 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.28 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.26 / train/model_loss_std 2.22 / 
train/model_opt_grad_norm 6.01 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9479.17 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.54 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.98 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.54 / train/policy_logprob_min -8.98 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.62 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.92 / train/post_ent_max 54.92 / train/post_ent_mean 37.59 / train/post_ent_min 
26.69 / train/post_ent_std 4.39 / train/prior_ent_mag 66.91 / train/prior_ent_max 66.91 / train/prior_ent_mean 38.83 / train/prior_ent_min 31.31 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.33 / train/reward_avg 1.26 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.25 / train/reward_rate 0.63 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.69 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 5.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 3.31 / report/image_loss_mean 0.17 / report/image_loss_std 0.3 / report/model_loss_mean 1.16 / report/model_loss_std 2.17 / report/post_ent_mag 59.26 / report/post_ent_max 59.26 / 
report/post_ent_mean 38.09 / report/post_ent_min 27.18 / report/post_ent_std 3.96 / report/prior_ent_mag 66.77 / report/prior_ent_max 66.77 / report/prior_ent_mean 39.15 / report/prior_ent_min 32.38 / report/prior_ent_std 5.28 / report/rep_loss_mean 1.53 / 
report/rep_loss_std 3.31 / report/reward_avg 1.23 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.24 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / eval/cont_loss_std 6.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 3.08 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.1 / eval/post_ent_mag 55.61 / eval/post_ent_max 55.61 / eval/post_ent_mean 
38.17 / eval/post_ent_min 30.03 / eval/post_ent_std 4.05 / eval/prior_ent_mag 66.77 / eval/prior_ent_max 66.77 / eval/prior_ent_mean 39.35 / eval/prior_ent_min 32.23 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 3.08 / eval/reward_avg 1.29 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 1.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.29 / eval/reward_rate 0.65 / 
replay/size 4.5e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3834 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.5 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.27 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 448500 Counter(448500) 448437
Saved chunk: 20230922T072009F902196-07hdM3l7jsL2UqmWDngBjM-2hjQCKfotFIxTZ2o1DZ5O9-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T072008F918570-6IfvmDWKsxIBT3imMml21z-165rQ7QVn6pDsXRfgNdxuW-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 449000 Counter(449000) 448937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 449500 Counter(449500) 449437
Saved chunk: 20230922T072128F684791-2hjQCKfotFIxTZ2o1DZ5O9-2H3fzeKtDSHFbzuhmX5xcB-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T072132F695701-165rQ7QVn6pDsXRfgNdxuW-0gwGqoI9dmqBK285AE4fTl-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 450000 Counter(450000) 449937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 450500 Counter(450500) 450437
Saved chunk: 20230922T072246F749149-2H3fzeKtDSHFbzuhmX5xcB-0Zqh6sfETLFDFzogKuW4pN-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T072252F267943-0gwGqoI9dmqBK285AE4fTl-4yst28vf4FYynSbkkwll5i-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 451000 Counter(451000) 450937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 451500 Counter(451500) 451437
Saved chunk: 20230922T072404F518835-0Zqh6sfETLFDFzogKuW4pN-1NGPXlz4jvXrkGTyyQDVtg-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T072411F573175-4yst28vf4FYynSbkkwll5i-5UfuUVcH8DUXl1pKt6kqQ5-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 452000 Counter(452000) 451937
eval_Episode has 500 steps and return 768.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 904202 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 768 / eval_episode/reward_rate 0.77 / train/action_mag 4.36 / train/action_max 4.16 / train/action_mean 0.04 / train/action_min -4.21 / train/action_std 1.06 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -3.12 / train/adv_mag 0.43 / train/adv_max 0.32 / train/adv_mean 1.6e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.61 / train/extr_critic_max 670.61 / train/extr_critic_mean 627.01 / train/extr_critic_min 449.61 / train/extr_critic_std 60.64 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.94 / train/extr_return_raw_max 668.94 / train/extr_return_raw_mean 627.04 / train/extr_return_raw_min 450.17 / train/extr_return_raw_std 60.66
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.3 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.25 / train/model_loss_std 2.2 / 
train/model_opt_grad_norm 5.72 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 8170.29 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6536.46 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.84 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.51 / train/policy_logprob_min -8.84 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.83 / train/post_ent_max 54.83 / train/post_ent_mean 37.5 / train/post_ent_min 
26.77 / train/post_ent_std 4.38 / train/prior_ent_mag 66.88 / train/prior_ent_max 66.88 / train/prior_ent_mean 38.72 / train/prior_ent_min 31.38 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.29 / train/reward_avg 1.27 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.75 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.64 / report/image_loss_mean 0.21 / report/image_loss_std 0.39 / report/model_loss_mean 1.28 / report/model_loss_std 2.49 / report/post_ent_mag 57.85 / report/post_ent_max 57.85 / 
report/post_ent_mean 37.12 / report/post_ent_min 24.46 / report/post_ent_std 4.12 / report/prior_ent_mag 67.07 / report/prior_ent_max 67.07 / report/prior_ent_mean 38.35 / report/prior_ent_min 31.29 / report/prior_ent_std 5.39 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.64 / report/reward_avg 1.26 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.26 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.5 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.13 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.59 / eval/post_ent_mag 52.86 / eval/post_ent_max 52.86 / eval/post_ent_mean 
36.26 / eval/post_ent_min 30.82 / eval/post_ent_std 3.57 / eval/prior_ent_mag 67.07 / eval/prior_ent_max 67.07 / eval/prior_ent_mean 37.21 / eval/prior_ent_min 32.05 / eval/prior_ent_std 5.19 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.5 / eval/reward_avg 1.73 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.73 / eval/reward_rate 0.86 / replay/size 
4.5e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3834 / timer/env.step_total 19.02 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.34 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.8e-3 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.34 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T072522F173696-1NGPXlz4jvXrkGTyyQDVtg-0000000000000000000000-895.npz
Saved chunk: 20230922T072530F812726-5UfuUVcH8DUXl1pKt6kqQ5-0000000000000000000000-616.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 452500 Counter(452500) 452437
Saved chunk: 20230922T072522F173696-1NGPXlz4jvXrkGTyyQDVtg-2hsdLE34lhTgmAzbkeZYpw-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T072530F812726-5UfuUVcH8DUXl1pKt6kqQ5-5vZTzlAoJPvHdL0Slsnuh5-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 453000 Counter(453000) 452937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 453500 Counter(453500) 453437
Saved chunk: 20230922T072641F412080-2hsdLE34lhTgmAzbkeZYpw-1KyRkjgmaHmYSFVdKeU3XQ-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T072651F568914-5vZTzlAoJPvHdL0Slsnuh5-1X4wgb5IpqQdD9mL3yv34i-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 454000 Counter(454000) 453937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 454500 Counter(454500) 454437
Saved chunk: 20230922T072759F323246-1KyRkjgmaHmYSFVdKeU3XQ-3TmzInOIlpciI5XEE9ob1A-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T072811F047604-1X4wgb5IpqQdD9mL3yv34i-3uyTJJhBljVQjxHqmmIgMR-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 455000 Counter(455000) 454937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 455500 Counter(455500) 455437
Saved chunk: 20230922T072917F098224-3TmzInOIlpciI5XEE9ob1A-3JZcakoS7DwVo5srx1jPNo-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T072930F349816-3uyTJJhBljVQjxHqmmIgMR-69zxoyDxBgzh3z2W7x2XIW-1024.npz
train_Episode has 500 steps and return 753.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 911958 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 753 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / train/action_mag 4.41 / train/action_max 4.15 / train/action_mean 0.03 / train/action_min -4.29 / train/action_std 1.07 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -1.92 / train/adv_mag 0.42 / train/adv_max 0.32 / train/adv_mean 4.1e-5 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.28 / train/extr_critic_max 670.28 / train/extr_critic_mean 625.87 / train/extr_critic_min 450.26 / train/extr_critic_std 60.2 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.35 / train/extr_return_raw_max 668.35 / train/extr_return_raw_mean 625.87 / train/extr_return_raw_min 451.48 / train/extr_return_raw_std 60.27
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.28 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.32 / train/model_loss_mean 1.26 / train/model_loss_std 2.26 / 
train/model_opt_grad_norm 5.58 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8788.66 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.52 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.83 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.52 / train/policy_logprob_min -8.83 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.88 / train/post_ent_max 54.88 / train/post_ent_mean 37.53 / train/post_ent_min
26.79 / train/post_ent_std 4.41 / train/prior_ent_mag 66.84 / train/prior_ent_max 66.84 / train/prior_ent_mean 38.77 / train/prior_ent_min 31.39 / train/prior_ent_std 5.74 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.37 / train/reward_avg 1.25 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.25 / train/reward_rate 0.63 / 
train_stats/mean_log_entropy 0.52 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.93 / report/image_loss_mean 0.18 / report/image_loss_std 0.27 / report/model_loss_mean 1.29 / report/model_loss_std 2.57 / report/post_ent_mag 56.69 / report/post_ent_max 56.69 / 
report/post_ent_mean 37.68 / report/post_ent_min 29.68 / report/post_ent_std 4.1 / report/prior_ent_mag 66.91 / report/prior_ent_max 66.91 / report/prior_ent_mean 38.9 / report/prior_ent_min 32.24 / report/prior_ent_std 5.58 / report/rep_loss_mean 1.72 / 
report/rep_loss_std 3.93 / report/reward_avg 1.26 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.1e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.26 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 5.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 3.01 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.14 / eval/model_loss_std 2.01 / eval/post_ent_mag 51.83 / eval/post_ent_max 51.83 / eval/post_ent_mean 
37.36 / eval/post_ent_min 29.83 / eval/post_ent_std 3.9 / eval/prior_ent_mag 66.91 / eval/prior_ent_max 66.91 / eval/prior_ent_mean 38.37 / eval/prior_ent_min 32.21 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 3.01 / eval/reward_avg 1.51 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.51 / eval/reward_rate 0.76 / replay/size 
4.6e5 / replay/inserts 3878 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3878 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.91 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7385 / timer/agent.policy_total 16.49 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1939 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1939 / timer/agent.train_total 246.29 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.85

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 456000 Counter(456000) 455937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 456500 Counter(456500) 456437
Saved chunk: 20230922T073034F864896-3JZcakoS7DwVo5srx1jPNo-6aDkPzXBTCCwsaA62SZ80H-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T073049F626847-69zxoyDxBgzh3z2W7x2XIW-1Lrp40S76SN2TuOrcpJbue-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 457000 Counter(457000) 456937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 457500 Counter(457500) 457437
Saved chunk: 20230922T073153F829029-6aDkPzXBTCCwsaA62SZ80H-2QLoKYiigKJ4pjajsqLZVn-1024.npz
eval_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T073210F301847-1Lrp40S76SN2TuOrcpJbue-3HqUNXdqp3hVEdOZXWM64F-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 458000 Counter(458000) 457937
eval_Episode has 500 steps and return 750.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 458500 Counter(458500) 458437
Saved chunk: 20230922T073311F889312-2QLoKYiigKJ4pjajsqLZVn-5SJfsytdY08VxjgQbN9Iaq-1024.npz
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T073329F811256-3HqUNXdqp3hVEdOZXWM64F-2y2TxIC2alb7SjbNMBbLhg-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 459000 Counter(459000) 458937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 459500 Counter(459500) 459437
Saved chunk: 20230922T073429F617897-5SJfsytdY08VxjgQbN9Iaq-2dohdYtjYS7vIqFfi04Rvw-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T073449F078756-2y2TxIC2alb7SjbNMBbLhg-2y2uVZtEVaeilx8v3upllH-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 919626 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 761 / episode/reward_rate 0.76 / train/action_mag 4.26 / train/action_max 3.93 / train/action_mean 0.04 / train/action_min -4.17 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -2.92 / train/adv_mag 0.41 / train/adv_max 0.31 / train/adv_mean 1.7e-4 / train/adv_min -0.35 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.93 / train/extr_critic_max 670.93 / train/extr_critic_mean 626 / train/extr_critic_min 446.31 / train/extr_critic_std 61.98 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.83 / train/extr_return_raw_max 668.83 / train/extr_return_raw_mean 626.03 / train/extr_return_raw_min 446.36 / train/extr_return_raw_std 62.03 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.25 / train/model_loss_std 2.2 / 
train/model_opt_grad_norm 5.78 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.85 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.85 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.37 / train/post_ent_mag 54.82 / train/post_ent_max 54.82 / train/post_ent_mean 37.5 / train/post_ent_min 
26.88 / train/post_ent_std 4.38 / train/prior_ent_mag 66.77 / train/prior_ent_max 66.77 / train/prior_ent_mean 38.72 / train/prior_ent_min 31.51 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.3 / train/reward_avg 1.26 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.26 / train/reward_rate 0.63 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.53 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 2.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.49 / report/image_loss_mean 0.21 / report/image_loss_std 0.45 / report/model_loss_mean 1.29 / report/model_loss_std 2.38 / report/post_ent_mag 55.97 / report/post_ent_max 55.97 / 
report/post_ent_mean 37.75 / report/post_ent_min 29.35 / report/post_ent_std 4.43 / report/prior_ent_mag 66.92 / report/prior_ent_max 66.92 / report/prior_ent_mean 38.94 / report/prior_ent_min 32.55 / report/prior_ent_std 5.88 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.49 / report/reward_avg 1.15 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.15 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 8.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.3 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.52 / eval/post_ent_mag 55.53 / eval/post_ent_max 55.53 / eval/post_ent_mean 
37.36 / eval/post_ent_min 28.73 / eval/post_ent_std 3.73 / eval/prior_ent_mag 66.92 / eval/prior_ent_max 66.92 / eval/prior_ent_mean 38.39 / eval/prior_ent_min 32.38 / eval/prior_ent_std 5.32 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.3 / eval/reward_avg 1.6 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.6 / eval/reward_rate 0.8 / replay/size 
4.6e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3834 / timer/env.step_total 18.86 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.42 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.5e-3 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.53 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 5.5e-5 / timer/dataset_eval_frac 1.8e-7 / timer/dataset_eval_avg 5.5e-5 / timer/dataset_eval_min 5.5e-5 / timer/dataset_eval_max 5.5e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 460000 Counter(460000) 459937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 460500 Counter(460500) 460437
Saved chunk: 20230922T073547F246357-2dohdYtjYS7vIqFfi04Rvw-0XI8gAG4Yz1eJyHIUvdacp-1024.npz
eval_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T073608F220475-2y2uVZtEVaeilx8v3upllH-6EARtKEiGAOegJrmq7Ojts-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 461000 Counter(461000) 460937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 461500 Counter(461500) 461437
Saved chunk: 20230922T073706F266783-0XI8gAG4Yz1eJyHIUvdacp-4Ow71pnkpYkPD9wzsogWDP-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T073728F916589-6EARtKEiGAOegJrmq7Ojts-2VE1zvhuHeWSSkDQhSMlMY-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 462000 Counter(462000) 461937
eval_Episode has 500 steps and return 721.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 462500 Counter(462500) 462437
Saved chunk: 20230922T073824F129220-4Ow71pnkpYkPD9wzsogWDP-3GnBbPj5L6zigMS5Pd028R-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T073848F289994-2VE1zvhuHeWSSkDQhSMlMY-0qj48wf0mTrcFph72qS6Wa-1024.npz
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 463000 Counter(463000) 462937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 463500 Counter(463500) 463437
Saved chunk: 20230922T073941F995764-3GnBbPj5L6zigMS5Pd028R-3RcHNvWbmfJUldRnqMbdAd-1024.npz
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 927294 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.18 / train/action_max 3.85 / train/action_mean 0.04 / train/action_min -4.09 / train/action_std 0.97 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -0.58 / train/adv_mag 0.45 / train/adv_max 0.33 / train/adv_mean -4.3e-5 / train/adv_min -0.39 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.38 / train/extr_critic_max 670.38 / train/extr_critic_mean 624.09 / train/extr_critic_min 441.84 / train/extr_critic_std 63.03 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.68 / train/extr_return_raw_max 668.68 / train/extr_return_raw_mean 624.09 / train/extr_return_raw_min 442.04 / train/extr_return_raw_std 63.09
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.28 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.19 / train/image_loss_std 0.29 / train/model_loss_mean 1.26 / train/model_loss_std 2.22 / 
train/model_opt_grad_norm 5.74 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8880.21 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.34 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.84 / train/policy_logprob_mag 8.74 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.34 / train/policy_logprob_min -8.74 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.36 / train/post_ent_mag 54.92 / train/post_ent_max 54.92 / train/post_ent_mean 37.55 / train/post_ent_min
27 / train/post_ent_std 4.33 / train/prior_ent_mag 66.77 / train/prior_ent_max 66.77 / train/prior_ent_mean 38.79 / train/prior_ent_min 31.65 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.33 / train/reward_avg 1.26 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.25 / train/reward_rate 0.63 / 
train_stats/mean_log_entropy 0.35 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 3.05 / report/image_loss_mean 0.18 / report/image_loss_std 0.21 / report/model_loss_mean 1.2 / report/model_loss_std 2 / report/post_ent_mag 53.14 / report/post_ent_max 53.14 / 
report/post_ent_mean 37.73 / report/post_ent_min 30.57 / report/post_ent_std 4.34 / report/prior_ent_mag 66.83 / report/prior_ent_max 66.83 / report/prior_ent_mean 38.94 / report/prior_ent_min 32.91 / report/prior_ent_std 5.67 / report/rep_loss_mean 1.58 / 
report/rep_loss_std 3.05 / report/reward_avg 1.21 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.2 / report/reward_rate 0.61 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 4.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.38 / eval/dyn_loss_std 2.19 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.07 / eval/model_loss_std 1.45 / eval/post_ent_mag 51.3 / eval/post_ent_max 51.3 / eval/post_ent_mean 36.75 / 
eval/post_ent_min 29.95 / eval/post_ent_std 3.6 / eval/prior_ent_mag 66.83 / eval/prior_ent_max 66.83 / eval/prior_ent_mean 37.71 / eval/prior_ent_min 33.02 / eval/prior_ent_std 5.12 / eval/rep_loss_mean 1.38 / eval/rep_loss_std 2.19 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size
4.6e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3834 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.03 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.29 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.35 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T074059F680690-3RcHNvWbmfJUldRnqMbdAd-0000000000000000000000-130.npz
Saved chunk: 20230922T074007F681689-0qj48wf0mTrcFph72qS6Wa-0000000000000000000000-952.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T074007F681689-0qj48wf0mTrcFph72qS6Wa-5LbSlwaKEqOe8G3Xh71Ia3-1024.npz
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 464000 Counter(464000) 463937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 464500 Counter(464500) 464437
Saved chunk: 20230922T074059F680690-3RcHNvWbmfJUldRnqMbdAd-0WthmGZHRVHIIhejqmMX4K-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T074128F168940-5LbSlwaKEqOe8G3Xh71Ia3-4bUXmSubFwVO8guvut92Sy-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 465000 Counter(465000) 464937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 465500 Counter(465500) 465437
Saved chunk: 20230922T074218F938190-0WthmGZHRVHIIhejqmMX4K-3LliUEWhql9C4asBmtxiXN-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T074247F740224-4bUXmSubFwVO8guvut92Sy-29soefNo2u5uklsIxjusu4-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 466000 Counter(466000) 465937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 466500 Counter(466500) 466437
Saved chunk: 20230922T074336F804480-3LliUEWhql9C4asBmtxiXN-7de4aLf253aLfnaHf5fwGm-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T074407F207910-29soefNo2u5uklsIxjusu4-50xFAXnGsARvNZKQa5TzA9-1024.npz
Starting evaluation at step 467000 Counter(467000) 466937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 467500 Counter(467500) 467437
Saved chunk: 20230922T074454F562427-7de4aLf253aLfnaHf5fwGm-3Uej7ICcLmzOzOj5qXxh4E-1024.npz
eval_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 935002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train/action_mag 4.48 / train/action_max 4.24 / train/action_mean 0.04 / train/action_min -4.3 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -3.49 / train/adv_mag 0.39 / train/adv_max 0.3 / train/adv_mean 1.9e-4 / train/adv_min -0.35 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.3 / train/extr_critic_max 670.3 / train/extr_critic_mean 627.64 / train/extr_critic_min 453.69 / train/extr_critic_std 59.78 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.79 / train/extr_return_raw_max 668.79 / train/extr_return_raw_mean 627.67 / train/extr_return_raw_min 454.11 / train/extr_return_raw_std 59.81
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.32 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.23 / train/model_loss_std 2.14 / 
train/model_opt_grad_norm 5.7 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8523.32 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.56 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 9 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.56 / train/policy_logprob_min -9 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.63 / train/policy_randomness_min 1.4e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.14 / train/post_ent_max 55.14 / train/post_ent_mean 37.59 / train/post_ent_min
27.47 / train/post_ent_std 4.23 / train/prior_ent_mag 66.99 / train/prior_ent_max 66.99 / train/prior_ent_mean 38.8 / train/prior_ent_min 32.13 / train/prior_ent_std 5.59 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.19 / train/reward_avg 1.29 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.29 / train/reward_rate 0.65 / 
train_stats/mean_log_entropy 0.72 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.17 / report/image_loss_mean 0.17 / report/image_loss_std 0.26 / report/model_loss_mean 1.22 / report/model_loss_std 2.08 / report/post_ent_mag 55.05 / report/post_ent_max 55.05 / 
report/post_ent_mean 37.46 / report/post_ent_min 29.28 / report/post_ent_std 4.03 / report/prior_ent_mag 67.17 / report/prior_ent_max 67.17 / report/prior_ent_mean 38.75 / report/prior_ent_min 33.27 / report/prior_ent_std 5.55 / report/rep_loss_mean 1.61 / 
report/rep_loss_std 3.17 / report/reward_avg 1.44 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.44 / report/reward_rate 0.72 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 3.13 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.16 / eval/model_loss_std 2.05 / eval/post_ent_mag 56.31 / eval/post_ent_max 56.31 / eval/post_ent_mean 36.94 / 
eval/post_ent_min 31.13 / eval/post_ent_std 4.01 / eval/prior_ent_mag 67.17 / eval/prior_ent_max 67.17 / eval/prior_ent_mean 38.01 / eval/prior_ent_min 33.51 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 3.13 / eval/reward_avg 1.52 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.52 / eval/reward_rate 0.76 / replay/size
4.7e5 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.65 / timer/env.step_count 3854 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.86 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7862 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1927 / timer/agent.train_total 244.99 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T074526F520239-50xFAXnGsARvNZKQa5TzA9-5nX2RbGoS3IkPxyCQZ2SKA-1024.npz
Starting evaluation at step 468000 Counter(468000) 467937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 468500 Counter(468500) 468437
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T074612F257588-3Uej7ICcLmzOzOj5qXxh4E-2puKELuW6VbEm2jCBtEyzY-1024.npz
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T074646F861454-5nX2RbGoS3IkPxyCQZ2SKA-67uYjqxvt7DgQCx91e0hyR-1024.npz
Starting evaluation at step 469000 Counter(469000) 468937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 469500 Counter(469500) 469437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 470000 Counter(470000) 469937
Saved chunk: 20230922T074731F331987-2puKELuW6VbEm2jCBtEyzY-1idYfr87Y8CuAapWdePNUy-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T074806F412478-67uYjqxvt7DgQCx91e0hyR-6ELmBhH8AC9bfECBnxUcqF-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 470500 Counter(470500) 470437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 471000 Counter(471000) 470937
Saved chunk: 20230922T074924F649402-1idYfr87Y8CuAapWdePNUy-2IEWS0qLMWPko12MpBRDvi-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T074929F136276-6ELmBhH8AC9bfECBnxUcqF-1WnJ9LOSQoIn9l3uR9tz43-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 942770 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 751 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.38 / train/action_max 4.05 / train/action_mean 0.03 / train/action_min -4.27 / train/action_std 1.05 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -3.71 / train/adv_mag 0.43 / train/adv_max 0.32 / train/adv_mean 2.3e-4 / train/adv_min -0.38 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.84 / train/extr_critic_max 670.84 / train/extr_critic_mean 627.51 / train/extr_critic_min 449.5 / train/extr_critic_std 60.44 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.23 / train/extr_return_raw_max 669.23 / train/extr_return_raw_mean 627.55 / train/extr_return_raw_min 451.55 / train/extr_return_raw_std 60.52
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.31 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / train/model_loss_mean 1.24 / train/model_loss_std 2.16 / 
train/model_opt_grad_norm 6.11 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.5 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.74 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.5 / train/policy_logprob_min -8.74 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.15 / train/post_ent_max 55.15 / train/post_ent_mean 37.72 / train/post_ent_min 
27.25 / train/post_ent_std 4.14 / train/prior_ent_mag 66.79 / train/prior_ent_max 66.79 / train/prior_ent_mean 38.93 / train/prior_ent_min 32.43 / train/prior_ent_std 5.5 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.24 / train/reward_avg 1.28 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.28 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.54 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.8e-11 / report/cont_loss_std 3.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 3 / report/image_loss_mean 0.17 / report/image_loss_std 0.3 / report/model_loss_mean 1.17 / report/model_loss_std 2.04 / report/post_ent_mag 54.97 / report/post_ent_max 54.97 / 
report/post_ent_mean 37.23 / report/post_ent_min 30.87 / report/post_ent_std 4.23 / report/prior_ent_mag 66.89 / report/prior_ent_max 66.89 / report/prior_ent_mean 38.26 / report/prior_ent_min 33.41 / report/prior_ent_std 5.57 / report/rep_loss_mean 1.53 / 
report/rep_loss_std 3 / report/reward_avg 1.47 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.47 / report/reward_rate 0.74 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 5.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.42 / eval/dyn_loss_std 2.09 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.38 / eval/post_ent_mag 52.45 / eval/post_ent_max 52.45 / eval/post_ent_mean 
36.59 / eval/post_ent_min 30.63 / eval/post_ent_std 3.15 / eval/prior_ent_mag 66.89 / eval/prior_ent_max 66.89 / eval/prior_ent_mean 37.52 / eval/prior_ent_min 33.55 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 1.42 / eval/rep_loss_std 2.09 / eval/reward_avg 1.8 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.8 / eval/reward_rate 0.9 / replay/size 
4.7e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3884 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 402.77 / timer/replay._sample_frac 1.34 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.13 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.73 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.88

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 471500 Counter(471500) 471437
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 472000 Counter(472000) 471937
Saved chunk: 20230922T075042F333456-2IEWS0qLMWPko12MpBRDvi-2sSfyc9XmUPKmRzsAx4leZ-1024.npz
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T075048F357087-1WnJ9LOSQoIn9l3uR9tz43-6VSOoYpQkh9E20QA41rw8Y-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 472500 Counter(472500) 472437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 473000 Counter(473000) 472937
Saved chunk: 20230922T075201F363094-2sSfyc9XmUPKmRzsAx4leZ-0WyBKosHrIzITXNyWmwS0S-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T075209F042553-6VSOoYpQkh9E20QA41rw8Y-6RDQZWt3CCPMUz6p2XPKym-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 473500 Counter(473500) 473437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 474000 Counter(474000) 473937
Saved chunk: 20230922T075319F382486-0WyBKosHrIzITXNyWmwS0S-2PNtbG0NLOxJxzF1TeOBXI-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T075328F536051-6RDQZWt3CCPMUz6p2XPKym-64Ch7TAKsSUmJMgz3QuWnG-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 474500 Counter(474500) 474437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 475000 Counter(475000) 474937
Saved chunk: 20230922T075437F133692-2PNtbG0NLOxJxzF1TeOBXI-0Zgi8cALweDkNmkNfEBtTf-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T075447F862444-64Ch7TAKsSUmJMgz3QuWnG-2BPHYR71vOrwB9T4o0i9yg-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 950434 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.4 / train/action_max 4.18 / train/action_mean 0.03 / train/action_min -4.28 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -1.32 / train/adv_mag 0.43 / train/adv_max 0.33 / train/adv_mean -1.7e-5 / train/adv_min -0.38 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.33 / train/extr_critic_max 671.33 / train/extr_critic_mean 629.01 / train/extr_critic_min 456.35 / train/extr_critic_std 59.38 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.12 / train/extr_return_raw_max 669.12 / train/extr_return_raw_mean 629.01 / train/extr_return_raw_min 456.01 / train/extr_return_raw_std 59.45
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.23 / train/model_loss_std 2.13 / 
train/model_opt_grad_norm 6.01 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.85 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.51 / train/policy_logprob_min -8.85 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 7.4e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 55.38 / train/post_ent_max 55.38 / train/post_ent_mean 37.62 / train/post_ent_min 
27.29 / train/post_ent_std 4.11 / train/prior_ent_mag 66.94 / train/prior_ent_max 66.94 / train/prior_ent_mean 38.82 / train/prior_ent_min 32.2 / train/prior_ent_std 5.48 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.18 / train/reward_avg 1.3 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / train/reward_rate 0.65 / 
train_stats/mean_log_entropy 0.76 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 6.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.51 / report/dyn_loss_std 2.2 / report/image_loss_mean 0.16 / report/image_loss_std 0.17 / report/model_loss_mean 1.14 / report/model_loss_std 1.44 / report/post_ent_mag 54.35 / report/post_ent_max 54.35 / 
report/post_ent_mean 37.23 / report/post_ent_min 27.36 / report/post_ent_std 4.01 / report/prior_ent_mag 66.64 / report/prior_ent_max 66.64 / report/prior_ent_mean 38.41 / report/prior_ent_min 32.89 / report/prior_ent_std 5.53 / report/rep_loss_mean 1.51 / 
report/rep_loss_std 2.2 / report/reward_avg 1.3 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.8e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.11 / report/reward_pred 1.3 / report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 3.09 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.28 / eval/model_loss_std 2.07 / eval/post_ent_mag 54.07 / eval/post_ent_max 54.07 / eval/post_ent_mean 38.35 / eval/post_ent_min 32.1 / 
eval/post_ent_std 3.82 / eval/prior_ent_mag 66.64 / eval/prior_ent_max 66.64 / eval/prior_ent_mean 39.71 / eval/prior_ent_min 33.17 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 3.09 / eval/reward_avg 1.13 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.26 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.15 / eval/reward_pred 1.12 / eval/reward_rate 0.57 / replay/size 4.8e5 / replay/inserts 3832 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3832 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 8.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.63 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1916
/ timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.55 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.8e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.8e-5 / timer/dataset_eval_min 4.8e-5 / timer/dataset_eval_max 4.8e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T075554F874425-0Zgi8cALweDkNmkNfEBtTf-0000000000000000000000-389.npz
Saved chunk: 20230922T075607F101267-2BPHYR71vOrwB9T4o0i9yg-0000000000000000000000-264.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
train_Episode has 500 steps and return 731.0.
Starting evaluation at step 475500 Counter(475500) 475437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 476000 Counter(476000) 475937
Saved chunk: 20230922T075554F874425-0Zgi8cALweDkNmkNfEBtTf-0VgYZrl3JA3CWGFE6rIoMr-1024.npz
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T075607F101267-2BPHYR71vOrwB9T4o0i9yg-0EOXWrkJqRwyWx6uKT651r-1024.npz
train_Episode has 500 steps and return 752.0.
Starting evaluation at step 476500 Counter(476500) 476437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 477000 Counter(477000) 476937
Saved chunk: 20230922T075714F179253-0VgYZrl3JA3CWGFE6rIoMr-7xEUvsPL4AxN2MX1sOG1k4-1024.npz
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T075728F020348-0EOXWrkJqRwyWx6uKT651r-6norBV10uCQiIUAOFU1ZV6-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 477500 Counter(477500) 477437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 478000 Counter(478000) 477937
Saved chunk: 20230922T075832F066544-7xEUvsPL4AxN2MX1sOG1k4-0moThKMCOfhTrfYsjB5F7c-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T075847F461580-6norBV10uCQiIUAOFU1ZV6-5lbewwYN3PvjgSHiumP1UI-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 478500 Counter(478500) 478437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 479000 Counter(479000) 478937
Saved chunk: 20230922T075949F914790-0moThKMCOfhTrfYsjB5F7c-0kdBy76SowW6akkA8Qd64B-1024.npz
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 958094 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 766 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.31 / train/action_max 4.02 / train/action_mean 0.03 / train/action_min -4.22 / train/action_std 1.03 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -1.37 / train/adv_mag 0.43 / train/adv_max 0.31 / train/adv_mean 9e-6 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 9.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.4 / train/extr_critic_max 670.4 / train/extr_critic_mean 625.38 / train/extr_critic_min 447.32 / train/extr_critic_std 61.82 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.91 / train/extr_return_raw_max 668.91 / train/extr_return_raw_mean 625.38 / train/extr_return_raw_min 446.91 / train/extr_return_raw_std 61.86
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.18 / train/image_loss_std 0.31 / train/model_loss_mean 1.24 / train/model_loss_std 2.2 / 
train/model_opt_grad_norm 5.52 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.44 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.44 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 7.3e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.12 / train/post_ent_max 55.12 / train/post_ent_mean 37.74 / train/post_ent_min
26.84 / train/post_ent_std 4.1 / train/prior_ent_mag 66.67 / train/prior_ent_max 66.67 / train/prior_ent_mean 38.96 / train/prior_ent_min 32 / train/prior_ent_std 5.46 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.28 / train/reward_avg 1.26 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.26 / train/reward_rate 0.63 / 
train_stats/mean_log_entropy 0.46 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.47 / report/dyn_loss_std 2.55 / report/image_loss_mean 0.13 / report/image_loss_std 0.31 / report/model_loss_mean 1.11 / report/model_loss_std 1.73 / report/post_ent_mag 54.87 / report/post_ent_max 54.87 / 
report/post_ent_mean 36.1 / report/post_ent_min 28.95 / report/post_ent_std 3.62 / report/prior_ent_mag 66.71 / report/prior_ent_max 66.71 / report/prior_ent_mean 37.1 / report/prior_ent_min 32.74 / report/prior_ent_std 5.19 / report/rep_loss_mean 1.47 / 
report/rep_loss_std 2.55 / report/reward_avg 1.56 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.5e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.56 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 6.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.46 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.16 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.59 / eval/post_ent_mag 55.44 / eval/post_ent_max 55.44 / eval/post_ent_mean 
37.75 / eval/post_ent_min 27.54 / eval/post_ent_std 3.56 / eval/prior_ent_mag 66.71 / eval/prior_ent_max 66.71 / eval/prior_ent_mean 38.79 / eval/prior_ent_min 33.08 / eval/prior_ent_std 5.03 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.46 / eval/reward_avg 1.49 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / replay/size
4.8e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3830 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.85 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7838 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.37 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T080006F765350-5lbewwYN3PvjgSHiumP1UI-0GBrSaOGk6PtOttH8DC5vu-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 479500 Counter(479500) 479437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 480000 Counter(480000) 479937
Saved chunk: 20230922T080107F576979-0kdBy76SowW6akkA8Qd64B-4Ry1xDO3iRdQEFqWWTV3we-1024.npz
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T080127F124532-0GBrSaOGk6PtOttH8DC5vu-35deQ017XSjzDXhKpqkjsh-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 480500 Counter(480500) 480437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 481000 Counter(481000) 480937
Saved chunk: 20230922T080226F684027-4Ry1xDO3iRdQEFqWWTV3we-17tk9WzGKz8R91mLnUi9VF-1024.npz
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T080246F713041-35deQ017XSjzDXhKpqkjsh-4QNMTJDMaqt2la2wtte9tf-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 481500 Counter(481500) 481437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 482000 Counter(482000) 481937
Saved chunk: 20230922T080344F513342-17tk9WzGKz8R91mLnUi9VF-0hlaY78YtqVRBj0SQqWlbk-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T080406F085810-4QNMTJDMaqt2la2wtte9tf-0cRv0ja98WjCaHrFZLeHTT-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 482500 Counter(482500) 482437
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 965862 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.29 / train/action_max 3.97 / train/action_mean 0.03 / train/action_min -4.19 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -2.69 / train/adv_mag 0.46 / train/adv_max 0.34 / train/adv_mean 1.4e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.54 / train/extr_critic_max 670.54 / train/extr_critic_mean 627 / train/extr_critic_min 455.32 / train/extr_critic_std 59.99 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.78 / train/extr_return_raw_max 668.78 / train/extr_return_raw_mean 627.02 / train/extr_return_raw_min 456.3 / train/extr_return_raw_std 60.03 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.3 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.24 / train/model_loss_std 2.15 / 
train/model_opt_grad_norm 5.8 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean
0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.11 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 8.4e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 55.09 / train/post_ent_max 55.09 / train/post_ent_mean 37.8 / train/post_ent_min 27.37 / train/post_ent_std 4.11 
/ train/prior_ent_mag 66.87 / train/prior_ent_max 66.87 / train/prior_ent_mean 39.02 / train/prior_ent_min 31.98 / train/prior_ent_std 5.46 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.23 / train/reward_avg 1.27 / train/reward_loss_mean 0.08 / train/reward_loss_std 
0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / train_stats/mean_log_entropy 0.46 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.26 / report/image_loss_mean 0.2 / report/image_loss_std 0.26 / report/model_loss_mean 1.25 / report/model_loss_std 2.16 / report/post_ent_mag 53.29 / report/post_ent_max 53.29 / report/post_ent_mean 39.16 / 
report/post_ent_min 27.86 / report/post_ent_std 4.24 / report/prior_ent_mag 66.74 / report/prior_ent_max 66.74 / report/prior_ent_mean 40.43 / report/prior_ent_min 32.54 / report/prior_ent_std 5.47 / report/rep_loss_mean 1.66 / report/rep_loss_std 3.26 / report/reward_avg
0.92 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 0.92 / 
report/reward_rate 0.46 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 5.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / 
eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.79 / eval/post_ent_mag 53.05 / eval/post_ent_max 53.05 / eval/post_ent_mean 36.67 / eval/post_ent_min 29.57 / eval/post_ent_std 3.38 / 
eval/prior_ent_mag 66.74 / eval/prior_ent_max 66.74 / eval/prior_ent_mean 37.71 / eval/prior_ent_min 32.53 / eval/prior_ent_std 4.9 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.75 / eval/reward_avg 1.76 / eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.1 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.76 / eval/reward_rate 0.88 / replay/size 4.8e5 / replay/inserts 3884 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3884 / timer/env.step_total 19.13 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 8.3e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.19 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.15 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1942 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.63 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 483000 Counter(483000) 482937
Saved chunk: 20230922T080502F216462-0hlaY78YtqVRBj0SQqWlbk-05qXDxavLEw1rQWtr1iXAH-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T080525F323447-0cRv0ja98WjCaHrFZLeHTT-4h8iZao4p4Q50ZgMqheFrz-1024.npz
train_Episode has 500 steps and return 772.0.
Starting evaluation at step 483500 Counter(483500) 483437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 484000 Counter(484000) 483937
Saved chunk: 20230922T080620F879727-05qXDxavLEw1rQWtr1iXAH-34uilMpVlFZ0rzY5dNEsou-1024.npz
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T080645F705366-4h8iZao4p4Q50ZgMqheFrz-3vSk4lOA7My1qQR33JHkTP-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 484500 Counter(484500) 484437
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 485000 Counter(485000) 484937
Saved chunk: 20230922T080738F987768-34uilMpVlFZ0rzY5dNEsou-7JdUDzdctLcj5rNfhfjxac-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T080805F214694-3vSk4lOA7My1qQR33JHkTP-1PS1udCxiuL6NUMvFpDwgC-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 485500 Counter(485500) 485437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 486000 Counter(486000) 485937
Saved chunk: 20230922T080856F742431-7JdUDzdctLcj5rNfhfjxac-61ImB8pWlpKgik2JLHyKu5-1024.npz
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T080924F512591-1PS1udCxiuL6NUMvFpDwgC-1ITgEuOCj3VLwqSELYCugP-1024.npz
train_Episode has 500 steps and return 765.0.
Starting evaluation at step 486500 Counter(486500) 486437
eval_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 973534 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 765 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 767 / eval_episode/reward_rate 0.77 / train/action_mag 4.23 / train/action_max 3.89 / train/action_mean 0.04 / train/action_min -4.14 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -0.94 / train/adv_mag 0.45 / train/adv_max 0.33 / train/adv_mean -2.2e-5 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.2 / train/extr_critic_max 670.2 / train/extr_critic_mean 627.31 / train/extr_critic_min 454.6 / train/extr_critic_std 59.37 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.49 / train/extr_return_raw_max 668.49 / train/extr_return_raw_mean 627.3 / train/extr_return_raw_min 455.89 / train/extr_return_raw_std 59.45 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.31 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.24 / train/model_loss_std 2.17 / 
train/model_opt_grad_norm 5.66 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.84 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 6.4e-5 / train/policy_randomness_std 0.36 / train/post_ent_mag 55.17 / train/post_ent_max 55.17 / train/post_ent_mean 37.72 / train/post_ent_min
27.08 / train/post_ent_std 4.16 / train/prior_ent_mag 66.78 / train/prior_ent_max 66.78 / train/prior_ent_mean 38.93 / train/prior_ent_min 31.89 / train/prior_ent_std 5.51 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.26 / train/reward_avg 1.28 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.28 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.6e-11 / report/cont_loss_std 3.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.68 / report/image_loss_mean 0.2 / report/image_loss_std 0.31 / report/model_loss_mean 1.27 / report/model_loss_std 2.45 / report/post_ent_mag 50.58 / report/post_ent_max 50.58 / 
report/post_ent_mean 38.53 / report/post_ent_min 28.96 / report/post_ent_std 3.99 / report/prior_ent_mag 66.72 / report/prior_ent_max 66.72 / report/prior_ent_mean 39.72 / report/prior_ent_min 29.87 / report/prior_ent_std 5.23 / report/rep_loss_mean 1.67 / 
report/rep_loss_std 3.68 / report/reward_avg 1.12 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.12 / report/reward_rate 0.56 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 5.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.37 / eval/dyn_loss_std 2.25 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.05 / eval/model_loss_std 1.52 / eval/post_ent_mag 54.18 / eval/post_ent_max 54.18 / eval/post_ent_mean 
37.02 / eval/post_ent_min 31.29 / eval/post_ent_std 3.46 / eval/prior_ent_mag 66.72 / eval/prior_ent_max 66.72 / eval/prior_ent_mean 37.98 / eval/prior_ent_min 33.15 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 1.37 / eval/rep_loss_std 2.25 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.4e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.61 / eval/reward_rate 0.8 / replay/size 
4.9e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3836 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.74 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.8e-3 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.68 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 764.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 487000 Counter(487000) 486937
Saved chunk: 20230922T081014F437081-61ImB8pWlpKgik2JLHyKu5-0000000000000000000000-648.npz
Saved chunk: 20230922T081043F761028-1ITgEuOCj3VLwqSELYCugP-0000000000000000000000-600.npz
Saved chunk: 20230922T081014F437081-61ImB8pWlpKgik2JLHyKu5-3OhH3Z0vozzHOz8KQzonbr-1024.npz
eval_Episode has 500 steps and return 772.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T081043F761028-1ITgEuOCj3VLwqSELYCugP-2maLEEbVmxmTs7fGuF7Ez4-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 487500 Counter(487500) 487437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 488000 Counter(488000) 487937
Saved chunk: 20230922T081133F579780-3OhH3Z0vozzHOz8KQzonbr-3SATeunfvoWr2ohK6xtFO2-1024.npz
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T081204F616767-2maLEEbVmxmTs7fGuF7Ez4-0PHX28s4lad6OXpotNXOhC-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 488500 Counter(488500) 488437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 489000 Counter(489000) 488937
Saved chunk: 20230922T081251F572817-3SATeunfvoWr2ohK6xtFO2-4S0XpCvVmK2cufKgeZXgbM-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T081324F040284-0PHX28s4lad6OXpotNXOhC-2mS3Hj2Da1YiDTrMjHjURX-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 489500 Counter(489500) 489437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 490000 Counter(490000) 489937
Saved chunk: 20230922T081409F352896-4S0XpCvVmK2cufKgeZXgbM-0ORX93FWMnBt3vtaYSqSk0-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T081443F350793-2mS3Hj2Da1YiDTrMjHjURX-03Hhst3VFnE9uNDPZmSJkg-1024.npz
Starting evaluation at step 490500 Counter(490500) 490437
eval_Episode has 500 steps and return 773.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 981198 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / train/action_mag 4.3 / train/action_max 3.98 / train/action_mean 0.04 / train/action_min -4.19 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -3.9 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean 2.8e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.67 / train/extr_critic_max 670.67 / train/extr_critic_mean 629.35 / train/extr_critic_min 453.16 / train/extr_critic_std 58.37 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.82 / train/extr_return_raw_max 668.82 / train/extr_return_raw_mean 629.4 / train/extr_return_raw_min 455.41 / train/extr_return_raw_std 58.42 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / train/model_loss_mean 1.24 / train/model_loss_std 2.17 / 
train/model_opt_grad_norm 5.51 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.61 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.61 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 5.8e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 54.53 / train/post_ent_max 54.53 / train/post_ent_mean 37.6 / train/post_ent_min 
27.15 / train/post_ent_std 4.16 / train/prior_ent_mag 66.65 / train/prior_ent_max 66.65 / train/prior_ent_mean 38.81 / train/prior_ent_min 31.64 / train/prior_ent_std 5.51 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.25 / train/reward_avg 1.3 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / train/reward_rate 0.65 / 
train_stats/mean_log_entropy 0.48 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.28 / report/image_loss_mean 0.2 / report/image_loss_std 0.41 / report/model_loss_mean 1.26 / report/model_loss_std 2.31 / report/post_ent_mag 54.12 / report/post_ent_max 54.12 / 
report/post_ent_mean 38.62 / report/post_ent_min 30.25 / report/post_ent_std 4.3 / report/prior_ent_mag 66.75 / report/prior_ent_max 66.75 / report/prior_ent_mean 39.84 / report/prior_ent_min 32.02 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.28 / report/reward_avg 1.17 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.17 / report/reward_rate 0.59 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 6.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.7 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.75 / eval/post_ent_mag 53.17 / eval/post_ent_max 53.17 / eval/post_ent_mean 
37.82 / eval/post_ent_min 25.8 / eval/post_ent_std 3.6 / eval/prior_ent_mag 66.75 / eval/prior_ent_max 66.75 / eval/prior_ent_mean 38.93 / eval/prior_ent_min 32.08 / eval/prior_ent_std 5.07 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.7 / eval/reward_avg 1.33 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.33 / eval/reward_rate 0.67 / 
replay/size 4.9e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3832 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.35 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.17 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 491000 Counter(491000) 490937
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T081527F051760-0ORX93FWMnBt3vtaYSqSk0-3gWyKGG8TnT3vccvMh8syA-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 491500 Counter(491500) 491437
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T081602F533832-03Hhst3VFnE9uNDPZmSJkg-2qC7ZA2GIZjN30RvJCcCPA-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 492000 Counter(492000) 491937
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T081645F862197-3gWyKGG8TnT3vccvMh8syA-5cHIW3XiPXnQ4tBhg4AHaE-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 492500 Counter(492500) 492437
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T081726F570207-2qC7ZA2GIZjN30RvJCcCPA-5CstPJG7rUi1rSb72IOZC6-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 493000 Counter(493000) 492937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 493500 Counter(493500) 493437
Saved chunk: 20230922T081805F769863-5cHIW3XiPXnQ4tBhg4AHaE-4AjbmpQwBJh0mQpHeF3sGi-1024.npz
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T081847F780406-5CstPJG7rUi1rSb72IOZC6-5JQlcgvbFnnvUMo4zyBXyO-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 494000 Counter(494000) 493937
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 988914 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.21 / train/action_max 3.99 / train/action_mean 0.04 / train/action_min -4.08 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -0.98 / train/adv_mag 0.42 / train/adv_max 0.32 / train/adv_mean -1.1e-5 / train/adv_min -0.35 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 8.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.56 / train/extr_critic_max 670.56 / train/extr_critic_mean 628.47 / train/extr_critic_min 456.28 / train/extr_critic_std 58.14 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.43 / train/extr_return_raw_max 668.43 / train/extr_return_raw_mean 628.47 / train/extr_return_raw_min 459.25 / train/extr_return_raw_std 58.18
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.31 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.23 / train/model_loss_std 2.14 / 
train/model_opt_grad_norm 5.77 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.37 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.37 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 5.4e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 55.13 / train/post_ent_max 55.13 / train/post_ent_mean 37.61 / train/post_ent_min
27.12 / train/post_ent_std 4.24 / train/prior_ent_mag 66.67 / train/prior_ent_max 66.67 / train/prior_ent_mean 38.8 / train/prior_ent_min 31.49 / train/prior_ent_std 5.56 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.21 / train/reward_avg 1.28 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.28 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 6.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.44 / report/dyn_loss_std 2.2 / report/image_loss_mean 0.13 / report/image_loss_std 0.21 / report/model_loss_mean 1.09 / report/model_loss_std 1.48 / report/post_ent_mag 53.81 / report/post_ent_max 53.81 / 
report/post_ent_mean 36.19 / report/post_ent_min 30.02 / report/post_ent_std 3.54 / report/prior_ent_mag 66.61 / report/prior_ent_max 66.61 / report/prior_ent_mean 37.27 / report/prior_ent_min 31.96 / report/prior_ent_std 5.08 / report/rep_loss_mean 1.44 / 
report/rep_loss_std 2.2 / report/reward_avg 1.72 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.72 / report/reward_rate 0.86 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 5.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.37 / eval/dyn_loss_std 1.99 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.04 / eval/model_loss_std 1.35 / eval/post_ent_mag 53.32 / eval/post_ent_max 53.32 / eval/post_ent_mean 36.45 / 
eval/post_ent_min 29.28 / eval/post_ent_std 2.99 / eval/prior_ent_mag 66.61 / eval/prior_ent_max 66.61 / eval/prior_ent_mean 37.32 / eval/prior_ent_min 32.16 / eval/prior_ent_std 4.61 / eval/rep_loss_mean 1.37 / eval/rep_loss_std 1.99 / eval/reward_avg 1.81 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.2e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.81 / eval/reward_rate 0.91 / replay/size 
4.9e5 / replay/inserts 3858 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3858 / timer/env.step_total 19 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.2 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7365 / timer/agent.policy_total 16.23 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.18 / 
timer/dataset_train_count 1929 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1929 / timer/agent.train_total 246.7 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 2.04 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.71

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 494500 Counter(494500) 494437
Saved chunk: 20230922T081958F908357-4AjbmpQwBJh0mQpHeF3sGi-1YYmuETRtcdD3PwDYOLCnN-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T082007F053044-5JQlcgvbFnnvUMo4zyBXyO-21y41Ksc5VlVHsYcjYZiol-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 495000 Counter(495000) 494937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 495500 Counter(495500) 495437
Saved chunk: 20230922T082117F516619-1YYmuETRtcdD3PwDYOLCnN-7I9FSRCl1qYLh2ayuyNNks-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T082127F268415-21y41Ksc5VlVHsYcjYZiol-38mJtpZdQt95fHiu8dVvXy-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 496000 Counter(496000) 495937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 496500 Counter(496500) 496437
Saved chunk: 20230922T082235F627703-7I9FSRCl1qYLh2ayuyNNks-4Xa5V2JHz0XWVRdDyhEiT3-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T082246F892050-38mJtpZdQt95fHiu8dVvXy-5sjh95ACbCXvVfvYcbzbNv-1024.npz
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 497000 Counter(497000) 496937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 497500 Counter(497500) 497437
Saved chunk: 20230922T082353F458916-4Xa5V2JHz0XWVRdDyhEiT3-7L2AQcsP15eZgpce4MulnB-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T082406F264222-5sjh95ACbCXvVfvYcbzbNv-0jKnAE81DHqJ8qHcBuHbtu-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 498000 Counter(498000) 497937
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 996578 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / train/action_mag 4.4 / train/action_max 4.23 / train/action_mean 0.04 / train/action_min -4.23 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -1.17 / train/adv_mag 0.46 / train/adv_max 0.36 / train/adv_mean -3.1e-5 / train/adv_min -0.38 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 9.8e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.03 / train/extr_critic_max 670.03 / train/extr_critic_mean 627.05 / train/extr_critic_min 455.7 / train/extr_critic_std 59.36 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.99 / train/extr_return_raw_max 667.99 / train/extr_return_raw_mean 627.05 / train/extr_return_raw_min 459.14 / train/extr_return_raw_std 59.42
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.31 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / train/model_loss_mean 1.23 / train/model_loss_std 2.16 / 
train/model_opt_grad_norm 5.63 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.51 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 5.7e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.17 / train/post_ent_max 55.17 / train/post_ent_mean 37.52 / train/post_ent_min 
26.74 / train/post_ent_std 4.28 / train/prior_ent_mag 66.71 / train/prior_ent_max 66.71 / train/prior_ent_mean 38.72 / train/prior_ent_min 31.34 / train/prior_ent_std 5.61 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.23 / train/reward_avg 1.28 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.28 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.75 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 6.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.67 / report/image_loss_mean 0.19 / report/image_loss_std 0.39 / report/model_loss_mean 1.24 / report/model_loss_std 2.52 / report/post_ent_mag 54.98 / report/post_ent_max 54.98 / 
report/post_ent_mean 38.25 / report/post_ent_min 23.04 / report/post_ent_std 4.49 / report/prior_ent_mag 66.74 / report/prior_ent_max 66.74 / report/prior_ent_mean 39.49 / report/prior_ent_min 31.55 / report/prior_ent_std 5.63 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.67 / report/reward_avg 1.03 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.03 / report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.43 / eval/dyn_loss_std 2.5 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.13 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.6 / eval/post_ent_mag 53.73 / eval/post_ent_max 53.73 / eval/post_ent_mean 
36.81 / eval/post_ent_min 19.35 / eval/post_ent_std 3.53 / eval/prior_ent_mag 66.74 / eval/prior_ent_max 66.74 / eval/prior_ent_mean 37.85 / eval/prior_ent_min 32.01 / eval/prior_ent_std 5.03 / eval/rep_loss_mean 1.43 / eval/rep_loss_std 2.5 / eval/reward_avg 1.78 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.78 / eval/reward_rate 0.89 / replay/size
5e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3832 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.01 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.67 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 498500 Counter(498500) 498437
Saved chunk: 20230922T082511F271622-7L2AQcsP15eZgpce4MulnB-4cTb2XAnqA3oCUmAiYN6aW-1024.npz
eval_Episode has 500 steps and return 514.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T082525F646229-0jKnAE81DHqJ8qHcBuHbtu-0000000000000000000000-936.npz
Saved chunk: 20230922T082630F254346-4cTb2XAnqA3oCUmAiYN6aW-0000000000000000000000-384.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T082525F646229-0jKnAE81DHqJ8qHcBuHbtu-1xCDeGhLkdk5Xrr1BVDz8S-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 499000 Counter(499000) 498937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 499500 Counter(499500) 499437
Saved chunk: 20230922T082630F254346-4cTb2XAnqA3oCUmAiYN6aW-1fA6ae9F6yp3uXnjFOtjvw-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T082646F575106-1xCDeGhLkdk5Xrr1BVDz8S-6zWVPFjyo4OsLIKXB4bCIg-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 500000 Counter(500000) 499937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 500500 Counter(500500) 500437
Saved chunk: 20230922T082748F561071-1fA6ae9F6yp3uXnjFOtjvw-4oVCD8rpoYW60A01U4RVjJ-1024.npz
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T082806F010131-6zWVPFjyo4OsLIKXB4bCIg-1JZKLsiPoPUtmCeapPavdb-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 501000 Counter(501000) 500937
eval_Episode has 500 steps and return 773.0.
Starting evaluation at step 501500 Counter(501500) 501437
Saved chunk: 20230922T082906F359856-4oVCD8rpoYW60A01U4RVjJ-5XtkE09ovcpcBBMTZ5D0rD-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T082925F356112-1JZKLsiPoPUtmCeapPavdb-5QiEk779tm2y2X9fUxjrUn-1024.npz
Starting evaluation at step 502000 Counter(502000) 501937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1004242 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / train/action_mag 4.39 / train/action_max 4.23 / train/action_mean 0.04 / train/action_min -4.22 / train/action_std 1.08 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -1.81 / train/adv_mag 0.43 / train/adv_max 0.32 / train/adv_mean 1.9e-5 / train/adv_min -0.38 / 
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.72 / train/extr_critic_max 669.72 / train/extr_critic_mean 628.82 / train/extr_critic_min 458.65 / train/extr_critic_std 58.49 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.44 / train/extr_return_raw_max 667.44 / train/extr_return_raw_mean 628.83 / train/extr_return_raw_min 459.85 / train/extr_return_raw_std 58.53
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.34 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.22 / train/model_loss_std 2.14 / 
train/model_opt_grad_norm 5.48 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8984.38 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.55 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.84 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.55 / train/policy_logprob_min -8.84 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.62 / train/policy_randomness_min 7.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.71 / train/post_ent_max 54.71 / train/post_ent_mean 37.3 / train/post_ent_min 
26.91 / train/post_ent_std 4.36 / train/prior_ent_mag 66.68 / train/prior_ent_max 66.68 / train/prior_ent_mean 38.49 / train/prior_ent_min 31.22 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.2 / train/reward_avg 1.31 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.31 / train/reward_rate 0.66 / 
train_stats/mean_log_entropy 0.7 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / report/cont_pred
1 / report/cont_rate 1 / report/dyn_loss_mean 1.74 / report/dyn_loss_std 4.13 / report/image_loss_mean 0.21 / report/image_loss_std 0.37 / report/model_loss_mean 1.32 / report/model_loss_std 2.76 / report/post_ent_mag 54.8 / report/post_ent_max 54.8 / report/post_ent_mean
37.69 / report/post_ent_min 26.3 / report/post_ent_std 5.17 / report/prior_ent_mag 66.73 / report/prior_ent_max 66.73 / report/prior_ent_mean 39.04 / report/prior_ent_min 29.69 / report/prior_ent_std 6.37 / report/rep_loss_mean 1.74 / report/rep_loss_std 4.13 / 
report/reward_avg 1 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1 
/ report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 6.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / 
eval/dyn_loss_std 2.83 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.85 / eval/post_ent_mag 54.02 / eval/post_ent_max 54.02 / eval/post_ent_mean 37.75 / eval/post_ent_min 29.24 / eval/post_ent_std 4.1 / 
eval/prior_ent_mag 66.73 / eval/prior_ent_max 66.73 / eval/prior_ent_mean 38.84 / eval/prior_ent_min 31.51 / eval/prior_ent_std 5.5 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.83 / eval/reward_avg 1.37 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.12 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.4e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.37 / eval/reward_rate 0.69 / replay/size 5e5 / replay/inserts 3832 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3832 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.6e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.36 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.18 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1916 / 
timer/agent.train_total 243.51 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 502500 Counter(502500) 502437
Saved chunk: 20230922T083024F118977-5XtkE09ovcpcBBMTZ5D0rD-546VaTZXcJfefF4NYkWrSk-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T083044F599634-5QiEk779tm2y2X9fUxjrUn-52XU91E5QZhvIBw0kj1R90-1024.npz
Starting evaluation at step 503000 Counter(503000) 502937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 503500 Counter(503500) 503437
Saved chunk: 20230922T083142F881860-546VaTZXcJfefF4NYkWrSk-3XPFAUdOHa9XlmFsgRTLll-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T083205F096661-52XU91E5QZhvIBw0kj1R90-3FffS2DCNyjTc7lavukfZe-1024.npz
Starting evaluation at step 504000 Counter(504000) 503937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 504500 Counter(504500) 504437
Saved chunk: 20230922T083300F764312-3XPFAUdOHa9XlmFsgRTLll-1oaOVtrNORIYgH4Gn5Q7tY-1024.npz
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T083324F448577-3FffS2DCNyjTc7lavukfZe-2iCHB5L0ujFwSxFjHCxPEG-1024.npz
Starting evaluation at step 505000 Counter(505000) 504937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 505500 Counter(505500) 505437
Saved chunk: 20230922T083418F644198-1oaOVtrNORIYgH4Gn5Q7tY-38XhSostA445xgduw3FZ3J-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T083443F854495-2iCHB5L0ujFwSxFjHCxPEG-7nndVuKGS8HPhjJSTkm6HZ-1024.npz
Starting evaluation at step 506000 Counter(506000) 505937
eval_Episode has 500 steps and return 773.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1012002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / train/action_mag 4.44 / train/action_max 4.28 / train/action_mean 0.05 / train/action_min -4.25 / train/action_std 1.09 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -2.12 / train/adv_mag 0.41 / train/adv_max 0.3 / train/adv_mean 4.5e-5 / train/adv_min -0.36 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 9.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.51 / train/extr_critic_max 669.51 / train/extr_critic_mean 628.31 / train/extr_critic_min 459.03 / train/extr_critic_std 58.32 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.27 / train/extr_return_raw_max 667.27 / train/extr_return_raw_mean 628.32 / train/extr_return_raw_min 458.75 / train/extr_return_raw_std 58.37
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.1 / 
train/model_opt_grad_norm 5.61 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8427.84 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.57 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.85 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.57 / train/policy_logprob_min -8.85 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.63 / train/policy_randomness_min 6.4e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 55.22 / train/post_ent_max 55.22 / train/post_ent_mean 37.3 / train/post_ent_min 
27.12 / train/post_ent_std 4.42 / train/prior_ent_mag 66.64 / train/prior_ent_max 66.64 / train/prior_ent_mean 38.48 / train/prior_ent_min 30.84 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.15 / train/reward_avg 1.3 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / train/reward_rate 0.65 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.76 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 2.69 / report/image_loss_mean 0.18 / report/image_loss_std 0.41 / report/model_loss_mean 1.19 / report/model_loss_std 1.94 / report/post_ent_mag 56.07 / report/post_ent_max 56.07 / 
report/post_ent_mean 36.21 / report/post_ent_min 26.99 / report/post_ent_std 4.23 / report/prior_ent_mag 66.76 / report/prior_ent_max 66.76 / report/prior_ent_mean 37.44 / report/prior_ent_min 31.49 / report/prior_ent_std 5.72 / report/rep_loss_mean 1.53 / 
report/rep_loss_std 2.69 / report/reward_avg 1.58 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.58 / report/reward_rate 0.79 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.99 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.16 / eval/model_loss_std 2.03 / eval/post_ent_mag 56.29 / eval/post_ent_max 56.29 / eval/post_ent_mean 37.55 / 
eval/post_ent_min 18.21 / eval/post_ent_std 3.63 / eval/prior_ent_mag 66.76 / eval/prior_ent_max 66.76 / eval/prior_ent_mean 38.67 / eval/prior_ent_min 31.71 / eval/prior_ent_std 5.13 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.99 / eval/reward_avg 1.55 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.55 / eval/reward_rate 0.77 / 
replay/size 5.1e5 / replay/inserts 3880 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.3 / timer/env.step_count 3880 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 404.79 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7888 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.6e-3 / 
timer/dataset_train_count 1940 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1940 / timer/agent.train_total 246.32 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.58

train_Episode has 500 steps and return 769.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 506500 Counter(506500) 506437
Saved chunk: 20230922T083536F344295-38XhSostA445xgduw3FZ3J-5d39lRv9ZOrhI0xJwWzZFu-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T083603F070988-7nndVuKGS8HPhjJSTkm6HZ-2XbIHJUEG14W4rmHxLIBfm-1024.npz
Starting evaluation at step 507000 Counter(507000) 506937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 507500 Counter(507500) 507437
Saved chunk: 20230922T083655F218097-5d39lRv9ZOrhI0xJwWzZFu-43jN8SlmNvc5Xcl0LSMxAr-1024.npz
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T083723F658632-2XbIHJUEG14W4rmHxLIBfm-5GwHaXEdSUG51qSqDjyEEv-1024.npz
Starting evaluation at step 508000 Counter(508000) 507937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 508500 Counter(508500) 508437
Saved chunk: 20230922T083813F203348-43jN8SlmNvc5Xcl0LSMxAr-561BISV8LuPlMPcW7tslrb-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T083843F137011-5GwHaXEdSUG51qSqDjyEEv-10Rgmn0gtYehtU4ms6ihcd-1024.npz
Starting evaluation at step 509000 Counter(509000) 508937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 509500 Counter(509500) 509437
Saved chunk: 20230922T083931F053184-561BISV8LuPlMPcW7tslrb-0ixLnfLn1Nff3oGBplfMus-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1019766 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / train_stats/mean_log_entropy 0.56 / train/action_mag 4.4 / train/action_max 4.22 / train/action_mean 0.05 / 
train/action_min -4.23 / train/action_std 1.06 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -2.23 / train/adv_mag 0.44 / train/adv_max 0.33
/ train/adv_mean 7.6e-5 / train/adv_min -0.37 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 /
train/cont_rate 1 / train/dyn_loss_mean 1.61 / train/dyn_loss_std 3.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / 
train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 669.28 / train/extr_critic_max 669.28 / train/extr_critic_mean 627.9 / train/extr_critic_min 455.58 / train/extr_critic_std 58.39 / train/extr_return_normed_mag
1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.26 / train/extr_return_raw_max 667.26 / train/extr_return_raw_mean 
627.91 / train/extr_return_raw_min 459.8 / train/extr_return_raw_std 58.45 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / 
train/model_loss_mean 1.23 / train/model_loss_std 2.15 / train/model_opt_grad_norm 5.67 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 /
train/policy_entropy_max 1.42 / train/policy_entropy_mean 0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.99 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.51 / train/policy_logprob_min -8.99 / 
train/policy_logprob_std 1.13 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 7.4e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 54.95 / train/post_ent_max 54.95 / 
train/post_ent_mean 37.31 / train/post_ent_min 26.97 / train/post_ent_std 4.42 / train/prior_ent_mag 66.79 / train/prior_ent_max 66.79 / train/prior_ent_mean 38.51 / train/prior_ent_min 30.9 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.22 /
train/reward_avg 1.3 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / 
train/reward_rate 0.65 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 7.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / report/cont_pred 1 / 
report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.52 / report/image_loss_mean 0.16 / report/image_loss_std 0.17 / report/model_loss_mean 1.15 / report/model_loss_std 1.64 / report/post_ent_mag 56.07 / report/post_ent_max 56.07 / report/post_ent_mean 
37.19 / report/post_ent_min 27.76 / report/post_ent_std 4.58 / report/prior_ent_mag 66.74 / report/prior_ent_max 66.74 / report/prior_ent_mean 38.37 / report/prior_ent_min 31.37 / report/prior_ent_std 5.99 / report/rep_loss_mean 1.52 / report/rep_loss_std 2.52 / 
report/reward_avg 1.25 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-7 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 
1.25 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 7.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 
/ eval/dyn_loss_std 3.05 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.28 / eval/model_loss_mean 1.17 / eval/model_loss_std 2.04 / eval/post_ent_mag 52.66 / eval/post_ent_max 52.66 / eval/post_ent_mean 38.06 / eval/post_ent_min 30.66 / eval/post_ent_std 3.29 / 
eval/prior_ent_mag 66.74 / eval/prior_ent_max 66.74 / eval/prior_ent_mean 39.15 / eval/prior_ent_min 31.63 / eval/prior_ent_std 4.87 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 3.05 / eval/reward_avg 1.45 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.1 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.3e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.44 / eval/reward_rate 0.73 / replay/size 5.1e5 / replay/inserts 3882 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3882 / timer/env.step_total 19.3 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.17 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.11 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7389 / timer/agent.policy_total 16.13 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.6e-3 / timer/dataset_train_count 1941 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1941 / timer/agent.train_total 246.49 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.87

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T084002F507150-10Rgmn0gtYehtU4ms6ihcd-6AcCXpsOJH9rZPlPDb1pk1-1024.npz
Starting evaluation at step 510000 Counter(510000) 509937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T084048F760300-0ixLnfLn1Nff3oGBplfMus-0000000000000000000000-643.npz
Saved chunk: 20230922T084122F748741-6AcCXpsOJH9rZPlPDb1pk1-0000000000000000000000-248.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 510500 Counter(510500) 510437
Saved chunk: 20230922T084048F760300-0ixLnfLn1Nff3oGBplfMus-0YqpiMroKtHSNP7EIx196m-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T084122F748741-6AcCXpsOJH9rZPlPDb1pk1-2ocUMOBzw0LudzGU1J0biR-1024.npz
Starting evaluation at step 511000 Counter(511000) 510937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 511500 Counter(511500) 511437
Saved chunk: 20230922T084208F007385-0YqpiMroKtHSNP7EIx196m-6iz8lxxgxjFNEXCphu7mfp-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 512000 Counter(512000) 511937
Saved chunk: 20230922T084242F633146-2ocUMOBzw0LudzGU1J0biR-5BHArGsIjaioBs4ccdbl6j-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 512500 Counter(512500) 512437
Saved chunk: 20230922T084325F807274-6iz8lxxgxjFNEXCphu7mfp-6lDKEJivyArgEV3qJxFfUs-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 513000 Counter(513000) 512937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T084401F932586-5BHArGsIjaioBs4ccdbl6j-5Wy2NInLWssB5JkyJCEsMP-1024.npz
Starting evaluation at step 513500 Counter(513500) 513437
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T084443F561203-6lDKEJivyArgEV3qJxFfUs-1ULDP5X1q9T5EEcAnekQYe-1024.npz
train_Episode has 500 steps and return 745.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1027434 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 774 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 745 / episode/reward_rate 0.75 / train/action_mag 4.38 / train/action_max 4.2 / train/action_mean 0.04 / train/action_min -4.19 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -1.34 / train/adv_mag 0.45 / train/adv_max 0.35 / train/adv_mean -1.5e-5 / train/adv_min -0.37 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.61 / train/extr_critic_max 669.61 / train/extr_critic_mean 629.46 / train/extr_critic_min 457.92 / train/extr_critic_std 56.68 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.62 / train/extr_return_raw_max 667.62 / train/extr_return_raw_mean 629.46 / train/extr_return_raw_min 461.87 / train/extr_return_raw_std 56.77
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.22 / train/model_loss_std 2.13 / 
train/model_opt_grad_norm 6.07 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.9 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.51 / train/policy_logprob_min -8.9 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 7.3e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 54.97 / train/post_ent_max 54.97 / train/post_ent_mean 37.29 / train/post_ent_min 
27.12 / train/post_ent_std 4.42 / train/prior_ent_mag 66.69 / train/prior_ent_max 66.69 / train/prior_ent_mean 38.48 / train/prior_ent_min 31.12 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.18 / train/reward_avg 1.3 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / train/reward_rate 0.65 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.61 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.51 / report/dyn_loss_std 2.77 / report/image_loss_mean 0.14 / report/image_loss_std 0.21 / report/model_loss_mean 1.13 / report/model_loss_std 1.83 / report/post_ent_mag 55.65 / report/post_ent_max 55.65 / 
report/post_ent_mean 36.2 / report/post_ent_min 26.33 / report/post_ent_std 4.1 / report/prior_ent_mag 66.6 / report/prior_ent_max 66.6 / report/prior_ent_mean 37.18 / report/prior_ent_min 31.2 / report/prior_ent_std 5.56 / report/rep_loss_mean 1.51 / report/rep_loss_std 
2.77 / report/reward_avg 1.55 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.4e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / 
report/reward_pred 1.55 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.52 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.67 / eval/post_ent_mag 56.4 / eval/post_ent_max 56.4 / eval/post_ent_mean 37.07 / eval/post_ent_min 28.92 / 
eval/post_ent_std 3.58 / eval/prior_ent_mag 66.6 / eval/prior_ent_max 66.6 / eval/prior_ent_mean 38.06 / eval/prior_ent_min 31.59 / eval/prior_ent_std 5.16 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.52 / eval/reward_avg 1.56 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.3e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.56 / eval/reward_rate 0.78 / replay/size 5.1e5 / replay/inserts 3834 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3834 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.42 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.8e-4 / 
timer/agent.train_count 1917 / timer/agent.train_total 243.42 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / 
timer/dataset_eval_max 4.4e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 514000 Counter(514000) 513937
eval_Episode has 500 steps and return 756.0.
train_Episode has 500 steps and return 747.0.
Saved chunk: 20230922T084524F540262-5Wy2NInLWssB5JkyJCEsMP-2M0EbFp5BGfHm9EZJMytNW-1024.npz
Starting evaluation at step 514500 Counter(514500) 514437
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T084601F205678-1ULDP5X1q9T5EEcAnekQYe-1EVRxoO9MYkMwB6mrVjkhD-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 515000 Counter(515000) 514937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T084644F973771-2M0EbFp5BGfHm9EZJMytNW-5Ih20PCmywSLcRjgZJVtpn-1024.npz
Starting evaluation at step 515500 Counter(515500) 515437
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T084720F246694-1EVRxoO9MYkMwB6mrVjkhD-2O4aNJWSBSsoo37AqxczMh-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 516000 Counter(516000) 515937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T084804F402419-5Ih20PCmywSLcRjgZJVtpn-4RCRNj36TyHM5y1hmTfbZG-1024.npz
Starting evaluation at step 516500 Counter(516500) 516437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 517000 Counter(517000) 516937
Saved chunk: 20230922T084838F127197-2O4aNJWSBSsoo37AqxczMh-4XLstmeUIEflc5O7jz8pNH-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T084923F846358-4RCRNj36TyHM5y1hmTfbZG-62zZfZY61ra2SCOWSPB5im-1024.npz
Starting evaluation at step 517500 Counter(517500) 517437
eval_Episode has 500 steps and return 741.0.
train_Episode has 500 steps and return 769.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1035106 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 741 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / train/action_mag 4.29 / train/action_max 4.1 / train/action_mean 0.04 / train/action_min -4.13 / train/action_std 1.02 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -2.7 / train/adv_mag 0.43 / train/adv_max 0.33 / train/adv_mean 1.3e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.91 / train/extr_critic_max 669.91 / train/extr_critic_mean 628.35 / train/extr_critic_min 455.09 / train/extr_critic_std 58.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.88 / train/extr_return_raw_max 667.88 / train/extr_return_raw_mean 628.37 / train/extr_return_raw_min 457.93 / train/extr_return_raw_std 58.99
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.07 / 
train/model_opt_grad_norm 5.46 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 6.1e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 54.98 / train/post_ent_max 54.98 / train/post_ent_mean 37.25 / train/post_ent_min
27.24 / train/post_ent_std 4.48 / train/prior_ent_mag 66.49 / train/prior_ent_max 66.49 / train/prior_ent_mean 38.43 / train/prior_ent_min 30.93 / train/prior_ent_std 5.77 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.3 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / train/reward_rate 0.65 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.58 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.38 / report/image_loss_mean 0.21 / report/image_loss_std 0.25 / report/model_loss_mean 1.23 / report/model_loss_std 2.2 / report/post_ent_mag 56.34 / report/post_ent_max 56.34 / 
report/post_ent_mean 39.45 / report/post_ent_min 30.85 / report/post_ent_std 4.11 / report/prior_ent_mag 66.72 / report/prior_ent_max 66.72 / report/prior_ent_mean 40.66 / report/prior_ent_min 32.31 / report/prior_ent_std 5.4 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.38 / report/reward_avg 0.7 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 0.7 / report/reward_rate 0.35 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 3.48 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.24 / eval/post_ent_mag 50.81 / eval/post_ent_max 50.81 / eval/post_ent_mean 37.66 / eval/post_ent_min 21.8 / 
eval/post_ent_std 3.74 / eval/prior_ent_mag 66.72 / eval/prior_ent_max 66.72 / eval/prior_ent_mean 38.7 / eval/prior_ent_min 31.37 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.48 / eval/reward_avg 1.53 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / replay/size 5.2e5 / replay/inserts 3836 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3836 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.06 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 518000 Counter(518000) 517937
Saved chunk: 20230922T085031F228193-4XLstmeUIEflc5O7jz8pNH-1YXRjs9GS602JvFfuDxAkp-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T085042F985930-62zZfZY61ra2SCOWSPB5im-0KfYqQCIloR07mPCpQlJl1-1024.npz
Starting evaluation at step 518500 Counter(518500) 518437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 519000 Counter(519000) 518937
Saved chunk: 20230922T085150F073338-1YXRjs9GS602JvFfuDxAkp-6kyB7o6j0O6BlqqHV4vQIb-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T085203F490677-0KfYqQCIloR07mPCpQlJl1-3sH9CVdlELGUeLRObDf2vD-1024.npz
Starting evaluation at step 519500 Counter(519500) 519437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 520000 Counter(520000) 519937
Saved chunk: 20230922T085307F947360-6kyB7o6j0O6BlqqHV4vQIb-5hi2ddws5wTSIViAnx4Xji-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T085322F842216-3sH9CVdlELGUeLRObDf2vD-0HVxbuuSrjad82x30ncqLG-1024.npz
Starting evaluation at step 520500 Counter(520500) 520437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 521000 Counter(521000) 520937
Saved chunk: 20230922T085425F654216-5hi2ddws5wTSIViAnx4Xji-5gZ7PsvpH7VjY9XYagOoZ8-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T085442F101940-0HVxbuuSrjad82x30ncqLG-0pZjjF2Fl8CzKMOZPpouSo-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1042876 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / train/action_mag 4.27 / train/action_max 4.12 / train/action_mean 0.05 / train/action_min -4.05 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -2.05 / train/adv_mag 0.42 / train/adv_max 0.32 / train/adv_mean 6.1e-5 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.72 / train/extr_critic_max 669.72 / train/extr_critic_mean 628.39 / train/extr_critic_min 458.84 / train/extr_critic_std 58.57 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.79 / train/extr_return_raw_max 667.79 / train/extr_return_raw_mean 628.4 / train/extr_return_raw_min 458.61 / train/extr_return_raw_std 58.61 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.32 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / train/model_loss_mean 1.23 / train/model_loss_std 2.14 / 
train/model_opt_grad_norm 5.7 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean
0.49 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.95 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.49 / train/policy_logprob_min -8.95 / train/policy_logprob_std 1.12 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 7e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.35 / train/post_ent_max 55.35 / train/post_ent_mean 37.19 / train/post_ent_min 26.81 / train/post_ent_std 4.47 / 
train/prior_ent_mag 66.65 / train/prior_ent_max 66.65 / train/prior_ent_mean 38.38 / train/prior_ent_min 30.9 / train/prior_ent_std 5.78 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.2 / train/reward_avg 1.29 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 /
train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.29 / train/reward_rate 0.65 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy
0.65 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / 
report/dyn_loss_std 2.93 / report/image_loss_mean 0.16 / report/image_loss_std 0.17 / report/model_loss_mean 1.16 / report/model_loss_std 1.87 / report/post_ent_mag 54.51 / report/post_ent_max 54.51 / report/post_ent_mean 37.31 / report/post_ent_min 27.38 / 
report/post_ent_std 4.75 / report/prior_ent_mag 66.05 / report/prior_ent_max 66.05 / report/prior_ent_mean 38.38 / report/prior_ent_min 30.23 / report/prior_ent_std 5.93 / report/rep_loss_mean 1.53 / report/rep_loss_std 2.93 / report/reward_avg 1.19 / 
report/reward_loss_mean 0.08 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.19 / 
report/reward_rate 0.6 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 8.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / 
eval/dyn_loss_std 2.66 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.14 / eval/model_loss_std 1.8 / eval/post_ent_mag 51.46 / eval/post_ent_max 51.46 / eval/post_ent_mean 37.21 / eval/post_ent_min 31.27 / eval/post_ent_std 3.44 / 
eval/prior_ent_mag 66.05 / eval/prior_ent_max 66.05 / eval/prior_ent_mean 38.29 / eval/prior_ent_min 32.78 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.66 / eval/reward_avg 1.5 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.08 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / replay/size 5.2e5 / replay/inserts 3885 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3885 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.2e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.21 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7392 / timer/agent.policy_total 16.33 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1942 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.33 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 521500 Counter(521500) 521437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T085601F339574-0pZjjF2Fl8CzKMOZPpouSo-0000000000000000000000-584.npz
Saved chunk: 20230922T085543F383765-5gZ7PsvpH7VjY9XYagOoZ8-0000000000000000000000-902.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 522000 Counter(522000) 521937
Saved chunk: 20230922T085543F383765-5gZ7PsvpH7VjY9XYagOoZ8-2TGfyBFnRpBd3qdzEoUsmJ-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T085601F339574-0pZjjF2Fl8CzKMOZPpouSo-62Q1EZN2eeORo3DbRrV44S-1024.npz
Starting evaluation at step 522500 Counter(522500) 522437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 523000 Counter(523000) 522937
Saved chunk: 20230922T085702F604742-2TGfyBFnRpBd3qdzEoUsmJ-7GYx2LeLNSowwO7gWRuKJA-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T085722F266255-62Q1EZN2eeORo3DbRrV44S-3iK0uf6W5lJIJHyxlSWlUk-1024.npz
Starting evaluation at step 523500 Counter(523500) 523437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 524000 Counter(524000) 523937
Saved chunk: 20230922T085820F473523-7GYx2LeLNSowwO7gWRuKJA-6sYIM5k8272BaMxJPd0rJG-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T085841F602254-3iK0uf6W5lJIJHyxlSWlUk-55dKV6APVLNvRZivbETBIS-1024.npz
Starting evaluation at step 524500 Counter(524500) 524437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 525000 Counter(525000) 524937
Saved chunk: 20230922T085938F235116-6sYIM5k8272BaMxJPd0rJG-5Um1KfgX1a1TrwTIk4c97V-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1050538 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / train/action_mag 4.13 / train/action_max 3.79 / train/action_mean 0.06 / train/action_min -4.02 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -0.49 / train/adv_mag 0.42 / train/adv_max 0.31 / train/adv_mean -3.2e-5 / train/adv_min -0.36 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.82 / train/extr_critic_max 669.82 / train/extr_critic_mean 628.91 / train/extr_critic_min 456.19 / train/extr_critic_std 59.61 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.86 / train/extr_return_raw_max 667.86 / train/extr_return_raw_mean 628.9 / train/extr_return_raw_min 457.21 / train/extr_return_raw_std 59.74 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.35 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.04 / 
train/model_opt_grad_norm 5.78 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.28 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.82 / train/policy_logprob_mag 8.6 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.28 / train/policy_logprob_min -8.6 / train/policy_logprob_std 1.08 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 8.8e-5 / train/policy_randomness_std 0.35 / train/post_ent_mag 55.21 / train/post_ent_max 55.21 / train/post_ent_mean 37.06 / train/post_ent_min 
27.23 / train/post_ent_std 4.49 / train/prior_ent_mag 66.61 / train/prior_ent_max 66.61 / train/prior_ent_mean 38.23 / train/prior_ent_min 30.94 / train/prior_ent_std 5.79 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.07 / train/reward_avg 1.33 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.33 / train/reward_rate 0.67 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.31 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 6.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 3.13 / report/image_loss_mean 0.16 / report/image_loss_std 0.33 / report/model_loss_mean 1.16 / report/model_loss_std 2.15 / report/post_ent_mag 52.9 / report/post_ent_max 52.9 / 
report/post_ent_mean 36.36 / report/post_ent_min 28.58 / report/post_ent_std 4.51 / report/prior_ent_mag 66.85 / report/prior_ent_max 66.85 / report/prior_ent_mean 37.47 / report/prior_ent_min 29.62 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 3.13 / report/reward_avg 1.46 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.46 / report/reward_rate 0.73 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 4.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.65 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.77 / eval/post_ent_mag 54.72 / eval/post_ent_max 54.72 / eval/post_ent_mean 
36.66 / eval/post_ent_min 29.53 / eval/post_ent_std 3.48 / eval/prior_ent_mag 66.85 / eval/prior_ent_max 66.85 / eval/prior_ent_mean 37.66 / eval/prior_ent_min 31.34 / eval/prior_ent_std 5.03 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.65 / eval/reward_avg 1.8 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.8 / eval/reward_rate 0.9 / replay/size 
5.3e5 / replay/inserts 3831 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3831 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.76 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7839 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.25 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T090000F856067-55dKV6APVLNvRZivbETBIS-4BGsLEqrSl2nP12G7sUg1j-1024.npz
Starting evaluation at step 525500 Counter(525500) 525437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 526000 Counter(526000) 525937
Saved chunk: 20230922T090055F892108-5Um1KfgX1a1TrwTIk4c97V-3TNhIeprnXUx8dd29qjYYb-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T090121F085129-4BGsLEqrSl2nP12G7sUg1j-0ziZf31WQc2pBOy7UYz76f-1024.npz
Starting evaluation at step 526500 Counter(526500) 526437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 527000 Counter(527000) 526937
Saved chunk: 20230922T090214F927307-3TNhIeprnXUx8dd29qjYYb-05PnwljWiinSg8oAoRRmeF-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T090240F713257-0ziZf31WQc2pBOy7UYz76f-0evZOIU24UHgI0rb420F8e-1024.npz
Starting evaluation at step 527500 Counter(527500) 527437
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 528000 Counter(528000) 527937
Saved chunk: 20230922T090332F750109-05PnwljWiinSg8oAoRRmeF-3msJTRueR4AHcEhAzgQFAA-1024.npz
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 765.0.
Saved chunk: 20230922T090400F065929-0evZOIU24UHgI0rb420F8e-2K018njhRoxkvNQgSwn6sx-1024.npz
Starting evaluation at step 528500 Counter(528500) 528437
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 529000 Counter(529000) 528937
Saved chunk: 20230922T090450F511300-3msJTRueR4AHcEhAzgQFAA-09zge1NuZDpXoAAsrj1Tcf-1024.npz
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 724.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1058206 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 760 / eval_episode/reward_rate 0.76 / episode/length 500 / episode/score 724 / episode/reward_rate 0.73 / train/action_mag 4.12 / train/action_max 3.84 / train/action_mean 0.08 / train/action_min -4 / train/action_std 0.97 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -1 / train/adv_mag 0.43 / train/adv_max 0.31 / train/adv_mean -1.3e-5 / train/adv_min -0.38 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 9.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.92 / train/extr_critic_max 669.92 / train/extr_critic_mean 628.25 / train/extr_critic_min 450.44 / train/extr_critic_std 61.05 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.23 / train/extr_return_raw_max 668.23 / train/extr_return_raw_mean 628.25 / train/extr_return_raw_min 451.61 / train/extr_return_raw_std 61.17
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.35 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.05 / 
train/model_opt_grad_norm 5.25 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.38 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.83 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.38 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.09 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.36 / train/post_ent_mag 54.79 / train/post_ent_max 54.79 / train/post_ent_mean 36.92 / train/post_ent_min
27.16 / train/post_ent_std 4.59 / train/prior_ent_mag 66.43 / train/prior_ent_max 66.43 / train/prior_ent_mean 38.1 / train/prior_ent_min 30.57 / train/prior_ent_std 5.86 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.07 / train/reward_avg 1.32 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.23 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 7.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 2.59 / report/image_loss_mean 0.16 / report/image_loss_std 0.16 / report/model_loss_mean 1.18 / report/model_loss_std 1.65 / report/post_ent_mag 57.79 / report/post_ent_max 57.79 / 
report/post_ent_mean 37.15 / report/post_ent_min 27.9 / report/post_ent_std 4.96 / report/prior_ent_mag 66.47 / report/prior_ent_max 66.47 / report/prior_ent_mean 38.44 / report/prior_ent_min 29.16 / report/prior_ent_std 6.07 / report/rep_loss_mean 1.55 / 
report/rep_loss_std 2.59 / report/reward_avg 1.35 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.35 / report/reward_rate 0.68 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 5.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.1 / eval/model_loss_std 1.7 / eval/post_ent_mag 55.07 / eval/post_ent_max 55.07 / eval/post_ent_mean 36.69
/ eval/post_ent_min 25.21 / eval/post_ent_std 3.3 / eval/prior_ent_mag 66.47 / eval/prior_ent_max 66.47 / eval/prior_ent_mean 37.74 / eval/prior_ent_min 30.92 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.6 / eval/reward_avg 1.8 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.8 / eval/reward_rate 0.9 / replay/size 
5.3e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3834 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.28 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.19 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.35 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T090519F376806-2K018njhRoxkvNQgSwn6sx-5aIWKyBVXG5nFjFTP7iylb-1024.npz
Starting evaluation at step 529500 Counter(529500) 529437
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 667.0.
Starting evaluation at step 530000 Counter(530000) 529937
Saved chunk: 20230922T090608F195363-09zge1NuZDpXoAAsrj1Tcf-15MoFDEyt9xOaXRYfKQyxq-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T090639F797165-5aIWKyBVXG5nFjFTP7iylb-44UGPxSW4y3xfs7QfIh2Qw-1024.npz
Starting evaluation at step 530500 Counter(530500) 530437
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 531000 Counter(531000) 530937
Saved chunk: 20230922T090727F357196-15MoFDEyt9xOaXRYfKQyxq-0SDfjIzGblySWNXZsRkqZx-1024.npz
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T090759F402109-44UGPxSW4y3xfs7QfIh2Qw-4TCNwJNZt7hIasPJECPKqy-1024.npz
Starting evaluation at step 531500 Counter(531500) 531437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 532000 Counter(532000) 531937
Saved chunk: 20230922T090845F206779-0SDfjIzGblySWNXZsRkqZx-0s3uYuPmWzZsY7G09GhpNW-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T090918F755320-4TCNwJNZt7hIasPJECPKqy-4euFCkFHOuqC3GOWHg78rD-1024.npz
Starting evaluation at step 532500 Counter(532500) 532437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 754.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1065966 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 771 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 754 / episode/reward_rate 0.76 / train/action_mag 4.17 / train/action_max 3.92 / train/action_mean 0.04 / train/action_min -4.03 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -5.21 / train/adv_mag 0.43 / train/adv_max 0.34 / train/adv_mean 4.1e-4 / train/adv_min -0.36 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 8.7e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.62 / train/extr_critic_max 670.62 / train/extr_critic_mean 628.89 / train/extr_critic_min 449.28 / train/extr_critic_std 59.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.66 / train/extr_return_raw_max 668.66 / train/extr_return_raw_mean 628.96 / train/extr_return_raw_min 453.82 / train/extr_return_raw_std 59.92
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.34 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.64 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.85 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.85 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.37 / train/post_ent_mag 55.18 / train/post_ent_max 55.18 / train/post_ent_mean 37.02 / train/post_ent_min
27.07 / train/post_ent_std 4.52 / train/prior_ent_mag 66.24 / train/prior_ent_max 66.24 / train/prior_ent_mean 38.22 / train/prior_ent_min 30.72 / train/prior_ent_std 5.8 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.31 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.31 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.41 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 9.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.45 / report/image_loss_mean 0.17 / report/image_loss_std 0.34 / report/model_loss_mean 1.23 / report/model_loss_std 2.34 / report/post_ent_mag 54.89 / report/post_ent_max 54.89 / 
report/post_ent_mean 37.24 / report/post_ent_min 28.36 / report/post_ent_std 4.52 / report/prior_ent_mag 66.26 / report/prior_ent_max 66.26 / report/prior_ent_mean 38.49 / report/prior_ent_min 30.76 / report/prior_ent_std 5.78 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.45 / report/reward_avg 1.31 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.31 / report/reward_rate 0.66 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.57 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.73 / eval/post_ent_mag 55.81 / eval/post_ent_max 55.81 / eval/post_ent_mean 37
/ eval/post_ent_min 28.79 / eval/post_ent_std 4.31 / eval/prior_ent_mag 66.26 / eval/prior_ent_max 66.26 / eval/prior_ent_mean 38.17 / eval/prior_ent_min 30.82 / eval/prior_ent_std 5.68 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.57 / eval/reward_avg 1.29 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.3 / eval/reward_rate 0.65 / replay/size 
5.3e5 / replay/inserts 3880 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3880 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 /
timer/env.step_min 4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.7 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7387 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1940 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1940 / timer/agent.train_total 246.45 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.87

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 533000 Counter(533000) 532937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T091002F931087-0s3uYuPmWzZsY7G09GhpNW-4U4bGE9yVYV55xmsysKs26-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T091038F081032-4euFCkFHOuqC3GOWHg78rD-0000000000000000000000-920.npz
Saved chunk: 20230922T091121F823756-4U4bGE9yVYV55xmsysKs26-0000000000000000000000-137.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 533500 Counter(533500) 533437
eval_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T091038F081032-4euFCkFHOuqC3GOWHg78rD-1dfb09afycqFaUEaTbPCGL-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 534000 Counter(534000) 533937
Saved chunk: 20230922T091121F823756-4U4bGE9yVYV55xmsysKs26-075Dd9ti20RNXWREQzXVCj-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 534500 Counter(534500) 534437
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T091202F303789-1dfb09afycqFaUEaTbPCGL-5dJsngyXkggVUfggawLLEd-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 535000 Counter(535000) 534937
Saved chunk: 20230922T091240F143480-075Dd9ti20RNXWREQzXVCj-6Y0i3PzMHbKeLzlqveNRUh-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 535500 Counter(535500) 535437
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T091321F801998-5dJsngyXkggVUfggawLLEd-5lWVDvhmx3bYeugUbG0Xhn-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 536000 Counter(536000) 535937
Saved chunk: 20230922T091357F999510-6Y0i3PzMHbKeLzlqveNRUh-2JZm48HRYycAJtnLrkeWYx-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 536500 Counter(536500) 536437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T091441F157406-5lWVDvhmx3bYeugUbG0Xhn-2URCGL7TtlzTTlzIMFjuvm-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1073622 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 767 / episode/reward_rate 0.77 / train/action_mag 4.24 / train/action_max 3.92 / train/action_mean 0.03 / train/action_min -4.13 / train/action_std 0.98 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.67 / train/adv_mag 0.41 / train/adv_max 0.3 / train/adv_mean 1.7e-4 / train/adv_min -0.37 / 
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 8.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.73 / train/extr_critic_max 670.73 / train/extr_critic_mean 630.41 / train/extr_critic_min 457.53 / train/extr_critic_std 58.27 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.18 / train/extr_return_raw_max 669.18 / train/extr_return_raw_mean 630.44 / train/extr_return_raw_min 458.03 / train/extr_return_raw_std 58.3 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.35 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.68 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.35 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.84 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.35 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.37 / train/post_ent_mag 54.67 / train/post_ent_max 54.67 / train/post_ent_mean 36.96 / train/post_ent_min
27.1 / train/post_ent_std 4.56 / train/prior_ent_mag 66.35 / train/prior_ent_max 66.35 / train/prior_ent_mean 38.14 / train/prior_ent_min 30.67 / train/prior_ent_std 5.83 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.11 / train/reward_avg 1.32 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.04 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 2.82 / report/image_loss_mean 0.14 / report/image_loss_std 0.21 / report/model_loss_mean 1.16 / report/model_loss_std 1.87 / report/post_ent_mag 51.42 / report/post_ent_max 51.42 / 
report/post_ent_mean 35.5 / report/post_ent_min 28.22 / report/post_ent_std 4.93 / report/prior_ent_mag 66.26 / report/prior_ent_max 66.26 / report/prior_ent_mean 36.6 / report/prior_ent_min 30.68 / report/prior_ent_std 6.17 / report/rep_loss_mean 1.53 / 
report/rep_loss_std 2.82 / report/reward_avg 1.65 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.13 / report/reward_pred 1.64 / report/reward_rate 0.83 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 3.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.41 / eval/dyn_loss_std 2.1 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.32 / eval/model_loss_mean 1.07 / eval/model_loss_std 1.51 / eval/post_ent_mag 55.71 / eval/post_ent_max 55.71 / eval/post_ent_mean 35.34 / eval/post_ent_min 27.81 / 
eval/post_ent_std 3.72 / eval/prior_ent_mag 66.26 / eval/prior_ent_max 66.26 / eval/prior_ent_mean 36.4 / eval/prior_ent_min 30.84 / eval/prior_ent_std 5.22 / eval/rep_loss_mean 1.41 / eval/rep_loss_std 2.1 / eval/reward_avg 1.81 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.4e-8 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.81 / eval/reward_rate 0.91 / replay/size 5.4e5 / replay/inserts 3828 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3828 / timer/env.step_total 18.87 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.28 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7836 / timer/agent.policy_total 17.39 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.3e-4 / 
timer/agent.train_count 1914 / timer/agent.train_total 243.28 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / 
timer/dataset_eval_max 3.3e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 537000 Counter(537000) 536937
Saved chunk: 20230922T091515F808625-2JZm48HRYycAJtnLrkeWYx-0BjqZxpspyTDonHdW7lArw-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 537500 Counter(537500) 537437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T091600F437654-2URCGL7TtlzTTlzIMFjuvm-7w3RX4p28yUVIeVFKXtGA0-1024.npz
Starting evaluation at step 538000 Counter(538000) 537937
eval_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T091634F690672-0BjqZxpspyTDonHdW7lArw-6VcLy9kLTWR09fJFGx1wzR-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 538500 Counter(538500) 538437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T091721F208514-7w3RX4p28yUVIeVFKXtGA0-7Cq7oUZovJbw9VH5W0fvjg-1024.npz
Starting evaluation at step 539000 Counter(539000) 538937
eval_Episode has 500 steps and return 764.0.
Saved chunk: 20230922T091752F737068-6VcLy9kLTWR09fJFGx1wzR-5QeyrdblaoutfyNGohyq26-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 539500 Counter(539500) 539437
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T091840F581835-7Cq7oUZovJbw9VH5W0fvjg-5N1ZTD8IPQ7lONoUNiczMz-1024.npz
Starting evaluation at step 540000 Counter(540000) 539937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 540500 Counter(540500) 540437
Saved chunk: 20230922T091910F627181-5QeyrdblaoutfyNGohyq26-1qYUWnDaOpbccqjFRTcYFU-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1081286 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / train/action_mag 4.18 / train/action_max 3.9 / train/action_mean 0.03 / train/action_min -4.07 / train/action_std 0.98 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.34 / train/adv_mag 0.48 / train/adv_max 0.36 / train/adv_mean 1.3e-4 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 9.3e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.25 / train/extr_critic_max 671.25 / train/extr_critic_mean 630.88 / train/extr_critic_min 455.36 / train/extr_critic_std 57.99 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.09 / train/extr_return_raw_max 669.09 / train/extr_return_raw_mean 630.9 / train/extr_return_raw_min 459.17 / train/extr_return_raw_std 58.03 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.35 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.29 / train/model_loss_mean 1.22 / train/model_loss_std 2.1 / 
train/model_opt_grad_norm 5.75 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8281.25 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.37 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.67 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.37 / train/policy_logprob_min -8.67 / train/policy_logprob_std 1.1 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.37 / train/post_ent_mag 54.72 / train/post_ent_max 54.72 / train/post_ent_mean 36.88 / train/post_ent_min
26.98 / train/post_ent_std 4.61 / train/prior_ent_mag 66.31 / train/prior_ent_max 66.31 / train/prior_ent_mean 38.08 / train/prior_ent_min 30.46 / train/prior_ent_std 5.88 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.15 / train/reward_avg 1.32 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.24 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 6.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.17 / report/image_loss_mean 0.18 / report/image_loss_std 0.3 / report/model_loss_mean 1.25 / report/model_loss_std 2.12 / report/post_ent_mag 51.43 / report/post_ent_max 51.43 / 
report/post_ent_mean 36.03 / report/post_ent_min 28.01 / report/post_ent_std 4.98 / report/prior_ent_mag 66.46 / report/prior_ent_max 66.46 / report/prior_ent_mean 37.28 / report/prior_ent_min 30.24 / report/prior_ent_std 6.25 / report/rep_loss_mean 1.62 / 
report/rep_loss_std 3.17 / report/reward_avg 1.48 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.48 / report/reward_rate 0.74 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 5.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.57 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.16 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.65 / eval/post_ent_mag 55.03 / eval/post_ent_max 55.03 / eval/post_ent_mean 
36.9 / eval/post_ent_min 29.85 / eval/post_ent_std 3.91 / eval/prior_ent_mag 66.46 / eval/prior_ent_max 66.46 / eval/prior_ent_mean 37.97 / eval/prior_ent_min 32.3 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.57 / eval/reward_avg 1.53 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / 
replay/size 5.4e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3832 / timer/env.step_total 18.9 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3
/ timer/env.step_min 4.2e-3 / timer/env.step_max 7.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.63 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.19 / 
timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.46 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T091959F916470-5N1ZTD8IPQ7lONoUNiczMz-2SfQxK7yPQ5xjkHPOwXIrh-1024.npz
Starting evaluation at step 541000 Counter(541000) 540937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 541500 Counter(541500) 541437
Saved chunk: 20230922T092103F820424-1qYUWnDaOpbccqjFRTcYFU-6ly10kEW7phGiDOi6gFeZ3-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T092120F240406-2SfQxK7yPQ5xjkHPOwXIrh-60uTgpJjZ0GtDxJzkS7RrF-1024.npz
Starting evaluation at step 542000 Counter(542000) 541937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 542500 Counter(542500) 542437
Saved chunk: 20230922T092222F964759-6ly10kEW7phGiDOi6gFeZ3-3YToi6yPbFB2fzLFE2CGqM-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T092239F986840-60uTgpJjZ0GtDxJzkS7RrF-0NM8mAh9gWEWRj8N3EMOxv-1024.npz
Starting evaluation at step 543000 Counter(543000) 542937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 543500 Counter(543500) 543437
Saved chunk: 20230922T092340F854063-3YToi6yPbFB2fzLFE2CGqM-5oYNd6OHbVUgG5SueyKVFg-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 760.0.
Saved chunk: 20230922T092359F372202-0NM8mAh9gWEWRj8N3EMOxv-1mD0aLLQwmlDCJZd6iN6hG-1024.npz
Starting evaluation at step 544000 Counter(544000) 543937
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 544500 Counter(544500) 544437
Saved chunk: 20230922T092458F536731-5oYNd6OHbVUgG5SueyKVFg-0kx9g8ipCZAgonRHy7z3uH-1024.npz
eval_Episode has 500 steps and return 772.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1089002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 772 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 768 / episode/reward_rate 0.77 / train/action_mag 4.16 / train/action_max 3.89 / train/action_mean 0.04 / train/action_min -4.02 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss 0.48 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean -1.5e-4 / train/adv_min -0.39 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 9.7e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.8 / train/extr_critic_max 670.8 / train/extr_critic_mean 629.2 / train/extr_critic_min 457.9 / train/extr_critic_std 58.45 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.13 / train/extr_return_raw_max 669.13 / train/extr_return_raw_mean 629.18 / train/extr_return_raw_min 459.34 / train/extr_return_raw_std 58.58
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.29 / train/model_loss_mean 1.22 / train/model_loss_std 2.11 / 
train/model_opt_grad_norm 5.57 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9119.17 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.33 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.82 / train/policy_logprob_mag 8.67 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.33 / train/policy_logprob_min -8.67 / train/policy_logprob_std 1.08 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 1.2e-4 / train/policy_randomness_std 0.36 / train/post_ent_mag 54.57 / train/post_ent_max 54.57 / train/post_ent_mean 36.94 / train/post_ent_min
26.97 / train/post_ent_std 4.63 / train/prior_ent_mag 66.32 / train/prior_ent_max 66.32 / train/prior_ent_mean 38.15 / train/prior_ent_min 30.31 / train/prior_ent_std 5.88 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.15 / train/reward_avg 1.31 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.31 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.26 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.44 / report/dyn_loss_std 2.23 / report/image_loss_mean 0.12 / report/image_loss_std 0.15 / report/model_loss_mean 1.09 / report/model_loss_std 1.46 / report/post_ent_mag 51.82 / report/post_ent_max 51.82 / 
report/post_ent_mean 34.5 / report/post_ent_min 27.5 / report/post_ent_std 4.25 / report/prior_ent_mag 66.16 / report/prior_ent_max 66.16 / report/prior_ent_mean 35.59 / report/prior_ent_min 30.54 / report/prior_ent_std 5.57 / report/rep_loss_mean 1.44 / 
report/rep_loss_std 2.23 / report/reward_avg 1.76 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.76 / report/reward_rate 0.88 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 5.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.83 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.83 / eval/post_ent_mag 55.4 / eval/post_ent_max 55.4 / eval/post_ent_mean 
37.13 / eval/post_ent_min 29.3 / eval/post_ent_std 3.78 / eval/prior_ent_mag 66.16 / eval/prior_ent_max 66.16 / eval/prior_ent_mean 38.26 / eval/prior_ent_min 31.52 / eval/prior_ent_std 5.2 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.83 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.6 / eval/reward_rate 0.8 / replay/size 
5.4e5 / replay/inserts 3858 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.71 / timer/env.step_count 3858 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.46 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7866 / timer/agent.policy_total 17.31 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.19 / 
timer/dataset_train_count 1929 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1929 / timer/agent.train_total 244.87 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 759.0.
Saved chunk: 20230922T092518F599753-1mD0aLLQwmlDCJZd6iN6hG-6lBnjwVmTnCv68g5uzQjab-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 545000 Counter(545000) 544937
Saved chunk: 20230922T092616F135350-0kx9g8ipCZAgonRHy7z3uH-0000000000000000000000-396.npz
Saved chunk: 20230922T092638F973180-6lBnjwVmTnCv68g5uzQjab-0000000000000000000000-232.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 545500 Counter(545500) 545437
Saved chunk: 20230922T092616F135350-0kx9g8ipCZAgonRHy7z3uH-6MBtGivG7pdTdACxnwFucR-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T092638F973180-6lBnjwVmTnCv68g5uzQjab-2yMDyetH3SuJDdtHJyWEjM-1024.npz
Starting evaluation at step 546000 Counter(546000) 545937
eval_Episode has 500 steps and return 766.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 546500 Counter(546500) 546437
Saved chunk: 20230922T092735F680668-6MBtGivG7pdTdACxnwFucR-4yl4FvdqFmptYnbsY4k7US-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T092758F913368-2yMDyetH3SuJDdtHJyWEjM-1bpsWd91vzVS5Uy98bLjy3-1024.npz
Starting evaluation at step 547000 Counter(547000) 546937
eval_Episode has 500 steps and return 767.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 547500 Counter(547500) 547437
Saved chunk: 20230922T092853F545603-4yl4FvdqFmptYnbsY4k7US-0EoP823YbpUEPTGweBHn67-1024.npz
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T092918F278720-1bpsWd91vzVS5Uy98bLjy3-2xjsSdpZz9J46318HzQ1WS-1024.npz
Starting evaluation at step 548000 Counter(548000) 547937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1096754 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / train/action_mag 4.1 / train/action_max 3.85 / train/action_mean 0.04 / train/action_min -3.96 / train/action_std 0.98 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -1.56 / train/adv_mag 0.44 / train/adv_max 0.33 / train/adv_mean 6e-5 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 9.2e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.08 / train/extr_critic_max 670.08 / train/extr_critic_mean 628.81 / train/extr_critic_min 458.32 / train/extr_critic_std 58.81 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.24 / train/extr_return_raw_max 668.24 / train/extr_return_raw_mean 628.82 / train/extr_return_raw_min 458.89 / train/extr_return_raw_std 58.88
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.35 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.29 / train/model_loss_mean 1.21 / train/model_loss_std 2.09 / 
train/model_opt_grad_norm 5.54 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.33 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.83 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.33 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.09 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.36 / train/post_ent_mag 54.65 / train/post_ent_max 54.65 / train/post_ent_mean 36.81 / train/post_ent_min
27.05 / train/post_ent_std 4.62 / train/prior_ent_mag 66.26 / train/prior_ent_max 66.26 / train/prior_ent_mean 38.02 / train/prior_ent_min 30.43 / train/prior_ent_std 5.89 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.13 / train/reward_avg 1.32 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
train_stats/mean_log_entropy 0.38 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.71 / report/image_loss_mean 0.17 / report/image_loss_std 0.19 / report/model_loss_mean 1.15 / report/model_loss_std 1.77 / report/post_ent_mag 54.66 / report/post_ent_max 54.66 / 
report/post_ent_mean 37.71 / report/post_ent_min 28.48 / report/post_ent_std 4.38 / report/prior_ent_mag 66.07 / report/prior_ent_max 66.07 / report/prior_ent_mean 38.84 / report/prior_ent_min 30.71 / report/prior_ent_std 5.57 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 2.71 / report/reward_avg 1.25 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.25 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 9.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.49 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.6 / eval/post_ent_mag 53.82 / eval/post_ent_max 53.82 / eval/post_ent_mean 
37.01 / eval/post_ent_min 28.22 / eval/post_ent_std 4.32 / eval/prior_ent_mag 66.07 / eval/prior_ent_max 66.07 / eval/prior_ent_mean 38.21 / eval/prior_ent_min 30.38 / eval/prior_ent_std 5.6 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.49 / eval/reward_avg 1.49 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.6e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / replay/size
5.5e5 / replay/inserts 3876 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3876 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.09 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7383 / timer/agent.policy_total 16.37 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1938 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1938 / timer/agent.train_total 246.24 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / 
timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.83

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 548500 Counter(548500) 548437
Saved chunk: 20230922T093011F254248-0EoP823YbpUEPTGweBHn67-7rqlrIbzbCVLmPX1wlgnwe-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T093037F566179-2xjsSdpZz9J46318HzQ1WS-3GewkxhbHIXySwnKwS2r5k-1024.npz
Starting evaluation at step 549000 Counter(549000) 548937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 549500 Counter(549500) 549437
Saved chunk: 20230922T093130F095007-7rqlrIbzbCVLmPX1wlgnwe-1Thkdaj8qV67LErY7OLnZD-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T093158F205147-3GewkxhbHIXySwnKwS2r5k-3cWMOBMlWKMj22mOBddCGb-1024.npz
Starting evaluation at step 550000 Counter(550000) 549937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 550500 Counter(550500) 550437
Saved chunk: 20230922T093248F300467-1Thkdaj8qV67LErY7OLnZD-4G2JHsHLT8SNtOMd3CATnL-1024.npz
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T093317F775662-3cWMOBMlWKMj22mOBddCGb-3POqTZiTQdCSiNLDiBTmHg-1024.npz
Starting evaluation at step 551000 Counter(551000) 550937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 551500 Counter(551500) 551437
Saved chunk: 20230922T093406F151855-4G2JHsHLT8SNtOMd3CATnL-6phLTAMWfo7yOLkuPveQtn-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T093437F101968-3POqTZiTQdCSiNLDiBTmHg-5BDvjgWuyxoVVAfvPP0Xbj-1024.npz
Starting evaluation at step 552000 Counter(552000) 551937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1104422 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 774 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / train/action_mag 4.15 / train/action_max 3.86 / train/action_mean 0.04 / train/action_min -4.03 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.94 / train/adv_mag 0.44 / train/adv_max 0.34 / train/adv_mean 1.6e-4 / train/adv_min -0.36 / 
train/adv_std 0.01 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 9.2e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.11 / train/extr_critic_max 670.11 / train/extr_critic_mean 632.01 / train/extr_critic_min 460.23 / train/extr_critic_std 56.26 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.39 / train/extr_return_raw_max 668.39 / train/extr_return_raw_mean 632.03 / train/extr_return_raw_min 462.44 / train/extr_return_raw_std 56.3 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.37 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.17 / train/image_loss_std 0.29 / train/model_loss_mean 1.21 / train/model_loss_std 2.1 / 
train/model_opt_grad_norm 5.29 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.45 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.45 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.07 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 1.5e-4 / train/policy_randomness_std 0.35 / train/post_ent_mag 54.44 / train/post_ent_max 54.44 / train/post_ent_mean 36.83 / train/post_ent_min
26.89 / train/post_ent_std 4.55 / train/prior_ent_mag 66.14 / train/prior_ent_max 66.14 / train/prior_ent_mean 38.03 / train/prior_ent_min 30.4 / train/prior_ent_std 5.82 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.14 / train/reward_avg 1.34 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.34 / train/reward_rate 0.67 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.55 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 2.98 / report/image_loss_mean 0.16 / report/image_loss_std 0.22 / report/model_loss_mean 1.19 / report/model_loss_std 1.95 / report/post_ent_mag 52.48 / report/post_ent_max 52.48 / 
report/post_ent_mean 37.73 / report/post_ent_min 31.22 / report/post_ent_std 3.99 / report/prior_ent_mag 66.14 / report/prior_ent_max 66.14 / report/prior_ent_mean 38.88 / report/prior_ent_min 31.68 / report/prior_ent_std 5.44 / report/rep_loss_mean 1.59 / 
report/rep_loss_std 2.98 / report/reward_avg 1.28 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 4.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.12 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.08 / eval/post_ent_mag 52.22 / eval/post_ent_max 52.22 / eval/post_ent_mean 
38.28 / eval/post_ent_min 30.96 / eval/post_ent_std 3.92 / eval/prior_ent_mag 66.14 / eval/prior_ent_max 66.14 / eval/prior_ent_mean 39.46 / eval/prior_ent_min 32.1 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.12 / eval/reward_avg 1.26 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.27 / eval/reward_rate 0.63 / 
replay/size 5.5e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3834 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.97 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.3e-3 / 
timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.47 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 552500 Counter(552500) 552437
Saved chunk: 20230922T093523F809505-6phLTAMWfo7yOLkuPveQtn-1KvDekd35xCeWWjsY5sTJ0-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T093556F248972-5BDvjgWuyxoVVAfvPP0Xbj-50waxogjCCVsxOfiX8EQQN-1024.npz
Starting evaluation at step 553000 Counter(553000) 552937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 553500 Counter(553500) 553437
Saved chunk: 20230922T093642F635933-1KvDekd35xCeWWjsY5sTJ0-6LuAaartVvfEqY4RUmPnz0-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T093717F023223-50waxogjCCVsxOfiX8EQQN-4qeqUDsAfTHbMFqk8yG1nI-1024.npz
Starting evaluation at step 554000 Counter(554000) 553937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 554500 Counter(554500) 554437
Saved chunk: 20230922T093800F764523-6LuAaartVvfEqY4RUmPnz0-14uqfLjN70y9J0Gu7cgMyv-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 555000 Counter(555000) 554937
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T093836F471148-4qeqUDsAfTHbMFqk8yG1nI-1WwJh6aFaejuewC822A249-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 555500 Counter(555500) 555437
Saved chunk: 20230922T093918F586041-14uqfLjN70y9J0Gu7cgMyv-6p9tQ96zI7wt6lEvpGxaVn-1024.npz
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 556000 Counter(556000) 555937
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T093959F194968-1WwJh6aFaejuewC822A249-2etw8KFcQgGta4qJaBLQxT-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1112084 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / train/action_mag 4.18 / train/action_max 3.95 / train/action_mean 0.05 / train/action_min -4.04 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -1.76 / train/adv_mag 0.47 / train/adv_max 0.34 / train/adv_mean 3.1e-5 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 8.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.21 / train/extr_critic_max 670.21 / train/extr_critic_mean 630.22 / train/extr_critic_min 451.79 / train/extr_critic_std 57.85 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.22 / train/extr_return_raw_max 668.22 / train/extr_return_raw_mean 630.22 / train/extr_return_raw_min 457.44 / train/extr_return_raw_std 57.91
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.34 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.49 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.5 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 9.01 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.5 / train/policy_logprob_min -9.01 / train/policy_logprob_std 1.08 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 1.6e-4 / train/policy_randomness_std 0.35 / train/post_ent_mag 54.3 / train/post_ent_max 54.3 / train/post_ent_mean 36.88 / train/post_ent_min 
27.02 / train/post_ent_std 4.58 / train/prior_ent_mag 66.12 / train/prior_ent_max 66.12 / train/prior_ent_mean 38.08 / train/prior_ent_min 30.54 / train/prior_ent_std 5.84 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.1 / train/reward_avg 1.32 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.5 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 5.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.8 / report/dyn_loss_std 4.04 / report/image_loss_mean 0.21 / report/image_loss_std 0.32 / report/model_loss_mean 1.35 / report/model_loss_std 2.65 / report/post_ent_mag 57.49 / report/post_ent_max 57.49 / 
report/post_ent_mean 37.31 / report/post_ent_min 24.7 / report/post_ent_std 5.15 / report/prior_ent_mag 65.98 / report/prior_ent_max 65.98 / report/prior_ent_mean 38.69 / report/prior_ent_min 30.34 / report/prior_ent_std 6.26 / report/rep_loss_mean 1.8 / 
report/rep_loss_std 4.04 / report/reward_avg 1.06 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 1.06 / report/reward_rate 0.53 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / eval/cont_loss_std 5.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.68 / eval/dyn_loss_std 3.28 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.16 / eval/post_ent_mag 54.32 / eval/post_ent_max 54.32 / eval/post_ent_mean 38.61 / eval/post_ent_min 27.18 / 
eval/post_ent_std 3.74 / eval/prior_ent_mag 65.98 / eval/prior_ent_max 65.98 / eval/prior_ent_mean 39.88 / eval/prior_ent_min 33.6 / eval/prior_ent_std 4.96 / eval/rep_loss_mean 1.68 / eval/rep_loss_std 3.28 / eval/reward_avg 1.25 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.24 / eval/reward_rate 0.63 / replay/size 5.6e5 / replay/inserts 3831 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3831 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.22 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.1e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7839 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 
1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.62 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 556500 Counter(556500) 556437
Saved chunk: 20230922T094036F352113-6p9tQ96zI7wt6lEvpGxaVn-7zEcNTb8QnLIkOJIC42CIa-1024.npz
eval_Episode has 500 steps and return 773.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Saved chunk: 20230922T094118F417279-2etw8KFcQgGta4qJaBLQxT-0000000000000000000000-568.npz
Saved chunk: 20230922T094155F296583-7zEcNTb8QnLIkOJIC42CIa-0000000000000000000000-132.npz
train_Episode has 500 steps and return 760.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/5/checkpoint.ckpt
Starting evaluation at step 557000 Counter(557000) 556937
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T094118F417279-2etw8KFcQgGta4qJaBLQxT-733MpKGVX5MbXATS00iCEW-1024.npz
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 557500 Counter(557500) 557437
Saved chunk: 20230922T094155F296583-7zEcNTb8QnLIkOJIC42CIa-0mn3L80GetnsQYf0TwmPLO-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 558000 Counter(558000) 557937
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T094239F373846-733MpKGVX5MbXATS00iCEW-74MuLx2rkRUVEZcRyipXda-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 558500 Counter(558500) 558437
Saved chunk: 20230922T094313F522561-0mn3L80GetnsQYf0TwmPLO-458mbb84cKSizOExEf5hr1-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 771.0.
Starting evaluation at step 559000 Counter(559000) 558937
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T094358F791102-74MuLx2rkRUVEZcRyipXda-68RgLZVekAUHgAO9tesvmO-1024.npz
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 559500 Counter(559500) 559437
Saved chunk: 20230922T094431F344944-458mbb84cKSizOExEf5hr1-6DwD5XMhSf5EQhLHQHkrGq-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 753.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1119842 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 753 / episode/reward_rate 0.75 / eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / train/action_mag 4.13 / train/action_max 3.84 / train/action_mean 0.06 / train/action_min -4.02 / train/action_std 0.98 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -0.73 / train/adv_mag 0.42 / train/adv_max 0.32 / train/adv_mean -4.6e-5 / train/adv_min -0.36 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 8.4e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.32 / train/extr_critic_max 670.32 / train/extr_critic_mean 630.24 / train/extr_critic_min 455.6 / train/extr_critic_std 58.27 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.27 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.43 / train/extr_return_raw_max 668.43 / train/extr_return_raw_mean 630.24 / train/extr_return_raw_min 457.13 / train/extr_return_raw_std 58.41
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.36 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.42 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.08 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 8.8e-5 / train/policy_randomness_std 0.35 / train/post_ent_mag 54.37 / train/post_ent_max 54.37 / train/post_ent_mean 36.96 / train/post_ent_min
27.03 / train/post_ent_std 4.49 / train/prior_ent_mag 66.12 / train/prior_ent_max 66.12 / train/prior_ent_mean 38.16 / train/prior_ent_min 30.84 / train/prior_ent_std 5.76 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.09 / train/reward_avg 1.33 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.33 / train/reward_rate 0.67 / 
train_stats/mean_log_entropy 0.44 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.66 / report/image_loss_mean 0.19 / report/image_loss_std 0.42 / report/model_loss_mean 1.26 / report/model_loss_std 2.46 / report/post_ent_mag 52.03 / report/post_ent_max 52.03 / 
report/post_ent_mean 37.18 / report/post_ent_min 29.39 / report/post_ent_std 4.99 / report/prior_ent_mag 66.11 / report/prior_ent_max 66.11 / report/prior_ent_mean 38.4 / report/prior_ent_min 31.09 / report/prior_ent_std 6.13 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.66 / report/reward_avg 1.31 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.31 / report/reward_rate 0.66 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / eval/cont_loss_std 3.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.69 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.8 / eval/post_ent_mag 53.28 / eval/post_ent_max 53.28 / eval/post_ent_mean 
37.73 / eval/post_ent_min 31.08 / eval/post_ent_std 4.23 / eval/prior_ent_mag 66.11 / eval/prior_ent_max 66.11 / eval/prior_ent_mean 38.8 / eval/prior_ent_min 32.23 / eval/prior_ent_std 5.42 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.69 / eval/reward_avg 1.39 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.39 / eval/reward_rate 0.7 / replay/size 
5.6e5 / replay/inserts 3879 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3879 / timer/env.step_total 19.13 / timer/env.step_frac 0.06 / timer/env.step_avg 
4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.89 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.3e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7386 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1940 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1940 / timer/agent.train_total 246.59 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.85

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 560000 Counter(560000) 559937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T094518F081088-68RgLZVekAUHgAO9tesvmO-7iQPz2ZUUUS3xM2JAE2U20-1024.npz
Starting evaluation at step 560500 Counter(560500) 560437
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T094548F992866-6DwD5XMhSf5EQhLHQHkrGq-5jyoardXSvFItKvtqXsM2s-1024.npz
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 561000 Counter(561000) 560937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T094638F432697-7iQPz2ZUUUS3xM2JAE2U20-37miQFXOba2rLWyzHqgU02-1024.npz
Starting evaluation at step 561500 Counter(561500) 561437
eval_Episode has 500 steps and return 771.0.
Saved chunk: 20230922T094708F025664-5jyoardXSvFItKvtqXsM2s-7CErtCMLAdjwckbRLVnbg6-1024.npz
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 562000 Counter(562000) 561937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T094758F080728-37miQFXOba2rLWyzHqgU02-15Oi4ba1Fcf4Pj2V8xuavh-1024.npz
Starting evaluation at step 562500 Counter(562500) 562437
eval_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T094825F986911-7CErtCMLAdjwckbRLVnbg6-2cAYoYu9Of7thepjWHNkjq-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 563000 Counter(563000) 562937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 761.0.
Saved chunk: 20230922T094917F428994-15Oi4ba1Fcf4Pj2V8xuavh-4tOWpiPVPwxj8GepBea1yt-1024.npz
Starting evaluation at step 563500 Counter(563500) 563437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 770.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1127494 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 770 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 770 / episode/reward_rate 0.77 / train/action_mag 4.03 / train/action_max 3.77 / train/action_mean 0.07 / train/action_min -3.9 / train/action_std 0.94 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -2.81 / train/adv_mag 0.41 / train/adv_max 0.31 / train/adv_mean 1.9e-4 / train/adv_min -0.37 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 8.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.59 / train/extr_critic_max 670.59 / train/extr_critic_mean 627.28 / train/extr_critic_min 454.61 / train/extr_critic_std 62.62 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.22 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.58 / train/extr_return_raw_max 668.58 / train/extr_return_raw_mean 627.31 / train/extr_return_raw_min 453.59 / train/extr_return_raw_std 62.67
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.6 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean
0.33 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.59 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.33 / train/policy_logprob_min -8.59 / train/policy_logprob_std 1.08 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.35 / train/post_ent_mag 54.7 / train/post_ent_max 54.7 / train/post_ent_mean 37.01 / train/post_ent_min 27.22 / train/post_ent_std 4.49 /
train/prior_ent_mag 65.99 / train/prior_ent_max 65.99 / train/prior_ent_mean 38.21 / train/prior_ent_min 31.05 / train/prior_ent_std 5.74 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.08 / train/reward_avg 1.31 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.1
/ train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.31 / train/reward_rate 0.66 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 0.35 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 3.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.46 / report/image_loss_mean 0.17 / report/image_loss_std 0.28 / report/model_loss_mean 1.23 / report/model_loss_std 2.3 / report/post_ent_mag 54.11 / report/post_ent_max 54.11 / report/post_ent_mean 36.68 / 
report/post_ent_min 27.63 / report/post_ent_std 4.66 / report/prior_ent_mag 65.94 / report/prior_ent_max 65.94 / report/prior_ent_mean 37.94 / report/prior_ent_min 31.42 / report/prior_ent_std 5.94 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.46 / report/reward_avg
1.2 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.6e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.2 / 
report/reward_rate 0.6 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / eval/cont_loss_std 4.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / 
eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.14 / eval/model_loss_std 1.84 / eval/post_ent_mag 54.47 / eval/post_ent_max 54.47 / eval/post_ent_mean 36.8 / eval/post_ent_min 29.23 / eval/post_ent_std 4.08 / 
eval/prior_ent_mag 65.94 / eval/prior_ent_max 65.94 / eval/prior_ent_mean 37.88 / eval/prior_ent_min 31.5 / eval/prior_ent_std 5.48 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.75 / eval/reward_avg 1.54 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.54 / eval/reward_rate 0.77 / replay/size 5.6e5 / replay/inserts 3826 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3826 / timer/env.step_total 18.86 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.1e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.19 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7834 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.2e-3 / timer/dataset_train_count 1913 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1913 / timer/agent.train_total 243.59 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.51 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.51

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 564000 Counter(564000) 563937
Saved chunk: 20230922T094943F729544-2cAYoYu9Of7thepjWHNkjq-6DvT7pwUKgMPp1Ym9Ool35-1024.npz
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T095036F703505-4tOWpiPVPwxj8GepBea1yt-3sRc45p2JMJ1iXvtqbAO2r-1024.npz
Starting evaluation at step 564500 Counter(564500) 564437
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 565000 Counter(565000) 564937
Saved chunk: 20230922T095138F502292-6DvT7pwUKgMPp1Ym9Ool35-73BIi8HEzDyUHIzZchvPeo-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T095157F728591-3sRc45p2JMJ1iXvtqbAO2r-7eOsasIhvZPPFVN3dwYo5G-1024.npz
Starting evaluation at step 565500 Counter(565500) 565437
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 767.0.
Starting evaluation at step 566000 Counter(566000) 565937
Saved chunk: 20230922T095256F668122-73BIi8HEzDyUHIzZchvPeo-1y1nhAwDgmRYxDqRvnWU94-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T095317F338752-7eOsasIhvZPPFVN3dwYo5G-48KRDgQ3VaNWiuAqaTDyhb-1024.npz
Starting evaluation at step 566500 Counter(566500) 566437
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 770.0.
Starting evaluation at step 567000 Counter(567000) 566937
Saved chunk: 20230922T095414F630665-1y1nhAwDgmRYxDqRvnWU94-7C6dOpYh2qND4Fey94CR8I-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T095436F885750-48KRDgQ3VaNWiuAqaTDyhb-1d1YiQH6lUkolZfMMFEHpO-1024.npz
Starting evaluation at step 567500 Counter(567500) 567437
eval_Episode has 500 steps and return 773.0.
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1135146 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 773 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 769 / episode/reward_rate 0.77 / train/action_mag 4.09 / train/action_max 3.83 / train/action_mean 0.05 / train/action_min -3.96 / train/action_std 0.94
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -4.32 / train/adv_mag 0.38 / train/adv_max 0.28 / train/adv_mean 3.3e-4 / train/adv_min 
-0.35 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 8.1e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.58 / train/dyn_loss_std 3.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 670.58 / train/extr_critic_max 670.58 / train/extr_critic_mean 632.24 / train/extr_critic_min 459.23 / train/extr_critic_std 58.29 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / 
train/extr_return_normed_mean 0.79 / train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.73 / train/extr_return_raw_max 668.73 / train/extr_return_raw_mean 632.3 / train/extr_return_raw_min 
459.46 / train/extr_return_raw_std 58.25 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / 
train/model_loss_std 2.02 / train/model_opt_grad_norm 5.63 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 
1.42 / train/policy_entropy_mean 0.35 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.81 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.35 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.07 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 0.35 / train/post_ent_mag 53.93 / train/post_ent_max 53.93 / train/post_ent_mean 36.92 / 
train/post_ent_min 27.3 / train/post_ent_std 4.35 / train/prior_ent_mag 65.87 / train/prior_ent_max 65.87 / train/prior_ent_mean 38.1 / train/prior_ent_min 31.11 / train/prior_ent_std 5.62 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.03 / train/reward_avg 1.35 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.35 / train/reward_rate 
0.68 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.23 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 5.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.5 / report/dyn_loss_std 2.45 / report/image_loss_mean 0.17 / report/image_loss_std 0.37 / report/model_loss_mean 1.14 / report/model_loss_std 1.73 / report/post_ent_mag 55.57 / report/post_ent_max 55.57 / 
report/post_ent_mean 37.85 / report/post_ent_min 29.66 / report/post_ent_std 4.49 / report/prior_ent_mag 66.12 / report/prior_ent_max 66.12 / report/prior_ent_mean 38.91 / report/prior_ent_min 31.27 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.5 / 
report/rep_loss_std 2.45 / report/reward_avg 1.12 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.12 / report/reward_rate 0.56 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 3.16 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.17 / eval/model_loss_std 2.13 / eval/post_ent_mag 51.78 / eval/post_ent_max 51.78 / eval/post_ent_mean 
37.58 / eval/post_ent_min 30.39 / eval/post_ent_std 4.02 / eval/prior_ent_mag 66.12 / eval/prior_ent_max 66.12 / eval/prior_ent_mean 38.66 / eval/prior_ent_min 32.14 / eval/prior_ent_std 5.33 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 3.16 / eval/reward_avg 1.45 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.45 / eval/reward_rate 0.73 / 
replay/size 5.7e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.3e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3826 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3
/ timer/env.step_min 4e-3 / timer/env.step_max 0.19 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.01 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7834 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.6e-3 
/ timer/dataset_train_count 1913 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1913 / timer/agent.train_total 243.36 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.5
