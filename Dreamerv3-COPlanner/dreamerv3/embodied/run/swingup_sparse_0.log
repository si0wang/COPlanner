Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {}
JAX devices (1): [gpu(id=0)]
Policy devices: gpu:0
Train devices:  gpu:0
Tracing train function.
Optimizer model_opt has 15,685,251 variables.
{'action': Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>, 'deter': Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>, 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>, 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>}
{'action': Traced<ShapedArray(float32[15,1024,1])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,1])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,1]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d8c0da220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3d84786310; dead>, <weakref at 0x7f3d84786590; dead>, <weakref at 0x7f3d84786f40; dead>, <weakref at 0x7f3d84786f90; dead>, <weakref at 0x7f3d84786e50; to 'JaxprTracer' at 0x7f3d8477fdb0>, <weakref at 0x7f3d84786e00; to 'JaxprTracer' at 0x7f3d8477fef0>, <weakref at 0x7f3d84786ef0; to 'JaxprTracer' at 0x7f3d8477f040>, <weakref at 0x7f3d84786ea0; to 'JaxprTracer' at 0x7f3d8477fbd0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3d847e0cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d8c0da220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3d84786310; dead>, <weakref at 0x7f3d84786590; dead>, <weakref at 0x7f3d84786f40; dead>, <weakref at 0x7f3d84786f90; dead>, <weakref at 0x7f3d84786e50; to 'JaxprTracer' at 0x7f3d8477fdb0>, <weakref at 0x7f3d84786e00; to 'JaxprTracer' at 0x7f3d8477fef0>, <weakref at 0x7f3d84786ef0; to 'JaxprTracer' at 0x7f3d8477f040>, <weakref at 0x7f3d84786ea0; to 'JaxprTracer' at 0x7f3d8477fbd0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3d847e0cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d8c0da220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3d84786310; dead>, <weakref at 0x7f3d84786590; dead>, <weakref at 0x7f3d84786f40; dead>, <weakref at 0x7f3d84786f90; dead>, <weakref at 0x7f3d84786e50; to 'JaxprTracer' at 0x7f3d8477fdb0>, <weakref at 0x7f3d84786e00; to 'JaxprTracer' at 0x7f3d8477fef0>, <weakref at 0x7f3d84786ef0; to 'JaxprTracer' at 0x7f3d8477f040>, <weakref at 0x7f3d84786ea0; to 'JaxprTracer' at 0x7f3d8477fbd0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3d847e0cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d8c0da220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3d84786310; dead>, <weakref at 0x7f3d84786590; dead>, <weakref at 0x7f3d84786f40; dead>, <weakref at 0x7f3d84786f90; dead>, <weakref at 0x7f3d84786e50; to 'JaxprTracer' at 0x7f3d8477fdb0>, <weakref at 0x7f3d84786e00; to 'JaxprTracer' at 0x7f3d8477fef0>, <weakref at 0x7f3d84786ef0; to 'JaxprTracer' at 0x7f3d8477f040>, <weakref at 0x7f3d84786ea0; to 'JaxprTracer' at 0x7f3d8477fbd0>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3d847e0cb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Optimizer actor_opt has 1,051,650 variables.
Optimizer critic_opt has 1,181,439 variables.
Logdir /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp
Observation space:
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  position         Space(dtype=float64, shape=(3,), low=-inf, high=inf)
  velocity         Space(dtype=float64, shape=(2,), low=-inf, high=inf)
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
Action space:
  reset            Space(dtype=bool, shape=(), low=False, high=True)
  action           Space(dtype=float32, shape=(1,), low=-1.0, high=1.0)
Prefill train dataset.
train_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Prefill eval dataset.
Saved chunk: 20230921T213832F311908-3zVfN4FYLWMiBL9Xlr5MMp-11pDUMYALvruDU38SYrGMf-1024.npz
eval_Episode has 500 steps and return 0.0.
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213836F542199-3iiMB8PPPtJC9Jg9B3vZLH-0nfmRjF9begXKcn0htz8I6-1024.npz
 Step 2200 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0
warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'


Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100 Counter(1100) 1037
Tracing policy function.
Saved chunk: 20230921T213840F184178-0nfmRjF9begXKcn0htz8I6-0000000000000000000000-76.npz
Saved chunk: 20230921T213835F944488-11pDUMYALvruDU38SYrGMf-0000000000000000000000-76.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Tracing policy function.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
Tracing policy function.
Tracing train function.
{'action': Traced<ShapedArray(float32[15,1024,1])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,1])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,1]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d944cffe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3dc00567c0; dead>, <weakref at 0x7f3dc0056540; dead>, <weakref at 0x7f3d947439f0; dead>, <weakref at 0x7f3d947439a0; dead>, <weakref at 0x7f3d94743d10; to 'JaxprTracer' at 0x7f3d946cd8b0>, <weakref at 0x7f3d94743b30; to 'JaxprTracer' at 0x7f3d946cd2c0>, <weakref at 0x7f3d94743680; to 'JaxprTracer' at 0x7f3d946cddb0>, <weakref at 0x7f3d945e5860; to 'JaxprTracer' at 0x7f3d946cd950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3b08d5dfb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d944cffe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3dc00567c0; dead>, <weakref at 0x7f3dc0056540; dead>, <weakref at 0x7f3d947439f0; dead>, <weakref at 0x7f3d947439a0; dead>, <weakref at 0x7f3d94743d10; to 'JaxprTracer' at 0x7f3d946cd8b0>, <weakref at 0x7f3d94743b30; to 'JaxprTracer' at 0x7f3d946cd2c0>, <weakref at 0x7f3d94743680; to 'JaxprTracer' at 0x7f3d946cddb0>, <weakref at 0x7f3d945e5860; to 'JaxprTracer' at 0x7f3d946cd950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3b08d5dfb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d944cffe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3dc00567c0; dead>, <weakref at 0x7f3dc0056540; dead>, <weakref at 0x7f3d947439f0; dead>, <weakref at 0x7f3d947439a0; dead>, <weakref at 0x7f3d94743d10; to 'JaxprTracer' at 0x7f3d946cd8b0>, <weakref at 0x7f3d94743b30; to 'JaxprTracer' at 0x7f3d946cd2c0>, <weakref at 0x7f3d94743680; to 'JaxprTracer' at 0x7f3d946cddb0>, <weakref at 0x7f3d945e5860; to 'JaxprTracer' at 0x7f3d946cd950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3b08d5dfb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f3d944cffe0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3dc00567c0; dead>, <weakref at 0x7f3dc0056540; dead>, <weakref at 0x7f3d947439f0; dead>, <weakref at 0x7f3d947439a0; dead>, <weakref at 0x7f3d94743d10; to 'JaxprTracer' at 0x7f3d946cd8b0>, <weakref at 0x7f3d94743b30; to 'JaxprTracer' at 0x7f3d946cd2c0>, <weakref at 0x7f3d94743680; to 'JaxprTracer' at 0x7f3d946cddb0>, <weakref at 0x7f3d945e5860; to 'JaxprTracer' at 0x7f3d946cd950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f3b08d5dfb0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Tracing report function.
Tracing report function.
 Step 2202 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.27 / train/action_max 4.27 / train/action_mean 0.11 / train/action_min -3.81 / train/action_std 0.96 / train/actor_opt_actor_opt_grad_overflow 0 / 
train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1e-4 / train/actor_opt_grad_steps 1 / train/actor_opt_loss -0.39 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 0.9 /
train/cont_loss_std 0.39 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 0.32 / train/cont_pos_loss 0.9 / train/cont_pred 0.43 / train/cont_rate 1 / train/dyn_loss_mean 7.23 / train/dyn_loss_std 0.29 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.74 / train/extr_critic_critic_opt_grad_steps 1 / train/extr_critic_critic_opt_loss 1.2e4 / train/extr_critic_mag 0 /
train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 0 / train/extr_return_normed_max -inf / train/extr_return_normed_mean 0 / train/extr_return_normed_min 0 / train/extr_return_normed_std
0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / 
train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2574.16 / train/image_loss_std 31.21 / train/model_loss_mean 2584.94 / train/model_loss_std 31.21 / train/model_opt_grad_norm nan / train/model_opt_grad_steps 0 / train/model_opt_loss 2.6e7 / 
train/model_opt_model_opt_grad_overflow 1 / train/model_opt_model_opt_grad_scale 5000 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / train/policy_entropy_mean 1.17 / train/policy_entropy_min 0.2 / train/policy_entropy_std 0.15 / train/policy_logprob_mag 
8.81 / train/policy_logprob_max 0.2 / train/policy_logprob_mean -1.17 / train/policy_logprob_min -8.81 / train/policy_logprob_std 0.73 / train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.89 / train/policy_randomness_min 
0.47 / train/policy_randomness_std 0.06 / train/post_ent_mag 107.54 / train/post_ent_max 107.54 / train/post_ent_mean 107.33 / train/post_ent_min 107.07 / train/post_ent_std 0.08 / train/prior_ent_mag 107.98 / train/prior_ent_max 107.98 / train/prior_ent_mean 107.38 / 
train/prior_ent_min 106.71 / train/prior_ent_std 0.22 / train/rep_loss_mean 7.23 / train/rep_loss_std 0.29 / train/reward_avg 0 / train/reward_loss_mean 5.54 / train/reward_loss_std 9.5e-7 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / 
train/reward_neg_loss 5.54 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train/params_agent/wm/model_opt 1.6e7 / train/params_agent/task_behavior/critic/critic_opt 1.2e6 / train/params_agent/task_behavior/ac/actor_opt
1.1e6 / report/cont_avg 1 / report/cont_loss_mean 0.89 / report/cont_loss_std 0.38 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 0.34 / report/cont_pos_loss 0.89 / report/cont_pred 0.44 / report/cont_rate 1 / report/dyn_loss_mean 7.19 / 
report/dyn_loss_std 0.29 / report/image_loss_mean 2575.44 / report/image_loss_std 30.48 / report/model_loss_mean 2586.19 / report/model_loss_std 30.49 / report/post_ent_mag 107.54 / report/post_ent_max 107.54 / report/post_ent_mean 107.34 / report/post_ent_min 107.03 / 
report/post_ent_std 0.08 / report/prior_ent_mag 107.94 / report/prior_ent_max 107.94 / report/prior_ent_mean 107.4 / report/prior_ent_min 106.63 / report/prior_ent_std 0.21 / report/rep_loss_mean 7.19 / report/rep_loss_std 0.29 / report/reward_avg 0 / 
report/reward_loss_mean 5.54 / report/reward_loss_std 9.5e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 5.54 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 
0 / eval/cont_avg 1 / eval/cont_loss_mean 0.85 / eval/cont_loss_std 0.37 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 0.39 / eval/cont_pos_loss 0.85 / eval/cont_pred 0.46 / eval/cont_rate 1 / eval/dyn_loss_mean 7.2 / eval/dyn_loss_std 0.31 / 
eval/image_loss_mean 2575.38 / eval/image_loss_std 30.48 / eval/model_loss_mean 2586.09 / eval/model_loss_std 30.5 / eval/post_ent_mag 107.53 / eval/post_ent_max 107.53 / eval/post_ent_mean 107.34 / eval/post_ent_min 107.07 / eval/post_ent_std 0.06 / eval/prior_ent_mag 
108.21 / eval/prior_ent_max 108.21 / eval/prior_ent_mean 107.41 / eval/prior_ent_min 106.7 / eval/prior_ent_std 0.24 / eval/rep_loss_mean 7.2 / eval/rep_loss_std 0.31 / eval/reward_avg 0 / eval/reward_loss_mean 5.54 / eval/reward_loss_std 9.5e-7 / eval/reward_max_data 0 /
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.54 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1038 / replay/inserts 1038 / replay/samples 112 / replay/insert_wait_avg 2.1e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1538 / eval_replay/inserts 1538 / eval_replay/samples 112 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 146.4 / timer/env.step_count 1101 / timer/env.step_total 4.35 / timer/env.step_frac 0.03 / timer/env.step_avg 4e-3 / timer/env.step_min 3.2e-3 / timer/env.step_max 0.68 / timer/replay._sample_count 112 / 
timer/replay._sample_total 24.74 / timer/replay._sample_frac 0.17 / timer/replay._sample_avg 0.22 / timer/replay._sample_min 7.8e-4 / timer/replay._sample_max 1.44 / timer/agent.save_count 1 / timer/agent.save_total 0.25 / timer/agent.save_frac 1.7e-3 / 
timer/agent.save_avg 0.25 / timer/agent.save_min 0.25 / timer/agent.save_max 0.25 / timer/agent.policy_count 502 / timer/agent.policy_total 48.8 / timer/agent.policy_frac 0.33 / timer/agent.policy_avg 0.1 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 46.51 / 
timer/dataset_train_count 1 / timer/dataset_train_total 2.8e-5 / timer/dataset_train_frac 1.9e-7 / timer/dataset_train_avg 2.8e-5 / timer/dataset_train_min 2.8e-5 / timer/dataset_train_max 2.8e-5 / timer/agent.train_count 1 / timer/agent.train_total 76.27 / 
timer/agent.train_frac 0.52 / timer/agent.train_avg 76.27 / timer/agent.train_min 76.27 / timer/agent.train_max 76.27 / timer/agent.report_count 2 / timer/agent.report_total 9.29 / timer/agent.report_frac 0.06 / timer/agent.report_avg 4.64 / timer/agent.report_min 0.07 / 
timer/agent.report_max 9.22 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 2.2e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 1500 Counter(1500) 1437
Saved chunk: 20230921T213840F184178-0nfmRjF9begXKcn0htz8I6-6FllQwZGBKJYBDR4F78mn2-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 2000 Counter(2000) 1937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213835F944488-11pDUMYALvruDU38SYrGMf-69rAQHggcRQuso9u2H8CGM-1024.npz
Starting evaluation at step 2500 Counter(2500) 2437
Saved chunk: 20230921T214129F045349-6FllQwZGBKJYBDR4F78mn2-5VW9hqaIHhA0nqHSb4fg3r-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 3000 Counter(3000) 2937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214211F269435-69rAQHggcRQuso9u2H8CGM-4TzA4qJLYVu96rI3mmNWS9-1024.npz
Starting evaluation at step 3500 Counter(3500) 3437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214246F268785-5VW9hqaIHhA0nqHSb4fg3r-43qUa2zdHmLJ3Pkj3crSAy-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 4000 Counter(4000) 3937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214330F390711-4TzA4qJLYVu96rI3mmNWS9-32fcD90DgkVbfNdGE0NEXz-1024.npz
Starting evaluation at step 4500 Counter(4500) 4437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 9738 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.35 / train/action_max 4.29 / train/action_mean 0.24 / train/action_min -3.85 / train/action_std 1.03 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.9e-5 / train/actor_opt_grad_steps 945 / train/actor_opt_loss -4.14 / train/adv_mag 2.2e-7 / train/adv_max 1.9e-7 / train/adv_mean -4e-9 / train/adv_min 
-2.2e-7 / train/adv_std 5.2e-8 / train/cont_avg 1 / train/cont_loss_mean 4.5e-3 / train/cont_loss_std 2e-3 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-3 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
1.71 / train/dyn_loss_std 1.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.31 / train/extr_critic_critic_opt_grad_steps 945 / 
train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 1.8e-7 / train/extr_critic_max -inf / train/extr_critic_mean 2.9e-9 / train/extr_critic_min -2.6e-8 / train/extr_critic_std 3.9e-8 / train/extr_return_normed_mag 2.3e-7 / train/extr_return_normed_max 2.1e-7 / 
train/extr_return_normed_mean 3e-8 / train/extr_return_normed_min -1.5e-8 / train/extr_return_normed_std 3.3e-8 / train/extr_return_rate 0 / train/extr_return_raw_mag 2.1e-7 / train/extr_return_raw_max 1.8e-7 / train/extr_return_raw_mean -9.2e-10 / 
train/extr_return_raw_min -4.6e-8 / train/extr_return_raw_std 3.3e-8 / train/extr_reward_mag 7.6e-9 / train/extr_reward_max -inf / train/extr_reward_mean -8.1e-10 / train/extr_reward_min -7.6e-9 / train/extr_reward_std 1.8e-9 / train/image_loss_mean 39.68 / 
train/image_loss_std 8.17 / train/model_loss_mean 40.89 / train/model_loss_std 8.42 / train/model_opt_grad_norm 108.37 / train/model_opt_grad_steps 936 / train/model_opt_loss 899.4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 28.67 / 
train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.41 / train/policy_entropy_min 1.35 / train/policy_entropy_std 3.4e-3 / train/policy_logprob_mag 9.16 / train/policy_logprob_max -0.87 / train/policy_logprob_mean -1.41 / 
train/policy_logprob_min -9.16 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.97 / train/policy_randomness_std 1.5e-3 / train/post_ent_mag 64.9 / 
train/post_ent_max 64.9 / train/post_ent_mean 56.4 / train/post_ent_min 50.19 / train/post_ent_std 2.92 / train/prior_ent_mag 70.47 / train/prior_ent_max 70.47 / train/prior_ent_mean 60.57 / train/prior_ent_min 55.43 / train/prior_ent_std 2.91 / train/rep_loss_mean 1.71 /
train/rep_loss_std 1.52 / train/reward_avg 0 / train/reward_loss_mean 0.19 / train/reward_loss_std 4.4e-4 / train/reward_max_data 0 / train/reward_max_pred 7e-9 / train/reward_neg_acc 1 / train/reward_neg_loss 0.19 / train/reward_pos_acc nan / train/reward_pos_loss nan / 
train/reward_pred -2.4e-9 / train/reward_rate 0 / train_stats/mean_log_entropy 1.41 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5e-6 / report/cont_loss_std 2.7e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 
/ report/cont_pos_loss 5e-6 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.25 / report/dyn_loss_std 3.3 / report/image_loss_mean 8.52 / report/image_loss_std 4.52 / report/model_loss_mean 9.87 / report/model_loss_std 5.28 / report/post_ent_mag 44.78 / 
report/post_ent_max 44.78 / report/post_ent_mean 30.76 / report/post_ent_min 20.27 / report/post_ent_std 4.39 / report/prior_ent_mag 52.34 / report/prior_ent_max 52.34 / report/prior_ent_mean 35.35 / report/prior_ent_min 24.35 / report/prior_ent_std 5.07 / 
report/rep_loss_mean 2.25 / report/rep_loss_std 3.3 / report/reward_avg 0 / report/reward_loss_mean 1.2e-3 / report/reward_loss_std 8.3e-6 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-6 / eval/cont_loss_std 2.4e-6 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 
4.7e-6 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.97 / eval/dyn_loss_std 3.48 / eval/image_loss_mean 9.66 / eval/image_loss_std 5.84 / eval/model_loss_mean 11.45 / eval/model_loss_std 6.69 / eval/post_ent_mag 50.66 / eval/post_ent_max 50.66 / 
eval/post_ent_mean 31.35 / eval/post_ent_min 20.5 / eval/post_ent_std 3.55 / eval/prior_ent_mag 52.34 / eval/prior_ent_max 52.34 / eval/prior_ent_mean 34.74 / eval/prior_ent_min 24.17 / eval/prior_ent_std 3.82 / eval/rep_loss_mean 2.97 / eval/rep_loss_std 3.48 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.2e-3 / eval/reward_loss_std 7.9e-6 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / 
eval/reward_rate 0 / replay/size 4806 / replay/inserts 3768 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5045 / eval_replay/inserts 3507 / eval_replay/samples 
16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 290.92 / timer/env.step_count 3768 / timer/env.step_total 18.8 / timer/env.step_frac 0.06 / timer/env.step_avg 
5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3e4 / timer/replay._sample_total 373.18 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7275 / timer/agent.policy_total 15.47 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1884 / timer/dataset_train_total 0.13 / timer/dataset_train_frac 4.6e-4 / timer/dataset_train_avg 7.1e-5 / timer/dataset_train_min 6.2e-5 / timer/dataset_train_max 3e-4 / timer/agent.train_count 1884 / timer/agent.train_total 239.17 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.16 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 5000 Counter(5000) 4937
Saved chunk: 20230921T214404F090098-43qUa2zdHmLJ3Pkj3crSAy-7eeKsas1iTm8qzs0kygaFJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214450F096233-32fcD90DgkVbfNdGE0NEXz-4K4wThmZhfHqm32ofd4JK4-1024.npz
Starting evaluation at step 5500 Counter(5500) 5437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 6000 Counter(6000) 5937
Saved chunk: 20230921T214558F582584-7eeKsas1iTm8qzs0kygaFJ-6AqpXeZnbJndkgxIqJiyYj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214610F532875-4K4wThmZhfHqm32ofd4JK4-37UlQNWMaHIEiWzPdtAcwb-1024.npz
Starting evaluation at step 6500 Counter(6500) 6437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 7000 Counter(7000) 6937
Saved chunk: 20230921T214717F261434-6AqpXeZnbJndkgxIqJiyYj-3busBxojH3PAjC8lftFAK0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214730F702608-37UlQNWMaHIEiWzPdtAcwb-5gzUq156BT3wHQeJo3XSKY-1024.npz
Starting evaluation at step 7500 Counter(7500) 7437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 8000 Counter(8000) 7937
Saved chunk: 20230921T214835F766148-3busBxojH3PAjC8lftFAK0-0LcoHsaZYukoxP7JAyM59n-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214850F751718-5gzUq156BT3wHQeJo3XSKY-5YjdpBk0a8DByRN0wLaD60-1024.npz
Starting evaluation at step 8500 Counter(8500) 8437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 17362 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.51 / train/action_min -3.77 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-5 / train/actor_opt_grad_steps 2840 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 1.9e-6 / train/cont_loss_std 1.1e-6 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-6 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.24 / train/dyn_loss_std 
3.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 2840 / train/extr_critic_critic_opt_loss 112.1 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 5.4e-16 / train/extr_return_normed_max 5.4e-16 / train/extr_return_normed_mean 5.4e-16 / 
train/extr_return_normed_min 5.4e-16 / train/extr_return_normed_std 2.6e-23 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / 
train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 4.6 / train/image_loss_std 3.62 / train/model_loss_mean 5.95 / train/model_loss_std 4.65 / train/model_opt_grad_norm
18.21 / train/model_opt_grad_steps 2831 / train/model_opt_loss 587.98 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 107.37 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.28 / train/policy_entropy_std 4.1e-3 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.83 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.94 / train/policy_randomness_std 1.8e-3 / train/post_ent_mag 38.23 / train/post_ent_max 38.23 / train/post_ent_mean 23.88 / train/post_ent_min 16.45 / train/post_ent_std 3.21 / 
train/prior_ent_mag 48.07 / train/prior_ent_max 48.07 / train/prior_ent_mean 27.04 / train/prior_ent_min 19.43 / train/prior_ent_std 4.31 / train/rep_loss_mean 2.24 / train/rep_loss_std 3.48 / train/reward_avg 0 / train/reward_loss_mean 6e-4 / train/reward_loss_std 4.7e-6
/ train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 6e-4 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.41
/ report/cont_avg 1 / report/cont_loss_mean 9.8e-7 / report/cont_loss_std 5e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.8e-7 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.2 / 
report/dyn_loss_std 3.68 / report/image_loss_mean 3.21 / report/image_loss_std 2.7 / report/model_loss_mean 4.53 / report/model_loss_std 3.86 / report/post_ent_mag 28.99 / report/post_ent_max 28.99 / report/post_ent_mean 20.64 / report/post_ent_min 14.27 / 
report/post_ent_std 2.42 / report/prior_ent_mag 46.14 / report/prior_ent_max 46.14 / report/prior_ent_mean 24.08 / report/prior_ent_min 16.74 / report/prior_ent_std 3.94 / report/rep_loss_mean 2.2 / report/rep_loss_std 3.68 / report/reward_avg 0 / report/reward_loss_mean 
2.7e-4 / report/reward_loss_std 2.3e-6 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-4 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 
/ eval/cont_loss_mean 1.1e-6 / eval/cont_loss_std 5.9e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-6 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.38 / eval/dyn_loss_std 4.4 / eval/image_loss_mean 5.5 /
eval/image_loss_std 3.88 / eval/model_loss_mean 7.53 / eval/model_loss_std 5.36 / eval/post_ent_mag 37.86 / eval/post_ent_max 37.86 / eval/post_ent_mean 21.86 / eval/post_ent_min 14.03 / eval/post_ent_std 3.62 / eval/prior_ent_mag 46.14 / eval/prior_ent_max 46.14 / 
eval/prior_ent_mean 24.87 / eval/prior_ent_min 16.42 / eval/prior_ent_std 4.37 / eval/rep_loss_mean 3.38 / eval/rep_loss_std 4.4 / eval/reward_avg 0 / eval/reward_loss_mean 2.7e-4 / eval/reward_loss_std 2.5e-6 / eval/reward_max_data 0 / eval/reward_max_pred 0 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 2.7e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 8618 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / 
replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9053 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 
/ timer/duration 300.09 / timer/env.step_count 3812 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 380.46 / 
timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7820 / timer/agent.policy_total 
16.59 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.4e-5 / 
timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.14 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / 
timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 9000 Counter(9000) 8937
Saved chunk: 20230921T214954F009592-0LcoHsaZYukoxP7JAyM59n-3XThakxfgc6P6sGuBKtgu7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215010F498812-5YjdpBk0a8DByRN0wLaD60-7fxuDYPUaKX4SKYD1iE9YD-1024.npz
Starting evaluation at step 9500 Counter(9500) 9437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 10000 Counter(10000) 9937
Saved chunk: 20230921T215112F834957-3XThakxfgc6P6sGuBKtgu7-5k6Yv1LdXYCwDN4pW8e9Of-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215131F073701-7fxuDYPUaKX4SKYD1iE9YD-1gSKQtN3jBzMGH8SAj1mdi-1024.npz
Starting evaluation at step 10500 Counter(10500) 10437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T215231F412928-5k6Yv1LdXYCwDN4pW8e9Of-0000000000000000000000-880.npz
Saved chunk: 20230921T215251F188879-1gSKQtN3jBzMGH8SAj1mdi-0000000000000000000000-660.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 11000 Counter(11000) 10937
Saved chunk: 20230921T215231F412928-5k6Yv1LdXYCwDN4pW8e9Of-7wJhBc6fJwy3q4OdQNg6Z7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215251F188879-1gSKQtN3jBzMGH8SAj1mdi-6F6F1znxKz441e03fZsYvz-1024.npz
Starting evaluation at step 11500 Counter(11500) 11437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 12000 Counter(12000) 11937
Saved chunk: 20230921T215350F067022-7wJhBc6fJwy3q4OdQNg6Z7-26Lvqpi9ZuVLeVaNu4yV4q-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215411F322689-6F6F1znxKz441e03fZsYvz-0UkJBmvaJvgfKvWCclNfy0-1024.npz
Starting evaluation at step 12500 Counter(12500) 12437
eval_Episode has 500 steps and return 0.0.
 Step 25002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.5 / train/action_min -3.83 / train/action_std 1.06 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.2e-5 / train/actor_opt_grad_steps 4750 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 4.7e-7 / train/cont_loss_std 2.5e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.03 / train/dyn_loss_std 
3.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 4750 / train/extr_critic_critic_opt_loss 28.25 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 2.5e-24 / train/extr_return_normed_max 2.5e-24 / train/extr_return_normed_mean 2.5e-24 / 
train/extr_return_normed_min 2.5e-24 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 
0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 1.89 / train/image_loss_std 1.86 / train/model_loss_mean 3.11 / train/model_loss_std 3.35 / train/model_opt_grad_norm 15.75 / 
train/model_opt_grad_steps 4741 / train/model_opt_loss 1203.3 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 407.4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.28 / train/policy_entropy_std 3.4e-3 / train/policy_logprob_mag 9.38 / train/policy_logprob_max -0.82 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.38 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.94 / train/policy_randomness_std 1.5e-3 / train/post_ent_mag 29.5 / train/post_ent_max 29.5 / train/post_ent_mean 20.8 / train/post_ent_min 13.91 / train/post_ent_std 2.38 / 
train/prior_ent_mag 44.75 / train/prior_ent_max 44.75 / train/prior_ent_mean 23.48 / train/prior_ent_min 16.34 / train/prior_ent_std 3.71 / train/rep_loss_mean 2.03 / train/rep_loss_std 3.73 / train/reward_avg 0 / train/reward_loss_mean 1.5e-4 / train/reward_loss_std 
1.2e-6 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-4 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 2e-7 / report/cont_loss_std 9.5e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-7 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.99 / report/dyn_loss_std 4.03 / report/image_loss_mean 1.01 / report/image_loss_std 1.26 / report/model_loss_mean 2.21 / report/model_loss_std 3.15 / report/post_ent_mag 30.3 / report/post_ent_max 30.3 / report/post_ent_mean 21.43 / 
report/post_ent_min 14.34 / report/post_ent_std 2.36 / report/prior_ent_mag 44.79 / report/prior_ent_max 44.79 / report/prior_ent_mean 23.54 / report/prior_ent_min 16.19 / report/prior_ent_std 3.57 / report/rep_loss_mean 1.99 / report/rep_loss_std 4.03 / report/reward_avg
0 / report/reward_loss_mean 8.2e-5 / report/reward_loss_std 6.2e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-5 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / 
report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-7 / eval/cont_loss_std 1.7e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-7 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.82 / 
eval/dyn_loss_std 6.81 / eval/image_loss_mean 4.64 / eval/image_loss_std 4 / eval/model_loss_mean 7.53 / eval/model_loss_std 7.11 / eval/post_ent_mag 40.76 / eval/post_ent_max 40.76 / eval/post_ent_mean 21.4 / eval/post_ent_min 14.29 / eval/post_ent_std 3.67 / 
eval/prior_ent_mag 44.79 / eval/prior_ent_max 44.79 / eval/prior_ent_mean 23.54 / eval/prior_ent_min 16.02 / eval/prior_ent_std 4.16 / eval/rep_loss_mean 4.82 / eval/rep_loss_std 6.81 / eval/reward_avg 0 / eval/reward_loss_mean 8.2e-5 / eval/reward_loss_std 8.4e-7 / 
eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.2e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.2e4 / replay/inserts 3820 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.3e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.9 / timer/env.step_count 3820 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.8e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.39 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / 
timer/agent.save_frac 3.8e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7828 / timer/agent.policy_total 16.72 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.11 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1910 / 
timer/agent.train_total 244.78 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 13000 Counter(13000) 12937
Saved chunk: 20230921T215508F264257-26Lvqpi9ZuVLeVaNu4yV4q-7kaH8diYU1Mq9WpvL9NquW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215531F007398-0UkJBmvaJvgfKvWCclNfy0-5eXqzZMprB6s3hhrE1z0ZZ-1024.npz
Starting evaluation at step 13500 Counter(13500) 13437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 14000 Counter(14000) 13937
Saved chunk: 20230921T215627F249977-7kaH8diYU1Mq9WpvL9NquW-62VXp4rYbkGn3CJtC4YbjR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215651F769257-5eXqzZMprB6s3hhrE1z0ZZ-1yG2zkrzgGdRb5Bwmq2NZ1-1024.npz
Starting evaluation at step 14500 Counter(14500) 14437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 15000 Counter(15000) 14937
Saved chunk: 20230921T215745F811052-62VXp4rYbkGn3CJtC4YbjR-2ROA3JAbsJyQ111ZXSTfgd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215811F857186-1yG2zkrzgGdRb5Bwmq2NZ1-6zvBQNLtL7FgvD6uKPVrqU-1024.npz
Starting evaluation at step 15500 Counter(15500) 15437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 16000 Counter(16000) 15937
Saved chunk: 20230921T215904F218066-2ROA3JAbsJyQ111ZXSTfgd-4QQ1O4uWOx3Hc8Kddctr0c-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 32718 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.61 / train/action_max 4.6 / train/action_mean 0.48 / train/action_min -3.93 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.8e-6 / train/actor_opt_grad_steps 6670 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 1.3e-7 / train/cont_loss_std 6.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.94 / train/dyn_loss_std 
3.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.02 / train/extr_critic_critic_opt_grad_steps 6670 / train/extr_critic_critic_opt_loss 9.29 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 1.1e-32 / train/extr_return_normed_max 1.1e-32 / train/extr_return_normed_mean 1.1e-32 / 
train/extr_return_normed_min 1.1e-32 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 
0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 1.01 / train/image_loss_std 1.16 / train/model_loss_mean 2.18 / train/model_loss_std 2.9 / train/model_opt_grad_norm 15.74 / 
train/model_opt_grad_steps 6661 / train/model_opt_loss 3288.5 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1551.17 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.31 / train/policy_entropy_std 2.6e-3 / train/policy_logprob_mag 9.34 / train/policy_logprob_max -0.85 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.34 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.95 / train/policy_randomness_std 1.1e-3 / train/post_ent_mag 31.87 / train/post_ent_max 31.87 / train/post_ent_mean 21.95 / train/post_ent_min 14.14 / train/post_ent_std 2.86 / 
train/prior_ent_mag 45.06 / train/prior_ent_max 45.06 / train/prior_ent_mean 24.41 / train/prior_ent_min 16.73 / train/prior_ent_std 3.93 / train/rep_loss_mean 1.94 / train/rep_loss_std 3.71 / train/reward_avg 0 / train/reward_loss_mean 5e-5 / train/reward_loss_std 3.8e-7
/ train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 5e-5 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.41 / eval_stats/mean_log_entropy 0
/ report/cont_avg 1 / report/cont_loss_mean 6.8e-8 / report/cont_loss_std 2.9e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.8e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.83 / 
report/dyn_loss_std 3.21 / report/image_loss_mean 0.75 / report/image_loss_std 0.73 / report/model_loss_mean 1.84 / report/model_loss_std 2.31 / report/post_ent_mag 33.12 / report/post_ent_max 33.12 / report/post_ent_mean 23.01 / report/post_ent_min 14.12 / 
report/post_ent_std 3.22 / report/prior_ent_mag 44.42 / report/prior_ent_max 44.42 / report/prior_ent_mean 25.33 / report/prior_ent_min 16.5 / report/prior_ent_std 4.08 / report/rep_loss_mean 1.83 / report/rep_loss_std 3.21 / report/reward_avg 0 / report/reward_loss_mean 
2.8e-5 / report/reward_loss_std 2.5e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-5 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 
/ eval/cont_loss_mean 9.8e-8 / eval/cont_loss_std 5.2e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.8e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 5.25 / eval/dyn_loss_std 7.31 / eval/image_loss_mean 3.91
/ eval/image_loss_std 4.01 / eval/model_loss_mean 7.06 / eval/model_loss_std 7.4 / eval/post_ent_mag 38.82 / eval/post_ent_max 38.82 / eval/post_ent_mean 21.98 / eval/post_ent_min 14.61 / eval/post_ent_std 3.87 / eval/prior_ent_mag 44.42 / eval/prior_ent_max 44.42 / 
eval/prior_ent_mean 24.32 / eval/prior_ent_min 16.35 / eval/prior_ent_std 4.19 / eval/rep_loss_mean 5.25 / eval/rep_loss_std 7.31 / eval/reward_avg 0 / eval/reward_loss_mean 2.8e-5 / eval/reward_loss_std 5.1e-7 / eval/reward_max_data 0 / eval/reward_max_pred 0 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.6e4 / replay/inserts 3858 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 
/ replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.7e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3858 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 390.11 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.09 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7365 / timer/agent.policy_total 15.69 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1929 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / 
timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1929 / timer/agent.train_total 247.16 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / 
timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.71

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T215931F691892-6zvBQNLtL7FgvD6uKPVrqU-2Oc6EFwzJPl8BO5ovnfFJZ-1024.npz
Starting evaluation at step 16500 Counter(16500) 16437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 17000 Counter(17000) 16937
Saved chunk: 20230921T220022F361892-4QQ1O4uWOx3Hc8Kddctr0c-2KwfUnW62CyZEXU94e6bCP-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220051F962752-2Oc6EFwzJPl8BO5ovnfFJZ-5Fx0k4Gj6ub3lu5HEPytCf-1024.npz
Starting evaluation at step 17500 Counter(17500) 17437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 18000 Counter(18000) 17937
Saved chunk: 20230921T220141F486367-2KwfUnW62CyZEXU94e6bCP-1dat76ue0K25aKOTgWW5Y2-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220212F320019-5Fx0k4Gj6ub3lu5HEPytCf-3q2Tf95UWj1mM0L9YXO9Sv-1024.npz
Starting evaluation at step 18500 Counter(18500) 18437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 19000 Counter(19000) 18937
Saved chunk: 20230921T220300F070816-1dat76ue0K25aKOTgWW5Y2-5idmBt7cLxX3BwZBVWQZ5w-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220332F322907-3q2Tf95UWj1mM0L9YXO9Sv-1xG5Gwn4pQs0GJ5mUr53k7-1024.npz
Starting evaluation at step 19500 Counter(19500) 19437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 20000 Counter(20000) 19937
Saved chunk: 20230921T220418F289777-5idmBt7cLxX3BwZBVWQZ5w-0dwolKs2EkpSwM7AFBAmto-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 40342 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.61 / train/action_max 4.61 / train/action_mean 0.48 / train/action_min -3.87 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.9e-6 / train/actor_opt_grad_steps 8585 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 4.7e-8 / train/cont_loss_std 2.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.89 / train/dyn_loss_std 
3.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.4e-3 / train/extr_critic_critic_opt_grad_steps 8585 / train/extr_critic_critic_opt_loss 3.36 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 4.3e-41 / train/extr_return_normed_max 4.3e-41 / train/extr_return_normed_mean 4.3e-41 / 
train/extr_return_normed_min 4.3e-41 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 
0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.72 / train/image_loss_std 0.89 / train/model_loss_mean 1.85 / train/model_loss_std 2.73 / train/model_opt_grad_norm 13.44 / 
train/model_opt_grad_steps 8575.24 / train/model_opt_loss 5843.77 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3184.21 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.33 / train/policy_entropy_std 2.2e-3 / train/policy_logprob_mag 9.33 / train/policy_logprob_max -0.87 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.33 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.96 / train/policy_randomness_std 9.5e-4 / train/post_ent_mag 34.94 / train/post_ent_max 34.94 / train/post_ent_mean 23.78 / train/post_ent_min 14.64 / train/post_ent_std 3.21 / 
train/prior_ent_mag 45.96 / train/prior_ent_max 45.96 / train/prior_ent_mean 26.12 / train/prior_ent_min 17.54 / train/prior_ent_std 4.05 / train/rep_loss_mean 1.89 / train/rep_loss_std 3.66 / train/reward_avg 0 / train/reward_loss_mean 1.8e-5 / train/reward_loss_std 
1.8e-7 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.8e-5 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 3e-8 / report/cont_loss_std 1.1e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-8 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.8 / report/dyn_loss_std 3.39 / report/image_loss_mean 0.68 / report/image_loss_std 0.75 / report/model_loss_mean 1.76 / report/model_loss_std 2.49 / report/post_ent_mag 36.17 / report/post_ent_max 36.17 / report/post_ent_mean 24.67 / 
report/post_ent_min 15.63 / report/post_ent_std 3.27 / report/prior_ent_mag 46.88 / report/prior_ent_max 46.88 / report/prior_ent_mean 27.05 / report/prior_ent_min 19.53 / report/prior_ent_std 3.96 / report/rep_loss_mean 1.8 / report/rep_loss_std 3.39 / report/reward_avg 
0 / report/reward_loss_mean 1e-5 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 1e-5 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0
/ eval/cont_avg 1 / eval/cont_loss_mean 4.8e-8 / eval/cont_loss_std 2.4e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 6.88 / eval/dyn_loss_std 9.07 / 
eval/image_loss_mean 4.66 / eval/image_loss_std 4.87 / eval/model_loss_mean 8.78 / eval/model_loss_std 9.59 / eval/post_ent_mag 36.17 / eval/post_ent_max 36.17 / eval/post_ent_mean 22.54 / eval/post_ent_min 13.72 / eval/post_ent_std 3.74 / eval/prior_ent_mag 46.88 / 
eval/prior_ent_max 46.88 / eval/prior_ent_mean 25.77 / eval/prior_ent_min 16.19 / eval/prior_ent_std 4.52 / eval/rep_loss_mean 6.88 / eval/rep_loss_std 9.07 / eval/reward_avg 0 / eval/reward_loss_mean 1e-5 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2e4 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3812 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 387.21 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.8e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7820 / timer/agent.policy_total 16.53 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.07 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / 
timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.22 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / 
timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T220452F018081-1xG5Gwn4pQs0GJ5mUr53k7-7EZVy2nJ56phCfRWWhGDwr-1024.npz
Starting evaluation at step 20500 Counter(20500) 20437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21000 Counter(21000) 20937
Saved chunk: 20230921T220536F416595-0dwolKs2EkpSwM7AFBAmto-6HYbHQungmhytMOP6CDXol-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21500 Counter(21500) 21437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220612F531704-7EZVy2nJ56phCfRWWhGDwr-5dlaRYLOPJSsUyL049Rh1P-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22000 Counter(22000) 21937
Saved chunk: 20230921T220655F702933-6HYbHQungmhytMOP6CDXol-1Br89UMFb1V4SQG8cGGQLw-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T220814F219949-1Br89UMFb1V4SQG8cGGQLw-0000000000000000000000-115.npz
Saved chunk: 20230921T220736F139297-5dlaRYLOPJSsUyL049Rh1P-0000000000000000000000-896.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 22500 Counter(22500) 22437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220736F139297-5dlaRYLOPJSsUyL049Rh1P-4kqObZi75vjEe5hQFsufMU-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 23000 Counter(23000) 22937
Saved chunk: 20230921T220814F219949-1Br89UMFb1V4SQG8cGGQLw-1J1OLERGWoGdAOGOqzixxO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 23500 Counter(23500) 23437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220856F371702-4kqObZi75vjEe5hQFsufMU-6UsBkvgReuoZyiEVKfrGF4-1024.npz
Starting evaluation at step 24000 Counter(24000) 23937
Saved chunk: 20230921T220932F770901-1J1OLERGWoGdAOGOqzixxO-2foxrtQzjERMXDMCGzz0jW-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 48002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.61 / train/action_max 4.6 / train/action_mean 0.47 / train/action_min -3.89 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.7e-6 / train/actor_opt_grad_steps 1e4 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2e-8 / train/cont_loss_std 9.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.86 / train/dyn_loss_std 3.64 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.5e-3 / train/extr_critic_critic_opt_grad_steps 1e4 / train/extr_critic_critic_opt_loss 1.29 / train/extr_critic_mag 
0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / 
train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / 
train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.57 / train/image_loss_std 0.73 / train/model_loss_mean 1.68 / train/model_loss_std 2.63 / train/model_opt_grad_norm 12.37 / train/model_opt_grad_steps 1e4 / 
train/model_opt_loss 7991.23 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4739.58 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.35 / 
train/policy_entropy_std 1.8e-3 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.88 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.97 / train/policy_randomness_std 8e-4 / train/post_ent_mag 37.77 / train/post_ent_max 37.77 / train/post_ent_mean 25.84 / train/post_ent_min 15.16 / train/post_ent_std 3.53 / train/prior_ent_mag 47.45 / 
train/prior_ent_max 47.45 / train/prior_ent_mean 28.05 / train/prior_ent_min 18.51 / train/prior_ent_std 4.19 / train/rep_loss_mean 1.86 / train/rep_loss_std 3.64 / train/reward_avg 0 / train/reward_loss_mean 6.3e-6 / train/reward_loss_std 7.1e-8 / train/reward_max_data 0
/ train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 6.3e-6 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.3e-8 / report/cont_loss_std 5.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.89 / report/dyn_loss_std 3.43 / 
report/image_loss_mean 0.49 / report/image_loss_std 0.56 / report/model_loss_mean 1.62 / report/model_loss_std 2.36 / report/post_ent_mag 33.62 / report/post_ent_max 33.62 / report/post_ent_mean 26.47 / report/post_ent_min 13.54 / report/post_ent_std 3.59 / 
report/prior_ent_mag 47.77 / report/prior_ent_max 47.77 / report/prior_ent_mean 28.3 / report/prior_ent_min 15.03 / report/prior_ent_std 4.21 / report/rep_loss_mean 1.89 / report/rep_loss_std 3.43 / report/reward_avg 0 / report/reward_loss_mean 3.8e-6 / 
report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 3.8e-6 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.8e-8 / eval/cont_loss_std 8.1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.66 / eval/dyn_loss_std 6.36 / eval/image_loss_mean 2.17 /
eval/image_loss_std 2.7 / eval/model_loss_mean 4.97 / eval/model_loss_std 5.84 / eval/post_ent_mag 38.82 / eval/post_ent_max 38.82 / eval/post_ent_mean 24.71 / eval/post_ent_min 14.24 / eval/post_ent_std 4.27 / eval/prior_ent_mag 47.77 / eval/prior_ent_max 47.77 / 
eval/prior_ent_mean 27.79 / eval/prior_ent_min 17.4 / eval/prior_ent_std 4.78 / eval/rep_loss_mean 4.66 / eval/rep_loss_std 6.36 / eval/reward_avg 0 / eval/reward_loss_mean 3.8e-6 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.4e4 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 
/ replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 301.9 / timer/env.step_count 3830 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 389.05 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / 
timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7838 / timer/agent.policy_total 16.71 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 /
timer/dataset_train_count 1915 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1915 / timer/agent.train_total 245.66 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.37

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 24500 Counter(24500) 24437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221016F192681-6UsBkvgReuoZyiEVKfrGF4-2igfJHtCnouaBy80jo8iA5-1024.npz
Starting evaluation at step 25000 Counter(25000) 24937
Saved chunk: 20230921T221051F062156-2foxrtQzjERMXDMCGzz0jW-5AIig2I5qFYlOM86tKyfJH-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 25500 Counter(25500) 25437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221136F876347-2igfJHtCnouaBy80jo8iA5-6N1VFMq08YuxCbKbVYsHJo-1024.npz
Starting evaluation at step 26000 Counter(26000) 25937
Saved chunk: 20230921T221210F720431-5AIig2I5qFYlOM86tKyfJH-46HlnbYicL7mHO4VwbuVcc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 26500 Counter(26500) 26437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221257F408480-6N1VFMq08YuxCbKbVYsHJo-2o37mkGfEQo1v9OPXbmNJo-1024.npz
Starting evaluation at step 27000 Counter(27000) 26937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221329F177380-46HlnbYicL7mHO4VwbuVcc-5IIBJZxjKSz4U2JdLthQGV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 27500 Counter(27500) 27437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221417F329527-2o37mkGfEQo1v9OPXbmNJo-7x2dOob0GzhRo0xs04RsZu-1024.npz
 Step 55710 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.47 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.8e-6 / train/actor_opt_grad_steps 1.2e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1e-8 / train/cont_loss_std 5.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / train/dyn_loss_std 3.6 /
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1e-3 / train/extr_critic_critic_opt_grad_steps 1.2e4 / train/extr_critic_critic_opt_loss 0.52 / train/extr_critic_mag 
0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / 
train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / 
train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.47 / train/image_loss_std 0.64 / train/model_loss_mean 1.58 / train/model_loss_std 2.56 / train/model_opt_grad_norm 12.33 / train/model_opt_grad_steps 1.2e4 / 
train/model_opt_loss 7675.99 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4869.79 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.35 / 
train/policy_entropy_std 1.6e-3 / train/policy_logprob_mag 9.52 / train/policy_logprob_max -0.89 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.52 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.97 / train/policy_randomness_std 7e-4 / train/post_ent_mag 39.95 / train/post_ent_max 39.95 / train/post_ent_mean 27.46 / train/post_ent_min 15.61 / train/post_ent_std 3.58 / train/prior_ent_mag 48.65 / 
train/prior_ent_max 48.65 / train/prior_ent_mean 29.56 / train/prior_ent_min 19.2 / train/prior_ent_std 4.13 / train/rep_loss_mean 1.84 / train/rep_loss_std 3.6 / train/reward_avg 0 / train/reward_loss_mean 2.2e-6 / train/reward_loss_std 4e-8 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 2.2e-6 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 5.6e-9 / report/cont_loss_std 2.3e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.6e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.87 / 
report/image_loss_mean 0.35 / report/image_loss_std 0.49 / report/model_loss_mean 1.41 / report/model_loss_std 2.62 / report/post_ent_mag 41.28 / report/post_ent_max 41.28 / report/post_ent_mean 29.04 / report/post_ent_min 16.17 / report/post_ent_std 3.17 / 
report/prior_ent_mag 49.57 / report/prior_ent_max 49.57 / report/prior_ent_mean 30.9 / report/prior_ent_min 19.64 / report/prior_ent_std 3.74 / report/rep_loss_mean 1.76 / report/rep_loss_std 3.87 / report/reward_avg 0 / report/reward_loss_mean 9.5e-7 / 
report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 9.5e-7 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 6.9e-9 / eval/cont_loss_std 4.9e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.9e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.23 / eval/dyn_loss_std 8.12 / eval/image_loss_mean 2.21 /
eval/image_loss_std 4.91 / eval/model_loss_mean 4.75 / eval/model_loss_std 9.26 / eval/post_ent_mag 41 / eval/post_ent_max 41 / eval/post_ent_mean 26.86 / eval/post_ent_min 13.88 / eval/post_ent_std 4.3 / eval/prior_ent_mag 49.57 / eval/prior_ent_max 49.57 / 
eval/prior_ent_mean 29.19 / eval/prior_ent_min 17.64 / eval/prior_ent_std 4.87 / eval/rep_loss_mean 4.23 / eval/rep_loss_std 8.12 / eval/reward_avg 0 / eval/reward_loss_mean 9.5e-7 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 9.5e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.8e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 
/ replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.8e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3854 / timer/env.step_total 19.24 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 389.18 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7361 / timer/agent.policy_total 16.06 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.46 / timer/dataset_train_count 1927 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / 
timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1927 / timer/agent.train_total 246.79 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / 
timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 28000 Counter(28000) 27937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 28500 Counter(28500) 28437
Saved chunk: 20230921T221447F405984-5IIBJZxjKSz4U2JdLthQGV-3opDZVsOzUZYo2igf3QnAE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221536F980215-7x2dOob0GzhRo0xs04RsZu-1pzQQ8TNLy3sl8fEmmd2Kb-1024.npz
Starting evaluation at step 29000 Counter(29000) 28937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 29500 Counter(29500) 29437
Saved chunk: 20230921T221642F186653-3opDZVsOzUZYo2igf3QnAE-4vB6Rp6sEObXSiHfNKgW5e-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221657F754669-1pzQQ8TNLy3sl8fEmmd2Kb-06f6845vBgMm7DTsJR0WmH-1024.npz
Starting evaluation at step 30000 Counter(30000) 29937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 30500 Counter(30500) 30437
Saved chunk: 20230921T221800F680789-4vB6Rp6sEObXSiHfNKgW5e-5TrXCNjmtdnIokulkHj0lN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T221817F767035-06f6845vBgMm7DTsJR0WmH-2ZZtvemsHQn5CE6bmkpigA-1024.npz
Starting evaluation at step 31000 Counter(31000) 30937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 31500 Counter(31500) 31437
Saved chunk: 20230921T221918F952078-5TrXCNjmtdnIokulkHj0lN-2djkY0vKuvDUDNnS2Swdf1-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 63334 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.49 / train/action_min -3.86 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.3e-6 / train/actor_opt_grad_steps 1.4e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.8e-9 / train/cont_loss_std 3.2e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / train/dyn_loss_std 
3.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.3e-4 / train/extr_critic_critic_opt_grad_steps 1.4e4 / train/extr_critic_critic_opt_loss 0.22 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.42 / train/image_loss_std 0.61 / train/model_loss_mean 1.52 / train/model_loss_std 2.53 / train/model_opt_grad_norm 11.23 / 
train/model_opt_grad_steps 1.4e4 / train/model_opt_loss 8255.75 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5445.03 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.36 / train/policy_entropy_std 1.4e-3 / train/policy_logprob_mag 9.38 / train/policy_logprob_max -0.89 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.38 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 6.1e-4 / train/post_ent_mag 41.87 / train/post_ent_max 41.87 / train/post_ent_mean 28.87 / train/post_ent_min 16.44 / train/post_ent_std 3.56 / 
train/prior_ent_mag 50.03 / train/prior_ent_max 50.03 / train/prior_ent_mean 30.96 / train/prior_ent_min 20.62 / train/prior_ent_std 4.08 / train/rep_loss_mean 1.84 / train/rep_loss_std 3.57 / train/reward_avg 0 / train/reward_loss_mean 9.5e-7 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.5e-7 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42
/ report/cont_avg 1 / report/cont_loss_mean 3.5e-9 / report/cont_loss_std 2.3e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / 
report/dyn_loss_std 2.96 / report/image_loss_mean 0.28 / report/image_loss_std 0.37 / report/model_loss_mean 1.3 / report/model_loss_std 2.01 / report/post_ent_mag 42.8 / report/post_ent_max 42.8 / report/post_ent_mean 30.69 / report/post_ent_min 21.82 / 
report/post_ent_std 2.78 / report/prior_ent_mag 50.38 / report/prior_ent_max 50.38 / report/prior_ent_mean 32.4 / report/prior_ent_min 24.36 / report/prior_ent_std 3.3 / report/rep_loss_mean 1.7 / report/rep_loss_std 2.96 / report/reward_avg 0 / report/reward_loss_mean 
9.5e-7 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 9.5e-7 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 4.3e-9 / eval/cont_loss_std 3.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.72 / eval/dyn_loss_std 7.39 / eval/image_loss_mean 1.78 /
eval/image_loss_std 4.07 / eval/model_loss_mean 4.01 / eval/model_loss_std 8.03 / eval/post_ent_mag 42.68 / eval/post_ent_max 42.68 / eval/post_ent_mean 28.89 / eval/post_ent_min 15.05 / eval/post_ent_std 4.74 / eval/prior_ent_mag 50.38 / eval/prior_ent_max 50.38 / 
eval/prior_ent_mean 31.35 / eval/prior_ent_min 16.81 / eval/prior_ent_std 4.84 / eval/rep_loss_mean 3.72 / eval/rep_loss_std 7.39 / eval/reward_avg 0 / eval/reward_loss_mean 9.5e-7 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 9.5e-7 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.2e4 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / 
replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.2e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac
1 / timer/duration 300.09 / timer/env.step_count 3812 / timer/env.step_total 18.99 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 384.56 / 
timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.3e-3 / timer/replay._sample_max 0.09 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7820 / timer/agent.policy_total 16.5
/ timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.6e-5 / 
timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.22 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2
/ timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T221937F589159-2ZZtvemsHQn5CE6bmkpigA-7rUUh8ELXyzbrQXT7QIvVr-1024.npz
Starting evaluation at step 32000 Counter(32000) 31937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 32500 Counter(32500) 32437
Saved chunk: 20230921T222037F133254-2djkY0vKuvDUDNnS2Swdf1-2qx0inUqj6UlLsl5kXH1BQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222057F932703-7rUUh8ELXyzbrQXT7QIvVr-1aum3a2WZuPIz4UEKnDiuI-1024.npz
Starting evaluation at step 33000 Counter(33000) 32937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 33500 Counter(33500) 33437
Saved chunk: 20230921T222156F364905-2qx0inUqj6UlLsl5kXH1BQ-1ZdptEfKg5QR6f2q3ZiEoK-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222218F226495-1aum3a2WZuPIz4UEKnDiuI-3NLhmn1NlF28sr2mrq7v7u-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T222338F178069-3NLhmn1NlF28sr2mrq7v7u-0000000000000000000000-108.npz
Saved chunk: 20230921T222314F801132-1ZdptEfKg5QR6f2q3ZiEoK-0000000000000000000000-374.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 34000 Counter(34000) 33937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 34500 Counter(34500) 34437
Saved chunk: 20230921T222314F801132-1ZdptEfKg5QR6f2q3ZiEoK-2T9KYCvlDIixy4zCkaiHBh-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222338F178069-3NLhmn1NlF28sr2mrq7v7u-2FJ0GYI3XbMgFE07HBQ8Fv-1024.npz
Starting evaluation at step 35000 Counter(35000) 34937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 35500 Counter(35500) 35437
Saved chunk: 20230921T222433F375672-2T9KYCvlDIixy4zCkaiHBh-181MGYC9yJsJSm6RxbBVbt-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 71002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.62 / train/action_max 4.62 / train/action_mean 0.49 / train/action_min -3.9 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3e-6 / train/actor_opt_grad_steps 1.6e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 3.1e-9 / train/cont_loss_std 2.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.83 / train/dyn_loss_std 
3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.9e-4 / train/extr_critic_critic_opt_grad_steps 1.6e4 / train/extr_critic_critic_opt_loss 0.09 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.39 / train/image_loss_std 0.58 / train/model_loss_mean 1.49 / train/model_loss_std 2.52 / train/model_opt_grad_norm 11.07 / 
train/model_opt_grad_steps 1.6e4 / train/model_opt_loss 6749.68 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4531.25 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.37 / train/policy_entropy_std 1.3e-3 / train/policy_logprob_mag 9.36 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.36 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 5.7e-4 / train/post_ent_mag 43.79 / train/post_ent_max 43.79 / train/post_ent_mean 30.34 / train/post_ent_min 16.98 / train/post_ent_std 3.6 / 
train/prior_ent_mag 51.82 / train/prior_ent_max 51.82 / train/prior_ent_mean 32.4 / train/prior_ent_min 21.8 / train/prior_ent_std 4.09 / train/rep_loss_mean 1.83 / train/rep_loss_std 3.59 / train/reward_avg 0 / train/reward_loss_mean 2.5e-7 / train/reward_loss_std 2e-8 /
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 2.5e-7 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42
/ report/cont_avg 1 / report/cont_loss_mean 3.1e-9 / report/cont_loss_std 3.4e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / 
report/dyn_loss_std 3.34 / report/image_loss_mean 0.35 / report/image_loss_std 0.42 / report/model_loss_mean 1.39 / report/model_loss_std 2.26 / report/post_ent_mag 44.69 / report/post_ent_max 44.69 / report/post_ent_mean 30.66 / report/post_ent_min 19.62 / 
report/post_ent_std 3.72 / report/prior_ent_mag 52.69 / report/prior_ent_max 52.69 / report/prior_ent_mean 32.95 / report/prior_ent_min 22.63 / report/prior_ent_std 4.2 / report/rep_loss_mean 1.72 / report/rep_loss_std 3.34 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 2.5e-9 / eval/cont_loss_std 1.8e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.08 / eval/dyn_loss_std 3.65 / eval/image_loss_mean 0.47 /
eval/image_loss_std 1.2 / eval/model_loss_mean 1.71 / eval/model_loss_std 3.03 / eval/post_ent_mag 44.66 / eval/post_ent_max 44.66 / eval/post_ent_mean 30.84 / eval/post_ent_min 18.19 / eval/post_ent_std 3.32 / eval/prior_ent_mag 52.69 / eval/prior_ent_max 52.69 / 
eval/prior_ent_mean 33.48 / eval/prior_ent_min 24.22 / eval/prior_ent_std 3.86 / eval/rep_loss_mean 2.08 / eval/rep_loss_std 3.65 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.5e4 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.6e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
302.03 / timer/env.step_count 3834 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.28 / timer/replay._sample_frac 
1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.09 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.3e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 /
timer/agent.policy_count 7842 / timer/agent.policy_total 16.75 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1917 / timer/agent.train_total 245.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222458F280215-2FJ0GYI3XbMgFE07HBQ8Fv-3DV6GiOW6C5ogSgDzvBa2P-1024.npz
Starting evaluation at step 36000 Counter(36000) 35937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 36500 Counter(36500) 36437
Saved chunk: 20230921T222551F580496-181MGYC9yJsJSm6RxbBVbt-3v4DLIXzGyC14ZspTL6NKc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222618F816766-3DV6GiOW6C5ogSgDzvBa2P-5hvnB8kzgh1mdfdeGuEN9k-1024.npz
Starting evaluation at step 37000 Counter(37000) 36937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 37500 Counter(37500) 37437
Saved chunk: 20230921T222710F904130-3v4DLIXzGyC14ZspTL6NKc-38b6r6ablATEb8LwNnJOUd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222739F046509-5hvnB8kzgh1mdfdeGuEN9k-4g8d8rkFLmK68y8pAzMR8P-1024.npz
Starting evaluation at step 38000 Counter(38000) 37937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 38500 Counter(38500) 38437
Saved chunk: 20230921T222829F398756-38b6r6ablATEb8LwNnJOUd-13248ZwkZQJTpm4MrwQ43q-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T222859F062909-4g8d8rkFLmK68y8pAzMR8P-27q960Og9aFWwkLY0s6tSe-1024.npz
Starting evaluation at step 39000 Counter(39000) 38937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 78714 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.5 / train/action_min -3.87 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.6e-6 / train/actor_opt_grad_steps 1.8e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.4e-9 / train/cont_loss_std 3.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.83 / train/dyn_loss_std 
3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.1e-4 / train/extr_critic_critic_opt_grad_steps 1.8e4 / train/extr_critic_critic_opt_loss 0.05 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.36 / train/image_loss_std 0.54 / train/model_loss_mean 1.46 / train/model_loss_std 2.54 / train/model_opt_grad_norm 9.7 / 
train/model_opt_grad_steps 1.8e4 / train/model_opt_loss 6043.85 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4140.62 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.37 / train/policy_entropy_std 1.2e-3 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 5.3e-4 / train/post_ent_mag 45.69 / train/post_ent_max 45.69 / train/post_ent_mean 31.58 / train/post_ent_min 17.55 / train/post_ent_std 3.76 / 
train/prior_ent_mag 53.43 / train/prior_ent_max 53.43 / train/prior_ent_mean 33.61 / train/prior_ent_min 22.22 / train/prior_ent_std 4.21 / train/rep_loss_mean 1.83 / train/rep_loss_std 3.65 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 1.7e-9 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / 
report/dyn_loss_std 2.68 / report/image_loss_mean 0.25 / report/image_loss_std 0.37 / report/model_loss_mean 1.24 / report/model_loss_std 1.77 / report/post_ent_mag 47.38 / report/post_ent_max 47.38 / report/post_ent_mean 32.94 / report/post_ent_min 17.85 / 
report/post_ent_std 3.42 / report/prior_ent_mag 55.18 / report/prior_ent_max 55.18 / report/prior_ent_mean 34.89 / report/prior_ent_min 23.97 / report/prior_ent_std 3.97 / report/rep_loss_mean 1.66 / report/rep_loss_std 2.68 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.5e-9 / eval/cont_loss_std 1.1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.24 / eval/image_loss_mean 0.2 / 
eval/image_loss_std 0.28 / eval/model_loss_mean 1.24 / eval/model_loss_std 2.14 / eval/post_ent_mag 47.23 / eval/post_ent_max 47.23 / eval/post_ent_mean 33.7 / eval/post_ent_min 20.05 / eval/post_ent_std 2.84 / eval/prior_ent_mag 55.18 / eval/prior_ent_max 55.18 / 
eval/prior_ent_mean 35.6 / eval/prior_ent_min 29.84 / eval/prior_ent_std 3.28 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.24 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.9e4 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.03 / timer/env.step_count 3856 / timer/env.step_total 19.2 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.39 / timer/replay._sample_frac 
1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7363 / timer/agent.policy_total 15.75 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.07 / timer/dataset_train_count 1928 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / 
timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1928 / timer/agent.train_total 247.07 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.2 / timer/agent.report_count 2
/ timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 39500 Counter(39500) 39437
Saved chunk: 20230921T222947F655751-13248ZwkZQJTpm4MrwQ43q-5h15Ce7fvES1pb5B2utr0W-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223018F836151-27q960Og9aFWwkLY0s6tSe-6tlgGSoZUvtlngdxzlh6ev-1024.npz
Starting evaluation at step 40000 Counter(40000) 39937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 40500 Counter(40500) 40437
Saved chunk: 20230921T223106F501577-5h15Ce7fvES1pb5B2utr0W-2EjYHyKu08HO6tmS7MLiWW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223139F520684-6tlgGSoZUvtlngdxzlh6ev-1s9cViuS3ZJYJcrJVjucYS-1024.npz
Starting evaluation at step 41000 Counter(41000) 40937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 41500 Counter(41500) 41437
Saved chunk: 20230921T223225F138235-2EjYHyKu08HO6tmS7MLiWW-1C9R90txuzFaJb8L520eYk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223259F609340-1s9cViuS3ZJYJcrJVjucYS-3phindnNgod1HR1hJYoZQ8-1024.npz
Starting evaluation at step 42000 Counter(42000) 41937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 42500 Counter(42500) 42437
Saved chunk: 20230921T223343F576348-1C9R90txuzFaJb8L520eYk-67U7QSVYKWK3MZa6cryYsN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 43000 Counter(43000) 42937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223419F539313-3phindnNgod1HR1hJYoZQ8-7fqjHjTurV1sIsgKZ9NoR1-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 86338 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.71 / train/action_max 4.68 / train/action_mean 0.49 / train/action_min -3.97 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.4e-6 / train/actor_opt_grad_steps 2e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 1.8e-9 / train/cont_loss_std 2e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std 3.57 /
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.4e-5 / train/extr_critic_critic_opt_grad_steps 2e4 / train/extr_critic_critic_opt_loss 0.02 / train/extr_critic_mag 
0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / 
train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / 
train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.32 / train/image_loss_std 0.49 / train/model_loss_mean 1.41 / train/model_loss_std 2.45 / train/model_opt_grad_norm 10.12 / train/model_opt_grad_steps 2e4 / 
train/model_opt_loss 5824 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 4162.3 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.37 / train/policy_entropy_std 
1.2e-3 / train/policy_logprob_mag 9.67 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.67 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / 
train/policy_randomness_min 0.98 / train/policy_randomness_std 5e-4 / train/post_ent_mag 47.34 / train/post_ent_max 47.34 / train/post_ent_mean 32.85 / train/post_ent_min 18.23 / train/post_ent_std 3.73 / train/prior_ent_mag 54.7 / train/prior_ent_max 54.7 / 
train/prior_ent_mean 34.83 / train/prior_ent_min 23.45 / train/prior_ent_std 4.17 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.57 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / train/reward_max_pred 0 / 
train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / report/cont_loss_mean 1.4e-9 / 
report/cont_loss_std 2.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.9 / report/dyn_loss_std 3.94 / report/image_loss_mean 0.33 / 
report/image_loss_std 0.54 / report/model_loss_mean 1.46 / report/model_loss_std 2.77 / report/post_ent_mag 48.02 / report/post_ent_max 48.02 / report/post_ent_mean 32.78 / report/post_ent_min 18.88 / report/post_ent_std 3.39 / report/prior_ent_mag 55.54 / 
report/prior_ent_max 55.54 / report/prior_ent_mean 34.9 / report/prior_ent_min 26.19 / report/prior_ent_std 4.07 / report/rep_loss_mean 1.9 / report/rep_loss_std 3.94 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 /
report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.6e-9 / eval/cont_loss_std 2.5e-9 / 
eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.12 / eval/dyn_loss_std 5.74 / eval/image_loss_mean 0.93 / eval/image_loss_std 2.35 / eval/model_loss_mean 2.8 / 
eval/model_loss_std 5.25 / eval/post_ent_mag 47.93 / eval/post_ent_max 47.93 / eval/post_ent_mean 32.55 / eval/post_ent_min 16.2 / eval/post_ent_std 5.29 / eval/prior_ent_mag 55.54 / eval/prior_ent_max 55.54 / eval/prior_ent_mean 35.19 / eval/prior_ent_min 22.43 / 
eval/prior_ent_std 4.34 / eval/rep_loss_mean 3.12 / eval/rep_loss_std 5.74 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan /
eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.3e4 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 
4.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3812 / timer/env.step_total
18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 3.9e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.97 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min
5.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7820 / timer/agent.policy_total 16.55 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 
1.7e-3 / timer/agent.policy_max 8.1e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1906 / 
timer/agent.train_total 244.16 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 43500 Counter(43500) 43437
Saved chunk: 20230921T223501F823341-67U7QSVYKWK3MZa6cryYsN-1KFFgL5iXDZ5LfMtnBSP2X-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 44000 Counter(44000) 43937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223542F493056-7fqjHjTurV1sIsgKZ9NoR1-2XOkbwLCYDbOkRcKObz3l6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 44500 Counter(44500) 44437
Saved chunk: 20230921T223620F658755-1KFFgL5iXDZ5LfMtnBSP2X-7smQQQ8hgXHnpUUq4LfLOy-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 45000 Counter(45000) 44937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223703F230451-2XOkbwLCYDbOkRcKObz3l6-4RATtg1PhLuU2gsrTKL68P-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T223823F067842-4RATtg1PhLuU2gsrTKL68P-0000000000000000000000-344.npz
Saved chunk: 20230921T223739F210410-7smQQQ8hgXHnpUUq4LfLOy-0000000000000000000000-633.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 45500 Counter(45500) 45437
Saved chunk: 20230921T223739F210410-7smQQQ8hgXHnpUUq4LfLOy-19YGlsmq6rseD7f0ftZuHY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 46000 Counter(46000) 45937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223823F067842-4RATtg1PhLuU2gsrTKL68P-5tqz7GhBxiAqz0VP7sIQov-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 46500 Counter(46500) 46437
Saved chunk: 20230921T223857F619341-19YGlsmq6rseD7f0ftZuHY-384y7qBc19m4JKZ0nshQMp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 47000 Counter(47000) 46937
eval_Episode has 500 steps and return 0.0.
 Step 94002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.49 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.2e-6 / train/actor_opt_grad_steps 2.2e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.2e-9 / train/cont_loss_std 1.7e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std 
3.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.6e-5 / train/extr_critic_critic_opt_grad_steps 2.2e4 / train/extr_critic_critic_opt_loss 4.7e-3 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.31 / train/image_loss_std 0.48 / train/model_loss_mean 1.39 / train/model_loss_std 2.49 / train/model_opt_grad_norm 9.69 / 
train/model_opt_grad_steps 2.2e4 / train/model_opt_loss 6968.1 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5026.04 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.37 / train/policy_entropy_std 1.1e-3 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 4.8e-4 / train/post_ent_mag 48.82 / train/post_ent_max 48.82 / train/post_ent_mean 33.76 / train/post_ent_min 18.71 / train/post_ent_std 3.81 / 
train/prior_ent_mag 56.07 / train/prior_ent_max 56.07 / train/prior_ent_mean 35.72 / train/prior_ent_min 24.52 / train/prior_ent_std 4.23 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.64 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 9.6e-10 / report/cont_loss_std 1.6e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.6e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.85 / 
report/dyn_loss_std 3.96 / report/image_loss_mean 0.3 / report/image_loss_std 0.41 / report/model_loss_mean 1.41 / report/model_loss_std 2.65 / report/post_ent_mag 49.36 / report/post_ent_max 49.36 / report/post_ent_mean 34 / report/post_ent_min 16.89 / 
report/post_ent_std 4.58 / report/prior_ent_mag 56.68 / report/prior_ent_max 56.68 / report/prior_ent_mean 36.19 / report/prior_ent_min 21.76 / report/prior_ent_std 4.75 / report/rep_loss_mean 1.85 / report/rep_loss_std 3.96 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 6.7e-10 / eval/cont_loss_std 4.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.66 / eval/image_loss_mean 
0.16 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.72 / eval/post_ent_mag 49.49 / eval/post_ent_max 49.49 / eval/post_ent_mean 34.98 / eval/post_ent_min 22.5 / eval/post_ent_std 3.16 / eval/prior_ent_mag 56.68 / eval/prior_ent_max 56.68 / 
eval/prior_ent_mean 36.9 / eval/prior_ent_min 31.49 / eval/prior_ent_std 3.45 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.66 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.7e4 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
301.2 / timer/env.step_count 3832 / timer/env.step_total 19.18 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.63 / timer/replay._sample_frac 1.3
/ timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7840 / timer/agent.policy_total 16.72 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1916 / timer/agent.train_total 245.82 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.44

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T223943F015435-5tqz7GhBxiAqz0VP7sIQov-66ot1jq4PSaqgwThs981Ek-1024.npz
Starting evaluation at step 47500 Counter(47500) 47437
Saved chunk: 20230921T224015F574380-384y7qBc19m4JKZ0nshQMp-3c9MCqpYT2CLpNRfCqdAfj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 48000 Counter(48000) 47937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224103F155391-66ot1jq4PSaqgwThs981Ek-6aXVn6iDRwyt8DqU5RKxMd-1024.npz
Starting evaluation at step 48500 Counter(48500) 48437
Saved chunk: 20230921T224134F553968-3c9MCqpYT2CLpNRfCqdAfj-10pMV1eDIL7yOc1HI0zMmt-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 49000 Counter(49000) 48937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224223F514783-6aXVn6iDRwyt8DqU5RKxMd-7Ej6fuxAhaVTAPiviI3AxD-1024.npz
Starting evaluation at step 49500 Counter(49500) 49437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224253F208148-10pMV1eDIL7yOc1HI0zMmt-7GvGRAP4bMsDQi96VYM7Aq-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 50000 Counter(50000) 49937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224343F567768-7Ej6fuxAhaVTAPiviI3AxD-2ntkPlspcHCaOspI342aBp-1024.npz
Starting evaluation at step 50500 Counter(50500) 50437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224411F610059-7GvGRAP4bMsDQi96VYM7Aq-48RnFpNJyd3S0spKIEfcfJ-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 101714 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.48 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-6 / train/actor_opt_grad_steps 2.4e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 9.6e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std 
3.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.2e-5 / train/extr_critic_critic_opt_grad_steps 2.4e4 / train/extr_critic_critic_opt_loss 6.6e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.3 / train/image_loss_std 0.47 / train/model_loss_mean 1.38 / train/model_loss_std 2.53 / train/model_opt_grad_norm 9.22 / 
train/model_opt_grad_steps 2.4e4 / train/model_opt_loss 5241.89 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 3776.04 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 1.1e-3 / train/policy_logprob_mag 9.43 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.43 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 4.7e-4 / train/post_ent_mag 50.14 / train/post_ent_max 50.14 / train/post_ent_mean 34.4 / train/post_ent_min 18.68 / train/post_ent_std 4.07 / 
train/prior_ent_mag 57.34 / train/prior_ent_max 57.34 / train/prior_ent_mean 36.32 / train/prior_ent_min 24.6 / train/prior_ent_std 4.5 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.7 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 7.2e-10 / report/cont_loss_std 7.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.01 / 
report/dyn_loss_std 4.59 / report/image_loss_mean 0.28 / report/image_loss_std 0.74 / report/model_loss_mean 1.49 / report/model_loss_std 3.36 / report/post_ent_mag 51.03 / report/post_ent_max 51.03 / report/post_ent_mean 34.45 / report/post_ent_min 18.36 / 
report/post_ent_std 3.75 / report/prior_ent_mag 58.35 / report/prior_ent_max 58.35 / report/prior_ent_mean 36.44 / report/prior_ent_min 23.61 / report/prior_ent_std 4.03 / report/rep_loss_mean 2.01 / report/rep_loss_std 4.59 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 7.6e-10 / eval/cont_loss_std 1.5e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.57 / eval/dyn_loss_std 5.18 / eval/image_loss_mean 0.65
/ eval/image_loss_std 2.01 / eval/model_loss_mean 2.19 / eval/model_loss_std 4.81 / eval/post_ent_mag 50.91 / eval/post_ent_max 50.91 / eval/post_ent_mean 34.64 / eval/post_ent_min 16.92 / eval/post_ent_std 4.25 / eval/prior_ent_mag 58.35 / eval/prior_ent_max 58.35 / 
eval/prior_ent_mean 36.72 / eval/prior_ent_min 23.73 / eval/prior_ent_std 4.24 / eval/rep_loss_mean 2.57 / eval/rep_loss_std 5.18 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.1e4 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.1e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.12 / timer/env.step_count 3856 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.11 / timer/replay._sample_frac 
1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7363 / timer/agent.policy_total 15.73 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.08 / timer/dataset_train_count 1928 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / 
timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1928 / timer/agent.train_total 247.16 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.21 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 51000 Counter(51000) 50937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224503F432496-2ntkPlspcHCaOspI342aBp-1KoH1pDybA3f5XqDzT9pne-1024.npz
Starting evaluation at step 51500 Counter(51500) 51437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 52000 Counter(52000) 51937
Saved chunk: 20230921T224529F818072-48RnFpNJyd3S0spKIEfcfJ-6fwjrTZPpTIuDGT3etAIP4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224623F980732-1KoH1pDybA3f5XqDzT9pne-6bgDyIuJXr124lhG5RIG7B-1024.npz
Starting evaluation at step 52500 Counter(52500) 52437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 53000 Counter(53000) 52937
Saved chunk: 20230921T224724F863281-6fwjrTZPpTIuDGT3etAIP4-2YxGgRjHUfqPQVwI07fGs4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224744F098523-6bgDyIuJXr124lhG5RIG7B-0CXUuvy1y2wH8HnbL2rdFg-1024.npz
Starting evaluation at step 53500 Counter(53500) 53437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 54000 Counter(54000) 53937
Saved chunk: 20230921T224843F313758-2YxGgRjHUfqPQVwI07fGs4-6GAsdmYnEOLY5INjauhmjN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T224904F075073-0CXUuvy1y2wH8HnbL2rdFg-0DvCH6Nzbd8GgJ2d2TafnN-1024.npz
Starting evaluation at step 54500 Counter(54500) 54437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 109338 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.47 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.9e-6 / train/actor_opt_grad_steps 2.6e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7.8e-10 / train/cont_loss_std 2.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / train/dyn_loss_std
3.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 7.5e-6 / train/extr_critic_critic_opt_grad_steps 2.6e4 / train/extr_critic_critic_opt_loss 5.5e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.27 / train/image_loss_std 0.42 / train/model_loss_mean 1.34 / train/model_loss_std 2.44 / train/model_opt_grad_norm 8.77 / 
train/model_opt_grad_steps 2.6e4 / train/model_opt_loss 7064.07 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5287.96 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.37 / train/policy_entropy_std 1e-3 / train/policy_logprob_mag 9.55 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.55 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 4.6e-4 / train/post_ent_mag 51.38 / train/post_ent_max 51.38 / train/post_ent_mean 35.14 / train/post_ent_min 19.8 / train/post_ent_std 4.03 / 
train/prior_ent_mag 58.41 / train/prior_ent_max 58.41 / train/prior_ent_mean 36.97 / train/prior_ent_min 25.82 / train/prior_ent_std 4.51 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.6 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 6e-10 / report/cont_loss_std 8.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.78 / 
report/dyn_loss_std 3.59 / report/image_loss_mean 0.26 / report/image_loss_std 0.41 / report/model_loss_mean 1.33 / report/model_loss_std 2.43 / report/post_ent_mag 50.93 / report/post_ent_max 50.93 / report/post_ent_mean 34.54 / report/post_ent_min 17.54 / 
report/post_ent_std 4.76 / report/prior_ent_mag 58.84 / report/prior_ent_max 58.84 / report/prior_ent_mean 36.76 / report/prior_ent_min 19.68 / report/prior_ent_std 4.9 / report/rep_loss_mean 1.78 / report/rep_loss_std 3.59 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 6.8e-10 / eval/cont_loss_std 8.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2 / eval/dyn_loss_std 3.29 / eval/image_loss_mean 0.39 /
eval/image_loss_std 0.51 / eval/model_loss_mean 1.59 / eval/model_loss_std 2.26 / eval/post_ent_mag 50.91 / eval/post_ent_max 50.91 / eval/post_ent_mean 34.9 / eval/post_ent_min 21.83 / eval/post_ent_std 4.6 / eval/prior_ent_mag 58.84 / eval/prior_ent_max 58.84 / 
eval/prior_ent_mean 37 / eval/prior_ent_min 24.2 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 2 / eval/rep_loss_std 3.29 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / 
eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.5e4 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6
/ replay/sample_wait_frac 1 / eval_replay/size 5.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3812 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 388.44 / timer/replay._sample_frac 1.29 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7820 / timer/agent.policy_total 16.46 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.29 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.41

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 55000 Counter(55000) 54937
Saved chunk: 20230921T225001F420454-6GAsdmYnEOLY5INjauhmjN-13BTh4mE3e8LXbqZmdUPRs-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225023F723143-0DvCH6Nzbd8GgJ2d2TafnN-55gSx3dCESqF0JZXCwmkXT-1024.npz
Starting evaluation at step 55500 Counter(55500) 55437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 56000 Counter(56000) 55937
Saved chunk: 20230921T225120F263890-13BTh4mE3e8LXbqZmdUPRs-7pLPVFq4Bz3HClwNqu1A1C-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225144F312564-55gSx3dCESqF0JZXCwmkXT-6mynVZ6lge8fwCvbRFMq31-1024.npz
Starting evaluation at step 56500 Counter(56500) 56437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T225304F451426-6mynVZ6lge8fwCvbRFMq31-0000000000000000000000-580.npz
Saved chunk: 20230921T225238F912042-7pLPVFq4Bz3HClwNqu1A1C-0000000000000000000000-892.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 57000 Counter(57000) 56937
Saved chunk: 20230921T225238F912042-7pLPVFq4Bz3HClwNqu1A1C-3w2L3JFHs5BTgDIV2LL4jC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225304F451426-6mynVZ6lge8fwCvbRFMq31-45kBXutfJbPJUDxma0lnHQ-1024.npz
Starting evaluation at step 57500 Counter(57500) 57437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 58000 Counter(58000) 57937
Saved chunk: 20230921T225357F564867-3w2L3JFHs5BTgDIV2LL4jC-6dhDSE0HN6AApClHBn3gz8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225424F635337-45kBXutfJbPJUDxma0lnHQ-1iRwi7eaTijy2XYQ0WJIi2-1024.npz
Starting evaluation at step 58500 Counter(58500) 58437
eval_Episode has 500 steps and return 0.0.
 Step 117002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.47 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.8e-6 / train/actor_opt_grad_steps 2.8e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 6.1e-10 / train/cont_loss_std 1.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std
3.61 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.5e-6 / train/extr_critic_critic_opt_grad_steps 2.8e4 / train/extr_critic_critic_opt_loss 3.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.27 / train/image_loss_std 0.43 / train/model_loss_mean 1.34 / train/model_loss_std 2.44 / train/model_opt_grad_norm 8.59 / 
train/model_opt_grad_steps 2.8e4 / train/model_opt_loss 6891.68 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5156.25 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.37 / train/policy_entropy_std 1e-3 / train/policy_logprob_mag 9.41 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.41 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 4.4e-4 / train/post_ent_mag 52.19 / train/post_ent_max 52.19 / train/post_ent_mean 35.52 / train/post_ent_min 19.7 / train/post_ent_std 4.11 / 
train/prior_ent_mag 59.3 / train/prior_ent_max 59.3 / train/prior_ent_mean 37.37 / train/prior_ent_min 25.56 / train/prior_ent_std 4.6 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.61 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 5.6e-10 / report/cont_loss_std 9.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.6e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / 
report/dyn_loss_std 2.96 / report/image_loss_mean 0.27 / report/image_loss_std 0.36 / report/model_loss_mean 1.27 / report/model_loss_std 1.98 / report/post_ent_mag 53.63 / report/post_ent_max 53.63 / report/post_ent_mean 35.09 / report/post_ent_min 17.34 / 
report/post_ent_std 4.74 / report/prior_ent_mag 59.8 / report/prior_ent_max 59.8 / report/prior_ent_mean 36.92 / report/prior_ent_min 19.54 / report/prior_ent_std 4.87 / report/rep_loss_mean 1.66 / report/rep_loss_std 2.96 / report/reward_avg 0 / report/reward_loss_mean 0
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 4.2e-10 / eval/cont_loss_std 8.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.68 / eval/dyn_loss_std 2.95 / eval/image_loss_mean 
0.19 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.2 / eval/model_loss_std 1.93 / eval/post_ent_mag 53.58 / eval/post_ent_max 53.58 / eval/post_ent_mean 36.02 / eval/post_ent_min 24.58 / eval/post_ent_std 3.95 / eval/prior_ent_mag 59.8 / eval/prior_ent_max 59.8 / 
eval/prior_ent_mean 37.75 / eval/prior_ent_min 31.32 / eval/prior_ent_std 4.46 / eval/rep_loss_mean 1.68 / eval/rep_loss_std 2.95 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.8e4 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.9e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
301.89 / timer/env.step_count 3832 / timer/env.step_total 19.08 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.9 / timer/replay._sample_frac 
1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 9.2e-4 / timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.3e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7840 / timer/agent.policy_total 16.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1916 / timer/agent.train_total 245.81 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 59000 Counter(59000) 58937
Saved chunk: 20230921T225515F793582-6dhDSE0HN6AApClHBn3gz8-407UYbYv6Vz0tVgOx7Kfn6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225544F366247-1iRwi7eaTijy2XYQ0WJIi2-7k2jXVPyu4RKVAWQAxwcYn-1024.npz
Starting evaluation at step 59500 Counter(59500) 59437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 60000 Counter(60000) 59937
Saved chunk: 20230921T225634F972532-407UYbYv6Vz0tVgOx7Kfn6-2bMyRyW6bLuX2cbYuhQfmB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225705F314299-7k2jXVPyu4RKVAWQAxwcYn-6gvtbtz2ohAGT3ynJQc5DH-1024.npz
Starting evaluation at step 60500 Counter(60500) 60437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 61000 Counter(61000) 60937
Saved chunk: 20230921T225753F566185-2bMyRyW6bLuX2cbYuhQfmB-5dSJXJhUrgHQa8temb4t4j-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T225825F346798-6gvtbtz2ohAGT3ynJQc5DH-2XpanRCtelsZ9beZAL5VmK-1024.npz
Starting evaluation at step 61500 Counter(61500) 61437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 62000 Counter(62000) 61937
Saved chunk: 20230921T225912F516313-5dSJXJhUrgHQa8temb4t4j-2lHT4hlkU7R6NVFFOBcSuQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 124702 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.63 / train/action_mean 0.45 / train/action_min -3.93 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.7e-6 / train/actor_opt_grad_steps 3e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 5.1e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std 
3.56 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.1e-6 / train/extr_critic_critic_opt_grad_steps 3e4 / train/extr_critic_critic_opt_loss 4e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.26 / train/image_loss_std 0.4 / train/model_loss_mean 1.32 / train/model_loss_std 2.4 / train/model_opt_grad_norm 8.67 / 
train/model_opt_grad_steps 3e4 / train/model_opt_loss 7334.46 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5546.88 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 9.6e-4 / train/policy_logprob_mag 9.47 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.47 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 4.2e-4 / train/post_ent_mag 53.16 / train/post_ent_max 53.16 / train/post_ent_mean 36.02 / train/post_ent_min 21.01 / train/post_ent_std 3.98 / 
train/prior_ent_mag 60.35 / train/prior_ent_max 60.35 / train/prior_ent_mean 37.85 / train/prior_ent_min 27.42 / train/prior_ent_std 4.55 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.56 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 4.5e-10 / report/cont_loss_std 7.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.78 / 
report/dyn_loss_std 3.4 / report/image_loss_mean 0.25 / report/image_loss_std 0.4 / report/model_loss_mean 1.32 / report/model_loss_std 2.25 / report/post_ent_mag 53.36 / report/post_ent_max 53.36 / report/post_ent_mean 36.23 / report/post_ent_min 20.91 / 
report/post_ent_std 4.13 / report/prior_ent_mag 60.72 / report/prior_ent_max 60.72 / report/prior_ent_mean 38.13 / report/prior_ent_min 25.69 / report/prior_ent_std 4.54 / report/rep_loss_mean 1.78 / report/rep_loss_std 3.4 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.2e-10 / eval/cont_loss_std 3.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 2.9 / eval/image_loss_mean 0.17
/ eval/image_loss_std 0.34 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.95 / eval/post_ent_mag 53.43 / eval/post_ent_max 53.43 / eval/post_ent_mean 37.02 / eval/post_ent_min 24.8 / eval/post_ent_std 3.71 / eval/prior_ent_mag 60.72 / eval/prior_ent_max 60.72 / 
eval/prior_ent_mean 38.73 / eval/prior_ent_min 33.25 / eval/prior_ent_std 4.04 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 2.9 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 6.2e4 / replay/inserts 3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300
/ timer/env.step_count 3850 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.48 / timer/replay._sample_frac 1.3 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.1 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7357 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.63 / timer/dataset_train_count 1925 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1925 / timer/agent.train_total 246.58 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T225945F743086-2XpanRCtelsZ9beZAL5VmK-1pKW9x4DtTOTAimWlXk7ne-1024.npz
Starting evaluation at step 62500 Counter(62500) 62437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 63000 Counter(63000) 62937
Saved chunk: 20230921T230030F529375-2lHT4hlkU7R6NVFFOBcSuQ-534dkS07Tli3E0OUqWa3HJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230106F035697-1pKW9x4DtTOTAimWlXk7ne-69df9D0s7x7z15HdLQEwAp-1024.npz
Starting evaluation at step 63500 Counter(63500) 63437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 64000 Counter(64000) 63937
Saved chunk: 20230921T230149F679466-534dkS07Tli3E0OUqWa3HJ-7rf9PlcFEcOr8uRkHKfZYp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 64500 Counter(64500) 64437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230226F242525-69df9D0s7x7z15HdLQEwAp-3UIIs7pV9WcRbPRVU83Nlm-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 65000 Counter(65000) 64937
Saved chunk: 20230921T230308F141916-7rf9PlcFEcOr8uRkHKfZYp-7CS0IMmcSsl6yZyW2wb6hp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 65500 Counter(65500) 65437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230349F557092-3UIIs7pV9WcRbPRVU83Nlm-1ErgyiCjvQTYaVDx7Nn94p-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 66000 Counter(66000) 65937
Saved chunk: 20230921T230426F382363-7CS0IMmcSsl6yZyW2wb6hp-5F0KMNGVkr544qmPL0mFEy-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 132330 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.44 / train/action_min -4 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.6e-6 / train/actor_opt_grad_steps 3.2e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.4e-10 / train/cont_loss_std 9.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.7e-5 / train/extr_critic_critic_opt_grad_steps 3.2e4 / train/extr_critic_critic_opt_loss 
3.2e-3 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.26 / train/image_loss_std 0.44 / train/model_loss_mean 1.33 / train/model_loss_std 2.46 / train/model_opt_grad_norm 8.49 / 
train/model_opt_grad_steps 3.2e4 / train/model_opt_loss 7127.7 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5340.31 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 9.5e-4 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 4.1e-4 / train/post_ent_mag 54.04 / train/post_ent_max 54.04 / train/post_ent_mean 36.39 / train/post_ent_min 21.06 / train/post_ent_std 4.15 / 
train/prior_ent_mag 61.5 / train/prior_ent_max 61.5 / train/prior_ent_mean 38.23 / train/prior_ent_min 26.69 / train/prior_ent_std 4.73 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.63 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 3.5e-10 / report/cont_loss_std 4.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / 
report/dyn_loss_std 3.91 / report/image_loss_mean 0.28 / report/image_loss_std 0.4 / report/model_loss_mean 1.34 / report/model_loss_std 2.62 / report/post_ent_mag 55.02 / report/post_ent_max 55.02 / report/post_ent_mean 35.71 / report/post_ent_min 18.31 / 
report/post_ent_std 5.46 / report/prior_ent_mag 61.77 / report/prior_ent_max 61.77 / report/prior_ent_mean 37.55 / report/prior_ent_min 19.93 / report/prior_ent_std 5.91 / report/rep_loss_mean 1.77 / report/rep_loss_std 3.91 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.7e-10 / eval/cont_loss_std 4.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.78 / eval/dyn_loss_std 3.35 / eval/image_loss_mean 
0.26 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.32 / eval/model_loss_std 2.18 / eval/post_ent_mag 54.87 / eval/post_ent_max 54.87 / eval/post_ent_mean 36.85 / eval/post_ent_min 24.17 / eval/post_ent_std 3.64 / eval/prior_ent_mag 61.77 / eval/prior_ent_max 61.77 /
eval/prior_ent_mean 38.79 / eval/prior_ent_min 33.06 / eval/prior_ent_std 4.35 / eval/rep_loss_mean 1.78 / eval/rep_loss_std 3.35 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 6.6e4 / replay/inserts 3814 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.06 / timer/env.step_count 3814 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.7 / timer/replay._sample_frac 
1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7822 / timer/agent.policy_total 16.5 / timer/agent.policy_frac
0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1907 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1907 / timer/agent.train_total 244.18 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 66500 Counter(66500) 66437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230509F193586-1ErgyiCjvQTYaVDx7Nn94p-284vAs0Iz1j9dclq1HXjsi-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 67000 Counter(67000) 66937
Saved chunk: 20230921T230544F426341-5F0KMNGVkr544qmPL0mFEy-3CIyzBJgvoWghOodCkGBxk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 67500 Counter(67500) 67437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230629F714600-284vAs0Iz1j9dclq1HXjsi-6V2P3rg4Mo57pRt2XCLGgi-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 68000 Counter(68000) 67937
Saved chunk: 20230921T230703F610186-3CIyzBJgvoWghOodCkGBxk-1CmaVr1936cGgRCbsUgIcx-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T230822F107423-1CmaVr1936cGgRCbsUgIcx-0000000000000000000000-127.npz
Saved chunk: 20230921T230749F915845-6V2P3rg4Mo57pRt2XCLGgi-0000000000000000000000-816.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 68500 Counter(68500) 68437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230749F915845-6V2P3rg4Mo57pRt2XCLGgi-6Mq0BDl2GCZ0S1J27SeAkF-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 69000 Counter(69000) 68937
Saved chunk: 20230921T230822F107423-1CmaVr1936cGgRCbsUgIcx-76NUCMPLYqTGbMy8mWRSmQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 69500 Counter(69500) 69437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T230910F059158-6Mq0BDl2GCZ0S1J27SeAkF-2Op8wz5yWz3hgrj0GAwPjB-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 70000 Counter(70000) 69937
Saved chunk: 20230921T230940F599502-76NUCMPLYqTGbMy8mWRSmQ-20dO51YVmhjX3GdJT47u7Y-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 140002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.63 / train/action_max 4.61 / train/action_mean 0.42 / train/action_min -4 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.5e-6 / train/actor_opt_grad_steps 3.3e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std 3.69
/ train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.3e-6 / train/extr_critic_critic_opt_grad_steps 3.3e4 / train/extr_critic_critic_opt_loss 2.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.26 / train/image_loss_std 0.43 / train/model_loss_mean 1.33 / train/model_loss_std 2.49 / train/model_opt_grad_norm 8.19 / 
train/model_opt_grad_steps 3.3e4 / train/model_opt_loss 8740.57 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6562.5 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 9.1e-4 / train/policy_logprob_mag 9.42 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.42 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 3.9e-4 / train/post_ent_mag 55.29 / train/post_ent_max 55.29 / train/post_ent_mean 36.95 / train/post_ent_min 21.38 / train/post_ent_std 4.2 / 
train/prior_ent_mag 62.45 / train/prior_ent_max 62.45 / train/prior_ent_mean 38.78 / train/prior_ent_min 27.49 / train/prior_ent_std 4.78 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.69 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 2.8e-10 / report/cont_loss_std 9.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.83 / 
report/dyn_loss_std 3.7 / report/image_loss_mean 0.23 / report/image_loss_std 0.46 / report/model_loss_mean 1.32 / report/model_loss_std 2.53 / report/post_ent_mag 55.82 / report/post_ent_max 55.82 / report/post_ent_mean 37.17 / report/post_ent_min 20.07 / 
report/post_ent_std 4.04 / report/prior_ent_mag 62.59 / report/prior_ent_max 62.59 / report/prior_ent_mean 39.04 / report/prior_ent_min 26.9 / report/prior_ent_std 4.43 / report/rep_loss_mean 1.83 / report/rep_loss_std 3.7 / report/reward_avg 0 / report/reward_loss_mean 0
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.6e-10 / eval/cont_loss_std 5.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.2 / eval/dyn_loss_std 7.06 / eval/image_loss_mean 1.01
/ eval/image_loss_std 3.52 / eval/model_loss_mean 2.93 / eval/model_loss_std 7.29 / eval/post_ent_mag 55.54 / eval/post_ent_max 55.54 / eval/post_ent_mean 37.21 / eval/post_ent_min 19.54 / eval/post_ent_std 4.68 / eval/prior_ent_mag 62.59 / eval/prior_ent_max 62.59 / 
eval/prior_ent_mean 39.26 / eval/prior_ent_min 24.47 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 3.2 / eval/rep_loss_std 7.06 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 7e4 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
302.04 / timer/env.step_count 3836 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 3.8e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.48 / timer/replay._sample_frac 
1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 
0.11 / timer/agent.policy_count 7844 / timer/agent.policy_total 16.84 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1918 / timer/agent.train_total 245.75 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.4

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 70500 Counter(70500) 70437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231029F653924-2Op8wz5yWz3hgrj0GAwPjB-6sUDrq6mb6zuqMdiROXBru-1024.npz
Starting evaluation at step 71000 Counter(71000) 70937
Saved chunk: 20230921T231058F752867-20dO51YVmhjX3GdJT47u7Y-2zBxQlozuRCeMiJ1zU2PD4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 71500 Counter(71500) 71437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231150F442981-6sUDrq6mb6zuqMdiROXBru-2bApPQvfdsgtdivbHl40gM-1024.npz
Starting evaluation at step 72000 Counter(72000) 71937
Saved chunk: 20230921T231218F002014-2zBxQlozuRCeMiJ1zU2PD4-6J5NRQs64xHobf4BVQiWxd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 72500 Counter(72500) 72437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231310F511330-2bApPQvfdsgtdivbHl40gM-3HpTOJeChYsSRCW3FwxfAh-1024.npz
Starting evaluation at step 73000 Counter(73000) 72937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231336F428145-6J5NRQs64xHobf4BVQiWxd-4jVXuIM00byosmCyto91Aa-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 73500 Counter(73500) 73437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231430F241794-3HpTOJeChYsSRCW3FwxfAh-3lsFTS0pJehmwvBcNrAKFn-1024.npz
 Step 147726 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.42 / train/action_min -4.04 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.5e-6 / train/actor_opt_grad_steps 3.5e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.5e-10 / train/cont_loss_std 1.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std
3.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.2e-6 / train/extr_critic_critic_opt_grad_steps 3.5e4 / train/extr_critic_critic_opt_loss 2.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.25 / train/image_loss_std 0.42 / train/model_loss_mean 1.32 / train/model_loss_std 2.45 / train/model_opt_grad_norm 8.09 / 
train/model_opt_grad_steps 3.5e4 / train/model_opt_loss 7670.16 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5803.11 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 9e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 3.9e-4 / train/post_ent_mag 56.15 / train/post_ent_max 56.15 / train/post_ent_mean 37.33 / train/post_ent_min 21.9 / train/post_ent_std 4.23 / 
train/prior_ent_mag 63.3 / train/prior_ent_max 63.3 / train/prior_ent_mean 39.13 / train/prior_ent_min 27.79 / train/prior_ent_std 4.86 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.64 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 3.5e-10 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / 
report/dyn_loss_std 2.65 / report/image_loss_mean 0.23 / report/image_loss_std 0.28 / report/model_loss_mean 1.23 / report/model_loss_std 1.73 / report/post_ent_mag 56.46 / report/post_ent_max 56.46 / report/post_ent_mean 38.24 / report/post_ent_min 21.6 / 
report/post_ent_std 4.22 / report/prior_ent_mag 64.13 / report/prior_ent_max 64.13 / report/prior_ent_mean 39.92 / report/prior_ent_min 30.63 / report/prior_ent_std 4.6 / report/rep_loss_mean 1.67 / report/rep_loss_std 2.65 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.3e-10 / eval/cont_loss_std 6.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.44 / eval/dyn_loss_std 4.85 / eval/image_loss_mean 
0.43 / eval/image_loss_std 0.83 / eval/model_loss_mean 1.9 / eval/model_loss_std 3.52 / eval/post_ent_mag 56.36 / eval/post_ent_max 56.36 / eval/post_ent_mean 37.06 / eval/post_ent_min 18.06 / eval/post_ent_std 5.65 / eval/prior_ent_mag 64.13 / eval/prior_ent_max 64.13 / 
eval/prior_ent_mean 39.25 / eval/prior_ent_min 22.33 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 2.44 / eval/rep_loss_std 4.85 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 7.4e4 / replay/inserts 3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.4e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300
/ timer/env.step_count 3862 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 3.9e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.21 / timer/replay._sample_frac 1.31 
/ timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7369 / timer/agent.policy_total 15.64 / timer/agent.policy_frac 0.05
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1931 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.7e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1931 / timer/agent.train_total 247.24 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.75

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 74000 Counter(74000) 73937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 74500 Counter(74500) 74437
Saved chunk: 20230921T231454F525365-4jVXuIM00byosmCyto91Aa-0H5fEHn02ohhY8DyyGZxVB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231549F808853-3lsFTS0pJehmwvBcNrAKFn-4wUPFZDPqESQ96dvrewfPw-1024.npz
Starting evaluation at step 75000 Counter(75000) 74937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 75500 Counter(75500) 75437
Saved chunk: 20230921T231649F200671-0H5fEHn02ohhY8DyyGZxVB-4zIjmlx1EJ1O4xEqy9lFf4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231710F543122-4wUPFZDPqESQ96dvrewfPw-6nnYbq2FJwEawKlPk7FQRm-1024.npz
Starting evaluation at step 76000 Counter(76000) 75937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 76500 Counter(76500) 76437
Saved chunk: 20230921T231807F578789-4zIjmlx1EJ1O4xEqy9lFf4-7ps3KSUaitWiIzaQPlmEis-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T231830F446710-6nnYbq2FJwEawKlPk7FQRm-6vjBAem5BckRdYezEX7k2F-1024.npz
Starting evaluation at step 77000 Counter(77000) 76937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 77500 Counter(77500) 77437
Saved chunk: 20230921T231925F790196-7ps3KSUaitWiIzaQPlmEis-0amLZ4WwFMKxefcim6Cz1n-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 155358 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.63 / train/action_mean 0.41 / train/action_min -4.06 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.4e-6 / train/actor_opt_grad_steps 3.7e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.1e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std 
3.69 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3e-6 / train/extr_critic_critic_opt_grad_steps 3.7e4 / train/extr_critic_critic_opt_loss 4.7e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.26 / train/image_loss_std 0.44 / train/model_loss_mean 1.33 / train/model_loss_std 2.49 / train/model_opt_grad_norm 8.06 / 
train/model_opt_grad_steps 3.7e4 / train/model_opt_loss 7796.35 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5837.7 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 9e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 3.9e-4 / train/post_ent_mag 57.42 / train/post_ent_max 57.42 / train/post_ent_mean 37.75 / train/post_ent_min 22.28 / train/post_ent_std 4.23 / 
train/prior_ent_mag 64.41 / train/prior_ent_max 64.41 / train/prior_ent_mean 39.53 / train/prior_ent_min 28.47 / train/prior_ent_std 4.89 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.69 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 2.8e-10 / report/cont_loss_std 4.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / 
report/dyn_loss_std 3.42 / report/image_loss_mean 0.21 / report/image_loss_std 0.43 / report/model_loss_mean 1.27 / report/model_loss_std 2.34 / report/post_ent_mag 58.14 / report/post_ent_max 58.14 / report/post_ent_mean 38.45 / report/post_ent_min 24.63 / 
report/post_ent_std 3.81 / report/prior_ent_mag 64.58 / report/prior_ent_max 64.58 / report/prior_ent_mean 40 / report/prior_ent_min 31.74 / report/prior_ent_std 4.46 / report/rep_loss_mean 1.75 / report/rep_loss_std 3.42 / report/reward_avg 0 / report/reward_loss_mean 0 
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 3.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.19 / eval/dyn_loss_std 4.81 / eval/image_loss_mean 
0.55 / eval/image_loss_std 1.87 / eval/model_loss_mean 1.87 / eval/model_loss_std 4.03 / eval/post_ent_mag 58.14 / eval/post_ent_max 58.14 / eval/post_ent_mean 36.94 / eval/post_ent_min 17.81 / eval/post_ent_std 4.67 / eval/prior_ent_mag 64.58 / eval/prior_ent_max 64.58 /
eval/prior_ent_mean 38.58 / eval/prior_ent_min 18.81 / eval/prior_ent_std 5.61 / eval/rep_loss_mean 2.19 / eval/rep_loss_std 4.81 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 7.8e4 / replay/inserts 3816 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.04 / timer/env.step_count 3816 / timer/env.step_total 18.82 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.81 / 
timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7824 / timer/agent.policy_total 16.55 
/ timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.08 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / 
timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1908 / timer/agent.train_total 244.28 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / 
timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.44

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T231950F173450-6vjBAem5BckRdYezEX7k2F-27z5pweTPhe3MAupzUOWsZ-1024.npz
Starting evaluation at step 78000 Counter(78000) 77937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 78500 Counter(78500) 78437
Saved chunk: 20230921T232043F840191-0amLZ4WwFMKxefcim6Cz1n-6BIptOlQQrhdVXsezPyLKl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232110F499679-27z5pweTPhe3MAupzUOWsZ-25mYQbmBdCJZMKCLz1i8Cd-1024.npz
Starting evaluation at step 79000 Counter(79000) 78937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 79500 Counter(79500) 79437
Saved chunk: 20230921T232203F025250-6BIptOlQQrhdVXsezPyLKl-1IYzXOinv04KaaKovzqdHG-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232230F670373-25mYQbmBdCJZMKCLz1i8Cd-6KOCDlTJOQk8cTu7aSKR2f-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T232321F382448-1IYzXOinv04KaaKovzqdHG-0000000000000000000000-386.npz
Saved chunk: 20230921T232350F536930-6KOCDlTJOQk8cTu7aSKR2f-0000000000000000000000-28.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 80000 Counter(80000) 79937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 80500 Counter(80500) 80437
Saved chunk: 20230921T232321F382448-1IYzXOinv04KaaKovzqdHG-38LY9iVhUJkiQowaB4c1S5-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232350F536930-6KOCDlTJOQk8cTu7aSKR2f-4pwTctVTWlZRo8hjbYbgAL-1024.npz
Starting evaluation at step 81000 Counter(81000) 80937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 81500 Counter(81500) 81437
Saved chunk: 20230921T232439F861017-38LY9iVhUJkiQowaB4c1S5-20CHIdkwcJFkl261yKYdDt-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 163002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.63 / train/action_max 4.61 / train/action_mean 0.42 / train/action_min -4 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.3e-6 / train/actor_opt_grad_steps 3.9e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.8e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std 
3.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.7e-6 / train/extr_critic_critic_opt_grad_steps 3.9e4 / train/extr_critic_critic_opt_loss 5.6e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.24 / train/image_loss_std 0.41 / train/model_loss_mean 1.32 / train/model_loss_std 2.51 / train/model_opt_grad_norm 7.9 / 
train/model_opt_grad_steps 3.9e4 / train/model_opt_loss 8123.81 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6151.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 8.1e-4 / train/policy_logprob_mag 9.53 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.53 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 3.5e-4 / train/post_ent_mag 58.24 / train/post_ent_max 58.24 / train/post_ent_mean 38.04 / train/post_ent_min 21.98 / train/post_ent_std 4.23 / 
train/prior_ent_mag 65.09 / train/prior_ent_max 65.09 / train/prior_ent_mean 39.79 / train/prior_ent_min 28.45 / train/prior_ent_std 4.91 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.74 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 2.8e-10 / report/cont_loss_std 1.7e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.73 / 
report/dyn_loss_std 3.46 / report/image_loss_mean 0.21 / report/image_loss_std 0.39 / report/model_loss_mean 1.25 / report/model_loss_std 2.37 / report/post_ent_mag 58.96 / report/post_ent_max 58.96 / report/post_ent_mean 38.69 / report/post_ent_min 24.67 / 
report/post_ent_std 4.18 / report/prior_ent_mag 65.53 / report/prior_ent_max 65.53 / report/prior_ent_mean 40.22 / report/prior_ent_min 31.26 / report/prior_ent_std 4.7 / report/rep_loss_mean 1.73 / report/rep_loss_std 3.46 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.7e-10 / eval/cont_loss_std 4.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.27 / eval/image_loss_mean 
0.17 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.21 / eval/model_loss_std 2.17 / eval/post_ent_mag 58.92 / eval/post_ent_max 58.92 / eval/post_ent_mean 38.24 / eval/post_ent_min 28.03 / eval/post_ent_std 3.8 / eval/prior_ent_mag 65.53 / eval/prior_ent_max 65.53 / 
eval/prior_ent_mean 39.8 / eval/prior_ent_min 33.21 / eval/prior_ent_std 4.62 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.27 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 8.1e4 / replay/inserts 3822 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.2e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.99 / timer/env.step_count 3822 / timer/env.step_total 18.84 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 7.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.51 / 
timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 /
timer/agent.save_max 0.11 / timer/agent.policy_count 7830 / timer/agent.policy_total 16.63 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1911 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1911 / timer/agent.train_total 245.11 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.39

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232510F593814-4pwTctVTWlZRo8hjbYbgAL-23NUlzQ34WdEyb3qMPYEMu-1024.npz
Starting evaluation at step 82000 Counter(82000) 81937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 82500 Counter(82500) 82437
Saved chunk: 20230921T232558F102613-20CHIdkwcJFkl261yKYdDt-3RgE5R5FYESmPXn2TMrd10-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232631F193841-23NUlzQ34WdEyb3qMPYEMu-7HzKgDoWA4JU1pAMuyL8hS-1024.npz
Starting evaluation at step 83000 Counter(83000) 82937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 83500 Counter(83500) 83437
Saved chunk: 20230921T232717F374898-3RgE5R5FYESmPXn2TMrd10-0vkZoqrtaOf4phIoXnrSlN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232751F345775-7HzKgDoWA4JU1pAMuyL8hS-4A3w2smMBDybgLHppXpnDQ-1024.npz
Starting evaluation at step 84000 Counter(84000) 83937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 84500 Counter(84500) 84437
Saved chunk: 20230921T232835F780438-0vkZoqrtaOf4phIoXnrSlN-0BFzufGOvXxkEg8zt1xK0D-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T232911F189979-4A3w2smMBDybgLHppXpnDQ-0EARS6EA28ksZOSydw6uS4-1024.npz
Starting evaluation at step 85000 Counter(85000) 84937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 170726 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.64 / train/action_mean 0.41 / train/action_min -4 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.2e-6 / train/actor_opt_grad_steps 4.1e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.3e-10 / train/cont_loss_std 9.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 8.2e-6 / train/extr_critic_critic_opt_grad_steps 4.1e4 / train/extr_critic_critic_opt_loss 
1e-3 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.24 / train/image_loss_std 0.4 / train/model_loss_mean 1.31 / train/model_loss_std 2.47 / train/model_opt_grad_norm 7.68 / 
train/model_opt_grad_steps 4.1e4 / train/model_opt_loss 8811.62 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6735.75 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.38 / train/policy_entropy_std 7.8e-4 / train/policy_logprob_mag 9.46 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.46 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 3.4e-4 / train/post_ent_mag 58.87 / train/post_ent_max 58.87 / train/post_ent_mean 38.41 / train/post_ent_min 22.68 / train/post_ent_std 4.18 / 
train/prior_ent_mag 65.56 / train/prior_ent_max 65.56 / train/prior_ent_mean 40.15 / train/prior_ent_min 28.95 / train/prior_ent_std 4.87 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.68 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 3e-10 / report/cont_loss_std 1.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / 
report/dyn_loss_std 4.36 / report/image_loss_mean 0.27 / report/image_loss_std 0.44 / report/model_loss_mean 1.37 / report/model_loss_std 2.94 / report/post_ent_mag 58.12 / report/post_ent_max 58.12 / report/post_ent_mean 38.53 / report/post_ent_min 18.99 / 
report/post_ent_std 4.68 / report/prior_ent_mag 65.52 / report/prior_ent_max 65.52 / report/prior_ent_mean 40.23 / report/prior_ent_min 28.75 / report/prior_ent_std 5.04 / report/rep_loss_mean 1.84 / report/rep_loss_std 4.36 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.76 / eval/dyn_loss_std 3.27 / eval/image_loss_mean 0.19 
/ eval/image_loss_std 0.24 / eval/model_loss_mean 1.25 / eval/model_loss_std 2.12 / eval/post_ent_mag 58.34 / eval/post_ent_max 58.34 / eval/post_ent_mean 38.76 / eval/post_ent_min 25.16 / eval/post_ent_std 3.73 / eval/prior_ent_mag 65.52 / eval/prior_ent_max 65.52 / 
eval/prior_ent_mean 40.35 / eval/prior_ent_min 32.96 / eval/prior_ent_std 4.47 / eval/rep_loss_mean 1.76 / eval/rep_loss_std 3.27 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 8.5e4 / replay/inserts 3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.6e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.02 / timer/env.step_count 3862 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.17 / 
timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.7e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7369 / timer/agent.policy_total 
15.65 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1931 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / 
timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1931 / timer/agent.train_total 247.4 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 /
timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / 
timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.74

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 85500 Counter(85500) 85437
Saved chunk: 20230921T232953F892410-0BFzufGOvXxkEg8zt1xK0D-3ZkKsli1a6gxiI23U6kXob-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 86000 Counter(86000) 85937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233030F754771-0EARS6EA28ksZOSydw6uS4-3Qf2vrvt76tgmgNysCPqFb-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 86500 Counter(86500) 86437
Saved chunk: 20230921T233112F655936-3ZkKsli1a6gxiI23U6kXob-4bBwzSeZqCF0DwGtkBoVMc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 87000 Counter(87000) 86937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233154F801313-3Qf2vrvt76tgmgNysCPqFb-5hPZApbmMd1hl2TyCXppHu-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 87500 Counter(87500) 87437
Saved chunk: 20230921T233231F271448-4bBwzSeZqCF0DwGtkBoVMc-6JFLNbGnHMwgIvRFEDyf63-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 88000 Counter(88000) 87937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233314F824569-5hPZApbmMd1hl2TyCXppHu-0EdOgeM3bZmMXjtLLAWAkP-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 88500 Counter(88500) 88437
Saved chunk: 20230921T233349F606829-6JFLNbGnHMwgIvRFEDyf63-4rCFALK1GRR7N5PQyFQjEe-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 89000 Counter(89000) 88937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233434F570223-0EdOgeM3bZmMXjtLLAWAkP-6fqSvGizZWn1jjHclofYf2-1024.npz
 Step 178350 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.61 / train/action_max 4.59 / train/action_mean 0.39 / train/action_min -4.05 / train/action_std 1.1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.2e-6 / train/actor_opt_grad_steps 4.3e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.1e-10 / train/cont_loss_std 8.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std
3.79 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.7e-6 / train/extr_critic_critic_opt_grad_steps 4.3e4 / train/extr_critic_critic_opt_loss 5.4e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.24 / train/image_loss_std 0.4 / train/model_loss_mean 1.32 / train/model_loss_std 2.53 / train/model_opt_grad_norm 7.88 / 
train/model_opt_grad_steps 4.3e4 / train/model_opt_loss 7512.49 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5710.53 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 7.4e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 3.2e-4 / train/post_ent_mag 59.39 / train/post_ent_max 59.39 / train/post_ent_mean 38.62 / train/post_ent_min 22.46 / train/post_ent_std 4.17 / 
train/prior_ent_mag 66.11 / train/prior_ent_max 66.11 / train/prior_ent_mean 40.35 / train/prior_ent_min 28.61 / train/prior_ent_std 4.88 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.79 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / 
report/dyn_loss_std 3.89 / report/image_loss_mean 0.3 / report/image_loss_std 0.77 / report/model_loss_mean 1.37 / report/model_loss_std 2.9 / report/post_ent_mag 59.3 / report/post_ent_max 59.3 / report/post_ent_mean 38.17 / report/post_ent_min 18.79 / 
report/post_ent_std 4.67 / report/prior_ent_mag 66.32 / report/prior_ent_max 66.32 / report/prior_ent_mean 40.04 / report/prior_ent_min 21.45 / report/prior_ent_std 5.24 / report/rep_loss_mean 1.79 / report/rep_loss_std 3.89 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 3.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.85 / eval/dyn_loss_std 3.93 / eval/image_loss_mean 
0.22 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.33 / eval/model_loss_std 2.6 / eval/post_ent_mag 59.21 / eval/post_ent_max 59.21 / eval/post_ent_mean 38.61 / eval/post_ent_min 23.71 / eval/post_ent_std 3.9 / eval/prior_ent_mag 66.32 / eval/prior_ent_max 66.32 / 
eval/prior_ent_mean 40.37 / eval/prior_ent_min 33.25 / eval/prior_ent_std 4.76 / eval/rep_loss_mean 1.85 / eval/rep_loss_std 3.93 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 8.9e4 / replay/inserts 3812 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
299.99 / timer/env.step_count 3812 / timer/env.step_total 18.78 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.49 / timer/replay._sample_frac 
1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7820 / timer/agent.policy_total 16.65 / timer/agent.policy_frac
0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.09 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.27 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.41

train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 89500 Counter(89500) 89437
Saved chunk: 20230921T233507F730918-4rCFALK1GRR7N5PQyFQjEe-0Y2kFdfuyOjVU1HxeaSZuk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 90000 Counter(90000) 89937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233554F305009-6fqSvGizZWn1jjHclofYf2-20pBeMeezZLnrpJyYRIk5j-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 90500 Counter(90500) 90437
Saved chunk: 20230921T233626F740083-0Y2kFdfuyOjVU1HxeaSZuk-7IoeNrgPidOaeKt8ZvMJCg-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 91000 Counter(91000) 90937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233715F178285-20pBeMeezZLnrpJyYRIk5j-5hsQ9UCApj2erSv8ZRe70I-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T233835F255225-5hsQ9UCApj2erSv8ZRe70I-0000000000000000000000-264.npz
Saved chunk: 20230921T233745F364557-7IoeNrgPidOaeKt8ZvMJCg-0000000000000000000000-645.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 91500 Counter(91500) 91437
Saved chunk: 20230921T233745F364557-7IoeNrgPidOaeKt8ZvMJCg-0u490bAhoOZOFMf7Acny4T-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 92000 Counter(92000) 91937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233835F255225-5hsQ9UCApj2erSv8ZRe70I-4gbGFHGwHkd4Ni5juXW4Gk-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 92500 Counter(92500) 92437
Saved chunk: 20230921T233904F015210-0u490bAhoOZOFMf7Acny4T-26EtB0bOzhE16ZAoXgGEgj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 93000 Counter(93000) 92937
eval_Episode has 500 steps and return 0.0.
 Step 186002 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train_stats/mean_log_entropy 1.42 / train/action_mag 4.63 / train/action_max 4.61 / train/action_mean 0.39 / train/action_min -4 / 
train/action_std 1.09 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.1e-6 / train/actor_opt_grad_steps 4.5e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / 
train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-10 / train/cont_loss_std 6.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-10 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.77 / train/dyn_loss_std 3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.2e-6 / train/extr_critic_critic_opt_grad_steps 4.5e4 / 
train/extr_critic_critic_opt_loss 4.8e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / 
train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / 
train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.23 / train/image_loss_std 0.38 / train/model_loss_mean 1.29 / train/model_loss_std 
2.44 / train/model_opt_grad_norm 7.51 / train/model_opt_grad_steps 4.5e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 9088.54 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.39 / train/policy_entropy_std 7e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 3e-4 / train/post_ent_mag 60.1 / train/post_ent_max 60.1 / train/post_ent_mean 38.66 / train/post_ent_min 23.25 
/ train/post_ent_std 4.3 / train/prior_ent_mag 66.49 / train/prior_ent_max 66.49 / train/prior_ent_mean 40.36 / train/prior_ent_min 29.74 / train/prior_ent_std 5.01 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.65 / train/reward_avg 0 / train/reward_loss_mean 0 / 
train/reward_loss_std 0 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 5.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / 
report/dyn_loss_std 3.29 / report/image_loss_mean 0.22 / report/image_loss_std 0.27 / report/model_loss_mean 1.2 / report/model_loss_std 2.14 / report/post_ent_mag 60.09 / report/post_ent_max 60.09 / report/post_ent_mean 39.82 / report/post_ent_min 22.34 / 
report/post_ent_std 4.71 / report/prior_ent_mag 66.2 / report/prior_ent_max 66.2 / report/prior_ent_mean 41.27 / report/prior_ent_min 31.23 / report/prior_ent_std 4.91 / report/rep_loss_mean 1.64 / report/rep_loss_std 3.29 / report/reward_avg 0 / report/reward_loss_mean 0
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.1e-10 / eval/cont_loss_std 5e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.08 / eval/dyn_loss_std 4.26 / eval/image_loss_mean 0.47 /
eval/image_loss_std 1.65 / eval/model_loss_mean 1.72 / eval/model_loss_std 3.73 / eval/post_ent_mag 59.94 / eval/post_ent_max 59.94 / eval/post_ent_mean 38.5 / eval/post_ent_min 20.22 / eval/post_ent_std 5.01 / eval/prior_ent_mag 66.2 / eval/prior_ent_max 66.2 / 
eval/prior_ent_mean 40.24 / eval/prior_ent_min 21.23 / eval/prior_ent_std 5.59 / eval/rep_loss_mean 2.08 / eval/rep_loss_std 4.26 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 9.3e4 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
301.47 / timer/env.step_count 3826 / timer/env.step_total 18.99 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.19 / timer/replay._sample_frac 
1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 
/ timer/agent.policy_count 7834 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1913 / timer/agent.train_total 245.31 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.38

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T233955F346851-4gbGFHGwHkd4Ni5juXW4Gk-2gnZStDUH1bgO4KcICk88C-1024.npz
Starting evaluation at step 93500 Counter(93500) 93437
Saved chunk: 20230921T234022F225164-26EtB0bOzhE16ZAoXgGEgj-6LpTZIcWxbWyno8QUYuyDG-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 94000 Counter(94000) 93937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234115F717213-2gnZStDUH1bgO4KcICk88C-0xRkpltCsFNRqQUTWV3qgP-1024.npz
Starting evaluation at step 94500 Counter(94500) 94437
Saved chunk: 20230921T234141F224214-6LpTZIcWxbWyno8QUYuyDG-2WW664mRUKAFQOXrSYMYVr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 95000 Counter(95000) 94937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234235F883829-0xRkpltCsFNRqQUTWV3qgP-4Jz5L48vfg7Z9ra5bK4vdL-1024.npz
Starting evaluation at step 95500 Counter(95500) 95437
Saved chunk: 20230921T234259F707471-2WW664mRUKAFQOXrSYMYVr-4lTrfdajO8jzk1oBcsYqFi-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 96000 Counter(96000) 95937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234355F799720-4Jz5L48vfg7Z9ra5bK4vdL-3eHbiMocSWklIFlwlZxQn9-1024.npz
Starting evaluation at step 96500 Counter(96500) 96437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234418F028695-4lTrfdajO8jzk1oBcsYqFi-7emQ166oro2h9X7Txd7OIi-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 193722 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.39 / train/action_min -4.06 / train/action_std 1.1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.1e-6 / train/actor_opt_grad_steps 4.7e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-10 / train/cont_loss_std 7.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-6 / train/extr_critic_critic_opt_grad_steps 4.7e4 / train/extr_critic_critic_opt_loss 
3.4e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.23 / train/image_loss_std 0.4 / train/model_loss_mean 1.3 / train/model_loss_std 2.46 / train/model_opt_grad_norm 7.06 / 
train/model_opt_grad_steps 4.7e4 / train/model_opt_loss 9703.6 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7461.14 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 7.1e-4 / train/policy_logprob_mag 9.58 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.58 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 3.1e-4 / train/post_ent_mag 60.41 / train/post_ent_max 60.41 / train/post_ent_mean 39.12 / train/post_ent_min 23.52 / train/post_ent_std 4.25 / 
train/prior_ent_mag 66.73 / train/prior_ent_max 66.73 / train/prior_ent_mean 40.79 / train/prior_ent_min 29.89 / train/prior_ent_std 4.98 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.68 / train/reward_avg 0 / train/reward_loss_mean 4.8e-12 / train/reward_loss_std 
1.5e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.8e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-10 / report/cont_loss_std 4.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.61 / report/image_loss_mean 0.22 / report/image_loss_std 0.31 / report/model_loss_mean 1.28 / report/model_loss_std 2.35 / report/post_ent_mag 60.24 / report/post_ent_max 60.24 / report/post_ent_mean 39.2 / 
report/post_ent_min 26.73 / report/post_ent_std 3.9 / report/prior_ent_mag 66.69 / report/prior_ent_max 66.69 / report/prior_ent_mean 40.96 / report/prior_ent_min 33.18 / report/prior_ent_std 4.82 / report/rep_loss_mean 1.76 / report/rep_loss_std 3.61 / report/reward_avg 
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 9.1e-11 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.68 / eval/dyn_loss_std 3.18 / 
eval/image_loss_mean 0.19 / eval/image_loss_std 0.32 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.12 / eval/post_ent_mag 60.52 / eval/post_ent_max 60.52 / eval/post_ent_mean 39.31 / eval/post_ent_min 28.1 / eval/post_ent_std 3.61 / eval/prior_ent_mag 66.69 / 
eval/prior_ent_max 66.69 / eval/prior_ent_mean 41.06 / eval/prior_ent_min 34.43 / eval/prior_ent_std 4.47 / eval/rep_loss_mean 1.68 / eval/rep_loss_std 3.18 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 9.7e4 / replay/inserts 3860 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.7e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3860 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 396.34 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7367 / timer/agent.policy_total 15.73 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.7e-3 / timer/dataset_train_count 1930 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1930 / timer/agent.train_total 247.25 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max
0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / 
timer/dataset_eval_frac 9.4e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.73

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 97000 Counter(97000) 96937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234515F554380-3eHbiMocSWklIFlwlZxQn9-4aIwogKRXvcsvWwCkAfvly-1024.npz
Starting evaluation at step 97500 Counter(97500) 97437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 98000 Counter(98000) 97937
Saved chunk: 20230921T234536F188102-7emQ166oro2h9X7Txd7OIi-5AMirwiRMvxRVr6gsjQ7jY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234636F168882-4aIwogKRXvcsvWwCkAfvly-13Gxe6R7mt6XmOZUuUO5TQ-1024.npz
Starting evaluation at step 98500 Counter(98500) 98437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 99000 Counter(99000) 98937
Saved chunk: 20230921T234731F208291-5AMirwiRMvxRVr6gsjQ7jY-6awKbPW2jtEW4Dnmw2KAmJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234756F230503-13Gxe6R7mt6XmOZUuUO5TQ-7dGDPe9uIXFNc2SjXyfqfw-1024.npz
Starting evaluation at step 99500 Counter(99500) 99437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 100000 Counter(100000) 99937
Saved chunk: 20230921T234849F552430-6awKbPW2jtEW4Dnmw2KAmJ-4YpyyeG6DPQW3608bDKy17-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T234916F038587-7dGDPe9uIXFNc2SjXyfqfw-3hTPPlhwUTCAMiUaGutHq6-1024.npz
Starting evaluation at step 100500 Counter(100500) 100437
eval_Episode has 500 steps and return 0.0.
 Step 201348 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.41 / train/action_min -4.01 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1e-6 / train/actor_opt_grad_steps 4.9e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 1.7e-10 / train/cont_loss_std 7.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / train/dyn_loss_std 
3.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 5.1e-6 / train/extr_critic_critic_opt_grad_steps 4.9e4 / train/extr_critic_critic_opt_loss 7.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.22 / train/image_loss_std 0.38 / train/model_loss_mean 1.29 / train/model_loss_std 2.43 / train/model_opt_grad_norm 7.08 / 
train/model_opt_grad_steps 4.9e4 / train/model_opt_loss 7394.95 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5763.16 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 6.6e-4 / train/policy_logprob_mag 9.55 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.55 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.9e-4 / train/post_ent_mag 60.74 / train/post_ent_max 60.74 / train/post_ent_mean 39.39 / train/post_ent_min 23.76 / train/post_ent_std 4.24 / 
train/prior_ent_mag 66.99 / train/prior_ent_max 66.99 / train/prior_ent_mean 41.06 / train/prior_ent_min 30.06 / train/prior_ent_std 4.96 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.64 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 1.5e-10 / report/cont_loss_std 5.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.74 / 
report/dyn_loss_std 3.12 / report/image_loss_mean 0.19 / report/image_loss_std 0.28 / report/model_loss_mean 1.23 / report/model_loss_std 2.05 / report/post_ent_mag 60.73 / report/post_ent_max 60.73 / report/post_ent_mean 39.62 / report/post_ent_min 23.21 / 
report/post_ent_std 3.55 / report/prior_ent_mag 67.07 / report/prior_ent_max 67.07 / report/prior_ent_mean 41.2 / report/prior_ent_min 30.41 / report/prior_ent_std 4.65 / report/rep_loss_mean 1.74 / report/rep_loss_std 3.12 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 5.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.79 / eval/dyn_loss_std 3.32 / eval/image_loss_mean 
0.16 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.23 / eval/model_loss_std 2.13 / eval/post_ent_mag 61.06 / eval/post_ent_max 61.06 / eval/post_ent_mean 39.04 / eval/post_ent_min 24.82 / eval/post_ent_std 3.72 / eval/prior_ent_mag 67.07 / eval/prior_ent_max 67.07 /
eval/prior_ent_mean 40.7 / eval/prior_ent_min 34.51 / eval/prior_ent_std 4.73 / eval/rep_loss_mean 1.79 / eval/rep_loss_std 3.32 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1e5 / replay/inserts 3813 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
299.99 / timer/env.step_count 3813 / timer/env.step_total 18.81 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.39 / timer/replay._sample_frac 
1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-4 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7821 / timer/agent.policy_total 16.67 / timer/agent.policy_frac
0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1906 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1906 / timer/agent.train_total 244.14 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.42

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 101000 Counter(101000) 100937
Saved chunk: 20230921T235007F651479-4YpyyeG6DPQW3608bDKy17-4vTGhb10VHw5eaJKRzBxfi-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235035F780233-3hTPPlhwUTCAMiUaGutHq6-3AQf6CjHvjDIVLd3EJYZL4-1024.npz
Starting evaluation at step 101500 Counter(101500) 101437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 102000 Counter(102000) 101937
Saved chunk: 20230921T235126F700670-4vTGhb10VHw5eaJKRzBxfi-0z6twUnEXZhHJl29bRnrJ4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235156F643997-3AQf6CjHvjDIVLd3EJYZL4-0ydfYWRuD8bejg4QjLFvZn-1024.npz
Starting evaluation at step 102500 Counter(102500) 102437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230921T235245F438551-0z6twUnEXZhHJl29bRnrJ4-0000000000000000000000-904.npz
Saved chunk: 20230921T235316F854992-0ydfYWRuD8bejg4QjLFvZn-0000000000000000000000-500.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 103000 Counter(103000) 102937
Saved chunk: 20230921T235245F438551-0z6twUnEXZhHJl29bRnrJ4-4L7MvJzDzblULqU2OkRjFm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235316F854992-0ydfYWRuD8bejg4QjLFvZn-1OR3PX4nKSNpLbvS3Dy0Ed-1024.npz
Starting evaluation at step 103500 Counter(103500) 103437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 104000 Counter(104000) 103937
Saved chunk: 20230921T235405F099421-4L7MvJzDzblULqU2OkRjFm-56Ln9G9pVhedOfplCffqSH-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235438F071301-1OR3PX4nKSNpLbvS3Dy0Ed-0f9T8i8h23qUuBkHljLkJB-1024.npz
Starting evaluation at step 104500 Counter(104500) 104437
eval_Episode has 500 steps and return 0.0.
 Step 209002 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.42 / train/action_min -3.97 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.1e-6 / train/actor_opt_grad_steps 5.1e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-10 / train/cont_loss_std 1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std 
3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.8e-6 / train/extr_critic_critic_opt_grad_steps 5.1e4 / train/extr_critic_critic_opt_loss 6.8e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.23 / train/image_loss_std 0.39 / train/model_loss_mean 1.3 / train/model_loss_std 2.45 / train/model_opt_grad_norm 7.32 / 
train/model_opt_grad_steps 5.1e4 / train/model_opt_loss 8881.33 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6848.96 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 6.6e-4 / train/policy_logprob_mag 9.31 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.31 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.9e-4 / train/post_ent_mag 61.43 / train/post_ent_max 61.43 / train/post_ent_mean 39.58 / train/post_ent_min 24.23 / train/post_ent_std 4.41 / 
train/prior_ent_mag 67.43 / train/prior_ent_max 67.43 / train/prior_ent_mean 41.29 / train/prior_ent_min 30.33 / train/prior_ent_std 5.11 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.65 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 7.7e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / 
report/dyn_loss_std 3.68 / report/image_loss_mean 0.19 / report/image_loss_std 0.44 / report/model_loss_mean 1.25 / report/model_loss_std 2.5 / report/post_ent_mag 61.25 / report/post_ent_max 61.25 / report/post_ent_mean 39.49 / report/post_ent_min 26.44 / 
report/post_ent_std 4.07 / report/prior_ent_mag 67.4 / report/prior_ent_max 67.4 / report/prior_ent_mean 41.29 / report/prior_ent_min 29.57 / report/prior_ent_std 4.84 / report/rep_loss_mean 1.75 / report/rep_loss_std 3.68 / report/reward_avg 0 / report/reward_loss_mean 0
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 9e-11 / eval/cont_loss_std 3.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.59 / eval/dyn_loss_std 2.43 / eval/image_loss_mean 0.16 / 
eval/image_loss_std 0.26 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.61 / eval/post_ent_mag 61.52 / eval/post_ent_max 61.52 / eval/post_ent_mean 39.38 / eval/post_ent_min 24.9 / eval/post_ent_std 3.96 / eval/prior_ent_mag 67.4 / eval/prior_ent_max 67.4 / 
eval/prior_ent_mean 41.05 / eval/prior_ent_min 34.38 / eval/prior_ent_std 4.56 / eval/rep_loss_mean 1.59 / eval/rep_loss_std 2.43 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1e5 / replay/inserts 3827 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
303.07 / timer/env.step_count 3827 / timer/env.step_total 19.11 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.91 / timer/replay._sample_frac 
1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7835 / timer/agent.policy_total 16.93 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1914 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1914 / timer/agent.train_total 246.55 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.96 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 105000 Counter(105000) 104937
Saved chunk: 20230921T235523F580306-56Ln9G9pVhedOfplCffqSH-3M9cnHYeRztlV0rqu8PoBt-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235557F990678-0f9T8i8h23qUuBkHljLkJB-3glrWuXI39SmMjjp7Tc86A-1024.npz
Starting evaluation at step 105500 Counter(105500) 105437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 106000 Counter(106000) 105937
Saved chunk: 20230921T235642F815598-3M9cnHYeRztlV0rqu8PoBt-3ZwVt9tLrXEz0aW5AdSPYj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235719F079629-3glrWuXI39SmMjjp7Tc86A-7MciVmzzSadwQoe8s7KZ4L-1024.npz
Starting evaluation at step 106500 Counter(106500) 106437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 107000 Counter(107000) 106937
Saved chunk: 20230921T235801F608389-3ZwVt9tLrXEz0aW5AdSPYj-3xJOEEvrLh13xw3vNLBhaI-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 107500 Counter(107500) 107437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T235839F318888-7MciVmzzSadwQoe8s7KZ4L-4MZW95F8SKtEeR0FllvBTk-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 108000 Counter(108000) 107937
Saved chunk: 20230921T235920F243668-3xJOEEvrLh13xw3vNLBhaI-2q9FmG0Lizc3bcGqm2Y4kC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 216686 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.44 / train/action_min -3.97 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.1e-6 / train/actor_opt_grad_steps 5.3e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 7.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / train/dyn_loss_std
3.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 5.3e-6 / train/extr_critic_critic_opt_grad_steps 5.3e4 / train/extr_critic_critic_opt_loss 7.2e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.23 / train/image_loss_std 0.4 / train/model_loss_mean 1.31 / train/model_loss_std 2.52 / train/model_opt_grad_norm 6.72 / 
train/model_opt_grad_steps 5.3e4 / train/model_opt_loss 7337.02 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5598.96 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 6.5e-4 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.8e-4 / train/post_ent_mag 61.72 / train/post_ent_max 61.72 / train/post_ent_mean 39.53 / train/post_ent_min 23.49 / train/post_ent_std 4.61 / 
train/prior_ent_mag 67.63 / train/prior_ent_max 67.63 / train/prior_ent_mean 41.24 / train/prior_ent_min 29.08 / train/prior_ent_std 5.29 / train/rep_loss_mean 1.8 / train/rep_loss_std 3.77 / train/reward_avg 0 / train/reward_loss_mean 1.5e-11 / train/reward_loss_std 
4.7e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.62 / report/dyn_loss_std 2.96 / report/image_loss_mean 0.17 / report/image_loss_std 0.24 / report/model_loss_mean 1.15 / report/model_loss_std 1.93 / report/post_ent_mag 62.17 / report/post_ent_max 62.17 / report/post_ent_mean 40 / 
report/post_ent_min 28.5 / report/post_ent_std 4.48 / report/prior_ent_mag 67.63 / report/prior_ent_max 67.63 / report/prior_ent_mean 41.47 / report/prior_ent_min 33.25 / report/prior_ent_std 5.14 / report/rep_loss_mean 1.62 / report/rep_loss_std 2.96 / report/reward_avg 
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 3.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.79 / eval/dyn_loss_std 3.7 / 
eval/image_loss_mean 0.23 / eval/image_loss_std 0.48 / eval/model_loss_mean 1.3 / eval/model_loss_std 2.52 / eval/post_ent_mag 62.09 / eval/post_ent_max 62.09 / eval/post_ent_mean 40.7 / eval/post_ent_min 20.27 / eval/post_ent_std 4.89 / eval/prior_ent_mag 67.63 / 
eval/prior_ent_max 67.63 / eval/prior_ent_mean 42.23 / eval/prior_ent_min 34.11 / eval/prior_ent_std 5.39 / eval/rep_loss_mean 1.79 / eval/rep_loss_std 3.7 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.1e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3842 / timer/env.step_total 18.96 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 394.72 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.7e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7349 / timer/agent.policy_total 15.94 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.09 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1921 / timer/agent.train_total 247.06 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / 
timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 108500 Counter(108500) 108437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000002F894666-4MZW95F8SKtEeR0FllvBTk-6gdFToVCnk76k8G5vR0roz-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 109000 Counter(109000) 108937
Saved chunk: 20230922T000038F792946-2q9FmG0Lizc3bcGqm2Y4kC-7nghW2Dj9NBH9oH04JULUw-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 109500 Counter(109500) 109437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000123F739535-6gdFToVCnk76k8G5vR0roz-3rmCq3gSw4nuxEYSXYvAS0-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 110000 Counter(110000) 109937
Saved chunk: 20230922T000158F324660-7nghW2Dj9NBH9oH04JULUw-13GZoCIS4nPNdRPhlLSjkg-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 110500 Counter(110500) 110437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000244F169528-3rmCq3gSw4nuxEYSXYvAS0-5rUBfsVTmBKYHqoL50KgMf-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 111000 Counter(111000) 110937
Saved chunk: 20230922T000316F992261-13GZoCIS4nPNdRPhlLSjkg-3dnUJrLWnuVfI0ltS1LRiC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 111500 Counter(111500) 111437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000404F369408-5rUBfsVTmBKYHqoL50KgMf-5GhMO0HrPNyYn8aHKXEgJD-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 112000 Counter(112000) 111937
Saved chunk: 20230922T000435F599879-3dnUJrLWnuVfI0ltS1LRiC-0IIuqZTKyKGLJNWnetQeS8-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 224278 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.64 / train/action_mean 0.46 / train/action_min -3.93 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.9e-7 / train/actor_opt_grad_steps 5.5e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.5e-10 / train/cont_loss_std 6.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.6e-6 / train/extr_critic_critic_opt_grad_steps 5.5e4 / train/extr_critic_critic_opt_loss 
5.2e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.36 / train/model_loss_mean 1.29 / train/model_loss_std 2.46 / train/model_opt_grad_norm 6.64 / 
train/model_opt_grad_steps 5.5e4 / train/model_opt_loss 8550.31 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6631.58 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 6.2e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.7e-4 / train/post_ent_mag 61.85 / train/post_ent_max 61.85 / train/post_ent_mean 39.67 / train/post_ent_min 23.85 / train/post_ent_std 4.57 / 
train/prior_ent_mag 67.66 / train/prior_ent_max 67.66 / train/prior_ent_mean 41.37 / train/prior_ent_min 29.69 / train/prior_ent_std 5.24 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.7 / train/reward_avg 0 / train/reward_loss_mean 9.8e-12 / train/reward_loss_std 
3.1e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.8e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / report/cont_loss_mean 1.6e-10 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.03 / report/image_loss_mean 0.19 / report/image_loss_std 0.36 / report/model_loss_mean 1.16 / report/model_loss_std 2.06 / report/post_ent_mag 61.91 / report/post_ent_max 61.91 / report/post_ent_mean 40.14 / 
report/post_ent_min 26.97 / report/post_ent_std 4.66 / report/prior_ent_mag 67.83 / report/prior_ent_max 67.83 / report/prior_ent_mean 41.68 / report/prior_ent_min 33.81 / report/prior_ent_std 5.18 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.03 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.86 / eval/dyn_loss_std 3.66 / 
eval/image_loss_mean 0.19 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.3 / eval/model_loss_std 2.4 / eval/post_ent_mag 61.85 / eval/post_ent_max 61.85 / eval/post_ent_mean 39.75 / eval/post_ent_min 21.53 / eval/post_ent_std 4.67 / eval/prior_ent_mag 67.83 / 
eval/prior_ent_max 67.83 / eval/prior_ent_mean 41.5 / eval/prior_ent_min 33.32 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 1.86 / eval/rep_loss_std 3.66 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.1e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3796 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 390.27 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.7e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7804 / timer/agent.policy_total 16.9 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / 
timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / 
timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 112500 Counter(112500) 112437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000524F485060-5GhMO0HrPNyYn8aHKXEgJD-0GDmPSp02cn3Q5nA9JpCM7-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 113000 Counter(113000) 112937
Saved chunk: 20230922T000554F041791-0IIuqZTKyKGLJNWnetQeS8-0dX1hJJvUovAunAjfWc7Ui-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 113500 Counter(113500) 113437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000645F454029-0GDmPSp02cn3Q5nA9JpCM7-2KdGUnXuRMo6VDnHXahAxY-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 114000 Counter(114000) 113937
Saved chunk: 20230922T000713F611150-0dX1hJJvUovAunAjfWc7Ui-1Vf0RklJm8fV4jsrGbeoZu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T000832F253206-1Vf0RklJm8fV4jsrGbeoZu-0000000000000000000000-139.npz
Saved chunk: 20230922T000805F780082-2KdGUnXuRMo6VDnHXahAxY-0000000000000000000000-736.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 114500 Counter(114500) 114437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000805F780082-2KdGUnXuRMo6VDnHXahAxY-5grOlSztAcIShlRjSG30CQ-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 115000 Counter(115000) 114937
Saved chunk: 20230922T000832F253206-1Vf0RklJm8fV4jsrGbeoZu-45VmmkK9LtkoKRwORqOIIC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 115500 Counter(115500) 115437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T000926F104381-5grOlSztAcIShlRjSG30CQ-7tklrEFNUh1HsW3hpBPzDb-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 231958 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.68 / train/action_mean 0.48 / train/action_min -3.98 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.3e-7 / train/actor_opt_grad_steps 5.6e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-10 / train/cont_loss_std 8.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.3e-6 / train/extr_critic_critic_opt_grad_steps 5.6e4 / train/extr_critic_critic_opt_loss 
8e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.22 / train/image_loss_std 0.37 / train/model_loss_mean 1.29 / train/model_loss_std 2.47 / train/model_opt_grad_norm 7.06 / 
train/model_opt_grad_steps 5.6e4 / train/model_opt_loss 9528.5 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 6e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.6e-4 / train/post_ent_mag 62.24 / train/post_ent_max 62.24 / train/post_ent_mean 39.77 / train/post_ent_min 24.09 / train/post_ent_std 4.76 / 
train/prior_ent_mag 67.92 / train/prior_ent_max 67.92 / train/prior_ent_mean 41.49 / train/prior_ent_min 29.71 / train/prior_ent_std 5.41 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.71 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 
1.6e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.9e-11 / report/cont_loss_std 3.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.9e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.86 / report/dyn_loss_std 4.35 / report/image_loss_mean 0.17 / report/image_loss_std 0.27 / report/model_loss_mean 1.28 / report/model_loss_std 2.78 / report/post_ent_mag 61.13 / report/post_ent_max 61.13 / report/post_ent_mean 39.17 / 
report/post_ent_min 17.79 / report/post_ent_std 4.47 / report/prior_ent_mag 67.86 / report/prior_ent_max 67.86 / report/prior_ent_mean 40.94 / report/prior_ent_min 22.63 / report/prior_ent_std 5.3 / report/rep_loss_mean 1.86 / report/rep_loss_std 4.35 / report/reward_avg 
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 4.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.7 / eval/dyn_loss_std 3.05 / 
eval/image_loss_mean 0.19 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.21 / eval/model_loss_std 2.03 / eval/post_ent_mag 62.38 / eval/post_ent_max 62.38 / eval/post_ent_mean 40 / eval/post_ent_min 28.09 / eval/post_ent_std 4.4 / eval/prior_ent_mag 67.86 / 
eval/prior_ent_max 67.86 / eval/prior_ent_mean 41.58 / eval/prior_ent_min 33.87 / eval/prior_ent_std 5.19 / eval/rep_loss_mean 1.7 / eval/rep_loss_std 3.05 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.2e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3840 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 392.51 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-4 / timer/replay._sample_max 0.12 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / 
timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7347 / timer/agent.policy_total 15.99 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 /
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.84 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 116000 Counter(116000) 115937
Saved chunk: 20230922T000951F011021-45VmmkK9LtkoKRwORqOIIC-77OW947TdC84S4UPwRLuWI-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 116500 Counter(116500) 116437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001046F219683-7tklrEFNUh1HsW3hpBPzDb-5ytgxKEaKXYhuuZK1amMHk-1024.npz
Starting evaluation at step 117000 Counter(117000) 116937
Saved chunk: 20230922T001110F181281-77OW947TdC84S4UPwRLuWI-5OvN3qB3GwN0KsDTnct8Z8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 117500 Counter(117500) 117437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001207F251471-5ytgxKEaKXYhuuZK1amMHk-4XKi7K6ty4q8dT1eoVASCF-1024.npz
Starting evaluation at step 118000 Counter(118000) 117937
Saved chunk: 20230922T001229F096303-5OvN3qB3GwN0KsDTnct8Z8-594tc8h0UwZULkMrwyLWTu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 118500 Counter(118500) 118437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001327F516567-4XKi7K6ty4q8dT1eoVASCF-6VxzJ3nF6ufelL276796tZ-1024.npz
Starting evaluation at step 119000 Counter(119000) 118937
Saved chunk: 20230922T001347F728359-594tc8h0UwZULkMrwyLWTu-14vSYxbe6d5OIE10ahAVsU-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 119500 Counter(119500) 119437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 239552 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 8.7e-7 / train/actor_opt_grad_steps 5.8e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 8.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / 
train/dyn_loss_std 3.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 8.1e-6 / train/extr_critic_critic_opt_grad_steps 5.8e4 / train/extr_critic_critic_opt_loss 
9.8e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.36 / train/model_loss_mean 1.27 / train/model_loss_std 2.43 / train/model_opt_grad_norm 6.98 / 
train/model_opt_grad_steps 5.8e4 / train/model_opt_loss 9658.57 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7619.05 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.6e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.4e-4 / train/post_ent_mag 62.63 / train/post_ent_max 62.63 / train/post_ent_mean 39.82 / train/post_ent_min 24.18 / train/post_ent_std 4.84 / 
train/prior_ent_mag 68.02 / train/prior_ent_max 68.02 / train/prior_ent_mean 41.51 / train/prior_ent_min 30.17 / train/prior_ent_std 5.48 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.66 / train/reward_avg 0 / train/reward_loss_mean 2.5e-11 / train/reward_loss_std 
7.9e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 2.5e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 2.08 / report/dyn_loss_std 4.97 / report/image_loss_mean 0.24 / report/image_loss_std 0.43 / report/model_loss_mean 1.49 / report/model_loss_std 3.28 / report/post_ent_mag 62.04 / report/post_ent_max 62.04 / report/post_ent_mean 39.45 / 
report/post_ent_min 16.33 / report/post_ent_std 4.54 / report/prior_ent_mag 68.04 / report/prior_ent_max 68.04 / report/prior_ent_mean 41.41 / report/prior_ent_min 22.89 / report/prior_ent_std 5.56 / report/rep_loss_mean 2.08 / report/rep_loss_std 4.97 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 4.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.78 / eval/dyn_loss_std 3.26 / 
eval/image_loss_mean 0.21 / eval/image_loss_std 0.32 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.16 / eval/post_ent_mag 62.36 / eval/post_ent_max 62.36 / eval/post_ent_mean 40.24 / eval/post_ent_min 25.95 / eval/post_ent_std 4.4 / eval/prior_ent_mag 68.04 / 
eval/prior_ent_max 68.04 / eval/prior_ent_mean 42.03 / eval/prior_ent_min 34.48 / eval/prior_ent_std 5.1 / eval/rep_loss_mean 1.78 / eval/rep_loss_std 3.26 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.2e5 / replay/inserts 3797 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3797 / timer/env.step_total 18.76 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 8.2e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 391.94 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7805 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 
0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / 
timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.31

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T001447F621522-6VxzJ3nF6ufelL276796tZ-4H5al7gdqzxAbXM7oU4b7l-1024.npz
Starting evaluation at step 120000 Counter(120000) 119937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001506F253461-14vSYxbe6d5OIE10ahAVsU-37VWQiE2wFJaLNVOLI457W-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 120500 Counter(120500) 120437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001608F344690-4H5al7gdqzxAbXM7oU4b7l-5Y96sJNHFfynCpsABmcykc-1024.npz
Starting evaluation at step 121000 Counter(121000) 120937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 121500 Counter(121500) 121437
Saved chunk: 20230922T001625F553202-37VWQiE2wFJaLNVOLI457W-46fKN4FB0M3vVq3YLqihFR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001728F889426-5Y96sJNHFfynCpsABmcykc-3XKtI543xVfBKzNXenCe0e-1024.npz
Starting evaluation at step 122000 Counter(122000) 121937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 122500 Counter(122500) 122437
Saved chunk: 20230922T001820F254742-46fKN4FB0M3vVq3YLqihFR-58rrzAOCdamYxUpUdojWD5-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T001848F993796-3XKtI543xVfBKzNXenCe0e-2tLQQQOtcB7kTTkRFeb8p7-1024.npz
Starting evaluation at step 123000 Counter(123000) 122937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 123500 Counter(123500) 123437
Saved chunk: 20230922T001938F660492-58rrzAOCdamYxUpUdojWD5-2DhaC4NScSqoSxj6T6S6UQ-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 247150 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 8.6e-7 / train/actor_opt_grad_steps 6e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 5.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std 
3.7 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.6e-6 / train/extr_critic_critic_opt_grad_steps 6e4 / train/extr_critic_critic_opt_loss 4.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.37 / train/model_loss_mean 1.28 / train/model_loss_std 2.46 / train/model_opt_grad_norm 6.8 / 
train/model_opt_grad_steps 6e4 / train/model_opt_loss 8647.65 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6736.84 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.7e-4 / train/policy_logprob_mag 9.27 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.27 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.5e-4 / train/post_ent_mag 62.51 / train/post_ent_max 62.51 / train/post_ent_mean 39.84 / train/post_ent_min 24.59 / train/post_ent_std 4.85 / 
train/prior_ent_mag 68.03 / train/prior_ent_max 68.03 / train/prior_ent_mean 41.53 / train/prior_ent_min 30.73 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.7 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 
1.6e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 5.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.79 / report/dyn_loss_std 3.77 / report/image_loss_mean 0.22 / report/image_loss_std 0.36 / report/model_loss_mean 1.29 / report/model_loss_std 2.53 / report/post_ent_mag 62.89 / report/post_ent_max 62.89 / report/post_ent_mean 40.5 / 
report/post_ent_min 24.46 / report/post_ent_std 4.85 / report/prior_ent_mag 68.17 / report/prior_ent_max 68.17 / report/prior_ent_mean 42.2 / report/prior_ent_min 33.67 / report/prior_ent_std 5.34 / report/rep_loss_mean 1.79 / report/rep_loss_std 3.77 / report/reward_avg 
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 1.1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / eval/dyn_loss_std 2.74 / 
eval/image_loss_mean 0.19 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.79 / eval/post_ent_mag 62.59 / eval/post_ent_max 62.59 / eval/post_ent_mean 40.16 / eval/post_ent_min 25.64 / eval/post_ent_std 4.83 / eval/prior_ent_mag 68.17 / 
eval/prior_ent_max 68.17 / eval/prior_ent_mean 41.95 / eval/prior_ent_min 34.2 / eval/prior_ent_std 5.12 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 2.74 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.2e5 / replay/inserts 3799 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3799 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 387.91 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7807 / timer/agent.policy_total 16.62 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.22 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 
0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / 
timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.32

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002008F988575-2tLQQQOtcB7kTTkRFeb8p7-6QYHLwE9BujqeIpV93Owas-1024.npz
Starting evaluation at step 124000 Counter(124000) 123937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 124500 Counter(124500) 124437
Saved chunk: 20230922T002057F069700-2DhaC4NScSqoSxj6T6S6UQ-3KMoV4vD44vk3Wg6VWCt6x-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002129F733819-6QYHLwE9BujqeIpV93Owas-4MHXqWHZ5PtOx6IfQrqR4n-1024.npz
Starting evaluation at step 125000 Counter(125000) 124937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 125500 Counter(125500) 125437
Saved chunk: 20230922T002216F491983-3KMoV4vD44vk3Wg6VWCt6x-6Q2FfG50m41H7eEJUdotrn-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T002335F095754-6Q2FfG50m41H7eEJUdotrn-0000000000000000000000-398.npz
Saved chunk: 20230922T002250F015486-4MHXqWHZ5PtOx6IfQrqR4n-0000000000000000000000-973.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T002250F015486-4MHXqWHZ5PtOx6IfQrqR4n-2SRNvIZ6S0wuK2EHlx83BQ-1024.npz
Starting evaluation at step 126000 Counter(126000) 125937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 126500 Counter(126500) 126437
Saved chunk: 20230922T002335F095754-6Q2FfG50m41H7eEJUdotrn-70E6vwfUPMx2oTthcW4jm3-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002410F357869-2SRNvIZ6S0wuK2EHlx83BQ-7fNsVf1khwgxX6zcovvKm7-1024.npz
Starting evaluation at step 127000 Counter(127000) 126937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 254842 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.69 / train/action_mean 0.49 / train/action_min -3.97 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9e-7 / train/actor_opt_grad_steps 6.2e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 6.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / train/dyn_loss_std 
3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 5.9e-6 / train/extr_critic_critic_opt_grad_steps 6.2e4 / train/extr_critic_critic_opt_loss 7.6e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.36 / train/model_loss_mean 1.28 / train/model_loss_std 2.44 / train/model_opt_grad_norm 6.67 / 
train/model_opt_grad_steps 6.2e4 / train/model_opt_loss 9899.65 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7772.02 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.9e-4 / train/policy_logprob_mag 9.69 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.69 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.6e-4 / train/post_ent_mag 62.8 / train/post_ent_max 62.8 / train/post_ent_mean 39.92 / train/post_ent_min 24.64 / train/post_ent_std 4.97 / 
train/prior_ent_mag 68.27 / train/prior_ent_max 68.27 / train/prior_ent_mean 41.6 / train/prior_ent_min 30.11 / train/prior_ent_std 5.6 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.68 / train/reward_avg 0 / train/reward_loss_mean 1.9e-11 / train/reward_loss_std 
6.2e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.9e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.4e-11 / report/cont_loss_std 2.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.4e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.78 / report/dyn_loss_std 3.77 / report/image_loss_mean 0.18 / report/image_loss_std 0.67 / report/model_loss_mean 1.25 / report/model_loss_std 2.79 / report/post_ent_mag 61.98 / report/post_ent_max 61.98 / report/post_ent_mean 38.99 / 
report/post_ent_min 26.55 / report/post_ent_std 4.42 / report/prior_ent_mag 68.05 / report/prior_ent_max 68.05 / report/prior_ent_mean 40.81 / report/prior_ent_min 33.56 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.78 / report/rep_loss_std 3.77 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 7.9e-11 / eval/cont_loss_std 3.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.76 / eval/dyn_loss_std 3.31 / 
eval/image_loss_mean 0.21 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.26 / eval/model_loss_std 2.22 / eval/post_ent_mag 61.59 / eval/post_ent_max 61.59 / eval/post_ent_mean 40.32 / eval/post_ent_min 29.54 / eval/post_ent_std 4.51 / eval/prior_ent_mag 68.05 / 
eval/prior_ent_max 68.05 / eval/prior_ent_mean 41.99 / eval/prior_ent_min 34.18 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 1.76 / eval/rep_loss_std 3.31 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.3e5 / replay/inserts 3846 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3846 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 398.61 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 
0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7353 / timer/agent.policy_total 15.93 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / 
timer/dataset_train_count 1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1923 / timer/agent.train_total 247.03 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 127500 Counter(127500) 127437
Saved chunk: 20230922T002453F760149-70E6vwfUPMx2oTthcW4jm3-1136K2lUcMTu227HTgPeXN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 128000 Counter(128000) 127937
Saved chunk: 20230922T002530F333412-7fNsVf1khwgxX6zcovvKm7-1IAyjJ0ap5JumoKhhugMsm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 128500 Counter(128500) 128437
Saved chunk: 20230922T002612F789507-1136K2lUcMTu227HTgPeXN-25QRLSuF6vX72VqHQarNNc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 129000 Counter(129000) 128937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002651F211510-1IAyjJ0ap5JumoKhhugMsm-6UF1eJvIuABI7ifUwlP4dz-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 129500 Counter(129500) 129437
Saved chunk: 20230922T002731F615493-25QRLSuF6vX72VqHQarNNc-3rjjc1LJSfAaLX5cUsQZSf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 130000 Counter(130000) 129937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002814F790887-6UF1eJvIuABI7ifUwlP4dz-2HQJMYw7OndIOTtGvi0ceg-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 130500 Counter(130500) 130437
Saved chunk: 20230922T002850F190641-3rjjc1LJSfAaLX5cUsQZSf-36zpdHmdDNZK4P6YqIUsQ9-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 131000 Counter(131000) 130937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T002934F927150-2HQJMYw7OndIOTtGvi0ceg-3ymxdqGi7kIAh8zudgxi2M-1024.npz
 Step 262442 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.5 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 8.4e-7 / train/actor_opt_grad_steps 6.4e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 7.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / 
train/dyn_loss_std 3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.8e-6 / train/extr_critic_critic_opt_grad_steps 6.4e4 / train/extr_critic_critic_opt_loss 
6.5e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.36 / train/model_loss_mean 1.27 / train/model_loss_std 2.44 / train/model_opt_grad_norm 6.43 / 
train/model_opt_grad_steps 6.4e4 / train/model_opt_loss 8331.48 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6578.95 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 5.8e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.5e-4 / train/post_ent_mag 62.65 / train/post_ent_max 62.65 / train/post_ent_mean 39.97 / train/post_ent_min 24.98 / train/post_ent_std 4.94 / 
train/prior_ent_mag 68.2 / train/prior_ent_max 68.2 / train/prior_ent_mean 41.65 / train/prior_ent_min 30.84 / train/prior_ent_std 5.54 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.65 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / 
report/dyn_loss_std 3.95 / report/image_loss_mean 0.22 / report/image_loss_std 0.33 / report/model_loss_mean 1.3 / report/model_loss_std 2.61 / report/post_ent_mag 63.01 / report/post_ent_max 63.01 / report/post_ent_mean 40.84 / report/post_ent_min 26.05 / 
report/post_ent_std 5.05 / report/prior_ent_mag 68.67 / report/prior_ent_max 68.67 / report/prior_ent_mean 42.57 / report/prior_ent_min 34.03 / report/prior_ent_std 5.54 / report/rep_loss_mean 1.79 / report/rep_loss_std 3.95 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.99 / eval/dyn_loss_std 4.01 / eval/image_loss_mean 
0.23 / eval/image_loss_std 0.38 / eval/model_loss_mean 1.42 / eval/model_loss_std 2.6 / eval/post_ent_mag 62.58 / eval/post_ent_max 62.58 / eval/post_ent_mean 39.57 / eval/post_ent_min 28.84 / eval/post_ent_std 4.9 / eval/prior_ent_mag 68.67 / eval/prior_ent_max 68.67 / 
eval/prior_ent_mean 41.57 / eval/prior_ent_min 34.38 / eval/prior_ent_std 5.58 / eval/rep_loss_mean 1.99 / eval/rep_loss_std 4.01 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.3e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.03 / timer/env.step_count 3800 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.19 / timer/replay._sample_frac 
1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7808 / timer/agent.policy_total 16.76 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 1e-2 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.03 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.33

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 131500 Counter(131500) 131437
Saved chunk: 20230922T003008F688717-36zpdHmdDNZK4P6YqIUsQ9-6DH3iAridXyPdqIY5lIxRx-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 132000 Counter(132000) 131937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T003054F889624-3ymxdqGi7kIAh8zudgxi2M-3ePvI2LvKwISySgwFvFNXO-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 132500 Counter(132500) 132437
Saved chunk: 20230922T003127F879066-6DH3iAridXyPdqIY5lIxRx-0B86PW1hKro7n9eDyFwHww-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 133000 Counter(133000) 132937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T003216F030993-3ePvI2LvKwISySgwFvFNXO-1v5CUGvW8OQfbof5yVb9bW-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 133500 Counter(133500) 133437
Saved chunk: 20230922T003246F786076-0B86PW1hKro7n9eDyFwHww-4LyCP03S6U1Yy98tBHETwb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 134000 Counter(134000) 133937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T003336F290853-1v5CUGvW8OQfbof5yVb9bW-6TVknj8fQn0tPwhahN2apP-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 134500 Counter(134500) 134437
Saved chunk: 20230922T003405F427212-4LyCP03S6U1Yy98tBHETwb-3l0IZarHDgktUglnsD690g-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 135000 Counter(135000) 134937
eval_Episode has 500 steps and return 0.0.
 Step 270034 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.69 / train/action_mean 0.5 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 8.5e-7 / train/actor_opt_grad_steps 6.6e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 6.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.73 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.7e-6 / train/extr_critic_critic_opt_grad_steps 6.6e4 / train/extr_critic_critic_opt_loss 
6.6e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.37 / train/model_loss_mean 1.29 / train/model_loss_std 2.49 / train/model_opt_grad_norm 6.78 / 
train/model_opt_grad_steps 6.6e4 / train/model_opt_loss 9957.58 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7724.87 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.9e-4 / train/policy_logprob_mag 9.46 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.46 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.6e-4 / train/post_ent_mag 62.76 / train/post_ent_max 62.76 / train/post_ent_mean 40.02 / train/post_ent_min 24.4 / train/post_ent_std 4.97 / 
train/prior_ent_mag 68.37 / train/prior_ent_max 68.37 / train/prior_ent_mean 41.73 / train/prior_ent_min 30.32 / train/prior_ent_std 5.62 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.73 / train/reward_avg 0 / train/reward_loss_mean 9.9e-12 / train/reward_loss_std 
3.2e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-10 / report/cont_loss_std 3.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 2.05 / report/dyn_loss_std 5.18 / report/image_loss_mean 0.25 / report/image_loss_std 0.39 / report/model_loss_mean 1.48 / report/model_loss_std 3.38 / report/post_ent_mag 63.31 / report/post_ent_max 63.31 / report/post_ent_mean 39.3 / 
report/post_ent_min 21.71 / report/post_ent_std 4.89 / report/prior_ent_mag 68.82 / report/prior_ent_max 68.82 / report/prior_ent_mean 41.09 / report/prior_ent_min 28.36 / report/prior_ent_std 5.75 / report/rep_loss_mean 2.05 / report/rep_loss_std 5.18 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 7.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.81 / eval/dyn_loss_std 3.59 / 
eval/image_loss_mean 0.23 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.32 / eval/model_loss_std 2.33 / eval/post_ent_mag 63.21 / eval/post_ent_max 63.21 / eval/post_ent_mean 40.65 / eval/post_ent_min 27.77 / eval/post_ent_std 5.15 / eval/prior_ent_mag 68.82 / 
eval/prior_ent_max 68.82 / eval/prior_ent_mean 42.36 / eval/prior_ent_min 34.65 / eval/prior_ent_std 5.79 / eval/rep_loss_mean 1.81 / eval/rep_loss_std 3.59 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.3e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3796 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 389.16 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7804 / timer/agent.policy_total 16.79 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.8e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.99 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 
0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / 
timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T003456F452654-6TVknj8fQn0tPwhahN2apP-0UFMj67GtCVpJXj3zXRYJV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 135500 Counter(135500) 135437
Saved chunk: 20230922T003523F885388-3l0IZarHDgktUglnsD690g-2GKI58kQ9lihohEmHF3ILn-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 136000 Counter(136000) 135937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T003617F128254-0UFMj67GtCVpJXj3zXRYJV-6SsjT2B12MY1TLzdj1wKwG-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 136500 Counter(136500) 136437
Saved chunk: 20230922T003643F234486-2GKI58kQ9lihohEmHF3ILn-5tMcu6OYkeAsb3R0Fp7ECT-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 137000 Counter(137000) 136937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T003737F574810-6SsjT2B12MY1TLzdj1wKwG-6ozLH9ZDKMiuOZOlPyk3Yd-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T003857F757261-6ozLH9ZDKMiuOZOlPyk3Yd-0000000000000000000000-184.npz
Saved chunk: 20230922T003801F972952-5tMcu6OYkeAsb3R0Fp7ECT-0000000000000000000000-657.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 137500 Counter(137500) 137437
Saved chunk: 20230922T003801F972952-5tMcu6OYkeAsb3R0Fp7ECT-3087XkA6MirjuyeVqZUvZu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 138000 Counter(138000) 137937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T003857F757261-6ozLH9ZDKMiuOZOlPyk3Yd-19NtDMPtewI1YCyrzQhkPT-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 138500 Counter(138500) 138437
Saved chunk: 20230922T003920F831558-3087XkA6MirjuyeVqZUvZu-3eovnznGo80kpqjOxCOETU-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 277718 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.68 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.8e-7 / train/actor_opt_grad_steps 6.8e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 9.9e-11 / train/cont_loss_std 6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std 
3.71 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-6 / train/extr_critic_critic_opt_grad_steps 6.8e4 / train/extr_critic_critic_opt_loss 3e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.36 / train/model_loss_mean 1.27 / train/model_loss_std 2.47 / train/model_opt_grad_norm 6.73 / 
train/model_opt_grad_steps 6.8e4 / train/model_opt_loss 9941.2 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7823.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.6e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.4e-4 / train/post_ent_mag 62.87 / train/post_ent_max 62.87 / train/post_ent_mean 40.07 / train/post_ent_min 24.7 / train/post_ent_std 4.87 / 
train/prior_ent_mag 68.48 / train/prior_ent_max 68.48 / train/prior_ent_mean 41.79 / train/prior_ent_min 30.56 / train/prior_ent_std 5.48 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.71 / train/reward_avg 0 / train/reward_loss_mean 2.4e-11 / train/reward_loss_std 
7.7e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.8e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.8e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.91 / report/dyn_loss_std 4.81 / report/image_loss_mean 0.27 / report/image_loss_std 0.91 / report/model_loss_mean 1.42 / report/model_loss_std 3.53 / report/post_ent_mag 63.1 / report/post_ent_max 63.1 / report/post_ent_mean 40.58 / 
report/post_ent_min 20.23 / report/post_ent_std 5.17 / report/prior_ent_mag 68.79 / report/prior_ent_max 68.79 / report/prior_ent_mean 42.65 / report/prior_ent_min 32.65 / report/prior_ent_std 5.42 / report/rep_loss_mean 1.91 / report/rep_loss_std 4.81 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 2.4e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 2.73 / 
eval/image_loss_mean 0.13 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.77 / eval/post_ent_mag 63.1 / eval/post_ent_max 63.1 / eval/post_ent_mean 39.55 / eval/post_ent_min 25.84 / eval/post_ent_std 4.53 / eval/prior_ent_mag 68.79 / 
eval/prior_ent_max 68.79 / eval/prior_ent_mean 41.44 / eval/prior_ent_min 34.03 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 2.73 / eval/reward_avg 0 / eval/reward_loss_mean 9.3e-10 / eval/reward_loss_std 3e-8 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.3e-10 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.4e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3842 / timer/env.step_total 19 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 396.67 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.7e-4 / timer/replay._sample_max 0.13 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / 
timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7349 / timer/agent.policy_total 16.13 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1921 / timer/agent.train_total 246.79 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 139000 Counter(139000) 138937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004018F126467-19NtDMPtewI1YCyrzQhkPT-69TgS469BfidrygBiSHMbg-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 139500 Counter(139500) 139437
Saved chunk: 20230922T004039F262918-3eovnznGo80kpqjOxCOETU-4f321JcvsKoJ9Zt7xEMOh6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 140000 Counter(140000) 139937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004138F918079-69TgS469BfidrygBiSHMbg-6vh3fFXaNOx3XFB8v5CxCw-1024.npz
Starting evaluation at step 140500 Counter(140500) 140437
Saved chunk: 20230922T004158F671531-4f321JcvsKoJ9Zt7xEMOh6-50OeRW9uTqPQJJZ2HKNnfo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 141000 Counter(141000) 140937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004259F334664-6vh3fFXaNOx3XFB8v5CxCw-0uI4634fEh3L5r4whZBeOD-1024.npz
Starting evaluation at step 141500 Counter(141500) 141437
Saved chunk: 20230922T004317F407760-50OeRW9uTqPQJJZ2HKNnfo-0YEmlh1SMbdCqCAU01j373-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 142000 Counter(142000) 141937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004419F461541-0uI4634fEh3L5r4whZBeOD-0sT6jTlpzS23X8r3oKjhGO-1024.npz
Starting evaluation at step 142500 Counter(142500) 142437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004435F958781-0YEmlh1SMbdCqCAU01j373-4iB4E2CPiLqmusKipeRBM4-1024.npz
 Step 285310 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.72 / train/action_max 4.7 / train/action_mean 0.5 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 8.2e-7 / train/actor_opt_grad_steps 7e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 9.3e-11 / train/cont_loss_std 4.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / train/dyn_loss_std 
3.72 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.7e-6 / train/extr_critic_critic_opt_grad_steps 7e4 / train/extr_critic_critic_opt_loss 6.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.21 / train/image_loss_std 0.36 / train/model_loss_mean 1.28 / train/model_loss_std 2.47 / train/model_opt_grad_norm 6.62 / 
train/model_opt_grad_steps 7e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9206.35 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.7e-4 / train/policy_logprob_mag 9.6 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.6 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.5e-4 / train/post_ent_mag 62.99 / train/post_ent_max 62.99 / train/post_ent_mean 40.3 / train/post_ent_min 24.48 / train/post_ent_std 4.93 / 
train/prior_ent_mag 68.61 / train/prior_ent_max 68.61 / train/prior_ent_mean 42 / train/prior_ent_min 30.49 / train/prior_ent_std 5.52 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.72 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 1.5e-10 / report/cont_loss_std 1.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / 
report/dyn_loss_std 3.26 / report/image_loss_mean 0.16 / report/image_loss_std 0.33 / report/model_loss_mean 1.2 / report/model_loss_std 2.18 / report/post_ent_mag 63.65 / report/post_ent_max 63.65 / report/post_ent_mean 39.58 / report/post_ent_min 21.02 / 
report/post_ent_std 4.14 / report/prior_ent_mag 69.07 / report/prior_ent_max 69.07 / report/prior_ent_mean 41.35 / report/prior_ent_min 33.35 / report/prior_ent_std 4.74 / report/rep_loss_mean 1.72 / report/rep_loss_std 3.26 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.6e-10 / eval/cont_loss_std 5.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.18 / eval/dyn_loss_std 4.55 / eval/image_loss_mean 
0.34 / eval/image_loss_std 0.46 / eval/model_loss_mean 1.65 / eval/model_loss_std 3.04 / eval/post_ent_mag 63.43 / eval/post_ent_max 63.43 / eval/post_ent_mean 41.91 / eval/post_ent_min 25.27 / eval/post_ent_std 5.02 / eval/prior_ent_mag 69.07 / eval/prior_ent_max 69.07 /
eval/prior_ent_mean 44.19 / eval/prior_ent_min 34.69 / eval/prior_ent_std 5.56 / eval/rep_loss_mean 2.18 / eval/rep_loss_std 4.55 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.4e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
299.99 / timer/env.step_count 3796 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.57 / timer/replay._sample_frac 1.3 
/ timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 
0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.31

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 143000 Counter(143000) 142937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004539F434934-0sT6jTlpzS23X8r3oKjhGO-5a1lAcVoflHBvs63EoCXOG-1024.npz
Starting evaluation at step 143500 Counter(143500) 143437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004554F354291-4iB4E2CPiLqmusKipeRBM4-6Q7XuADEUOxvyF6A0tQTb7-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 144000 Counter(144000) 143937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004700F524350-5a1lAcVoflHBvs63EoCXOG-7oWM3eKjyOX2MazRT45Whz-1024.npz
Starting evaluation at step 144500 Counter(144500) 144437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 145000 Counter(145000) 144937
Saved chunk: 20230922T004713F895741-6Q7XuADEUOxvyF6A0tQTb7-5g3GwFHWql7SHJPayr7Bpp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004820F702658-7oWM3eKjyOX2MazRT45Whz-2mxzHApO0VbAdutE6kC9Gn-1024.npz
Starting evaluation at step 145500 Counter(145500) 145437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 146000 Counter(146000) 145937
Saved chunk: 20230922T004908F398725-5g3GwFHWql7SHJPayr7Bpp-3rYtHahzj296jLH1w12c95-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T004940F896763-2mxzHApO0VbAdutE6kC9Gn-6S9IL2cxCxyyDas4dh6Ygi-1024.npz
 Step 292998 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.7 / train/action_mean 0.5 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.8e-7 / train/actor_opt_grad_steps 7.2e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 9.3e-11 / train/cont_loss_std 5.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.61 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-6 / train/extr_critic_critic_opt_grad_steps 7.2e4 / train/extr_critic_critic_opt_loss 
2.8e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.35 / train/model_loss_mean 1.26 / train/model_loss_std 2.39 / train/model_opt_grad_norm 6.11 / 
train/model_opt_grad_steps 7.2e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8186.53 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.5e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.4e-4 / train/post_ent_mag 63.07 / train/post_ent_max 63.07 / train/post_ent_mean 40.25 / train/post_ent_min 24.7 / train/post_ent_std 4.9 / 
train/prior_ent_mag 68.6 / train/prior_ent_max 68.6 / train/prior_ent_mean 41.91 / train/prior_ent_min 31.11 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.61 / train/reward_avg 0 / train/reward_loss_mean 9.7e-12 / train/reward_loss_std 
3.1e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.7e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.7e-11 / report/cont_loss_std 5.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.7e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.82 / report/dyn_loss_std 3.9 / report/image_loss_mean 0.25 / report/image_loss_std 0.45 / report/model_loss_mean 1.34 / report/model_loss_std 2.62 / report/post_ent_mag 63.98 / report/post_ent_max 63.98 / report/post_ent_mean 39.41 / 
report/post_ent_min 22.24 / report/post_ent_std 5.54 / report/prior_ent_mag 68.91 / report/prior_ent_max 68.91 / report/prior_ent_mean 41.2 / report/prior_ent_min 25.65 / report/prior_ent_std 5.98 / report/rep_loss_mean 1.82 / report/rep_loss_std 3.9 / report/reward_avg 0
/ report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 8.3e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.71 / eval/dyn_loss_std 3.47 / 
eval/image_loss_mean 0.21 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.23 / eval/model_loss_std 2.24 / eval/post_ent_mag 63.6 / eval/post_ent_max 63.6 / eval/post_ent_mean 41.1 / eval/post_ent_min 26.21 / eval/post_ent_std 5.05 / eval/prior_ent_mag 68.91 / 
eval/prior_ent_max 68.91 / eval/prior_ent_mean 42.76 / eval/prior_ent_min 34.4 / eval/prior_ent_std 5.56 / eval/rep_loss_mean 1.71 / eval/rep_loss_std 3.47 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.5e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3844 / timer/env.step_total 18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 395.42 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7351 / timer/agent.policy_total 15.93 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1922 / timer/agent.train_total 247.03 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 
0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / 
timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.62

Starting evaluation at step 146500 Counter(146500) 146437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 147000 Counter(147000) 146937
Saved chunk: 20230922T005026F955934-3rYtHahzj296jLH1w12c95-4dAAvPS1NJqqJ6x434qKy2-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005100F972492-6S9IL2cxCxyyDas4dh6Ygi-07Eeusoza0n8WVieHlx1JR-1024.npz
Starting evaluation at step 147500 Counter(147500) 147437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 148000 Counter(148000) 147937
Saved chunk: 20230922T005146F526909-4dAAvPS1NJqqJ6x434qKy2-5uvUT1uhv8oyjjoO18DBTw-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005222F278287-07Eeusoza0n8WVieHlx1JR-21Xo4Ym5t0z8QknXjbt1uh-1024.npz
Starting evaluation at step 148500 Counter(148500) 148437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T005342F519803-21Xo4Ym5t0z8QknXjbt1uh-0000000000000000000000-420.npz
Saved chunk: 20230922T005305F313682-5uvUT1uhv8oyjjoO18DBTw-0000000000000000000000-916.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 149000 Counter(149000) 148937
Saved chunk: 20230922T005305F313682-5uvUT1uhv8oyjjoO18DBTw-5KgN4EuPLsEju4cXm3aOMX-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 149500 Counter(149500) 149437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005342F519803-21Xo4Ym5t0z8QknXjbt1uh-2bK0g2WJmfPRHg5jvRnGwv-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 150000 Counter(150000) 149937
Saved chunk: 20230922T005424F095630-5KgN4EuPLsEju4cXm3aOMX-5I7fHSol2WN0m7wpt9tZKp-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 300582 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_stats/mean_log_entropy 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.49 / train/action_min -3.94 / 
train/action_std 1.08 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.2e-7 / train/actor_opt_grad_steps 7.4e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / 
train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 8.6e-11 / train/cont_loss_std 6.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.6e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.76 / train/dyn_loss_std 3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-6 / train/extr_critic_critic_opt_grad_steps 7.4e4 / 
train/extr_critic_critic_opt_loss 2.8e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / 
train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / 
train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.34 / train/model_loss_mean 1.26 / train/model_loss_std 
2.42 / train/model_opt_grad_norm 6.05 / train/model_opt_grad_steps 7.4e4 / train/model_opt_loss 9397.76 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7486.77 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.4 / train/policy_entropy_std 5.3e-4 / train/policy_logprob_mag 9.51 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.51 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.3e-4 / train/post_ent_mag 63.1 / train/post_ent_max 63.1 / train/post_ent_mean 40.26 / train/post_ent_min 
24.94 / train/post_ent_std 4.82 / train/prior_ent_mag 68.61 / train/prior_ent_max 68.61 / train/prior_ent_mean 41.93 / train/prior_ent_min 31.56 / train/prior_ent_std 5.46 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.65 / train/reward_avg 0 / train/reward_loss_mean 0
/ train/reward_loss_std 0 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 6.2e-11 / report/cont_loss_std 3.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / 
report/dyn_loss_std 2.83 / report/image_loss_mean 0.15 / report/image_loss_std 0.22 / report/model_loss_mean 1.12 / report/model_loss_std 1.83 / report/post_ent_mag 63.87 / report/post_ent_max 63.87 / report/post_ent_mean 40.22 / report/post_ent_min 25.94 / 
report/post_ent_std 4.53 / report/prior_ent_mag 68.75 / report/prior_ent_max 68.75 / report/prior_ent_mean 41.93 / report/prior_ent_min 34.86 / report/prior_ent_std 5.06 / report/rep_loss_mean 1.62 / report/rep_loss_std 2.83 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 7.8e-11 / eval/cont_loss_std 4.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.78 / eval/dyn_loss_std 3.32 / eval/image_loss_mean 
0.22 / eval/image_loss_std 0.42 / eval/model_loss_mean 1.29 / eval/model_loss_std 2.32 / eval/post_ent_mag 64.05 / eval/post_ent_max 64.05 / eval/post_ent_mean 40.97 / eval/post_ent_min 25.56 / eval/post_ent_std 4.36 / eval/prior_ent_mag 68.75 / eval/prior_ent_max 68.75 /
eval/prior_ent_mean 42.56 / eval/prior_ent_min 34.9 / eval/prior_ent_std 4.83 / eval/rep_loss_mean 1.78 / eval/rep_loss_std 3.32 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.5e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.05 / timer/env.step_count 3792 / timer/env.step_total 18.69 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 388.13 / timer/replay._sample_frac 
1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7800 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 2.3e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.49 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 150500 Counter(150500) 150437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005506F187253-2bK0g2WJmfPRHg5jvRnGwv-4eXjD860lObhErOQ0zSpMV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 151000 Counter(151000) 150937
Saved chunk: 20230922T005542F522617-5I7fHSol2WN0m7wpt9tZKp-109lnIbZY2CEDrLCzSjyWl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 151500 Counter(151500) 151437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005627F026560-4eXjD860lObhErOQ0zSpMV-1FD3HoeDjiF57XPJXw6Xao-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 152000 Counter(152000) 151937
Saved chunk: 20230922T005702F038698-109lnIbZY2CEDrLCzSjyWl-5Bn1wNlAo5fQecFHyODy57-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 152500 Counter(152500) 152437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005747F457241-1FD3HoeDjiF57XPJXw6Xao-4REGZR2YkHmkORwyEcULL3-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 153000 Counter(153000) 152937
Saved chunk: 20230922T005820F792311-5Bn1wNlAo5fQecFHyODy57-3QywchcGkxVeptYP1CRtDV-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 153500 Counter(153500) 153437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T005907F730305-4REGZR2YkHmkORwyEcULL3-4bFaMvHdRXSovpFAN9CMG0-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 154000 Counter(154000) 153937
Saved chunk: 20230922T005939F401168-3QywchcGkxVeptYP1CRtDV-7wCOa3s0mFuLlbLBCOqDKa-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 308174 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.48 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.1e-7 / train/actor_opt_grad_steps 7.6e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7.9e-11 / train/cont_loss_std 5.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-6 / train/extr_critic_critic_opt_grad_steps 7.6e4 / train/extr_critic_critic_opt_loss 
3.2e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.33 / train/model_loss_mean 1.25 / train/model_loss_std 2.41 / train/model_opt_grad_norm 6.4 / 
train/model_opt_grad_steps 7.5e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9868.42 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.2e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 63.45 / train/post_ent_max 63.45 / train/post_ent_mean 40.35 / train/post_ent_min 24.29 / train/post_ent_std 4.88 / 
train/prior_ent_mag 68.82 / train/prior_ent_max 68.82 / train/prior_ent_mean 42.02 / train/prior_ent_min 30.69 / train/prior_ent_std 5.46 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.65 / train/reward_avg 0 / train/reward_loss_mean 9.8e-12 / train/reward_loss_std 
3.1e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.8e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 4.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.82 / report/dyn_loss_std 4.26 / report/image_loss_mean 0.25 / report/image_loss_std 0.4 / report/model_loss_mean 1.34 / report/model_loss_std 2.85 / report/post_ent_mag 63.32 / report/post_ent_max 63.32 / report/post_ent_mean 40.68 / 
report/post_ent_min 22.92 / report/post_ent_std 5.56 / report/prior_ent_mag 68.88 / report/prior_ent_max 68.88 / report/prior_ent_mean 42.38 / report/prior_ent_min 26.53 / report/prior_ent_std 5.88 / report/rep_loss_mean 1.82 / report/rep_loss_std 4.26 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 8.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.92 / eval/dyn_loss_std 3.74 / 
eval/image_loss_mean 0.26 / eval/image_loss_std 0.63 / eval/model_loss_mean 1.42 / eval/model_loss_std 2.64 / eval/post_ent_mag 62.91 / eval/post_ent_max 62.91 / eval/post_ent_mean 39.25 / eval/post_ent_min 21.69 / eval/post_ent_std 5.09 / eval/prior_ent_mag 68.88 / 
eval/prior_ent_max 68.88 / eval/prior_ent_mean 41.11 / eval/prior_ent_min 27.85 / eval/prior_ent_std 5.22 / eval/rep_loss_mean 1.92 / eval/rep_loss_std 3.74 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.5e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.4e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3796 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 389.43 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7804 / timer/agent.policy_total 16.88 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1898 / timer/agent.train_total 244.02 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / 
timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 154500 Counter(154500) 154437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010027F735736-4bFaMvHdRXSovpFAN9CMG0-5RTrxW19CdKFqutDOgh2hq-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 155000 Counter(155000) 154937
Saved chunk: 20230922T010057F797182-7wCOa3s0mFuLlbLBCOqDKa-4Rg4UnK2yWg4EWfuWzcWak-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 155500 Counter(155500) 155437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010148F760733-5RTrxW19CdKFqutDOgh2hq-51Am12fsB5voxxRNeRBpVe-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 156000 Counter(156000) 155937
Saved chunk: 20230922T010218F390415-4Rg4UnK2yWg4EWfuWzcWak-5DMu2W6Ci5HZUfIdams32E-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 156500 Counter(156500) 156437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010310F010310-51Am12fsB5voxxRNeRBpVe-0kBO7t7u9n1F2NOo0U9rS6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 157000 Counter(157000) 156937
Saved chunk: 20230922T010336F953200-5DMu2W6Ci5HZUfIdams32E-45ye9bQRaVpbHaii0NS4Dr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 157500 Counter(157500) 157437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010430F060773-0kBO7t7u9n1F2NOo0U9rS6-3K8D7TLqPAE44X5CQUecXi-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 315838 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.66 / train/action_mean 0.48 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.4e-7 / train/actor_opt_grad_steps 7.7e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7.6e-11 / train/cont_loss_std 4.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.8e-6 / train/extr_critic_critic_opt_grad_steps 7.7e4 / train/extr_critic_critic_opt_loss 
2.7e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.35 / train/model_loss_mean 1.26 / train/model_loss_std 2.42 / train/model_opt_grad_norm 6.29 / 
train/model_opt_grad_steps 7.7e4 / train/model_opt_loss 8944.82 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7083.33 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.5e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.4e-4 / train/post_ent_mag 63.66 / train/post_ent_max 63.66 / train/post_ent_mean 40.44 / train/post_ent_min 24.74 / train/post_ent_std 4.74 / 
train/prior_ent_mag 69.01 / train/prior_ent_max 69.01 / train/prior_ent_mean 42.1 / train/prior_ent_min 31.12 / train/prior_ent_std 5.36 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.64 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 7.1e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.83 / 
report/dyn_loss_std 3.97 / report/image_loss_mean 0.22 / report/image_loss_std 0.31 / report/model_loss_mean 1.31 / report/model_loss_std 2.59 / report/post_ent_mag 63.55 / report/post_ent_max 63.55 / report/post_ent_mean 41.42 / report/post_ent_min 26.59 / 
report/post_ent_std 4.73 / report/prior_ent_mag 69.05 / report/prior_ent_max 69.05 / report/prior_ent_mean 43.09 / report/prior_ent_min 33.73 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.83 / report/rep_loss_std 3.97 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 2.83 / eval/image_loss_mean 0.17 
/ eval/image_loss_std 0.22 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.83 / eval/post_ent_mag 64.04 / eval/post_ent_max 64.04 / eval/post_ent_mean 40.86 / eval/post_ent_min 25.17 / eval/post_ent_std 4.45 / eval/prior_ent_mag 69.05 / eval/prior_ent_max 69.05 / 
eval/prior_ent_mean 42.35 / eval/prior_ent_min 32.7 / eval/prior_ent_std 5.01 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 2.83 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.6e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
299.99 / timer/env.step_count 3832 / timer/env.step_total 18.91 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.29 / 
timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7339 / timer/agent.policy_total 15.81
/ timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 7.2e-3 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / 
timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1916 / timer/agent.train_total 247.19 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 1.12 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 158000 Counter(158000) 157937
Saved chunk: 20230922T010455F404180-45ye9bQRaVpbHaii0NS4Dr-3g1mXokQdVFi8mvOEWRJ0e-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 158500 Counter(158500) 158437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010550F018543-3K8D7TLqPAE44X5CQUecXi-2wS0klolDRFgVNFnyfFoIc-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 159000 Counter(159000) 158937
Saved chunk: 20230922T010614F510688-3g1mXokQdVFi8mvOEWRJ0e-05sLqZzk5PqxhFgF5qaYD4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 159500 Counter(159500) 159437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010711F101830-2wS0klolDRFgVNFnyfFoIc-0q9qoGVDX8bdJXVf1ikv6I-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 160000 Counter(160000) 159937
Saved chunk: 20230922T010733F414762-05sLqZzk5PqxhFgF5qaYD4-3XQm5Rh2zjg0UTeZvRWCbX-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T010831F319639-0q9qoGVDX8bdJXVf1ikv6I-0000000000000000000000-656.npz
Saved chunk: 20230922T010851F996346-3XQm5Rh2zjg0UTeZvRWCbX-0000000000000000000000-151.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 160500 Counter(160500) 160437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T010831F319639-0q9qoGVDX8bdJXVf1ikv6I-3F0eFaqFL5k0DGQEWPtzE0-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 161000 Counter(161000) 160937
Saved chunk: 20230922T010851F996346-3XQm5Rh2zjg0UTeZvRWCbX-4SnWh5ipyVc1rPmtbZlbuL-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 161500 Counter(161500) 161437
eval_Episode has 500 steps and return 0.0.
 Step 323430 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.63 / train/action_max 4.61 / train/action_mean 0.48 / train/action_min -3.97 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.6e-7 / train/actor_opt_grad_steps 7.9e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 8.7e-11 / train/cont_loss_std 7.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / 
train/dyn_loss_std 3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.1e-6 / train/extr_critic_critic_opt_grad_steps 7.9e4 / train/extr_critic_critic_opt_loss 
4e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.35 / train/model_loss_mean 1.27 / train/model_loss_std 2.44 / train/model_opt_grad_norm 6.05 / 
train/model_opt_grad_steps 7.9e4 / train/model_opt_loss 9706.06 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7645.5 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.6e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.4e-4 / train/post_ent_mag 63.67 / train/post_ent_max 63.67 / train/post_ent_mean 40.46 / train/post_ent_min 24.53 / train/post_ent_std 4.75 / 
train/prior_ent_mag 69.04 / train/prior_ent_max 69.04 / train/prior_ent_mean 42.15 / train/prior_ent_min 30.52 / train/prior_ent_std 5.38 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.68 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 8.8e-11 / report/cont_loss_std 3.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / 
report/dyn_loss_std 3.17 / report/image_loss_mean 0.21 / report/image_loss_std 0.27 / report/model_loss_mean 1.19 / report/model_loss_std 2.09 / report/post_ent_mag 63.98 / report/post_ent_max 63.98 / report/post_ent_mean 41.97 / report/post_ent_min 26.85 / 
report/post_ent_std 4.47 / report/prior_ent_mag 69.29 / report/prior_ent_max 69.29 / report/prior_ent_mean 43.29 / report/prior_ent_min 34.29 / report/prior_ent_std 4.81 / report/rep_loss_mean 1.64 / report/rep_loss_std 3.17 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.48 / eval/image_loss_mean 
0.16 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.62 / eval/post_ent_mag 63.93 / eval/post_ent_max 63.93 / eval/post_ent_mean 41.12 / eval/post_ent_min 28.65 / eval/post_ent_std 4.32 / eval/prior_ent_mag 69.29 / eval/prior_ent_max 69.29 /
eval/prior_ent_mean 42.73 / eval/prior_ent_min 34.75 / eval/prior_ent_std 4.85 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.48 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.6e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 
/ timer/env.step_count 3796 / timer/env.step_total 18.84 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3e4 / timer/replay._sample_total 386.54 / timer/replay._sample_frac 1.29 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7804 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T010951F547530-3F0eFaqFL5k0DGQEWPtzE0-5XItRAw2wPWhCQSwtPPFPk-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 162000 Counter(162000) 161937
Saved chunk: 20230922T011010F627276-4SnWh5ipyVc1rPmtbZlbuL-4IS0jK1tgpjsUCav84kz8i-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 162500 Counter(162500) 162437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011112F260433-5XItRAw2wPWhCQSwtPPFPk-1hJeS8NiIGZ6vl4L7v8ktU-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 163000 Counter(163000) 162937
Saved chunk: 20230922T011129F944541-4IS0jK1tgpjsUCav84kz8i-0mstA2AhFpiS0G249J95eb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 163500 Counter(163500) 163437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011232F854680-1hJeS8NiIGZ6vl4L7v8ktU-4gs9UzChvNAGZmQpFOP2Rb-1024.npz
Starting evaluation at step 164000 Counter(164000) 163937
Saved chunk: 20230922T011248F861893-0mstA2AhFpiS0G249J95eb-6sRcDjntBr6S3adGWr8L7Q-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 164500 Counter(164500) 164437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011353F018409-4gs9UzChvNAGZmQpFOP2Rb-5ieBz1UTGFasY4Inr9NWHX-1024.npz
Starting evaluation at step 165000 Counter(165000) 164937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011407F381650-6sRcDjntBr6S3adGWr8L7Q-418JY7wSPjhdefxPFRf8Oi-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 165500 Counter(165500) 165437
eval_Episode has 500 steps and return 0.0.
 Step 331026 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.47 / train/action_min -3.97 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.2e-7 / train/actor_opt_grad_steps 8.1e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7.1e-11 / train/cont_loss_std 5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.77 / train/dyn_loss_std 
3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2e-6 / train/extr_critic_critic_opt_grad_steps 8.1e4 / train/extr_critic_critic_opt_loss 2.8e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.35 / train/model_loss_mean 1.26 / train/model_loss_std 2.44 / train/model_opt_grad_norm 6.24 / 
train/model_opt_grad_steps 8.1e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 5.4e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.3e-4 / train/post_ent_mag 63.92 / train/post_ent_max 63.92 / train/post_ent_mean 40.43 / train/post_ent_min 24.72 / train/post_ent_std 4.75 / train/prior_ent_mag 69.22 / 
train/prior_ent_max 69.22 / train/prior_ent_mean 42.1 / train/prior_ent_min 30.33 / train/prior_ent_std 5.37 / train/rep_loss_mean 1.77 / train/rep_loss_std 3.68 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 6e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.76 / 
report/image_loss_mean 0.2 / report/image_loss_std 0.34 / report/model_loss_mean 1.23 / report/model_loss_std 2.49 / report/post_ent_mag 64.05 / report/post_ent_max 64.05 / report/post_ent_mean 41.08 / report/post_ent_min 18.34 / report/post_ent_std 5.26 / 
report/prior_ent_mag 69.11 / report/prior_ent_max 69.11 / report/prior_ent_mean 42.84 / report/prior_ent_min 34.75 / report/prior_ent_std 5.65 / report/rep_loss_mean 1.72 / report/rep_loss_std 3.76 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / 
eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 2.9 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.26 / 
eval/model_loss_mean 1.19 / eval/model_loss_std 1.9 / eval/post_ent_mag 63.71 / eval/post_ent_max 63.71 / eval/post_ent_mean 40.68 / eval/post_ent_min 27.11 / eval/post_ent_std 4.7 / eval/prior_ent_mag 69.11 / eval/prior_ent_max 69.11 / eval/prior_ent_mean 42.38 / 
eval/prior_ent_min 32.46 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 2.9 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.7e5 / replay/inserts 3798 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / 
timer/env.step_count 3798 / timer/env.step_total 18.83 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.51 / timer/replay._sample_frac 1.3 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7806 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 1e-2 / timer/dataset_train_count 1899 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1899 / timer/agent.train_total 244 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.31

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011513F039255-5ieBz1UTGFasY4Inr9NWHX-4iLkT6g8d9F0fzpXYI9G3P-1024.npz
Starting evaluation at step 166000 Counter(166000) 165937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011525F799141-418JY7wSPjhdefxPFRf8Oi-28PvMh8TJdoz13X6GBVfm4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 166500 Counter(166500) 166437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011633F767957-4iLkT6g8d9F0fzpXYI9G3P-3EspG5qrrYmEtRl0IvUhQ4-1024.npz
Starting evaluation at step 167000 Counter(167000) 166937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 167500 Counter(167500) 167437
Saved chunk: 20230922T011645F064394-28PvMh8TJdoz13X6GBVfm4-1M1D8vKNWOWEPbrXSbyHhv-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011754F225581-3EspG5qrrYmEtRl0IvUhQ4-1N1LUYOj1SwN0D00K4Qky0-1024.npz
Starting evaluation at step 168000 Counter(168000) 167937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 168500 Counter(168500) 168437
Saved chunk: 20230922T011839F786750-1M1D8vKNWOWEPbrXSbyHhv-1B78j08kLTvjTjQJVJHBHY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T011914F428471-1N1LUYOj1SwN0D00K4Qky0-0zVcPLALT3ngUVGTRJxAmZ-1024.npz
Starting evaluation at step 169000 Counter(169000) 168937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 338718 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.47 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.6e-7 / train/actor_opt_grad_steps 8.3e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 6.8e-11 / train/cont_loss_std 4.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.64 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.5e-6 / train/extr_critic_critic_opt_grad_steps 8.3e4 / train/extr_critic_critic_opt_loss 
3.4e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.36 / train/model_loss_mean 1.25 / train/model_loss_std 2.43 / train/model_opt_grad_norm 6.08 / 
train/model_opt_grad_steps 8.3e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 8575.13 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.1e-4 / train/policy_logprob_mag 9.51 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.51 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 64.06 / train/post_ent_max 64.06 / train/post_ent_mean 40.46 / train/post_ent_min 25.06 / train/post_ent_std 4.72 / 
train/prior_ent_mag 69.14 / train/prior_ent_max 69.14 / train/prior_ent_mean 42.1 / train/prior_ent_min 31.19 / train/prior_ent_std 5.34 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.64 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 6.7e-11 / report/cont_loss_std 2.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / 
report/dyn_loss_std 2.51 / report/image_loss_mean 0.15 / report/image_loss_std 0.2 / report/model_loss_mean 1.08 / report/model_loss_std 1.6 / report/post_ent_mag 63.57 / report/post_ent_max 63.57 / report/post_ent_mean 40.52 / report/post_ent_min 27.6 / 
report/post_ent_std 4.65 / report/prior_ent_mag 68.9 / report/prior_ent_max 68.9 / report/prior_ent_mean 42.14 / report/prior_ent_min 33.52 / report/prior_ent_std 5.26 / report/rep_loss_mean 1.55 / report/rep_loss_std 2.51 / report/reward_avg 0 / report/reward_loss_mean 0
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.88 / eval/dyn_loss_std 3.78 / eval/image_loss_mean 
0.18 / eval/image_loss_std 0.38 / eval/model_loss_mean 1.3 / eval/model_loss_std 2.55 / eval/post_ent_mag 62.86 / eval/post_ent_max 62.86 / eval/post_ent_mean 40.07 / eval/post_ent_min 26.02 / eval/post_ent_std 4.25 / eval/prior_ent_mag 68.9 / eval/prior_ent_max 68.9 / 
eval/prior_ent_mean 41.84 / eval/prior_ent_min 32.77 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 1.88 / eval/rep_loss_std 3.78 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.7e5 / replay/inserts 3846 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.12 / timer/env.step_count 3846 / timer/env.step_total 18.99 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.25 / 
timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7353 / timer/agent.policy_total 
15.91 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.6e-3 / timer/dataset_train_count 1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / 
timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1923 / timer/agent.train_total 247.12 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / 
timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 169500 Counter(169500) 169437
Saved chunk: 20230922T011958F340593-1B78j08kLTvjTjQJVJHBHY-59ijTHIcN4y1bfIIaC7KnC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012034F428197-0zVcPLALT3ngUVGTRJxAmZ-0JTDGHQCQVUmroP0zQXAxs-1024.npz
Starting evaluation at step 170000 Counter(170000) 169937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 170500 Counter(170500) 170437
Saved chunk: 20230922T012117F414818-59ijTHIcN4y1bfIIaC7KnC-2ZjwQyttZokde6WuOkRHOY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 171000 Counter(171000) 170937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012155F387829-0JTDGHQCQVUmroP0zQXAxs-0DuWgFHat78tsmxyrMKvYm-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 171500 Counter(171500) 171437
Saved chunk: 20230922T012236F289958-2ZjwQyttZokde6WuOkRHOY-7euJhdC9F4v8FofW7vnOhW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T012355F024775-7euJhdC9F4v8FofW7vnOhW-0000000000000000000000-410.npz
Saved chunk: 20230922T012319F104462-0DuWgFHat78tsmxyrMKvYm-0000000000000000000000-892.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 172000 Counter(172000) 171937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012319F104462-0DuWgFHat78tsmxyrMKvYm-6Wnh71HIKd5tkLGX6CEqcb-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 172500 Counter(172500) 172437
Saved chunk: 20230922T012355F024775-7euJhdC9F4v8FofW7vnOhW-1xFSmewdOdOadZOPi9lhtf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 173000 Counter(173000) 172937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012439F516411-6Wnh71HIKd5tkLGX6CEqcb-08CQg49aZwOFyV6cqt5tgc-1024.npz
 Step 346306 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.47 / train/action_min -3.95 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 7.1e-7 / train/actor_opt_grad_steps 8.5e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7.8e-11 / train/cont_loss_std 7.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.76 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1e-6 / train/extr_critic_critic_opt_grad_steps 8.5e4 / train/extr_critic_critic_opt_loss 
1.8e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.36 / train/model_loss_mean 1.27 / train/model_loss_std 2.5 / train/model_opt_grad_norm 6.12 / 
train/model_opt_grad_steps 8.5e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7910.05 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.6e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.4e-4 / train/post_ent_mag 64.08 / train/post_ent_max 64.08 / train/post_ent_mean 40.44 / train/post_ent_min 24.38 / train/post_ent_std 4.78 / 
train/prior_ent_mag 69.14 / train/prior_ent_max 69.14 / train/prior_ent_mean 42.1 / train/prior_ent_min 30.47 / train/prior_ent_std 5.4 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.76 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.81 / 
report/dyn_loss_std 3.87 / report/image_loss_mean 0.15 / report/image_loss_std 0.24 / report/model_loss_mean 1.24 / report/model_loss_std 2.48 / report/post_ent_mag 65.07 / report/post_ent_max 65.07 / report/post_ent_mean 40.11 / report/post_ent_min 27.54 / 
report/post_ent_std 4.17 / report/prior_ent_mag 69.53 / report/prior_ent_max 69.53 / report/prior_ent_mean 41.54 / report/prior_ent_min 33.88 / report/prior_ent_std 5.4 / report/rep_loss_mean 1.81 / report/rep_loss_std 3.87 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 9.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 2.74 / eval/image_loss_mean 
0.17 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.79 / eval/post_ent_mag 64.79 / eval/post_ent_max 64.79 / eval/post_ent_mean 40.9 / eval/post_ent_min 25.59 / eval/post_ent_std 4.62 / eval/prior_ent_mag 69.53 / eval/prior_ent_max 69.53 / 
eval/prior_ent_mean 42.4 / eval/prior_ent_min 33.55 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 2.74 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.7e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.05 / timer/env.step_count 3794 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.84 / timer/replay._sample_frac 
1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 
0.11 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.92 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1897 / timer/agent.train_total 243.8 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min
0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 173500 Counter(173500) 173437
Saved chunk: 20230922T012513F694143-1xFSmewdOdOadZOPi9lhtf-6A1ZaWGPU7M4b46jXyDRVz-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 174000 Counter(174000) 173937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012559F419767-08CQg49aZwOFyV6cqt5tgc-1KgxkD7GkfLOgaVaQK87tV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 174500 Counter(174500) 174437
Saved chunk: 20230922T012632F997132-6A1ZaWGPU7M4b46jXyDRVz-3rdByBqGZfqaFjWgB9AvNd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 175000 Counter(175000) 174937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012720F690242-1KgxkD7GkfLOgaVaQK87tV-5UZuvUFATWf2kr97qEKcEx-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 175500 Counter(175500) 175437
Saved chunk: 20230922T012751F887246-3rdByBqGZfqaFjWgB9AvNd-5kPtiTgwolwabDJKleJoMm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 176000 Counter(176000) 175937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T012840F897465-5UZuvUFATWf2kr97qEKcEx-5RIuHKu5yHVs1N55Uqd7bT-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 176500 Counter(176500) 176437
Saved chunk: 20230922T012910F513549-5kPtiTgwolwabDJKleJoMm-6DpwlgADaGrmdGMLenqw6y-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 353986 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.47 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.6e-7 / train/actor_opt_grad_steps 8.7e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7.3e-11 / train/cont_loss_std 7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / train/dyn_loss_std 
3.62 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.5e-6 / train/extr_critic_critic_opt_grad_steps 8.7e4 / train/extr_critic_critic_opt_loss 6.7e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.2 / train/image_loss_std 0.34 / train/model_loss_mean 1.25 / train/model_loss_std 2.4 / train/model_opt_grad_norm 5.95 / 
train/model_opt_grad_steps 8.7e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8255.21 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.1e-4 / train/policy_logprob_mag 9.51 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.51 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 64.14 / train/post_ent_max 64.14 / train/post_ent_mean 40.66 / train/post_ent_min 24.74 / train/post_ent_std 4.75 / 
train/prior_ent_mag 69.15 / train/prior_ent_max 69.15 / train/prior_ent_mean 42.29 / train/prior_ent_min 31.4 / train/prior_ent_std 5.36 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.62 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / 
report/dyn_loss_std 2.95 / report/image_loss_mean 0.14 / report/image_loss_std 0.23 / report/model_loss_mean 1.1 / report/model_loss_std 1.94 / report/post_ent_mag 63.65 / report/post_ent_max 63.65 / report/post_ent_mean 40.79 / report/post_ent_min 29.65 / 
report/post_ent_std 4.33 / report/prior_ent_mag 68.95 / report/prior_ent_max 68.95 / report/prior_ent_mean 42.36 / report/prior_ent_min 34.18 / report/prior_ent_std 4.87 / report/rep_loss_mean 1.6 / report/rep_loss_std 2.95 / report/reward_avg 0 / report/reward_loss_mean 
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.6e-10 / eval/cont_loss_std 2.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.83 / eval/dyn_loss_std 3.61 / eval/image_loss_mean 0.22
/ eval/image_loss_std 0.37 / eval/model_loss_mean 1.32 / eval/model_loss_std 2.42 / eval/post_ent_mag 62.96 / eval/post_ent_max 62.96 / eval/post_ent_mean 41.49 / eval/post_ent_min 19.27 / eval/post_ent_std 4.86 / eval/prior_ent_mag 68.95 / eval/prior_ent_max 68.95 / 
eval/prior_ent_mean 43.23 / eval/prior_ent_min 30.55 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 1.83 / eval/rep_loss_std 3.61 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.8e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.08 / timer/env.step_count 3840 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.45 / timer/replay._sample_frac 
1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7347 / timer/agent.policy_total 15.87 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 8.6e-3 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / 
timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.98 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 177000 Counter(177000) 176937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013001F118944-5RIuHKu5yHVs1N55Uqd7bT-2PZAqREOzK9C4ewmAWbq4l-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 177500 Counter(177500) 177437
Saved chunk: 20230922T013029F129790-6DpwlgADaGrmdGMLenqw6y-4QizEXqrymYNIOPq8GAJym-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 178000 Counter(178000) 177937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013122F154474-2PZAqREOzK9C4ewmAWbq4l-6AZCbtwlf409Ka1GW5Pb2K-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 178500 Counter(178500) 178437
Saved chunk: 20230922T013148F738327-4QizEXqrymYNIOPq8GAJym-0gTv6zxS4cV8GvpWtsIpnD-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 179000 Counter(179000) 178937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013242F656429-6AZCbtwlf409Ka1GW5Pb2K-1o3fk6Mb1cmnUq6TpeGXKj-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 179500 Counter(179500) 179437
Saved chunk: 20230922T013307F518356-0gTv6zxS4cV8GvpWtsIpnD-5GQU3Oeck7cxxsqqZ5LxF8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 180000 Counter(180000) 179937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013402F844604-1o3fk6Mb1cmnUq6TpeGXKj-6qBf2ubcGWFVFH6l3dd8PP-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 180500 Counter(180500) 180437
Saved chunk: 20230922T013426F148837-5GQU3Oeck7cxxsqqZ5LxF8-5u8sKSFgmtfEI4XvQNymdO-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 361574 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.63 / train/action_max 4.62 / train/action_mean 0.46 / train/action_min -3.91 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.6e-7 / train/actor_opt_grad_steps 8.9e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 6.4e-11 / train/cont_loss_std 4.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.75 / 
train/dyn_loss_std 3.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 8.4e-7 / train/extr_critic_critic_opt_grad_steps 8.9e4 / train/extr_critic_critic_opt_loss 
1.5e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.19 / train/image_loss_std 0.33 / train/model_loss_mean 1.24 / train/model_loss_std 2.4 / train/model_opt_grad_norm 6.34 / 
train/model_opt_grad_steps 8.9e4 / train/model_opt_loss 9135.68 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7368.42 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 5.1e-4 / train/policy_logprob_mag 9.58 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.58 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 64.13 / train/post_ent_max 64.13 / train/post_ent_mean 40.66 / train/post_ent_min 25.23 / train/post_ent_std 4.78 / 
train/prior_ent_mag 69.09 / train/prior_ent_max 69.09 / train/prior_ent_mean 42.3 / train/prior_ent_min 31.56 / train/prior_ent_std 5.38 / train/rep_loss_mean 1.75 / train/rep_loss_std 3.63 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / 
report/dyn_loss_std 4.38 / report/image_loss_mean 0.2 / report/image_loss_std 0.4 / report/model_loss_mean 1.31 / report/model_loss_std 2.95 / report/post_ent_mag 63.34 / report/post_ent_max 63.34 / report/post_ent_mean 41.11 / report/post_ent_min 20.26 / 
report/post_ent_std 5.01 / report/prior_ent_mag 69.34 / report/prior_ent_max 69.34 / report/prior_ent_mean 42.68 / report/prior_ent_min 29.48 / report/prior_ent_std 5.68 / report/rep_loss_mean 1.84 / report/rep_loss_std 4.38 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.65 / eval/dyn_loss_std 3.15 / eval/image_loss_mean 
0.16 / eval/image_loss_std 0.37 / eval/model_loss_mean 1.15 / eval/model_loss_std 2.15 / eval/post_ent_mag 63.34 / eval/post_ent_max 63.34 / eval/post_ent_mean 40.09 / eval/post_ent_min 28.36 / eval/post_ent_std 4.13 / eval/prior_ent_mag 69.34 / eval/prior_ent_max 69.34 /
eval/prior_ent_mean 41.79 / eval/prior_ent_min 33.58 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.65 / eval/rep_loss_std 3.15 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.8e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.11 / timer/env.step_count 3794 / timer/env.step_total 18.73 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 386.92 / timer/replay._sample_frac 
1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 17.02 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.8e-5 / 
timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1897 / timer/agent.train_total 243.78 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 
/ timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / 
timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 181000 Counter(181000) 180937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013522F893870-6qBf2ubcGWFVFH6l3dd8PP-5KdmNyLaDdu4xFy3umxGtD-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 181500 Counter(181500) 181437
Saved chunk: 20230922T013544F617446-5u8sKSFgmtfEI4XvQNymdO-1Pa3wEoTuJ1hVSZ8MZyJxs-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 182000 Counter(182000) 181937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013643F913065-5KdmNyLaDdu4xFy3umxGtD-5LgJq50yzBU5GA61ALY9R4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 182500 Counter(182500) 182437
Saved chunk: 20230922T013704F162292-1Pa3wEoTuJ1hVSZ8MZyJxs-39m0zbfeEjJlYiNYiKemNf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 183000 Counter(183000) 182937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013804F298966-5LgJq50yzBU5GA61ALY9R4-19Wrh7jrD7JrCgWsdvZ6rl-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T013822F877233-39m0zbfeEjJlYiNYiKemNf-0000000000000000000000-669.npz
Saved chunk: 20230922T013924F468248-19Wrh7jrD7JrCgWsdvZ6rl-0000000000000000000000-104.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 183500 Counter(183500) 183437
Saved chunk: 20230922T013822F877233-39m0zbfeEjJlYiNYiKemNf-7x4B89meQRC54Xcwl9HSCK-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 184000 Counter(184000) 183937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T013924F468248-19Wrh7jrD7JrCgWsdvZ6rl-6z5Rp1qErCS3608MJ9ZbW0-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 184500 Counter(184500) 184437
Saved chunk: 20230922T013941F678279-7x4B89meQRC54Xcwl9HSCK-7sFDIvDvmYWxvhDuAvNrg3-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 369158 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.47 / train/action_min -3.97 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.3e-7 / train/actor_opt_grad_steps 9.1e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.75 / 
train/dyn_loss_std 3.61 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.4e-6 / train/extr_critic_critic_opt_grad_steps 9.1e4 / train/extr_critic_critic_opt_loss 
2.1e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.19 / train/image_loss_std 0.34 / train/model_loss_mean 1.24 / train/model_loss_std 2.4 / train/model_opt_grad_norm 5.99 / 
train/model_opt_grad_steps 9.1e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 5.1e-4 / train/policy_logprob_mag 9.58 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.58 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 64.31 / train/post_ent_max 64.31 / train/post_ent_mean 40.54 / train/post_ent_min 25.2 / train/post_ent_std 4.69 / train/prior_ent_mag 69.17 / 
train/prior_ent_max 69.17 / train/prior_ent_mean 42.17 / train/prior_ent_min 31.25 / train/prior_ent_std 5.33 / train/rep_loss_mean 1.75 / train/rep_loss_std 3.61 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 6.9e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / report/dyn_loss_std 3.27 / 
report/image_loss_mean 0.18 / report/image_loss_std 0.28 / report/model_loss_mean 1.23 / report/model_loss_std 2.13 / report/post_ent_mag 63.23 / report/post_ent_max 63.23 / report/post_ent_mean 40.44 / report/post_ent_min 27.99 / report/post_ent_std 4.47 / 
report/prior_ent_mag 68.93 / report/prior_ent_max 68.93 / report/prior_ent_mean 42.25 / report/prior_ent_min 31.63 / report/prior_ent_std 5.1 / report/rep_loss_mean 1.75 / report/rep_loss_std 3.27 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.9e-11 / 
eval/cont_loss_std 2.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.88 / eval/dyn_loss_std 3.8 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.29 / 
eval/model_loss_mean 1.35 / eval/model_loss_std 2.45 / eval/post_ent_mag 63.22 / eval/post_ent_max 63.22 / eval/post_ent_mean 41.29 / eval/post_ent_min 25.69 / eval/post_ent_std 4.78 / eval/prior_ent_mag 68.93 / eval/prior_ent_max 68.93 / eval/prior_ent_mean 43.16 / 
eval/prior_ent_min 31.54 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 1.88 / eval/rep_loss_std 3.8 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.8e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3792 / timer/env.step_total 18.84 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.14 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7800 / timer/agent.policy_total 16.9 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.87 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 185000 Counter(185000) 184937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014044F762999-6z5Rp1qErCS3608MJ9ZbW0-0eqbiYcN5kwg2XQYQfxu0Q-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 185500 Counter(185500) 185437
Saved chunk: 20230922T014100F143511-7sFDIvDvmYWxvhDuAvNrg3-3aGGA92MwyfYc87O4S76eP-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 186000 Counter(186000) 185937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014205F909370-0eqbiYcN5kwg2XQYQfxu0Q-4u4KXVPNCByHciwuRyGFoX-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 186500 Counter(186500) 186437
Saved chunk: 20230922T014219F810510-3aGGA92MwyfYc87O4S76eP-0M8aped08yQayPkUQh9jGT-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 187000 Counter(187000) 186937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014326F193506-4u4KXVPNCByHciwuRyGFoX-4sQitJHcQtwIIEx05fBM3t-1024.npz
Starting evaluation at step 187500 Counter(187500) 187437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014338F496795-0M8aped08yQayPkUQh9jGT-6AyXD9hwzd5yKuKAElw6FY-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 188000 Counter(188000) 187937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014446F460877-4sQitJHcQtwIIEx05fBM3t-1lJJkWVDvo7f2tv1VJEgon-1024.npz
 Step 376842 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.46 / train/action_min -3.97 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.5e-7 / train/actor_opt_grad_steps 9.3e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 5.6e-11 / train/cont_loss_std 3.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4e-6 / train/extr_critic_critic_opt_grad_steps 9.3e4 / train/extr_critic_critic_opt_loss 
4.9e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.19 / train/image_loss_std 0.34 / train/model_loss_mean 1.25 / train/model_loss_std 2.41 / train/model_opt_grad_norm 6.15 / 
train/model_opt_grad_steps 9.3e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 5e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 64.26 / train/post_ent_max 64.26 / train/post_ent_mean 40.66 / train/post_ent_min 24.77 / train/post_ent_std 4.75 / train/prior_ent_mag 69.15 / 
train/prior_ent_max 69.15 / train/prior_ent_mean 42.29 / train/prior_ent_min 30.71 / train/prior_ent_std 5.36 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.63 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 3.6e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.71 / report/dyn_loss_std 3.33 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.25 / report/model_loss_mean 1.16 / report/model_loss_std 2.16 / report/post_ent_mag 64.31 / report/post_ent_max 64.31 / report/post_ent_mean 39.99 / report/post_ent_min 26.75 / report/post_ent_std 3.76 / 
report/prior_ent_mag 68.84 / report/prior_ent_max 68.84 / report/prior_ent_mean 41.56 / report/prior_ent_min 29.48 / report/prior_ent_std 4.61 / report/rep_loss_mean 1.71 / report/rep_loss_std 3.33 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / 
eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.89 / eval/dyn_loss_std 3.55 / eval/image_loss_mean 0.22 / eval/image_loss_std 0.36 /
eval/model_loss_mean 1.36 / eval/model_loss_std 2.36 / eval/post_ent_mag 64.64 / eval/post_ent_max 64.64 / eval/post_ent_mean 40.46 / eval/post_ent_min 24.48 / eval/post_ent_std 4.88 / eval/prior_ent_mag 68.84 / eval/prior_ent_max 68.84 / eval/prior_ent_mean 42.14 / 
eval/prior_ent_min 26.07 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.89 / eval/rep_loss_std 3.55 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.9e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / 
timer/env.step_count 3842 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.69 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7349 / timer/agent.policy_total 15.92 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.1e-3 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1921 / timer/agent.train_total 247 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 188500 Counter(188500) 188437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014457F165537-6AyXD9hwzd5yKuKAElw6FY-3OMkdFDfGjoRROjADswmlo-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 189000 Counter(189000) 188937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014606F436937-1lJJkWVDvo7f2tv1VJEgon-19CM44KjvFX1cYT2M4gtsT-1024.npz
Starting evaluation at step 189500 Counter(189500) 189437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014616F306857-3OMkdFDfGjoRROjADswmlo-6OHFJIbQPF5j80BK4q5iH3-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 190000 Counter(190000) 189937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014727F667925-19CM44KjvFX1cYT2M4gtsT-5Pp0l1WgcSbf4HSX1obbZO-1024.npz
Starting evaluation at step 190500 Counter(190500) 190437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 191000 Counter(191000) 190937
Saved chunk: 20230922T014735F224906-6OHFJIbQPF5j80BK4q5iH3-1qRePyzcTR20gjdzuyTOSQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T014847F898072-5Pp0l1WgcSbf4HSX1obbZO-4tvdTOZDid58GsW1TRwS5M-1024.npz
Starting evaluation at step 191500 Counter(191500) 191437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 192000 Counter(192000) 191937
Saved chunk: 20230922T014929F695668-1qRePyzcTR20gjdzuyTOSQ-1LkWMDROjT7izb1gW4itQs-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 384434 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.45 / train/action_min -3.94 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 6.3e-7 / train/actor_opt_grad_steps 9.5e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.9e-6 / train/extr_critic_critic_opt_grad_steps 9.5e4 / train/extr_critic_critic_opt_loss 
2.6e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.19 / train/image_loss_std 0.32 / train/model_loss_mean 1.23 / train/model_loss_std 2.34 / train/model_opt_grad_norm 6.39 / 
train/model_opt_grad_steps 9.5e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 5.1e-4 / train/policy_logprob_mag 9.45 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.45 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2.2e-4 / train/post_ent_mag 64.39 / train/post_ent_max 64.39 / train/post_ent_mean 40.62 / train/post_ent_min 24.77 / train/post_ent_std 4.64 / train/prior_ent_mag 68.96 / 
train/prior_ent_max 68.96 / train/prior_ent_mean 42.23 / train/prior_ent_min 30.64 / train/prior_ent_std 5.24 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.55 / train/reward_avg 0 / train/reward_loss_mean 9.9e-12 / train/reward_loss_std 3.2e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 
/ report/cont_loss_mean 4.7e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.86 / report/dyn_loss_std 4.21 / 
report/image_loss_mean 0.2 / report/image_loss_std 0.41 / report/model_loss_mean 1.32 / report/model_loss_std 2.85 / report/post_ent_mag 64.43 / report/post_ent_max 64.43 / report/post_ent_mean 40.93 / report/post_ent_min 23.04 / report/post_ent_std 4.7 / 
report/prior_ent_mag 68.96 / report/prior_ent_max 68.96 / report/prior_ent_mean 42.38 / report/prior_ent_min 32.05 / report/prior_ent_std 5.4 / report/rep_loss_mean 1.86 / report/rep_loss_std 4.21 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.8 / eval/dyn_loss_std 3.78 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.4 / 
eval/model_loss_mean 1.27 / eval/model_loss_std 2.56 / eval/post_ent_mag 64.14 / eval/post_ent_max 64.14 / eval/post_ent_mean 40.21 / eval/post_ent_min 22.53 / eval/post_ent_std 4.89 / eval/prior_ent_mag 68.96 / eval/prior_ent_max 68.96 / eval/prior_ent_mean 41.96 / 
eval/prior_ent_min 28.99 / eval/prior_ent_std 5.33 / eval/rep_loss_mean 1.8 / eval/rep_loss_std 3.78 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.9e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / 
timer/env.step_count 3796 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 388.89 / timer/replay._sample_frac 1.3 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.96 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.31

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 192500 Counter(192500) 192437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015007F945304-4tvdTOZDid58GsW1TRwS5M-2DbKWZkVH1qN3HAe7ehliU-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 193000 Counter(193000) 192937
Saved chunk: 20230922T015048F128144-1LkWMDROjT7izb1gW4itQs-55eJ27eG6kz5cW9SXzd2EO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 193500 Counter(193500) 193437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015132F211761-2DbKWZkVH1qN3HAe7ehliU-44cqcZekh8KRSkAgM2k3V1-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 194000 Counter(194000) 193937
Saved chunk: 20230922T015207F704410-55eJ27eG6kz5cW9SXzd2EO-0WXd8UHwj0zI2LchZkDTJU-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 194500 Counter(194500) 194437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015252F639774-44cqcZekh8KRSkAgM2k3V1-42K95PPkX4Ks2phdbiLZl9-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T015326F439287-0WXd8UHwj0zI2LchZkDTJU-0000000000000000000000-928.npz
Saved chunk: 20230922T015412F900413-42K95PPkX4Ks2phdbiLZl9-0000000000000000000000-340.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 195000 Counter(195000) 194937
Saved chunk: 20230922T015326F439287-0WXd8UHwj0zI2LchZkDTJU-7xYhF0FBKreZARrZ5pUil1-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 195500 Counter(195500) 195437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015412F900413-42K95PPkX4Ks2phdbiLZl9-58wkU0ZjPiSvSq4cC6d88H-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 196000 Counter(196000) 195937
Saved chunk: 20230922T015445F348716-7xYhF0FBKreZARrZ5pUil1-4FOyWIWLClYsUgQ84lEf0b-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 392014 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.67 / train/action_mean 0.45 / train/action_min -3.94 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.7e-7 / train/actor_opt_grad_steps 9.7e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 6.5e-11 / train/cont_loss_std 7.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.2e-7 / train/extr_critic_critic_opt_grad_steps 9.7e4 / train/extr_critic_critic_opt_loss 
1.5e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.32 / train/model_loss_mean 1.22 / train/model_loss_std 2.33 / train/model_opt_grad_norm 5.85 / 
train/model_opt_grad_steps 9.6e4 / train/model_opt_loss 9015.83 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7368.42 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 4.6e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2e-4 / train/post_ent_mag 64.7 / train/post_ent_max 64.7 / train/post_ent_mean 40.74 / train/post_ent_min 24.5 / train/post_ent_std 4.64 / 
train/prior_ent_mag 69.23 / train/prior_ent_max 69.23 / train/prior_ent_mean 42.32 / train/prior_ent_min 30.36 / train/prior_ent_std 5.25 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.52 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 
1.6e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.5e-11 / report/cont_loss_std 5.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.5e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.89 / report/dyn_loss_std 3.64 / report/image_loss_mean 0.22 / report/image_loss_std 0.3 / report/model_loss_mean 1.36 / report/model_loss_std 2.36 / report/post_ent_mag 65.01 / report/post_ent_max 65.01 / report/post_ent_mean 41.05 / 
report/post_ent_min 25.84 / report/post_ent_std 5.39 / report/prior_ent_mag 69.32 / report/prior_ent_max 69.32 / report/prior_ent_mean 42.63 / report/prior_ent_min 27.85 / report/prior_ent_std 6.17 / report/rep_loss_mean 1.89 / report/rep_loss_std 3.64 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 9.3e-11 / eval/cont_loss_std 1.8e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.5 / eval/dyn_loss_std 5.71 / 
eval/image_loss_mean 0.44 / eval/image_loss_std 1.56 / eval/model_loss_mean 1.94 / eval/model_loss_std 4.57 / eval/post_ent_mag 65.01 / eval/post_ent_max 65.01 / eval/post_ent_mean 40.27 / eval/post_ent_min 18.73 / eval/post_ent_std 5.48 / eval/prior_ent_mag 69.32 / 
eval/prior_ent_max 69.32 / eval/prior_ent_mean 42.14 / eval/prior_ent_min 26.17 / eval/prior_ent_std 5.92 / eval/rep_loss_mean 2.5 / eval/rep_loss_std 5.71 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3790 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.05 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 390.81 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / 
timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7798 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.13 / 
timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.64 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 196500 Counter(196500) 196437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015533F224212-58wkU0ZjPiSvSq4cC6d88H-5YHMaA2IsKuDa9tSy2oZh7-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 197000 Counter(197000) 196937
Saved chunk: 20230922T015603F744469-4FOyWIWLClYsUgQ84lEf0b-7z3HszM1csztW6Rkn4n7uO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 197500 Counter(197500) 197437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015654F239702-5YHMaA2IsKuDa9tSy2oZh7-26VVbWdMfaUDkEfos70Hyk-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 198000 Counter(198000) 197937
Saved chunk: 20230922T015723F374348-7z3HszM1csztW6Rkn4n7uO-2qFT2fBIvIyvhxPmkHfOgi-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 198500 Counter(198500) 198437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015814F577450-26VVbWdMfaUDkEfos70Hyk-2Q4NXFZ4gzvwS0PFbHaSlu-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 199000 Counter(199000) 198937
Saved chunk: 20230922T015842F021146-2qFT2fBIvIyvhxPmkHfOgi-5mYe4FwNy24j6rZmR5DLwf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 199500 Counter(199500) 199437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T015934F726881-2Q4NXFZ4gzvwS0PFbHaSlu-1QuAy7tn28pio98RIkGHMh-1024.npz
 Step 399698 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.66 / train/action_mean 0.45 / train/action_min -3.95 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.7e-7 / train/actor_opt_grad_steps 9.8e4 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 5.3e-11 / train/cont_loss_std 4.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.6 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.1e-6 / train/extr_critic_critic_opt_grad_steps 9.8e4 / train/extr_critic_critic_opt_loss 
5.3e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.33 / train/model_loss_mean 1.23 / train/model_loss_std 2.38 / train/model_opt_grad_norm 5.5 / 
train/model_opt_grad_steps 9.8e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.7e-4 / train/policy_logprob_mag 9.41 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.41 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2e-4 / train/post_ent_mag 64.95 / train/post_ent_max 64.95 / train/post_ent_mean 40.71 / train/post_ent_min 24.75 / train/post_ent_std 4.58 / train/prior_ent_mag 69.28 / 
train/prior_ent_max 69.28 / train/prior_ent_mean 42.31 / train/prior_ent_min 30.87 / train/prior_ent_std 5.22 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.6 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 8.8e-11 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.87 / report/dyn_loss_std 3.82 / 
report/image_loss_mean 0.23 / report/image_loss_std 0.39 / report/model_loss_mean 1.35 / report/model_loss_std 2.58 / report/post_ent_mag 65.02 / report/post_ent_max 65.02 / report/post_ent_mean 40.04 / report/post_ent_min 22.68 / report/post_ent_std 5.47 / 
report/prior_ent_mag 69.51 / report/prior_ent_max 69.51 / report/prior_ent_mean 41.71 / report/prior_ent_min 27.79 / report/prior_ent_std 6.02 / report/rep_loss_mean 1.87 / report/rep_loss_std 3.82 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / 
eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 3.24 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.25 /
eval/model_loss_mean 1.19 / eval/model_loss_std 2.1 / eval/post_ent_mag 64.2 / eval/post_ent_max 64.2 / eval/post_ent_mean 40.89 / eval/post_ent_min 29.19 / eval/post_ent_std 4.72 / eval/prior_ent_mag 69.51 / eval/prior_ent_max 69.51 / eval/prior_ent_mean 42.55 / 
eval/prior_ent_min 33.57 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 3.24 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3842 / timer/env.step_total 18.94 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.07 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.5e-4 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7349 / timer/agent.policy_total 15.94 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.7e-3 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1921 / timer/agent.train_total 247.02 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 200000 Counter(200000) 199937
Saved chunk: 20230922T020000F590499-5mYe4FwNy24j6rZmR5DLwf-4m98xUwKxCGZqS4VDZzLmo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 200500 Counter(200500) 200437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T020054F772453-1QuAy7tn28pio98RIkGHMh-4SNpdsj2oiguo3sz9FYw23-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 201000 Counter(201000) 200937
Saved chunk: 20230922T020119F885788-4m98xUwKxCGZqS4VDZzLmo-4hprfQJ0TGSJp47p3JjYQN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 201500 Counter(201500) 201437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T020215F968221-4SNpdsj2oiguo3sz9FYw23-681O4NOWTrfniAvIMBFvqE-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 202000 Counter(202000) 201937
Saved chunk: 20230922T020238F762170-4hprfQJ0TGSJp47p3JjYQN-059MjLC8UDcTyoBPT03GOv-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 202500 Counter(202500) 202437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T020336F331134-681O4NOWTrfniAvIMBFvqE-6QhYtysepSMJ0X5Y23rfOC-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 203000 Counter(203000) 202937
Saved chunk: 20230922T020357F528895-059MjLC8UDcTyoBPT03GOv-1lR9lYLWR7GUpMIsFpDZKx-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 203500 Counter(203500) 203437
eval_Episode has 500 steps and return 0.0.
 Step 407278 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.44 / train/action_min -3.94 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.6e-7 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / train/dyn_loss_std 
3.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2e-6 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 2.6e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.32 / train/model_loss_mean 1.22 / train/model_loss_std 2.33 / train/model_opt_grad_norm 5.94 / 
train/model_opt_grad_steps 1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.4 / train/policy_entropy_std 4.5e-4 / train/policy_logprob_mag 9.52 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.52 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2e-4 / train/post_ent_mag 65.03 / train/post_ent_max 65.03 / train/post_ent_mean 40.75 / train/post_ent_min 25.23 / train/post_ent_std 4.6 / train/prior_ent_mag 69.39 / 
train/prior_ent_max 69.39 / train/prior_ent_mean 42.35 / train/prior_ent_min 31.12 / train/prior_ent_std 5.24 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.53 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 3e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.99 / report/dyn_loss_std 5.03 / 
report/image_loss_mean 0.21 / report/image_loss_std 0.59 / report/model_loss_mean 1.4 / report/model_loss_std 3.44 / report/post_ent_mag 64.58 / report/post_ent_max 64.58 / report/post_ent_mean 40.26 / report/post_ent_min 26.24 / report/post_ent_std 4.42 / 
report/prior_ent_mag 69.59 / report/prior_ent_max 69.59 / report/prior_ent_mean 42.03 / report/prior_ent_min 30.93 / report/prior_ent_std 5.19 / report/rep_loss_mean 1.99 / report/rep_loss_std 5.03 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / 
eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.65 / eval/dyn_loss_std 3.05 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.33 /
eval/model_loss_mean 1.16 / eval/model_loss_std 2.07 / eval/post_ent_mag 64.58 / eval/post_ent_max 64.58 / eval/post_ent_mean 40.58 / eval/post_ent_min 26.12 / eval/post_ent_std 4.51 / eval/prior_ent_mag 69.59 / eval/prior_ent_max 69.59 / eval/prior_ent_mean 42.29 / 
eval/prior_ent_min 33.19 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 1.65 / eval/rep_loss_std 3.05 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3790 / timer/env.step_total 18.78 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.58 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.2e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 16.8 / timer/agent.policy_frac 0.06 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.3e-3 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1895 / timer/agent.train_total 244 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.36 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T020456F519361-6QhYtysepSMJ0X5Y23rfOC-5dcOkQUG9xg7fSk2kmbQQr-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 204000 Counter(204000) 203937
Saved chunk: 20230922T020516F101184-1lR9lYLWR7GUpMIsFpDZKx-0grFxCxP01Qdg3VLSbEjhn-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 204500 Counter(204500) 204437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T020617F538851-5dcOkQUG9xg7fSk2kmbQQr-5hHdeXXza3G0g2s78s3h3k-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 205000 Counter(205000) 204937
Saved chunk: 20230922T020635F686253-0grFxCxP01Qdg3VLSbEjhn-6Lh3yPd3ZmHU7lLqCNNjhB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 205500 Counter(205500) 205437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T020738F020123-5hHdeXXza3G0g2s78s3h3k-2SLP8yK0m0JplMDIJIvkmI-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 206000 Counter(206000) 205937
Saved chunk: 20230922T020754F503944-6Lh3yPd3ZmHU7lLqCNNjhB-38fGti9oFazeUQBpQPOZ1e-1024.npz
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T020858F192845-2SLP8yK0m0JplMDIJIvkmI-0000000000000000000000-576.npz
Saved chunk: 20230922T020913F050054-38fGti9oFazeUQBpQPOZ1e-0000000000000000000000-163.npz
train_Episode has 500 steps and return 0.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 206500 Counter(206500) 206437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T020858F192845-2SLP8yK0m0JplMDIJIvkmI-1SBne2wMf9iyAqHW8k3sfa-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 207000 Counter(207000) 206937
Saved chunk: 20230922T020913F050054-38fGti9oFazeUQBpQPOZ1e-5psOYB8rFz60VwyaDk7SHa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 414958 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.45 / train/action_min -3.96 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.6e-7 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 4.8e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / train/dyn_loss_std 
3.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.4e-6 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 2e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.31 / train/model_loss_mean 1.21 / train/model_loss_std 2.29 / train/model_opt_grad_norm 6.04 / 
train/model_opt_grad_steps 1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.4 / train/policy_entropy_std 4.7e-4 / train/policy_logprob_mag 9.52 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.52 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2e-4 / train/post_ent_mag 65.46 / train/post_ent_max 65.46 / train/post_ent_mean 40.87 / train/post_ent_min 25.32 / train/post_ent_std 4.51 / train/prior_ent_mag 69.52 / 
train/prior_ent_max 69.52 / train/prior_ent_mean 42.44 / train/prior_ent_min 31.2 / train/prior_ent_std 5.13 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.48 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.31 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.24 / report/model_loss_mean 1.18 / report/model_loss_std 2.14 / report/post_ent_mag 65.04 / report/post_ent_max 65.04 / report/post_ent_mean 40.73 / report/post_ent_min 21.2 / report/post_ent_std 4.17 / 
report/prior_ent_mag 69.33 / report/prior_ent_max 69.33 / report/prior_ent_mean 42.47 / report/prior_ent_min 32.21 / report/prior_ent_std 4.82 / report/rep_loss_mean 1.69 / report/rep_loss_std 3.31 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1e-11 / 
eval/cont_loss_std 4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 3.16 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.26 / 
eval/model_loss_mean 1.14 / eval/model_loss_std 2.09 / eval/post_ent_mag 65.24 / eval/post_ent_max 65.24 / eval/post_ent_mean 39.97 / eval/post_ent_min 27.11 / eval/post_ent_std 4.14 / eval/prior_ent_mag 69.33 / eval/prior_ent_max 69.33 / eval/prior_ent_mean 41.71 / 
eval/prior_ent_min 32.95 / eval/prior_ent_std 4.65 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 3.16 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.1e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3840 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.55 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7347 / timer/agent.policy_total 15.92 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.88 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 207500 Counter(207500) 207437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021018F513037-1SBne2wMf9iyAqHW8k3sfa-7g3KZ88wXifKC81QMY8rCg-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 208000 Counter(208000) 207937
Saved chunk: 20230922T021031F792032-5psOYB8rFz60VwyaDk7SHa-0Nn1VN6XP8eLN1YmTjgqQ4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 208500 Counter(208500) 208437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021139F504691-7g3KZ88wXifKC81QMY8rCg-2cZCMPJ9iP2OSli1mpoifh-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 209000 Counter(209000) 208937
Saved chunk: 20230922T021151F276554-0Nn1VN6XP8eLN1YmTjgqQ4-3tDJpxTIfpG1Pb8UC1klZQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 209500 Counter(209500) 209437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021259F795926-2cZCMPJ9iP2OSli1mpoifh-62QT0by9SlNWjhLE2YY1bg-1024.npz
Starting evaluation at step 210000 Counter(210000) 209937
Saved chunk: 20230922T021309F970044-3tDJpxTIfpG1Pb8UC1klZQ-3y1mgg3dOEPMuw7FMlRfHC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 210500 Counter(210500) 210437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021420F000178-62QT0by9SlNWjhLE2YY1bg-2rVQr7F5kjhUDjb1kNXRyT-1024.npz
Starting evaluation at step 211000 Counter(211000) 210937
Saved chunk: 20230922T021428F574468-3y1mgg3dOEPMuw7FMlRfHC-4Q8Id5dpz2Priq9cx8WZsC-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 422550 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.46 / train/action_min -3.99 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.5e-7 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 5.1e-11 / train/cont_loss_std 4.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / train/dyn_loss_std 
3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.1e-6 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 1.7e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.32 / train/model_loss_mean 1.21 / train/model_loss_std 2.32 / train/model_opt_grad_norm 5.88 / 
train/model_opt_grad_steps 1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.4 / train/policy_entropy_std 4.6e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2e-4 / train/post_ent_mag 65.14 / train/post_ent_max 65.14 / train/post_ent_mean 40.87 / train/post_ent_min 25 / train/post_ent_std 4.48 / train/prior_ent_mag 69.33 / 
train/prior_ent_max 69.33 / train/prior_ent_mean 42.44 / train/prior_ent_min 31.27 / train/prior_ent_std 5.1 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.52 / train/reward_avg 0 / train/reward_loss_mean 9.9e-12 / train/reward_loss_std 3.2e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 
/ report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.33 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.22 / report/model_loss_mean 1.22 / report/model_loss_std 2.14 / report/post_ent_mag 65.62 / report/post_ent_max 65.62 / report/post_ent_mean 41.2 / report/post_ent_min 27.17 / report/post_ent_std 3.79 / 
report/prior_ent_mag 69.46 / report/prior_ent_max 69.46 / report/prior_ent_mean 42.66 / report/prior_ent_min 33.66 / report/prior_ent_std 4.8 / report/rep_loss_mean 1.76 / report/rep_loss_std 3.33 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / 
eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.65 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.25 / 
eval/model_loss_mean 1.09 / eval/model_loss_std 1.77 / eval/post_ent_mag 65.62 / eval/post_ent_max 65.62 / eval/post_ent_mean 41.09 / eval/post_ent_min 24.98 / eval/post_ent_std 4.12 / eval/prior_ent_mag 69.46 / eval/prior_ent_max 69.46 / eval/prior_ent_mean 42.58 / 
eval/prior_ent_min 33.21 / eval/prior_ent_std 4.65 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.65 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.1e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / 
timer/env.step_count 3796 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.4 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.94 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 211500 Counter(211500) 211437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021540F094161-2rVQr7F5kjhUDjb1kNXRyT-1cmtvN5L6QjrtAC0PnKusq-1024.npz
Starting evaluation at step 212000 Counter(212000) 211937
Saved chunk: 20230922T021547F081762-4Q8Id5dpz2Priq9cx8WZsC-1Rn5qRVUlvp7CKJJEmz34y-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 212500 Counter(212500) 212437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021702F374964-1cmtvN5L6QjrtAC0PnKusq-4XuJVXFk6p3LrCZvVqhOLz-1024.npz
Starting evaluation at step 213000 Counter(213000) 212937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021707F826896-1Rn5qRVUlvp7CKJJEmz34y-5vF4bCXDiMJCJLG5TeO2tl-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 213500 Counter(213500) 213437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 214000 Counter(214000) 213937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021822F624684-4XuJVXFk6p3LrCZvVqhOLz-3rQHfyf4DI8cQD8BjVQdNj-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 214500 Counter(214500) 214437
Saved chunk: 20230922T021826F474983-5vF4bCXDiMJCJLG5TeO2tl-27WevaNzgpLossIs5nu3gd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 215000 Counter(215000) 214937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T021945F998077-3rQHfyf4DI8cQD8BjVQdNj-1qcY82taQ0sfULPqS1RdVF-1024.npz
 Step 430118 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.46 / train/action_min -3.95 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.3e-7 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / train/dyn_loss_std 
3.58 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.7e-6 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 3.2e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.32 / train/model_loss_mean 1.22 / train/model_loss_std 2.37 / train/model_opt_grad_norm 5.84 / 
train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.4e-4 / train/policy_logprob_mag 9.39 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.39 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 65.21 / train/post_ent_max 65.21 / train/post_ent_mean 41.03 / train/post_ent_min 25.35 / train/post_ent_std 4.39 / train/prior_ent_mag 69.3 / 
train/prior_ent_max 69.3 / train/prior_ent_mean 42.6 / train/prior_ent_min 31.69 / train/prior_ent_std 5 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.58 / train/reward_avg 0 / train/reward_loss_mean 1.5e-11 / train/reward_loss_std 4.7e-10 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.04 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.23 / report/model_loss_mean 1.15 / report/model_loss_std 1.97 / report/post_ent_mag 64.29 / report/post_ent_max 64.29 / report/post_ent_mean 41.09 / report/post_ent_min 25.23 / report/post_ent_std 3.82 / 
report/prior_ent_mag 69.13 / report/prior_ent_max 69.13 / report/prior_ent_mean 42.46 / report/prior_ent_min 33.7 / report/prior_ent_std 4.81 / report/rep_loss_mean 1.67 / report/rep_loss_std 3.04 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.9e-11 / 
eval/cont_loss_std 2.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 2.85 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.28 /
eval/model_loss_mean 1.15 / eval/model_loss_std 1.89 / eval/post_ent_mag 64.29 / eval/post_ent_max 64.29 / eval/post_ent_mean 40.56 / eval/post_ent_min 27.35 / eval/post_ent_std 4 / eval/prior_ent_mag 69.13 / eval/prior_ent_max 69.13 / eval/prior_ent_mean 42.05 / 
eval/prior_ent_min 32.54 / eval/prior_ent_std 4.78 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 2.85 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.1e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / 
timer/env.step_count 3784 / timer/env.step_total 18.76 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3e4 / timer/replay._sample_total 387.37 / timer/replay._sample_frac 1.29 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7792 / timer/agent.policy_total 16.65 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1892 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1892 / timer/agent.train_total 243.02 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / 
timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 215500 Counter(215500) 215437
Saved chunk: 20230922T022020F625633-27WevaNzgpLossIs5nu3gd-1wVFYbiShkQEfQiY2dApwc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 216000 Counter(216000) 215937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022105F859864-1qcY82taQ0sfULPqS1RdVF-1hx8jtF5TuhDpCDfGMEP9A-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 216500 Counter(216500) 216437
Saved chunk: 20230922T022139F892327-1wVFYbiShkQEfQiY2dApwc-0DHFc7Qx60PMa9RFDSkhuH-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 217000 Counter(217000) 216937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022227F109704-1hx8jtF5TuhDpCDfGMEP9A-0sxElw2ci4k5DBz0wTy9TH-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 217500 Counter(217500) 217437
Saved chunk: 20230922T022258F823778-0DHFc7Qx60PMa9RFDSkhuH-7wq8MOoWVqM2dQlpFVMM2n-1024.npz
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T022417F406461-7wq8MOoWVqM2dQlpFVMM2n-0000000000000000000000-422.npz
Saved chunk: 20230922T022347F360960-0sxElw2ci4k5DBz0wTy9TH-0000000000000000000000-812.npz
train_Episode has 500 steps and return 0.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 218000 Counter(218000) 217937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022347F360960-0sxElw2ci4k5DBz0wTy9TH-6qvmBbtAwXWQDN7FRNakAd-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 218500 Counter(218500) 218437
Saved chunk: 20230922T022417F406461-7wq8MOoWVqM2dQlpFVMM2n-4LXKQEwZ06mtQysg130y7N-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 437794 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.64 / train/action_mean 0.47 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.5e-7 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 5.5e-11 / train/cont_loss_std 5.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.3e-6 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
4.1e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.32 / train/model_loss_mean 1.22 / train/model_loss_std 2.37 / train/model_opt_grad_norm 5.76 / 
train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.6e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 2e-4 / train/post_ent_mag 65.03 / train/post_ent_max 65.03 / train/post_ent_mean 40.9 / train/post_ent_min 25.06 / train/post_ent_std 4.38 / train/prior_ent_mag 69.24 / 
train/prior_ent_max 69.24 / train/prior_ent_mean 42.48 / train/prior_ent_min 31.42 / train/prior_ent_std 5.03 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.59 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / report/dyn_loss_std 3.14 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.33 / report/model_loss_mean 1.1 / report/model_loss_std 2.06 / report/post_ent_mag 64.94 / report/post_ent_max 64.94 / report/post_ent_mean 41.21 / report/post_ent_min 29.85 / report/post_ent_std 4.05 / 
report/prior_ent_mag 69.7 / report/prior_ent_max 69.7 / report/prior_ent_mean 42.83 / report/prior_ent_min 32.91 / report/prior_ent_std 5.02 / report/rep_loss_mean 1.6 / report/rep_loss_std 3.14 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / 
eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.67 / eval/dyn_loss_std 3.23 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.31 /
eval/model_loss_mean 1.16 / eval/model_loss_std 2.17 / eval/post_ent_mag 64.49 / eval/post_ent_max 64.49 / eval/post_ent_mean 40.35 / eval/post_ent_min 27.28 / eval/post_ent_std 4.08 / eval/prior_ent_mag 69.7 / eval/prior_ent_max 69.7 / eval/prior_ent_mean 42.1 / 
eval/prior_ent_min 33.27 / eval/prior_ent_std 4.87 / eval/rep_loss_mean 1.67 / eval/rep_loss_std 3.23 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.2e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / 
timer/env.step_count 3838 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.04 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.85 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-4 / timer/replay._sample_max 0.14 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7345 / timer/agent.policy_total 16.14 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1919 / timer/agent.train_total 246.69 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 219000 Counter(219000) 218937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022507F804473-6qvmBbtAwXWQDN7FRNakAd-4niRXOUxmg2VyuY4Fj1N8t-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 219500 Counter(219500) 219437
Saved chunk: 20230922T022536F224379-4LXKQEwZ06mtQysg130y7N-3pym3lvbvkFowiZ2mCEtbs-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 220000 Counter(220000) 219937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022628F746933-4niRXOUxmg2VyuY4Fj1N8t-1PnMJ4jR4rlmHMd5Lgl1k6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 220500 Counter(220500) 220437
Saved chunk: 20230922T022655F864454-3pym3lvbvkFowiZ2mCEtbs-2IntdBiDp77lpHiv1kYEJk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 221000 Counter(221000) 220937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022749F157876-1PnMJ4jR4rlmHMd5Lgl1k6-3BPx8ZeSlDX7nZIH6HZ9ND-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 221500 Counter(221500) 221437
Saved chunk: 20230922T022814F518991-2IntdBiDp77lpHiv1kYEJk-6A5xBtr5FRGqc75Fks6Rf8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 222000 Counter(222000) 221937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T022909F286537-3BPx8ZeSlDX7nZIH6HZ9ND-306CSJk6FFMMn40cb67EN3-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 222500 Counter(222500) 222437
Saved chunk: 20230922T022933F044306-6A5xBtr5FRGqc75Fks6Rf8-0ecAEcerSo8j0pXW4unzEy-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 445386 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.62 / train/action_max 4.62 / train/action_mean 0.47 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.2e-7 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-6 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
2.7e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.31 / train/model_loss_mean 1.2 / train/model_loss_std 2.27 / train/model_opt_grad_norm 5.79 / 
train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.4e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 65.53 / train/post_ent_max 65.53 / train/post_ent_mean 41.16 / train/post_ent_min 25.75 / train/post_ent_std 4.33 / train/prior_ent_mag 69.51 / 
train/prior_ent_max 69.51 / train/prior_ent_mean 42.72 / train/prior_ent_min 31.72 / train/prior_ent_std 4.97 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.43 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 3.1e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / report/dyn_loss_std 3.75 / 
report/image_loss_mean 0.19 / report/image_loss_std 0.38 / report/model_loss_mean 1.24 / report/model_loss_std 2.52 / report/post_ent_mag 65.67 / report/post_ent_max 65.67 / report/post_ent_mean 40.94 / report/post_ent_min 25.95 / report/post_ent_std 4.55 / 
report/prior_ent_mag 69.83 / report/prior_ent_max 69.83 / report/prior_ent_mean 42.5 / report/prior_ent_min 30.35 / report/prior_ent_std 5.4 / report/rep_loss_mean 1.75 / report/rep_loss_std 3.75 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / 
eval/cont_loss_std 5.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.03 / eval/dyn_loss_std 4.73 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.53 /
eval/model_loss_mean 1.45 / eval/model_loss_std 3.28 / eval/post_ent_mag 65.96 / eval/post_ent_max 65.96 / eval/post_ent_mean 40.37 / eval/post_ent_min 17.77 / eval/post_ent_std 4.12 / eval/prior_ent_mag 69.83 / eval/prior_ent_max 69.83 / eval/prior_ent_mean 42.11 / 
eval/prior_ent_min 29.57 / eval/prior_ent_std 4.96 / eval/rep_loss_mean 2.03 / eval/rep_loss_std 4.73 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.2e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / 
timer/env.step_count 3796 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.85 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.2e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.3e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1898 / timer/agent.train_total 243.99 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / 
timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 223000 Counter(223000) 222937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023029F343111-306CSJk6FFMMn40cb67EN3-7CFC7oO8Gv11yJLi28FP3B-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 223500 Counter(223500) 223437
Saved chunk: 20230922T023051F487369-0ecAEcerSo8j0pXW4unzEy-1lVyHub1kJIuwmt24REmnu-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 224000 Counter(224000) 223937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023150F362723-7CFC7oO8Gv11yJLi28FP3B-1v77RbnrtfGXOqmIajWV4V-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 224500 Counter(224500) 224437
Saved chunk: 20230922T023211F038687-1lVyHub1kJIuwmt24REmnu-1b26v2KSS0jsTl6tk9X7yE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 225000 Counter(225000) 224937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023310F535657-1v77RbnrtfGXOqmIajWV4V-5zZzGwTWMBxcAhQSu5Tbus-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 225500 Counter(225500) 225437
Saved chunk: 20230922T023329F603230-1b26v2KSS0jsTl6tk9X7yE-07zuGZkl0vRkFjDjpIsoEk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 226000 Counter(226000) 225937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023430F708132-5zZzGwTWMBxcAhQSu5Tbus-0tMHmqyDOFCghUuxsd8OKY-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 226500 Counter(226500) 226437
Saved chunk: 20230922T023448F147665-07zuGZkl0vRkFjDjpIsoEk-39ETeq56t8TolLShY3MjCk-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 453002 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.67 / train/action_mean 0.47 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.2e-7 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 7e-11 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / train/dyn_loss_std 
3.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.2e-6 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 3.8e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.31 / train/model_loss_mean 1.21 / train/model_loss_std 2.31 / train/model_opt_grad_norm 5.89 / 
train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.4e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 65.57 / train/post_ent_max 65.57 / train/post_ent_mean 41.24 / train/post_ent_min 25.08 / train/post_ent_std 4.27 / train/prior_ent_mag 69.56 / 
train/prior_ent_max 69.56 / train/prior_ent_mean 42.8 / train/prior_ent_min 31.7 / train/prior_ent_std 4.91 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.49 / train/reward_avg 0 / train/reward_loss_mean 9.8e-12 / train/reward_loss_std 3.1e-10 / train/reward_max_data 0
/ train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.8e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.1e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.7 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.3 / report/model_loss_mean 1.17 / report/model_loss_std 2.44 / report/post_ent_mag 65.8 / report/post_ent_max 65.8 / report/post_ent_mean 41.35 / report/post_ent_min 26.92 / report/post_ent_std 3.95 / 
report/prior_ent_mag 69.45 / report/prior_ent_max 69.45 / report/prior_ent_mean 42.69 / report/prior_ent_min 34.05 / report/prior_ent_std 4.62 / report/rep_loss_mean 1.69 / report/rep_loss_std 3.7 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.59 / eval/dyn_loss_std 2.61 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.19 /
eval/model_loss_mean 1.09 / eval/model_loss_std 1.66 / eval/post_ent_mag 65.59 / eval/post_ent_max 65.59 / eval/post_ent_mean 40.81 / eval/post_ent_min 25.05 / eval/post_ent_std 4.35 / eval/prior_ent_mag 69.45 / eval/prior_ent_max 69.45 / eval/prior_ent_mean 42.33 / 
eval/prior_ent_min 32.99 / eval/prior_ent_std 4.75 / eval/rep_loss_mean 1.59 / eval/rep_loss_std 2.61 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.3e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.77 / 
timer/env.step_count 3808 / timer/env.step_total 18.79 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.1 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.8e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7816 / timer/agent.policy_total 16.75 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1904 / timer/agent.train_total 244.69 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.13
/ timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.32

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 227000 Counter(227000) 226937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023550F726687-0tMHmqyDOFCghUuxsd8OKY-6lGf0nVjTeYpSmejUL5tXc-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 227500 Counter(227500) 227437
Saved chunk: 20230922T023606F592828-39ETeq56t8TolLShY3MjCk-1r5PaBkSDHw3ErURiJPgpC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 228000 Counter(228000) 227937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023711F877512-6lGf0nVjTeYpSmejUL5tXc-4cyIHqa9ky1DXxY9F8WQXI-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 228500 Counter(228500) 228437
Saved chunk: 20230922T023726F243091-1r5PaBkSDHw3ErURiJPgpC-2bxzmELnzwccpCpQMFuLhK-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 229000 Counter(229000) 228937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T023832F145039-4cyIHqa9ky1DXxY9F8WQXI-3HsZFgBshZWSPzx0AvwCDe-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T023952F216948-3HsZFgBshZWSPzx0AvwCDe-0000000000000000000000-24.npz
Saved chunk: 20230922T023844F924364-2bxzmELnzwccpCpQMFuLhK-0000000000000000000000-681.npz
train_Episode has 500 steps and return 0.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 229500 Counter(229500) 229437
Saved chunk: 20230922T023844F924364-2bxzmELnzwccpCpQMFuLhK-5jBSsyaAxwT39oTsd7aj9b-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 230000 Counter(230000) 229937
eval_Episode has 500 steps and return 0.0.
 Step 460686 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.47 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.1e-7 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1e-6 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.6e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.31 / train/model_loss_mean 1.21 / train/model_loss_std 2.32 / train/model_opt_grad_norm 5.73 / 
train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.3e-4 / train/policy_logprob_mag 9.53 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.53 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 65.72 / train/post_ent_max 65.72 / train/post_ent_mean 41.27 / train/post_ent_min 25.56 / train/post_ent_std 4.22 / train/prior_ent_mag 69.62 / 
train/prior_ent_max 69.62 / train/prior_ent_mean 42.83 / train/prior_ent_min 32.13 / train/prior_ent_std 4.92 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.52 / train/reward_avg 0 / train/reward_loss_mean 1.5e-11 / train/reward_loss_std 4.7e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 3e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 3.06 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.25 / report/model_loss_mean 1.09 / report/model_loss_std 1.97 / report/post_ent_mag 66.21 / report/post_ent_max 66.21 / report/post_ent_mean 41.47 / report/post_ent_min 27.25 / report/post_ent_std 4.36 / 
report/prior_ent_mag 69.4 / report/prior_ent_max 69.4 / report/prior_ent_mean 42.89 / report/prior_ent_min 33.74 / report/prior_ent_std 5.05 / report/rep_loss_mean 1.57 / report/rep_loss_std 3.06 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / 
eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.67 / eval/dyn_loss_std 3.24 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.26 /
eval/model_loss_mean 1.16 / eval/model_loss_std 2.1 / eval/post_ent_mag 65.46 / eval/post_ent_max 65.46 / eval/post_ent_mean 41.12 / eval/post_ent_min 22.98 / eval/post_ent_std 3.87 / eval/prior_ent_mag 69.4 / eval/prior_ent_max 69.4 / eval/prior_ent_mean 42.69 / 
eval/prior_ent_min 33.58 / eval/prior_ent_std 4.58 / eval/rep_loss_mean 1.67 / eval/rep_loss_std 3.24 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.3e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / 
timer/env.step_count 3842 / timer/env.step_total 18.99 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 400.57 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.1e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7349 / timer/agent.policy_total 16.11 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1921 / timer/agent.train_total 246.81 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T023952F216948-3HsZFgBshZWSPzx0AvwCDe-3gZBk4PvsQprd9EaAtKHrS-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 230500 Counter(230500) 230437
Saved chunk: 20230922T024003F689773-5jBSsyaAxwT39oTsd7aj9b-28zpYHcJIibLCnNYqQjEpt-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 231000 Counter(231000) 230937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024113F084418-3gZBk4PvsQprd9EaAtKHrS-2DMQW8KX8ckXUy5DPi4U8d-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 231500 Counter(231500) 231437
Saved chunk: 20230922T024122F760542-28zpYHcJIibLCnNYqQjEpt-5HRClK9LgGGdnNr5Pje8Fr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 232000 Counter(232000) 231937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024233F666907-2DMQW8KX8ckXUy5DPi4U8d-2HV6szqhvGM1Z2wxHNKGUW-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 232500 Counter(232500) 232437
Saved chunk: 20230922T024241F690629-5HRClK9LgGGdnNr5Pje8Fr-3ugy46ynU1OLeghyv3a64l-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 233000 Counter(233000) 232937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024353F930363-2HV6szqhvGM1Z2wxHNKGUW-6uTpwRCCdlgJbrHlkQAkSy-1024.npz
Starting evaluation at step 233500 Counter(233500) 233437
Saved chunk: 20230922T024400F406899-3ugy46ynU1OLeghyv3a64l-0sNgXntxKwd8Qoc5eF8UpD-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 234000 Counter(234000) 233937
eval_Episode has 500 steps and return 0.0.
 Step 468274 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.47 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5e-7 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / train/dyn_loss_std 3.52
/ train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.6e-6 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 3.2e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.2 / train/model_loss_std 2.32 / train/model_opt_grad_norm 5.63 / 
train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.3e-4 / train/policy_logprob_mag 9.39 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.39 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 65.75 / train/post_ent_max 65.75 / train/post_ent_mean 41.26 / train/post_ent_min 25.42 / train/post_ent_std 4.33 / train/prior_ent_mag 69.58 / 
train/prior_ent_max 69.58 / train/prior_ent_mean 42.82 / train/prior_ent_min 31.87 / train/prior_ent_std 4.95 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.52 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 2.99 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.24 / report/model_loss_mean 1.07 / report/model_loss_std 1.95 / report/post_ent_mag 66.26 / report/post_ent_max 66.26 / report/post_ent_mean 41.06 / report/post_ent_min 28.67 / report/post_ent_std 4.33 / 
report/prior_ent_mag 69.42 / report/prior_ent_max 69.42 / report/prior_ent_mean 42.43 / report/prior_ent_min 32.4 / report/prior_ent_std 4.96 / report/rep_loss_mean 1.58 / report/rep_loss_std 2.99 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / 
eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.35 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.31 /
eval/model_loss_mean 1.08 / eval/model_loss_std 1.6 / eval/post_ent_mag 66.26 / eval/post_ent_max 66.26 / eval/post_ent_mean 41.08 / eval/post_ent_min 24.06 / eval/post_ent_std 4.45 / eval/prior_ent_mag 69.42 / eval/prior_ent_max 69.42 / eval/prior_ent_mean 42.48 / 
eval/prior_ent_min 33.95 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.35 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.3e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / 
timer/env.step_count 3794 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 396.6 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.2e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.72 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1897 / timer/agent.train_total 244.05 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024514F022065-6uTpwRCCdlgJbrHlkQAkSy-6l5EBKwp6Gjdw6lI8SSvES-1024.npz
Starting evaluation at step 234500 Counter(234500) 234437
Saved chunk: 20230922T024518F904813-0sNgXntxKwd8Qoc5eF8UpD-6JY3u5ElauYK486bu5kANY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 235000 Counter(235000) 234937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 235500 Counter(235500) 235437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024638F314354-6JY3u5ElauYK486bu5kANY-54vxtoGV3IiKTW0YoPsa3k-1024.npz
Saved chunk: 20230922T024634F980081-6l5EBKwp6Gjdw6lI8SSvES-0z6E9xmg17MQ5jD2ZaOdVm-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 236000 Counter(236000) 235937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 236500 Counter(236500) 236437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024757F285246-54vxtoGV3IiKTW0YoPsa3k-4t9nUwvtqWL2Htjo37X6H7-1024.npz
Saved chunk: 20230922T024758F917925-0z6E9xmg17MQ5jD2ZaOdVm-08NwYDvqT2Rii8LqNEB543-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 237000 Counter(237000) 236937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 237500 Counter(237500) 237437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T024919F181183-08NwYDvqT2Rii8LqNEB543-4COozxvdHNwTBAN3MLRrI8-1024.npz
 Step 475946 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.73 / train/action_max 4.72 / train/action_mean 0.48 / train/action_min -3.89 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5.1e-7 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 3.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / 
train/dyn_loss_std 3.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4e-6 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
4.3e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.21 / train/model_loss_std 2.29 / train/model_opt_grad_norm 5.89 / 
train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9010.42 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 4.3e-4 / train/policy_logprob_mag 9.45 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.45 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 65.59 / train/post_ent_max 65.59 / train/post_ent_mean 41.31 / train/post_ent_min 25.43 / train/post_ent_std 4.24 / 
train/prior_ent_mag 69.53 / train/prior_ent_max 69.53 / train/prior_ent_mean 42.87 / train/prior_ent_min 31.97 / train/prior_ent_std 4.89 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.47 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 9.6e-12 / report/cont_loss_std 3.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.6e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / 
report/dyn_loss_std 3.76 / report/image_loss_mean 0.13 / report/image_loss_std 0.22 / report/model_loss_mean 1.1 / report/model_loss_std 2.4 / report/post_ent_mag 66.15 / report/post_ent_max 66.15 / report/post_ent_mean 40.27 / report/post_ent_min 28.13 / 
report/post_ent_std 3.91 / report/prior_ent_mag 69.53 / report/prior_ent_max 69.53 / report/prior_ent_mean 41.57 / report/prior_ent_min 30.03 / report/prior_ent_std 4.86 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.76 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.74 / eval/image_loss_mean 
0.12 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.05 / eval/model_loss_std 1.78 / eval/post_ent_mag 66.48 / eval/post_ent_max 66.48 / eval/post_ent_mean 40.48 / eval/post_ent_min 27.88 / eval/post_ent_std 3.94 / eval/prior_ent_mag 69.53 / eval/prior_ent_max 69.53 /
eval/prior_ent_mean 41.99 / eval/prior_ent_min 32.31 / eval/prior_ent_std 4.44 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.74 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.4e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.07 / timer/env.step_count 3836 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.64 / 
timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 
15.91 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / 
timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1918 / timer/agent.train_total 247.01 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / 
timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.57

train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 238000 Counter(238000) 237937
Saved chunk: 20230922T024915F957873-4t9nUwvtqWL2Htjo37X6H7-1nXemPiznQkTdR5GxBBO9s-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 238500 Counter(238500) 238437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025039F415837-4COozxvdHNwTBAN3MLRrI8-2ehLOzyamQGAMGu4A6RpY6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 239000 Counter(239000) 238937
Saved chunk: 20230922T025111F180836-1nXemPiznQkTdR5GxBBO9s-1A9iB0ocKmtO470ixxW3ZW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 239500 Counter(239500) 239437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025200F662760-2ehLOzyamQGAMGu4A6RpY6-0m1vUdQzYkQJ4RPBH21RgW-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 240000 Counter(240000) 239937
Saved chunk: 20230922T025230F195778-1A9iB0ocKmtO470ixxW3ZW-4dIuZHmlG1O2UfNkZ34KLc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 240500 Counter(240500) 240437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025320F872609-0m1vUdQzYkQJ4RPBH21RgW-2GAMNm8YH93hhUrBtsMrCj-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T025441F042547-2GAMNm8YH93hhUrBtsMrCj-0000000000000000000000-260.npz
Saved chunk: 20230922T025348F792609-4dIuZHmlG1O2UfNkZ34KLc-0000000000000000000000-940.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 241000 Counter(241000) 240937
Saved chunk: 20230922T025348F792609-4dIuZHmlG1O2UfNkZ34KLc-6JbXpgUZKPEo091X7CnkRy-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 241500 Counter(241500) 241437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025441F042547-2GAMNm8YH93hhUrBtsMrCj-5rXEGWFPQSLzzUyRXCXU9J-1024.npz
 Step 483526 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train_stats/mean_log_entropy 1.42 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.49 / train/action_min -3.91
/ train/action_std 1.08 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.8e-7 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / 
train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.72 / train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.1e-6 / train/extr_critic_critic_opt_grad_steps 1.2e5 / 
train/extr_critic_critic_opt_loss 1.7e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / 
train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / 
train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.21 / train/model_loss_std 
2.32 / train/model_opt_grad_norm 5.55 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8368.42 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.4 / train/policy_entropy_std 4.1e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.8e-4 / train/post_ent_mag 65.92 / train/post_ent_max 65.92 / train/post_ent_mean 41.25 / train/post_ent_min 
25.57 / train/post_ent_std 4.22 / train/prior_ent_mag 69.65 / train/prior_ent_max 69.65 / train/prior_ent_mean 42.82 / train/prior_ent_min 32.03 / train/prior_ent_std 4.88 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.52 / train/reward_avg 0 / train/reward_loss_mean 0
/ train/reward_loss_std 0 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 2.7e-10 / report/cont_loss_std 4.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-10 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.83 / 
report/dyn_loss_std 4.55 / report/image_loss_mean 0.18 / report/image_loss_std 0.32 / report/model_loss_mean 1.28 / report/model_loss_std 2.96 / report/post_ent_mag 66.23 / report/post_ent_max 66.23 / report/post_ent_mean 41.48 / report/post_ent_min 21.23 / 
report/post_ent_std 4.11 / report/prior_ent_mag 69.95 / report/prior_ent_max 69.95 / report/prior_ent_mean 43 / report/prior_ent_min 33.35 / report/prior_ent_std 4.69 / report/rep_loss_mean 1.83 / report/rep_loss_std 4.55 / report/reward_avg 0 / report/reward_loss_mean 0 
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 9.8e-12 / eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.8e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.76 / eval/image_loss_mean 
0.12 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.06 / eval/model_loss_std 1.77 / eval/post_ent_mag 65.98 / eval/post_ent_max 65.98 / eval/post_ent_mean 40.14 / eval/post_ent_min 24.97 / eval/post_ent_std 3.54 / eval/prior_ent_mag 69.95 / eval/prior_ent_max 69.95 /
eval/prior_ent_mean 41.72 / eval/prior_ent_min 33.41 / eval/prior_ent_std 4.5 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.76 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.4e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.08 / timer/env.step_count 3790 / timer/env.step_total 18.77 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.42 / timer/replay._sample_frac 1.3 
/ timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7798 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.61 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 242000 Counter(242000) 241937
Saved chunk: 20230922T025507F648507-6JbXpgUZKPEo091X7CnkRy-4i6B0LbjbCU7Y8KPwnZiQk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 242500 Counter(242500) 242437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025601F420047-5rXEGWFPQSLzzUyRXCXU9J-3qXPeWf9aUXDUJXdQi8E9D-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 243000 Counter(243000) 242937
Saved chunk: 20230922T025627F068353-4i6B0LbjbCU7Y8KPwnZiQk-6s2l3iGF1kx0Tzmcx3NHii-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 243500 Counter(243500) 243437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025722F611283-3qXPeWf9aUXDUJXdQi8E9D-479LVJsnrGtM9rU8A5Oc3a-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 244000 Counter(244000) 243937
Saved chunk: 20230922T025745F871479-6s2l3iGF1kx0Tzmcx3NHii-4RO9aeAT4wKq3dDdf2pY8S-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 244500 Counter(244500) 244437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T025842F826765-479LVJsnrGtM9rU8A5Oc3a-381ZVYSdca3rruUBx36NF4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 245000 Counter(245000) 244937
Saved chunk: 20230922T025904F536941-4RO9aeAT4wKq3dDdf2pY8S-1O4f32nhbVn2EtDpPNDWP1-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 245500 Counter(245500) 245437
eval_Episode has 500 steps and return 0.0.
 Step 491118 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.68 / train/action_mean 0.5 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.7e-7 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.3e-11 / train/cont_loss_std 4.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.1e-6 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.7e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.32 / train/model_loss_mean 1.2 / train/model_loss_std 2.29 / train/model_opt_grad_norm 5.83 / 
train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.1e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.8e-4 / train/post_ent_mag 65.94 / train/post_ent_max 65.94 / train/post_ent_mean 41.15 / train/post_ent_min 25.58 / train/post_ent_std 4.23 / train/prior_ent_mag 69.52 / 
train/prior_ent_max 69.52 / train/prior_ent_mean 42.72 / train/prior_ent_min 32.02 / train/prior_ent_std 4.86 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.46 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.09 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.18 / report/model_loss_mean 1.13 / report/model_loss_std 1.96 / report/post_ent_mag 65.88 / report/post_ent_max 65.88 / report/post_ent_mean 40.72 / report/post_ent_min 22.9 / report/post_ent_std 3.98 / 
report/prior_ent_mag 69.08 / report/prior_ent_max 69.08 / report/prior_ent_mean 42.32 / report/prior_ent_min 33.44 / report/prior_ent_std 4.89 / report/rep_loss_mean 1.68 / report/rep_loss_std 3.09 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-11 / 
eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.79 / eval/dyn_loss_std 4.26 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.43 /
eval/model_loss_mean 1.25 / eval/model_loss_std 2.88 / eval/post_ent_mag 64.98 / eval/post_ent_max 64.98 / eval/post_ent_mean 40.88 / eval/post_ent_min 24.26 / eval/post_ent_std 4.39 / eval/prior_ent_mag 69.08 / eval/prior_ent_max 69.08 / eval/prior_ent_mean 42.46 / 
eval/prior_ent_min 31.65 / eval/prior_ent_std 4.74 / eval/rep_loss_mean 1.79 / eval/rep_loss_std 4.26 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.5e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3796 / timer/env.step_total 18.73 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.13 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-4 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 16.79 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1898 / timer/agent.train_total 244 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / 
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T030002F899898-381ZVYSdca3rruUBx36NF4-4a7gz01JFIjADXo0XyOg1h-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 246000 Counter(246000) 245937
Saved chunk: 20230922T030022F967085-1O4f32nhbVn2EtDpPNDWP1-55ngVuGyblTsR87LXtmAaD-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 246500 Counter(246500) 246437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030123F787290-4a7gz01JFIjADXo0XyOg1h-5lMnZTy1KKgk8ycm9qAN28-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 247000 Counter(247000) 246937
Saved chunk: 20230922T030142F384380-55ngVuGyblTsR87LXtmAaD-5ikiYE6bnigFc3Hv9G6m3X-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 247500 Counter(247500) 247437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030244F244865-5lMnZTy1KKgk8ycm9qAN28-0QedTAGWlvlLc6WbN3tX0A-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 248000 Counter(248000) 247937
Saved chunk: 20230922T030301F169723-5ikiYE6bnigFc3Hv9G6m3X-33jwixswqXPnWMTBdv4grU-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 248500 Counter(248500) 248437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030404F366466-0QedTAGWlvlLc6WbN3tX0A-1yPbZFjFArvEvJMK29vDik-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 249000 Counter(249000) 248937
Saved chunk: 20230922T030419F718312-33jwixswqXPnWMTBdv4grU-4fBK9HnP8uyyGv2YZ5yMPe-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 498806 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.71 / train/action_max 4.7 / train/action_mean 0.5 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.8e-7 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.4e-6 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
2.1e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.2 / train/model_loss_std 2.28 / train/model_opt_grad_norm 5.43 / 
train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 8857.31 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 4.2e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.8e-4 / train/post_ent_mag 66.06 / train/post_ent_max 66.06 / train/post_ent_mean 41.17 / train/post_ent_min 25.66 / train/post_ent_std 4.28 / 
train/prior_ent_mag 69.38 / train/prior_ent_max 69.38 / train/prior_ent_mean 42.73 / train/prior_ent_min 32.22 / train/prior_ent_std 4.88 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.46 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.9 / 
report/dyn_loss_std 4.2 / report/image_loss_mean 0.21 / report/image_loss_std 0.46 / report/model_loss_mean 1.35 / report/model_loss_std 2.88 / report/post_ent_mag 65.68 / report/post_ent_max 65.68 / report/post_ent_mean 41.59 / report/post_ent_min 25.46 / 
report/post_ent_std 4.13 / report/prior_ent_mag 69.37 / report/prior_ent_max 69.37 / report/prior_ent_mean 43.4 / report/prior_ent_min 29.66 / report/prior_ent_std 4.91 / report/rep_loss_mean 1.9 / report/rep_loss_std 4.2 / report/reward_avg 0 / report/reward_loss_mean 0 
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 3.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.24 / eval/dyn_loss_std 5.29 / eval/image_loss_mean 
0.31 / eval/image_loss_std 0.88 / eval/model_loss_mean 1.65 / eval/model_loss_std 3.88 / eval/post_ent_mag 66.45 / eval/post_ent_max 66.45 / eval/post_ent_mean 40.48 / eval/post_ent_min 21.17 / eval/post_ent_std 4.57 / eval/prior_ent_mag 69.37 / eval/prior_ent_max 69.37 /
eval/prior_ent_mean 42.33 / eval/prior_ent_min 30.86 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 2.24 / eval/rep_loss_std 5.29 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.5e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.11 / timer/env.step_count 3844 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.2 / timer/replay._sample_frac 
1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7351 / timer/agent.policy_total 15.88 / 
timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / 
timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1922 / timer/agent.train_total 247.14 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 
/ timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / 
timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 249500 Counter(249500) 249437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030524F494211-1yPbZFjFArvEvJMK29vDik-48It9bYEASVqvojS8KEkp8-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 250000 Counter(250000) 249937
Saved chunk: 20230922T030538F232884-4fBK9HnP8uyyGv2YZ5yMPe-16JUSBUZBO3FDrIFcvruQp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 250500 Counter(250500) 250437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030645F500811-48It9bYEASVqvojS8KEkp8-7x2XO1c61cDfojz9tvAIK7-1024.npz
Starting evaluation at step 251000 Counter(251000) 250937
Saved chunk: 20230922T030657F785047-16JUSBUZBO3FDrIFcvruQp-6roMWZfSA15vL24xTysFu0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 251500 Counter(251500) 251437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030805F844771-7x2XO1c61cDfojz9tvAIK7-697FlsvAkTbyU82atIloh7-1024.npz
Starting evaluation at step 252000 Counter(252000) 251937
Saved chunk: 20230922T030816F507468-6roMWZfSA15vL24xTysFu0-5pRHeV69PC8yxm3GvMecZl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T030926F036277-697FlsvAkTbyU82atIloh7-0000000000000000000000-496.npz
Saved chunk: 20230922T030935F102384-5pRHeV69PC8yxm3GvMecZl-0000000000000000000000-175.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 252500 Counter(252500) 252437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T030926F036277-697FlsvAkTbyU82atIloh7-2F0jZheF66CO4bc5OD4fWF-1024.npz
Starting evaluation at step 253000 Counter(253000) 252937
Saved chunk: 20230922T030935F102384-5pRHeV69PC8yxm3GvMecZl-3mnTSE7NutYeQJ99OjN6P9-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 506390 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.68 / train/action_mean 0.48 / train/action_min -3.98 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 5e-7 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / train/dyn_loss_std 
3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.4e-6 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 2.9e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.18 / train/image_loss_std 0.32 / train/model_loss_mean 1.21 / train/model_loss_std 2.33 / train/model_opt_grad_norm 5.55 / 
train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.3e-4 / train/policy_logprob_mag 9.46 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.46 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.9e-4 / train/post_ent_mag 66.17 / train/post_ent_max 66.17 / train/post_ent_mean 41.2 / train/post_ent_min 25.82 / train/post_ent_std 4.27 / train/prior_ent_mag 69.57 / 
train/prior_ent_max 69.57 / train/prior_ent_mean 42.77 / train/prior_ent_min 32.08 / train/prior_ent_std 4.91 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.52 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.2e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.72 / 
report/image_loss_mean 0.2 / report/image_loss_std 0.38 / report/model_loss_mean 1.22 / report/model_loss_std 2.5 / report/post_ent_mag 66.77 / report/post_ent_max 66.77 / report/post_ent_mean 41.47 / report/post_ent_min 27.27 / report/post_ent_std 4.88 / 
report/prior_ent_mag 69.5 / report/prior_ent_max 69.5 / report/prior_ent_mean 42.89 / report/prior_ent_min 29.88 / report/prior_ent_std 5.13 / report/rep_loss_mean 1.7 / report/rep_loss_std 3.72 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-11 / 
eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.64 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.31 /
eval/model_loss_mean 1.21 / eval/model_loss_std 2.37 / eval/post_ent_mag 65.91 / eval/post_ent_max 65.91 / eval/post_ent_mean 40.04 / eval/post_ent_min 21.7 / eval/post_ent_std 3.98 / eval/prior_ent_mag 69.5 / eval/prior_ent_max 69.5 / eval/prior_ent_mean 41.63 / 
eval/prior_ent_min 31.36 / eval/prior_ent_std 4.71 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.64 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.5e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3792 / timer/env.step_total 18.84 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.29 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7800 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.7e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.82 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 253500 Counter(253500) 253437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031046F291211-2F0jZheF66CO4bc5OD4fWF-56F4h32S0WvH5smD4Yurhn-1024.npz
Starting evaluation at step 254000 Counter(254000) 253937
Saved chunk: 20230922T031053F771431-3mnTSE7NutYeQJ99OjN6P9-2ivDDCZocOGbhB0jbjD7cp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 254500 Counter(254500) 254437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031207F564298-56F4h32S0WvH5smD4Yurhn-2e6SyN4iK6n86cEcSOzzVz-1024.npz
Starting evaluation at step 255000 Counter(255000) 254937
Saved chunk: 20230922T031213F494508-2ivDDCZocOGbhB0jbjD7cp-6LfpUq1zTn0zikYZpt9L3M-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 255500 Counter(255500) 255437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 256000 Counter(256000) 255937
Saved chunk: 20230922T031327F876938-2e6SyN4iK6n86cEcSOzzVz-1XYU5Zy2SUdLP3t0tP9XS0-1024.npz
Saved chunk: 20230922T031332F227979-6LfpUq1zTn0zikYZpt9L3M-3vD3oCiRe5ObBZgrmPgcHd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 256500 Counter(256500) 256437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 257000 Counter(257000) 256937
Saved chunk: 20230922T031450F859667-3vD3oCiRe5ObBZgrmPgcHd-0QjBRYgniow4RWFBMuileu-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 514002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.4e-7 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 4.1e-11 / train/cont_loss_std 4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4e-6 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 4.7e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.3 / train/model_loss_mean 1.18 / train/model_loss_std 2.25 / train/model_opt_grad_norm 5.85 / 
train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 8718.68 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 3.9e-4 / train/policy_logprob_mag 9.53 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.53 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.7e-4 / train/post_ent_mag 66.21 / train/post_ent_max 66.21 / train/post_ent_mean 41.11 / train/post_ent_min 25.58 / train/post_ent_std 4.17 / 
train/prior_ent_mag 69.6 / train/prior_ent_max 69.6 / train/prior_ent_mean 42.65 / train/prior_ent_min 32.28 / train/prior_ent_std 4.83 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.41 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 5.8e-11 / report/cont_loss_std 4.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.94 / 
report/dyn_loss_std 4.58 / report/image_loss_mean 0.22 / report/image_loss_std 0.48 / report/model_loss_mean 1.39 / report/model_loss_std 3.12 / report/post_ent_mag 66.5 / report/post_ent_max 66.5 / report/post_ent_mean 41.69 / report/post_ent_min 26.66 / 
report/post_ent_std 4.34 / report/prior_ent_mag 69.96 / report/prior_ent_max 69.96 / report/prior_ent_mean 43.32 / report/prior_ent_min 32.62 / report/prior_ent_std 5.01 / report/rep_loss_mean 1.94 / report/rep_loss_std 4.58 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.23 / eval/image_loss_mean 
0.18 / eval/image_loss_std 0.37 / eval/model_loss_mean 1.21 / eval/model_loss_std 2.18 / eval/post_ent_mag 65.49 / eval/post_ent_max 65.49 / eval/post_ent_mean 40.76 / eval/post_ent_min 27.6 / eval/post_ent_std 3.87 / eval/prior_ent_mag 69.96 / eval/prior_ent_max 69.96 / 
eval/prior_ent_mean 42.32 / eval/prior_ent_min 32.05 / eval/prior_ent_std 4.6 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.23 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.6e5 / replay/inserts 3806 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
301.11 / timer/env.step_count 3806 / timer/env.step_total 18.81 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.87 / timer/replay._sample_frac 
1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7814 / timer/agent.policy_total 16.88 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 7e-3 / timer/dataset_train_count 1903 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / 
timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1903 / timer/agent.train_total 244.89 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 
/ timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / 
timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T031448F083440-1XYU5Zy2SUdLP3t0tP9XS0-7mLzl4D3ttwdlSJ1YlCd4j-1024.npz
Starting evaluation at step 257500 Counter(257500) 257437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 258000 Counter(258000) 257937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031609F348168-0QjBRYgniow4RWFBMuileu-36Oev64CSyDsssilRcqsnp-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031612F338281-7mLzl4D3ttwdlSJ1YlCd4j-1hRMiTTZIE0Q1SDtgSrVDV-1024.npz
Starting evaluation at step 258500 Counter(258500) 258437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 259000 Counter(259000) 258937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031729F236747-36Oev64CSyDsssilRcqsnp-3gURtdzAsLp34GFn5po2eu-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031733F028515-1hRMiTTZIE0Q1SDtgSrVDV-1moC2uZqbmWoHxz50c2AMW-1024.npz
Starting evaluation at step 259500 Counter(259500) 259437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 260000 Counter(260000) 259937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T031853F464058-1moC2uZqbmWoHxz50c2AMW-14FIyHx33utu0mMyLGsO14-1024.npz
Starting evaluation at step 260500 Counter(260500) 260437
Saved chunk: 20230922T031848F101644-3gURtdzAsLp34GFn5po2eu-7HQ8OEndOFz72CE0Yqc4bp-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 521670 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train_stats/mean_log_entropy 1.42 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.49 / train/action_min -3.92
/ train/action_std 1.08 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.9e-7 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / 
train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.71 / train/dyn_loss_std 3.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.6e-6 / train/extr_critic_critic_opt_grad_steps 1.3e5 / 
train/extr_critic_critic_opt_loss 2e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / 
train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / 
train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.2 / train/model_loss_std 
2.29 / train/model_opt_grad_norm 5.53 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.4 / train/policy_entropy_std 4.2e-4 / train/policy_logprob_mag 9.57 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.57 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.8e-4 / train/post_ent_mag 65.93 / train/post_ent_max 65.93 / train/post_ent_mean 41.2 / train/post_ent_min 
25.59 / train/post_ent_std 4.2 / train/prior_ent_mag 69.7 / train/prior_ent_max 69.7 / train/prior_ent_mean 42.76 / train/prior_ent_min 32.09 / train/prior_ent_std 4.85 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.47 / train/reward_avg 0 / train/reward_loss_mean 
4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.76 / report/dyn_loss_std 4.37 / report/image_loss_mean 0.18 / report/image_loss_std 0.53 / report/model_loss_mean 1.23 / report/model_loss_std 2.96 / report/post_ent_mag 66.16 / report/post_ent_max 66.16 / report/post_ent_mean 40.72 / 
report/post_ent_min 26.02 / report/post_ent_std 4.53 / report/prior_ent_mag 69.95 / report/prior_ent_max 69.95 / report/prior_ent_mean 42.49 / report/prior_ent_min 30.39 / report/prior_ent_std 5.14 / report/rep_loss_mean 1.76 / report/rep_loss_std 4.37 / report/reward_avg
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.77 / eval/dyn_loss_std 3.97 / 
eval/image_loss_mean 0.16 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.61 / eval/post_ent_mag 65.54 / eval/post_ent_max 65.54 / eval/post_ent_mean 40.41 / eval/post_ent_min 23.7 / eval/post_ent_std 4.11 / eval/prior_ent_mag 69.95 / 
eval/prior_ent_max 69.95 / eval/prior_ent_mean 42.26 / eval/prior_ent_min 32.76 / eval/prior_ent_std 4.76 / eval/rep_loss_mean 1.77 / eval/rep_loss_std 3.97 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.6e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3834 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 396.93 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7341 / timer/agent.policy_total 16.08 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / 
timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1917 / timer/agent.train_total 246.64 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 
0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / 
timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 261000 Counter(261000) 260937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032013F682712-14FIyHx33utu0mMyLGsO14-2ngj0yejCJYbIcYmkeGDrk-1024.npz
Starting evaluation at step 261500 Counter(261500) 261437
Saved chunk: 20230922T032042F691885-7HQ8OEndOFz72CE0Yqc4bp-7kvJuwK47RpiXd24kDADZA-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 262000 Counter(262000) 261937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032134F773661-2ngj0yejCJYbIcYmkeGDrk-0lck15LN9fNY2Aqns4KoF3-1024.npz
Starting evaluation at step 262500 Counter(262500) 262437
Saved chunk: 20230922T032202F289000-7kvJuwK47RpiXd24kDADZA-3tKt0Rpl6uXUaqJwYuItc0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 263000 Counter(263000) 262937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032255F122118-0lck15LN9fNY2Aqns4KoF3-25p0GzH1HMMRQ6bcuweyFD-1024.npz
Starting evaluation at step 263500 Counter(263500) 263437
Saved chunk: 20230922T032320F937298-3tKt0Rpl6uXUaqJwYuItc0-28bcoikYq5i31KgLeF5qM3-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T032415F259560-25p0GzH1HMMRQ6bcuweyFD-0000000000000000000000-732.npz
Saved chunk: 20230922T032439F451338-28bcoikYq5i31KgLeF5qM3-0000000000000000000000-434.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 264000 Counter(264000) 263937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032415F259560-25p0GzH1HMMRQ6bcuweyFD-2AxubUFZZwUN5u2Yt9bJYV-1024.npz
Starting evaluation at step 264500 Counter(264500) 264437
Saved chunk: 20230922T032439F451338-28bcoikYq5i31KgLeF5qM3-1ywL6KwdfRPDuEJEtcQjmd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 529258 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.6e-7 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.7e-6 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
3.4e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.32 / train/model_loss_mean 1.2 / train/model_loss_std 2.3 / train/model_opt_grad_norm 5.66 / 
train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4.1e-4 / train/policy_logprob_mag 9.39 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.39 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.8e-4 / train/post_ent_mag 66.28 / train/post_ent_max 66.28 / train/post_ent_mean 41.25 / train/post_ent_min 25.39 / train/post_ent_std 4.18 / train/prior_ent_mag 69.71 / 
train/prior_ent_max 69.71 / train/prior_ent_mean 42.8 / train/prior_ent_min 31.85 / train/prior_ent_std 4.84 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.48 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 
/ report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 2.46 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.16 / report/model_loss_mean 1.04 / report/model_loss_std 1.56 / report/post_ent_mag 65.11 / report/post_ent_max 65.11 / report/post_ent_mean 40.72 / report/post_ent_min 24.61 / report/post_ent_std 4.07 / 
report/prior_ent_mag 69.72 / report/prior_ent_max 69.72 / report/prior_ent_mean 42.23 / report/prior_ent_min 32.65 / report/prior_ent_std 4.68 / report/rep_loss_mean 1.54 / report/rep_loss_std 2.46 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-11 / 
eval/cont_loss_std 6.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.25 /
eval/model_loss_mean 1.11 / eval/model_loss_std 1.84 / eval/post_ent_mag 65.32 / eval/post_ent_max 65.32 / eval/post_ent_mean 40.38 / eval/post_ent_min 22.65 / eval/post_ent_std 4.14 / eval/prior_ent_mag 69.72 / eval/prior_ent_max 69.72 / eval/prior_ent_mean 42.02 / 
eval/prior_ent_min 32.82 / eval/prior_ent_std 4.75 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 2.75 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.6e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.4e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3794 / timer/env.step_total 18.84 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.3 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7802 / timer/agent.policy_total 16.92 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1897 / timer/agent.train_total 243.76 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 265000 Counter(265000) 264937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032535F492817-2AxubUFZZwUN5u2Yt9bJYV-5vo2dE9XZRsISQR0jQL2Bu-1024.npz
Starting evaluation at step 265500 Counter(265500) 265437
Saved chunk: 20230922T032558F093946-1ywL6KwdfRPDuEJEtcQjmd-3pho2XwqCshAWYNjP1fueW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 266000 Counter(266000) 265937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032656F620973-5vo2dE9XZRsISQR0jQL2Bu-576OTrNM7lF10dGddZxTbc-1024.npz
Starting evaluation at step 266500 Counter(266500) 266437
Saved chunk: 20230922T032717F792169-3pho2XwqCshAWYNjP1fueW-1JfxM1cSqxaJZu5ESYww0c-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 267000 Counter(267000) 266937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032816F952956-576OTrNM7lF10dGddZxTbc-1LC1GrdfxwcJqVWeS520TV-1024.npz
Starting evaluation at step 267500 Counter(267500) 267437
Saved chunk: 20230922T032836F487208-1JfxM1cSqxaJZu5ESYww0c-2JFoNguPfAgwc9VEQ9JAx2-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 268000 Counter(268000) 267937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T032937F082604-1LC1GrdfxwcJqVWeS520TV-7bTmAjIWwkF9fDFM6YYDrI-1024.npz
 Step 536938 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.49 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.4e-7 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std 
3.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.6e-7 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 1.5e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.3 / train/model_loss_mean 1.18 / train/model_loss_std 2.26 / train/model_opt_grad_norm 5.23 / 
train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 8736.21 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 3.8e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.7e-4 / train/post_ent_mag 66.43 / train/post_ent_max 66.43 / train/post_ent_mean 41.18 / train/post_ent_min 25.47 / train/post_ent_std 4.19 / 
train/prior_ent_mag 69.83 / train/prior_ent_max 69.83 / train/prior_ent_mean 42.73 / train/prior_ent_min 32.24 / train/prior_ent_std 4.87 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.42 / train/reward_avg 0 / train/reward_loss_mean 9.7e-12 / train/reward_loss_std 
3.1e-10 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.7e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / report/cont_loss_mean 5e-11 / report/cont_loss_std 2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.84 / report/dyn_loss_std 3.2 / report/image_loss_mean 0.24 / report/image_loss_std 0.4 / report/model_loss_mean 1.34 / report/model_loss_std 2.13 / report/post_ent_mag 65.95 / report/post_ent_max 65.95 / report/post_ent_mean 40.85 / 
report/post_ent_min 24.65 / report/post_ent_std 4.71 / report/prior_ent_mag 69.76 / report/prior_ent_max 69.76 / report/prior_ent_mean 42.87 / report/prior_ent_min 29.34 / report/prior_ent_std 5.19 / report/rep_loss_mean 1.84 / report/rep_loss_std 3.2 / report/reward_avg 
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 2.8e-11 / eval/cont_loss_std 2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 2.73 / 
eval/image_loss_mean 0.14 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.75 / eval/post_ent_mag 64.98 / eval/post_ent_max 64.98 / eval/post_ent_mean 40.9 / eval/post_ent_min 27.33 / eval/post_ent_std 4.1 / eval/prior_ent_mag 69.76 / 
eval/prior_ent_max 69.76 / eval/prior_ent_mean 42.5 / eval/prior_ent_min 32.83 / eval/prior_ent_std 4.71 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 2.73 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.7e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3840 / timer/env.step_total 18.96 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 397.14 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7347 / timer/agent.policy_total 15.88 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / 
timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1920 / timer/agent.train_total 247.02 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / 
timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 268500 Counter(268500) 268437
Saved chunk: 20230922T032955F051561-2JFoNguPfAgwc9VEQ9JAx2-6GDznJpTl73WKWoPgjXbD8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 269000 Counter(269000) 268937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T033057F197671-7bTmAjIWwkF9fDFM6YYDrI-5FFZMEdFe12cELs2aEWsFF-1024.npz
Starting evaluation at step 269500 Counter(269500) 269437
Saved chunk: 20230922T033114F299233-6GDznJpTl73WKWoPgjXbD8-6TPrGO2EbISRfnLPAl11yE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 270000 Counter(270000) 269937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T033218F474365-5FFZMEdFe12cELs2aEWsFF-6JB9zP2QmaC900plqzRhLK-1024.npz
Starting evaluation at step 270500 Counter(270500) 270437
Saved chunk: 20230922T033233F320803-6TPrGO2EbISRfnLPAl11yE-25LDY88Nzc9I06sel5MVxw-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 271000 Counter(271000) 270937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T033338F772833-6JB9zP2QmaC900plqzRhLK-7zxPBhw4Uv1C6oJjF0VeBQ-1024.npz
Starting evaluation at step 271500 Counter(271500) 271437
Saved chunk: 20230922T033352F025883-25LDY88Nzc9I06sel5MVxw-1oukQl86DjPsuZ0jdPAPVt-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 272000 Counter(272000) 271937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 544522 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.48 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.5e-7 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std
3.51 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.4e-6 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 3.9e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.19 / train/model_loss_std 2.32 / train/model_opt_grad_norm 5.12 / 
train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 4e-4 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.7e-4 / train/post_ent_mag 66.32 / train/post_ent_max 66.32 / train/post_ent_mean 41.02 / train/post_ent_min 25.5 / train/post_ent_std 4.22 / train/prior_ent_mag 69.88 / 
train/prior_ent_max 69.88 / train/prior_ent_mean 42.57 / train/prior_ent_min 31.98 / train/prior_ent_std 4.91 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.51 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.44 / report/dyn_loss_std 2.16 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.15 / report/model_loss_mean 1 / report/model_loss_std 1.37 / report/post_ent_mag 67.31 / report/post_ent_max 67.31 / report/post_ent_mean 41.2 / report/post_ent_min 27.54 / report/post_ent_std 4.37 / 
report/prior_ent_mag 70.38 / report/prior_ent_max 70.38 / report/prior_ent_mean 42.6 / report/prior_ent_min 32.43 / report/prior_ent_std 4.89 / report/rep_loss_mean 1.44 / report/rep_loss_std 2.16 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.5e-12 / 
eval/cont_loss_std 4.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.56 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.32 /
eval/model_loss_mean 1.17 / eval/model_loss_std 2.38 / eval/post_ent_mag 66.34 / eval/post_ent_max 66.34 / eval/post_ent_mean 39.74 / eval/post_ent_min 25.05 / eval/post_ent_std 3.76 / eval/prior_ent_mag 70.38 / eval/prior_ent_max 70.38 / eval/prior_ent_mean 41.76 / 
eval/prior_ent_min 32.85 / eval/prior_ent_std 4.56 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.56 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.7e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / 
timer/env.step_count 3792 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.12 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7800 / timer/agent.policy_total 16.82 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.2e-3 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T033458F945331-7zxPBhw4Uv1C6oJjF0VeBQ-2W0zXCETLJoWYBy9oPmGob-1024.npz
Starting evaluation at step 272500 Counter(272500) 272437
Saved chunk: 20230922T033510F576740-1oukQl86DjPsuZ0jdPAPVt-1cjNn0Y5OJS1k19gHTk2n2-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 273000 Counter(273000) 272937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T033619F848738-2W0zXCETLJoWYBy9oPmGob-2OusNQWEICPGEwQeXu1G2A-1024.npz
Starting evaluation at step 273500 Counter(273500) 273437
Saved chunk: 20230922T033629F965061-1cjNn0Y5OJS1k19gHTk2n2-5wAEtDajHMQQDkxhCmCaS7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 274000 Counter(274000) 273937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T033740F275609-2OusNQWEICPGEwQeXu1G2A-0jRIhAy4Hox63XEec2WR2f-1024.npz
Starting evaluation at step 274500 Counter(274500) 274437
Saved chunk: 20230922T033748F780308-5wAEtDajHMQQDkxhCmCaS7-4DhVG1pJ7NiDzxkfL21l6A-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 275000 Counter(275000) 274937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T033901F687786-0jRIhAy4Hox63XEec2WR2f-0000000000000000000000-968.npz
Saved chunk: 20230922T033908F595529-4DhVG1pJ7NiDzxkfL21l6A-0000000000000000000000-693.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T033901F687786-0jRIhAy4Hox63XEec2WR2f-1ftt5U9pbbsWdaoFAYoS4B-1024.npz
Starting evaluation at step 275500 Counter(275500) 275437
Saved chunk: 20230922T033908F595529-4DhVG1pJ7NiDzxkfL21l6A-2HC1GIIguiFqWI28UHCNyN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 276000 Counter(276000) 275937
eval_Episode has 500 steps and return 0.0.
 Step 552074 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.48 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.5e-7 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std
3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.1e-6 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 1.5e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.3 / train/model_loss_mean 1.19 / train/model_loss_std 2.26 / train/model_opt_grad_norm 5.47 / 
train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.9e-4 / train/policy_logprob_mag 9.51 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.51 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.7e-4 / train/post_ent_mag 66.75 / train/post_ent_max 66.75 / train/post_ent_mean 41.02 / train/post_ent_min 25.67 / train/post_ent_std 4.28 / train/prior_ent_mag 70.06 / 
train/prior_ent_max 70.06 / train/prior_ent_mean 42.57 / train/prior_ent_min 32.14 / train/prior_ent_std 4.95 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.43 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 5.2e-12 / report/cont_loss_std 2.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 2.87 / 
report/image_loss_mean 0.1 / report/image_loss_std 0.18 / report/model_loss_mean 1.03 / report/model_loss_std 1.86 / report/post_ent_mag 66.35 / report/post_ent_max 66.35 / report/post_ent_mean 40.39 / report/post_ent_min 28.39 / report/post_ent_std 3.41 / 
report/prior_ent_mag 69.89 / report/prior_ent_max 69.89 / report/prior_ent_mean 41.86 / report/prior_ent_min 32.41 / report/prior_ent_std 4.35 / report/rep_loss_mean 1.54 / report/rep_loss_std 2.87 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / 
eval/cont_loss_std 8.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / eval/dyn_loss_std 3.12 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.21 /
eval/model_loss_mean 1.13 / eval/model_loss_std 2 / eval/post_ent_mag 66.21 / eval/post_ent_max 66.21 / eval/post_ent_mean 40.62 / eval/post_ent_min 27.46 / eval/post_ent_std 3.92 / eval/prior_ent_mag 69.89 / eval/prior_ent_max 69.89 / eval/prior_ent_mean 42.32 / 
eval/prior_ent_min 32.68 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 3.12 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.8e5 / replay/inserts 3776 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / 
timer/env.step_count 3776 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.46 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7784 / timer/agent.policy_total 16.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1888 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1888 / timer/agent.train_total 243.82 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 
0.13 / timer/agent.train_max 1.49 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.17

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T034021F897888-1ftt5U9pbbsWdaoFAYoS4B-1dA6HwxsIhkvNfG2TSLa4v-1024.npz
Starting evaluation at step 276500 Counter(276500) 276437
Saved chunk: 20230922T034027F263885-2HC1GIIguiFqWI28UHCNyN-6dwOywV5tdHbHug1Gh9KaZ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 277000 Counter(277000) 276937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 277500 Counter(277500) 277437
Saved chunk: 20230922T034146F716587-6dwOywV5tdHbHug1Gh9KaZ-61xwj1SAbHqSy3PZVEXZmV-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034142F901425-1dA6HwxsIhkvNfG2TSLa4v-5dolPZlhhewiYKihYT4YYP-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 278000 Counter(278000) 277937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 278500 Counter(278500) 278437
Saved chunk: 20230922T034305F479111-61xwj1SAbHqSy3PZVEXZmV-3j3WgpLPWashtJHb2lOg6u-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034306F639896-5dolPZlhhewiYKihYT4YYP-6Mw9odVe8hSBfsnBxypilA-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 279000 Counter(279000) 278937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 279500 Counter(279500) 279437
Saved chunk: 20230922T034424F034352-3j3WgpLPWashtJHb2lOg6u-5YGGpCaE1CvwSsvyJYOYab-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034426F796326-6Mw9odVe8hSBfsnBxypilA-6xYyGdbVwIYlcFiLK8eO4x-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 559762 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.48 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.3e-7 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std
3.42 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.8e-6 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 4e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.3 / train/model_loss_mean 1.18 / train/model_loss_std 2.25 / train/model_opt_grad_norm 5.23 / 
train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.7e-4 / train/policy_logprob_mag 9.26 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.26 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.6e-4 / train/post_ent_mag 66.89 / train/post_ent_max 66.89 / train/post_ent_mean 41.05 / train/post_ent_min 25.4 / train/post_ent_std 4.25 / train/prior_ent_mag 69.97 / 
train/prior_ent_max 69.97 / train/prior_ent_mean 42.59 / train/prior_ent_min 32.41 / train/prior_ent_std 4.94 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.42 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 4.3e-11 / report/cont_loss_std 2.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.61 / 
report/image_loss_mean 0.18 / report/image_loss_std 0.4 / report/model_loss_mean 1.23 / report/model_loss_std 2.47 / report/post_ent_mag 66.64 / report/post_ent_max 66.64 / report/post_ent_mean 41.95 / report/post_ent_min 24.13 / report/post_ent_std 4.39 / 
report/prior_ent_mag 69.91 / report/prior_ent_max 69.91 / report/prior_ent_mean 43.49 / report/prior_ent_min 28.21 / report/prior_ent_std 5.08 / report/rep_loss_mean 1.76 / report/rep_loss_std 3.61 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-12 / 
eval/cont_loss_std 1.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.6 / eval/dyn_loss_std 3 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.23 / 
eval/model_loss_mean 1.08 / eval/model_loss_std 1.93 / eval/post_ent_mag 66.97 / eval/post_ent_max 66.97 / eval/post_ent_mean 39.83 / eval/post_ent_min 22.26 / eval/post_ent_std 4.25 / eval/prior_ent_mag 69.91 / eval/prior_ent_max 69.91 / eval/prior_ent_mean 41.55 / 
eval/prior_ent_min 33.45 / eval/prior_ent_std 4.49 / eval/rep_loss_mean 1.6 / eval/rep_loss_std 3 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / 
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.8e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / 
timer/env.step_count 3844 / timer/env.step_total 18.94 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.98 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7351 / timer/agent.policy_total 15.83 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.5e-3 / timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1922 / timer/agent.train_total 247.15 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 280000 Counter(280000) 279937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 280500 Counter(280500) 280437
Saved chunk: 20230922T034542F492981-5YGGpCaE1CvwSsvyJYOYab-1wEz9iaJOkI1oFL8ei1olF-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034546F803440-6xYyGdbVwIYlcFiLK8eO4x-3tr69AynPcVEKvfkIJ7EYi-1024.npz
Starting evaluation at step 281000 Counter(281000) 280937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 281500 Counter(281500) 281437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034702F085632-1wEz9iaJOkI1oFL8ei1olF-3iTiZP8wz2rLkCXkRoRgDz-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034708F000298-3tr69AynPcVEKvfkIJ7EYi-5SnzpatRA50YewlC9nqU73-1024.npz
Starting evaluation at step 282000 Counter(282000) 281937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 282500 Counter(282500) 282437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034820F803326-3iTiZP8wz2rLkCXkRoRgDz-1nC7OOUmiOExrOPaQI6LQC-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034828F255704-5SnzpatRA50YewlC9nqU73-3SqqwbKrArSmrrPVwdCDOK-1024.npz
Starting evaluation at step 283000 Counter(283000) 282937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 283500 Counter(283500) 283437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T034948F485160-3SqqwbKrArSmrrPVwdCDOK-42Bd70oqjk85om5sMu2G2K-1024.npz
 Step 567350 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.4e-7 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std 
3.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-6 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 2.7e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.19 / train/model_loss_std 2.29 / train/model_opt_grad_norm 5.48 / 
train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.8e-4 / train/policy_logprob_mag 9.38 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.38 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.6e-4 / train/post_ent_mag 66.91 / train/post_ent_max 66.91 / train/post_ent_mean 40.9 / train/post_ent_min 25.49 / train/post_ent_std 4.28 / train/prior_ent_mag 70.11 / 
train/prior_ent_max 70.11 / train/prior_ent_mean 42.48 / train/prior_ent_min 32.15 / train/prior_ent_std 4.97 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.48 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.53 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.35 / report/model_loss_mean 1.14 / report/model_loss_std 2.37 / report/post_ent_mag 66.7 / report/post_ent_max 66.7 / report/post_ent_mean 41.34 / report/post_ent_min 27.21 / report/post_ent_std 4.59 / 
report/prior_ent_mag 69.86 / report/prior_ent_max 69.86 / report/prior_ent_mean 42.8 / report/prior_ent_min 32.99 / report/prior_ent_std 5.08 / report/rep_loss_mean 1.63 / report/rep_loss_std 3.53 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.45 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.19 /
eval/model_loss_mean 1.06 / eval/model_loss_std 1.58 / eval/post_ent_mag 66.84 / eval/post_ent_max 66.84 / eval/post_ent_mean 40.29 / eval/post_ent_min 24.74 / eval/post_ent_std 4.42 / eval/prior_ent_mag 69.86 / eval/prior_ent_max 69.86 / eval/prior_ent_mean 41.86 / 
eval/prior_ent_min 33.08 / eval/prior_ent_std 4.83 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.45 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.8e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3794 / timer/env.step_total 18.85 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.82 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.5e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.6e-3 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1897 / timer/agent.train_total 243.89 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 284000 Counter(284000) 283937
Saved chunk: 20230922T034939F464229-1nC7OOUmiOExrOPaQI6LQC-2P2WO8GaU3k8XUHIo5Bn97-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 284500 Counter(284500) 284437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035108F477098-42Bd70oqjk85om5sMu2G2K-6qmY7DURfdFEzj0aZKIqAZ-1024.npz
Starting evaluation at step 285000 Counter(285000) 284937
Saved chunk: 20230922T035134F722137-2P2WO8GaU3k8XUHIo5Bn97-1nxHR3h26iw4lKdoV24GJr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 285500 Counter(285500) 285437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035229F767558-6qmY7DURfdFEzj0aZKIqAZ-6RwGDwoIQM6lgMkSw0F8KB-1024.npz
Starting evaluation at step 286000 Counter(286000) 285937
Saved chunk: 20230922T035253F502186-1nxHR3h26iw4lKdoV24GJr-2Fu1Yc54NZoKmO689xEL77-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 286500 Counter(286500) 286437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035349F981954-6RwGDwoIQM6lgMkSw0F8KB-53KNF8sJOoeIBtwbMVL7rU-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T035510F219487-53KNF8sJOoeIBtwbMVL7rU-0000000000000000000000-180.npz
Saved chunk: 20230922T035412F135484-2Fu1Yc54NZoKmO689xEL77-0000000000000000000000-952.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 287000 Counter(287000) 286937
Saved chunk: 20230922T035412F135484-2Fu1Yc54NZoKmO689xEL77-3J32EJ9AAv878ftRrDWsys-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 287500 Counter(287500) 287437
eval_Episode has 500 steps and return 0.0.
 Step 575002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.48 / train/action_min -3.91 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.4e-7 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / 
train/dyn_loss_std 3.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.9e-6 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
3.5e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.18 / train/model_loss_std 2.21 / train/model_opt_grad_norm 5.57 / 
train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 8946.17 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7578.12 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 3.8e-4 / train/policy_logprob_mag 9.36 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.36 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.7e-4 / train/post_ent_mag 66.9 / train/post_ent_max 66.9 / train/post_ent_mean 40.93 / train/post_ent_min 25.71 / train/post_ent_std 4.26 / 
train/prior_ent_mag 70.05 / train/prior_ent_max 70.05 / train/prior_ent_mean 42.49 / train/prior_ent_min 32.23 / train/prior_ent_std 4.95 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.35 / train/reward_avg 0 / train/reward_loss_mean 5.8e-11 / train/reward_loss_std 
1.9e-9 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.61 / report/image_loss_mean 0.17 / report/image_loss_std 0.26 / report/model_loss_mean 1.18 / report/model_loss_std 2.36 / report/post_ent_mag 67.46 / report/post_ent_max 67.46 / report/post_ent_mean 41.11 / 
report/post_ent_min 27.66 / report/post_ent_std 4.4 / report/prior_ent_mag 69.74 / report/prior_ent_max 69.74 / report/prior_ent_mean 42.49 / report/prior_ent_min 31.86 / report/prior_ent_std 4.99 / report/rep_loss_mean 1.68 / report/rep_loss_std 3.61 / report/reward_avg 
0 / report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.81 / 
eval/image_loss_mean 0.13 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.84 / eval/post_ent_mag 67.24 / eval/post_ent_max 67.24 / eval/post_ent_mean 40.47 / eval/post_ent_min 24.32 / eval/post_ent_std 4.13 / eval/prior_ent_mag 69.74 / 
eval/prior_ent_max 69.74 / eval/prior_ent_mean 42.21 / eval/prior_ent_min 33.05 / eval/prior_ent_std 4.75 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.81 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.9e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 302.84 / timer/env.step_count 3826 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 396.38 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / 
timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7834 / timer/agent.policy_total 17.18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1913 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1913 / timer/agent.train_total 246.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035510F219487-53KNF8sJOoeIBtwbMVL7rU-5lVLFiWdQErUQZknTsx3RP-1024.npz
Starting evaluation at step 288000 Counter(288000) 287937
Saved chunk: 20230922T035531F052908-3J32EJ9AAv878ftRrDWsys-6Pm7NC37w1bsvR03WFnCqd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 288500 Counter(288500) 288437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035631F616548-5lVLFiWdQErUQZknTsx3RP-6sMnHcIy2w1HYmVahREHKk-1024.npz
Starting evaluation at step 289000 Counter(289000) 288937
Saved chunk: 20230922T035650F707694-6Pm7NC37w1bsvR03WFnCqd-1UU4BxiL2GmCHz4zM2NaXO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 289500 Counter(289500) 289437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035752F041985-6sMnHcIy2w1HYmVahREHKk-5yQkELdHv3Wul1gNZnabrR-1024.npz
Starting evaluation at step 290000 Counter(290000) 289937
Saved chunk: 20230922T035809F439422-1UU4BxiL2GmCHz4zM2NaXO-0VqKLEsc8dOPkNaTRwDQjN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 290500 Counter(290500) 290437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T035912F208609-5yQkELdHv3Wul1gNZnabrR-6Ees2HU4osLhjvIfLuEl7I-1024.npz
Starting evaluation at step 291000 Counter(291000) 290937
Saved chunk: 20230922T035928F054856-0VqKLEsc8dOPkNaTRwDQjN-3kpm9ap4z3r0Jb41uyRXba-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 582682 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.48 / train/action_min -3.89 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.4e-7 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std
3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-6 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 2.8e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.17 / train/image_loss_std 0.31 / train/model_loss_mean 1.19 / train/model_loss_std 2.27 / train/model_opt_grad_norm 5.19 / 
train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9817.71 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.4 / train/policy_entropy_std 3.9e-4 / train/policy_logprob_mag 9.43 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.43 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.7e-4 / train/post_ent_mag 66.97 / train/post_ent_max 66.97 / train/post_ent_mean 40.91 / train/post_ent_min 25.4 / train/post_ent_std 4.35 / 
train/prior_ent_mag 69.98 / train/prior_ent_max 69.98 / train/prior_ent_mean 42.47 / train/prior_ent_min 32.05 / train/prior_ent_std 5 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.43 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 2.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / 
report/dyn_loss_std 2.82 / report/image_loss_mean 0.13 / report/image_loss_std 0.19 / report/model_loss_mean 1.09 / report/model_loss_std 1.82 / report/post_ent_mag 67.11 / report/post_ent_max 67.11 / report/post_ent_mean 41.1 / report/post_ent_min 17.22 / 
report/post_ent_std 4.6 / report/prior_ent_mag 70.19 / report/prior_ent_max 70.19 / report/prior_ent_mean 42.6 / report/prior_ent_min 33.17 / report/prior_ent_std 5.06 / report/rep_loss_mean 1.59 / report/rep_loss_std 2.82 / report/reward_avg 0 / report/reward_loss_mean 0
/ report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 1.1e-11 / eval/cont_loss_std 6.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.56 / eval/image_loss_mean 
0.13 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.06 / eval/model_loss_std 1.65 / eval/post_ent_mag 67.11 / eval/post_ent_max 67.11 / eval/post_ent_mean 40.27 / eval/post_ent_min 29.07 / eval/post_ent_std 4.07 / eval/prior_ent_mag 70.19 / eval/prior_ent_max 70.19 /
eval/prior_ent_mean 41.89 / eval/prior_ent_min 33.27 / eval/prior_ent_std 4.56 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.56 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 2.9e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.06 / timer/env.step_count 3840 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.79 / timer/replay._sample_frac 1.33
/ timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7347 / timer/agent.policy_total 15.95 / timer/agent.policy_frac 
0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.87 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 291500 Counter(291500) 291437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040032F433967-6Ees2HU4osLhjvIfLuEl7I-5N3XElpWBaeLWs6dT1CBUc-1024.npz
Starting evaluation at step 292000 Counter(292000) 291937
Saved chunk: 20230922T040046F638832-3kpm9ap4z3r0Jb41uyRXba-4qHwBGRuouYczMnbIZLG25-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 292500 Counter(292500) 292437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040153F493581-5N3XElpWBaeLWs6dT1CBUc-0aZPK5p3bRUVJ6dPjWQISA-1024.npz
Starting evaluation at step 293000 Counter(293000) 292937
Saved chunk: 20230922T040206F252694-4qHwBGRuouYczMnbIZLG25-2U1KwSL3yFoX54glW50jvC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 293500 Counter(293500) 293437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040313F711817-0aZPK5p3bRUVJ6dPjWQISA-4JwVccNs4up3CxxWCrCFbw-1024.npz
Starting evaluation at step 294000 Counter(294000) 293937
Saved chunk: 20230922T040324F811112-2U1KwSL3yFoX54glW50jvC-2vjCrSmE3VOvMAKBNYxvJJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 294500 Counter(294500) 294437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040433F704268-4JwVccNs4up3CxxWCrCFbw-2FnlEg9Vg00fizGPobwq9T-1024.npz
Starting evaluation at step 295000 Counter(295000) 294937
Saved chunk: 20230922T040443F222018-2vjCrSmE3VOvMAKBNYxvJJ-0dSFyXTxss2KNHgiMPLlES-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 590282 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.66 / train/action_mean 0.48 / train/action_min -3.88 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.1e-7 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / train/dyn_loss_std 
3.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.5e-6 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 1.9e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.2 / train/model_opt_grad_norm 5.65 / 
train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.7e-4 / train/policy_logprob_mag 9.34 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.34 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.6e-4 / train/post_ent_mag 66.77 / train/post_ent_max 66.77 / train/post_ent_mean 40.95 / train/post_ent_min 25.38 / train/post_ent_std 4.23 / train/prior_ent_mag 69.94 / 
train/prior_ent_max 69.94 / train/prior_ent_mean 42.49 / train/prior_ent_min 32.26 / train/prior_ent_std 4.9 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.35 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 8.1e-12 / report/cont_loss_std 3.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.1e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 2.88 / 
report/image_loss_mean 0.11 / report/image_loss_std 0.21 / report/model_loss_mean 1.1 / report/model_loss_std 1.87 / report/post_ent_mag 66.83 / report/post_ent_max 66.83 / report/post_ent_mean 40.18 / report/post_ent_min 25.13 / report/post_ent_std 3.97 / 
report/prior_ent_mag 69.68 / report/prior_ent_max 69.68 / report/prior_ent_mean 41.73 / report/prior_ent_min 33.42 / report/prior_ent_std 4.59 / report/rep_loss_mean 1.64 / report/rep_loss_std 2.88 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.3e-12 / 
eval/cont_loss_std 1.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.3e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.28 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.31 /
eval/model_loss_mean 1.01 / eval/model_loss_std 1.59 / eval/post_ent_mag 66.49 / eval/post_ent_max 66.49 / eval/post_ent_mean 39.02 / eval/post_ent_min 24.28 / eval/post_ent_std 4.15 / eval/prior_ent_mag 69.68 / eval/prior_ent_max 69.68 / eval/prior_ent_mean 40.83 / 
eval/prior_ent_min 33.17 / eval/prior_ent_std 4.58 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.28 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 
1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3800 / 
timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.07 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 4.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7808 / timer/agent.policy_total 16.73 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 
/ timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5e-4 / 
timer/agent.train_count 1900 / timer/agent.train_total 244.08 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / 
timer/dataset_eval_max 3.4e-5 / fps 25.33

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 295500 Counter(295500) 295437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040553F666690-2FnlEg9Vg00fizGPobwq9T-5th1ZPK1raV0h6jad9cQ8O-1024.npz
Starting evaluation at step 296000 Counter(296000) 295937
Saved chunk: 20230922T040601F580331-0dSFyXTxss2KNHgiMPLlES-4aqOXYUo63p3Xbi583Qo78-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 296500 Counter(296500) 296437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040714F913907-5th1ZPK1raV0h6jad9cQ8O-4pdZ4DR4bavrHanlLXtvEV-1024.npz
Starting evaluation at step 297000 Counter(297000) 296937
Saved chunk: 20230922T040721F325519-4aqOXYUo63p3Xbi583Qo78-22MvUOEmmlHCKfBDvy3YSX-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 297500 Counter(297500) 297437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040835F203669-4pdZ4DR4bavrHanlLXtvEV-60FRML2XKKCVSUBURQi6jX-1024.npz
Starting evaluation at step 298000 Counter(298000) 297937
Saved chunk: 20230922T040840F033198-22MvUOEmmlHCKfBDvy3YSX-4qFQUVVgZvMvm8wqBc3eYg-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T040955F325124-60FRML2XKKCVSUBURQi6jX-0000000000000000000000-416.npz
Saved chunk: 20230922T040958F563565-4qFQUVVgZvMvm8wqBc3eYg-0000000000000000000000-187.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 298500 Counter(298500) 298437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 597958 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.47 / train/action_min -3.91 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.2e-7 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / train/dyn_loss_std 
3.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.4e-6 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 1.8e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.19 / train/model_opt_grad_norm 5.01 / 
train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.7e-4 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.6e-4 / train/post_ent_mag 66.51 / train/post_ent_max 66.51 / train/post_ent_mean 41.07 / train/post_ent_min 25.7 / train/post_ent_std 4.23 / train/prior_ent_mag 69.68 / 
train/prior_ent_max 69.68 / train/prior_ent_mean 42.6 / train/prior_ent_min 32.44 / train/prior_ent_std 4.89 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.34 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 
/ report/cont_loss_mean 2.9e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.87 / report/dyn_loss_std 4.3 / 
report/image_loss_mean 0.24 / report/image_loss_std 0.56 / report/model_loss_mean 1.35 / report/model_loss_std 2.88 / report/post_ent_mag 65.92 / report/post_ent_max 65.92 / report/post_ent_mean 41.69 / report/post_ent_min 28 / report/post_ent_std 4.47 / 
report/prior_ent_mag 69.52 / report/prior_ent_max 69.52 / report/prior_ent_mean 43.34 / report/prior_ent_min 33.39 / report/prior_ent_std 5.14 / report/rep_loss_mean 1.87 / report/rep_loss_std 4.3 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 9.2e-12 / 
eval/cont_loss_std 5.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / eval/dyn_loss_std 3.19 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.27 /
eval/model_loss_mean 1.11 / eval/model_loss_std 2.12 / eval/post_ent_mag 66.51 / eval/post_ent_max 66.51 / eval/post_ent_mean 40.08 / eval/post_ent_min 26.1 / eval/post_ent_std 3.57 / eval/prior_ent_mag 69.52 / eval/prior_ent_max 69.52 / eval/prior_ent_mean 41.72 / 
eval/prior_ent_min 32.51 / eval/prior_ent_std 4.55 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 3.19 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / 
timer/env.step_count 3838 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.73 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7345 / timer/agent.policy_total 15.99 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1919 / timer/agent.train_total 246.94 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 299000 Counter(299000) 298937
Saved chunk: 20230922T040958F563565-4qFQUVVgZvMvm8wqBc3eYg-4a38e7ymIHQpdunJG9Tvz0-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T040955F325124-60FRML2XKKCVSUBURQi6jX-6mxtttufBStu0WwIwrAiSM-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 299500 Counter(299500) 299437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 300000 Counter(300000) 299937
Saved chunk: 20230922T041118F022412-4a38e7ymIHQpdunJG9Tvz0-6JkcnjO6tgbXjPRETKFE7w-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041119F735162-6mxtttufBStu0WwIwrAiSM-7FVZ2zQpSikG8tw1S2M5Ui-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 300500 Counter(300500) 300437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 301000 Counter(301000) 300937
Saved chunk: 20230922T041236F921688-6JkcnjO6tgbXjPRETKFE7w-74ug1KTeNUUteyh2oeg9YW-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041240F216250-7FVZ2zQpSikG8tw1S2M5Ui-3zLijisF9OaPr4WjPFPatV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 301500 Counter(301500) 301437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 302000 Counter(302000) 301937
Saved chunk: 20230922T041355F504547-74ug1KTeNUUteyh2oeg9YW-3RZm9jURfByw35ECYtxn7d-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041400F383874-3zLijisF9OaPr4WjPFPatV-1CYRDV8qOX2h7K8bia9Hux-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 302500 Counter(302500) 302437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 605546 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.47 / train/action_min -3.95 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / train/dyn_loss_std 
3.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.5e-6 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 1.9e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.22 / train/model_opt_grad_norm 5.6 / 
train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.5e-4 / train/policy_logprob_mag 9.36 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.36 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.35 / train/post_ent_max 66.35 / train/post_ent_mean 41.04 / train/post_ent_min 25.63 / train/post_ent_std 4.11 / train/prior_ent_mag 69.5 / 
train/prior_ent_max 69.5 / train/prior_ent_mean 42.57 / train/prior_ent_min 32.73 / train/prior_ent_std 4.79 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.37 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.7e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.11 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.28 / report/model_loss_mean 1.14 / report/model_loss_std 2.09 / report/post_ent_mag 65.38 / report/post_ent_max 65.38 / report/post_ent_mean 40.71 / report/post_ent_min 28.16 / report/post_ent_std 3.09 / 
report/prior_ent_mag 69.37 / report/prior_ent_max 69.37 / report/prior_ent_mean 42.18 / report/prior_ent_min 33.49 / report/prior_ent_std 4.38 / report/rep_loss_mean 1.68 / report/rep_loss_std 3.11 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / 
eval/cont_loss_std 8.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 3.6 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.31 / 
eval/model_loss_mean 1.17 / eval/model_loss_std 2.35 / eval/post_ent_mag 65.47 / eval/post_ent_max 65.47 / eval/post_ent_mean 40.44 / eval/post_ent_min 24.34 / eval/post_ent_std 4.2 / eval/prior_ent_mag 69.37 / eval/prior_ent_max 69.37 / eval/prior_ent_mean 42.14 / 
eval/prior_ent_min 33.64 / eval/prior_ent_std 4.87 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 3.6 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 
1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3794 / 
timer/env.step_total 18.73 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 391.48 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.84 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 
/ timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / 
timer/agent.train_count 1897 / timer/agent.train_total 243.98 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 303000 Counter(303000) 302937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041514F140158-3RZm9jURfByw35ECYtxn7d-1lPTXabBg18aZUKge93i3s-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041520F593585-1CYRDV8qOX2h7K8bia9Hux-1qDwk22DU1x9NP0WK5Ug24-1024.npz
Starting evaluation at step 303500 Counter(303500) 303437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 304000 Counter(304000) 303937
Saved chunk: 20230922T041633F620788-1lPTXabBg18aZUKge93i3s-3AzckHoKAMPTOVaYtE6asD-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041641F677670-1qDwk22DU1x9NP0WK5Ug24-4xDU7e5I1BX4NMBAFfRbWr-1024.npz
Starting evaluation at step 304500 Counter(304500) 304437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 305000 Counter(305000) 304937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041752F410888-3AzckHoKAMPTOVaYtE6asD-7DjEDs2oQndzDvGlOT0D74-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041802F033809-4xDU7e5I1BX4NMBAFfRbWr-12W7NJOuJm2ks5hXoLpUgm-1024.npz
Starting evaluation at step 305500 Counter(305500) 305437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 306000 Counter(306000) 305937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041911F027879-7DjEDs2oQndzDvGlOT0D74-0xse7IBwwZYOl79TDkauqB-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T041922F204171-12W7NJOuJm2ks5hXoLpUgm-1k0Gqo1QgulKNJIG9qYufy-1024.npz
Starting evaluation at step 306500 Counter(306500) 306437
eval_Episode has 500 steps and return 0.0.
 Step 613134 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.48 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / train/dyn_loss_std 
3.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.7e-6 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 3e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.3 / train/model_loss_mean 1.18 / train/model_loss_std 2.25 / train/model_opt_grad_norm 5.1 / 
train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.5e-4 / train/policy_logprob_mag 9.52 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.52 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.17 / train/post_ent_max 66.17 / train/post_ent_mean 41.05 / train/post_ent_min 25.99 / train/post_ent_std 4.19 / train/prior_ent_mag 69.49 / 
train/prior_ent_max 69.49 / train/prior_ent_mean 42.59 / train/prior_ent_min 32.82 / train/prior_ent_std 4.85 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.41 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.1e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.21 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.37 / report/model_loss_mean 1.15 / report/model_loss_std 2.2 / report/post_ent_mag 66.75 / report/post_ent_max 66.75 / report/post_ent_mean 40.71 / report/post_ent_min 23.56 / report/post_ent_std 4.37 / 
report/prior_ent_mag 69.86 / report/prior_ent_max 69.86 / report/prior_ent_mean 42.21 / report/prior_ent_min 31.65 / report/prior_ent_std 4.74 / report/rep_loss_mean 1.67 / report/rep_loss_std 3.21 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / 
eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.65 / eval/dyn_loss_std 3.08 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.23 /
eval/model_loss_mean 1.12 / eval/model_loss_std 2 / eval/post_ent_mag 66.2 / eval/post_ent_max 66.2 / eval/post_ent_mean 39.97 / eval/post_ent_min 20.38 / eval/post_ent_std 3.64 / eval/prior_ent_mag 69.86 / eval/prior_ent_max 69.86 / eval/prior_ent_mean 41.55 / 
eval/prior_ent_min 32.28 / eval/prior_ent_std 4.67 / eval/rep_loss_mean 1.65 / eval/rep_loss_std 3.08 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.1e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3794 / timer/env.step_total 18.86 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3e4 / timer/replay._sample_total 390.96 / timer/replay._sample_frac 1.3 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.7e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.5e-3 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1897 / timer/agent.train_total 243.84 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 307000 Counter(307000) 306937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042042F197595-1k0Gqo1QgulKNJIG9qYufy-4YrCouJREEV91nH8xSSBXZ-1024.npz
Starting evaluation at step 307500 Counter(307500) 307437
Saved chunk: 20230922T042029F505934-0xse7IBwwZYOl79TDkauqB-5aOHTh4KC0ARjIvqDlkf3E-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 308000 Counter(308000) 307937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042203F416238-4YrCouJREEV91nH8xSSBXZ-70lRoP4SAcUDNXIn3nLtmF-1024.npz
Starting evaluation at step 308500 Counter(308500) 308437
Saved chunk: 20230922T042225F031203-5aOHTh4KC0ARjIvqDlkf3E-11wPnOVbVq3AbWDOmTRB9W-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 309000 Counter(309000) 308937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042323F646160-70lRoP4SAcUDNXIn3nLtmF-4bW9njSeI5b4AvNYmXf6rt-1024.npz
Starting evaluation at step 309500 Counter(309500) 309437
Saved chunk: 20230922T042343F650425-11wPnOVbVq3AbWDOmTRB9W-03cVNmzELLChA1yBEcnDZ1-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T042502F148231-03cVNmzELLChA1yBEcnDZ1-0000000000000000000000-446.npz
Saved chunk: 20230922T042443F769328-4bW9njSeI5b4AvNYmXf6rt-0000000000000000000000-652.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 310000 Counter(310000) 309937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042443F769328-4bW9njSeI5b4AvNYmXf6rt-31BYYzY9vBx7OhQJPSSOOE-1024.npz
 Step 620814 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.46 / train/action_min -3.95 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.6e-6 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 2e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.3 / train/model_loss_mean 1.18 / train/model_loss_std 2.24 / train/model_opt_grad_norm 5.53 / 
train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.6e-4 / train/policy_logprob_mag 9.55 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.55 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.54 / train/post_ent_max 66.54 / train/post_ent_mean 40.98 / train/post_ent_min 25.64 / train/post_ent_std 4.27 / train/prior_ent_mag 69.64 / 
train/prior_ent_max 69.64 / train/prior_ent_mean 42.52 / train/prior_ent_min 32.8 / train/prior_ent_std 4.94 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.4 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 0
/ train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.9e-11 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.65 / 
report/image_loss_mean 0.21 / report/image_loss_std 0.4 / report/model_loss_mean 1.22 / report/model_loss_std 2.49 / report/post_ent_mag 66.36 / report/post_ent_max 66.36 / report/post_ent_mean 42.28 / report/post_ent_min 27.31 / report/post_ent_std 5.06 / 
report/prior_ent_mag 69.39 / report/prior_ent_max 69.39 / report/prior_ent_mean 43.81 / report/prior_ent_min 32.53 / report/prior_ent_std 5.37 / report/rep_loss_mean 1.7 / report/rep_loss_std 3.65 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.9e-12 / 
eval/cont_loss_std 3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.9e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.58 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.15 / 
eval/model_loss_mean 1.04 / eval/model_loss_std 1.63 / eval/post_ent_mag 66.6 / eval/post_ent_max 66.6 / eval/post_ent_mean 39.62 / eval/post_ent_min 25.65 / eval/post_ent_std 3.84 / eval/prior_ent_mag 69.39 / eval/prior_ent_max 69.39 / eval/prior_ent_mean 41.17 / 
eval/prior_ent_min 33.34 / eval/prior_ent_std 4.44 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.58 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.1e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3840 / timer/env.step_total 19.08 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.38 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7347 / timer/agent.policy_total 15.97 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.7e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.81 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 310500 Counter(310500) 310437
Saved chunk: 20230922T042502F148231-03cVNmzELLChA1yBEcnDZ1-1l4NLAM7PUZE0b7zhL6JMV-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 311000 Counter(311000) 310937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042604F023053-31BYYzY9vBx7OhQJPSSOOE-7ua2aPQAC7aW1TqaBgX7id-1024.npz
Starting evaluation at step 311500 Counter(311500) 311437
Saved chunk: 20230922T042621F689611-1l4NLAM7PUZE0b7zhL6JMV-4mQMOgstLRNsa8Gvxa3S0C-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 312000 Counter(312000) 311937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042725F360564-7ua2aPQAC7aW1TqaBgX7id-1U8BLwfy8471UzOWHXxmwj-1024.npz
Starting evaluation at step 312500 Counter(312500) 312437
Saved chunk: 20230922T042740F692008-4mQMOgstLRNsa8Gvxa3S0C-1nMvOQEbtIm2PoGTRHt4A9-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 313000 Counter(313000) 312937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T042845F650758-1U8BLwfy8471UzOWHXxmwj-1zonCrQWru4gt6XsMKAqSu-1024.npz
Starting evaluation at step 313500 Counter(313500) 313437
Saved chunk: 20230922T042859F369457-1nMvOQEbtIm2PoGTRHt4A9-3QiCCfbAIMvwX7JIEy2JZY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 314000 Counter(314000) 313937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 628394 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.45 / train/action_min -3.98 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.4e-6 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 1.7e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.22 / train/model_opt_grad_norm 5.4 / 
train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.5e-4 / train/policy_logprob_mag 9.43 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.43 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.29 / train/post_ent_max 66.29 / train/post_ent_mean 40.88 / train/post_ent_min 25.84 / train/post_ent_std 4.27 / train/prior_ent_mag 69.6 / 
train/prior_ent_max 69.6 / train/prior_ent_mean 42.42 / train/prior_ent_min 32.88 / train/prior_ent_std 4.93 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.37 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 
/ report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.04 / 
report/image_loss_mean 0.18 / report/image_loss_std 0.23 / report/model_loss_mean 1.16 / report/model_loss_std 1.98 / report/post_ent_mag 67.12 / report/post_ent_max 67.12 / report/post_ent_mean 41.85 / report/post_ent_min 24.92 / report/post_ent_std 4.59 / 
report/prior_ent_mag 69.89 / report/prior_ent_max 69.89 / report/prior_ent_mean 43.29 / report/prior_ent_min 33.64 / report/prior_ent_std 5.21 / report/rep_loss_mean 1.63 / report/rep_loss_std 3.04 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-11 / 
eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 2.98 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.46 /
eval/model_loss_mean 1.12 / eval/model_loss_std 2.12 / eval/post_ent_mag 66.51 / eval/post_ent_max 66.51 / eval/post_ent_mean 39.85 / eval/post_ent_min 25.44 / eval/post_ent_std 4.2 / eval/prior_ent_mag 69.89 / eval/prior_ent_max 69.89 / eval/prior_ent_mean 41.54 / 
eval/prior_ent_min 33.67 / eval/prior_ent_std 5.1 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 2.98 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.1e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 
1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3790 / 
timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.88 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 
/ timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1895 / timer/agent.train_total 243.98 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / 
timer/dataset_eval_max 3.4e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T043005F845942-1zonCrQWru4gt6XsMKAqSu-409Ajrxd5NPeuzcBaOCeSj-1024.npz
Starting evaluation at step 314500 Counter(314500) 314437
Saved chunk: 20230922T043017F977973-3QiCCfbAIMvwX7JIEy2JZY-4hO4CIIAykNJu64Uk5joJ3-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 315000 Counter(315000) 314937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043126F835611-409Ajrxd5NPeuzcBaOCeSj-643sRPseXKiM5QjhjB14fY-1024.npz
Starting evaluation at step 315500 Counter(315500) 315437
Saved chunk: 20230922T043137F476711-4hO4CIIAykNJu64Uk5joJ3-6Ldb04ceoaOFdc87aEDgs4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 316000 Counter(316000) 315937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043247F344796-643sRPseXKiM5QjhjB14fY-4zclStn94eXlOk3TfD1SrR-1024.npz
Starting evaluation at step 316500 Counter(316500) 316437
Saved chunk: 20230922T043256F336349-6Ldb04ceoaOFdc87aEDgs4-2AQsbOqIStcXWoJ5wyH8Fj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 317000 Counter(317000) 316937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043407F531975-4zclStn94eXlOk3TfD1SrR-3LIOuA9CL9ECFI7IpGadV7-1024.npz
Starting evaluation at step 317500 Counter(317500) 317437
Saved chunk: 20230922T043414F975121-2AQsbOqIStcXWoJ5wyH8Fj-5M6fRcqKRfDBYffxxqjr1E-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 318000 Counter(318000) 317937
eval_Episode has 500 steps and return 0.0.
 Step 636002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.45 / train/action_min -3.97 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / train/dyn_loss_std 
3.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.2e-6 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 1.5e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.2 / train/model_opt_grad_norm 5.45 / 
train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.6e-4 / train/policy_logprob_mag 9.53 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.53 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.71 / train/post_ent_max 66.71 / train/post_ent_mean 40.89 / train/post_ent_min 25.95 / train/post_ent_std 4.32 / train/prior_ent_mag 69.75 / 
train/prior_ent_max 69.75 / train/prior_ent_mean 42.41 / train/prior_ent_min 32.58 / train/prior_ent_std 4.98 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.32 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 
/ report/cont_loss_mean 2e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.82 / report/dyn_loss_std 3.82 / 
report/image_loss_mean 0.18 / report/image_loss_std 0.44 / report/model_loss_mean 1.27 / report/model_loss_std 2.61 / report/post_ent_mag 66.29 / report/post_ent_max 66.29 / report/post_ent_mean 40.53 / report/post_ent_min 26.98 / report/post_ent_std 4.24 / 
report/prior_ent_mag 69.82 / report/prior_ent_max 69.82 / report/prior_ent_mean 42.27 / report/prior_ent_min 33.24 / report/prior_ent_std 5.19 / report/rep_loss_mean 1.82 / report/rep_loss_std 3.82 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.7e-12 / 
eval/cont_loss_std 3.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.65 / eval/dyn_loss_std 2.89 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.24 /
eval/model_loss_mean 1.12 / eval/model_loss_std 1.9 / eval/post_ent_mag 67.15 / eval/post_ent_max 67.15 / eval/post_ent_mean 39.61 / eval/post_ent_min 25.71 / eval/post_ent_std 4.41 / eval/prior_ent_mag 69.82 / eval/prior_ent_max 69.82 / eval/prior_ent_mean 41.33 / 
eval/prior_ent_min 33.13 / eval/prior_ent_std 4.98 / eval/rep_loss_mean 1.65 / eval/rep_loss_std 2.89 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.2e5 / replay/inserts 3804 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.87 / 
timer/env.step_count 3804 / timer/env.step_total 18.79 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.87 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7812 / timer/agent.policy_total 16.79 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.6e-3 / timer/dataset_train_count 1902 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1902 / timer/agent.train_total 244.76 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043527F629155-3LIOuA9CL9ECFI7IpGadV7-2ZMKmkU3u0phhbl2d4LGyA-1024.npz
Starting evaluation at step 318500 Counter(318500) 318437
Saved chunk: 20230922T043533F473682-5M6fRcqKRfDBYffxxqjr1E-0kIVginftOQ1p4PTFD1AuO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 319000 Counter(319000) 318937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043648F719377-2ZMKmkU3u0phhbl2d4LGyA-1ObbqSZ7AOt5qzQqE2j7iI-1024.npz
Starting evaluation at step 319500 Counter(319500) 319437
Saved chunk: 20230922T043653F008361-0kIVginftOQ1p4PTFD1AuO-6fwjOxyvqvi854P4VaI8om-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 320000 Counter(320000) 319937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 320500 Counter(320500) 320437
Saved chunk: 20230922T043811F718147-6fwjOxyvqvi854P4VaI8om-6VnvR8imecWKEYxhXleBlg-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043809F043157-1ObbqSZ7AOt5qzQqE2j7iI-4bJqQEhuWTUddqwuTSDjMi-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 321000 Counter(321000) 320937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T043930F306206-6VnvR8imecWKEYxhXleBlg-0000000000000000000000-705.npz
Saved chunk: 20230922T043932F561623-4bJqQEhuWTUddqwuTSDjMi-0000000000000000000000-888.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 321500 Counter(321500) 321437
Saved chunk: 20230922T043930F306206-6VnvR8imecWKEYxhXleBlg-7sKC7iw1RMzU8LsjRKfTbI-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T043932F561623-4bJqQEhuWTUddqwuTSDjMi-7Lte9B9G5e2DMWWsGdz4uq-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 643682 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.45 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.1e-6 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 2.5e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.3 / train/model_loss_mean 1.18 / train/model_loss_std 2.24 / train/model_opt_grad_norm 5.3 / 
train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.6e-4 / train/policy_logprob_mag 9.59 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.59 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.6e-4 / train/post_ent_mag 66.74 / train/post_ent_max 66.74 / train/post_ent_mean 40.81 / train/post_ent_min 25.75 / train/post_ent_std 4.33 / train/prior_ent_mag 69.71 / 
train/prior_ent_max 69.71 / train/prior_ent_mean 42.34 / train/prior_ent_min 32.74 / train/prior_ent_std 4.99 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.4 / train/reward_avg 0 / train/reward_loss_mean 1.9e-11 / train/reward_loss_std 6.2e-10 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.9e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 1.8e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 2.64 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.18 / report/model_loss_mean 1.07 / report/model_loss_std 1.7 / report/post_ent_mag 67.46 / report/post_ent_max 67.46 / report/post_ent_mean 40.91 / report/post_ent_min 26.81 / report/post_ent_std 3.59 / 
report/prior_ent_mag 69.67 / report/prior_ent_max 69.67 / report/prior_ent_mean 42.34 / report/prior_ent_min 33.41 / report/prior_ent_std 4.48 / report/rep_loss_mean 1.57 / report/rep_loss_std 2.64 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / 
eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.76 / eval/dyn_loss_std 4.13 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.28 /
eval/model_loss_mean 1.22 / eval/model_loss_std 2.67 / eval/post_ent_mag 66.62 / eval/post_ent_max 66.62 / eval/post_ent_mean 39.98 / eval/post_ent_min 26.56 / eval/post_ent_std 4.12 / eval/prior_ent_mag 69.67 / eval/prior_ent_max 69.67 / eval/prior_ent_mean 41.58 / 
eval/prior_ent_min 32.29 / eval/prior_ent_std 4.94 / eval/rep_loss_mean 1.76 / eval/rep_loss_std 4.13 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.2e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3840 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.82 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.2e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7347 / timer/agent.policy_total 16.01 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.9 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 322000 Counter(322000) 321937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 322500 Counter(322500) 322437
Saved chunk: 20230922T044048F963253-7sKC7iw1RMzU8LsjRKfTbI-2fOlPXGKnlJiscnH0u7Wdr-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044052F786283-7Lte9B9G5e2DMWWsGdz4uq-6vCFdiQX7jDdjzCLpSbRTY-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 323000 Counter(323000) 322937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 323500 Counter(323500) 323437
Saved chunk: 20230922T044208F579944-2fOlPXGKnlJiscnH0u7Wdr-4x07FItUjQxBH0We07Ku1T-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044214F004675-6vCFdiQX7jDdjzCLpSbRTY-1dxmfc4FWEIxslKpqlgWtm-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 324000 Counter(324000) 323937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 324500 Counter(324500) 324437
Saved chunk: 20230922T044327F297213-4x07FItUjQxBH0We07Ku1T-3in1uQYObc8edGa6Uw9rU8-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044334F274668-1dxmfc4FWEIxslKpqlgWtm-5f7z59ECZRf7oHVLG2pWGr-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 325000 Counter(325000) 324937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 325500 Counter(325500) 325437
Saved chunk: 20230922T044445F839781-3in1uQYObc8edGa6Uw9rU8-1Mi6oa7bGwI0EQUR1itEh7-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044454F388854-5f7z59ECZRf7oHVLG2pWGr-7wAMSAkaYhIdQ70unXUOVa-1024.npz
 Step 651274 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.45 / train/action_min -3.98 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4e-7 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.2e-6 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 1.5e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.21 / train/model_opt_grad_norm 5.08 / 
train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.6e-4 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.6e-4 / train/post_ent_mag 67.09 / train/post_ent_max 67.09 / train/post_ent_mean 40.88 / train/post_ent_min 26.14 / train/post_ent_std 4.32 / train/prior_ent_mag 69.83 / 
train/prior_ent_max 69.83 / train/prior_ent_mean 42.42 / train/prior_ent_min 32.7 / train/prior_ent_std 4.99 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.36 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.9e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.03 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.26 / report/model_loss_mean 1.16 / report/model_loss_std 1.98 / report/post_ent_mag 67.89 / report/post_ent_max 67.89 / report/post_ent_mean 41 / report/post_ent_min 25.26 / report/post_ent_std 4.42 / 
report/prior_ent_mag 69.82 / report/prior_ent_max 69.82 / report/prior_ent_mean 42.48 / report/prior_ent_min 25.42 / report/prior_ent_std 5.15 / report/rep_loss_mean 1.67 / report/rep_loss_std 3.03 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 9.8e-12 / 
eval/cont_loss_std 9.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.8e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.66 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.22 /
eval/model_loss_mean 1.06 / eval/model_loss_std 1.74 / eval/post_ent_mag 67.9 / eval/post_ent_max 67.9 / eval/post_ent_mean 40.15 / eval/post_ent_min 20.72 / eval/post_ent_std 4.16 / eval/prior_ent_mag 69.82 / eval/prior_ent_max 69.82 / eval/prior_ent_mean 41.65 / 
eval/prior_ent_min 32.96 / eval/prior_ent_std 4.65 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.66 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.3e5 / replay/inserts 3796 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / 
timer/env.step_count 3796 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.66 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7804 / timer/agent.policy_total 16.76 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1898 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1898 / timer/agent.train_total 244.01 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.3

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 326000 Counter(326000) 325937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 326500 Counter(326500) 326437
Saved chunk: 20230922T044604F236743-1Mi6oa7bGwI0EQUR1itEh7-2qByH2mQdcicGy44FNYFvI-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044614F332972-7wAMSAkaYhIdQ70unXUOVa-39BLaVek1joImrwCBPUR57-1024.npz
Starting evaluation at step 327000 Counter(327000) 326937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 327500 Counter(327500) 327437
Saved chunk: 20230922T044724F010673-2qByH2mQdcicGy44FNYFvI-3jlbjsTcNWEymYUpCXh3HI-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044735F733989-39BLaVek1joImrwCBPUR57-6jwsKNxEkwjxnxX5nZUMxu-1024.npz
Starting evaluation at step 328000 Counter(328000) 327937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 328500 Counter(328500) 328437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044842F699009-3jlbjsTcNWEymYUpCXh3HI-0g9eoONhpH4GNNy4nykyqH-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T044856F007026-6jwsKNxEkwjxnxX5nZUMxu-2MoJiW0ZywFhC8R6xD79SR-1024.npz
Starting evaluation at step 329000 Counter(329000) 328937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 658950 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.44 / train/action_min -3.98 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.8e-7 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 8.2e-7 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 1.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.24 / train/model_opt_grad_norm 5.44 / 
train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.4e-4 / train/policy_logprob_mag 9.5 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.5 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 67.18 / train/post_ent_max 67.18 / train/post_ent_mean 40.93 / train/post_ent_min 25.81 / train/post_ent_std 4.22 / train/prior_ent_mag 69.82 / 
train/prior_ent_max 69.82 / train/prior_ent_mean 42.46 / train/prior_ent_min 32.76 / train/prior_ent_std 4.9 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.4 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.9e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.33 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.23 / report/model_loss_mean 1.16 / report/model_loss_std 2.14 / report/post_ent_mag 67.27 / report/post_ent_max 67.27 / report/post_ent_mean 41.48 / report/post_ent_min 27.27 / report/post_ent_std 4.63 / 
report/prior_ent_mag 69.45 / report/prior_ent_max 69.45 / report/prior_ent_mean 43.11 / report/prior_ent_min 33.45 / report/prior_ent_std 5.12 / report/rep_loss_mean 1.66 / report/rep_loss_std 3.33 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.6e-11 / 
eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 2.79 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.23 / 
eval/model_loss_mean 1.11 / eval/model_loss_std 1.82 / eval/post_ent_mag 67.56 / eval/post_ent_max 67.56 / eval/post_ent_mean 39.82 / eval/post_ent_min 26.5 / eval/post_ent_std 4.5 / eval/prior_ent_mag 69.45 / eval/prior_ent_max 69.45 / eval/prior_ent_mean 41.64 / 
eval/prior_ent_min 33.36 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 2.79 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.3e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / 
timer/env.step_count 3838 / timer/env.step_total 18.96 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.43 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7345 / timer/agent.policy_total 16.06 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1919 / timer/agent.train_total 246.64 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 329500 Counter(329500) 329437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045001F343068-0g9eoONhpH4GNNy4nykyqH-2fgNfLawNSW8sVhvUTsyuq-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045016F163027-2MoJiW0ZywFhC8R6xD79SR-4L6QfQrDQrRsUKYvoxZjjE-1024.npz
Starting evaluation at step 330000 Counter(330000) 329937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 330500 Counter(330500) 330437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045137F171975-4L6QfQrDQrRsUKYvoxZjjE-6RofVQnBDmQlZF0xmpxJD0-1024.npz
Starting evaluation at step 331000 Counter(331000) 330937
Saved chunk: 20230922T045120F644514-2fgNfLawNSW8sVhvUTsyuq-12JgF4s6gm16sM5IutqniC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 331500 Counter(331500) 331437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045257F562392-6RofVQnBDmQlZF0xmpxJD0-2MWQSVHFBYfxBxGVuls9pH-1024.npz
Starting evaluation at step 332000 Counter(332000) 331937
Saved chunk: 20230922T045315F512364-12JgF4s6gm16sM5IutqniC-7vYknibn0Aj1E9Bh9gT12J-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 332500 Counter(332500) 332437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045417F874433-2MWQSVHFBYfxBxGVuls9pH-15LzfhJvKDPnmeuX3ibxYd-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T045538F145605-15LzfhJvKDPnmeuX3ibxYd-0000000000000000000000-100.npz
Saved chunk: 20230922T045434F229666-7vYknibn0Aj1E9Bh9gT12J-0000000000000000000000-964.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 333000 Counter(333000) 332937
Saved chunk: 20230922T045434F229666-7vYknibn0Aj1E9Bh9gT12J-5SyD1Zs92qOrKY8rD1b59p-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 666522 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.44 / train/action_min -3.93 / train/action_std 1.09 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.8e-7 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / train/dyn_loss_std 
3.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.9e-7 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 9.8e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.3 / train/model_loss_mean 1.17 / train/model_loss_std 2.21 / train/model_opt_grad_norm 5.2 / 
train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.4e-4 / train/policy_logprob_mag 9.41 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.41 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 67.26 / train/post_ent_max 67.26 / train/post_ent_mean 40.84 / train/post_ent_min 26.09 / train/post_ent_std 4.28 / train/prior_ent_mag 69.88 / 
train/prior_ent_max 69.88 / train/prior_ent_mean 42.36 / train/prior_ent_min 32.74 / train/prior_ent_std 4.96 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.36 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.9e-11 / report/cont_loss_std 7.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 2.89 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.24 / report/model_loss_mean 1.08 / report/model_loss_std 1.91 / report/post_ent_mag 67.39 / report/post_ent_max 67.39 / report/post_ent_mean 40.11 / report/post_ent_min 22.25 / report/post_ent_std 4.48 / 
report/prior_ent_mag 69.91 / report/prior_ent_max 69.91 / report/prior_ent_mean 41.59 / report/prior_ent_min 33.29 / report/prior_ent_std 4.86 / report/rep_loss_mean 1.57 / report/rep_loss_std 2.89 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.7e-12 / 
eval/cont_loss_std 4.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.61 / eval/dyn_loss_std 2.96 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.28 /
eval/model_loss_mean 1.11 / eval/model_loss_std 1.96 / eval/post_ent_mag 67.43 / eval/post_ent_max 67.43 / eval/post_ent_mean 39.72 / eval/post_ent_min 25.05 / eval/post_ent_std 4.64 / eval/prior_ent_mag 69.91 / eval/prior_ent_max 69.91 / eval/prior_ent_mean 41.25 / 
eval/prior_ent_min 33.17 / eval/prior_ent_std 5.01 / eval/rep_loss_mean 1.61 / eval/rep_loss_std 2.96 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.3e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3786 / timer/env.step_total 19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.92 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7794 / timer/agent.policy_total 16.95 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1893 / timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 333500 Counter(333500) 333437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045538F145605-15LzfhJvKDPnmeuX3ibxYd-22g27Gi2vxJFW2hibwNgE0-1024.npz
Starting evaluation at step 334000 Counter(334000) 333937
Saved chunk: 20230922T045553F038659-5SyD1Zs92qOrKY8rD1b59p-0SQaKnYL9MBrHqKNYQc8zz-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 334500 Counter(334500) 334437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045659F628732-22g27Gi2vxJFW2hibwNgE0-5vOp1dmGC91qVJbKhRVU0N-1024.npz
Starting evaluation at step 335000 Counter(335000) 334937
Saved chunk: 20230922T045712F811168-0SQaKnYL9MBrHqKNYQc8zz-408R3EO2EODawLTxpHZ5Bj-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 335500 Counter(335500) 335437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045819F843251-5vOp1dmGC91qVJbKhRVU0N-4MzQTk7lRZUEjf0FPyeUTy-1024.npz
Starting evaluation at step 336000 Counter(336000) 335937
Saved chunk: 20230922T045831F425297-408R3EO2EODawLTxpHZ5Bj-6v6eAfF3VYybFitLv6UbFh-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 336500 Counter(336500) 336437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T045939F950633-4MzQTk7lRZUEjf0FPyeUTy-1782Wrk9SxRvMGX7MEFkWQ-1024.npz
Starting evaluation at step 337000 Counter(337000) 336937
Saved chunk: 20230922T045949F942021-6v6eAfF3VYybFitLv6UbFh-2QmzQzsgMLNduf9obOkOVC-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 674106 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.45 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.6e-7 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / train/dyn_loss_std 
3.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 7.2e-7 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.28 / train/model_loss_mean 1.16 / train/model_loss_std 2.18 / train/model_opt_grad_norm 5.18 / 
train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.3e-4 / train/policy_logprob_mag 9.51 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.51 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.95 / train/post_ent_max 66.95 / train/post_ent_mean 40.73 / train/post_ent_min 25.91 / train/post_ent_std 4.31 / train/prior_ent_mag 69.71 / 
train/prior_ent_max 69.71 / train/prior_ent_mean 42.26 / train/prior_ent_min 32.82 / train/prior_ent_std 4.96 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.32 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.8 / report/dyn_loss_std 4.06 / 
report/image_loss_mean 0.21 / report/image_loss_std 0.44 / report/model_loss_mean 1.28 / report/model_loss_std 2.8 / report/post_ent_mag 66.95 / report/post_ent_max 66.95 / report/post_ent_mean 40.38 / report/post_ent_min 25.53 / report/post_ent_std 4.43 / 
report/prior_ent_mag 69.62 / report/prior_ent_max 69.62 / report/prior_ent_mean 42.01 / report/prior_ent_min 27.56 / report/prior_ent_std 5 / report/rep_loss_mean 1.8 / report/rep_loss_std 4.06 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 /
report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 9.6e-12 / 
eval/cont_loss_std 4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.6e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.55 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.22 / 
eval/model_loss_mean 1.08 / eval/model_loss_std 1.66 / eval/post_ent_mag 67.15 / eval/post_ent_max 67.15 / eval/post_ent_mean 40.04 / eval/post_ent_min 25.88 / eval/post_ent_std 4.35 / eval/prior_ent_mag 69.62 / eval/prior_ent_max 69.62 / eval/prior_ent_mean 41.74 / 
eval/prior_ent_min 33.7 / eval/prior_ent_std 4.82 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.55 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.4e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3792 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.56 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7800 / timer/agent.policy_total 16.82 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.5e-3 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.93 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 337500 Counter(337500) 337437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T050100F071479-1782Wrk9SxRvMGX7MEFkWQ-2FI4ucafQrJCAE3GxlnRmP-1024.npz
Starting evaluation at step 338000 Counter(338000) 337937
Saved chunk: 20230922T050108F530356-2QmzQzsgMLNduf9obOkOVC-0kP15porrLlMQGRWrbrZRN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 338500 Counter(338500) 338437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T050221F568297-2FI4ucafQrJCAE3GxlnRmP-6oMgaOtsqdZjYfK4HmgnqE-1024.npz
Starting evaluation at step 339000 Counter(339000) 338937
Saved chunk: 20230922T050228F467412-0kP15porrLlMQGRWrbrZRN-1uq41u5SKkiGZHGCD4heFs-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 339500 Counter(339500) 339437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T050341F916936-6oMgaOtsqdZjYfK4HmgnqE-4LbpyBKJXVmXNRkYq7RWwE-1024.npz
Starting evaluation at step 340000 Counter(340000) 339937
Saved chunk: 20230922T050347F208065-1uq41u5SKkiGZHGCD4heFs-0D35Y4PFEyGVgEDbI172Ii-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 340500 Counter(340500) 340437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 681778 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.64 / train/action_mean 0.45 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.6e-7 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.6e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.6e-7 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.3e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.31 / train/model_loss_mean 1.17 / train/model_loss_std 2.22 / train/model_opt_grad_norm 4.79 / 
train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.4e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 67.2 / train/post_ent_max 67.2 / train/post_ent_mean 40.74 / train/post_ent_min 25.62 / train/post_ent_std 4.31 / train/prior_ent_mag 69.74 / 
train/prior_ent_max 69.74 / train/prior_ent_mean 42.27 / train/prior_ent_min 32.77 / train/prior_ent_std 4.96 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.36 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 5.6e-11 / report/cont_loss_std 6.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.53 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.22 / report/model_loss_mean 1.12 / report/model_loss_std 2.28 / report/post_ent_mag 67.55 / report/post_ent_max 67.55 / report/post_ent_mean 40.75 / report/post_ent_min 28.66 / report/post_ent_std 4.45 / 
report/prior_ent_mag 69.56 / report/prior_ent_max 69.56 / report/prior_ent_mean 42.21 / report/prior_ent_min 33.56 / report/prior_ent_std 5.05 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.53 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / 
eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.76 / eval/dyn_loss_std 3.44 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.39 /
eval/model_loss_mean 1.24 / eval/model_loss_std 2.3 / eval/post_ent_mag 67.29 / eval/post_ent_max 67.29 / eval/post_ent_mean 40.28 / eval/post_ent_min 25.56 / eval/post_ent_std 4.47 / eval/prior_ent_mag 69.56 / eval/prior_ent_max 69.56 / eval/prior_ent_mean 41.89 / 
eval/prior_ent_min 30.45 / eval/prior_ent_std 5.11 / eval/rep_loss_mean 1.76 / eval/rep_loss_std 3.44 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.4e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3836 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.76 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 15.92 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1918 / timer/agent.train_total 246.84 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T050502F084339-4LbpyBKJXVmXNRkYq7RWwE-6XbF6dw6DiRRYIBVnvUEIh-1024.npz
Starting evaluation at step 341000 Counter(341000) 340937
Saved chunk: 20230922T050505F799691-0D35Y4PFEyGVgEDbI172Ii-6nQQIcba0Pcpoa3NIhznf7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 341500 Counter(341500) 341437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 342000 Counter(342000) 341937
Saved chunk: 20230922T050625F216596-6nQQIcba0Pcpoa3NIhznf7-4J26vvMGiY4ihMkV09tOe1-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T050623F037455-6XbF6dw6DiRRYIBVnvUEIh-6W9xhtCeFwtmIsIZVAOA6N-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 342500 Counter(342500) 342437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 343000 Counter(343000) 342937
Saved chunk: 20230922T050745F723131-4J26vvMGiY4ihMkV09tOe1-3ISytOO6WIfI6VUPqr7Fw6-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T050748F539375-6W9xhtCeFwtmIsIZVAOA6N-1HUMtKdDTD5HXdxVW6x5k6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 343500 Counter(343500) 343437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 344000 Counter(344000) 343937
Saved chunk: 20230922T050904F397866-3ISytOO6WIfI6VUPqr7Fw6-1MNNZs8tSnzPSUCn3zSwE7-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T050908F788903-1HUMtKdDTD5HXdxVW6x5k6-1IkFOjtptDck1NZJAG15en-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T051028F973126-1IkFOjtptDck1NZJAG15en-0000000000000000000000-236.npz
Saved chunk: 20230922T051023F031264-1MNNZs8tSnzPSUCn3zSwE7-0000000000000000000000-199.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 344500 Counter(344500) 344437
eval_Episode has 500 steps and return 0.0.
 Step 689306 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.66 / train/action_mean 0.45 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.7e-7 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.2e-7 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.3e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.3 / train/model_loss_mean 1.17 / train/model_loss_std 2.21 / train/model_opt_grad_norm 5.21 / 
train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.4e-4 / train/policy_logprob_mag 9.55 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.55 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.84 / train/post_ent_max 66.84 / train/post_ent_mean 40.79 / train/post_ent_min 25.9 / train/post_ent_std 4.35 / train/prior_ent_mag 69.55 / 
train/prior_ent_max 69.55 / train/prior_ent_mean 42.32 / train/prior_ent_min 32.53 / train/prior_ent_std 4.99 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.34 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 2.38 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.23 / report/model_loss_mean 1.07 / report/model_loss_std 1.55 / report/post_ent_mag 67.17 / report/post_ent_max 67.17 / report/post_ent_mean 40.66 / report/post_ent_min 24.44 / report/post_ent_std 4.97 / 
report/prior_ent_mag 70.11 / report/prior_ent_max 70.11 / report/prior_ent_mean 42.25 / report/prior_ent_min 33.17 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.54 / report/rep_loss_std 2.38 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-12 / 
eval/cont_loss_std 4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.82 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.25 / 
eval/model_loss_mean 1.07 / eval/model_loss_std 1.87 / eval/post_ent_mag 66.73 / eval/post_ent_max 66.73 / eval/post_ent_mean 38.96 / eval/post_ent_min 26.59 / eval/post_ent_std 4.56 / eval/prior_ent_mag 70.11 / eval/prior_ent_max 70.11 / eval/prior_ent_mean 40.79 / 
eval/prior_ent_min 32.89 / eval/prior_ent_std 4.93 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.82 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.4e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / 
timer/env.step_count 3764 / timer/env.step_total 18.59 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.22 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / 
timer/agent.policy_count 7772 / timer/agent.policy_total 16.8 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1882 / timer/agent.train_total 244.11 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 
0.13 / timer/agent.train_max 1.69 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.09

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 345000 Counter(345000) 344937
Saved chunk: 20230922T051023F031264-1MNNZs8tSnzPSUCn3zSwE7-5UKXjKpDzmMqmQYOXzwuss-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051028F973126-1IkFOjtptDck1NZJAG15en-5SLIsGc4VeBuEb13HrCnY4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 345500 Counter(345500) 345437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 346000 Counter(346000) 345937
Saved chunk: 20230922T051142F953539-5UKXjKpDzmMqmQYOXzwuss-1pIOThNkRWoZA579Cm1l0L-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051150F539044-5SLIsGc4VeBuEb13HrCnY4-2KCSrX9PoBvlrBxBuBhiCi-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 346500 Counter(346500) 346437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 347000 Counter(347000) 346937
Saved chunk: 20230922T051301F866318-1pIOThNkRWoZA579Cm1l0L-00KvUKrfU2P4vwKUpotGui-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051310F965907-2KCSrX9PoBvlrBxBuBhiCi-1Vhkz3hEex3ZhCjiihvbKc-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 347500 Counter(347500) 347437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 348000 Counter(348000) 347937
Saved chunk: 20230922T051420F462762-00KvUKrfU2P4vwKUpotGui-1anmNeQz5szrUtQPDUXdFj-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051431F144023-1Vhkz3hEex3ZhCjiihvbKc-6SwtjFQQkgzcL6RP5fDuMr-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 696982 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.64 / train/action_mean 0.45 / train/action_min -3.97 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.7e-7 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.3e-6 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
2.6e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.16 / train/model_loss_std 2.19 / train/model_opt_grad_norm 5.01 / 
train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.4e-4 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.74 / train/post_ent_max 66.74 / train/post_ent_mean 40.75 / train/post_ent_min 25.8 / train/post_ent_std 4.33 / train/prior_ent_mag 69.51 / 
train/prior_ent_max 69.51 / train/prior_ent_mean 42.28 / train/prior_ent_min 32.63 / train/prior_ent_std 4.95 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.33 / train/reward_avg 0 / train/reward_loss_mean 1.3e-10 / train/reward_loss_std 4.2e-9 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.3e-10 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 1e-11 / report/cont_loss_std 5.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.29 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.26 / report/model_loss_mean 1.14 / report/model_loss_std 2.18 / report/post_ent_mag 66.79 / report/post_ent_max 66.79 / report/post_ent_mean 40.31 / report/post_ent_min 26.01 / report/post_ent_std 3.7 / 
report/prior_ent_mag 69.47 / report/prior_ent_max 69.47 / report/prior_ent_mean 41.79 / report/prior_ent_min 33.28 / report/prior_ent_std 4.52 / report/rep_loss_mean 1.69 / report/rep_loss_std 3.29 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / 
eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 2.97 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.21 /
eval/model_loss_mean 1.07 / eval/model_loss_std 1.92 / eval/post_ent_mag 66.57 / eval/post_ent_max 66.57 / eval/post_ent_mean 40.26 / eval/post_ent_min 25.59 / eval/post_ent_std 4.18 / eval/prior_ent_mag 69.47 / eval/prior_ent_max 69.47 / eval/prior_ent_mean 41.83 / 
eval/prior_ent_min 33.82 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 2.97 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.5e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3838 / timer/env.step_total 18.94 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.01 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7345 / timer/agent.policy_total 15.91 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 246.96 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 348500 Counter(348500) 348437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 349000 Counter(349000) 348937
Saved chunk: 20230922T051538F987009-1anmNeQz5szrUtQPDUXdFj-4PxaBNWF1CI9J2Lx1R5nm7-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051551F233940-6SwtjFQQkgzcL6RP5fDuMr-1njYCX30I5dQ66lZsRNWvO-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 349500 Counter(349500) 349437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 350000 Counter(350000) 349937
Saved chunk: 20230922T051658F804606-4PxaBNWF1CI9J2Lx1R5nm7-2csQFAVufQIutmAc6b8Bxk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051712F689669-1njYCX30I5dQ66lZsRNWvO-3ej6naCOOumJvkbNLvisj2-1024.npz
Starting evaluation at step 350500 Counter(350500) 350437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 351000 Counter(351000) 350937
Saved chunk: 20230922T051817F595114-2csQFAVufQIutmAc6b8Bxk-6FjNg0OIT4j9t5wiqiTc5m-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051832F992525-3ej6naCOOumJvkbNLvisj2-4KBbe4xkbgJIB58jWfowBJ-1024.npz
Starting evaluation at step 351500 Counter(351500) 351437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 352000 Counter(352000) 351937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051936F200909-6FjNg0OIT4j9t5wiqiTc5m-6XEB5TFM0z95Er1NgKKZE0-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T051953F158743-4KBbe4xkbgJIB58jWfowBJ-0suqaD8fnjL2PdwJyyxHvK-1024.npz
 Step 704558 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.44 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.6e-7 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.4e-7 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
6.6e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.16 / train/model_loss_std 2.22 / train/model_opt_grad_norm 5.07 / 
train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.3e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.52 / train/post_ent_max 66.52 / train/post_ent_mean 40.89 / train/post_ent_min 26.23 / train/post_ent_std 4.22 / train/prior_ent_mag 69.33 / 
train/prior_ent_max 69.33 / train/prior_ent_mean 42.42 / train/prior_ent_min 32.88 / train/prior_ent_std 4.88 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.37 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.5e-11 / report/cont_loss_std 7.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.57 / 
report/image_loss_mean 0.17 / report/image_loss_std 0.29 / report/model_loss_mean 1.17 / report/model_loss_std 2.33 / report/post_ent_mag 66.18 / report/post_ent_max 66.18 / report/post_ent_mean 40.62 / report/post_ent_min 26.12 / report/post_ent_std 4.38 / 
report/prior_ent_mag 69.06 / report/prior_ent_max 69.06 / report/prior_ent_mean 42.1 / report/prior_ent_min 29.97 / report/prior_ent_std 4.84 / report/rep_loss_mean 1.67 / report/rep_loss_std 3.57 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-11 / 
eval/cont_loss_std 4.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.64 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.22 /
eval/model_loss_mean 1.05 / eval/model_loss_std 1.71 / eval/post_ent_mag 66.37 / eval/post_ent_max 66.37 / eval/post_ent_mean 39.88 / eval/post_ent_min 25.59 / eval/post_ent_std 4.2 / eval/prior_ent_mag 69.06 / eval/prior_ent_max 69.06 / eval/prior_ent_mean 41.41 / 
eval/prior_ent_min 33.19 / eval/prior_ent_std 4.87 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.64 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.5e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / 
timer/env.step_count 3788 / timer/env.step_total 18.71 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.69 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.33 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 352500 Counter(352500) 352437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 353000 Counter(353000) 352937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052054F754176-6XEB5TFM0z95Er1NgKKZE0-3froduJ4aESHUKZWIb37Ck-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052113F302679-0suqaD8fnjL2PdwJyyxHvK-1Z0yab1iVSqPJGlNMdrUQx-1024.npz
Starting evaluation at step 353500 Counter(353500) 353437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 354000 Counter(354000) 353937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052234F686746-1Z0yab1iVSqPJGlNMdrUQx-2XnqDe6RphWQwSx2rYTI2n-1024.npz
Starting evaluation at step 354500 Counter(354500) 354437
Saved chunk: 20230922T052214F555511-3froduJ4aESHUKZWIb37Ck-7zp8Jxl2fVhnlZ6I68q34C-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 355000 Counter(355000) 354937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052354F815133-2XnqDe6RphWQwSx2rYTI2n-2u51JLT09I50MYmXcVdAO6-1024.npz
Starting evaluation at step 355500 Counter(355500) 355437
Saved chunk: 20230922T052408F992734-7zp8Jxl2fVhnlZ6I68q34C-0uvhQ4rsdpyNfxAyQUN0mm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T052527F436686-0uvhQ4rsdpyNfxAyQUN0mm-0000000000000000000000-458.npz
Saved chunk: 20230922T052514F861216-2u51JLT09I50MYmXcVdAO6-0000000000000000000000-472.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 356000 Counter(356000) 355937
eval_Episode has 500 steps and return 0.0.
 Step 712142 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.65 / train/action_mean 0.46 / train/action_min -3.96 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.5e-7 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.3e-7 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.19 / train/model_opt_grad_norm 5.08 / 
train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.4e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.5e-4 / train/post_ent_mag 66.56 / train/post_ent_max 66.56 / train/post_ent_mean 40.86 / train/post_ent_min 26.29 / train/post_ent_std 4.23 / train/prior_ent_mag 69.18 / 
train/prior_ent_max 69.18 / train/prior_ent_mean 42.4 / train/prior_ent_min 32.71 / train/prior_ent_std 4.87 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.32 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.2e-11 / report/cont_loss_std 9.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.2 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.28 / report/model_loss_mean 1.12 / report/model_loss_std 2.13 / report/post_ent_mag 66.44 / report/post_ent_max 66.44 / report/post_ent_mean 41.47 / report/post_ent_min 28.09 / report/post_ent_std 4.28 / 
report/prior_ent_mag 69.58 / report/prior_ent_max 69.58 / report/prior_ent_mean 43.01 / report/prior_ent_min 33.43 / report/prior_ent_std 4.92 / report/rep_loss_mean 1.61 / report/rep_loss_std 3.2 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / 
eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 2.7 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / 
eval/model_loss_mean 1.09 / eval/model_loss_std 1.73 / eval/post_ent_mag 65.94 / eval/post_ent_max 65.94 / eval/post_ent_mean 39.51 / eval/post_ent_min 28.05 / eval/post_ent_std 4.09 / eval/prior_ent_mag 69.58 / eval/prior_ent_max 69.58 / eval/prior_ent_mean 41.27 / 
eval/prior_ent_min 33.45 / eval/prior_ent_std 4.68 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 2.7 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.6e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / 
timer/env.step_count 3792 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 396.61 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.13 / timer/agent.save_frac 4.4e-4 / timer/agent.save_avg 0.13 / timer/agent.save_min 0.13 / timer/agent.save_max 0.13 / 
timer/agent.policy_count 7800 / timer/agent.policy_total 16.88 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.95 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.7e-8 / timer/dataset_eval_avg 2.6e-5 / timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052514F861216-2u51JLT09I50MYmXcVdAO6-3xHErJECMlP99DBmdXWTT0-1024.npz
Starting evaluation at step 356500 Counter(356500) 356437
Saved chunk: 20230922T052527F436686-0uvhQ4rsdpyNfxAyQUN0mm-4ZXinF8obMWEe8o7V53ehN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 357000 Counter(357000) 356937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052636F174707-3xHErJECMlP99DBmdXWTT0-5vGW3WJ8kmbs54QizVDUv0-1024.npz
Starting evaluation at step 357500 Counter(357500) 357437
Saved chunk: 20230922T052647F299151-4ZXinF8obMWEe8o7V53ehN-2INH9WLJmGK4DGV6i2I6w6-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 358000 Counter(358000) 357937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052756F616113-5vGW3WJ8kmbs54QizVDUv0-51kdd2gT921qeyyrv9LUBU-1024.npz
Starting evaluation at step 358500 Counter(358500) 358437
Saved chunk: 20230922T052806F103830-2INH9WLJmGK4DGV6i2I6w6-4YjMFKN6djkzq43l60e4XJ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 359000 Counter(359000) 358937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T052916F848898-51kdd2gT921qeyyrv9LUBU-2LpyLkuZLsXechVwLfzSfH-1024.npz
Starting evaluation at step 359500 Counter(359500) 359437
Saved chunk: 20230922T052924F743762-4YjMFKN6djkzq43l60e4XJ-1knB4m2lr0FEOxbggNrmmi-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 719822 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.63 / train/action_max 4.62 / train/action_mean 0.45 / train/action_min -3.95 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.5e-7 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.2e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.4e-7 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
6.4e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.29 / train/model_loss_mean 1.15 / train/model_loss_std 2.14 / train/model_opt_grad_norm 4.97 / 
train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.4 / train/policy_entropy_std 3.3e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.65 / train/post_ent_max 66.65 / train/post_ent_mean 40.92 / train/post_ent_min 25.93 / train/post_ent_std 4.27 / train/prior_ent_mag 69.25 / 
train/prior_ent_max 69.25 / train/prior_ent_mean 42.44 / train/prior_ent_min 32.87 / train/prior_ent_std 4.89 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.24 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 2.5e-11 / report/cont_loss_std 9.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.45 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.18 / report/model_loss_mean 1.06 / report/model_loss_std 1.57 / report/post_ent_mag 66.32 / report/post_ent_max 66.32 / report/post_ent_mean 41.5 / report/post_ent_min 28.79 / report/post_ent_std 4.4 / 
report/prior_ent_mag 69.06 / report/prior_ent_max 69.06 / report/prior_ent_mean 42.73 / report/prior_ent_min 33.43 / report/prior_ent_std 4.97 / report/rep_loss_mean 1.52 / report/rep_loss_std 2.45 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-12 / 
eval/cont_loss_std 1.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.53 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.3 / 
eval/model_loss_mean 1.03 / eval/model_loss_std 1.68 / eval/post_ent_mag 66.92 / eval/post_ent_max 66.92 / eval/post_ent_mean 39.17 / eval/post_ent_min 26.16 / eval/post_ent_std 4.08 / eval/prior_ent_mag 69.06 / eval/prior_ent_max 69.06 / eval/prior_ent_mean 40.74 / 
eval/prior_ent_min 31.88 / eval/prior_ent_std 4.51 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.53 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.6e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / 
timer/env.step_count 3840 / timer/env.step_total 18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 400.49 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.7e-4 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7347 / timer/agent.policy_total 15.89 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1920 / timer/agent.train_total 247.02 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / 
timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 360000 Counter(360000) 359937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053036F910851-2LpyLkuZLsXechVwLfzSfH-4Yq611azQjEjzG5EYDWGiz-1024.npz
Starting evaluation at step 360500 Counter(360500) 360437
Saved chunk: 20230922T053043F227669-1knB4m2lr0FEOxbggNrmmi-2tvciErN2PuAHAkjYJCv7L-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 361000 Counter(361000) 360937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053158F147108-4Yq611azQjEjzG5EYDWGiz-14ibi9LnR3sHNcviH6gUiv-1024.npz
Starting evaluation at step 361500 Counter(361500) 361437
Saved chunk: 20230922T053202F925940-2tvciErN2PuAHAkjYJCv7L-4giAE4nhwLNZ8iEprvRn5S-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 362000 Counter(362000) 361937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053318F535171-14ibi9LnR3sHNcviH6gUiv-1chpNJfJiqoxiyeW2FHAfG-1024.npz
Starting evaluation at step 362500 Counter(362500) 362437
Saved chunk: 20230922T053321F710445-4giAE4nhwLNZ8iEprvRn5S-0rqC9HsIFFnVhdRpXwXD22-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 363000 Counter(363000) 362937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 363500 Counter(363500) 363437
Saved chunk: 20230922T053440F419434-0rqC9HsIFFnVhdRpXwXD22-7ClS30ZzGipSTXj3Ddnzqs-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053438F821224-1chpNJfJiqoxiyeW2FHAfG-7fIHKeG8OXlg7EG1wCTS7d-1024.npz
 Step 727402 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.45 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.2e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.4e-7 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
5.4e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.29 / train/model_loss_mean 1.15 / train/model_loss_std 2.16 / train/model_opt_grad_norm 5.25 / 
train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.42 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.42 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.85 / train/post_ent_max 66.85 / train/post_ent_mean 40.86 / train/post_ent_min 26.29 / train/post_ent_std 4.18 / train/prior_ent_mag 69.3 / 
train/prior_ent_max 69.3 / train/prior_ent_mean 42.39 / train/prior_ent_min 32.8 / train/prior_ent_std 4.85 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.28 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.7e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.49 / report/dyn_loss_std 2.39 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.19 / report/model_loss_mean 1.03 / report/model_loss_std 1.55 / report/post_ent_mag 67.1 / report/post_ent_max 67.1 / report/post_ent_mean 40.95 / report/post_ent_min 23.02 / report/post_ent_std 4.63 / 
report/prior_ent_mag 69.37 / report/prior_ent_max 69.37 / report/prior_ent_mean 42.37 / report/prior_ent_min 33.33 / report/prior_ent_std 5 / report/rep_loss_mean 1.49 / report/rep_loss_std 2.39 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.64 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.23 / 
eval/model_loss_mean 1.08 / eval/model_loss_std 1.72 / eval/post_ent_mag 67.33 / eval/post_ent_max 67.33 / eval/post_ent_mean 40.14 / eval/post_ent_min 23.35 / eval/post_ent_std 4.75 / eval/prior_ent_mag 69.37 / eval/prior_ent_max 69.37 / eval/prior_ent_mean 41.72 / 
eval/prior_ent_min 33.22 / eval/prior_ent_std 5.08 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.64 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.6e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3790 / timer/env.step_total 18.73 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.99 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 16.8 / timer/agent.policy_frac 0.06 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 364000 Counter(364000) 363937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 364500 Counter(364500) 364437
Saved chunk: 20230922T053558F872779-7ClS30ZzGipSTXj3Ddnzqs-0dosY6c4qaMGKeIVTlWiIL-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053602F226937-7fIHKeG8OXlg7EG1wCTS7d-1GLWZueil55QTeE6Tn8OHM-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 365000 Counter(365000) 364937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 365500 Counter(365500) 365437
Saved chunk: 20230922T053718F671977-0dosY6c4qaMGKeIVTlWiIL-1S6BCaEEAiN0zmz80N8YIZ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053723F626688-1GLWZueil55QTeE6Tn8OHM-5pTL5QCgSYqR4Yh2bmDnr7-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 366000 Counter(366000) 365937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 366500 Counter(366500) 366437
Saved chunk: 20230922T053837F451240-1S6BCaEEAiN0zmz80N8YIZ-4rTWFEPP6ZKRPsbDzjNluX-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T053843F961347-5pTL5QCgSYqR4Yh2bmDnr7-0IApyYa5ZgrOAWNh4VC8Dv-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 367000 Counter(367000) 366937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T054004F108216-0IApyYa5ZgrOAWNh4VC8Dv-0000000000000000000000-708.npz
Saved chunk: 20230922T053956F064144-4rTWFEPP6ZKRPsbDzjNluX-0000000000000000000000-717.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 367500 Counter(367500) 367437
Saved chunk: 20230922T053956F064144-4rTWFEPP6ZKRPsbDzjNluX-1TtiDYXUy366G3Wv2hoTJE-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 735002 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.46 / train/action_min -3.95 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.4e-7 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.3e-7 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
6.3e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.28 / train/model_loss_mean 1.16 / train/model_loss_std 2.16 / train/model_opt_grad_norm 5.29 / 
train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.2e-4 / train/policy_logprob_mag 9.42 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.42 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.35 / train/post_ent_max 66.35 / train/post_ent_mean 41.03 / train/post_ent_min 26.21 / train/post_ent_std 4.19 / train/prior_ent_mag 69.05 / 
train/prior_ent_max 69.05 / train/prior_ent_mean 42.55 / train/prior_ent_min 32.81 / train/prior_ent_std 4.85 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.27 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 3.7e-11 / report/cont_loss_std 3.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.42 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.21 / report/model_loss_mean 1.12 / report/model_loss_std 2.19 / report/post_ent_mag 66.35 / report/post_ent_max 66.35 / report/post_ent_mean 40.63 / report/post_ent_min 22.79 / report/post_ent_std 3.99 / 
report/prior_ent_mag 69.02 / report/prior_ent_max 69.02 / report/prior_ent_mean 42.11 / report/prior_ent_min 31.75 / report/prior_ent_std 4.74 / report/rep_loss_mean 1.64 / report/rep_loss_std 3.42 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / 
eval/cont_loss_std 9.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 3 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / 
eval/model_loss_mean 1.16 / eval/model_loss_std 1.94 / eval/post_ent_mag 66.78 / eval/post_ent_max 66.78 / eval/post_ent_mean 40.49 / eval/post_ent_min 25.55 / eval/post_ent_std 3.51 / eval/prior_ent_mag 69.02 / eval/prior_ent_max 69.02 / eval/prior_ent_mean 42.13 / 
eval/prior_ent_min 33.74 / eval/prior_ent_std 4.85 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 3 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / 
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.7e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.91 / 
timer/env.step_count 3800 / timer/env.step_total 18.79 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 397.37 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.19 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7808 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.53 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T054004F108216-0IApyYa5ZgrOAWNh4VC8Dv-7zliRTbIV4c2mBHIDPkOTW-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 368000 Counter(368000) 367937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 368500 Counter(368500) 368437
Saved chunk: 20230922T054114F686983-1TtiDYXUy366G3Wv2hoTJE-69MRB3jA5p5pk1yIqucOCg-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054125F185107-7zliRTbIV4c2mBHIDPkOTW-28WqwGUIy2wu8VoZ9ISwRk-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 369000 Counter(369000) 368937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 369500 Counter(369500) 369437
Saved chunk: 20230922T054234F539805-69MRB3jA5p5pk1yIqucOCg-0iYMPRlDAcXpFAp98vMIpV-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054245F746557-28WqwGUIy2wu8VoZ9ISwRk-7d5yshLpgP5l0uCqAWVQm4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 370000 Counter(370000) 369937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 370500 Counter(370500) 370437
Saved chunk: 20230922T054353F172193-0iYMPRlDAcXpFAp98vMIpV-0Rz6aA8ZTbQIN0LdQfRuJ0-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054405F968772-7d5yshLpgP5l0uCqAWVQm4-3QVoNMyw32mrxD2WiiXehQ-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 371000 Counter(371000) 370937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 742682 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.46 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 8.3e-7 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.16 / train/model_loss_std 2.16 / train/model_opt_grad_norm 5 / 
train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.24 / train/post_ent_max 66.24 / train/post_ent_mean 41.02 / train/post_ent_min 25.9 / train/post_ent_std 4.17 / train/prior_ent_mag 68.82 / 
train/prior_ent_max 68.82 / train/prior_ent_mean 42.52 / train/prior_ent_min 32.61 / train/prior_ent_std 4.8 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.29 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.7e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / report/dyn_loss_std 2.55 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.21 / report/model_loss_mean 1.09 / report/model_loss_std 1.64 / report/post_ent_mag 66.22 / report/post_ent_max 66.22 / report/post_ent_mean 40.55 / report/post_ent_min 27.66 / report/post_ent_std 4.05 / 
report/prior_ent_mag 68.79 / report/prior_ent_max 68.79 / report/prior_ent_mean 41.96 / report/prior_ent_min 29.89 / report/prior_ent_std 4.73 / report/rep_loss_mean 1.56 / report/rep_loss_std 2.55 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-11 / 
eval/cont_loss_std 7.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.34 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / 
eval/model_loss_mean 1.04 / eval/model_loss_std 1.53 / eval/post_ent_mag 66.22 / eval/post_ent_max 66.22 / eval/post_ent_mean 40.89 / eval/post_ent_min 26.25 / eval/post_ent_std 4.46 / eval/prior_ent_mag 68.79 / eval/prior_ent_max 68.79 / eval/prior_ent_mean 42.34 / 
eval/prior_ent_min 33.03 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.34 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.7e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / 
timer/env.step_count 3840 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 400.83 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7347 / timer/agent.policy_total 15.93 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.6e-3 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1920 / timer/agent.train_total 247.06 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 371500 Counter(371500) 371437
Saved chunk: 20230922T054511F782555-0Rz6aA8ZTbQIN0LdQfRuJ0-6nuTcYKI977jEMt94aZWOD-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054526F112948-3QVoNMyw32mrxD2WiiXehQ-6o6z4gwj5MbR8vw3DtZiPe-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 372000 Counter(372000) 371937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 372500 Counter(372500) 372437
Saved chunk: 20230922T054631F141575-6nuTcYKI977jEMt94aZWOD-3VckzDbRn5iePfHxZSXCXJ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054647F156111-6o6z4gwj5MbR8vw3DtZiPe-1jf1d4YL0SH3QzlTDZTLCd-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 373000 Counter(373000) 372937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 373500 Counter(373500) 373437
Saved chunk: 20230922T054750F020989-3VckzDbRn5iePfHxZSXCXJ-16aXG3QTdaxHcIppCF085Q-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054807F549641-1jf1d4YL0SH3QzlTDZTLCd-5Dw4xp0fk2Y4h2IVdiz69O-1024.npz
Starting evaluation at step 374000 Counter(374000) 373937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 374500 Counter(374500) 374437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054908F695375-16aXG3QTdaxHcIppCF085Q-3HHpFNpBRRGscMpnCfgv24-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T054927F737006-5Dw4xp0fk2Y4h2IVdiz69O-7vuez1sXrDHhwsOyJFiTwS-1024.npz
Starting evaluation at step 375000 Counter(375000) 374937
eval_Episode has 500 steps and return 0.0.
 Step 750270 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.47 / train/action_min -3.91 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.1e-7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.2e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.5e-7 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
8.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.15 / train/model_loss_std 2.14 / train/model_opt_grad_norm 5.24 / 
train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3e-4 / train/policy_logprob_mag 9.43 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.43 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 65.97 / train/post_ent_max 65.97 / train/post_ent_mean 41.05 / train/post_ent_min 26.26 / train/post_ent_std 4.12 / train/prior_ent_mag 68.77 / 
train/prior_ent_max 68.77 / train/prior_ent_mean 42.56 / train/prior_ent_min 32.69 / train/prior_ent_std 4.76 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.26 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 3.1 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.36 / report/model_loss_mean 1.1 / report/model_loss_std 2.12 / report/post_ent_mag 66.47 / report/post_ent_max 66.47 / report/post_ent_mean 41.52 / report/post_ent_min 28.61 / report/post_ent_std 4.02 / 
report/prior_ent_mag 69.07 / report/prior_ent_max 69.07 / report/prior_ent_mean 42.95 / report/prior_ent_min 33.03 / report/prior_ent_std 4.65 / report/rep_loss_mean 1.57 / report/rep_loss_std 3.1 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / 
eval/cont_loss_std 7.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.43 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.18 /
eval/model_loss_mean 1.03 / eval/model_loss_std 1.57 / eval/post_ent_mag 66.67 / eval/post_ent_max 66.67 / eval/post_ent_mean 39.67 / eval/post_ent_min 28.24 / eval/post_ent_std 3.6 / eval/prior_ent_mag 69.07 / eval/prior_ent_max 69.07 / eval/prior_ent_mean 41.35 / 
eval/prior_ent_min 33.21 / eval/prior_ent_std 4.35 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.43 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.8e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / 
timer/env.step_count 3794 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.15 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1897 / timer/agent.train_total 244.05 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 375500 Counter(375500) 375437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055027F156625-3HHpFNpBRRGscMpnCfgv24-5dUhawDM2pSm00OKrsvjr2-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055047F749594-7vuez1sXrDHhwsOyJFiTwS-3zWXXTSUYOVgi2vGxMCkoQ-1024.npz
Starting evaluation at step 376000 Counter(376000) 375937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 376500 Counter(376500) 376437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055209F173455-3zWXXTSUYOVgi2vGxMCkoQ-4oIwmXN1V9WpASngQLLbuf-1024.npz
Starting evaluation at step 377000 Counter(377000) 376937
Saved chunk: 20230922T055146F793702-5dUhawDM2pSm00OKrsvjr2-6ktFuUMQuxthGPWz8CbYNs-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 377500 Counter(377500) 377437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055329F516456-4oIwmXN1V9WpASngQLLbuf-6hhRRxcXrDBD1IsyqUtQay-1024.npz
Starting evaluation at step 378000 Counter(378000) 377937
Saved chunk: 20230922T055341F622136-6ktFuUMQuxthGPWz8CbYNs-2dw0kszIVjEykYEwhUkH19-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 378500 Counter(378500) 378437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T055449F695219-6hhRRxcXrDBD1IsyqUtQay-0000000000000000000000-944.npz
Saved chunk: 20230922T055500F181717-2dw0kszIVjEykYEwhUkH19-0000000000000000000000-976.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T055449F695219-6hhRRxcXrDBD1IsyqUtQay-3UDIkWXVkyR9YVkpteeX1M-1024.npz
 Step 757934 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.68 / train/action_mean 0.46 / train/action_min -3.95 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / train/dyn_loss_std 
3.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 5.2e-7 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 7.1e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.2 / train/model_opt_grad_norm 5.22 / 
train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 65.78 / train/post_ent_max 65.78 / train/post_ent_mean 41.22 / train/post_ent_min 26.41 / train/post_ent_std 4.04 / train/prior_ent_mag 68.7 / 
train/prior_ent_max 68.7 / train/prior_ent_mean 42.72 / train/prior_ent_min 32.67 / train/prior_ent_std 4.69 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.34 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.09 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.24 / report/model_loss_mean 1.14 / report/model_loss_std 2.03 / report/post_ent_mag 66.6 / report/post_ent_max 66.6 / report/post_ent_mean 42.25 / report/post_ent_min 27.4 / report/post_ent_std 3.96 / 
report/prior_ent_mag 68.97 / report/prior_ent_max 68.97 / report/prior_ent_mean 43.72 / report/prior_ent_min 32.98 / report/prior_ent_std 4.72 / report/rep_loss_mean 1.64 / report/rep_loss_std 3.09 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-11 / 
eval/cont_loss_std 5.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.08 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.24 /
eval/model_loss_mean 1.16 / eval/model_loss_std 1.99 / eval/post_ent_mag 66.37 / eval/post_ent_max 66.37 / eval/post_ent_mean 40.35 / eval/post_ent_min 26.21 / eval/post_ent_std 3.91 / eval/prior_ent_mag 68.97 / eval/prior_ent_max 68.97 / eval/prior_ent_mean 42.01 / 
eval/prior_ent_min 32.29 / eval/prior_ent_std 4.73 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.08 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.8e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3832 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.12 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7339 / timer/agent.policy_total 16.23 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.15 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1916 / timer/agent.train_total 246.48 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 
0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 379000 Counter(379000) 378937
Saved chunk: 20230922T055500F181717-2dw0kszIVjEykYEwhUkH19-1Y8wBZUezpcUXGkhStquNa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 379500 Counter(379500) 379437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055610F040753-3UDIkWXVkyR9YVkpteeX1M-4wYpNwAxKPNVXLkXHne8ri-1024.npz
Starting evaluation at step 380000 Counter(380000) 379937
Saved chunk: 20230922T055619F855602-1Y8wBZUezpcUXGkhStquNa-05jbN1uAxvcyHOn0aWQhyX-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 380500 Counter(380500) 380437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055731F605139-4wYpNwAxKPNVXLkXHne8ri-2rf6EtBfrhmOd0YARaVNqU-1024.npz
Starting evaluation at step 381000 Counter(381000) 380937
Saved chunk: 20230922T055738F958455-05jbN1uAxvcyHOn0aWQhyX-0kdAhFHZN60aGgrrwMjWdo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 381500 Counter(381500) 381437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T055851F785018-2rf6EtBfrhmOd0YARaVNqU-27U1SqPylDYNhe2MllEKsf-1024.npz
Starting evaluation at step 382000 Counter(382000) 381937
Saved chunk: 20230922T055857F564666-0kdAhFHZN60aGgrrwMjWdo-2wcfAsbNeQtuzNtYiiVYHz-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 382500 Counter(382500) 382437
eval_Episode has 500 steps and return 0.0.
 Step 765516 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.46 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.3e-7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.2e-7 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
5e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.28 / train/model_loss_mean 1.15 / train/model_loss_std 2.14 / train/model_opt_grad_norm 4.97 / 
train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 65.98 / train/post_ent_max 65.98 / train/post_ent_mean 41.4 / train/post_ent_min 26.5 / train/post_ent_std 4.02 / train/prior_ent_mag 68.69 / 
train/prior_ent_max 68.69 / train/prior_ent_mean 42.91 / train/prior_ent_min 32.37 / train/prior_ent_std 4.66 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.25 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.57 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.32 / report/model_loss_mean 1.13 / report/model_loss_std 2.36 / report/post_ent_mag 66.48 / report/post_ent_max 66.48 / report/post_ent_mean 41.24 / report/post_ent_min 25.51 / report/post_ent_std 4.12 / 
report/prior_ent_mag 68.81 / report/prior_ent_max 68.81 / report/prior_ent_mean 42.7 / report/prior_ent_min 31.75 / report/prior_ent_std 4.56 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.57 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.6e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.52 / eval/dyn_loss_std 2.55 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.18 /
eval/model_loss_mean 1.04 / eval/model_loss_std 1.63 / eval/post_ent_mag 66.27 / eval/post_ent_max 66.27 / eval/post_ent_mean 40.13 / eval/post_ent_min 26.17 / eval/post_ent_std 4.92 / eval/prior_ent_mag 68.81 / eval/prior_ent_max 68.81 / eval/prior_ent_mean 41.85 / 
eval/prior_ent_min 32.43 / eval/prior_ent_std 5.11 / eval/rep_loss_mean 1.52 / eval/rep_loss_std 2.55 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.8e5 / replay/inserts 3791 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / 
timer/env.step_count 3791 / timer/env.step_total 18.71 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 3.7e-3 / timer/env.step_max 7.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.52 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7799 / timer/agent.policy_total 16.9 / timer/agent.policy_frac 0.06 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.79 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.27

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T060011F894698-27U1SqPylDYNhe2MllEKsf-2TERKJQ4NRJCiYCH9x4Q3U-1024.npz
Starting evaluation at step 383000 Counter(383000) 382937
Saved chunk: 20230922T060016F106833-2wcfAsbNeQtuzNtYiiVYHz-15B3PfjKVdZloBnjePqxKx-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 383500 Counter(383500) 383437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 384000 Counter(384000) 383937
Saved chunk: 20230922T060132F907650-2TERKJQ4NRJCiYCH9x4Q3U-0ngN8kRkj7eRwlPbpNsUAD-1024.npz
Saved chunk: 20230922T060135F558698-15B3PfjKVdZloBnjePqxKx-1312gjUrQPPrPF2czggLME-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 384500 Counter(384500) 384437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 385000 Counter(385000) 384937
Saved chunk: 20230922T060254F466293-1312gjUrQPPrPF2czggLME-19Kwoy1AfmyrzQHYiEigux-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T060253F413409-0ngN8kRkj7eRwlPbpNsUAD-0f0AmcaASI0K4Bib4r6lzi-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 385500 Counter(385500) 385437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 386000 Counter(386000) 385937
Saved chunk: 20230922T060413F048079-19Kwoy1AfmyrzQHYiEigux-1xsW0VC2Z0SHg5dDtdeQVN-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T060416F963359-0f0AmcaASI0K4Bib4r6lzi-0BEgMQwb3XcQg1rP2DsC7h-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 386500 Counter(386500) 386437
eval_Episode has 500 steps and return 0.0.
 Step 773102 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.47 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.3e-7 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
6.3e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.28 / train/model_loss_mean 1.15 / train/model_loss_std 2.15 / train/model_opt_grad_norm 5.16 / 
train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.08 / train/post_ent_max 66.08 / train/post_ent_mean 41.32 / train/post_ent_min 26.5 / train/post_ent_std 4.03 / train/prior_ent_mag 68.68 / 
train/prior_ent_max 68.68 / train/prior_ent_mean 42.83 / train/prior_ent_min 32.03 / train/prior_ent_std 4.68 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.26 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.1e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / report/dyn_loss_std 3.67 / 
report/image_loss_mean 0.18 / report/image_loss_std 0.79 / report/model_loss_mean 1.23 / report/model_loss_std 2.57 / report/post_ent_mag 66.59 / report/post_ent_max 66.59 / report/post_ent_mean 41.19 / report/post_ent_min 27.49 / report/post_ent_std 4.3 / 
report/prior_ent_mag 68.76 / report/prior_ent_max 68.76 / report/prior_ent_mean 42.73 / report/prior_ent_min 31.87 / report/prior_ent_std 4.83 / report/rep_loss_mean 1.75 / report/rep_loss_std 3.67 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.3e-12 / 
eval/cont_loss_std 4.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.3e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.59 / eval/dyn_loss_std 2.74 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.39 /
eval/model_loss_mean 1.1 / eval/model_loss_std 1.91 / eval/post_ent_mag 66.52 / eval/post_ent_max 66.52 / eval/post_ent_mean 40.63 / eval/post_ent_min 25.42 / eval/post_ent_std 3.83 / eval/prior_ent_mag 68.76 / eval/prior_ent_max 68.76 / eval/prior_ent_mean 42.29 / 
eval/prior_ent_min 32.49 / eval/prior_ent_std 4.61 / eval/rep_loss_mean 1.59 / eval/rep_loss_std 2.74 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.9e5 / replay/inserts 3793 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / 
timer/env.step_count 3793 / timer/env.step_total 18.7 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.03 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7801 / timer/agent.policy_total 16.78 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1897 / timer/agent.train_total 244.07 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 387000 Counter(387000) 386937
Saved chunk: 20230922T060531F562462-1xsW0VC2Z0SHg5dDtdeQVN-3lx5boC698aYOdO082Pnik-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T060537F036095-0BEgMQwb3XcQg1rP2DsC7h-2I0sC0KcRNx6bZ26D9JGmv-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 387500 Counter(387500) 387437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 388000 Counter(388000) 387937
Saved chunk: 20230922T060651F180708-3lx5boC698aYOdO082Pnik-4gVGDI9P4p0G4AVD94mkJp-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T060658F264985-2I0sC0KcRNx6bZ26D9JGmv-0hJHszQe9rUBbAIEPX1NQ8-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 388500 Counter(388500) 388437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 389000 Counter(389000) 388937
Saved chunk: 20230922T060809F966969-4gVGDI9P4p0G4AVD94mkJp-2QEkpXxeO6pSmbbzpGCYtz-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T060818F624276-0hJHszQe9rUBbAIEPX1NQ8-0RSuh4SODpVpum1qkNljDC-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 389500 Counter(389500) 389437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 390000 Counter(390000) 389937
Saved chunk: 20230922T060928F729676-2QEkpXxeO6pSmbbzpGCYtz-7FeLXSM0fgAOGh5VL9qyWa-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T060938F926401-0RSuh4SODpVpum1qkNljDC-1gMCHENzCHPgKN88pqclpA-1024.npz
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T061047F259170-7FeLXSM0fgAOGh5VL9qyWa-0000000000000000000000-211.npz
Saved chunk: 20230922T061059F027945-1gMCHENzCHPgKN88pqclpA-0000000000000000000000-156.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
 Step 780770 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.47 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.5e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 7.2e-7 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
8.9e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.18 / train/model_opt_grad_norm 5.17 / 
train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.55 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.55 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.06 / train/post_ent_max 66.06 / train/post_ent_mean 41.4 / train/post_ent_min 26.22 / train/post_ent_std 4.03 / train/prior_ent_mag 68.58 / 
train/prior_ent_max 68.58 / train/prior_ent_mean 42.92 / train/prior_ent_min 31.99 / train/prior_ent_std 4.68 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.31 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 3.4e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.52 / 
report/image_loss_mean 0.17 / report/image_loss_std 0.25 / report/model_loss_mean 1.17 / report/model_loss_std 2.26 / report/post_ent_mag 64.88 / report/post_ent_max 64.88 / report/post_ent_mean 41.9 / report/post_ent_min 27.97 / report/post_ent_std 3.91 / 
report/prior_ent_mag 68.5 / report/prior_ent_max 68.5 / report/prior_ent_mean 43.5 / report/prior_ent_min 32.16 / report/prior_ent_std 4.6 / report/rep_loss_mean 1.67 / report/rep_loss_std 3.52 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 /
report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2e-11 / 
eval/cont_loss_std 8.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.5 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.19 / 
eval/model_loss_mean 1.05 / eval/model_loss_std 1.61 / eval/post_ent_mag 64.88 / eval/post_ent_max 64.88 / eval/post_ent_mean 40.91 / eval/post_ent_min 25.55 / eval/post_ent_std 4.03 / eval/prior_ent_mag 68.5 / eval/prior_ent_max 68.5 / eval/prior_ent_mean 42.45 / 
eval/prior_ent_min 32.25 / eval/prior_ent_std 4.69 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.5 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.9e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / 
timer/env.step_count 3834 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 401.52 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 9e-4 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7341 / timer/agent.policy_total 16.08 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1917 / timer/agent.train_total 246.79 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 390500 Counter(390500) 390437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 391000 Counter(391000) 390937
Saved chunk: 20230922T061047F259170-7FeLXSM0fgAOGh5VL9qyWa-6lVCw3KnWlOU5SLGDnZzDp-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T061059F027945-1gMCHENzCHPgKN88pqclpA-4acarrl8FuEqPlYNWHr57W-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 391500 Counter(391500) 391437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 392000 Counter(392000) 391937
Saved chunk: 20230922T061207F246060-6lVCw3KnWlOU5SLGDnZzDp-4hNrCWStRhnJmPCZaZ6S1G-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T061220F646113-4acarrl8FuEqPlYNWHr57W-2njx8DK3UfIRse6nqftq3Z-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 392500 Counter(392500) 392437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 393000 Counter(393000) 392937
Saved chunk: 20230922T061325F985247-4hNrCWStRhnJmPCZaZ6S1G-0D1sxrg7TMTfsZsLyyDWT6-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T061340F897347-2njx8DK3UfIRse6nqftq3Z-6A7obANDAR1E2M8MPNwSop-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 393500 Counter(393500) 393437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 394000 Counter(394000) 393937
Saved chunk: 20230922T061444F593922-0D1sxrg7TMTfsZsLyyDWT6-0AFNJEwVoLB4EgbwvuUFTN-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 788354 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.48 / train/action_min -3.91 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / train/dyn_loss_std 
3.31 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.4e-7 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 6.4e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.15 / train/model_loss_std 2.18 / train/model_opt_grad_norm 5.23 / 
train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.41 / train/policy_entropy_std 3.2e-4 / train/policy_logprob_mag 9.52 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.52 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.4e-4 / train/post_ent_mag 66.06 / train/post_ent_max 66.06 / train/post_ent_mean 41.35 / train/post_ent_min 26.64 / train/post_ent_std 4.02 / train/prior_ent_mag 68.55 / 
train/prior_ent_max 68.55 / train/prior_ent_mean 42.86 / train/prior_ent_min 31.65 / train/prior_ent_std 4.66 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.31 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 3.1e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.43 / 
report/image_loss_mean 0.17 / report/image_loss_std 0.21 / report/model_loss_mean 1.14 / report/model_loss_std 2.18 / report/post_ent_mag 66.51 / report/post_ent_max 66.51 / report/post_ent_mean 42.36 / report/post_ent_min 28.76 / report/post_ent_std 4.11 / 
report/prior_ent_mag 68.46 / report/prior_ent_max 68.46 / report/prior_ent_mean 43.79 / report/prior_ent_min 31.88 / report/prior_ent_std 4.74 / report/rep_loss_mean 1.63 / report/rep_loss_std 3.43 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-11 / 
eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.94 / eval/dyn_loss_std 5.18 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.48 /
eval/model_loss_mean 1.34 / eval/model_loss_std 3.51 / eval/post_ent_mag 66.21 / eval/post_ent_max 66.21 / eval/post_ent_mean 40.26 / eval/post_ent_min 23.06 / eval/post_ent_std 4.27 / eval/prior_ent_mag 68.46 / eval/prior_ent_max 68.46 / eval/prior_ent_mean 42.05 / 
eval/prior_ent_min 31.71 / eval/prior_ent_std 4.91 / eval/rep_loss_mean 1.94 / eval/rep_loss_std 5.18 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 3.9e5 / replay/inserts 3792 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3792 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 391.99 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7800 / timer/agent.policy_total 16.84 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1896 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1896 / timer/agent.train_total 243.93 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.28

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T061501F052974-6A7obANDAR1E2M8MPNwSop-5dSd1j9KtSn5SsBSw3E3ed-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 394500 Counter(394500) 394437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 395000 Counter(395000) 394937
Saved chunk: 20230922T061603F025198-0AFNJEwVoLB4EgbwvuUFTN-2EM4v7rL3sqE37kA6AmWCT-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T061621F945372-5dSd1j9KtSn5SsBSw3E3ed-1xqmOckSlKUf0OLYIckqmR-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 395500 Counter(395500) 395437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 396000 Counter(396000) 395937
Saved chunk: 20230922T061722F802641-2EM4v7rL3sqE37kA6AmWCT-6NJWXbPAWHhRAKkX2jgQ06-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T061742F471160-1xqmOckSlKUf0OLYIckqmR-1dUsbQi1h2tZP6bJRXUgvR-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 396500 Counter(396500) 396437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 397000 Counter(397000) 396937
Saved chunk: 20230922T061841F505262-6NJWXbPAWHhRAKkX2jgQ06-1B1Yq6uO9ZDeKnUupyqnRN-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T061902F742605-1dUsbQi1h2tZP6bJRXUgvR-51KggdWakU3VVj69UrAoPr-1024.npz
Starting evaluation at step 397500 Counter(397500) 397437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 398000 Counter(398000) 397937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062000F154473-1B1Yq6uO9ZDeKnUupyqnRN-2dkvgrUtnMVASaxIpNIsZd-1024.npz
 Step 796002 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.66 / train/action_mean 0.49 / train/action_min -3.91 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3e-7 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 /
train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / train/dyn_loss_std 
3.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9e-7 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e-4 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.15 / train/model_loss_std 2.15 / train/model_opt_grad_norm 5.05 / 
train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.41 / train/policy_entropy_std 3e-4 / train/policy_logprob_mag 9.55 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.55 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 65.99 / train/post_ent_max 65.99 / train/post_ent_mean 41.36 / train/post_ent_min 26.5 / train/post_ent_std 4.05 / train/prior_ent_mag 68.61 / 
train/prior_ent_max 68.61 / train/prior_ent_mean 42.89 / train/prior_ent_min 31.9 / train/prior_ent_std 4.68 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.27 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 4e-11 / report/cont_loss_std 5.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.22 / 
report/image_loss_mean 0.17 / report/image_loss_std 0.27 / report/model_loss_mean 1.19 / report/model_loss_std 2.12 / report/post_ent_mag 66.11 / report/post_ent_max 66.11 / report/post_ent_mean 41.67 / report/post_ent_min 29.22 / report/post_ent_std 3.92 / 
report/prior_ent_mag 68.63 / report/prior_ent_max 68.63 / report/prior_ent_mean 43.2 / report/prior_ent_min 32.21 / report/prior_ent_std 4.61 / report/rep_loss_mean 1.69 / report/rep_loss_std 3.22 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.2e-12 / 
eval/cont_loss_std 7.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.72 / eval/dyn_loss_std 3.87 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.35 /
eval/model_loss_mean 1.17 / eval/model_loss_std 2.61 / eval/post_ent_mag 66.11 / eval/post_ent_max 66.11 / eval/post_ent_mean 40.55 / eval/post_ent_min 22.99 / eval/post_ent_std 3.26 / eval/prior_ent_mag 68.63 / eval/prior_ent_max 68.63 / eval/prior_ent_mean 42.32 / 
eval/prior_ent_min 31.83 / eval/prior_ent_std 4.27 / eval/rep_loss_mean 1.72 / eval/rep_loss_std 3.87 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4e5 / replay/inserts 3824 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.35 / 
timer/env.step_count 3824 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.86 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7832 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.7e-3 / timer/dataset_train_count 1912 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1912 / timer/agent.train_total 245.89 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062022F888515-51KggdWakU3VVj69UrAoPr-0p5PKNIjOv2F1z64F7Khsv-1024.npz
Starting evaluation at step 398500 Counter(398500) 398437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 399000 Counter(399000) 398937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062118F566947-2dkvgrUtnMVASaxIpNIsZd-5EYoyKYgpzwBMY3czLHnUa-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062144F016175-0p5PKNIjOv2F1z64F7Khsv-1oN4npezhWbGSh1AKWIPOY-1024.npz
Starting evaluation at step 399500 Counter(399500) 399437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 400000 Counter(400000) 399937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062304F398448-1oN4npezhWbGSh1AKWIPOY-2wse6txIBlmhGJkKH51Wmk-1024.npz
Starting evaluation at step 400500 Counter(400500) 400437
Saved chunk: 20230922T062238F479908-5EYoyKYgpzwBMY3czLHnUa-2ZvwRb3tpRNWk2ovhbjs1p-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 401000 Counter(401000) 400937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062424F559461-2wse6txIBlmhGJkKH51Wmk-2pXqgUYry7oIDKV01ptfFq-1024.npz
Starting evaluation at step 401500 Counter(401500) 401437
Saved chunk: 20230922T062432F955966-2ZvwRb3tpRNWk2ovhbjs1p-718hJi7TGGsE9sd2vQcmgw-1024.npz
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062544F655662-2pXqgUYry7oIDKV01ptfFq-0000000000000000000000-392.npz
Saved chunk: 20230922T062551F455845-718hJi7TGGsE9sd2vQcmgw-0000000000000000000000-470.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
 Step 803674 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.48 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.1e-7 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.3e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / train/dyn_loss_std 
3.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.4e-7 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 5.9e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.15 / train/model_loss_std 2.15 / train/model_opt_grad_norm 5.1 / 
train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.37 / train/post_ent_max 66.37 / train/post_ent_mean 41.36 / train/post_ent_min 26.46 / train/post_ent_std 4.04 / train/prior_ent_mag 68.7 / 
train/prior_ent_max 68.7 / train/prior_ent_mean 42.87 / train/prior_ent_min 31.87 / train/prior_ent_std 4.7 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.26 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data 0
/ train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.71 / report/dyn_loss_std 3.46 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.29 / report/model_loss_mean 1.19 / report/model_loss_std 2.26 / report/post_ent_mag 67.24 / report/post_ent_max 67.24 / report/post_ent_mean 41.45 / report/post_ent_min 27.78 / report/post_ent_std 4.1 / 
report/prior_ent_mag 68.98 / report/prior_ent_max 68.98 / report/prior_ent_mean 42.95 / report/prior_ent_min 31.6 / report/prior_ent_std 4.82 / report/rep_loss_mean 1.71 / report/rep_loss_std 3.46 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.5e-12 / 
eval/cont_loss_std 4.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.43 / eval/dyn_loss_std 1.97 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.15 /
eval/model_loss_mean 1 / eval/model_loss_std 1.24 / eval/post_ent_mag 67.24 / eval/post_ent_max 67.24 / eval/post_ent_mean 40.55 / eval/post_ent_min 25.15 / eval/post_ent_std 5.29 / eval/prior_ent_mag 68.98 / eval/prior_ent_max 68.98 / eval/prior_ent_mean 41.9 / 
eval/prior_ent_min 31.78 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 1.43 / eval/rep_loss_std 1.97 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3836 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.44 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7343 / timer/agent.policy_total 16.04 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1918 / timer/agent.train_total 246.8 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 402000 Counter(402000) 401937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062544F655662-2pXqgUYry7oIDKV01ptfFq-3YOGW50A3Y1nOZfBcJzn0b-1024.npz
Starting evaluation at step 402500 Counter(402500) 402437
Saved chunk: 20230922T062551F455845-718hJi7TGGsE9sd2vQcmgw-1au1WxC1YkV5iuCaGFsuub-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 403000 Counter(403000) 402937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062706F259154-3YOGW50A3Y1nOZfBcJzn0b-1TpOxt4wxLIBqZEIrNx75Y-1024.npz
Starting evaluation at step 403500 Counter(403500) 403437
Saved chunk: 20230922T062711F510302-1au1WxC1YkV5iuCaGFsuub-7otUmJqEHKHcQanvDfwYya-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 404000 Counter(404000) 403937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062826F581804-1TpOxt4wxLIBqZEIrNx75Y-7mjjafrXMIHSZj4VJ4yiVr-1024.npz
Starting evaluation at step 404500 Counter(404500) 404437
Saved chunk: 20230922T062830F245247-7otUmJqEHKHcQanvDfwYya-1x5Sbr6otDS6sKJW5QbFsL-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 405000 Counter(405000) 404937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 405500 Counter(405500) 405437
Saved chunk: 20230922T062948F743356-1x5Sbr6otDS6sKJW5QbFsL-5YzGLLY7PQLFAZaCqVZHz9-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T062946F666536-7mjjafrXMIHSZj4VJ4yiVr-4AVzEorGNQtTJG8MinmF0f-1024.npz
 Step 811262 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.64 / train/action_mean 0.48 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.1e-7 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / train/dyn_loss_std 
3.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.7e-7 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 5.1e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.16 / train/model_loss_std 2.2 / train/model_opt_grad_norm 5.02 / 
train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.41 / train/policy_entropy_std 3e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.39 / train/post_ent_max 66.39 / train/post_ent_mean 41.36 / train/post_ent_min 26.4 / train/post_ent_std 3.98 / train/prior_ent_mag 68.78 / 
train/prior_ent_max 68.78 / train/prior_ent_mean 42.89 / train/prior_ent_min 31.86 / train/prior_ent_std 4.67 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.34 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.3e-11 / report/cont_loss_std 5.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.3 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.25 / report/model_loss_mean 1.12 / report/model_loss_std 2.15 / report/post_ent_mag 66.39 / report/post_ent_max 66.39 / report/post_ent_mean 41.16 / report/post_ent_min 28.02 / report/post_ent_std 3.83 / 
report/prior_ent_mag 68.84 / report/prior_ent_max 68.84 / report/prior_ent_mean 42.81 / report/prior_ent_min 32 / report/prior_ent_std 4.61 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.3 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 /
report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-11 / 
eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.69 / eval/dyn_loss_std 3.4 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.43 / 
eval/model_loss_mean 1.17 / eval/model_loss_std 2.38 / eval/post_ent_mag 66.03 / eval/post_ent_max 66.03 / eval/post_ent_mean 40.46 / eval/post_ent_min 27.83 / eval/post_ent_std 3.61 / eval/prior_ent_mag 68.84 / eval/prior_ent_max 68.84 / eval/prior_ent_mean 42.26 / 
eval/prior_ent_min 31.77 / eval/prior_ent_std 4.55 / eval/rep_loss_mean 1.69 / eval/rep_loss_std 3.4 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.1e5 / replay/inserts 3794 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3794 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.14 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.8e-4 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7802 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.4e-3 / timer/dataset_train_count 1897 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1897 / timer/agent.train_total 243.99 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.29

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 406000 Counter(406000) 405937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 406500 Counter(406500) 406437
Saved chunk: 20230922T063107F061455-5YzGLLY7PQLFAZaCqVZHz9-3ztOnFbBANrbCWhM3NpPDe-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063109F996935-4AVzEorGNQtTJG8MinmF0f-2VmdoOI0Zm7jkqL7b9n0GH-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 407000 Counter(407000) 406937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 407500 Counter(407500) 407437
Saved chunk: 20230922T063226F945383-3ztOnFbBANrbCWhM3NpPDe-41Scp1HQ3oIn2NTlqLqoK2-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063231F414170-2VmdoOI0Zm7jkqL7b9n0GH-44P3HPJAjjtvU2aqGUYxrq-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 408000 Counter(408000) 407937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 408500 Counter(408500) 408437
Saved chunk: 20230922T063345F676748-41Scp1HQ3oIn2NTlqLqoK2-2pT3EsciMYrYzzTmmkpzyN-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063351F702044-44P3HPJAjjtvU2aqGUYxrq-6iZSua00YLxt1gWDu5GXBL-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 409000 Counter(409000) 408937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 818942 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.47 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.9e-7 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / train/dyn_loss_std 
3.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.1e-7 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 4.8e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.14 / train/model_loss_std 2.11 / train/model_opt_grad_norm 5.09 / 
train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min 
1.41 / train/policy_entropy_std 2.9e-4 / train/policy_logprob_mag 9.27 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.27 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.58 / train/post_ent_max 66.58 / train/post_ent_mean 41.47 / train/post_ent_min 26.6 / train/post_ent_std 4.04 / train/prior_ent_mag 68.92 / 
train/prior_ent_max 68.92 / train/prior_ent_mean 42.97 / train/prior_ent_min 31.82 / train/prior_ent_std 4.68 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.21 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.7e-11 / report/cont_loss_std 7.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.51 / report/dyn_loss_std 2.32 / 
report/image_loss_mean 0.1 / report/image_loss_std 0.13 / report/model_loss_mean 1.01 / report/model_loss_std 1.46 / report/post_ent_mag 66.1 / report/post_ent_max 66.1 / report/post_ent_mean 40.84 / report/post_ent_min 24.7 / report/post_ent_std 4.32 / 
report/prior_ent_mag 68.91 / report/prior_ent_max 68.91 / report/prior_ent_mean 42.58 / report/prior_ent_min 31.7 / report/prior_ent_std 4.77 / report/rep_loss_mean 1.51 / report/rep_loss_std 2.32 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.95 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.29 /
eval/model_loss_mean 1.06 / eval/model_loss_std 1.97 / eval/post_ent_mag 66.1 / eval/post_ent_max 66.1 / eval/post_ent_mean 40.79 / eval/post_ent_min 26.91 / eval/post_ent_std 3.73 / eval/prior_ent_mag 68.91 / eval/prior_ent_max 68.91 / eval/prior_ent_mean 42.45 / 
eval/prior_ent_min 32.1 / eval/prior_ent_std 4.57 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.95 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.1e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3840 / timer/env.step_total 18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 399.36 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7347 / timer/agent.policy_total 15.96 / timer/agent.policy_frac 0.05 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1920 / timer/agent.train_total 246.91 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 409500 Counter(409500) 409437
Saved chunk: 20230922T063504F192747-2pT3EsciMYrYzzTmmkpzyN-6V1KX2B3U23ygW1YjeYL4V-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063511F784616-6iZSua00YLxt1gWDu5GXBL-4zNNpAfkNJK0LSISSEZDli-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 410000 Counter(410000) 409937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 410500 Counter(410500) 410437
Saved chunk: 20230922T063623F549251-6V1KX2B3U23ygW1YjeYL4V-76jV2H3I6tjw3ma6EbF7oD-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063632F801816-4zNNpAfkNJK0LSISSEZDli-6ZBltAl0Ty4CaCkqipeHhM-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 411000 Counter(411000) 410937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 411500 Counter(411500) 411437
Saved chunk: 20230922T063742F559363-76jV2H3I6tjw3ma6EbF7oD-5H9TaR3TmJtrGs8FIGnrrY-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063753F314247-6ZBltAl0Ty4CaCkqipeHhM-31uubAaVJcVnmCNo8sn4cE-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 412000 Counter(412000) 411937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 412500 Counter(412500) 412437
Saved chunk: 20230922T063901F157985-5H9TaR3TmJtrGs8FIGnrrY-4MAr4W55aBhgx3uJP5TyN6-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T063913F492241-31uubAaVJcVnmCNo8sn4cE-0p4cg214XTTAgyQgvlyjaD-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 413000 Counter(413000) 412937
eval_Episode has 500 steps and return 0.0.
 Step 826522 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.59 / train/action_max 4.58 / train/action_mean 0.48 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.1e-7 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.2e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.3e-7 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
6.1e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.15 / train/model_loss_std 2.16 / train/model_opt_grad_norm 4.65 / 
train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3.1e-4 / train/policy_logprob_mag 9.36 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.36 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.53 / train/post_ent_max 66.53 / train/post_ent_mean 41.64 / train/post_ent_min 26.46 / train/post_ent_std 4.04 / train/prior_ent_mag 68.83 / 
train/prior_ent_max 68.83 / train/prior_ent_mean 43.15 / train/prior_ent_min 31.9 / train/prior_ent_std 4.67 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.28 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 8.2e-12 / report/cont_loss_std 4.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.2e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.2 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.2 / report/model_loss_mean 1.12 / report/model_loss_std 2.06 / report/post_ent_mag 65.88 / report/post_ent_max 65.88 / report/post_ent_mean 41.81 / report/post_ent_min 24.6 / report/post_ent_std 3.65 / 
report/prior_ent_mag 68.83 / report/prior_ent_max 68.83 / report/prior_ent_mean 43.26 / report/prior_ent_min 31.7 / report/prior_ent_std 4.45 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.2 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-11 / 
eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.46 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.37 /
eval/model_loss_mean 1.01 / eval/model_loss_std 1.75 / eval/post_ent_mag 65.88 / eval/post_ent_max 65.88 / eval/post_ent_mean 39.95 / eval/post_ent_min 25.39 / eval/post_ent_std 4.6 / eval/prior_ent_mag 68.83 / eval/prior_ent_max 68.83 / eval/prior_ent_mean 41.53 / 
eval/prior_ent_min 31.76 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.46 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.1e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / 
timer/env.step_count 3790 / timer/env.step_total 18.74 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.32 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 16.83 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.9 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T064033F648303-0p4cg214XTTAgyQgvlyjaD-0000000000000000000000-629.npz
Saved chunk: 20230922T064019F768014-4MAr4W55aBhgx3uJP5TyN6-0000000000000000000000-729.npz
train_Episode has 500 steps and return 0.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 413500 Counter(413500) 413437
Saved chunk: 20230922T064019F768014-4MAr4W55aBhgx3uJP5TyN6-1nvBnUcKh2UccKwKwPC3Za-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064033F648303-0p4cg214XTTAgyQgvlyjaD-6s7WtecXPZHHOC5TsK8ctk-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 414000 Counter(414000) 413937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 414500 Counter(414500) 414437
Saved chunk: 20230922T064139F570975-1nvBnUcKh2UccKwKwPC3Za-3oyOvVJTNtPl3259V5b8SY-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064155F136041-6s7WtecXPZHHOC5TsK8ctk-3ZpCGCwPvBLkLBZOfKDYj5-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 415000 Counter(415000) 414937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 415500 Counter(415500) 415437
Saved chunk: 20230922T064300F220409-3oyOvVJTNtPl3259V5b8SY-2Nkr3aA1qHtYYv4wsP2sdL-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064317F232904-3ZpCGCwPvBLkLBZOfKDYj5-176zUQ7NPeNTOwKBBHt0lY-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 416000 Counter(416000) 415937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 416500 Counter(416500) 416437
Saved chunk: 20230922T064418F783483-2Nkr3aA1qHtYYv4wsP2sdL-1BBAnnBGsXrLUhN2jTuqpQ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064437F409939-176zUQ7NPeNTOwKBBHt0lY-2XVOxSjuhzPt1sWsxtTN6L-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 417000 Counter(417000) 416937
eval_Episode has 500 steps and return 0.0.
 Step 834050 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.63 / train/action_mean 0.48 / train/action_min -3.92 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3e-7 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / train/dyn_loss_std 
3.27 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.7e-7 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 5.3e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.14 / train/model_loss_std 2.15 / train/model_opt_grad_norm 5.18 / 
train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.9e-4 / train/policy_logprob_mag 9.46 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.46 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.44 / train/post_ent_max 66.44 / train/post_ent_mean 41.55 / train/post_ent_min 26.44 / train/post_ent_std 4.04 / train/prior_ent_mag 68.73 / 
train/prior_ent_max 68.73 / train/prior_ent_mean 43.06 / train/prior_ent_min 31.71 / train/prior_ent_std 4.67 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.27 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.1e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.45 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.21 / report/model_loss_mean 1.12 / report/model_loss_std 2.19 / report/post_ent_mag 66.49 / report/post_ent_max 66.49 / report/post_ent_mean 40.54 / report/post_ent_min 25.79 / report/post_ent_std 3.74 / 
report/prior_ent_mag 69.04 / report/prior_ent_max 69.04 / report/prior_ent_mean 42.07 / report/prior_ent_min 31.64 / report/prior_ent_std 4.35 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.45 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-11 / 
eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.7 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.18 / 
eval/model_loss_mean 1.06 / eval/model_loss_std 1.73 / eval/post_ent_mag 66.49 / eval/post_ent_max 66.49 / eval/post_ent_mean 40.11 / eval/post_ent_min 26.11 / eval/post_ent_std 4.11 / eval/prior_ent_mag 69.04 / eval/prior_ent_max 69.04 / eval/prior_ent_mean 41.8 / 
eval/prior_ent_min 31.84 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.7 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.2e5 / replay/inserts 3764 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 
1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3764 / 
timer/env.step_total 18.73 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3e4 / timer/replay._sample_total 389.4 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 4.1e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7772 / 
timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1882 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / 
timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1882 / timer/agent.train_total 243.95 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 
1.88 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / 
timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 417500 Counter(417500) 417437
Saved chunk: 20230922T064537F267093-1BBAnnBGsXrLUhN2jTuqpQ-35DAHE0tqhk69UZlRkQnzo-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064557F426260-2XVOxSjuhzPt1sWsxtTN6L-1bXu1euFMDFuc5GeSkH84a-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 418000 Counter(418000) 417937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 418500 Counter(418500) 418437
Saved chunk: 20230922T064657F041376-35DAHE0tqhk69UZlRkQnzo-6pqcUoXUWAuAWLcP622WL1-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064718F843459-1bXu1euFMDFuc5GeSkH84a-1otsRjQXoADDKddVQNhB4S-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 419000 Counter(419000) 418937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 419500 Counter(419500) 419437
Saved chunk: 20230922T064815F835433-6pqcUoXUWAuAWLcP622WL1-6LRsbRmv7ooZBIxjaV04ML-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T064839F176392-1otsRjQXoADDKddVQNhB4S-4VfbaFeilsLsq8PaxTwCfH-1024.npz
Starting evaluation at step 420000 Counter(420000) 419937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 420500 Counter(420500) 420437
Saved chunk: 20230922T064934F455314-6LRsbRmv7ooZBIxjaV04ML-089gZnbqKpRWXjf06UBygl-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 841726 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.68 / train/action_mean 0.48 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.2e-7 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.4e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.9e-7 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
5.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.16 / train/image_loss_std 0.29 / train/model_loss_mean 1.17 / train/model_loss_std 2.2 / train/model_opt_grad_norm 5.05 / 
train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 3e-4 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.48 / train/post_ent_max 66.48 / train/post_ent_mean 41.57 / train/post_ent_min 26.16 / train/post_ent_std 4.11 / train/prior_ent_mag 68.8 / 
train/prior_ent_max 68.8 / train/prior_ent_mean 43.1 / train/prior_ent_min 31.43 / train/prior_ent_std 4.73 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.34 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.2e-11 / report/cont_loss_std 8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / report/dyn_loss_std 2.89 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.35 / report/model_loss_mean 1.1 / report/model_loss_std 1.99 / report/post_ent_mag 66.91 / report/post_ent_max 66.91 / report/post_ent_mean 41.16 / report/post_ent_min 26.06 / report/post_ent_std 3.94 / 
report/prior_ent_mag 68.62 / report/prior_ent_max 68.62 / report/prior_ent_mean 42.53 / report/prior_ent_min 31.31 / report/prior_ent_std 4.53 / report/rep_loss_mean 1.6 / report/rep_loss_std 2.89 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-11 / 
eval/cont_loss_std 4.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.75 / eval/dyn_loss_std 3.72 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.28 /
eval/model_loss_mean 1.23 / eval/model_loss_std 2.43 / eval/post_ent_mag 66.54 / eval/post_ent_max 66.54 / eval/post_ent_mean 41.18 / eval/post_ent_min 28.39 / eval/post_ent_std 4.31 / eval/prior_ent_mag 68.62 / eval/prior_ent_max 68.62 / eval/prior_ent_mean 42.69 / 
eval/prior_ent_min 31.4 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 1.75 / eval/rep_loss_std 3.72 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.2e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.3e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / 
timer/env.step_count 3838 / timer/env.step_total 19.11 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.11 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7345 / timer/agent.policy_total 15.96 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.8e-3 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.17 / timer/dataset_train_frac 5.6e-4 / timer/dataset_train_avg 8.7e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 0.01 / timer/agent.train_count 1919 / timer/agent.train_total 246.82 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 5e-5 / timer/dataset_eval_frac 1.7e-7 / timer/dataset_eval_avg 5e-5 / timer/dataset_eval_min 
5e-5 / timer/dataset_eval_max 5e-5 / fps 25.58

Saved chunk: 20230922T064959F323533-4VfbaFeilsLsq8PaxTwCfH-4ZqNG0KRH6jnGeIWKHceqD-1024.npz
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 421000 Counter(421000) 420937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 421500 Counter(421500) 421437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065052F985897-089gZnbqKpRWXjf06UBygl-4gO4rAyVLzrCnM2gBTtijJ-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065119F638095-4ZqNG0KRH6jnGeIWKHceqD-561c0rvOCanR2n85aje4CX-1024.npz
Starting evaluation at step 422000 Counter(422000) 421937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 422500 Counter(422500) 422437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065212F740132-4gO4rAyVLzrCnM2gBTtijJ-1K5qrRSgasRAdi6tpf3zmf-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065240F867681-561c0rvOCanR2n85aje4CX-1hr2xKLXHkMW40YJeLx4FM-1024.npz
Starting evaluation at step 423000 Counter(423000) 422937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 423500 Counter(423500) 423437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065401F169219-1hr2xKLXHkMW40YJeLx4FM-5K5b9lJ14wjRmK50amulKg-1024.npz
Starting evaluation at step 424000 Counter(424000) 423937
Saved chunk: 20230922T065331F507436-1K5qrRSgasRAdi6tpf3zmf-6oRelmNA6auqqeN30R2GKf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 424500 Counter(424500) 424437
eval_Episode has 500 steps and return 0.0.
 Step 849306 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.68 / train/action_mean 0.5 / train/action_min -3.9 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.9e-7 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.1e-7 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
7.9e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.29 / train/model_loss_mean 1.14 / train/model_loss_std 2.14 / train/model_opt_grad_norm 4.74 / 
train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.9e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 66.41 / train/post_ent_max 66.41 / train/post_ent_mean 41.58 / train/post_ent_min 26.14 / train/post_ent_std 4.1 / train/prior_ent_mag 68.69 / 
train/prior_ent_max 68.69 / train/prior_ent_mean 43.08 / train/prior_ent_min 31.33 / train/prior_ent_std 4.7 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.24 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.3e-11 / report/cont_loss_std 6.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / report/dyn_loss_std 3.79 / 
report/image_loss_mean 0.2 / report/image_loss_std 0.99 / report/model_loss_mean 1.26 / report/model_loss_std 2.78 / report/post_ent_mag 66.07 / report/post_ent_max 66.07 / report/post_ent_mean 41.31 / report/post_ent_min 27.49 / report/post_ent_std 3.97 / 
report/prior_ent_mag 68.66 / report/prior_ent_max 68.66 / report/prior_ent_mean 42.94 / report/prior_ent_min 31.27 / report/prior_ent_std 4.63 / report/rep_loss_mean 1.76 / report/rep_loss_std 3.79 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / 
eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 2.85 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.27 /
eval/model_loss_mean 1.14 / eval/model_loss_std 1.88 / eval/post_ent_mag 65.68 / eval/post_ent_max 65.68 / eval/post_ent_mean 40.85 / eval/post_ent_min 26.26 / eval/post_ent_std 4.03 / eval/prior_ent_mag 68.66 / eval/prior_ent_max 68.66 / eval/prior_ent_mean 42.35 / 
eval/prior_ent_min 31.89 / eval/prior_ent_std 4.82 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 2.85 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.2e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3790 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 398 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.6e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 16.84 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.84 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T065526F012154-6oRelmNA6auqqeN30R2GKf-0000000000000000000000-988.npz
Saved chunk: 20230922T065521F315394-5K5b9lJ14wjRmK50amulKg-0000000000000000000000-764.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065521F315394-5K5b9lJ14wjRmK50amulKg-639NrDyytHDqd8wVJTIaNX-1024.npz
Starting evaluation at step 425000 Counter(425000) 424937
Saved chunk: 20230922T065526F012154-6oRelmNA6auqqeN30R2GKf-7gn2GYUzxOfENeSoFN73Ki-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 425500 Counter(425500) 425437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065642F701009-639NrDyytHDqd8wVJTIaNX-1ApVCR91Yxi9JSRxBBrscL-1024.npz
Starting evaluation at step 426000 Counter(426000) 425937
Saved chunk: 20230922T065645F839527-7gn2GYUzxOfENeSoFN73Ki-0e7EQuj9zrfL2BXSEbT2zt-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 426500 Counter(426500) 426437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 427000 Counter(427000) 426937
Saved chunk: 20230922T065804F608422-0e7EQuj9zrfL2BXSEbT2zt-1bb4zpIlmR47NMG8KVN8Ri-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065803F077091-1ApVCR91Yxi9JSRxBBrscL-5EkvawYDnAn7DYHcZclvRp-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 427500 Counter(427500) 427437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 428000 Counter(428000) 427937
Saved chunk: 20230922T065923F235208-1bb4zpIlmR47NMG8KVN8Ri-3qXZI7OpnJpcXFdiMxAhXm-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T065926F632727-5EkvawYDnAn7DYHcZclvRp-2S1jQ66SJOqnCIs9jxqjZl-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 856982 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.69 / train/action_mean 0.49 / train/action_min -3.92 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.9e-7 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.1e-7 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
5.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.14 / train/model_loss_std 2.13 / train/model_opt_grad_norm 5.29 / 
train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.9e-4 / train/policy_logprob_mag 9.46 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.46 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.14 / train/post_ent_max 66.14 / train/post_ent_mean 41.61 / train/post_ent_min 26.05 / train/post_ent_std 4.05 / train/prior_ent_mag 68.58 / 
train/prior_ent_max 68.58 / train/prior_ent_mean 43.1 / train/prior_ent_min 31.33 / train/prior_ent_std 4.69 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.24 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.4e-11 / report/cont_loss_std 9.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.74 / report/dyn_loss_std 3.92 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.29 / report/model_loss_mean 1.21 / report/model_loss_std 2.54 / report/post_ent_mag 66.4 / report/post_ent_max 66.4 / report/post_ent_mean 41.22 / report/post_ent_min 27.49 / report/post_ent_std 4.3 / 
report/prior_ent_mag 68.51 / report/prior_ent_max 68.51 / report/prior_ent_mean 42.78 / report/prior_ent_min 31.48 / report/prior_ent_std 4.79 / report/rep_loss_mean 1.74 / report/rep_loss_std 3.92 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.5e-12 / 
eval/cont_loss_std 4.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 3.01 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.24 /
eval/model_loss_mean 1.12 / eval/model_loss_std 1.97 / eval/post_ent_mag 66.04 / eval/post_ent_max 66.04 / eval/post_ent_mean 40.91 / eval/post_ent_min 26.3 / eval/post_ent_std 3.61 / eval/prior_ent_mag 68.51 / eval/prior_ent_max 68.51 / eval/prior_ent_mean 42.47 / 
eval/prior_ent_min 31.8 / eval/prior_ent_std 4.57 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 3.01 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.3e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3838 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 3.9e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 400.3 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7345 / timer/agent.policy_total 16.09 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1919 / timer/agent.train_total 247.03 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 428500 Counter(428500) 428437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 429000 Counter(429000) 428937
Saved chunk: 20230922T070041F675401-3qXZI7OpnJpcXFdiMxAhXm-6OxkeUOb13r74Ifej7wloI-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070046F584411-2S1jQ66SJOqnCIs9jxqjZl-3lOdEpZ5xR4bqm1dk3e709-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 429500 Counter(429500) 429437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 430000 Counter(430000) 429937
Saved chunk: 20230922T070201F357081-6OxkeUOb13r74Ifej7wloI-0wE2u4HqKervCa83wCov2M-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070207F857499-3lOdEpZ5xR4bqm1dk3e709-69EgezPQJguzG5wx1BODJI-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 430500 Counter(430500) 430437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 431000 Counter(431000) 430937
Saved chunk: 20230922T070319F926768-0wE2u4HqKervCa83wCov2M-3Ps20zvUrWQZFnI1Ok1eyz-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070327F976057-69EgezPQJguzG5wx1BODJI-0Pkrkfjrg9vsdscalJjoLN-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 431500 Counter(431500) 431437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 432000 Counter(432000) 431937
Saved chunk: 20230922T070438F299817-3Ps20zvUrWQZFnI1Ok1eyz-6Es9DYsAAQ7VFqXGxkElg4-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070447F947904-0Pkrkfjrg9vsdscalJjoLN-1o4oFHlMWAFzZpZqGGuLsK-1024.npz
 Step 864582 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.48 / train/action_min -3.93 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.8e-7 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4e-7 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
5.5e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.14 / train/model_loss_std 2.14 / train/model_opt_grad_norm 5.14 / 
train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.8e-4 / train/policy_logprob_mag 9.47 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.47 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 66.04 / train/post_ent_max 66.04 / train/post_ent_mean 41.71 / train/post_ent_min 26.19 / train/post_ent_std 4.09 / train/prior_ent_mag 68.57 / 
train/prior_ent_max 68.57 / train/prior_ent_mean 43.21 / train/prior_ent_min 31.41 / train/prior_ent_std 4.71 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.25 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.7e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.51 / report/dyn_loss_std 2.82 / 
report/image_loss_mean 0.11 / report/image_loss_std 0.2 / report/model_loss_mean 1.02 / report/model_loss_std 1.84 / report/post_ent_mag 67.05 / report/post_ent_max 67.05 / report/post_ent_mean 41.41 / report/post_ent_min 25.94 / report/post_ent_std 3.99 / 
report/prior_ent_mag 68.88 / report/prior_ent_max 68.88 / report/prior_ent_mean 42.83 / report/prior_ent_min 31.44 / report/prior_ent_std 4.65 / report/rep_loss_mean 1.51 / report/rep_loss_std 2.82 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-12 / 
eval/cont_loss_std 6.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.52 / eval/dyn_loss_std 2.59 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.2 / 
eval/model_loss_mean 1.02 / eval/model_loss_std 1.69 / eval/post_ent_mag 66.71 / eval/post_ent_max 66.71 / eval/post_ent_mean 39.82 / eval/post_ent_min 17.89 / eval/post_ent_std 4.23 / eval/prior_ent_mag 68.88 / eval/prior_ent_max 68.88 / eval/prior_ent_mean 41.57 / 
eval/prior_ent_min 31.4 / eval/prior_ent_std 4.55 / eval/rep_loss_mean 1.52 / eval/rep_loss_std 2.59 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.3e5 / replay/inserts 3800 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / 
timer/env.step_count 3800 / timer/env.step_total 18.76 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 396.41 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7808 / timer/agent.policy_total 17.04 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1900 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1900 / timer/agent.train_total 244.24 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.32

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 432500 Counter(432500) 432437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 433000 Counter(433000) 432937
Saved chunk: 20230922T070556F612373-6Es9DYsAAQ7VFqXGxkElg4-5o9pMNmAppqWJMq7YdvuJX-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070607F906438-1o4oFHlMWAFzZpZqGGuLsK-6PuuDevodBX3fwb9xVCTC4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 433500 Counter(433500) 433437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 434000 Counter(434000) 433937
Saved chunk: 20230922T070716F457860-5o9pMNmAppqWJMq7YdvuJX-1BCkX8YYJJBhD1Ta3YrNro-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070729F382459-6PuuDevodBX3fwb9xVCTC4-40rAiyFGKQy8cCZNSAQYhS-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 434500 Counter(434500) 434437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 435000 Counter(435000) 434937
Saved chunk: 20230922T070835F273849-1BCkX8YYJJBhD1Ta3YrNro-5KXYUhnPzqWa1ObHmnapMq-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T070849F730875-40rAiyFGKQy8cCZNSAQYhS-0hcxvXmJuiyuEEP4oD7kuI-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 435500 Counter(435500) 435437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 436000 Counter(436000) 435937
Saved chunk: 20230922T070953F877380-5KXYUhnPzqWa1ObHmnapMq-661CLS5wvS2VBIKUTSNDk0-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 872158 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.49 / train/action_min -3.94 / train/action_std 1.08 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.8e-7 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / train/dyn_loss_std 
3.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.4e-7 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 4.9e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.13 / train/model_loss_std 2.09 / train/model_opt_grad_norm 4.88 / 
train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.9e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 66.06 / train/post_ent_max 66.06 / train/post_ent_mean 41.56 / train/post_ent_min 26.06 / train/post_ent_std 4.15 / train/prior_ent_mag 68.48 / 
train/prior_ent_max 68.48 / train/prior_ent_mean 43.06 / train/prior_ent_min 31.24 / train/prior_ent_std 4.73 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.18 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 3.1e-11 / report/cont_loss_std 3.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.88 / report/dyn_loss_std 4.55 / 
report/image_loss_mean 0.2 / report/image_loss_std 0.3 / report/model_loss_mean 1.33 / report/model_loss_std 2.95 / report/post_ent_mag 65.51 / report/post_ent_max 65.51 / report/post_ent_mean 41.11 / report/post_ent_min 25.19 / report/post_ent_std 4.18 / 
report/prior_ent_mag 68.65 / report/prior_ent_max 68.65 / report/prior_ent_mean 42.82 / report/prior_ent_min 32.09 / report/prior_ent_std 4.89 / report/rep_loss_mean 1.88 / report/rep_loss_std 4.55 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-12 / 
eval/cont_loss_std 6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.7 / eval/dyn_loss_std 3.57 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.48 / 
eval/model_loss_mean 1.19 / eval/model_loss_std 2.52 / eval/post_ent_mag 65.1 / eval/post_ent_max 65.1 / eval/post_ent_mean 40.67 / eval/post_ent_min 27.72 / eval/post_ent_std 3.96 / eval/prior_ent_mag 68.65 / eval/prior_ent_max 68.65 / eval/prior_ent_mean 42.36 / 
eval/prior_ent_min 31.39 / eval/prior_ent_std 4.65 / eval/rep_loss_mean 1.7 / eval/rep_loss_std 3.57 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.4e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / 
timer/env.step_count 3788 / timer/env.step_total 18.75 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 3.8e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.91 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.7 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.13 
/ timer/agent.report_frac 4.3e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / 
timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T071112F337596-661CLS5wvS2VBIKUTSNDk0-0000000000000000000000-223.npz
Saved chunk: 20230922T071009F871990-0hcxvXmJuiyuEEP4oD7kuI-0000000000000000000000-1000.npz
Saved chunk: 20230922T071009F871990-0hcxvXmJuiyuEEP4oD7kuI-710AQRIgRa2szW6uYsb0ZZ-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 436500 Counter(436500) 436437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 437000 Counter(437000) 436937
Saved chunk: 20230922T071112F337596-661CLS5wvS2VBIKUTSNDk0-7f5NR2qHpbNibuwrWGkcss-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071131F203786-710AQRIgRa2szW6uYsb0ZZ-2tDCXQ8ZgeeyGFUkqEk2XQ-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 437500 Counter(437500) 437437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 438000 Counter(438000) 437937
Saved chunk: 20230922T071232F593819-7f5NR2qHpbNibuwrWGkcss-6LJBl7DPNhMrr15xX98qFZ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071251F804834-2tDCXQ8ZgeeyGFUkqEk2XQ-2KI7IcRzYXmu2p0vcOG8lT-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 438500 Counter(438500) 438437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 439000 Counter(439000) 438937
Saved chunk: 20230922T071351F376588-6LJBl7DPNhMrr15xX98qFZ-47cKdxhnsjGFfmitHx9Raw-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071412F111918-2KI7IcRzYXmu2p0vcOG8lT-3vG6aRuLw3kZgxt08uixJ3-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 439500 Counter(439500) 439437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 879818 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.64 / train/action_mean 0.5 / train/action_min -3.92 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.8e-7 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / train/dyn_loss_std 
3.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.4e-7 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 3.8e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.13 / train/model_loss_std 2.1 / train/model_opt_grad_norm 5.15 / 
train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.8e-4 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 66.04 / train/post_ent_max 66.04 / train/post_ent_mean 41.47 / train/post_ent_min 26.17 / train/post_ent_std 4.17 / train/prior_ent_mag 68.28 / 
train/prior_ent_max 68.28 / train/prior_ent_mean 42.96 / train/prior_ent_min 31.25 / train/prior_ent_std 4.73 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.19 / train/reward_avg 0 / train/reward_loss_mean 4.9e-12 / train/reward_loss_std 1.6e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 4.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 1.3e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 2.77 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.21 / report/model_loss_mean 1.07 / report/model_loss_std 1.81 / report/post_ent_mag 65.88 / report/post_ent_max 65.88 / report/post_ent_mean 41.53 / report/post_ent_min 22.68 / report/post_ent_std 4.74 / 
report/prior_ent_mag 68.7 / report/prior_ent_max 68.7 / report/prior_ent_mean 43.08 / report/prior_ent_min 31.35 / report/prior_ent_std 5.02 / report/rep_loss_mean 1.55 / report/rep_loss_std 2.77 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1e-11 / 
eval/cont_loss_std 6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.16 / 
eval/model_loss_mean 1.05 / eval/model_loss_std 1.65 / eval/post_ent_mag 66.24 / eval/post_ent_max 66.24 / eval/post_ent_mean 40.53 / eval/post_ent_min 24.89 / eval/post_ent_std 4.37 / eval/prior_ent_mag 68.7 / eval/prior_ent_max 68.7 / eval/prior_ent_mean 42.21 / 
eval/prior_ent_min 31.26 / eval/prior_ent_std 4.84 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.6 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.4e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3830 / timer/env.step_total 18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 401.13 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.6e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7337 / timer/agent.policy_total 16.03 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1915 / timer/agent.train_total 246.84 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 440000 Counter(440000) 439937
Saved chunk: 20230922T071510F022477-47cKdxhnsjGFfmitHx9Raw-0kjZgrnfnvqGrpMGqL2nLc-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071532F344216-3vG6aRuLw3kZgxt08uixJ3-6kUvgQNeu1ovJNbdrSGmB0-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 440500 Counter(440500) 440437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 441000 Counter(441000) 440937
Saved chunk: 20230922T071629F623274-0kjZgrnfnvqGrpMGqL2nLc-0KS1V6g1ev56cel9yJW24r-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071653F656841-6kUvgQNeu1ovJNbdrSGmB0-7CORm88VPoFgbWqJapUlAs-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 441500 Counter(441500) 441437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 442000 Counter(442000) 441937
Saved chunk: 20230922T071748F596719-0KS1V6g1ev56cel9yJW24r-1sgoNy4fFxw8ra35NGVdRO-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071814F046440-7CORm88VPoFgbWqJapUlAs-2Vuv1M3lsjgxYfP5UCR6wx-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 442500 Counter(442500) 442437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 443000 Counter(443000) 442937
Saved chunk: 20230922T071907F213869-1sgoNy4fFxw8ra35NGVdRO-07eFTfaQbEZNBSKatLvPkG-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T071934F242459-2Vuv1M3lsjgxYfP5UCR6wx-7GGywcOTMp8mbHl1X4CzNF-1024.npz
Starting evaluation at step 443500 Counter(443500) 443437
eval_Episode has 500 steps and return 0.0.
 Step 887398 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.67 / train/action_mean 0.51 / train/action_min -3.86 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.8e-7 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 2.1e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.1e-6 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.3e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.14 / train/model_loss_std 2.12 / train/model_opt_grad_norm 5.12 / 
train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.9e-4 / train/policy_logprob_mag 9.45 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.45 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.3e-4 / train/post_ent_mag 66.02 / train/post_ent_max 66.02 / train/post_ent_mean 41.32 / train/post_ent_min 25.84 / train/post_ent_std 4.23 / train/prior_ent_mag 68.27 / 
train/prior_ent_max 68.27 / train/prior_ent_mean 42.84 / train/prior_ent_min 31.22 / train/prior_ent_std 4.76 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.22 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.78 / report/dyn_loss_std 4.04 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.43 / report/model_loss_mean 1.23 / report/model_loss_std 2.79 / report/post_ent_mag 66.45 / report/post_ent_max 66.45 / report/post_ent_mean 41.15 / report/post_ent_min 25.13 / report/post_ent_std 4.01 / 
report/prior_ent_mag 68.39 / report/prior_ent_max 68.39 / report/prior_ent_mean 42.82 / report/prior_ent_min 31.21 / report/prior_ent_std 4.86 / report/rep_loss_mean 1.78 / report/rep_loss_std 4.04 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-11 / 
eval/cont_loss_std 6.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.57 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.56 /
eval/model_loss_mean 1.11 / eval/model_loss_std 1.81 / eval/post_ent_mag 66.45 / eval/post_ent_max 66.45 / eval/post_ent_mean 40.96 / eval/post_ent_min 25.19 / eval/post_ent_std 4.81 / eval/prior_ent_mag 68.39 / eval/prior_ent_max 68.39 / eval/prior_ent_mean 42.57 / 
eval/prior_ent_min 31.46 / eval/prior_ent_std 5.39 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.57 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.4e5 / replay/inserts 3790 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3790 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.32 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7798 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1895 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.7e-4 / timer/agent.train_count 1895 / timer/agent.train_total 243.77 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.13 
/ timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 444000 Counter(444000) 443937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072025F854198-07eFTfaQbEZNBSKatLvPkG-7GGkJ9I45k4jkOxLdYtc9T-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072054F348446-7GGywcOTMp8mbHl1X4CzNF-4xquPssbTnsjLCr2T5cufP-1024.npz
Starting evaluation at step 444500 Counter(444500) 444437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 445000 Counter(445000) 444937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072145F438913-7GGkJ9I45k4jkOxLdYtc9T-7vt8Hs0oyYdylysxA49eON-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072215F853656-4xquPssbTnsjLCr2T5cufP-1u3SnLWiuTFLBb1cHFybLV-1024.npz
Starting evaluation at step 445500 Counter(445500) 445437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 446000 Counter(446000) 445937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072304F417644-7vt8Hs0oyYdylysxA49eON-0vqQnID85Br6604a2D3Pht-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072336F270414-1u3SnLWiuTFLBb1cHFybLV-10bKna6EA3cLV1pYiLRuBp-1024.npz
Starting evaluation at step 446500 Counter(446500) 446437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 447000 Counter(447000) 446937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072456F557976-10bKna6EA3cLV1pYiLRuBp-6dKVAZIo6nknB4bL8kxqOy-1024.npz
Starting evaluation at step 447500 Counter(447500) 447437
Saved chunk: 20230922T072423F202799-0vqQnID85Br6604a2D3Pht-2hZZMc5jo2Z8LeFf8qvxMz-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 895002 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.66 / train/action_mean 0.51 / train/action_min -3.85 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.7e-7 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4e-7 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
5.3e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.13 / train/model_loss_std 2.1 / train/model_opt_grad_norm 4.95 / 
train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.8e-4 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.48 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.89 / train/post_ent_max 65.89 / train/post_ent_mean 41.28 / train/post_ent_min 25.89 / train/post_ent_std 4.24 / train/prior_ent_mag 68.23 / 
train/prior_ent_max 68.23 / train/prior_ent_mean 42.82 / train/prior_ent_min 31.28 / train/prior_ent_std 4.81 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.19 / train/reward_avg 0 / train/reward_loss_mean 7.8e-11 / train/reward_loss_std 2.5e-9 / train/reward_max_data 
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 7.8e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 1e-11 / report/cont_loss_std 9.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 2.75 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.35 / report/model_loss_mean 1.08 / report/model_loss_std 1.88 / report/post_ent_mag 65.85 / report/post_ent_max 65.85 / report/post_ent_mean 40.73 / report/post_ent_min 26.35 / report/post_ent_std 3.96 / 
report/prior_ent_mag 68.19 / report/prior_ent_max 68.19 / report/prior_ent_mean 42.39 / report/prior_ent_min 31.65 / report/prior_ent_std 4.57 / report/rep_loss_mean 1.59 / report/rep_loss_std 2.75 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-12 / 
eval/cont_loss_std 2.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.59 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.18 /
eval/model_loss_mean 1.06 / eval/model_loss_std 1.77 / eval/post_ent_mag 65.45 / eval/post_ent_max 65.45 / eval/post_ent_mean 39.76 / eval/post_ent_min 24.32 / eval/post_ent_std 3.91 / eval/prior_ent_mag 68.19 / eval/prior_ent_max 68.19 / eval/prior_ent_mean 41.6 / 
eval/prior_ent_min 31.81 / eval/prior_ent_std 4.6 / eval/rep_loss_mean 1.59 / eval/rep_loss_std 2.75 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.5e5 / replay/inserts 3802 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.33 / 
timer/env.step_count 3802 / timer/env.step_total 18.83 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 8.5e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 399.63 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7810 / timer/agent.policy_total 16.91 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1901 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1901 / timer/agent.train_total 245.07 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T072616F708361-6dKVAZIo6nknB4bL8kxqOy-0000000000000000000000-212.npz
Saved chunk: 20230922T072617F699185-2hZZMc5jo2Z8LeFf8qvxMz-0000000000000000000000-482.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 448000 Counter(448000) 447937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 448500 Counter(448500) 448437
Saved chunk: 20230922T072617F699185-2hZZMc5jo2Z8LeFf8qvxMz-3CicTIXkq1GRdqtwOwxatU-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072616F708361-6dKVAZIo6nknB4bL8kxqOy-2IQU2GWI50DynA8BDkoaOv-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 449000 Counter(449000) 448937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 449500 Counter(449500) 449437
Saved chunk: 20230922T072737F986071-3CicTIXkq1GRdqtwOwxatU-7M4crd5iNxP5puJPMjROLj-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072741F949379-2IQU2GWI50DynA8BDkoaOv-3pBByBfvA5eX8QTsT8HhHF-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 450000 Counter(450000) 449937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 450500 Counter(450500) 450437
Saved chunk: 20230922T072856F738727-7M4crd5iNxP5puJPMjROLj-6rLbbuWaivnVyMe1epJSTL-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T072902F279658-3pBByBfvA5eX8QTsT8HhHF-41SI27Lig4hTND9sCcNEXQ-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 451000 Counter(451000) 450937
eval_Episode has 500 steps and return 0.0.
 Step 902662 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.62 / train/action_mean 0.5 / train/action_min -3.91 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.7e-7 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.5e-6 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.7e-4 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.13 / train/model_loss_std 2.1 / train/model_opt_grad_norm 4.77 / 
train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.8e-4 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 66.12 / train/post_ent_max 66.12 / train/post_ent_mean 41.16 / train/post_ent_min 26.3 / train/post_ent_std 4.3 / train/prior_ent_mag 68.24 / 
train/prior_ent_max 68.24 / train/prior_ent_mean 42.7 / train/prior_ent_min 31.34 / train/prior_ent_std 4.82 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.19 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 5.2e-12 / report/cont_loss_std 2.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.2e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.15 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.23 / report/model_loss_mean 1.1 / report/model_loss_std 2.05 / report/post_ent_mag 66.5 / report/post_ent_max 66.5 / report/post_ent_mean 41.17 / report/post_ent_min 28.41 / report/post_ent_std 3.53 / 
report/prior_ent_mag 68.15 / report/prior_ent_max 68.15 / report/prior_ent_mean 42.63 / report/prior_ent_min 31.69 / report/prior_ent_std 4.54 / report/rep_loss_mean 1.64 / report/rep_loss_std 3.15 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 9.1e-12 / 
eval/cont_loss_std 6.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.1e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.61 / eval/dyn_loss_std 3.04 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.32 /
eval/model_loss_mean 1.11 / eval/model_loss_std 2.03 / eval/post_ent_mag 66.17 / eval/post_ent_max 66.17 / eval/post_ent_mean 39.56 / eval/post_ent_min 27.48 / eval/post_ent_std 4.31 / eval/prior_ent_mag 68.15 / eval/prior_ent_max 68.15 / eval/prior_ent_mean 41.14 / 
eval/prior_ent_min 31.68 / eval/prior_ent_std 4.73 / eval/rep_loss_mean 1.61 / eval/rep_loss_std 3.04 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.5e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / 
timer/env.step_count 3830 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.27 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7337 / timer/agent.policy_total 16.04 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1915 / timer/agent.train_total 246.7 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min
0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total
3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 451500 Counter(451500) 451437
Saved chunk: 20230922T073015F385685-6rLbbuWaivnVyMe1epJSTL-5wjCeI6yzxRgwSeUacIAF4-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073022F500375-41SI27Lig4hTND9sCcNEXQ-1p1BKFDbCwaA7KpMXpp5q6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 452000 Counter(452000) 451937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 452500 Counter(452500) 452437
Saved chunk: 20230922T073135F080791-5wjCeI6yzxRgwSeUacIAF4-0R5g615fVuFdHfpfJquVJi-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073143F852130-1p1BKFDbCwaA7KpMXpp5q6-7KYDRTRsppq2LvCrrE7Gk1-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 453000 Counter(453000) 452937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 453500 Counter(453500) 453437
Saved chunk: 20230922T073254F068176-0R5g615fVuFdHfpfJquVJi-1yzlskL1UatBKbUR5x8zQ0-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073304F362797-7KYDRTRsppq2LvCrrE7Gk1-5lm44nl4PPHbbg8px44c4v-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 454000 Counter(454000) 453937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 454500 Counter(454500) 454437
Saved chunk: 20230922T073412F719958-1yzlskL1UatBKbUR5x8zQ0-7x4U82OEb1jfmmpZ1F1WBf-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073424F548816-5lm44nl4PPHbbg8px44c4v-2u5ShdhryDhMAHs4zyKPcL-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 455000 Counter(455000) 454937
eval_Episode has 500 steps and return 0.0.
 Step 910238 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.51 / train/action_min -3.84 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.7e-7 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.7e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.7e-7 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
5e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.27 / train/model_loss_mean 1.14 / train/model_loss_std 2.12 / train/model_opt_grad_norm 4.97 / 
train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.41 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.41 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.75 / train/post_ent_max 65.75 / train/post_ent_mean 41.24 / train/post_ent_min 26.32 / train/post_ent_std 4.31 / train/prior_ent_mag 68.11 / 
train/prior_ent_max 68.11 / train/prior_ent_mean 42.77 / train/prior_ent_min 31.43 / train/prior_ent_std 4.84 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.22 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 8e-12 / report/cont_loss_std 4.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 2.79 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.26 / report/model_loss_mean 1.06 / report/model_loss_std 1.86 / report/post_ent_mag 66.18 / report/post_ent_max 66.18 / report/post_ent_mean 40.58 / report/post_ent_min 28.08 / report/post_ent_std 4.2 / 
report/prior_ent_mag 67.81 / report/prior_ent_max 67.81 / report/prior_ent_mean 42.01 / report/prior_ent_min 31.8 / report/prior_ent_std 4.65 / report/rep_loss_mean 1.55 / report/rep_loss_std 2.79 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.2e-12 / 
eval/cont_loss_std 3.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.72 / eval/dyn_loss_std 3.62 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.3 / 
eval/model_loss_mean 1.2 / eval/model_loss_std 2.38 / eval/post_ent_mag 66.18 / eval/post_ent_max 66.18 / eval/post_ent_mean 40.01 / eval/post_ent_min 23.14 / eval/post_ent_std 4.82 / eval/prior_ent_mag 67.81 / eval/prior_ent_max 67.81 / eval/prior_ent_mean 41.7 / 
eval/prior_ent_min 31.7 / eval/prior_ent_std 5.23 / eval/rep_loss_mean 1.72 / eval/rep_loss_std 3.62 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.6e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3788 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 391.28 / timer/replay._sample_frac 1.3 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.79 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.8e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.94 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 455500 Counter(455500) 455437
Saved chunk: 20230922T073531F226303-7x4U82OEb1jfmmpZ1F1WBf-0MsqZCyWkbOynpkDfIssG2-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073544F599227-2u5ShdhryDhMAHs4zyKPcL-1mkeQDCyGoIT4SfbFWKw6x-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 456000 Counter(456000) 455937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 456500 Counter(456500) 456437
Saved chunk: 20230922T073650F935006-0MsqZCyWkbOynpkDfIssG2-6r6Io8lEbcHTIu2Q9m6hib-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073706F018572-1mkeQDCyGoIT4SfbFWKw6x-4IJJNCBDWnpY2Q36X4wvI5-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 457000 Counter(457000) 456937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 457500 Counter(457500) 457437
Saved chunk: 20230922T073809F812516-6r6Io8lEbcHTIu2Q9m6hib-2jqU89vDbZAi7vsVWvCdWi-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073826F367155-4IJJNCBDWnpY2Q36X4wvI5-2b3JumFujyDK9CuN9hwAkl-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 458000 Counter(458000) 457937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 458500 Counter(458500) 458437
Saved chunk: 20230922T073928F436910-2jqU89vDbZAi7vsVWvCdWi-3EzNog5jCLksIGbi3AXvSn-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T073946F562211-2b3JumFujyDK9CuN9hwAkl-1c3wegc6Hg9wY8F1NnZJ0B-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 917910 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.65 / train/action_mean 0.51 / train/action_min -3.85 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.8e-7 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-7 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
2.9e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.14 / train/model_loss_std 2.1 / train/model_opt_grad_norm 5.02 / 
train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.88 / train/post_ent_max 65.88 / train/post_ent_mean 41.22 / train/post_ent_min 26.12 / train/post_ent_std 4.38 / train/prior_ent_mag 68.06 / 
train/prior_ent_max 68.06 / train/prior_ent_mean 42.75 / train/prior_ent_min 31.3 / train/prior_ent_std 4.89 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.19 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.9e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / report/dyn_loss_std 2.61 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.14 / report/model_loss_mean 1.06 / report/model_loss_std 1.64 / report/post_ent_mag 66.17 / report/post_ent_max 66.17 / report/post_ent_mean 41.48 / report/post_ent_min 28.65 / report/post_ent_std 4.47 / 
report/prior_ent_mag 68.08 / report/prior_ent_max 68.08 / report/prior_ent_mean 42.9 / report/prior_ent_min 31.28 / report/prior_ent_std 5.16 / report/rep_loss_mean 1.56 / report/rep_loss_std 2.61 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-11 / 
eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.56 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.22 /
eval/model_loss_mean 1.03 / eval/model_loss_std 1.69 / eval/post_ent_mag 65.96 / eval/post_ent_max 65.96 / eval/post_ent_mean 39.99 / eval/post_ent_min 27.94 / eval/post_ent_std 4.31 / eval/prior_ent_mag 68.08 / eval/prior_ent_max 68.08 / eval/prior_ent_mean 41.46 / 
eval/prior_ent_min 31.47 / eval/prior_ent_std 4.8 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.56 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.6e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / 
timer/env.step_count 3836 / timer/env.step_total 19.29 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 401.91 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 15.98 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.8e-3 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1918 / timer/agent.train_total 246.61 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 459000 Counter(459000) 458937
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T074046F958166-3EzNog5jCLksIGbi3AXvSn-0000000000000000000000-741.npz
Saved chunk: 20230922T074106F654914-1c3wegc6Hg9wY8F1NnZJ0B-0000000000000000000000-448.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 459500 Counter(459500) 459437
Saved chunk: 20230922T074046F958166-3EzNog5jCLksIGbi3AXvSn-4oqJI3XY7CEOFxKfGRwjIO-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074106F654914-1c3wegc6Hg9wY8F1NnZJ0B-4DwCENDmySKN3bGAswb8fW-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 460000 Counter(460000) 459937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 460500 Counter(460500) 460437
Saved chunk: 20230922T074207F148934-4oqJI3XY7CEOFxKfGRwjIO-6QBGbfVyvLPa56GvAJvTPm-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074228F474637-4DwCENDmySKN3bGAswb8fW-4KuceAbI7AvHUfBHBSAykh-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 461000 Counter(461000) 460937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 461500 Counter(461500) 461437
Saved chunk: 20230922T074325F928635-6QBGbfVyvLPa56GvAJvTPm-4ClHoWIlP1yPSQ78skVXVk-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074348F778000-4KuceAbI7AvHUfBHBSAykh-7z7EqA0YaifqqqxAE0RDBs-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 462000 Counter(462000) 461937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 462500 Counter(462500) 462437
Saved chunk: 20230922T074444F554504-4ClHoWIlP1yPSQ78skVXVk-6fC4yhtI6UCmAdd9twboXL-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 925482 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.63 / train/action_max 4.62 / train/action_mean 0.52 / train/action_min -3.86 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.6e-7 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.5e-7 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
5.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.13 / train/model_loss_std 2.06 / train/model_opt_grad_norm 4.84 / 
train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.38 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.38 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.88 / train/post_ent_max 65.88 / train/post_ent_mean 41.21 / train/post_ent_min 26.05 / train/post_ent_std 4.31 / train/prior_ent_mag 68.11 / 
train/prior_ent_max 68.11 / train/prior_ent_mean 42.75 / train/prior_ent_min 31.43 / train/prior_ent_std 4.84 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.15 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 9.1e-12 / report/cont_loss_std 4.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.1e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 2.89 / 
report/image_loss_mean 0.11 / report/image_loss_std 0.24 / report/model_loss_mean 1.07 / report/model_loss_std 1.9 / report/post_ent_mag 65.87 / report/post_ent_max 65.87 / report/post_ent_mean 41.28 / report/post_ent_min 22.81 / report/post_ent_std 3.82 / 
report/prior_ent_mag 67.77 / report/prior_ent_max 67.77 / report/prior_ent_mean 42.83 / report/prior_ent_min 31.47 / report/prior_ent_std 4.41 / report/rep_loss_mean 1.59 / report/rep_loss_std 2.89 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.9e-12 / 
eval/cont_loss_std 4.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.9e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.52 / eval/dyn_loss_std 2.57 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.28 /
eval/model_loss_mean 1.04 / eval/model_loss_std 1.76 / eval/post_ent_mag 65.67 / eval/post_ent_max 65.67 / eval/post_ent_mean 39.91 / eval/post_ent_min 25.29 / eval/post_ent_std 4.53 / eval/prior_ent_mag 67.77 / eval/prior_ent_max 67.77 / eval/prior_ent_mean 41.41 / 
eval/prior_ent_min 31.6 / eval/prior_ent_std 4.81 / eval/rep_loss_mean 1.52 / eval/rep_loss_std 2.57 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.6e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / 
timer/env.step_count 3786 / timer/env.step_total 18.68 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 396.23 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7794 / timer/agent.policy_total 16.96 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1893 / timer/agent.train_total 243.82 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 
0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total
3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T074508F925792-7z7EqA0YaifqqqxAE0RDBs-30iv8FyoeBW6LBTNiYTgT4-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 463000 Counter(463000) 462937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 463500 Counter(463500) 463437
Saved chunk: 20230922T074602F964155-6fC4yhtI6UCmAdd9twboXL-3fohLEuy6RIYdeE9WZtBmA-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074629F935492-30iv8FyoeBW6LBTNiYTgT4-3LNqHuIpWa5IuVNVDjPE2v-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 464000 Counter(464000) 463937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 464500 Counter(464500) 464437
Saved chunk: 20230922T074722F881485-3fohLEuy6RIYdeE9WZtBmA-5rO5LxPCmySBg6W3Rh7zn8-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074750F531503-3LNqHuIpWa5IuVNVDjPE2v-60FB3bVBGc0buwW1ljlEM7-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 465000 Counter(465000) 464937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 465500 Counter(465500) 465437
Saved chunk: 20230922T074841F687795-5rO5LxPCmySBg6W3Rh7zn8-5BnFW3vukuNmfatbB8tkGB-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T074910F864598-60FB3bVBGc0buwW1ljlEM7-37lLZFAUtpnLWSavf4iwoA-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 466000 Counter(466000) 465937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 466500 Counter(466500) 466437
Saved chunk: 20230922T075000F353188-5BnFW3vukuNmfatbB8tkGB-1gwjCFlJWK96FIw7SR5rvY-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 933058 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.52 / train/action_min -3.84 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.6e-7 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.6e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.8e-7 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
5.1e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.15 / train/image_loss_std 0.28 / train/model_loss_mean 1.14 / train/model_loss_std 2.13 / train/model_opt_grad_norm 4.71 / 
train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.33 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.33 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.77 / train/post_ent_max 65.77 / train/post_ent_mean 41.22 / train/post_ent_min 26.19 / train/post_ent_std 4.35 / train/prior_ent_mag 68.01 / 
train/prior_ent_max 68.01 / train/prior_ent_mean 42.78 / train/prior_ent_min 31.48 / train/prior_ent_std 4.87 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.23 / train/reward_avg 0 / train/reward_loss_mean 9.9e-12 / train/reward_loss_std 3.2e-10 / train/reward_max_data
0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 9.9e-12 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 
/ report/cont_loss_mean 8.1e-12 / report/cont_loss_std 5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.1e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / report/dyn_loss_std 3.21 / 
report/image_loss_mean 0.1 / report/image_loss_std 0.19 / report/model_loss_mean 1.02 / report/model_loss_std 2.07 / report/post_ent_mag 65.67 / report/post_ent_max 65.67 / report/post_ent_mean 40.85 / report/post_ent_min 27.85 / report/post_ent_std 4.61 / 
report/prior_ent_mag 68.11 / report/prior_ent_max 68.11 / report/prior_ent_mean 42.48 / report/prior_ent_min 31.62 / report/prior_ent_std 4.81 / report/rep_loss_mean 1.53 / report/rep_loss_std 3.21 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-12 / 
eval/cont_loss_std 3.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.49 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.16 /
eval/model_loss_mean 1.03 / eval/model_loss_std 1.57 / eval/post_ent_mag 65.67 / eval/post_ent_max 65.67 / eval/post_ent_mean 39.54 / eval/post_ent_min 27.34 / eval/post_ent_std 4.37 / eval/prior_ent_mag 68.11 / eval/prior_ent_max 68.11 / eval/prior_ent_mean 41.35 / 
eval/prior_ent_min 31.56 / eval/prior_ent_std 4.7 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.49 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.7e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3788 / timer/env.step_total 18.73 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.72 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.88 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.8e-3 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.9 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075031F044667-37lLZFAUtpnLWSavf4iwoA-1OJUK3ouVHQLRvrXXgR4Yp-1024.npz
Starting evaluation at step 467000 Counter(467000) 466937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 467500 Counter(467500) 467437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075118F816878-1gwjCFlJWK96FIw7SR5rvY-26mCdlKOnCUwuTa0A56lCK-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075152F294316-1OJUK3ouVHQLRvrXXgR4Yp-43xY5Hu8F0PHEevdfrFdio-1024.npz
Starting evaluation at step 468000 Counter(468000) 467937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 468500 Counter(468500) 468437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075238F874736-26mCdlKOnCUwuTa0A56lCK-5ASF6ae3kMkubauGq9FMYv-1024.npz
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075312F771281-43xY5Hu8F0PHEevdfrFdio-4IcyrnJKQEeg2MXv1yGjz3-1024.npz
Starting evaluation at step 469000 Counter(469000) 468937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 469500 Counter(469500) 469437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 470000 Counter(470000) 469937
Saved chunk: 20230922T075357F554328-5ASF6ae3kMkubauGq9FMYv-5MBK9Idmuoa4UtGUTNgwM4-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075433F017282-4IcyrnJKQEeg2MXv1yGjz3-1ra0hl7Iu1RT5x7eeMWHog-1024.npz
 Step 940728 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.51 / train/action_min -3.86 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.6e-7 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.7e-7 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
5e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.13 / train/model_loss_std 2.08 / train/model_opt_grad_norm 4.89 / 
train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.72 / train/post_ent_max 65.72 / train/post_ent_mean 41.15 / train/post_ent_min 25.98 / train/post_ent_std 4.38 / train/prior_ent_mag 67.99 / 
train/prior_ent_max 67.99 / train/prior_ent_mean 42.7 / train/prior_ent_min 31.55 / train/prior_ent_std 4.88 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.17 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.7e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.49 / report/dyn_loss_std 2.56 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.15 / report/model_loss_mean 1.02 / report/model_loss_std 1.63 / report/post_ent_mag 65.94 / report/post_ent_max 65.94 / report/post_ent_mean 41.75 / report/post_ent_min 27.92 / report/post_ent_std 3.94 / 
report/prior_ent_mag 67.77 / report/prior_ent_max 67.77 / report/prior_ent_mean 42.92 / report/prior_ent_min 31.43 / report/prior_ent_std 4.48 / report/rep_loss_mean 1.49 / report/rep_loss_std 2.56 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1e-11 / 
eval/cont_loss_std 6.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / eval/dyn_loss_std 3.13 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.25 / 
eval/model_loss_mean 1.14 / eval/model_loss_std 2.01 / eval/post_ent_mag 65.72 / eval/post_ent_max 65.72 / eval/post_ent_mean 40.36 / eval/post_ent_min 28.07 / eval/post_ent_std 4.3 / eval/prior_ent_mag 67.77 / eval/prior_ent_max 67.77 / eval/prior_ent_mean 41.87 / 
eval/prior_ent_min 31.66 / eval/prior_ent_std 4.89 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 3.13 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.7e5 / replay/inserts 3835 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / 
timer/env.step_count 3835 / timer/env.step_total 18.97 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 400.65 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.2e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7342 / timer/agent.policy_total 16.16 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1917 / timer/agent.train_total 246.68 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 470500 Counter(470500) 470437
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T075551F990338-5MBK9Idmuoa4UtGUTNgwM4-0000000000000000000000-1000.npz
Saved chunk: 20230922T075556F498054-1ra0hl7Iu1RT5x7eeMWHog-0000000000000000000000-684.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 471000 Counter(471000) 470937
Saved chunk: 20230922T075551F990338-5MBK9Idmuoa4UtGUTNgwM4-47IzuptUS9U181Vq1VNNzQ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075556F498054-1ra0hl7Iu1RT5x7eeMWHog-7DduWo5b2T8bKrFeozXx1O-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 471500 Counter(471500) 471437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 472000 Counter(472000) 471937
Saved chunk: 20230922T075712F065041-47IzuptUS9U181Vq1VNNzQ-3XYHXTvLmtV7hbTJWfXJKc-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075718F198102-7DduWo5b2T8bKrFeozXx1O-4HQteg5Raw8U9Bl3geNcyy-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 472500 Counter(472500) 472437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 473000 Counter(473000) 472937
Saved chunk: 20230922T075830F845508-3XYHXTvLmtV7hbTJWfXJKc-2LiyrTUeB00OxyWzrvy9MK-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075838F510290-4HQteg5Raw8U9Bl3geNcyy-1UH3FAairMtAQb3t7urPMu-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 473500 Counter(473500) 473437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 474000 Counter(474000) 473937
Saved chunk: 20230922T075949F566561-2LiyrTUeB00OxyWzrvy9MK-78htsxjfuJXJLtY1AAlz62-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T075958F763294-1UH3FAairMtAQb3t7urPMu-0tTmPKlAxMLOLFTC8ouC1X-1024.npz
 Step 948298 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.68 / train/action_mean 0.51 / train/action_min -3.89 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.6e-7 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.8e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.3e-7 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
4.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.12 / train/model_loss_std 2.05 / train/model_opt_grad_norm 4.88 / 
train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.51 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.51 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.79 / train/post_ent_max 65.79 / train/post_ent_mean 41.12 / train/post_ent_min 26.06 / train/post_ent_std 4.47 / train/prior_ent_mag 67.89 / 
train/prior_ent_max 67.89 / train/prior_ent_mean 42.67 / train/prior_ent_min 31.37 / train/prior_ent_std 4.93 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.12 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.1e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.52 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.24 / report/model_loss_mean 1.11 / report/model_loss_std 2.28 / report/post_ent_mag 66.05 / report/post_ent_max 66.05 / report/post_ent_mean 41.77 / report/post_ent_min 27.85 / report/post_ent_std 4.6 / 
report/prior_ent_mag 68.16 / report/prior_ent_max 68.16 / report/prior_ent_mean 43.26 / report/prior_ent_min 31.45 / report/prior_ent_std 4.93 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.52 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1e-11 / 
eval/cont_loss_std 6.4e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 3.1 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.24 / 
eval/model_loss_mean 1.06 / eval/model_loss_std 2.03 / eval/post_ent_mag 66.05 / eval/post_ent_max 66.05 / eval/post_ent_mean 39.64 / eval/post_ent_min 25.6 / eval/post_ent_std 4.8 / eval/prior_ent_mag 68.16 / eval/prior_ent_max 68.16 / eval/prior_ent_mean 41.43 / 
eval/prior_ent_min 31.33 / eval/prior_ent_std 5.06 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 3.1 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.7e5 / replay/inserts 3785 / replay/samples 3e4 / replay/insert_wait_avg 3.2e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3785 / timer/env.step_total 18.85 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.6 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.4e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7793 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1893 / timer/agent.train_total 243.67 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 474500 Counter(474500) 474437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 475000 Counter(475000) 474937
Saved chunk: 20230922T080107F992899-78htsxjfuJXJLtY1AAlz62-5PPjiZVYRknwX53dtTckm3-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080118F826483-0tTmPKlAxMLOLFTC8ouC1X-0T2ToH7baBhZbiKuskjcWB-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 475500 Counter(475500) 475437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 476000 Counter(476000) 475937
Saved chunk: 20230922T080227F947132-5PPjiZVYRknwX53dtTckm3-3TbZU6Iizv6hLz0pbOrEBl-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080240F365395-0T2ToH7baBhZbiKuskjcWB-1L17pZoVoIf0W4d3pEuIdJ-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 476500 Counter(476500) 476437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 477000 Counter(477000) 476937
Saved chunk: 20230922T080346F613425-3TbZU6Iizv6hLz0pbOrEBl-2vhMdBsCbZkY8OA9VLrXab-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080400F587550-1L17pZoVoIf0W4d3pEuIdJ-4Bqa2Mxrzm3UVyAtKgc4wR-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 477500 Counter(477500) 477437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 955970 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.53 / train/action_min -3.92 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.5e-7 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.7e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.8e-7 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
4.1e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.12 / train/model_loss_std 2.07 / train/model_opt_grad_norm 4.81 / 
train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.7e-4 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 1.2e-4 / train/post_ent_mag 65.83 / train/post_ent_max 65.83 / train/post_ent_mean 41.12 / train/post_ent_min 26.37 / train/post_ent_std 4.41 / train/prior_ent_mag 67.94 / 
train/prior_ent_max 67.94 / train/prior_ent_mean 42.66 / train/prior_ent_min 31.48 / train/prior_ent_std 4.91 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.15 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 6e-12 / report/cont_loss_std 3.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / report/dyn_loss_std 4.02 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.34 / report/model_loss_mean 1.22 / report/model_loss_std 2.65 / report/post_ent_mag 65.64 / report/post_ent_max 65.64 / report/post_ent_mean 40.81 / report/post_ent_min 27.21 / report/post_ent_std 4.82 / 
report/prior_ent_mag 67.77 / report/prior_ent_max 67.77 / report/prior_ent_mean 42.66 / report/prior_ent_min 29.1 / report/prior_ent_std 5.13 / report/rep_loss_mean 1.77 / report/rep_loss_std 4.02 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.7e-12 / 
eval/cont_loss_std 9.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.7e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.45 / eval/image_loss_mean 0.1 / eval/image_loss_std 0.22 / 
eval/model_loss_mean 1.02 / eval/model_loss_std 1.59 / eval/post_ent_mag 65.54 / eval/post_ent_max 65.54 / eval/post_ent_mean 39.3 / eval/post_ent_min 23.97 / eval/post_ent_std 4.21 / eval/prior_ent_mag 67.77 / eval/prior_ent_max 67.77 / eval/prior_ent_mean 41.18 / 
eval/prior_ent_min 31.68 / eval/prior_ent_std 4.52 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.45 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.8e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3836 / timer/env.step_total 18.95 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 403.06 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 15.97 / timer/agent.policy_frac 0.05 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1918 / timer/agent.train_total 246.95 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 478000 Counter(478000) 477937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T080505F277453-2vhMdBsCbZkY8OA9VLrXab-4KNcuZNbB18NG93MY25IcK-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080520F841669-4Bqa2Mxrzm3UVyAtKgc4wR-5xFe5lpLyrbeyqF0LFIUxe-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 478500 Counter(478500) 478437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 479000 Counter(479000) 478937
Saved chunk: 20230922T080624F863666-4KNcuZNbB18NG93MY25IcK-4EgJ68cTqybWOg6MWt9Yds-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080642F136916-5xFe5lpLyrbeyqF0LFIUxe-3W48Cm7QmZ7UlJ34b9S78w-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 479500 Counter(479500) 479437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 480000 Counter(480000) 479937
Saved chunk: 20230922T080743F994138-4EgJ68cTqybWOg6MWt9Yds-1oZfcLOGWZHsD4MV9Caar5-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080802F744143-3W48Cm7QmZ7UlJ34b9S78w-659Qb8otU6b0Wk7PNB1vtE-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 480500 Counter(480500) 480437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 481000 Counter(481000) 480937
Saved chunk: 20230922T080902F674593-1oZfcLOGWZHsD4MV9Caar5-2no7hDMvnRDH5PuRjSMg02-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T080922F955339-659Qb8otU6b0Wk7PNB1vtE-474JeEyWwRTED4WVkFq2ET-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 481500 Counter(481500) 481437
eval_Episode has 500 steps and return 0.0.
 Step 963542 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.54 / train/action_min -3.82 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.4e-7 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.6e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-7 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
3.3e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.12 / train/model_loss_std 2.08 / train/model_opt_grad_norm 5.05 / 
train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.6e-4 / train/policy_logprob_mag 9.42 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.42 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.69 / train/post_ent_max 65.69 / train/post_ent_mean 41.02 / train/post_ent_min 26.33 / train/post_ent_std 4.4 / train/prior_ent_mag 68.02 / 
train/prior_ent_max 68.02 / train/prior_ent_mean 42.57 / train/prior_ent_min 31.4 / train/prior_ent_std 4.92 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.16 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.2e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 2.98 / 
report/image_loss_mean 0.11 / report/image_loss_std 0.2 / report/model_loss_mean 1.1 / report/model_loss_std 1.92 / report/post_ent_mag 65.24 / report/post_ent_max 65.24 / report/post_ent_mean 41.09 / report/post_ent_min 26.33 / report/post_ent_std 4.36 / 
report/prior_ent_mag 68.08 / report/prior_ent_max 68.08 / report/prior_ent_mean 42.75 / report/prior_ent_min 31.17 / report/prior_ent_std 5.03 / report/rep_loss_mean 1.65 / report/rep_loss_std 2.98 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-12 / 
eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.17 /
eval/model_loss_mean 1.04 / eval/model_loss_std 1.75 / eval/post_ent_mag 64.91 / eval/post_ent_max 64.91 / eval/post_ent_mean 39.75 / eval/post_ent_min 26.53 / eval/post_ent_std 3.87 / eval/prior_ent_mag 68.08 / eval/prior_ent_max 68.08 / eval/prior_ent_mean 41.49 / 
eval/prior_ent_min 31.73 / eval/prior_ent_std 4.51 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.75 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.8e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / 
timer/env.step_count 3786 / timer/env.step_total 18.7 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 394.02 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1893 / timer/agent.train_total 243.7 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 482000 Counter(482000) 481937
Saved chunk: 20230922T081021F238909-2no7hDMvnRDH5PuRjSMg02-4iic2UAK3uNN92L5A9v6X2-1024.npz
eval_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T081043F082910-474JeEyWwRTED4WVkFq2ET-0000000000000000000000-920.npz
Saved chunk: 20230922T081140F926888-4iic2UAK3uNN92L5A9v6X2-0000000000000000000000-235.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T081043F082910-474JeEyWwRTED4WVkFq2ET-6zQbgLP052TRw52Oy2Ek32-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 482500 Counter(482500) 482437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 483000 Counter(483000) 482937
Saved chunk: 20230922T081140F926888-4iic2UAK3uNN92L5A9v6X2-1mASbFRGCByIMuYT2wUc61-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T081204F733322-6zQbgLP052TRw52Oy2Ek32-5wLggCPiJoEpzR8oEZN7Xq-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 483500 Counter(483500) 483437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 484000 Counter(484000) 483937
Saved chunk: 20230922T081300F158103-1mASbFRGCByIMuYT2wUc61-5Qv2VBaCwAebUGrhXnw1Hm-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T081325F147272-5wLggCPiJoEpzR8oEZN7Xq-1RPJBBE5fmCuM8kKRgVS77-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 484500 Counter(484500) 484437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 485000 Counter(485000) 484937
Saved chunk: 20230922T081418F768108-5Qv2VBaCwAebUGrhXnw1Hm-1ainUHyjjnoqI6zoI0P056-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T081445F327146-1RPJBBE5fmCuM8kKRgVS77-32kSFsYCmvoxSbNSyOKa2G-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 485500 Counter(485500) 485437
eval_Episode has 500 steps and return 0.0.
 Step 971110 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.54 / train/action_min -3.84 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.5e-7 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.7e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.2e-7 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
3.4e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.13 / train/model_loss_std 2.08 / train/model_opt_grad_norm 4.87 / 
train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.6e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.69 / train/post_ent_max 65.69 / train/post_ent_mean 41.04 / train/post_ent_min 26.11 / train/post_ent_std 4.42 / train/prior_ent_mag 67.81 / 
train/prior_ent_max 67.81 / train/prior_ent_mean 42.58 / train/prior_ent_min 31.5 / train/prior_ent_std 4.91 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.16 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.8e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.19 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.19 / report/model_loss_mean 1.15 / report/model_loss_std 2.01 / report/post_ent_mag 65.57 / report/post_ent_max 65.57 / report/post_ent_mean 40.55 / report/post_ent_min 25.74 / report/post_ent_std 4.3 / 
report/prior_ent_mag 68.03 / report/prior_ent_max 68.03 / report/prior_ent_mean 42.06 / report/prior_ent_min 31.54 / report/prior_ent_std 4.97 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.19 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-11 / 
eval/cont_loss_std 8.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.73 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.36 /
eval/model_loss_mean 1.19 / eval/model_loss_std 2.5 / eval/post_ent_mag 65.57 / eval/post_ent_max 65.57 / eval/post_ent_mean 40.22 / eval/post_ent_min 27.7 / eval/post_ent_std 5.19 / eval/prior_ent_mag 68.03 / eval/prior_ent_max 68.03 / eval/prior_ent_mean 41.86 / 
eval/prior_ent_min 31.51 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.73 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.9e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / 
timer/env.step_count 3784 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3e4 / timer/replay._sample_total 392.91 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-4 / timer/replay._sample_max 0.18 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7792 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1892 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1892 / timer/agent.train_total 243.48 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.23

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 486000 Counter(486000) 485937
Saved chunk: 20230922T081537F331973-1ainUHyjjnoqI6zoI0P056-6pRzvmroQVItH3PHHAfXMF-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T081605F350900-32kSFsYCmvoxSbNSyOKa2G-0w8Kq1mWZ6IzemGidN9P66-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 486500 Counter(486500) 486437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 487000 Counter(487000) 486937
Saved chunk: 20230922T081657F072650-6pRzvmroQVItH3PHHAfXMF-1L1KAbYfhP3KpAGPsfNmlJ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T081726F897265-0w8Kq1mWZ6IzemGidN9P66-3PhJK3mbCsABqZNUqSgDBP-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 487500 Counter(487500) 487437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 488000 Counter(488000) 487937
Saved chunk: 20230922T081815F892941-1L1KAbYfhP3KpAGPsfNmlJ-4kQKBbDsefMDHUVJS8kaYf-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T081847F195927-3PhJK3mbCsABqZNUqSgDBP-2od8qfpaKg4qcVBZwp7rsP-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 488500 Counter(488500) 488437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 489000 Counter(489000) 488937
Saved chunk: 20230922T081934F471473-4kQKBbDsefMDHUVJS8kaYf-3iWxD6vqaQGqk2sYh2eG4q-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 978786 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.7 / train/action_mean 0.54 / train/action_min -3.81 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.5e-7 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.6e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.9e-7 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
6.2e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.13 / train/model_loss_std 2.09 / train/model_opt_grad_norm 5.01 / 
train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.6e-4 / train/policy_logprob_mag 9.54 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.54 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.83 / train/post_ent_max 65.83 / train/post_ent_mean 40.99 / train/post_ent_min 26.14 / train/post_ent_std 4.48 / train/prior_ent_mag 67.91 / 
train/prior_ent_max 67.91 / train/prior_ent_mean 42.55 / train/prior_ent_min 31.45 / train/prior_ent_std 4.96 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.18 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.5e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / report/dyn_loss_std 3.17 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.26 / report/model_loss_mean 1.22 / report/model_loss_std 2.08 / report/post_ent_mag 65.44 / report/post_ent_max 65.44 / report/post_ent_mean 41.95 / report/post_ent_min 26.76 / report/post_ent_std 4.45 / 
report/prior_ent_mag 67.99 / report/prior_ent_max 67.99 / report/prior_ent_mean 43.56 / report/prior_ent_min 31.69 / report/prior_ent_std 5.29 / report/rep_loss_mean 1.77 / report/rep_loss_std 3.17 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-12 / 
eval/cont_loss_std 1.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.52 / eval/dyn_loss_std 2.56 / eval/image_loss_mean 0.1 / eval/image_loss_std 0.14 / 
eval/model_loss_mean 1.01 / eval/model_loss_std 1.61 / eval/post_ent_mag 65.63 / eval/post_ent_max 65.63 / eval/post_ent_mean 39.02 / eval/post_ent_min 23.82 / eval/post_ent_std 4.33 / eval/prior_ent_mag 67.99 / eval/prior_ent_max 67.99 / eval/prior_ent_mean 40.57 / 
eval/prior_ent_min 31.7 / eval/prior_ent_std 4.77 / eval/rep_loss_mean 1.52 / eval/rep_loss_std 2.56 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.9e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / 
timer/env.step_count 3838 / timer/env.step_total 18.96 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 401.28 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7345 / timer/agent.policy_total 15.92 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 247.02 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T082007F287619-2od8qfpaKg4qcVBZwp7rsP-1clUGUpV8VWyLgJKyyVMzx-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 489500 Counter(489500) 489437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 490000 Counter(490000) 489937
Saved chunk: 20230922T082053F013316-3iWxD6vqaQGqk2sYh2eG4q-0Jp65kQ6fR1fYtk5COb8s4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 490500 Counter(490500) 490437
Saved chunk: 20230922T082128F364581-1clUGUpV8VWyLgJKyyVMzx-5ZGauG30zsnYtsCDNNKaMP-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 491000 Counter(491000) 490937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082212F921229-0Jp65kQ6fR1fYtk5COb8s4-20VGvyWn2J6AYTqfW4TqJq-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 491500 Counter(491500) 491437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082249F029468-5ZGauG30zsnYtsCDNNKaMP-4Jieosebal2k7LR9rxcc2p-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 492000 Counter(492000) 491937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082331F711734-20VGvyWn2J6AYTqfW4TqJq-7iZVvnmQ0gKmub2NQX3yhA-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 492500 Counter(492500) 492437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082412F631604-4Jieosebal2k7LR9rxcc2p-4PcsaOwS2TQPQNNxsXPCu6-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 493000 Counter(493000) 492937
eval_Episode has 500 steps and return 0.0.
 Step 986362 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.54 / train/action_min -3.87 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.4e-7 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.7e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.9e-7 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
4e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.12 / train/model_loss_std 2.05 / train/model_opt_grad_norm 5.27 / 
train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.6e-4 / train/policy_logprob_mag 9.45 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.45 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 66 / train/post_ent_max 66 / train/post_ent_mean 40.99 / train/post_ent_min 26.17 / train/post_ent_std 4.53 / train/prior_ent_mag 67.94 / 
train/prior_ent_max 67.94 / train/prior_ent_mean 42.53 / train/prior_ent_min 31.5 / train/prior_ent_std 4.99 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.12 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 4.1e-12 / report/cont_loss_std 3.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / report/dyn_loss_std 2.73 / 
report/image_loss_mean 0.1 / report/image_loss_std 0.21 / report/model_loss_mean 1.04 / report/model_loss_std 1.8 / report/post_ent_mag 66.09 / report/post_ent_max 66.09 / report/post_ent_mean 40.24 / report/post_ent_min 27.25 / report/post_ent_std 4.26 / 
report/prior_ent_mag 67.98 / report/prior_ent_max 67.98 / report/prior_ent_mean 41.84 / report/prior_ent_min 30.09 / report/prior_ent_std 4.77 / report/rep_loss_mean 1.56 / report/rep_loss_std 2.73 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.7e-12 / 
eval/cont_loss_std 5.5e-12 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.7e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.23 / eval/image_loss_mean 0.1 / eval/image_loss_std 0.14 / 
eval/model_loss_mean 0.99 / eval/model_loss_std 1.41 / eval/post_ent_mag 66.35 / eval/post_ent_max 66.35 / eval/post_ent_mean 38.95 / eval/post_ent_min 22.94 / eval/post_ent_std 4.55 / eval/prior_ent_mag 67.98 / eval/prior_ent_max 67.98 / eval/prior_ent_mean 40.65 / 
eval/prior_ent_min 31.65 / eval/prior_ent_std 4.68 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.23 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 4.9e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3788 / timer/env.step_total 18.7 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.5 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.85 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.6e-3 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.92 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 493500 Counter(493500) 493437
Saved chunk: 20230922T082450F301997-7iZVvnmQ0gKmub2NQX3yhA-0iMXpgO2bDnwwspycmNe7i-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082532F803561-4PcsaOwS2TQPQNNxsXPCu6-0IuBB4M7eGF4I1x8szOjjF-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T082654F029958-0IuBB4M7eGF4I1x8szOjjF-0000000000000000000000-132.npz
Saved chunk: 20230922T082645F765313-0iMXpgO2bDnwwspycmNe7i-0000000000000000000000-494.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 494000 Counter(494000) 493937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 494500 Counter(494500) 494437
Saved chunk: 20230922T082645F765313-0iMXpgO2bDnwwspycmNe7i-0skI32d8Kkmj0sad1MybO0-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082654F029958-0IuBB4M7eGF4I1x8szOjjF-52MbpkhXCUH058pAf5zITU-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 495000 Counter(495000) 494937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 495500 Counter(495500) 495437
Saved chunk: 20230922T082806F831885-0skI32d8Kkmj0sad1MybO0-1SedVqTIFk8Ea0YO5oF9eJ-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082816F601280-52MbpkhXCUH058pAf5zITU-5Y63fQszKEYrroSByMTqgS-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 496000 Counter(496000) 495937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 496500 Counter(496500) 496437
Saved chunk: 20230922T082925F370859-1SedVqTIFk8Ea0YO5oF9eJ-2a2X7MhuYOBHCsXoRJSM5w-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T082936F697120-5Y63fQszKEYrroSByMTqgS-5NA1LXDvUQUvQ5cFI3tRMB-1024.npz
 Step 993978 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.64 / train/action_max 4.63 / train/action_mean 0.54 / train/action_min -3.82 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.4e-7 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.5e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.8e-7 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
4.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.11 / train/model_loss_std 2.02 / train/model_opt_grad_norm 4.81 / 
train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.6e-4 / train/policy_logprob_mag 9.28 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.28 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 66.16 / train/post_ent_max 66.16 / train/post_ent_mean 40.95 / train/post_ent_min 26.43 / train/post_ent_std 4.59 / train/prior_ent_mag 67.99 / 
train/prior_ent_max 67.99 / train/prior_ent_mean 42.5 / train/prior_ent_min 31.59 / train/prior_ent_std 5.05 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.07 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 2.7e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.71 / report/dyn_loss_std 3.51 / 
report/image_loss_mean 0.17 / report/image_loss_std 0.29 / report/model_loss_mean 1.19 / report/model_loss_std 2.29 / report/post_ent_mag 66.32 / report/post_ent_max 66.32 / report/post_ent_mean 41.65 / report/post_ent_min 28.72 / report/post_ent_std 4.5 / 
report/prior_ent_mag 68.03 / report/prior_ent_max 68.03 / report/prior_ent_mean 43.23 / report/prior_ent_min 31.75 / report/prior_ent_std 5.01 / report/rep_loss_mean 1.71 / report/rep_loss_std 3.51 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1e-11 / 
eval/cont_loss_std 4.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 2.7 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.19 / 
eval/model_loss_mean 1.15 / eval/model_loss_std 1.73 / eval/post_ent_mag 66.2 / eval/post_ent_max 66.2 / eval/post_ent_mean 40.27 / eval/post_ent_min 23.52 / eval/post_ent_std 4.54 / eval/prior_ent_mag 68.03 / eval/prior_ent_max 68.03 / eval/prior_ent_mean 41.93 / 
eval/prior_ent_min 31.89 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 2.7 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5e5 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 
1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3808 / 
timer/env.step_total 18.82 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 399.27 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 5.3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7315 / 
timer/agent.policy_total 15.97 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1904 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / 
timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1904 / timer/agent.train_total 247.15 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max
2.09 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / 
timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.38

train_Episode has 500 steps and return 0.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 497000 Counter(497000) 496937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 497500 Counter(497500) 497437
Saved chunk: 20230922T083043F855264-2a2X7MhuYOBHCsXoRJSM5w-4eyWh2rndudQ6U1j31RdJy-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083056F789026-5NA1LXDvUQUvQ5cFI3tRMB-2n5v67wuDo6dboBRARfPBA-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 498000 Counter(498000) 497937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 498500 Counter(498500) 498437
Saved chunk: 20230922T083203F781605-4eyWh2rndudQ6U1j31RdJy-05fZ6b1zLBoe3k0jPg4Tdl-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083218F370349-2n5v67wuDo6dboBRARfPBA-5I8i1txEyl0KCR9gv6NnHn-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 499000 Counter(499000) 498937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 499500 Counter(499500) 499437
Saved chunk: 20230922T083322F643021-05fZ6b1zLBoe3k0jPg4Tdl-2fvrCgS7X305FF8cTNb7nR-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083338F748348-5I8i1txEyl0KCR9gv6NnHn-6tyNyjwyDow4PS8Xg19RGo-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 500000 Counter(500000) 499937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 500500 Counter(500500) 500437
Saved chunk: 20230922T083441F245622-2fvrCgS7X305FF8cTNb7nR-7ioILV3xi2AcyaLVKRX1Px-1024.npz
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083458F912223-6tyNyjwyDow4PS8Xg19RGo-4npPqDyRbn3f5kslqyGCIB-1024.npz
 Step 1001554 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train_stats/mean_log_entropy 1.42 / train/action_mag 4.65 / train/action_max 4.64 / train/action_mean 0.53 / train/action_min -3.81
/ train/action_std 1.07 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.3e-7 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / 
train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.61 / train/dyn_loss_std 3.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-7 / train/extr_critic_critic_opt_grad_steps 2.5e5 / 
train/extr_critic_critic_opt_loss 2.6e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / 
train/extr_return_normed_mean 7e-44 / train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / 
train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.25 / train/model_loss_mean 1.1 / train/model_loss_std 2 
/ train/model_opt_grad_norm 4.93 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.41 / train/policy_entropy_std 2.5e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.72 / train/post_ent_max 65.72 / train/post_ent_mean 41.03 / train/post_ent_min 26.49
/ train/post_ent_std 4.53 / train/prior_ent_mag 67.71 / train/prior_ent_max 67.71 / train/prior_ent_mean 42.56 / train/prior_ent_min 31.67 / train/prior_ent_std 4.98 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.06 / train/reward_avg 0 / train/reward_loss_mean 0 / 
train/reward_loss_std 0 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
report/cont_avg 1 / report/cont_loss_mean 5.8e-11 / report/cont_loss_std 5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.76 / 
report/dyn_loss_std 3.94 / report/image_loss_mean 0.22 / report/image_loss_std 0.47 / report/model_loss_mean 1.28 / report/model_loss_std 2.7 / report/post_ent_mag 66.02 / report/post_ent_max 66.02 / report/post_ent_mean 40.98 / report/post_ent_min 27.56 / 
report/post_ent_std 5.02 / report/prior_ent_mag 67.72 / report/prior_ent_max 67.72 / report/prior_ent_mean 42.47 / report/prior_ent_min 31.59 / report/prior_ent_std 5.44 / report/rep_loss_mean 1.76 / report/rep_loss_std 3.94 / report/reward_avg 0 / report/reward_loss_mean
0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 3.9e-12 / eval/cont_loss_std 2.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.04 / eval/image_loss_mean 
0.11 / eval/image_loss_std 0.34 / eval/model_loss_mean 0.99 / eval/model_loss_std 1.33 / eval/post_ent_mag 66.02 / eval/post_ent_max 66.02 / eval/post_ent_mean 38.28 / eval/post_ent_min 25.15 / eval/post_ent_std 5.3 / eval/prior_ent_mag 67.72 / eval/prior_ent_max 67.72 / 
eval/prior_ent_mean 39.67 / eval/prior_ent_min 31.56 / eval/prior_ent_std 5.2 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.04 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 
1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 
1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 
300.07 / timer/env.step_count 3788 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 7.4e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 397.52 / timer/replay._sample_frac 
1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 17.02 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / 
timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.38 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 
2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / 
timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 501000 Counter(501000) 500937
eval_Episode has 500 steps and return 0.0.
Starting evaluation at step 501500 Counter(501500) 501437
Saved chunk: 20230922T083559F730770-7ioILV3xi2AcyaLVKRX1Px-3VlCOuZBQu4T8LBVNhZbyb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083618F926575-4npPqDyRbn3f5kslqyGCIB-3w8YMwlZsG4hWsDEkxzxGh-1024.npz
Starting evaluation at step 502000 Counter(502000) 501937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 502500 Counter(502500) 502437
Saved chunk: 20230922T083719F678703-3VlCOuZBQu4T8LBVNhZbyb-1thvMjaVu0DT5cZp3Il1fd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083740F605198-3w8YMwlZsG4hWsDEkxzxGh-5XEezrB4qN6rK5l4ZZCenc-1024.npz
Starting evaluation at step 503000 Counter(503000) 502937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 503500 Counter(503500) 503437
Saved chunk: 20230922T083838F484367-1thvMjaVu0DT5cZp3Il1fd-5Fa25YQA8am88Ex10vLiVO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T083900F852053-5XEezrB4qN6rK5l4ZZCenc-1NqtOhtNm1ECyei7HoC54N-1024.npz
Starting evaluation at step 504000 Counter(504000) 503937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 504500 Counter(504500) 504437
Saved chunk: 20230922T083957F018641-5Fa25YQA8am88Ex10vLiVO-5KZdcbGmnEFXKXg8jA3oSY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1009130 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.68 / train/action_mean 0.53 / train/action_min -3.85 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.2e-7 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.5e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.3e-7 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
2.2e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.25 / train/model_loss_mean 1.11 / train/model_loss_std 2.03 / train/model_opt_grad_norm 4.79 / 
train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.5e-4 / train/policy_logprob_mag 9.43 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.43 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.76 / train/post_ent_max 65.76 / train/post_ent_mean 40.93 / train/post_ent_min 26.48 / train/post_ent_std 4.58 / train/prior_ent_mag 67.81 / 
train/prior_ent_max 67.81 / train/prior_ent_mean 42.49 / train/prior_ent_min 31.77 / train/prior_ent_std 5.04 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.1 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 6.1e-12 / report/cont_loss_std 2.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.1e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.68 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.24 / report/model_loss_mean 1.13 / report/model_loss_std 2.4 / report/post_ent_mag 65.57 / report/post_ent_max 65.57 / report/post_ent_mean 41.55 / report/post_ent_min 27.22 / report/post_ent_std 4.23 / 
report/prior_ent_mag 67.49 / report/prior_ent_max 67.49 / report/prior_ent_mean 43.07 / report/prior_ent_min 31.75 / report/prior_ent_std 4.74 / report/rep_loss_mean 1.66 / report/rep_loss_std 3.68 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-12 / 
eval/cont_loss_std 2.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.92 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.27 /
eval/model_loss_mean 1.06 / eval/model_loss_std 1.94 / eval/post_ent_mag 65.29 / eval/post_ent_max 65.29 / eval/post_ent_mean 39.75 / eval/post_ent_min 25.57 / eval/post_ent_std 4.4 / eval/prior_ent_mag 67.49 / eval/prior_ent_max 67.49 / eval/prior_ent_mean 41.36 / 
eval/prior_ent_min 31.81 / eval/prior_ent_std 4.7 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.92 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 
1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3788 / 
timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 399.27 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / 
timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1894 / timer/agent.train_total 243.87 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / 
timer/dataset_eval_max 3.7e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T084020F953074-1NqtOhtNm1ECyei7HoC54N-6pybAwqf4dKXGsrZSypjNF-1024.npz
Starting evaluation at step 505000 Counter(505000) 504937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T084142F146368-6pybAwqf4dKXGsrZSypjNF-0000000000000000000000-268.npz
Saved chunk: 20230922T084115F468067-5KZdcbGmnEFXKXg8jA3oSY-0000000000000000000000-753.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 505500 Counter(505500) 505437
Saved chunk: 20230922T084115F468067-5KZdcbGmnEFXKXg8jA3oSY-7KnZ1BknvDjIIzOAsLV8q7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T084142F146368-6pybAwqf4dKXGsrZSypjNF-0QCrRpxZpDICVLEoOaRODL-1024.npz
Starting evaluation at step 506000 Counter(506000) 505937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 506500 Counter(506500) 506437
Saved chunk: 20230922T084235F701895-7KnZ1BknvDjIIzOAsLV8q7-7vuAbk6ih4N2mSiHvAnqtc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T084302F859612-0QCrRpxZpDICVLEoOaRODL-0NYfbVL5YQOIakJoAo9vPo-1024.npz
Starting evaluation at step 507000 Counter(507000) 506937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 507500 Counter(507500) 507437
Saved chunk: 20230922T084354F445233-7vuAbk6ih4N2mSiHvAnqtc-7yQwxYT8ncusGheTPxB61K-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T084423F128987-0NYfbVL5YQOIakJoAo9vPo-50y5RVn8pEWziSGVpEwYYL-1024.npz
Starting evaluation at step 508000 Counter(508000) 507937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1016790 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.66 / train/action_mean 0.53 / train/action_min -3.8 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.4e-7 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.5e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.15 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.1e-7 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
4e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.12 / train/model_loss_std 2.07 / train/model_opt_grad_norm 5 / 
train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.6e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.7 / train/post_ent_max 65.7 / train/post_ent_mean 40.92 / train/post_ent_min 26.1 / train/post_ent_std 4.64 / train/prior_ent_mag 67.77 / 
train/prior_ent_max 67.77 / train/prior_ent_mean 42.5 / train/prior_ent_min 31.76 / train/prior_ent_std 5.08 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.15 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 6.7e-12 / report/cont_loss_std 3.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.7e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.04 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.27 / report/model_loss_mean 1.11 / report/model_loss_std 1.97 / report/post_ent_mag 65.15 / report/post_ent_max 65.15 / report/post_ent_mean 40.41 / report/post_ent_min 25.36 / report/post_ent_std 4.74 / 
report/prior_ent_mag 67.45 / report/prior_ent_max 67.45 / report/prior_ent_mean 41.92 / report/prior_ent_min 32.14 / report/prior_ent_std 5.07 / report/rep_loss_mean 1.63 / report/rep_loss_std 3.04 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.9e-12 / 
eval/cont_loss_std 5.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.9e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.47 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.2 / 
eval/model_loss_mean 1.05 / eval/model_loss_std 1.6 / eval/post_ent_mag 65.33 / eval/post_ent_max 65.33 / eval/post_ent_mean 39.56 / eval/post_ent_min 25.56 / eval/post_ent_std 4.75 / eval/prior_ent_mag 67.45 / eval/prior_ent_max 67.45 / eval/prior_ent_mean 41.26 / 
eval/prior_ent_min 32.08 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.47 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.1e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / 
timer/env.step_count 3830 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 402.96 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7337 / timer/agent.policy_total 16.07 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1915 / timer/agent.train_total 246.67 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.53

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 508500 Counter(508500) 508437
Saved chunk: 20230922T084513F116278-7yQwxYT8ncusGheTPxB61K-7fe9EyrtaZg2zBtkOoApGY-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T084543F353292-50y5RVn8pEWziSGVpEwYYL-00ayNSWtQdmfiZ0eUNTijv-1024.npz
Starting evaluation at step 509000 Counter(509000) 508937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 509500 Counter(509500) 509437
Saved chunk: 20230922T084632F828059-7fe9EyrtaZg2zBtkOoApGY-7BUHfLPpFQaVUNIdsU3For-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T084704F885383-00ayNSWtQdmfiZ0eUNTijv-5kzBFbdrS3Mju0LKY1vHtj-1024.npz
Starting evaluation at step 510000 Counter(510000) 509937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 510500 Counter(510500) 510437
Saved chunk: 20230922T084751F851693-7BUHfLPpFQaVUNIdsU3For-4d8DO2JJKpFBYjwpIF8sZr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T084825F275081-5kzBFbdrS3Mju0LKY1vHtj-6v7EA969KMWvOz2lpCrwAx-1024.npz
Starting evaluation at step 511000 Counter(511000) 510937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 511500 Counter(511500) 511437
Saved chunk: 20230922T084910F534238-4d8DO2JJKpFBYjwpIF8sZr-0dKsvJQnDPulNnL37q62JI-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 512000 Counter(512000) 511937
Saved chunk: 20230922T084945F473548-6v7EA969KMWvOz2lpCrwAx-1sOqwyqfwxbg4ysDig10bo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1024362 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.53 / train/action_min -3.89 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.3e-7 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.6e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 4.5e-7 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
5.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.12 / train/model_loss_std 2.09 / train/model_opt_grad_norm 4.89 / 
train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.5e-4 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.74 / train/post_ent_max 65.74 / train/post_ent_mean 40.94 / train/post_ent_min 26.2 / train/post_ent_std 4.65 / train/prior_ent_mag 67.86 / 
train/prior_ent_max 67.86 / train/prior_ent_mean 42.51 / train/prior_ent_min 31.86 / train/prior_ent_std 5.07 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.16 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 6.9e-12 / report/cont_loss_std 4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.9e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.27 / report/model_loss_mean 1.11 / report/model_loss_std 2.02 / report/post_ent_mag 65.86 / report/post_ent_max 65.86 / report/post_ent_mean 40.82 / report/post_ent_min 24.06 / report/post_ent_std 4.93 / 
report/prior_ent_mag 67.97 / report/prior_ent_max 67.97 / report/prior_ent_mean 42.39 / report/prior_ent_min 32.16 / report/prior_ent_std 5.25 / report/rep_loss_mean 1.63 / report/rep_loss_std 3 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-12 / 
eval/cont_loss_std 1.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 1.95 / eval/image_loss_mean 0.09 / eval/image_loss_std 0.16 /
eval/model_loss_mean 0.96 / eval/model_loss_std 1.26 / eval/post_ent_mag 65.84 / eval/post_ent_max 65.84 / eval/post_ent_mean 39 / eval/post_ent_min 23.15 / eval/post_ent_std 4.95 / eval/prior_ent_mag 67.97 / eval/prior_ent_max 67.97 / eval/prior_ent_mean 40.56 / 
eval/prior_ent_min 32.11 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 1.95 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.1e5 / replay/inserts 3786 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / 
timer/env.step_count 3786 / timer/env.step_total 18.89 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 399.29 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7794 / timer/agent.policy_total 16.86 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1893 / timer/agent.train_total 243.58 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 512500 Counter(512500) 512437
Saved chunk: 20230922T085029F085404-0dKsvJQnDPulNnL37q62JI-5BzmPDOFK2XbtyHjo4O9xk-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 513000 Counter(513000) 512937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085105F593537-1sOqwyqfwxbg4ysDig10bo-1nLPgwqUKG1yczhhlLklY3-1024.npz
Starting evaluation at step 513500 Counter(513500) 513437
Saved chunk: 20230922T085148F848364-5BzmPDOFK2XbtyHjo4O9xk-5Z5Qv4WamTXEvtBaLDbjyh-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 514000 Counter(514000) 513937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085230F580797-1nLPgwqUKG1yczhhlLklY3-3UhJgQ1MHc8igjDQ9sZJAc-1024.npz
Starting evaluation at step 514500 Counter(514500) 514437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085307F827361-5Z5Qv4WamTXEvtBaLDbjyh-6keZtfsocKLdzahChMpvrt-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 515000 Counter(515000) 514937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085351F004412-3UhJgQ1MHc8igjDQ9sZJAc-3oenmaJi9TOwyxAEXuTUaE-1024.npz
Starting evaluation at step 515500 Counter(515500) 515437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085426F641365-6keZtfsocKLdzahChMpvrt-1Mj6fTXcOarFA0oRsU8vMh-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 516000 Counter(516000) 515937
eval_Episode has 500 steps and return 0.0.
 Step 1032002 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.54 / train/action_min -3.87 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.3e-7 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.6e-7 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
3.5e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.11 / train/model_loss_std 2.06 / train/model_opt_grad_norm 4.85 / 
train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.4e-4 / train/policy_logprob_mag 9.45 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.45 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.83 / train/post_ent_max 65.83 / train/post_ent_mean 41.02 / train/post_ent_min 26.55 / train/post_ent_std 4.6 / train/prior_ent_mag 67.79 / 
train/prior_ent_max 67.79 / train/prior_ent_mean 42.56 / train/prior_ent_min 31.98 / train/prior_ent_std 5.05 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.13 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.7e-11 / report/cont_loss_std 8.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.71 / report/dyn_loss_std 4.02 / 
report/image_loss_mean 0.17 / report/image_loss_std 0.26 / report/model_loss_mean 1.19 / report/model_loss_std 2.6 / report/post_ent_mag 65.12 / report/post_ent_max 65.12 / report/post_ent_mean 41.91 / report/post_ent_min 28.22 / report/post_ent_std 5.19 / 
report/prior_ent_mag 67.41 / report/prior_ent_max 67.41 / report/prior_ent_mean 43.47 / report/prior_ent_min 31.35 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.71 / report/rep_loss_std 4.02 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.9e-12 / 
eval/cont_loss_std 4.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.9e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.4 / eval/image_loss_mean 0.1 / eval/image_loss_std 0.19 / 
eval/model_loss_mean 1 / eval/model_loss_std 1.54 / eval/post_ent_mag 65.25 / eval/post_ent_max 65.25 / eval/post_ent_mean 39.93 / eval/post_ent_min 28.52 / eval/post_ent_std 4.28 / eval/prior_ent_mag 67.41 / eval/prior_ent_max 67.41 / eval/prior_ent_mean 41.59 / 
eval/prior_ent_min 32.13 / eval/prior_ent_std 4.68 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.4 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / 
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.2e5 / replay/inserts 3820 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.62 / 
timer/env.step_count 3820 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 403 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7828 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1910 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1910 / timer/agent.train_total 245.98 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.9e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.9e-5 / 
timer/dataset_eval_min 4.9e-5 / timer/dataset_eval_max 4.9e-5 / fps 25.24

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085511F253363-3oenmaJi9TOwyxAEXuTUaE-0ccCSVTHYgEuexEhNLmAvZ-1024.npz
Starting evaluation at step 516500 Counter(516500) 516437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T085545F147764-1Mj6fTXcOarFA0oRsU8vMh-0000000000000000000000-1012.npz
Saved chunk: 20230922T085632F431146-0ccCSVTHYgEuexEhNLmAvZ-0000000000000000000000-504.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 517000 Counter(517000) 516937
Saved chunk: 20230922T085545F147764-1Mj6fTXcOarFA0oRsU8vMh-6j3u2gXY1Ahmce0SyOkwy3-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085632F431146-0ccCSVTHYgEuexEhNLmAvZ-5R8hxPF5ZCCMBXJ9m53vQH-1024.npz
Starting evaluation at step 517500 Counter(517500) 517437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 518000 Counter(518000) 517937
Saved chunk: 20230922T085741F319422-6j3u2gXY1Ahmce0SyOkwy3-7qYZTaPkiTOqaRShAd0diS-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085753F270476-5R8hxPF5ZCCMBXJ9m53vQH-6PCGD9Pwh3cAdVWzBfLmT1-1024.npz
Starting evaluation at step 518500 Counter(518500) 518437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 519000 Counter(519000) 518937
Saved chunk: 20230922T085900F022058-7qYZTaPkiTOqaRShAd0diS-1zOwNgcPeJuiaLH8pcSKAA-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T085913F507884-6PCGD9Pwh3cAdVWzBfLmT1-3gMj0efRov060C8aLJqHtm-1024.npz
Starting evaluation at step 519500 Counter(519500) 519437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1039666 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.68 / train/action_max 4.67 / train/action_mean 0.54 / train/action_min -3.8 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.3e-7 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.3e-11 / train/cont_loss_std 9.9e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.6e-7 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
2.6e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.12 / train/model_loss_std 2.05 / train/model_opt_grad_norm 5.06 / 
train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.4e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1e-4 / train/post_ent_mag 65.43 / train/post_ent_max 65.43 / train/post_ent_mean 41.26 / train/post_ent_min 26.28 / train/post_ent_std 4.57 / train/prior_ent_mag 67.6 / 
train/prior_ent_max 67.6 / train/prior_ent_mean 42.81 / train/prior_ent_min 32.08 / train/prior_ent_std 4.99 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.13 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 7.4e-12 / report/cont_loss_std 4.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.4e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 3.04 / 
report/image_loss_mean 0.11 / report/image_loss_std 0.3 / report/model_loss_mean 1.06 / report/model_loss_std 2.05 / report/post_ent_mag 65.33 / report/post_ent_max 65.33 / report/post_ent_mean 40.46 / report/post_ent_min 27.07 / report/post_ent_std 4.34 / 
report/prior_ent_mag 67.25 / report/prior_ent_max 67.25 / report/prior_ent_mean 42.07 / report/prior_ent_min 32.07 / report/prior_ent_std 4.75 / report/rep_loss_mean 1.58 / report/rep_loss_std 3.04 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 2e-12 / 
eval/cont_loss_std 6.4e-12 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2 / eval/image_loss_mean 0.1 / eval/image_loss_std 0.13 / 
eval/model_loss_mean 0.97 / eval/model_loss_std 1.25 / eval/post_ent_mag 65.37 / eval/post_ent_max 65.37 / eval/post_ent_mean 38.42 / eval/post_ent_min 26.15 / eval/post_ent_std 4.91 / eval/prior_ent_mag 67.25 / eval/prior_ent_max 67.25 / eval/prior_ent_mean 40.12 / 
eval/prior_ent_min 32.21 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / 
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.2e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3832 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 404.64 / timer/replay._sample_frac 1.35 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7339 / timer/agent.policy_total 16.09 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / 
timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1916 / timer/agent.train_total 246.63 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 2.5e-5 / timer/dataset_eval_frac 8.3e-8 / timer/dataset_eval_avg 2.5e-5 / timer/dataset_eval_min 2.5e-5 / timer/dataset_eval_max 2.5e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 520000 Counter(520000) 519937
Saved chunk: 20230922T090018F645942-1zOwNgcPeJuiaLH8pcSKAA-3JKLYLTDLZ46njv8Ya8xU7-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090033F676542-3gMj0efRov060C8aLJqHtm-4Bq21nbNYLdIzevPeHCdCA-1024.npz
Starting evaluation at step 520500 Counter(520500) 520437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 521000 Counter(521000) 520937
Saved chunk: 20230922T090138F260906-3JKLYLTDLZ46njv8Ya8xU7-3JFa07WJObzli7dUYcULO4-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090155F038147-4Bq21nbNYLdIzevPeHCdCA-74uumHzdlys0ZlAEKbKZI8-1024.npz
Starting evaluation at step 521500 Counter(521500) 521437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 522000 Counter(522000) 521937
Saved chunk: 20230922T090257F191128-3JFa07WJObzli7dUYcULO4-3cDHZCAKWGkTHCYxTCENmR-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090315F444156-74uumHzdlys0ZlAEKbKZI8-5v5mjXtEERpCuATHIZurDt-1024.npz
Starting evaluation at step 522500 Counter(522500) 522437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 523000 Counter(523000) 522937
Saved chunk: 20230922T090415F861931-3cDHZCAKWGkTHCYxTCENmR-2fhfnoFyWuUV1bxPNjOtno-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090435F667211-5v5mjXtEERpCuATHIZurDt-0a2mySCtiZf9GIPCM33rS8-1024.npz
Starting evaluation at step 523500 Counter(523500) 523437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1047242 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.71 / train/action_max 4.7 / train/action_mean 0.54 / train/action_min -3.84 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.2e-7 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.3e-11 / train/cont_loss_std 9.6e-11 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 9.9e-8 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.11 / train/model_loss_std 2.06 / train/model_opt_grad_norm 4.83 / 
train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1e-4 / train/post_ent_mag 65.49 / train/post_ent_max 65.49 / train/post_ent_mean 41.07 / train/post_ent_min 26.42 / train/post_ent_std 4.57 / train/prior_ent_mag 67.69 / 
train/prior_ent_max 67.69 / train/prior_ent_mean 42.63 / train/prior_ent_min 32.22 / train/prior_ent_std 5.02 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.13 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 8.2e-12 / report/cont_loss_std 5.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.2e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 2.94 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.22 / report/model_loss_mean 1.07 / report/model_loss_std 1.92 / report/post_ent_mag 65.9 / report/post_ent_max 65.9 / report/post_ent_mean 41.04 / report/post_ent_min 27.17 / report/post_ent_std 4.32 / 
report/prior_ent_mag 67.44 / report/prior_ent_max 67.44 / report/prior_ent_mean 42.56 / report/prior_ent_min 32.26 / report/prior_ent_std 4.94 / report/rep_loss_mean 1.57 / report/rep_loss_std 2.94 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-12 / 
eval/cont_loss_std 2.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.04 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.13 /
eval/model_loss_mean 0.97 / eval/model_loss_std 1.29 / eval/post_ent_mag 65.95 / eval/post_ent_max 65.95 / eval/post_ent_mean 39.1 / eval/post_ent_min 25.19 / eval/post_ent_std 4.68 / eval/prior_ent_mag 67.44 / eval/prior_ent_max 67.44 / eval/prior_ent_mean 40.63 / 
eval/prior_ent_min 32.02 / eval/prior_ent_std 4.89 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.04 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.2e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3788 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3e4 / timer/replay._sample_total 399.95 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.87 / timer/agent.policy_frac 0.06 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.2e-3 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.87 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 524000 Counter(524000) 523937
Saved chunk: 20230922T090534F489876-2fhfnoFyWuUV1bxPNjOtno-43nBAKwPfDva4qQZm6IDOS-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090555F820562-0a2mySCtiZf9GIPCM33rS8-4It4wYLIXpAFNxKFYxkAnV-1024.npz
Starting evaluation at step 524500 Counter(524500) 524437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 525000 Counter(525000) 524937
Saved chunk: 20230922T090654F253375-43nBAKwPfDva4qQZm6IDOS-54sYVlioYUDfJ6bXQKZXJv-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090717F313402-4It4wYLIXpAFNxKFYxkAnV-1TPBQXm9yIwptZJJMlmzrC-1024.npz
Starting evaluation at step 525500 Counter(525500) 525437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 526000 Counter(526000) 525937
Saved chunk: 20230922T090813F203187-54sYVlioYUDfJ6bXQKZXJv-3sk6HFKhDV0pVMGfc98li8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090837F748339-1TPBQXm9yIwptZJJMlmzrC-10MJve8QVl0DujbXH5Iedf-1024.npz
Starting evaluation at step 526500 Counter(526500) 526437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 527000 Counter(527000) 526937
Saved chunk: 20230922T090931F867716-3sk6HFKhDV0pVMGfc98li8-0hHcaRKaxLzL3hDbJKwcBb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T090957F938363-10MJve8QVl0DujbXH5Iedf-3VNlHx6Pae5Z4z5hkSguSM-1024.npz
 Step 1054914 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.68 / train/action_mean 0.54 / train/action_min -3.86 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.3e-7 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.18 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 3.6e-7 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
5.2e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.27 / train/model_loss_mean 1.12 / train/model_loss_std 2.09 / train/model_opt_grad_norm 4.76 / 
train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.4e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1.1e-4 / train/post_ent_mag 65.35 / train/post_ent_max 65.35 / train/post_ent_mean 41.06 / train/post_ent_min 26.44 / train/post_ent_std 4.56 / train/prior_ent_mag 67.58 / 
train/prior_ent_max 67.58 / train/prior_ent_mean 42.61 / train/prior_ent_min 32.13 / train/prior_ent_std 5.01 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.18 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.73 / report/dyn_loss_std 3.9 / 
report/image_loss_mean 0.2 / report/image_loss_std 0.37 / report/model_loss_mean 1.23 / report/model_loss_std 2.64 / report/post_ent_mag 65.75 / report/post_ent_max 65.75 / report/post_ent_mean 41.89 / report/post_ent_min 27.74 / report/post_ent_std 4.92 / 
report/prior_ent_mag 67.63 / report/prior_ent_max 67.63 / report/prior_ent_mean 43.5 / report/prior_ent_min 32.5 / report/prior_ent_std 5.35 / report/rep_loss_mean 1.73 / report/rep_loss_std 3.9 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 
/ report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 9.9e-12 / 
eval/cont_loss_std 7.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.9e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 2.66 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.17 /
eval/model_loss_mean 1.07 / eval/model_loss_std 1.71 / eval/post_ent_mag 65.7 / eval/post_ent_max 65.7 / eval/post_ent_mean 39.41 / eval/post_ent_min 23.17 / eval/post_ent_std 4.82 / eval/prior_ent_mag 67.63 / eval/prior_ent_max 67.63 / eval/prior_ent_mean 41.27 / 
eval/prior_ent_min 32.2 / eval/prior_ent_std 5.32 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 2.66 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.3e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3836 / timer/env.step_total 18.92 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 404.14 / timer/replay._sample_frac 1.35 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7343 / timer/agent.policy_total 16.1 / timer/agent.policy_frac 0.05 /
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1918 / timer/agent.train_total 246.87 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 527500 Counter(527500) 527437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 528000 Counter(528000) 527937
Saved chunk: 20230922T091050F326730-0hHcaRKaxLzL3hDbJKwcBb-6TmebNlicDfxdb9IePbZ6u-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T091210F267186-6TmebNlicDfxdb9IePbZ6u-0000000000000000000000-247.npz
Saved chunk: 20230922T091117F903753-3VNlHx6Pae5Z4z5hkSguSM-0000000000000000000000-740.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T091117F903753-3VNlHx6Pae5Z4z5hkSguSM-4IwuJhDEJfXzZv2zsIRkxN-1024.npz
Starting evaluation at step 528500 Counter(528500) 528437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 529000 Counter(529000) 528937
Saved chunk: 20230922T091210F267186-6TmebNlicDfxdb9IePbZ6u-6gxS1h46yOFGrmCXmelr8I-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T091239F844830-4IwuJhDEJfXzZv2zsIRkxN-7gFnLQgwjN8evY3LK1P0VN-1024.npz
Starting evaluation at step 529500 Counter(529500) 529437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 530000 Counter(530000) 529937
Saved chunk: 20230922T091329F296453-6gxS1h46yOFGrmCXmelr8I-5GrqAgD3KC2omfVgrqYkpG-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T091400F147496-7gFnLQgwjN8evY3LK1P0VN-3JqeLEnWEFbkcJxGryCUPU-1024.npz
Starting evaluation at step 530500 Counter(530500) 530437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 531000 Counter(531000) 530937
Saved chunk: 20230922T091447F963362-5GrqAgD3KC2omfVgrqYkpG-16hlPMDmhSbfHH6k53YS4M-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1062478 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.7 / train/action_mean 0.55 / train/action_min -3.79 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.2e-7 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2e-7 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
2.9e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.1 / train/model_loss_std 2.01 / train/model_opt_grad_norm 4.81 / 
train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1e-4 / train/post_ent_mag 65.46 / train/post_ent_max 65.46 / train/post_ent_mean 40.9 / train/post_ent_min 26.46 / train/post_ent_std 4.64 / train/prior_ent_mag 67.61 / 
train/prior_ent_max 67.61 / train/prior_ent_mean 42.47 / train/prior_ent_min 32.23 / train/prior_ent_std 5.06 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.06 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.1e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.64 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.29 / report/model_loss_mean 1.18 / report/model_loss_std 2.4 / report/post_ent_mag 65.41 / report/post_ent_max 65.41 / report/post_ent_mean 41.95 / report/post_ent_min 27.75 / report/post_ent_std 4.89 / 
report/prior_ent_mag 67.65 / report/prior_ent_max 67.65 / report/prior_ent_mean 43.64 / report/prior_ent_min 32.47 / report/prior_ent_std 5.41 / report/rep_loss_mean 1.72 / report/rep_loss_std 3.64 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-12 / 
eval/cont_loss_std 4.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.16 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.16 /
eval/model_loss_mean 1 / eval/model_loss_std 1.38 / eval/post_ent_mag 65.18 / eval/post_ent_max 65.18 / eval/post_ent_mean 39.09 / eval/post_ent_min 25.43 / eval/post_ent_std 4.74 / eval/prior_ent_mag 67.65 / eval/prior_ent_max 67.65 / eval/prior_ent_mean 40.78 / 
eval/prior_ent_min 32.65 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.16 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.3e5 / replay/inserts 3782 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / 
timer/env.step_count 3782 / timer/env.step_total 18.88 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 393.98 / timer/replay._sample_frac 1.31 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7790 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1891 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1891 / timer/agent.train_total 243.51 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.21

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T091520F298999-3JqeLEnWEFbkcJxGryCUPU-0ORM4b4ekdXLFj01PLqsT9-1024.npz
Starting evaluation at step 531500 Counter(531500) 531437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 532000 Counter(532000) 531937
Saved chunk: 20230922T091606F522564-16hlPMDmhSbfHH6k53YS4M-63juAsnISBOe4gHQxsrO0Y-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T091641F593829-0ORM4b4ekdXLFj01PLqsT9-5Hc5pUIygDtJQMWX8hMSC4-1024.npz
Starting evaluation at step 532500 Counter(532500) 532437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 533000 Counter(533000) 532937
Saved chunk: 20230922T091726F586219-63juAsnISBOe4gHQxsrO0Y-1fDlXUtpvHDRcIgs3NfKhd-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 533500 Counter(533500) 533437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T091802F182938-5Hc5pUIygDtJQMWX8hMSC4-34vRWLDj2d9F4SgpbSn7Sy-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 534000 Counter(534000) 533937
Saved chunk: 20230922T091845F327433-1fDlXUtpvHDRcIgs3NfKhd-2fcsp11Or1AnsuvQD7J16m-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 534500 Counter(534500) 534437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T091925F756495-34vRWLDj2d9F4SgpbSn7Sy-29jm2l3yNuicZQjTxpC53o-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 535000 Counter(535000) 534937
Saved chunk: 20230922T092003F874533-2fcsp11Or1AnsuvQD7J16m-7Fa1qamomMJynpZOx1EX9N-1024.npz
eval_Episode has 500 steps and return 0.0.
 Step 1070054 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.7 / train/action_max 4.7 / train/action_mean 0.55 / train/action_min -3.78 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.3e-7 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-7 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
2.7e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.11 / train/model_loss_std 2.04 / train/model_opt_grad_norm 4.91 / 
train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.4e-4 / train/policy_logprob_mag 9.44 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.44 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1e-4 / train/post_ent_mag 65.36 / train/post_ent_max 65.36 / train/post_ent_mean 41.03 / train/post_ent_min 26.39 / train/post_ent_std 4.59 / train/prior_ent_mag 67.55 / 
train/prior_ent_max 67.55 / train/prior_ent_mean 42.61 / train/prior_ent_min 32.36 / train/prior_ent_std 5.03 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.11 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.4e-11 / report/cont_loss_std 8.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.43 / 
report/image_loss_mean 0.15 / report/image_loss_std 0.25 / report/model_loss_mean 1.17 / report/model_loss_std 2.24 / report/post_ent_mag 65.82 / report/post_ent_max 65.82 / report/post_ent_mean 41.34 / report/post_ent_min 25 / report/post_ent_std 4.8 / 
report/prior_ent_mag 67.76 / report/prior_ent_max 67.76 / report/prior_ent_mean 43 / report/prior_ent_min 30.96 / report/prior_ent_std 5.34 / report/rep_loss_mean 1.7 / report/rep_loss_std 3.43 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 0 /
report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5e-12 / 
eval/cont_loss_std 3.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.47 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.18 / 
eval/model_loss_mean 1.05 / eval/model_loss_std 1.59 / eval/post_ent_mag 65.76 / eval/post_ent_max 65.76 / eval/post_ent_mean 39.41 / eval/post_ent_min 25.18 / eval/post_ent_std 4.56 / eval/prior_ent_mag 67.76 / eval/prior_ent_max 67.76 / eval/prior_ent_mean 41.01 / 
eval/prior_ent_min 32.41 / eval/prior_ent_std 5.02 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.47 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.3e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / 
timer/env.step_count 3788 / timer/env.step_total 18.71 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 7e-3 / timer/replay._sample_count 3e4 / timer/replay._sample_total 397.78 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 17.02 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.18 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.77 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 535500 Counter(535500) 535437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092045F928328-29jm2l3yNuicZQjTxpC53o-3xrpt8IBggQMxLnsqtJ6x0-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 536000 Counter(536000) 535937
Saved chunk: 20230922T092122F416854-7Fa1qamomMJynpZOx1EX9N-5wg6knaDJACwieBFcElXWv-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 536500 Counter(536500) 536437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092207F299221-3xrpt8IBggQMxLnsqtJ6x0-1hXEWBxvRU6F1OtK5iCB3u-1024.npz
Starting evaluation at step 537000 Counter(537000) 536937
Saved chunk: 20230922T092242F419067-5wg6knaDJACwieBFcElXWv-78cRYhfUMZdmSjhy6GCsBQ-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 537500 Counter(537500) 537437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092327F622507-1hXEWBxvRU6F1OtK5iCB3u-7ydfRZ2PCGdwH4kd8aph0O-1024.npz
Starting evaluation at step 538000 Counter(538000) 537937
Saved chunk: 20230922T092401F031427-78cRYhfUMZdmSjhy6GCsBQ-5nHzFvGFIe62JfdQx0xxol-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 538500 Counter(538500) 538437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092447F809893-7ydfRZ2PCGdwH4kd8aph0O-07GQNop0LpZQpZGOScvyWW-1024.npz
 Step 1077730 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.66 / train/action_max 4.65 / train/action_mean 0.55 / train/action_min -3.84 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2e-7 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 1.3e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / train/dyn_loss_std 
3.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.7e-7 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 2.5e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.13 / train/image_loss_std 0.26 / train/model_loss_mean 1.1 / train/model_loss_std 2.01 / train/model_opt_grad_norm 5.05 / 
train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.35 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.35 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 9.9e-5 / train/post_ent_mag 65.64 / train/post_ent_max 65.64 / train/post_ent_mean 40.92 / train/post_ent_min 26.42 / train/post_ent_std 4.54 / train/prior_ent_mag 67.62 / 
train/prior_ent_max 67.62 / train/prior_ent_mean 42.47 / train/prior_ent_min 32.21 / train/prior_ent_std 4.97 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.06 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 6.9e-12 / report/cont_loss_std 3.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.9e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.71 / report/dyn_loss_std 3.6 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.25 / report/model_loss_mean 1.17 / report/model_loss_std 2.36 / report/post_ent_mag 66.1 / report/post_ent_max 66.1 / report/post_ent_mean 40.43 / report/post_ent_min 23.81 / report/post_ent_std 4.52 / 
report/prior_ent_mag 67.73 / report/prior_ent_max 67.73 / report/prior_ent_mean 42.14 / report/prior_ent_min 30.77 / report/prior_ent_std 4.95 / report/rep_loss_mean 1.71 / report/rep_loss_std 3.6 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std 
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.1e-12 / 
eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.1e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 2.58 / eval/image_loss_mean 0.1 / eval/image_loss_std 0.17 / 
eval/model_loss_mean 1.05 / eval/model_loss_std 1.65 / eval/post_ent_mag 66.1 / eval/post_ent_max 66.1 / eval/post_ent_mean 38.43 / eval/post_ent_min 23.95 / eval/post_ent_std 5.07 / eval/prior_ent_mag 67.73 / eval/prior_ent_max 67.73 / eval/prior_ent_mean 40.38 / 
eval/prior_ent_min 32.57 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 2.58 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.4e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / 
timer/env.step_count 3838 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 403.49 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7345 / timer/agent.policy_total 15.98 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 / timer/dataset_train_count 1919 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 246.8 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 539000 Counter(539000) 538937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092519F617052-5nHzFvGFIe62JfdQx0xxol-3VX9jTI32csCKFJ5uxwWQr-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 539500 Counter(539500) 539437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T092639F290299-3VX9jTI32csCKFJ5uxwWQr-0000000000000000000000-506.npz
Saved chunk: 20230922T092607F865466-07GQNop0LpZQpZGOScvyWW-0000000000000000000000-976.npz
Saved chunk: 20230922T092607F865466-07GQNop0LpZQpZGOScvyWW-2WylHHO6DG2LBKkNKvPgnD-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 540000 Counter(540000) 539937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 540500 Counter(540500) 540437
Saved chunk: 20230922T092639F290299-3VX9jTI32csCKFJ5uxwWQr-0Y86R6kiToAbl6cqzbQbkc-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092729F778637-2WylHHO6DG2LBKkNKvPgnD-5WHnOjqApG58mTCGKG4mIV-1024.npz
Starting evaluation at step 541000 Counter(541000) 540937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 541500 Counter(541500) 541437
Saved chunk: 20230922T092834F485756-0Y86R6kiToAbl6cqzbQbkc-3Qlf38e41FXxTLLu9nHNDB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T092850F108272-5WHnOjqApG58mTCGKG4mIV-3kSU5QFafYWaeJx8SZPrXK-1024.npz
Starting evaluation at step 542000 Counter(542000) 541937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 542500 Counter(542500) 542437
Saved chunk: 20230922T092953F106158-3Qlf38e41FXxTLLu9nHNDB-53wmA88it0fxzJJE74Xiv8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1085298 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.67 / train/action_max 4.67 / train/action_mean 0.55 / train/action_min -3.81 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-7 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.1e-7 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
3e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.11 / train/model_loss_std 2.02 / train/model_opt_grad_norm 4.64 / 
train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.4 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.4 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 9.8e-5 / train/post_ent_mag 65.66 / train/post_ent_max 65.66 / train/post_ent_mean 40.87 / train/post_ent_min 26.54 / train/post_ent_std 4.59 / train/prior_ent_mag 67.76 / 
train/prior_ent_max 67.76 / train/prior_ent_mean 42.45 / train/prior_ent_min 32.38 / train/prior_ent_std 5.03 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.08 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 8e-12 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8e-12 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 2.63 / 
report/image_loss_mean 0.12 / report/image_loss_std 0.2 / report/model_loss_mean 1.06 / report/model_loss_std 1.68 / report/post_ent_mag 65.56 / report/post_ent_max 65.56 / report/post_ent_mean 41.24 / report/post_ent_min 24.18 / report/post_ent_std 4.28 / 
report/prior_ent_mag 67.78 / report/prior_ent_max 67.78 / report/prior_ent_mean 42.69 / report/prior_ent_min 32.54 / report/prior_ent_std 4.84 / report/rep_loss_mean 1.57 / report/rep_loss_std 2.63 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-11 / 
eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 2.52 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.39 /
eval/model_loss_mean 1.06 / eval/model_loss_std 1.76 / eval/post_ent_mag 65.76 / eval/post_ent_max 65.76 / eval/post_ent_mean 38.98 / eval/post_ent_min 23.44 / eval/post_ent_std 4.64 / eval/prior_ent_mag 67.78 / eval/prior_ent_max 67.78 / eval/prior_ent_mean 40.78 / 
eval/prior_ent_min 32.57 / eval/prior_ent_std 4.93 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 2.52 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.4e5 / replay/inserts 3784 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / 
timer/env.step_count 3784 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 395.8 / timer/replay._sample_frac 1.32 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7792 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1892 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1892 / timer/agent.train_total 243.59 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.22

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T093010F259571-3kSU5QFafYWaeJx8SZPrXK-7ANR1JftJcX1Ty9th63o8z-1024.npz
Starting evaluation at step 543000 Counter(543000) 542937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 543500 Counter(543500) 543437
Saved chunk: 20230922T093111F527716-53wmA88it0fxzJJE74Xiv8-5GTPCnAP8gMVoA3kN1YyaG-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093131F355659-7ANR1JftJcX1Ty9th63o8z-0zfBkKcdoTXrMQuiuexCzA-1024.npz
Starting evaluation at step 544000 Counter(544000) 543937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 544500 Counter(544500) 544437
Saved chunk: 20230922T093231F583391-5GTPCnAP8gMVoA3kN1YyaG-42M9bjK8vcHcWa0LrVtai8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093251F974261-0zfBkKcdoTXrMQuiuexCzA-7B2bL33kS4p0olpbfVb1oy-1024.npz
Starting evaluation at step 545000 Counter(545000) 544937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 545500 Counter(545500) 545437
Saved chunk: 20230922T093350F303462-42M9bjK8vcHcWa0LrVtai8-6IaWaOfnkkv9cueUizrIRh-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093412F250551-7B2bL33kS4p0olpbfVb1oy-2VG53IQ60zPM5wxW2ihUZF-1024.npz
Starting evaluation at step 546000 Counter(546000) 545937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1092962 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.68 / train/action_mean 0.55 / train/action_min -3.81 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-7 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 7.3e-7 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
7.8e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.1 / train/model_loss_std 2.03 / train/model_opt_grad_norm 4.77 / 
train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.38 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.38 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 9.8e-5 / train/post_ent_mag 65.79 / train/post_ent_max 65.79 / train/post_ent_mean 40.9 / train/post_ent_min 26.27 / train/post_ent_std 4.54 / train/prior_ent_mag 67.68 / 
train/prior_ent_max 67.68 / train/prior_ent_mean 42.46 / train/prior_ent_min 32.41 / train/prior_ent_std 5 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.09 / train/reward_avg 0 / train/reward_loss_mean 2.9e-11 / train/reward_loss_std 9.3e-10 / train/reward_max_data 0 
/ train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-11 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.4e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.72 / report/dyn_loss_std 3.71 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.23 / report/model_loss_mean 1.19 / report/model_loss_std 2.39 / report/post_ent_mag 65.87 / report/post_ent_max 65.87 / report/post_ent_mean 41.17 / report/post_ent_min 21.63 / report/post_ent_std 4.54 / 
report/prior_ent_mag 67.97 / report/prior_ent_max 67.97 / report/prior_ent_mean 42.87 / report/prior_ent_min 31.42 / report/prior_ent_std 5.05 / report/rep_loss_mean 1.72 / report/rep_loss_std 3.71 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-12 / 
eval/cont_loss_std 3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.59 / eval/dyn_loss_std 2.97 / eval/image_loss_mean 0.11 / eval/image_loss_std 0.21 / 
eval/model_loss_mean 1.06 / eval/model_loss_std 1.93 / eval/post_ent_mag 65.91 / eval/post_ent_max 65.91 / eval/post_ent_mean 38.99 / eval/post_ent_min 25.2 / eval/post_ent_std 4.47 / eval/prior_ent_mag 67.97 / eval/prior_ent_max 67.97 / eval/prior_ent_mean 40.9 / 
eval/prior_ent_min 32.54 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 1.59 / eval/rep_loss_std 2.97 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.5e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / 
timer/env.step_count 3832 / timer/env.step_total 18.94 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 404.31 / timer/replay._sample_frac 1.35 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7339 / timer/agent.policy_total 15.96 / timer/agent.policy_frac 0.05 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1916 / timer/agent.train_total 246.89 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 546500 Counter(546500) 546437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T093509F040600-6IaWaOfnkkv9cueUizrIRh-39CiMunUtZ1yYujWDo0pGf-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093532F508026-2VG53IQ60zPM5wxW2ihUZF-1UYGPCdplx1MI4aBnjxXpE-1024.npz
Starting evaluation at step 547000 Counter(547000) 546937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 547500 Counter(547500) 547437
Saved chunk: 20230922T093628F607734-39CiMunUtZ1yYujWDo0pGf-5uDJQprQTkxV6iB35dmmki-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093653F909478-1UYGPCdplx1MI4aBnjxXpE-3zCFyyAmMDTgzeDPswg1Ke-1024.npz
Starting evaluation at step 548000 Counter(548000) 547937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 548500 Counter(548500) 548437
Saved chunk: 20230922T093747F723831-5uDJQprQTkxV6iB35dmmki-1eAZrjj2I2MGZxtmfNasVx-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093814F386051-3zCFyyAmMDTgzeDPswg1Ke-7aflfjuqfFOBMFnR23RRAz-1024.npz
Starting evaluation at step 549000 Counter(549000) 548937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 549500 Counter(549500) 549437
Saved chunk: 20230922T093906F403952-1eAZrjj2I2MGZxtmfNasVx-3lqOoBiqnMjQYihyjGO5ql-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T093934F580171-7aflfjuqfFOBMFnR23RRAz-310RcPygfQb4kLUd30SlIT-1024.npz
Starting evaluation at step 550000 Counter(550000) 549937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1100538 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.72 / train/action_max 4.71 / train/action_mean 0.55 / train/action_min -3.87 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2e-7 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0
/ train/cont_avg 1 / train/cont_loss_mean 1.3e-11 / train/cont_loss_std 1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / train/dyn_loss_std 
3.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.3e-7 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 2e-5 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.13 / train/image_loss_std 0.25 / train/model_loss_mean 1.1 / train/model_loss_std 2 / train/model_opt_grad_norm 4.77 / 
train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.2e-4 / train/policy_logprob_mag 9.43 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.43 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 9.8e-5 / train/post_ent_mag 65.65 / train/post_ent_max 65.65 / train/post_ent_mean 40.92 / train/post_ent_min 26.56 / train/post_ent_std 4.52 / train/prior_ent_mag 67.71 / 
train/prior_ent_max 67.71 / train/prior_ent_mean 42.47 / train/prior_ent_min 32.38 / train/prior_ent_std 4.98 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.04 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 2.1e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 3.53 / 
report/image_loss_mean 0.16 / report/image_loss_std 0.45 / report/model_loss_mean 1.24 / report/model_loss_std 2.45 / report/post_ent_mag 66.07 / report/post_ent_max 66.07 / report/post_ent_mean 41.52 / report/post_ent_min 28.28 / report/post_ent_std 4.47 / 
report/prior_ent_mag 67.42 / report/prior_ent_max 67.42 / report/prior_ent_mean 43.22 / report/prior_ent_min 31.48 / report/prior_ent_std 5.17 / report/rep_loss_mean 1.79 / report/rep_loss_std 3.53 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-12 / 
eval/cont_loss_std 2.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.69 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.17 /
eval/model_loss_mean 1.05 / eval/model_loss_std 1.71 / eval/post_ent_mag 66.33 / eval/post_ent_max 66.33 / eval/post_ent_mean 39.41 / eval/post_ent_min 25.29 / eval/post_ent_std 4.53 / eval/prior_ent_mag 67.42 / eval/prior_ent_max 67.42 / eval/prior_ent_mean 41.09 / 
eval/prior_ent_min 32.65 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.69 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.5e5 / replay/inserts 3788 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / 
timer/env.step_count 3788 / timer/env.step_total 18.87 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3e4 / timer/replay._sample_total 398.89 / timer/replay._sample_frac 1.33 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7796 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 
/ timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.9e-3 / timer/dataset_train_count 1894 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1894 / timer/agent.train_total 243.48 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 
4e-5 / timer/dataset_eval_max 4e-5 / fps 25.25

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 550500 Counter(550500) 550437
Saved chunk: 20230922T094024F928285-3lqOoBiqnMjQYihyjGO5ql-0eo4SN4qQRiZ5ok2ZBDDE8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094054F607796-310RcPygfQb4kLUd30SlIT-3b8hikoQizOQVvRtnZXJLp-1024.npz
Starting evaluation at step 551000 Counter(551000) 550937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Saved chunk: 20230922T094216F262986-3b8hikoQizOQVvRtnZXJLp-0000000000000000000000-188.npz
Saved chunk: 20230922T094144F673884-0eo4SN4qQRiZ5ok2ZBDDE8-0000000000000000000000-765.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/4/checkpoint.ckpt
Starting evaluation at step 551500 Counter(551500) 551437
Saved chunk: 20230922T094144F673884-0eo4SN4qQRiZ5ok2ZBDDE8-33H4Js63mN7tLIttQd00e5-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094216F262986-3b8hikoQizOQVvRtnZXJLp-317eAxhcQ4cusJbE8BGznC-1024.npz
Starting evaluation at step 552000 Counter(552000) 551937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 552500 Counter(552500) 552437
Saved chunk: 20230922T094303F913271-33H4Js63mN7tLIttQd00e5-1iRCRCO6vdUABtA2VGcRCC-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094336F991904-317eAxhcQ4cusJbE8BGznC-7sxuhOwqlEkHiXHpcD4Dyp-1024.npz
Starting evaluation at step 553000 Counter(553000) 552937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 553500 Counter(553500) 553437
Saved chunk: 20230922T094422F745719-1iRCRCO6vdUABtA2VGcRCC-15taAK20bLCOjk05vKTdqi-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094457F220546-7sxuhOwqlEkHiXHpcD4Dyp-0MuguICR1s4rELQKwJHbXY-1024.npz
Starting evaluation at step 554000 Counter(554000) 553937
eval_Episode has 500 steps and return 0.0.
 Step 1108098 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.71 / train/action_max 4.7 / train/action_mean 0.54 / train/action_min -3.85 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-7 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.4e-7 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
2.4e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.11 / train/model_loss_std 2.04 / train/model_opt_grad_norm 4.84 / 
train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.41 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.41 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 9.9e-5 / train/post_ent_mag 65.88 / train/post_ent_max 65.88 / train/post_ent_mean 40.92 / train/post_ent_min 26.64 / train/post_ent_std 4.55 / train/prior_ent_mag 67.9 / 
train/prior_ent_max 67.9 / train/prior_ent_mean 42.5 / train/prior_ent_min 32.29 / train/prior_ent_std 5.02 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.11 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / report/cont_avg 1 / 
report/cont_loss_mean 1.6e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.59 / 
report/image_loss_mean 0.14 / report/image_loss_std 0.25 / report/model_loss_mean 1.11 / report/model_loss_std 2.32 / report/post_ent_mag 66.37 / report/post_ent_max 66.37 / report/post_ent_mean 40.84 / report/post_ent_min 25.33 / report/post_ent_std 5.19 / 
report/prior_ent_mag 67.83 / report/prior_ent_max 67.83 / report/prior_ent_mean 42.41 / report/prior_ent_min 32.37 / report/prior_ent_std 5.43 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.59 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 8.5e-12 / 
eval/cont_loss_std 9.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.5e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.58 / eval/dyn_loss_std 3.22 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.29 /
eval/model_loss_mean 1.08 / eval/model_loss_std 2.14 / eval/post_ent_mag 66.37 / eval/post_ent_max 66.37 / eval/post_ent_mean 39.28 / eval/post_ent_min 26.23 / eval/post_ent_std 4.1 / eval/prior_ent_mag 67.83 / eval/prior_ent_max 67.83 / eval/prior_ent_mean 41.08 / 
eval/prior_ent_min 32.52 / eval/prior_ent_std 4.74 / eval/rep_loss_mean 1.58 / eval/rep_loss_std 3.22 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 
/ eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.5e5 / replay/inserts 3780 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / 
timer/env.step_count 3780 / timer/env.step_total 18.72 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3e4 / timer/replay._sample_total 402.13 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-4 / timer/replay._sample_max 0.22 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / 
timer/agent.policy_count 7788 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1890 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1890 / timer/agent.train_total 243.63 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / 
timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 554500 Counter(554500) 554437
Saved chunk: 20230922T094541F308974-15taAK20bLCOjk05vKTdqi-2CHfgskybO1dH2d6XFSgsn-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 555000 Counter(555000) 554937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094617F310687-0MuguICR1s4rELQKwJHbXY-27hKd42Hf6pD1JwDukyqoX-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 555500 Counter(555500) 555437
Saved chunk: 20230922T094701F221882-2CHfgskybO1dH2d6XFSgsn-1xeA9qtoDoxuGXJQT4ulv8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 556000 Counter(556000) 555937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094742F422994-27hKd42Hf6pD1JwDukyqoX-5QjyPWD93cFm9kXiNqk5y7-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 556500 Counter(556500) 556437
Saved chunk: 20230922T094820F084022-1xeA9qtoDoxuGXJQT4ulv8-0PXdvfMyOWq5FdITjxxpgm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 557000 Counter(557000) 556937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T094902F697631-5QjyPWD93cFm9kXiNqk5y7-4BnTnISM18iCKLU2hwc1yY-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 557500 Counter(557500) 557437
Saved chunk: 20230922T094938F732341-0PXdvfMyOWq5FdITjxxpgm-7hSzcqaYJyJUiKc4QUPZkv-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
 Step 1115766 
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.74 / train/action_max 4.73 / train/action_mean 0.54 / train/action_min -3.86 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2.1e-7 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.6e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 2.1e-7 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
3e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 
/ train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.14 / train/image_loss_std 0.26 / train/model_loss_mean 1.1 / train/model_loss_std 2.03 / train/model_opt_grad_norm 4.78 / 
train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / train/policy_entropy_min
1.41 / train/policy_entropy_std 2.3e-4 / train/policy_logprob_mag 9.56 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.56 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / 
train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 1e-4 / train/post_ent_mag 65.91 / train/post_ent_max 65.91 / train/post_ent_mean 40.91 / train/post_ent_min 26.71 / train/post_ent_std 4.5 / train/prior_ent_mag 67.74 / 
train/prior_ent_max 67.74 / train/prior_ent_mean 42.49 / train/prior_ent_min 32.28 / train/prior_ent_std 4.98 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.08 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / train/reward_max_data 0 / 
train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train_stats/mean_log_entropy 1.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / 
report/cont_loss_mean 1.8e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 2.46 / 
report/image_loss_mean 0.13 / report/image_loss_std 0.35 / report/model_loss_mean 1.07 / report/model_loss_std 1.7 / report/post_ent_mag 65.19 / report/post_ent_max 65.19 / report/post_ent_mean 40.67 / report/post_ent_min 28.66 / report/post_ent_std 4.26 / 
report/prior_ent_mag 67.84 / report/prior_ent_max 67.84 / report/prior_ent_mean 42.17 / report/prior_ent_min 32.52 / report/prior_ent_std 4.81 / report/rep_loss_mean 1.57 / report/rep_loss_std 2.46 / report/reward_avg 0 / report/reward_loss_mean 0 / report/reward_loss_std
0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-12 / 
eval/cont_loss_std 5.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.25 / 
eval/model_loss_mean 1.06 / eval/model_loss_std 1.72 / eval/post_ent_mag 64.9 / eval/post_ent_max 64.9 / eval/post_ent_mean 39.24 / eval/post_ent_min 24.9 / eval/post_ent_std 4.41 / eval/prior_ent_mag 67.84 / eval/prior_ent_max 67.84 / eval/prior_ent_mean 40.85 / 
eval/prior_ent_min 32.48 / eval/prior_ent_std 4.81 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 2.6 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 /
eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.6e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.3e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / 
replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / 
timer/env.step_count 3834 / timer/env.step_total 18.98 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 402.62 / timer/replay._sample_frac 1.34 / 
timer/replay._sample_avg 0.01 / timer/replay._sample_min 1e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7341 / timer/agent.policy_total 15.97 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.6e-3 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1917 / timer/agent.train_total 246.85 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12
/ timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 558000 Counter(558000) 557937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T095022F840573-4BnTnISM18iCKLU2hwc1yY-0ioDLFQGydTZPno2DldQE2-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 558500 Counter(558500) 558437
Saved chunk: 20230922T095057F222446-7hSzcqaYJyJUiKc4QUPZkv-58bfdXLrt0JTfwCjSdUfj8-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 559000 Counter(559000) 558937
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T095144F101450-0ioDLFQGydTZPno2DldQE2-1W2qJfSGgsPllz8vvQxmfh-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 559500 Counter(559500) 559437
Saved chunk: 20230922T095217F213550-58bfdXLrt0JTfwCjSdUfj8-0fPndSAJpqDmT9uhZaUihE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 560000 Counter(560000) 559937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T095304F661936-1W2qJfSGgsPllz8vvQxmfh-300JKbwgkqP1xd6n26Ltvz-1024.npz
Starting evaluation at step 560500 Counter(560500) 560437
Saved chunk: 20230922T095336F031418-0fPndSAJpqDmT9uhZaUihE-0dwW8XfNDvcJpX0itwADRm-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 561000 Counter(561000) 560937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T095424F931060-300JKbwgkqP1xd6n26Ltvz-4PzWwBVkaZpexf5rm38CLs-1024.npz
Starting evaluation at step 561500 Counter(561500) 561437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230922T095454F732260-0dwW8XfNDvcJpX0itwADRm-7JCo0UroBQKay1Ro9hwHIL-1024.npz
train_Episode has 500 steps and return 0.0.
 Step 1123340 
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.69 / train/action_max 4.69 / train/action_mean 0.54 / train/action_min -3.83 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 2e-7 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -4.17 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std
0 / train/cont_avg 1 / train/cont_loss_mean 1.4e-11 / train/cont_loss_std 1.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 1.8e-7 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss
2.6e-5 / train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 7e-44 / train/extr_return_normed_max 7e-44 / train/extr_return_normed_mean 7e-44 / 
train/extr_return_normed_min 7e-44 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 
0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 0.13 / train/image_loss_std 0.26 / train/model_loss_mean 1.1 / train/model_loss_std 2.02 / train/model_opt_grad_norm 4.99 / 
train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.41 / train/policy_entropy_std 2.2e-4 / train/policy_logprob_mag 9.37 / train/policy_logprob_max -0.92 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.37 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 1 / train/policy_randomness_std 9.6e-5 / train/post_ent_mag 65.82 / train/post_ent_max 65.82 / train/post_ent_mean 40.89 / train/post_ent_min 26.68 / train/post_ent_std 4.52 / 
train/prior_ent_mag 67.68 / train/prior_ent_max 67.68 / train/prior_ent_mean 42.47 / train/prior_ent_min 32.46 / train/prior_ent_std 4.99 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.06 / train/reward_avg 0 / train/reward_loss_mean 0 / train/reward_loss_std 0 / 
train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 0 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.42 / 
report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / 
report/dyn_loss_std 2.66 / report/image_loss_mean 0.13 / report/image_loss_std 0.3 / report/model_loss_mean 1.07 / report/model_loss_std 1.77 / report/post_ent_mag 65.61 / report/post_ent_max 65.61 / report/post_ent_mean 40.67 / report/post_ent_min 27.53 / 
report/post_ent_std 4.68 / report/prior_ent_mag 67.75 / report/prior_ent_max 67.75 / report/prior_ent_mean 42.2 / report/prior_ent_min 32.58 / report/prior_ent_std 5.15 / report/rep_loss_mean 1.56 / report/rep_loss_std 2.66 / report/reward_avg 0 / 
report/reward_loss_mean 0 / report/reward_loss_std 0 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 0 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / 
eval/cont_avg 1 / eval/cont_loss_mean 4.2e-12 / eval/cont_loss_std 2.5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-12 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.08 / 
eval/image_loss_mean 0.12 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.06 / eval/model_loss_std 1.95 / eval/post_ent_mag 65.86 / eval/post_ent_max 65.86 / eval/post_ent_mean 38.9 / eval/post_ent_min 23.5 / eval/post_ent_std 4.31 / eval/prior_ent_mag 67.75 / 
eval/prior_ent_max 67.75 / eval/prior_ent_mean 40.44 / eval/prior_ent_min 32.46 / eval/prior_ent_std 4.59 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.08 / eval/reward_avg 0 / eval/reward_loss_mean 0 / eval/reward_loss_std 0 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 0 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 5.6e5 / replay/inserts 3787 / replay/samples 3e4 / replay/insert_wait_avg 3.3e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.4e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3787 / timer/env.step_total 18.69 / timer/env.step_frac 0.06 / timer/env.step_avg 4.9e-3 / timer/env.step_min 4e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3e4 / 
timer/replay._sample_total 396.61 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.22 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / 
timer/agent.policy_count 7795 / timer/agent.policy_total 16.91 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 1893 / timer/dataset_train_total 0.15 / 
timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1893 / timer/agent.train_total 243.77 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / 
timer/agent.train_min 0.13 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 /
timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.25
