Encoder CNN shapes: {'image': (64, 64, 3)}
Encoder MLP shapes: {}
Decoder CNN shapes: {'image': (64, 64, 3)}
Decoder MLP shapes: {}
JAX devices (1): [gpu(id=0)]
Policy devices: gpu:0
Train devices:  gpu:0
Tracing train function.
Optimizer model_opt has 15,685,251 variables.
{'action': Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>, 'deter': Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>, 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>, 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>}
{'action': Traced<ShapedArray(float32[15,1024,1])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,1])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,1]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7d805a220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8045e50; dead>, <weakref at 0x7fd7d80459a0; dead>, <weakref at 0x7fd7d8045ae0; dead>, <weakref at 0x7fd7d80457c0; dead>, <weakref at 0x7fd7d8045db0; to 'JaxprTracer' at 0x7fd58a3c3180>, <weakref at 0x7fd7d8045720; to 'JaxprTracer' at 0x7fd7d8045900>, <weakref at 0x7fd7d80459f0; to 'JaxprTracer' at 0x7fd7d80454a0>, <weakref at 0x7fd7d80452c0; to 'JaxprTracer' at 0x7fd7d8045950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd58a41b170>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7d805a220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8045e50; dead>, <weakref at 0x7fd7d80459a0; dead>, <weakref at 0x7fd7d8045ae0; dead>, <weakref at 0x7fd7d80457c0; dead>, <weakref at 0x7fd7d8045db0; to 'JaxprTracer' at 0x7fd58a3c3180>, <weakref at 0x7fd7d8045720; to 'JaxprTracer' at 0x7fd7d8045900>, <weakref at 0x7fd7d80459f0; to 'JaxprTracer' at 0x7fd7d80454a0>, <weakref at 0x7fd7d80452c0; to 'JaxprTracer' at 0x7fd7d8045950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd58a41b170>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7d805a220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8045e50; dead>, <weakref at 0x7fd7d80459a0; dead>, <weakref at 0x7fd7d8045ae0; dead>, <weakref at 0x7fd7d80457c0; dead>, <weakref at 0x7fd7d8045db0; to 'JaxprTracer' at 0x7fd58a3c3180>, <weakref at 0x7fd7d8045720; to 'JaxprTracer' at 0x7fd7d8045900>, <weakref at 0x7fd7d80459f0; to 'JaxprTracer' at 0x7fd7d80454a0>, <weakref at 0x7fd7d80452c0; to 'JaxprTracer' at 0x7fd7d8045950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd58a41b170>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7d805a220>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8045e50; dead>, <weakref at 0x7fd7d80459a0; dead>, <weakref at 0x7fd7d8045ae0; dead>, <weakref at 0x7fd7d80457c0; dead>, <weakref at 0x7fd7d8045db0; to 'JaxprTracer' at 0x7fd58a3c3180>, <weakref at 0x7fd7d8045720; to 'JaxprTracer' at 0x7fd7d8045900>, <weakref at 0x7fd7d80459f0; to 'JaxprTracer' at 0x7fd7d80454a0>, <weakref at 0x7fd7d80452c0; to 'JaxprTracer' at 0x7fd7d8045950>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd58a41b170>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Optimizer actor_opt has 1,051,650 variables.
Optimizer critic_opt has 1,181,439 variables.
Logdir /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp
Observation space:
  reward           Space(dtype=float32, shape=(), low=-inf, high=inf)
  is_first         Space(dtype=bool, shape=(), low=False, high=True)
  is_last          Space(dtype=bool, shape=(), low=False, high=True)
  is_terminal      Space(dtype=bool, shape=(), low=False, high=True)
  position         Space(dtype=float64, shape=(3,), low=-inf, high=inf)
  velocity         Space(dtype=float64, shape=(2,), low=-inf, high=inf)
  image            Space(dtype=uint8, shape=(64, 64, 3), low=0, high=255)
Action space:
  reset            Space(dtype=bool, shape=(), low=False, high=True)
  action           Space(dtype=float32, shape=(1,), low=-1.0, high=1.0)
Prefill train dataset.
train_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Prefill eval dataset.
Saved chunk: 20230921T213832F312509-3eDn15EyxHE7oqDQr8P5qc-5K7Q8CJH464kX6RC6gKozm-1024.npz
eval_Episode has 500 steps and return 0.0.
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213836F542366-1o7PLXXRPx1KJN7wrTpd5R-44f6I56uHMjQ7m0di0jsbN-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2200 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 0 / episode/reward_rate 0 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0
warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'

warning: Linking two modules of different target triples: 'LLVMDialectModule' is 'nvptx64-nvidia-gpulibs' whereas '' is 'nvptx64-nvidia-cuda'


Creating new TensorBoard event file writer.
Did not find any checkpoint.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Start training loop.
Starting evaluation at step 1100 Counter(1100) 1037
Saved chunk: 20230921T213840F173860-44f6I56uHMjQ7m0di0jsbN-0000000000000000000000-76.npz
Saved chunk: 20230921T213835F946425-5K7Q8CJH464kX6RC6gKozm-0000000000000000000000-76.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Tracing policy function.
Tracing policy function.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 0.0.
Tracing policy function.
Tracing train function.
{'action': Traced<ShapedArray(float32[15,1024,1])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[15,1024,1])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[15,1024,1])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[15,1024,1]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7fc446cc0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8add900; dead>, <weakref at 0x7fd7d8add810; dead>, <weakref at 0x7fd7d8add310; dead>, <weakref at 0x7fd7d8addb80; dead>, <weakref at 0x7fd7d8add950; to 'JaxprTracer' at 0x7fd7d8add860>, <weakref at 0x7fd7d8abb130; to 'JaxprTracer' at 0x7fd7d8addea0>, <weakref at 0x7fd7d8abb720; to 'JaxprTracer' at 0x7fd7d8add360>, <weakref at 0x7fd7d8abb090; to 'JaxprTracer' at 0x7fd7d8add090>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd5895296f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'deter': Traced<ShapedArray(float16[15,1024,512])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,512])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,512])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,512]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7fc446cc0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8add900; dead>, <weakref at 0x7fd7d8add810; dead>, <weakref at 0x7fd7d8add310; dead>, <weakref at 0x7fd7d8addb80; dead>, <weakref at 0x7fd7d8add950; to 'JaxprTracer' at 0x7fd7d8add860>, <weakref at 0x7fd7d8abb130; to 'JaxprTracer' at 0x7fd7d8addea0>, <weakref at 0x7fd7d8abb720; to 'JaxprTracer' at 0x7fd7d8add360>, <weakref at 0x7fd7d8abb090; to 'JaxprTracer' at 0x7fd7d8add090>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd5895296f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'logit': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7fc446cc0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8add900; dead>, <weakref at 0x7fd7d8add810; dead>, <weakref at 0x7fd7d8add310; dead>, <weakref at 0x7fd7d8addb80; dead>, <weakref at 0x7fd7d8add950; to 'JaxprTracer' at 0x7fd7d8add860>, <weakref at 0x7fd7d8abb130; to 'JaxprTracer' at 0x7fd7d8addea0>, <weakref at 0x7fd7d8abb720; to 'JaxprTracer' at 0x7fd7d8add360>, <weakref at 0x7fd7d8abb090; to 'JaxprTracer' at 0x7fd7d8add090>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd5895296f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan'))))), 'stoch': Traced<ShapedArray(float16[15,1024,32,32])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float16[15,1024,32,32])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float16[15,1024,32,32])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float16[15,1024,32,32]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7fd7fc446cc0>, in_tracers=(Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1025,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[512,1024]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1536,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[512,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1536]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,512]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float16[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[15,1024,32,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7fd7d8add900; dead>, <weakref at 0x7fd7d8add810; dead>, <weakref at 0x7fd7d8add310; dead>, <weakref at 0x7fd7d8addb80; dead>, <weakref at 0x7fd7d8add950; to 'JaxprTracer' at 0x7fd7d8add860>, <weakref at 0x7fd7d8abb130; to 'JaxprTracer' at 0x7fd7d8addea0>, <weakref at 0x7fd7d8abb720; to 'JaxprTracer' at 0x7fd7d8add360>, <weakref at 0x7fd7d8abb090; to 'JaxprTracer' at 0x7fd7d8add090>], out_avals=[ShapedArray(float32[1024,1]), ShapedArray(float16[1024,512]), ShapedArray(float16[1024,32,32]), ShapedArray(float16[1024,32,32]), ShapedArray(float32[15,1024,1]), ShapedArray(float16[15,1024,512]), ShapedArray(float16[15,1024,32,32]), ShapedArray(float16[15,1024,32,32])], primitive=scan, params={'reverse': False, 'length': 15, 'unroll': 1, 'jaxpr': { lambda ; a:f32[1,512] b:f16[512,512] c:f32[1,512] d:f16[512,1] e:f16[512,1] f:f16[1025,512]
    g:f32[1,512] h:f16[1024,1536] i:f32[1,1536] j:f16[512,512] k:f32[1,512] l:f16[512,1024]
    m:f32[1024,32,1] n:f32[1536,512] o:f32[512] p:f32[512] q:f32[512,512] r:f32[512]
    s:f32[512] t:f32[512,1] u:f32[1] v:f32[512,1] w:f32[1] x:f32[1024,1] y:f16[1024,512]
    z:f16[1024,32,32] ba:f16[1024,32,32] bb:f32[1,1024,1] bc:f16[1024,1536] bd:f32[1024,1]
    be:f32[1024,512] bf:f32[1024,512] bg:f32[1024,1] bh:f32[1024,1] bi:f32[1024,512]
    bj:f16[1024,512] bk:f16[1024,512] bl:f16[1024,512] bm:f16[1024,512] bn:f32[1024,1]
    bo:f32[1024,512] bp:f32[1024,512] bq:f32[1024,1] br:f32[1024,1] bs:f32[1024,512]
    bt:f16[1024,512] bu:f16[1024,512] bv:f16[1024,512] bw:f16[1024,512] bx:f32[1024,1]
    by:f32[1024,1] bz:f32[1024,1] ca:f16[1024,1] cb:f32[1024,1] cc:f32[1024,512]
    cd:f32[1024,512] ce:f32[1024,1] cf:f32[1024,1] cg:f16[1024,512] ch:f16[1024,512]
    ci:f16[1024,512] cj:f32[1024,1] ck:f32[1024,1536] cl:f32[1024,1536] cm:f32[1024,1]
    cn:f32[1024,1] co:f16[1024,512] cp:f16[1024,512] cq:f16[1024,512] cr:f16[1024,512]
    cs:f16[1024,512] ct:f16[1024,512] cu:f16[1024,512] cv:f16[1024,512] cw:f16[1024,512]
    cx:f32[1024,1] cy:f32[1024,512] cz:f32[1024,512] da:f32[1024,1] db:f32[1024,1]
    dc:f16[1024,512] dd:f16[1024,512] de:f16[1024,512] df:f16[1024,32,32] dg:f16[1024,32,1]
    dh:f16[1024,32,1] di:f16[1024,32,32] dj:f32[1024,32,32] dk:f32[1024,32] dl:bool[1024,32,1]
    dm:f32[1024,32,32] dn:f32[1024,32,1] do:f32[1024,32,1]. let
    dp:f16[1536,512] = convert_element_type[new_dtype=float16 weak_type=False] n
    dq:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bc dp
    dr:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] dq
    ds:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] dr bd be bf bg bh
    en:f32[1024,512] = mul ds a
    eo:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] o
    ep:f32[1024,512] = mul bi eo
    eq:f32[1024,512] = add_any en ep
    er:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] p
    es:f32[1024,512] = add eq er
    et:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] es
    eu:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] et bj bk bl
    fg:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] eu b
    fh:f16[512,512] = convert_element_type[new_dtype=float16 weak_type=False] q
    fi:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bm fh
    fj:f16[1024,512] = add_any fg fi
    fk:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] fj
    fl:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] fk bn bo bp bq br
    fm:f32[1024,512] = mul fl c
    fn:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] r
    fo:f32[1024,512] = mul bs fn
    fp:f32[1024,512] = add_any fm fo
    fq:f32[1,512] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 512)] s
    fr:f32[1024,512] = add fp fq
    fs:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] fr
    ft:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] fs bt bu bv
    fu:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft d
    fv:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] v
    fw:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw fv
    fx:f16[1024,1] = add_any fu fw
    fy:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] w
    fz:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] fy
    ga:f16[1024,1] = add fx fz
    gb:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] ga
    gc:f32[1024,1] = pjit[
      jaxpr={ lambda ; gd:f32[1024,1] ge:f32[1024,1]. let
          gf:f32[1024,1] = mul gd ge
        in (gf,) }
      name=sigmoid
    ] gb bx
    gg:f32[1024,1] = mul 0.8999999761581421 gc
    gh:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gg
    gi:f32[1,1024,1] = mul bb gh
    gj:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ft e
    gk:f16[512,1] = convert_element_type[new_dtype=float16 weak_type=False] t
    gl:f16[1024,1] = dot_general[dimension_numbers=(([1], [0]), ([], []))] bw gk
    gm:f16[1024,1] = add_any gj gl
    gn:f16[1] = convert_element_type[new_dtype=float16 weak_type=False] u
    go:f16[1,1] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(1, 1)] gn
    gp:f16[1024,1] = add gm go
    gq:f32[1024,1] = convert_element_type[new_dtype=float32 weak_type=False] gp
    gr:f32[1024,1] = mul gq by
    gs:f32[1024,1] = add gq gr
    gt:f32[1024,1] = mul gs bz
    gu:f32[1,1024,1] = broadcast_in_dim[
      broadcast_dimensions=(1, 2)
      shape=(1, 1024, 1)
    ] gt
    gv:f32[1,1024,1] = add gi gu
    gw:f32[1024,1] = reshape[dimensions=None new_sizes=(1024, 1)] gv
    gx:f16[1024,1024] = reshape[dimensions=None new_sizes=(1024, 1024)] ba
    gy:f16[1024,1] = convert_element_type[new_dtype=float16 weak_type=False] x
    gz:f16[1024,1] = mul gy ca
    ha:f16[1024,1025] = concatenate[dimension=1] gx gz
    hb:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] ha f
    hc:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] hb
    hd:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] hc cb cc cd ce cf
    he:f32[1024,512] = mul hd g
    hf:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] he
    hg:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] hf cg ch ci
    hh:f16[1024,1024] = concatenate[dimension=1] y hg
    hi:f16[1024,1536] = dot_general[dimension_numbers=(([1], [0]), ([], []))] hh
      h
    hj:f32[1024,1536] = convert_element_type[new_dtype=float32 weak_type=False] hi
    hk:f32[1024,1536] = pjit[
      jaxpr={ lambda ; hl:f32[1024,1536] hm:f32[1024,1] hn:f32[1024,1536] ho:f32[1024,1536]
          hp:f32[1024,1] hq:f32[1024,1]. let
          hr:f32[1024] = reduce_sum[axes=(1,)] hl
          hs:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hr
          ht:f32[1024,1] = div hs 1536.0
          hu:f32[1024,1536] = sub hl ht
          hv:f32[1024,1536] = mul hu hm
          hw:f32[1024,1536] = mul hl ho
          hx:f32[1024] = reduce_sum[axes=(1,)] hw
          hy:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] hx
          hz:f32[1024,1] = div hy 1536.0
          ia:f32[1024,1] = mul ht hp
          ib:f32[1024,1] = sub hz ia
          ic:f32[1024,1] = mul ib hq
          id:f32[1024,1536] = mul hn ic
          ie:f32[1024,1536] = add_any hv id
        in (ie,) }
      name=standardize
    ] hj cj ck cl cm cn
    if:f32[1024,1536] = mul hk i
    ig:f16[1024,1536] = convert_element_type[new_dtype=float16 weak_type=False] if
    ih:f16[1024,512] = slice[
      limit_indices=(1024, 1536)
      start_indices=(0, 1024)
      strides=None
    ] ig
    ii:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ih co
    ij:f16[1024,512] = mul ii cp
    ik:f16[1024,512] = slice[
      limit_indices=(1024, 512)
      start_indices=(0, 0)
      strides=None
    ] ig
    il:f16[1024,512] = pjit[
      jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
          fd:f16[1024,512] = mul fb fc
        in (fd,) }
      name=sigmoid
    ] ik cr
    im:f16[1024,512] = mul il cs
    in:f16[1024,512] = slice[
      limit_indices=(1024, 1024)
      start_indices=(0, 512)
      strides=None
    ] ig
    io:f16[1024,512] = mul ct in
    ip:f16[1024,512] = add_any im io
    iq:f16[1024,512] = mul ip cp
    ir:f16[1024,512] = add ip iq
    is:f16[1024,512] = mul ir cu
    it:f16[1024,512] = mul cq is
    iu:f16[1024,512] = add_any ij it
    iv:f16[1024,512] = neg ii
    iw:f16[1024,512] = mul iv cv
    ix:f16[1024,512] = mul cw y
    iy:f16[1024,512] = add_any iw ix
    iz:f16[1024,512] = add iu iy
    ja:f16[1024,512] = dot_general[dimension_numbers=(([1], [0]), ([], []))] iz j
    jb:f32[1024,512] = convert_element_type[new_dtype=float32 weak_type=False] ja
    jc:f32[1024,512] = pjit[
      jaxpr={ lambda ; dt:f32[1024,512] du:f32[1024,1] dv:f32[1024,512] dw:f32[1024,512]
          dx:f32[1024,1] dy:f32[1024,1]. let
          dz:f32[1024] = reduce_sum[axes=(1,)] dt
          ea:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] dz
          eb:f32[1024,1] = div ea 512.0
          ec:f32[1024,512] = sub dt eb
          ed:f32[1024,512] = mul ec du
          ee:f32[1024,512] = mul dt dw
          ef:f32[1024] = reduce_sum[axes=(1,)] ee
          eg:f32[1024,1] = broadcast_in_dim[
            broadcast_dimensions=(0,)
            shape=(1024, 1)
          ] ef
          eh:f32[1024,1] = div eg 512.0
          ei:f32[1024,1] = mul eb dx
          ej:f32[1024,1] = sub eh ei
          ek:f32[1024,1] = mul ej dy
          el:f32[1024,512] = mul dv ek
          em:f32[1024,512] = add_any ed el
        in (em,) }
      name=standardize
    ] jb cx cy cz da db
    jd:f32[1024,512] = mul jc k
    je:f16[1024,512] = convert_element_type[new_dtype=float16 weak_type=False] jd
    jf:f16[1024,512] = pjit[
      jaxpr={ lambda ; ev:f16[1024,512] ew:f16[1024,512] ex:f16[1024,512] ey:f16[1024,512]. let
          ez:f16[1024,512] = mul ev ew
          fa:f16[1024,512] = pjit[
            jaxpr={ lambda ; fb:f16[1024,512] fc:f16[1024,512]. let
                fd:f16[1024,512] = mul fb fc
              in (fd,) }
            name=sigmoid
          ] ev ey
          fe:f16[1024,512] = mul ex fa
          ff:f16[1024,512] = add_any ez fe
        in (ff,) }
      name=silu
    ] je dc dd de
    jg:f16[1024,1024] = dot_general[dimension_numbers=(([1], [0]), ([], []))] jf
      l
    jh:f16[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] jg
    ji:f16[1024,32,32] = mul jh df
    jj:f16[1024,32,32] = div ji dg
    jk:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] ji
    jl:f32[1024,32] = reduce_sum[axes=(2,)] jk
    jm:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jl
    jn:f16[1024,32,1] = convert_element_type[new_dtype=float16 weak_type=False] jm
    jo:f16[1024,32,1] = neg jn
    jp:f16[1024,32,32] = mul jo df
    jq:f16[1024,32,32] = mul jp dh
    jr:f16[1024,32,32] = add_any jj jq
    js:f16[1024,32,32] = mul 0.990234375 jr
    jt:f16[1024,32,32] = div js di
    ju:f32[1024,32,32] = convert_element_type[new_dtype=float32 weak_type=False] jt
    jv:f32[1024,32,32] = mul ju dj
    jw:f32[1024,32] = reduce_sum[axes=(2,)] jv
    jx:f32[1024,32] = div jw dk
    jy:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] jx
    jz:f32[1024,32,1] = pjit[
      jaxpr={ lambda ; ka:f32[1024,32,1] kb:bool[1024,32,1] kc:f32[1024,32,1]. let
          kd:f32[1024,32,1] = select_n kb ka kc
        in (kd,) }
      name=_where
    ] jy dl m
    ke:f32[1024,32,32] = sub ju jz
    kf:f32[1024,32,32] = mul ke dm
    kg:f32[1024,32,32] = div kf dn
    kh:f32[1024,32] = reduce_sum[axes=(2,)] kf
    ki:f32[1024,32,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(1024, 32, 1)
    ] kh
    kj:f32[1024,32,1] = neg ki
    kk:f32[1024,32,32] = mul kj dm
    kl:f32[1024,32,32] = mul kk do
    km:f32[1024,32,32] = add_any kg kl
    kn:f32[1,1024,32,32] = broadcast_in_dim[
      broadcast_dimensions=(1, 2, 3)
      shape=(1, 1024, 32, 32)
    ] km
    ko:f32[1024,32,32] = reshape[dimensions=None new_sizes=(1024, 32, 32)] kn
    kp:f16[1024,32,32] = convert_element_type[new_dtype=float16 weak_type=False] ko
  in (gw, iz, jt, kp, gw, iz, jt, kp) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 23, 'num_carry': 4}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fd5895296f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='wm'), Scope(name='scan')))))}
Tracing report function.
Tracing report function.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 2202 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.58 / train/action_max 4.58 / train/action_mean -0.06 / train/action_min -3.76 / train/action_std 1.04 / train/actor_opt_actor_opt_grad_overflow 0 / 
train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 4.2e-4 / train/actor_opt_grad_steps 1 / train/actor_opt_loss -3.19 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 0 / train/cont_avg 1 / train/cont_loss_mean 
0.27 / train/cont_loss_std 0.17 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 0.98 / train/cont_pos_loss 0.27 / train/cont_pred 0.78 / train/cont_rate 1 / train/dyn_loss_mean 6.87 / train/dyn_loss_std 0.28 / 
train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 12.78 / train/extr_critic_critic_opt_grad_steps 1 / train/extr_critic_critic_opt_loss 9e4 / train/extr_critic_mag 0 / 
train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 0 / train/extr_return_normed_max -inf / train/extr_return_normed_mean 0 / train/extr_return_normed_min 0 / train/extr_return_normed_std
0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / 
train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 2892.82 / train/image_loss_std 33.24 / train/model_loss_mean 2902.75 / train/model_loss_std 33.24 / train/model_opt_grad_norm nan / train/model_opt_grad_steps 0 / train/model_opt_loss 2.9e7 / 
train/model_opt_model_opt_grad_overflow 1 / train/model_opt_model_opt_grad_scale 5000 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / train/policy_entropy_mean 1.3 / train/policy_entropy_min 0.55 / train/policy_entropy_std 0.08 / train/policy_logprob_mag
11.57 / train/policy_logprob_max -0.22 / train/policy_logprob_mean -1.3 / train/policy_logprob_min -11.57 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.95 / train/policy_randomness_min 0.62
/ train/policy_randomness_std 0.04 / train/post_ent_mag 107.65 / train/post_ent_max 107.65 / train/post_ent_mean 107.41 / train/post_ent_min 107.11 / train/post_ent_std 0.09 / train/prior_ent_mag 107.89 / train/prior_ent_max 107.89 / train/prior_ent_mean 107.38 / 
train/prior_ent_min 106.55 / train/prior_ent_std 0.22 / train/rep_loss_mean 6.87 / train/rep_loss_std 0.28 / train/reward_avg 0 / train/reward_loss_mean 5.54 / train/reward_loss_std 9.5e-7 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / 
train/reward_neg_loss 5.54 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / train/params_agent/wm/model_opt 1.6e7 / train/params_agent/task_behavior/critic/critic_opt 1.2e6 / train/params_agent/task_behavior/ac/actor_opt
1.1e6 / report/cont_avg 1 / report/cont_loss_mean 0.28 / report/cont_loss_std 0.17 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 0.97 / report/cont_pos_loss 0.28 / report/cont_pred 0.77 / report/cont_rate 1 / report/dyn_loss_mean 6.88 / 
report/dyn_loss_std 0.31 / report/image_loss_mean 2893.87 / report/image_loss_std 33.27 / report/model_loss_mean 2903.82 / report/model_loss_std 33.26 / report/post_ent_mag 107.65 / report/post_ent_max 107.65 / report/post_ent_mean 107.41 / report/post_ent_min 107.14 / 
report/post_ent_std 0.09 / report/prior_ent_mag 108 / report/prior_ent_max 108 / report/prior_ent_mean 107.38 / report/prior_ent_min 106.56 / report/prior_ent_std 0.22 / report/rep_loss_mean 6.88 / report/rep_loss_std 0.31 / report/reward_avg 0 / report/reward_loss_mean 
5.54 / report/reward_loss_std 9.5e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 5.54 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / 
eval/cont_loss_mean 0.28 / eval/cont_loss_std 0.17 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 0.97 / eval/cont_pos_loss 0.28 / eval/cont_pred 0.77 / eval/cont_rate 1 / eval/dyn_loss_mean 6.86 / eval/dyn_loss_std 0.28 / eval/image_loss_mean 
2893.72 / eval/image_loss_std 33.41 / eval/model_loss_mean 2903.65 / eval/model_loss_std 33.41 / eval/post_ent_mag 107.61 / eval/post_ent_max 107.61 / eval/post_ent_mean 107.4 / eval/post_ent_min 107.17 / eval/post_ent_std 0.08 / eval/prior_ent_mag 108.1 / 
eval/prior_ent_max 108.1 / eval/prior_ent_mean 107.42 / eval/prior_ent_min 106.55 / eval/prior_ent_std 0.21 / eval/rep_loss_mean 6.86 / eval/rep_loss_std 0.28 / eval/reward_avg 0 / eval/reward_loss_mean 5.54 / eval/reward_loss_std 9.5e-7 / eval/reward_max_data 0 / 
eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.54 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1038 / replay/inserts 1038 / replay/samples 112 / replay/insert_wait_avg 2.4e-6 / 
replay/insert_wait_frac 1 / replay/sample_wait_avg 1.2e-6 / replay/sample_wait_frac 1 / eval_replay/size 1538 / eval_replay/inserts 1538 / eval_replay/samples 112 / eval_replay/insert_wait_avg 2.5e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 146.75 / timer/env.step_count 1101 / timer/env.step_total 4.5 / timer/env.step_frac 0.03 / timer/env.step_avg 4.1e-3 / timer/env.step_min 3.1e-3 / timer/env.step_max 0.83 / timer/replay._sample_count 112 / 
timer/replay._sample_total 24.06 / timer/replay._sample_frac 0.16 / timer/replay._sample_avg 0.21 / timer/replay._sample_min 4.8e-4 / timer/replay._sample_max 1.43 / timer/agent.save_count 1 / timer/agent.save_total 0.2 / timer/agent.save_frac 1.4e-3 / 
timer/agent.save_avg 0.2 / timer/agent.save_min 0.2 / timer/agent.save_max 0.2 / timer/agent.policy_count 502 / timer/agent.policy_total 48.74 / timer/agent.policy_frac 0.33 / timer/agent.policy_avg 0.1 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 46.45 / 
timer/dataset_train_count 1 / timer/dataset_train_total 3.4e-5 / timer/dataset_train_frac 2.3e-7 / timer/dataset_train_avg 3.4e-5 / timer/dataset_train_min 3.4e-5 / timer/dataset_train_max 3.4e-5 / timer/agent.train_count 1 / timer/agent.train_total 76.48 / 
timer/agent.train_frac 0.52 / timer/agent.train_avg 76.48 / timer/agent.train_min 76.48 / timer/agent.train_max 76.48 / timer/agent.report_count 2 / timer/agent.report_total 9.39 / timer/agent.report_frac 0.06 / timer/agent.report_avg 4.69 / timer/agent.report_min 0.07 / 
timer/agent.report_max 9.32 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 2.5e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 1500 Counter(1500) 1437
Saved chunk: 20230921T213840F173860-44f6I56uHMjQ7m0di0jsbN-6uUPyobBfOzoJRnjsXPcxo-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 2000 Counter(2000) 1937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T213835F946425-5K7Q8CJH464kX6RC6gKozm-69pafr9bLGPD00LcBcvTDB-1024.npz
Starting evaluation at step 2500 Counter(2500) 2437
Saved chunk: 20230921T214129F073356-6uUPyobBfOzoJRnjsXPcxo-2IpFQEORFV72dtOBmXiy7M-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 3000 Counter(3000) 2937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214211F214896-69pafr9bLGPD00LcBcvTDB-3lK3CzR9ibsAYQJaBpXs7U-1024.npz
Starting evaluation at step 3500 Counter(3500) 3437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214246F006559-2IpFQEORFV72dtOBmXiy7M-7pBRV0Q9IsGPHUPjRvi3pK-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 4000 Counter(4000) 3937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214329F688234-3lK3CzR9ibsAYQJaBpXs7U-5KCecP7ZcqXlFHRCta53Jr-1024.npz
Starting evaluation at step 4500 Counter(4500) 4437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 9818 ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.75 / train/action_max 3.35 / train/action_mean -0.74 / train/action_min -4.75 / train/action_std 1.02 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 3.7e-5 / train/actor_opt_grad_steps 955 / train/actor_opt_loss -4.16 / train/adv_mag 2.3e-7 / train/adv_max 1.9e-7 / train/adv_mean -6.4e-9 / train/adv_min 
-2.2e-7 / train/adv_std 5.2e-8 / train/cont_avg 1 / train/cont_loss_mean 1.5e-3 / train/cont_loss_std 9.6e-4 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.5e-3 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.52 / train/dyn_loss_std 1.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 6.43 / train/extr_critic_critic_opt_grad_steps 955 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 1.9e-7 / train/extr_critic_max -inf / train/extr_critic_mean 3.9e-9 / train/extr_critic_min -3.5e-8 / train/extr_critic_std 3.9e-8 / train/extr_return_normed_mag 2.2e-7 / train/extr_return_normed_max 2e-7 / 
train/extr_return_normed_mean 3e-8 / train/extr_return_normed_min -1.8e-8 / train/extr_return_normed_std 3.3e-8 / train/extr_return_rate 0 / train/extr_return_raw_mag 2e-7 / train/extr_return_raw_max 1.7e-7 / train/extr_return_raw_mean -2.7e-9 / train/extr_return_raw_min 
-5e-8 / train/extr_return_raw_std 3.3e-8 / train/extr_reward_mag 6.9e-9 / train/extr_reward_max -inf / train/extr_reward_mean -1e-9 / train/extr_reward_min -6.9e-9 / train/extr_reward_std 1.9e-9 / train/image_loss_mean 38.82 / train/image_loss_std 9.68 / 
train/model_loss_mean 39.91 / train/model_loss_std 9.89 / train/model_opt_grad_norm 116.21 / train/model_opt_grad_steps 946 / train/model_opt_loss 862.43 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 28.78 / train/policy_entropy_mag 
1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.41 / train/policy_entropy_min 1.38 / train/policy_entropy_std 2.1e-3 / train/policy_logprob_mag 9.48 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.41 / train/policy_logprob_min -9.48 / 
train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 9.3e-4 / train/post_ent_mag 64.2 / train/post_ent_max 64.2 / train/post_ent_mean
56.08 / train/post_ent_min 48.93 / train/post_ent_std 2.37 / train/prior_ent_mag 68.15 / train/prior_ent_max 68.15 / train/prior_ent_mean 60.54 / train/prior_ent_min 55.65 / train/prior_ent_std 2.1 / train/rep_loss_mean 1.52 / train/rep_loss_std 1.14 / train/reward_avg 0 
/ train/reward_loss_mean 0.18 / train/reward_loss_std 4.7e-4 / train/reward_max_data 0 / train/reward_max_pred 7.5e-9 / train/reward_neg_acc 1 / train/reward_neg_loss 0.18 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred -2.3e-9 / 
train/reward_rate 0 / train_stats/mean_log_entropy 1.41 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-6 / report/cont_loss_std 1.8e-6 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 
3.3e-6 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.93 / report/dyn_loss_std 2.78 / report/image_loss_mean 6.59 / report/image_loss_std 6.13 / report/model_loss_mean 7.75 / report/model_loss_std 6.63 / report/post_ent_mag 44.42 / report/post_ent_max 
44.42 / report/post_ent_mean 28.68 / report/post_ent_min 17.58 / report/post_ent_std 4.66 / report/prior_ent_mag 51.21 / report/prior_ent_max 51.21 / report/prior_ent_mean 32.08 / report/prior_ent_min 22.16 / report/prior_ent_std 5.09 / report/rep_loss_mean 1.93 / 
report/rep_loss_std 2.78 / report/reward_avg 0 / report/reward_loss_mean 1.2e-3 / report/reward_loss_std 9.8e-6 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc nan / 
report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-6 / eval/cont_loss_std 1.6e-6 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-6 / eval/cont_pred 1 / 
eval/cont_rate 1 / eval/dyn_loss_mean 2.23 / eval/dyn_loss_std 3.02 / eval/image_loss_mean 7.71 / eval/image_loss_std 5.4 / eval/model_loss_mean 9.05 / eval/model_loss_std 5.93 / eval/post_ent_mag 41.92 / eval/post_ent_max 41.92 / eval/post_ent_mean 29.9 / 
eval/post_ent_min 17.8 / eval/post_ent_std 4.4 / eval/prior_ent_mag 51.21 / eval/prior_ent_max 51.21 / eval/prior_ent_mean 33.58 / eval/prior_ent_min 21.91 / eval/prior_ent_std 4.89 / eval/rep_loss_mean 2.23 / eval/rep_loss_std 3.02 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.2e-3 / eval/reward_loss_std 7.3e-6 / eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 
4846 / replay/inserts 3808 / replay/samples 3e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5045 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 290.83 / timer/env.step_count 3808 / timer/env.step_total 19.14 / timer/env.step_frac 0.07 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 
/ timer/env.step_max 0.06 / timer/replay._sample_count 3e4 / timer/replay._sample_total 367.59 / timer/replay._sample_frac 1.26 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7315 / timer/agent.policy_total 15.74 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1904 / timer/dataset_train_total 0.13 / timer/dataset_train_frac 4.6e-4 / timer/dataset_train_avg 7e-5 / timer/dataset_train_min 6.2e-5 / timer/dataset_train_max 2.8e-4 / timer/agent.train_count 1904 / timer/agent.train_total 238.45 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.16 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 26.19

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 5000 Counter(5000) 4937
Saved chunk: 20230921T214402F946226-7pBRV0Q9IsGPHUPjRvi3pK-0lrzS45N41VEzvVugw9ijW-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214448F294774-5KCecP7ZcqXlFHRCta53Jr-6Uf8UjMzDNfMIqtSzZFFbr-1024.npz
Starting evaluation at step 5500 Counter(5500) 5437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 6000 Counter(6000) 5937
Saved chunk: 20230921T214555F744265-0lrzS45N41VEzvVugw9ijW-3BUErw7g4EKdLdigkd9KQH-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214607F533821-6Uf8UjMzDNfMIqtSzZFFbr-1vFKfbfly1x1VcEDwvwPwi-1024.npz
Starting evaluation at step 6500 Counter(6500) 6437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 7000 Counter(7000) 6937
Saved chunk: 20230921T214713F427580-3BUErw7g4EKdLdigkd9KQH-00vL6L4iFbWgzialEXKkEb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214726F733414-1vFKfbfly1x1VcEDwvwPwi-7Fgg6mffOi3KzQ9gTz32DM-1024.npz
Starting evaluation at step 7500 Counter(7500) 7437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 8000 Counter(8000) 7937
Saved chunk: 20230921T214830F904367-00vL6L4iFbWgzialEXKkEb-3GDWhajFRiw8ePG4sdSVIE-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T214845F754272-7Fgg6mffOi3KzQ9gTz32DM-2gsuSdZkpJylwmhAmz2kp2-1024.npz
Starting evaluation at step 8500 Counter(8500) 8437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 17550 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.71 / train/action_max 3.66 / train/action_mean -0.62 / train/action_min -4.7 / train/action_std 1.05 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.4e-5 / train/actor_opt_grad_steps 2870 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 1.3e-6 / train/cont_loss_std 7.4e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-6 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.89 / train/dyn_loss_std 
3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 2870 / train/extr_critic_critic_opt_loss 109.93 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 4.4e-16 / train/extr_return_normed_max 4.4e-16 / train/extr_return_normed_mean 4.4e-16 / 
train/extr_return_normed_min 4.4e-16 / train/extr_return_normed_std 2.7e-23 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / 
train/extr_reward_mag 0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 3.49 / train/image_loss_std 3.63 / train/model_loss_mean 4.63 / train/model_loss_std 4.48 / 
train/model_opt_grad_norm 16.54 / train/model_opt_grad_steps 2861 / train/model_opt_loss 468.95 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 109.09 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.4 / train/policy_entropy_std 1.8e-3 / train/policy_logprob_mag 9.32 / train/policy_logprob_max -0.91 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.32 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 7.6e-4 / train/post_ent_mag 37.68 / train/post_ent_max 37.68 / train/post_ent_mean 21.57 / train/post_ent_min 
14.65 / train/post_ent_std 3.56 / train/prior_ent_mag 46 / train/prior_ent_max 46 / train/prior_ent_mean 24.61 / train/prior_ent_min 17.64 / train/prior_ent_std 4.49 / train/rep_loss_mean 1.89 / train/rep_loss_std 3.11 / train/reward_avg 0 / train/reward_loss_mean 5.8e-4 
/ train/reward_loss_std 4.8e-6 / train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 5.8e-4 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 4.9e-7 / report/cont_loss_std 2.9e-7 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-7 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.85 / report/dyn_loss_std 3.19 / report/image_loss_mean 2.15 / report/image_loss_std 2.47 / report/model_loss_mean 3.27 / report/model_loss_std 3.45 / report/post_ent_mag 37.05 / report/post_ent_max 37.05 / report/post_ent_mean 18.39 / 
report/post_ent_min 13.78 / report/post_ent_std 2.91 / report/prior_ent_mag 42.78 / report/prior_ent_max 42.78 / report/prior_ent_mean 21.54 / report/prior_ent_min 16.53 / report/prior_ent_std 3.8 / report/rep_loss_mean 1.85 / report/rep_loss_std 3.19 / report/reward_avg 
0 / report/reward_loss_mean 2.6e-4 / report/reward_loss_std 2.6e-6 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 2.6e-4 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / 
report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 7.6e-7 / eval/cont_loss_std 4.3e-7 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.6e-7 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 4.1 / 
eval/dyn_loss_std 5.21 / eval/image_loss_mean 6.06 / eval/image_loss_std 3.56 / eval/model_loss_mean 8.51 / eval/model_loss_std 5.49 / eval/post_ent_mag 29.81 / eval/post_ent_max 29.81 / eval/post_ent_mean 20.72 / eval/post_ent_min 12.09 / eval/post_ent_std 3.45 / 
eval/prior_ent_mag 42.78 / eval/prior_ent_max 42.78 / eval/prior_ent_mean 23.94 / eval/prior_ent_min 14.71 / eval/prior_ent_std 4.55 / eval/rep_loss_mean 4.1 / eval/rep_loss_std 5.21 / eval/reward_avg 0 / eval/reward_loss_mean 2.6e-4 / eval/reward_loss_std 2.5e-6 / 
eval/reward_max_data 0 / eval/reward_max_pred 0 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-4 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 8712 / replay/inserts 3866 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9053 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3866 / timer/env.step_total 19.37 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 376.34 / timer/replay._sample_frac 1.25 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.08 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7874 / timer/agent.policy_total 16.81 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.4e-3 / timer/dataset_train_count 1933 / 
timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.3e-5 / timer/dataset_train_min 6.5e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1933 / timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.17 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.76

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 9000 Counter(9000) 8937
Saved chunk: 20230921T214948F196935-3GDWhajFRiw8ePG4sdSVIE-3uPm9aHn9sfCqlTTI5aqQr-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215004F492687-2gsuSdZkpJylwmhAmz2kp2-0Xj7nHf4fY7VwO28gFSYIA-1024.npz
Starting evaluation at step 9500 Counter(9500) 9437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 10000 Counter(10000) 9937
Saved chunk: 20230921T215106F025134-3uPm9aHn9sfCqlTTI5aqQr-73BJYfDInKQqko2STccOC0-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215123F993429-0Xj7nHf4fY7VwO28gFSYIA-6jJrXpaCIzPmh7buDE1YTU-1024.npz
Starting evaluation at step 10500 Counter(10500) 10437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 11000 Counter(11000) 10937
Saved chunk: 20230921T215223F571709-73BJYfDInKQqko2STccOC0-5wH4kSwBTupM6mgrx28DeO-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T215340F922728-5wH4kSwBTupM6mgrx28DeO-0000000000000000000000-357.npz
Saved chunk: 20230921T215242F981803-6jJrXpaCIzPmh7buDE1YTU-0000000000000000000000-860.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T215242F981803-6jJrXpaCIzPmh7buDE1YTU-7DLyZxtQlg9yvywAzwWvBl-1024.npz
Starting evaluation at step 11500 Counter(11500) 11437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 12000 Counter(12000) 11937
Saved chunk: 20230921T215340F922728-5wH4kSwBTupM6mgrx28DeO-0LSLEen7hyoj3iVHHUrbyy-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215402F206819-7DLyZxtQlg9yvywAzwWvBl-3Tjdz6YOl0y71EtAkrjXmx-1024.npz
Starting evaluation at step 12500 Counter(12500) 12437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 25274 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.58 / train/action_max 3.91 / train/action_mean -0.43 / train/action_min -4.55 / train/action_std 1.07 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 9.5e-6 / train/actor_opt_grad_steps 4800 / train/actor_opt_loss -4.16 / train/adv_mag 0 / train/adv_max 0 / train/adv_mean 0 / train/adv_min 0 / train/adv_std 
0 / train/cont_avg 1 / train/cont_loss_mean 2.3e-7 / train/cont_loss_std 1.8e-7 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.3e-7 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.88 / train/dyn_loss_std 
3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 4800 / train/extr_critic_critic_opt_loss 27.37 / 
train/extr_critic_mag 0 / train/extr_critic_max -inf / train/extr_critic_mean 0 / train/extr_critic_min 0 / train/extr_critic_std 0 / train/extr_return_normed_mag 1.7e-24 / train/extr_return_normed_max 1.7e-24 / train/extr_return_normed_mean 1.7e-24 / 
train/extr_return_normed_min 1.7e-24 / train/extr_return_normed_std 0 / train/extr_return_rate 0 / train/extr_return_raw_mag 0 / train/extr_return_raw_max 0 / train/extr_return_raw_mean 0 / train/extr_return_raw_min 0 / train/extr_return_raw_std 0 / train/extr_reward_mag 
0 / train/extr_reward_max -inf / train/extr_reward_mean 0 / train/extr_reward_min 0 / train/extr_reward_std 0 / train/image_loss_mean 1.6 / train/image_loss_std 2.06 / train/model_loss_mean 2.73 / train/model_loss_std 3.32 / train/model_opt_grad_norm 15.19 / 
train/model_opt_grad_steps 4791 / train/model_opt_loss 1119.23 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 419.37 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 1.42 / 
train/policy_entropy_min 1.39 / train/policy_entropy_std 2e-3 / train/policy_logprob_mag 9.36 / train/policy_logprob_max -0.9 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.36 / train/policy_logprob_std 0.71 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.99 / train/policy_randomness_std 8.8e-4 / train/post_ent_mag 34.11 / train/post_ent_max 34.11 / train/post_ent_mean 18.68 / train/post_ent_min 12.06 / train/post_ent_std 2.78 / 
train/prior_ent_mag 44.2 / train/prior_ent_max 44.2 / train/prior_ent_mean 21.43 / train/prior_ent_min 14.49 / train/prior_ent_std 4.08 / train/rep_loss_mean 1.88 / train/rep_loss_std 3.46 / train/reward_avg 0 / train/reward_loss_mean 1.5e-4 / train/reward_loss_std 1.5e-6
/ train/reward_max_data 0 / train/reward_max_pred 0 / train/reward_neg_acc 1 / train/reward_neg_loss 1.5e-4 / train/reward_pos_acc nan / train/reward_pos_loss nan / train/reward_pred 0 / train/reward_rate 0 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 
1.41 / report/cont_avg 1 / report/cont_loss_mean 8.5e-8 / report/cont_loss_std 6e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.5e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.88 / 
report/dyn_loss_std 3.23 / report/image_loss_mean 0.99 / report/image_loss_std 1.66 / report/model_loss_mean 2.12 / report/model_loss_std 2.95 / report/post_ent_mag 32.41 / report/post_ent_max 32.41 / report/post_ent_mean 19.48 / report/post_ent_min 12.7 / 
report/post_ent_std 2.79 / report/prior_ent_mag 44.56 / report/prior_ent_max 44.56 / report/prior_ent_mean 22.23 / report/prior_ent_min 14.81 / report/prior_ent_std 4.02 / report/rep_loss_mean 1.88 / report/rep_loss_std 3.23 / report/reward_avg 0 / report/reward_loss_mean
7.9e-5 / report/reward_loss_std 6.3e-7 / report/reward_max_data 0 / report/reward_max_pred 0 / report/reward_neg_acc 1 / report/reward_neg_loss 7.9e-5 / report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 0 / report/reward_rate 0 / eval/cont_avg 1 
/ eval/cont_loss_mean 1.4e-7 / eval/cont_loss_std 9.6e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-7 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.64 / eval/dyn_loss_std 3.62 / eval/image_loss_mean 2.29
/ eval/image_loss_std 1.87 / eval/model_loss_mean 3.87 / eval/model_loss_std 3.4 / eval/post_ent_mag 32.32 / eval/post_ent_max 32.32 / eval/post_ent_mean 18.75 / eval/post_ent_min 12.12 / eval/post_ent_std 2.64 / eval/prior_ent_mag 44.56 / eval/prior_ent_max 44.56 / 
eval/prior_ent_mean 21.4 / eval/prior_ent_min 14.56 / eval/prior_ent_std 4.17 / eval/rep_loss_mean 2.64 / eval/rep_loss_std 3.62 / eval/reward_avg 0 / eval/reward_loss_mean 7.9e-5 / eval/reward_loss_std 6.7e-7 / eval/reward_max_data 0 / eval/reward_max_pred 0 / 
eval/reward_neg_acc 1 / eval/reward_neg_loss 7.9e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 0 / eval/reward_rate 0 / replay/size 1.3e4 / replay/inserts 3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 
/ replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.3e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3862 / timer/env.step_total 19.52 / timer/env.step_frac 0.07 / timer/env.step_avg 5.1e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 381.72 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.7e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / 
timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7870 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 
/ timer/dataset_train_count 1931 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.7e-4 / timer/dataset_train_avg 7.3e-5 / timer/dataset_train_min 6.4e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1931 / timer/agent.train_total 243.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.05 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.75

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 13000 Counter(13000) 12937
Saved chunk: 20230921T215458F457157-0LSLEen7hyoj3iVHHUrbyy-03J5JnFwgMCfQkx2MsXMSK-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215520F962733-3Tjdz6YOl0y71EtAkrjXmx-2Cm7xLrCEyYbvP1swktK7F-1024.npz
Starting evaluation at step 13500 Counter(13500) 13437
eval_Episode has 500 steps and return 5.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 14000 Counter(14000) 13937
Saved chunk: 20230921T215616F427152-03J5JnFwgMCfQkx2MsXMSK-4zvUW2bDEq90PZhicIiaxB-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215640F624521-2Cm7xLrCEyYbvP1swktK7F-2vwkwM1jJ1Gz49XpOr6x48-1024.npz
Starting evaluation at step 14500 Counter(14500) 14437
eval_Episode has 500 steps and return 2.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 15000 Counter(15000) 14937
Saved chunk: 20230921T215734F072448-4zvUW2bDEq90PZhicIiaxB-1AJZd0HCUKPgG3vtu9M7AU-1024.npz
eval_Episode has 500 steps and return 3.0.
train_Episode has 500 steps and return 5.0.
Saved chunk: 20230921T215759F758071-2vwkwM1jJ1Gz49XpOr6x48-0t3pWqnl2wxMIQgLKHFOy0-1024.npz
Starting evaluation at step 15500 Counter(15500) 15437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 16000 Counter(16000) 15937
Saved chunk: 20230921T215851F532654-1AJZd0HCUKPgG3vtu9M7AU-3Lu834bWZTcG4EJ6QtokHa-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T215918F748099-0t3pWqnl2wxMIQgLKHFOy0-2nMF4hbXWwRhHkqTmIMrkv-1024.npz
Starting evaluation at step 16500 Counter(16500) 16437
eval_Episode has 500 steps and return 0.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 33002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / episode/length 500 / episode/score 0 / episode/reward_rate 0 / train/action_mag 4.6 / train/action_max 4.23 / train/action_mean -0.21 / train/action_min -4.48 / train/action_std 1.1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 1.4e-3 / train/actor_opt_grad_steps 6735 / train/actor_opt_loss -6.42 / train/adv_mag 0.04 / train/adv_max 0.04 / train/adv_mean 2.3e-4 / train/adv_min -1.1e-3
/ train/adv_std 1.8e-3 / train/cont_avg 1 / train/cont_loss_mean 5.6e-8 / train/cont_loss_std 5.1e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.6e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.1 / 
train/dyn_loss_std 3.86 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.03 / train/extr_critic_critic_opt_grad_steps 6735 / train/extr_critic_critic_opt_loss 
130.68 / train/extr_critic_mag 3e-3 / train/extr_critic_max -inf / train/extr_critic_mean 9e-5 / train/extr_critic_min 5.2e-5 / train/extr_critic_std 1.5e-4 / train/extr_return_normed_mag 0.04 / train/extr_return_normed_max 0.04 / train/extr_return_normed_mean 2.7e-4 / 
train/extr_return_normed_min 1.1e-5 / train/extr_return_normed_std 1.9e-3 / train/extr_return_rate 7.8e-5 / train/extr_return_raw_mag 0.04 / train/extr_return_raw_max 0.04 / train/extr_return_raw_mean 3.2e-4 / train/extr_return_raw_min 5.7e-5 / train/extr_return_raw_std 
1.9e-3 / train/extr_reward_mag 0.01 / train/extr_reward_max -inf / train/extr_reward_mean 3.5e-5 / train/extr_reward_min 4.4e-6 / train/extr_reward_std 3.5e-4 / train/image_loss_mean 1.42 / train/image_loss_std 2.01 / train/model_loss_mean 2.68 / train/model_loss_std 3.6 
/ train/model_opt_grad_norm 15.18 / train/model_opt_grad_steps 6726 / train/model_opt_loss 4357.48 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1614.05 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.42 / train/policy_entropy_min 1.38 / train/policy_entropy_std 2.6e-3 / train/policy_logprob_mag 9.53 / train/policy_logprob_max -0.89 / train/policy_logprob_mean -1.42 / train/policy_logprob_min -9.53 / train/policy_logprob_std 0.71 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 1 / train/policy_randomness_min 0.98 / train/policy_randomness_std 1.1e-3 / train/post_ent_mag 36.26 / train/post_ent_max 36.26 / train/post_ent_mean 19.72 / train/post_ent_min 
12.77 / train/post_ent_std 3.22 / train/prior_ent_mag 46.49 / train/prior_ent_max 46.49 / train/prior_ent_mean 22.48 / train/prior_ent_min 14.93 / train/prior_ent_std 4.73 / train/rep_loss_mean 2.1 / train/rep_loss_std 3.86 / train/reward_avg 1.3e-4 / 
train/reward_loss_mean 6.4e-4 / train/reward_loss_std 0.01 / train/reward_max_data 0.05 / train/reward_max_pred 5.9e-3 / train/reward_neg_acc 1 / train/reward_neg_loss 1e-4 / train/reward_pos_acc 0.4 / train/reward_pos_loss 7.1 / train/reward_pred 3.5e-5 / 
train/reward_rate 7.6e-5 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 1.41 / report/cont_avg 1 / report/cont_loss_mean 3.2e-8 / report/cont_loss_std 2.9e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 3.2e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.56 / report/dyn_loss_std 4.29 / report/image_loss_mean 2.21 / report/image_loss_std 2.55 / report/model_loss_mean 3.75 / report/model_loss_std 4.18 / report/post_ent_mag 37.11 /
report/post_ent_max 37.11 / report/post_ent_mean 20.93 / report/post_ent_min 13.29 / report/post_ent_std 4.26 / report/prior_ent_mag 49.2 / report/prior_ent_max 49.2 / report/prior_ent_mean 24.29 / report/prior_ent_min 16.52 / report/prior_ent_std 5.91 / 
report/rep_loss_mean 2.56 / report/rep_loss_std 4.29 / report/reward_avg 4.9e-3 / report/reward_loss_mean 7.1e-3 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 0.81 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.5e-3 / 
report/reward_pos_acc 1 / report/reward_pos_loss 1.56 / report/reward_pred 4e-3 / report/reward_rate 2.9e-3 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-8 / eval/cont_loss_std 1.9e-8 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.2e-8 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.2 / eval/dyn_loss_std 4.6 / eval/image_loss_mean 1.88 / eval/image_loss_std 1.57 / eval/model_loss_mean 3.8 / eval/model_loss_std 3.79 / eval/post_ent_mag 34.82 / eval/post_ent_max 
34.82 / eval/post_ent_mean 19.7 / eval/post_ent_min 13.71 / eval/post_ent_std 2.22 / eval/prior_ent_mag 49.2 / eval/prior_ent_max 49.2 / eval/prior_ent_mean 22.88 / eval/prior_ent_min 16.93 / eval/prior_ent_std 4.26 / eval/rep_loss_mean 3.2 / eval/rep_loss_std 4.6 / 
eval/reward_avg 0 / eval/reward_loss_mean 4e-5 / eval/reward_loss_std 3.3e-6 / eval/reward_max_data 0 / eval/reward_max_pred 3.3e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.1e-5 / 
eval/reward_rate 0 / replay/size 1.6e4 / replay/inserts 3864 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1.7e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.31 / timer/env.step_count 3864 / timer/env.step_total 19.38 / timer/env.step_frac 0.06 /
timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 379.08 / timer/replay._sample_frac 1.26 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / 
timer/replay._sample_max 0.08 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7872 / timer/agent.policy_total 16.89 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 9.4e-3 / timer/dataset_train_count 1932 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1932 / 
timer/agent.train_total 243.65 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.73

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 17000 Counter(17000) 16937
Saved chunk: 20230921T220008F873120-3Lu834bWZTcG4EJ6QtokHa-7EQxUqbv5az7X04xeMRRfb-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220037F577075-2nMF4hbXWwRhHkqTmIMrkv-4SHfJ3OfP2NlFytDU8Fj14-1024.npz
Starting evaluation at step 17500 Counter(17500) 17437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 18000 Counter(18000) 17937
Saved chunk: 20230921T220126F948564-7EQxUqbv5az7X04xeMRRfb-46o3KJAHoWFvTGD7XPEdxS-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220157F366850-4SHfJ3OfP2NlFytDU8Fj14-0rfB1YclUSvjZ0UVirYFqu-1024.npz
Starting evaluation at step 18500 Counter(18500) 18437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 19000 Counter(19000) 18937
Saved chunk: 20230921T220244F596200-46o3KJAHoWFvTGD7XPEdxS-0jdQ9uOQXbtHSX9i8FIuxP-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220316F499721-0rfB1YclUSvjZ0UVirYFqu-6mVUzZVETQq2veTy8h8xKN-1024.npz
Starting evaluation at step 19500 Counter(19500) 19437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 20.0.
Starting evaluation at step 20000 Counter(20000) 19937
Saved chunk: 20230921T220402F141207-0jdQ9uOQXbtHSX9i8FIuxP-6SvdxcKHvNkoV3x0aMVd1S-1024.npz
eval_Episode has 500 steps and return 28.0.
train_Episode has 500 steps and return 34.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 40816 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 34 / episode/reward_rate 0.04 / eval_episode/length 500 / eval_episode/score 28 / eval_episode/reward_rate 0.04 / train/action_mag 4.78 / train/action_max 4.53 / train/action_mean -0.04 / train/action_min -4.44 / train/action_std 1.18 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.02 / train/actor_opt_grad_steps 8680 / train/actor_opt_loss -33.43 / train/adv_mag 0.57 / train/adv_max 0.57 / train/adv_mean 3e-3 / train/adv_min -0.07 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1.8e-8 / train/cont_loss_std 2e-8 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-8 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.26 / 
train/dyn_loss_std 4.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 8680 / train/extr_critic_critic_opt_loss 
2425.37 / train/extr_critic_mag 0.15 / train/extr_critic_max 0.15 / train/extr_critic_mean 8.6e-3 / train/extr_critic_min 2e-3 / train/extr_critic_std 0.02 / train/extr_return_normed_mag 0.67 / train/extr_return_normed_max 0.67 / train/extr_return_normed_mean 9.5e-3 / 
train/extr_return_normed_min -4.3e-5 / train/extr_return_normed_std 0.04 / train/extr_return_rate 4.5e-3 / train/extr_return_raw_mag 0.67 / train/extr_return_raw_max 0.67 / train/extr_return_raw_mean 0.01 / train/extr_return_raw_min 2.1e-3 / train/extr_return_raw_std 0.04
/ train/extr_reward_mag 0.18 / train/extr_reward_max 0.18 / train/extr_reward_mean 4.3e-4 / train/extr_reward_min 4.8e-6 / train/extr_reward_std 5.2e-3 / train/image_loss_mean 1.34 / train/image_loss_std 1.72 / train/model_loss_mean 2.7 / train/model_loss_std 3.59 / 
train/model_opt_grad_norm 13.38 / train/model_opt_grad_steps 8670.17 / train/model_opt_loss 9003.33 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 3320.51 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 1.38 / train/policy_entropy_min 0.66 / train/policy_entropy_std 0.1 / train/policy_logprob_mag 9.49 / train/policy_logprob_max -0.21 / train/policy_logprob_mean -1.38 / train/policy_logprob_min -9.49 / train/policy_logprob_std 0.73 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.98 / train/policy_randomness_min 0.67 / train/policy_randomness_std 0.04 / train/post_ent_mag 37.5 / train/post_ent_max 37.5 / train/post_ent_mean 21.25 / train/post_ent_min 
14.28 / train/post_ent_std 3.05 / train/prior_ent_mag 50.45 / train/prior_ent_max 50.45 / train/prior_ent_mean 24.04 / train/prior_ent_min 16.43 / train/prior_ent_std 4.83 / train/rep_loss_mean 2.26 / train/rep_loss_std 4.24 / train/reward_avg 7e-4 / 
train/reward_loss_mean 1.3e-3 / train/reward_loss_std 0.02 / train/reward_max_data 0.3 / train/reward_max_pred 0.13 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-4 / train/reward_pos_acc 0.81 / train/reward_pos_loss 2.63 / train/reward_pred 5.9e-4 / 
train/reward_rate 4.5e-4 / train_stats/mean_log_entropy 1.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-8 / report/cont_loss_std 8.9e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 1.1e-8 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.28 / report/dyn_loss_std 3.79 / report/image_loss_mean 1.39 / report/image_loss_std 1.58 / report/model_loss_mean 2.76 / report/model_loss_std 3.26 / report/post_ent_mag 37.79 /
report/post_ent_max 37.79 / report/post_ent_mean 22.69 / report/post_ent_min 13.25 / report/post_ent_std 3.12 / report/prior_ent_mag 52.5 / report/prior_ent_max 52.5 / report/prior_ent_mean 25.69 / report/prior_ent_min 15.94 / report/prior_ent_std 4.91 / 
report/rep_loss_mean 2.28 / report/rep_loss_std 3.79 / report/reward_avg 0 / report/reward_loss_mean 4.3e-5 / report/reward_loss_std 1.4e-4 / report/reward_max_data 0 / report/reward_max_pred 2.1e-3 / report/reward_neg_acc 1 / report/reward_neg_loss 4.3e-5 / 
report/reward_pos_acc nan / report/reward_pos_loss nan / report/reward_pred 2.7e-5 / report/reward_rate 0 / eval/cont_avg 1 / eval/cont_loss_mean 9.2e-9 / eval/cont_loss_std 6.6e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss
9.2e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.79 / eval/dyn_loss_std 5.19 / eval/image_loss_mean 1.17 / eval/image_loss_std 1.42 / eval/model_loss_mean 2.85 / eval/model_loss_std 4.12 / eval/post_ent_mag 37.77 / eval/post_ent_max 37.77 / 
eval/post_ent_mean 21.5 / eval/post_ent_min 16.01 / eval/post_ent_std 2 / eval/prior_ent_mag 52.5 / eval/prior_ent_max 52.5 / eval/prior_ent_mean 24.01 / eval/prior_ent_min 18.98 / eval/prior_ent_std 4.04 / eval/rep_loss_mean 2.79 / eval/rep_loss_std 5.19 / 
eval/reward_avg 0 / eval/reward_loss_mean 1.6e-5 / eval/reward_loss_std 4e-6 / eval/reward_max_data 0 / eval/reward_max_pred 5.4e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 6.4e-6 / 
eval/reward_rate 0 / replay/size 2e4 / replay/inserts 3907 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.1e4 / eval_replay/inserts 3507 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3907 / timer/env.step_total 19.54 / timer/env.step_frac 0.07 /
timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 381.47 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / 
timer/replay._sample_max 0.09 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7414 / timer/agent.policy_total 15.96 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 0.02 / timer/dataset_train_count 1953 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.4e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 3.7e-4 / timer/agent.train_count 1953 / 
timer/agent.train_total 246.42 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 26.05

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T220435F527687-6mVUzZVETQq2veTy8h8xKN-1zFQCBXzBsykt1oihZFtLY-1024.npz
Starting evaluation at step 20500 Counter(20500) 20437
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 29.0.
Starting evaluation at step 21000 Counter(21000) 20937
Saved chunk: 20230921T220519F440319-6SvdxcKHvNkoV3x0aMVd1S-1tR72c52Z2STzYf5SvmNaz-1024.npz
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 21500 Counter(21500) 21437
eval_Episode has 500 steps and return 0.0.
Saved chunk: 20230921T220554F890004-1zFQCBXzBsykt1oihZFtLY-6RGszdL8Z1n5Mkr491UNRV-1024.npz
train_Episode has 500 steps and return 0.0.
Starting evaluation at step 22000 Counter(22000) 21937
Saved chunk: 20230921T220637F654291-1tR72c52Z2STzYf5SvmNaz-6qcjSrkXF89MtedCfiOOY1-1024.npz
eval_Episode has 500 steps and return 25.0.
train_Episode has 500 steps and return 25.0.
Starting evaluation at step 22500 Counter(22500) 22437
eval_Episode has 500 steps and return 27.0.
Saved chunk: 20230921T220717F612051-6RGszdL8Z1n5Mkr491UNRV-5mAeLNLekGIFCQU4PIDVIZ-1024.npz
train_Episode has 500 steps and return 22.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T220836F676203-5mAeLNLekGIFCQU4PIDVIZ-0000000000000000000000-272.npz
Saved chunk: 20230921T220755F227733-6qcjSrkXF89MtedCfiOOY1-0000000000000000000000-616.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 23000 Counter(23000) 22937
Saved chunk: 20230921T220755F227733-6qcjSrkXF89MtedCfiOOY1-4rcKJtyO4sHzqgtZTWvfke-1024.npz
eval_Episode has 500 steps and return 30.0.
train_Episode has 500 steps and return 24.0.
Starting evaluation at step 23500 Counter(23500) 23437
eval_Episode has 500 steps and return 31.0.
train_Episode has 500 steps and return 30.0.
Saved chunk: 20230921T220836F676203-5mAeLNLekGIFCQU4PIDVIZ-1D579CNlLBZVt7RqGsSiqy-1024.npz
Starting evaluation at step 24000 Counter(24000) 23937
Saved chunk: 20230921T220912F957189-4rcKJtyO4sHzqgtZTWvfke-5ZjbPMp5znzXr1gLLfw8lN-1024.npz
eval_Episode has 500 steps and return 37.0.
train_Episode has 500 steps and return 33.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 48510 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 37 / eval_episode/reward_rate 0.05 / episode/length 500 / episode/score 33 / episode/reward_rate 0.05 / train/action_mag 2.72 / train/action_max 2.5 / train/action_mean 0.62 / train/action_min -2.29 / train/action_std 0.75 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e4 / train/actor_opt_loss -379.88 / train/adv_mag 2.55 / train/adv_max 2.53 / train/adv_mean 0.04 / train/adv_min -0.66 / 
train/adv_std 0.15 / train/cont_avg 1 / train/cont_loss_mean 6.8e-9 / train/cont_loss_std 9.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.8e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.45 / 
train/dyn_loss_std 4.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.66 / train/extr_critic_critic_opt_grad_steps 1.1e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 2.44 / train/extr_critic_max 2.44 / train/extr_critic_mean 0.61 / train/extr_critic_min 0.11 / train/extr_critic_std 0.47 / train/extr_return_normed_mag 3.64 / train/extr_return_normed_max 3.64 / train/extr_return_normed_mean 0.28 / 
train/extr_return_normed_min -0.02 / train/extr_return_normed_std 0.37 / train/extr_return_rate 0.45 / train/extr_return_raw_mag 5.66 / train/extr_return_raw_max 5.66 / train/extr_return_raw_mean 0.67 / train/extr_return_raw_min 0.12 / train/extr_return_raw_std 0.6 / 
train/extr_reward_mag 1.35 / train/extr_reward_max 1.35 / train/extr_reward_mean 5.6e-3 / train/extr_reward_min 9.6e-7 / train/extr_reward_std 0.07 / train/image_loss_mean 1.22 / train/image_loss_std 1.41 / train/model_loss_mean 2.69 / train/model_loss_std 3.66 / 
train/model_opt_grad_norm 12.11 / train/model_opt_grad_steps 1.1e4 / train/model_opt_loss 1.7e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6406.25 / train/policy_entropy_mag 1.12 / train/policy_entropy_max 1.11 / 
train/policy_entropy_mean -0.27 / train/policy_entropy_min -0.87 / train/policy_entropy_std 0.4 / train/policy_logprob_mag 7.76 / train/policy_logprob_max 1.36 / train/policy_logprob_mean 0.27 / train/policy_logprob_min -7.76 / train/policy_logprob_std 0.82 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.26 / train/policy_randomness_min 6.8e-3 / train/policy_randomness_std 0.17 / train/post_ent_mag 39.99 / train/post_ent_max 39.99 / train/post_ent_mean 22.95 / 
train/post_ent_min 15.27 / train/post_ent_std 2.86 / train/prior_ent_mag 54.25 / train/prior_ent_max 54.25 / train/prior_ent_mean 25.81 / train/prior_ent_min 17.65 / train/prior_ent_std 4.92 / train/rep_loss_mean 2.45 / train/rep_loss_std 4.65 / train/reward_avg 6.2e-3 / 
train/reward_loss_mean 6.6e-3 / train/reward_loss_std 0.08 / train/reward_max_data 1.44 / train/reward_max_pred 1.14 / train/reward_neg_acc 1 / train/reward_neg_loss 1.4e-3 / train/reward_pos_acc 0.98 / train/reward_pos_loss 1.22 / train/reward_pred 5.5e-3 / 
train/reward_rate 4.4e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.51 / report/cont_avg 1 / report/cont_loss_mean 2.8e-9 / report/cont_loss_std 2.9e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / 
report/cont_pos_loss 2.8e-9 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.09 / report/dyn_loss_std 4.12 / report/image_loss_mean 0.74 / report/image_loss_std 1.02 / report/model_loss_mean 2 / report/model_loss_std 3.03 / report/post_ent_mag 40.55 / 
report/post_ent_max 40.55 / report/post_ent_mean 22.87 / report/post_ent_min 15.98 / report/post_ent_std 2.78 / report/prior_ent_mag 55.66 / report/prior_ent_max 55.66 / report/prior_ent_mean 25.78 / report/prior_ent_min 17.6 / report/prior_ent_std 4.72 / 
report/rep_loss_mean 2.09 / report/rep_loss_std 4.12 / report/reward_avg 3.9e-3 / report/reward_loss_mean 3.5e-3 / report/reward_loss_std 0.05 / report/reward_max_data 1 / report/reward_max_pred 1.12 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-4 / 
report/reward_pos_acc 1 / report/reward_pos_loss 0.84 / report/reward_pred 3.7e-3 / report/reward_rate 3.9e-3 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-9 / eval/cont_loss_std 2.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / 
eval/cont_pos_loss 3.7e-9 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.03 / eval/dyn_loss_std 5.29 / eval/image_loss_mean 1.19 / eval/image_loss_std 0.89 / eval/model_loss_mean 3 / eval/model_loss_std 3.75 / eval/post_ent_mag 40.55 / eval/post_ent_max 
40.55 / eval/post_ent_mean 22.03 / eval/post_ent_min 15.8 / eval/post_ent_std 2.05 / eval/prior_ent_mag 55.66 / eval/prior_ent_max 55.66 / eval/prior_ent_mean 25.37 / eval/prior_ent_min 19.57 / eval/prior_ent_std 4.38 / eval/rep_loss_mean 3.03 / eval/rep_loss_std 5.29 / 
eval/reward_avg 0 / eval/reward_loss_mean 5.5e-6 / eval/reward_loss_std 2.1e-6 / eval/reward_max_data 0 / eval/reward_max_pred 2.5e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.5e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.1e-6 / 
eval/reward_rate 0 / replay/size 2.4e4 / replay/inserts 3847 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.5e4 / eval_replay/inserts 4008 / 
eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3847 / timer/env.step_total 19.27 / timer/env.step_frac 0.06 / 
timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 380.52 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / 
timer/replay._sample_max 0.1 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7855 / timer/agent.policy_total 17.05 / 
timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.2 / timer/dataset_train_count 1924 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / 
timer/dataset_train_min 6.6e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1924 / timer/agent.train_total 243.27 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.57 / timer/agent.report_count 
2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / 
timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.65

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 24500 Counter(24500) 24437
eval_Episode has 500 steps and return 40.0.
train_Episode has 500 steps and return 30.0.
Saved chunk: 20230921T220955F929318-1D579CNlLBZVt7RqGsSiqy-1pvyduzgd7OIO1skUpiY2e-1024.npz
Starting evaluation at step 25000 Counter(25000) 24937
Saved chunk: 20230921T221030F762459-5ZjbPMp5znzXr1gLLfw8lN-55aGVQV1RtF4LGlxK0eETb-1024.npz
eval_Episode has 500 steps and return 78.0.
train_Episode has 500 steps and return 29.0.
Starting evaluation at step 25500 Counter(25500) 25437
eval_Episode has 500 steps and return 39.0.
train_Episode has 500 steps and return 27.0.
Saved chunk: 20230921T221115F988154-1pvyduzgd7OIO1skUpiY2e-6bTxPbAlzOR0ExThjfLjpU-1024.npz
Starting evaluation at step 26000 Counter(26000) 25937
Saved chunk: 20230921T221149F052780-55aGVQV1RtF4LGlxK0eETb-6JUL5ObtRbiB8VhiEYrgYE-1024.npz
eval_Episode has 500 steps and return 50.0.
train_Episode has 500 steps and return 38.0.
Starting evaluation at step 26500 Counter(26500) 26437
eval_Episode has 500 steps and return 50.0.
train_Episode has 500 steps and return 47.0.
Saved chunk: 20230921T221235F210335-6bTxPbAlzOR0ExThjfLjpU-1OsLPbMSKubzUyJ1ijYeii-1024.npz
Starting evaluation at step 27000 Counter(27000) 26937
eval_Episode has 500 steps and return 40.0.
Saved chunk: 20230921T221306F587366-6JUL5ObtRbiB8VhiEYrgYE-3csbgFLTcZ2e5UjvK2l4PZ-1024.npz
train_Episode has 500 steps and return 39.0.
Starting evaluation at step 27500 Counter(27500) 27437
eval_Episode has 500 steps and return 33.0.
train_Episode has 500 steps and return 41.0.
Saved chunk: 20230921T221354F172628-1OsLPbMSKubzUyJ1ijYeii-356hxtKbo50bSEbxfItv3B-1024.npz
Starting evaluation at step 28000 Counter(28000) 27937
eval_Episode has 500 steps and return 39.0.
train_Episode has 500 steps and return 38.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 56230 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 39 / eval_episode/reward_rate 0.05 / episode/length 500 / episode/score 38 / episode/reward_rate 0.05 / train/action_mag 2.63 / train/action_max 2.54 / train/action_mean 0.47 / train/action_min -2.16 / train/action_std 0.84 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.05 / train/actor_opt_grad_steps 1.3e4 / train/actor_opt_loss -252.25 / train/adv_mag 1.17 / train/adv_max 1.15 / train/adv_mean 0.03 / train/adv_min -0.56 / 
train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 3.3e-9 / train/cont_loss_std 4.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.44 / 
train/dyn_loss_std 4.84 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.72 / train/extr_critic_critic_opt_grad_steps 1.3e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 7.44 / train/extr_critic_max 7.44 / train/extr_critic_mean 2.99 / train/extr_critic_min 0.74 / train/extr_critic_std 1.64 / train/extr_return_normed_mag 1.99 / train/extr_return_normed_max 1.99 / train/extr_return_normed_mean 0.37 / 
train/extr_return_normed_min -0.06 / train/extr_return_normed_std 0.34 / train/extr_return_rate 0.98 / train/extr_return_raw_mag 11.8 / train/extr_return_raw_max 11.8 / train/extr_return_raw_mean 3.13 / train/extr_return_raw_min 0.83 / train/extr_return_raw_std 1.79 / 
train/extr_reward_mag 1.9 / train/extr_reward_max 1.9 / train/extr_reward_mean 0.01 / train/extr_reward_min 3.1e-9 / train/extr_reward_std 0.13 / train/image_loss_mean 1.02 / train/image_loss_std 1.04 / train/model_loss_mean 2.49 / train/model_loss_std 3.55 / 
train/model_opt_grad_norm 11.52 / train/model_opt_grad_steps 1.3e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5673.58 / train/policy_entropy_mag 1.12 / train/policy_entropy_max 1.12 / 
train/policy_entropy_mean -0.39 / train/policy_entropy_min -0.87 / train/policy_entropy_std 0.37 / train/policy_logprob_mag 7.75 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.39 / train/policy_logprob_min -7.75 / train/policy_logprob_std 0.8 / 
train/policy_randomness_mag 0.87 / train/policy_randomness_max 0.87 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 4.8e-3 / train/policy_randomness_std 0.16 / train/post_ent_mag 42.32 / train/post_ent_max 42.32 / train/post_ent_mean 24.02 / 
train/post_ent_min 15.44 / train/post_ent_std 3.02 / train/prior_ent_mag 56.87 / train/prior_ent_max 56.87 / train/prior_ent_mean 26.78 / train/prior_ent_min 18.69 / train/prior_ent_std 4.94 / train/rep_loss_mean 2.44 / train/rep_loss_std 4.84 / train/reward_avg 0.01 / 
train/reward_loss_mean 0.01 / train/reward_loss_std 0.11 / train/reward_max_data 1.85 / train/reward_max_pred 1.76 / train/reward_neg_acc 1 / train/reward_neg_loss 1.6e-3 / train/reward_pos_acc 0.98 / train/reward_pos_loss 0.89 / train/reward_pred 0.01 / train/reward_rate
9.7e-3 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.64 / report/cont_avg 1 / report/cont_loss_mean 2.5e-9 / report/cont_loss_std 3e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.29 / report/dyn_loss_std 4.94 / report/image_loss_mean 0.94 / report/image_loss_std 0.9 / report/model_loss_mean 2.33 / report/model_loss_std 3.55 / report/post_ent_mag 44.7 / report/post_ent_max 44.7 / 
report/post_ent_mean 23.83 / report/post_ent_min 15.06 / report/post_ent_std 2.95 / report/prior_ent_mag 58.52 / report/prior_ent_max 58.52 / report/prior_ent_mean 26.88 / report/prior_ent_min 18.03 / report/prior_ent_std 5.06 / report/rep_loss_mean 2.29 / 
report/rep_loss_std 4.94 / report/reward_avg 0.03 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 1.95 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.8 / report/reward_pred 0.03 / report/reward_rate 0.02 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-9 / eval/cont_loss_std 9.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-9 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 2 / eval/dyn_loss_std 3.86 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.58 / eval/model_loss_mean 1.65 / eval/model_loss_std 2.7 / eval/post_ent_mag 44.64 / eval/post_ent_max 44.64 / eval/post_ent_mean 24.75 / 
eval/post_ent_min 14.78 / eval/post_ent_std 3.28 / eval/prior_ent_mag 58.52 / eval/prior_ent_max 58.52 / eval/prior_ent_mean 27.45 / eval/prior_ent_min 19.3 / eval/prior_ent_std 5.25 / eval/rep_loss_mean 2 / eval/rep_loss_std 3.86 / eval/reward_avg 0 / 
eval/reward_loss_mean 1e-6 / eval/reward_loss_std 1e-6 / eval/reward_max_data 0 / eval/reward_max_pred 2.3e-5 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 3.2e-7 / eval/reward_rate 0 / 
replay/size 2.8e4 / replay/inserts 3860 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 2.9e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3860 / timer/env.step_total 19.34 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.06 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 377.74 / timer/replay._sample_frac 1.26 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7868 / timer/agent.policy_total 16.85 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1930 / timer/dataset_train_total 0.14 / timer/dataset_train_frac 4.8e-4 / timer/dataset_train_avg 7.5e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1930 / timer/agent.train_total 243.54 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.73

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 28500 Counter(28500) 28437
Saved chunk: 20230921T221423F925413-3csbgFLTcZ2e5UjvK2l4PZ-5G8eAOHv5fQ1qi6EProV7v-1024.npz
eval_Episode has 500 steps and return 39.0.
train_Episode has 500 steps and return 36.0.
Saved chunk: 20230921T221513F008839-356hxtKbo50bSEbxfItv3B-5hK7ske2n5kcje6I44ciLz-1024.npz
Starting evaluation at step 29000 Counter(29000) 28937
eval_Episode has 500 steps and return 63.0.
train_Episode has 500 steps and return 41.0.
Starting evaluation at step 29500 Counter(29500) 29437
Saved chunk: 20230921T221617F323255-5G8eAOHv5fQ1qi6EProV7v-6d4Wo39hxNykslyRpdq4ja-1024.npz
eval_Episode has 500 steps and return 68.0.
train_Episode has 500 steps and return 42.0.
Saved chunk: 20230921T221632F773047-5hK7ske2n5kcje6I44ciLz-3F4C9h6lzPqkWx7Ek7P2UQ-1024.npz
Starting evaluation at step 30000 Counter(30000) 29937
eval_Episode has 500 steps and return 216.0.
train_Episode has 500 steps and return 64.0.
Starting evaluation at step 30500 Counter(30500) 30437
Saved chunk: 20230921T221735F092207-6d4Wo39hxNykslyRpdq4ja-2aP7QGKSQvghhEdsksEvlT-1024.npz
eval_Episode has 500 steps and return 96.0.
train_Episode has 500 steps and return 87.0.
Saved chunk: 20230921T221752F074351-3F4C9h6lzPqkWx7Ek7P2UQ-5fw81WtgaHrYX22IRf29ZO-1024.npz
Starting evaluation at step 31000 Counter(31000) 30937
eval_Episode has 500 steps and return 58.0.
train_Episode has 500 steps and return 73.0.
Starting evaluation at step 31500 Counter(31500) 31437
Saved chunk: 20230921T221852F684170-2aP7QGKSQvghhEdsksEvlT-0Qgef5zj85Q7x59eRaERsO-1024.npz
eval_Episode has 500 steps and return 99.0.
train_Episode has 500 steps and return 33.0.
Saved chunk: 20230921T221911F178221-5fw81WtgaHrYX22IRf29ZO-6SxYTz9VqhAwZJJBRiMu6s-1024.npz
Starting evaluation at step 32000 Counter(32000) 31937
eval_Episode has 500 steps and return 66.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 64002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 66 / eval_episode/reward_rate 0.07 / episode/length 500 / episode/score 33 / episode/reward_rate 0.04 / train/action_mag 2.9 / train/action_max 2.84 / train/action_mean 0.42 / train/action_min -2.21 / train/action_std 0.85 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.4e4 / train/actor_opt_loss -234.23 / train/adv_mag 1.08 / train/adv_max 1.06 / train/adv_mean 0.02 / train/adv_min -0.5 / 
train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 2.2e-9 / train/cont_loss_std 3.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.2e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.42 / 
train/dyn_loss_std 5.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.72 / train/extr_critic_critic_opt_grad_steps 1.4e4 / train/extr_critic_critic_opt_loss 
1.3e4 / train/extr_critic_mag 14.15 / train/extr_critic_max 14.15 / train/extr_critic_mean 7.45 / train/extr_critic_min 2.27 / train/extr_critic_std 3.11 / train/extr_return_normed_mag 1.92 / train/extr_return_normed_max 1.92 / train/extr_return_normed_mean 0.46 / 
train/extr_return_normed_min -0.09 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 21.55 / train/extr_return_raw_max 21.55 / train/extr_return_raw_mean 7.67 / train/extr_return_raw_min 2.47 / train/extr_return_raw_std 3.3 / 
train/extr_reward_mag 1.99 / train/extr_reward_max 1.99 / train/extr_reward_mean 0.03 / train/extr_reward_min -9.6e-8 / train/extr_reward_std 0.2 / train/image_loss_mean 0.86 / train/image_loss_std 0.86 / train/model_loss_mean 2.32 / train/model_loss_std 3.59 / 
train/model_opt_grad_norm 10.99 / train/model_opt_grad_steps 1.4e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5717.95 / train/policy_entropy_mag 1.23 / train/policy_entropy_max 1.23 / 
train/policy_entropy_mean -0.39 / train/policy_entropy_min -0.87 / train/policy_entropy_std 0.38 / train/policy_logprob_mag 7.74 / train/policy_logprob_max 1.36 / train/policy_logprob_mean 0.39 / train/policy_logprob_min -7.74 / train/policy_logprob_std 0.81 / 
train/policy_randomness_mag 0.92 / train/policy_randomness_max 0.92 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 5.6e-3 / train/policy_randomness_std 0.17 / train/post_ent_mag 45.06 / train/post_ent_max 45.06 / train/post_ent_mean 25.39 / 
train/post_ent_min 15.41 / train/post_ent_std 3.36 / train/prior_ent_mag 58.83 / train/prior_ent_max 58.83 / train/prior_ent_mean 28.1 / train/prior_ent_min 19.17 / train/prior_ent_std 5.12 / train/rep_loss_mean 2.42 / train/rep_loss_std 5.04 / train/reward_avg 0.02 / 
train/reward_loss_mean 0.01 / train/reward_loss_std 0.12 / train/reward_max_data 1.98 / train/reward_max_pred 1.97 / train/reward_neg_acc 1 / train/reward_neg_loss 1.8e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.69 / train/reward_pred 0.02 / train/reward_rate
0.02 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.45 / report/cont_avg 1 / report/cont_loss_mean 1.3e-9 / report/cont_loss_std 1.7e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.17 / report/dyn_loss_std 4.25 / report/image_loss_mean 0.57 / report/image_loss_std 0.74 / report/model_loss_mean 1.88 / report/model_loss_std 3.06 / report/post_ent_mag 46.61 / report/post_ent_max 46.61 / 
report/post_ent_mean 27.08 / report/post_ent_min 15.15 / report/post_ent_std 3.88 / report/prior_ent_mag 58.88 / report/prior_ent_max 58.88 / report/prior_ent_mean 29.41 / report/prior_ent_min 20.78 / report/prior_ent_std 5.31 / report/rep_loss_mean 2.17 / 
report/rep_loss_std 4.25 / report/reward_avg 0.02 / report/reward_loss_mean 7.7e-3 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.7 / report/reward_pred 0.02 / report/reward_rate 9.8e-3 / eval/cont_avg 1 / eval/cont_loss_mean 9.3e-10 / eval/cont_loss_std 7.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.05 / eval/dyn_loss_std 4.21 / eval/image_loss_mean 0.46 / eval/image_loss_std 0.59 / eval/model_loss_mean 1.7 / eval/model_loss_std 2.89 / eval/post_ent_mag 46.6 / eval/post_ent_max 46.6 / eval/post_ent_mean 26.01
/ eval/post_ent_min 18.15 / eval/post_ent_std 3.32 / eval/prior_ent_mag 58.88 / eval/prior_ent_max 58.88 / eval/prior_ent_mean 28.46 / eval/prior_ent_min 21.31 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 2.05 / eval/rep_loss_std 4.21 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.1e-5 / eval/reward_loss_std 2.2e-4 / eval/reward_max_data 0 / eval/reward_max_pred 5.1e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1e-5 / eval/reward_rate 0 / 
replay/size 3.2e4 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.3e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.43 / timer/env.step_count 3886 / timer/env.step_total 19.54 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 382.81 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.09 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7894 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.2e-3 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1943 / timer/agent.train_total 245.43 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.19 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 145.0.
Starting evaluation at step 32500 Counter(32500) 32437
Saved chunk: 20230921T222010F195941-0Qgef5zj85Q7x59eRaERsO-4wNPBGgBDz9I5NDlaz2DiH-1024.npz
eval_Episode has 500 steps and return 52.0.
train_Episode has 500 steps and return 117.0.
Saved chunk: 20230921T222030F206574-6SxYTz9VqhAwZJJBRiMu6s-0WBL8uebWzpwa5dSmfp5Zu-1024.npz
Starting evaluation at step 33000 Counter(33000) 32937
eval_Episode has 500 steps and return 64.0.
train_Episode has 500 steps and return 81.0.
Starting evaluation at step 33500 Counter(33500) 33437
Saved chunk: 20230921T222128F404040-4wNPBGgBDz9I5NDlaz2DiH-4CHYUhgR6OTeUAzDvlc3Vp-1024.npz
eval_Episode has 500 steps and return 49.0.
train_Episode has 500 steps and return 33.0.
Saved chunk: 20230921T222150F101761-0WBL8uebWzpwa5dSmfp5Zu-7n2DAEQqQlF5IhS9gUXXbS-1024.npz
Starting evaluation at step 34000 Counter(34000) 33937
eval_Episode has 500 steps and return 63.0.
train_Episode has 500 steps and return 71.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 34500 Counter(34500) 34437
Saved chunk: 20230921T222309F251499-7n2DAEQqQlF5IhS9gUXXbS-0000000000000000000000-708.npz
Saved chunk: 20230921T222246F077711-4CHYUhgR6OTeUAzDvlc3Vp-0000000000000000000000-876.npz
Saved chunk: 20230921T222246F077711-4CHYUhgR6OTeUAzDvlc3Vp-4IEY9z4cm2U1DYtoZN9O1j-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
eval_Episode has 500 steps and return 52.0.
train_Episode has 500 steps and return 99.0.
Saved chunk: 20230921T222309F251499-7n2DAEQqQlF5IhS9gUXXbS-4spofzqhEVc5U0Sr3GC4cd-1024.npz
Starting evaluation at step 35000 Counter(35000) 34937
eval_Episode has 500 steps and return 48.0.
train_Episode has 500 steps and return 108.0.
Starting evaluation at step 35500 Counter(35500) 35437
Saved chunk: 20230921T222403F956809-4IEY9z4cm2U1DYtoZN9O1j-0VCuO6mACbrMQsEoaPZz0d-1024.npz
eval_Episode has 500 steps and return 46.0.
train_Episode has 500 steps and return 46.0.
Saved chunk: 20230921T222428F613229-4spofzqhEVc5U0Sr3GC4cd-3Gqtv4Zd38HJSNZv4pgYfx-1024.npz
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 71802 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 46 / episode/reward_rate 0.06 / eval_episode/length 500 / eval_episode/score 46 / eval_episode/reward_rate 0.06 / train/action_mag 3.12 / train/action_max 3.09 / train/action_mean 0.4 / train/action_min -2.15 / train/action_std 0.85 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 1.6e4 / train/actor_opt_loss -222.28 / train/adv_mag 1.13 / train/adv_max 1.12 / train/adv_mean 0.02 / train/adv_min -0.5 / 
train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 1.4e-9 / train/cont_loss_std 2.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.4e-9 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.38 / 
train/dyn_loss_std 5.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.65 / train/extr_critic_critic_opt_grad_steps 1.6e4 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 24.26 / train/extr_critic_max 24.26 / train/extr_critic_mean 13.48 / train/extr_critic_min 4.41 / train/extr_critic_std 4.24 / train/extr_return_normed_mag 2.16 / train/extr_return_normed_max 2.16 / train/extr_return_normed_mean 0.54 / 
train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 35.35 / train/extr_return_raw_max 35.35 / train/extr_return_raw_mean 13.78 / train/extr_return_raw_min 4.82 / train/extr_return_raw_std 4.58 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.04 / train/extr_reward_min -3.7e-8 / train/extr_reward_std 0.26 / train/image_loss_mean 0.75 / train/image_loss_std 0.76 / train/model_loss_mean 2.19 / train/model_loss_std 3.56 / 
train/model_opt_grad_norm 10.91 / train/model_opt_grad_steps 1.6e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5846.15 / train/policy_entropy_mag 1.32 / train/policy_entropy_max 1.32 / 
train/policy_entropy_mean -0.41 / train/policy_entropy_min -0.87 / train/policy_entropy_std 0.41 / train/policy_logprob_mag 7.74 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.41 / train/policy_logprob_min -7.74 / train/policy_logprob_std 0.82 / 
train/policy_randomness_mag 0.96 / train/policy_randomness_max 0.96 / train/policy_randomness_mean 0.21 / train/policy_randomness_min 4e-3 / train/policy_randomness_std 0.18 / train/post_ent_mag 47.63 / train/post_ent_max 47.63 / train/post_ent_mean 27.18 / 
train/post_ent_min 15.92 / train/post_ent_std 3.72 / train/prior_ent_mag 60.25 / train/prior_ent_max 60.25 / train/prior_ent_mean 29.81 / train/prior_ent_min 20.12 / train/prior_ent_std 5.22 / train/rep_loss_mean 2.38 / train/rep_loss_std 5.09 / train/reward_avg 0.04 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.58 / train/reward_pred 0.04 / train/reward_rate 0.02 
/ train_stats/mean_log_entropy -0.43 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-9 / report/cont_loss_std 1.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-9 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.41 / report/dyn_loss_std 4.98 / report/image_loss_mean 0.72 / report/image_loss_std 0.61 / report/model_loss_mean 2.18 / report/model_loss_std 3.4 / report/post_ent_mag 48.65 / report/post_ent_max 48.65 / 
report/post_ent_mean 28.69 / report/post_ent_min 17.71 / report/post_ent_std 3.82 / report/prior_ent_mag 61.34 / report/prior_ent_max 61.34 / report/prior_ent_mean 31.46 / report/prior_ent_min 22.62 / report/prior_ent_std 5.26 / report/rep_loss_mean 2.41 / 
report/rep_loss_std 4.98 / report/reward_avg 0.04 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.48 / report/reward_pred 0.04 / report/reward_rate 0.03 / eval/cont_avg 1 / eval/cont_loss_mean 5.8e-10 / eval/cont_loss_std 2.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.8e-10 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.96 / eval/dyn_loss_std 3.64 / eval/image_loss_mean 0.35 / eval/image_loss_std 0.42 / eval/model_loss_mean 1.53 / eval/model_loss_std 2.45 / eval/post_ent_mag 48.71 / eval/post_ent_max 48.71 / eval/post_ent_mean 26.85 / eval/post_ent_min 17.77 / 
eval/post_ent_std 3.83 / eval/prior_ent_mag 61.34 / eval/prior_ent_max 61.34 / eval/prior_ent_mean 29.18 / eval/prior_ent_min 20.9 / eval/prior_ent_std 5.39 / eval/rep_loss_mean 1.96 / eval/rep_loss_std 3.64 / eval/reward_avg 0 / eval/reward_loss_mean 1.6e-6 / 
eval/reward_loss_std 2.8e-5 / eval/reward_max_data 0 / eval/reward_max_pred 5.6e-4 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-6 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.4e-6 / eval/reward_rate 0 / replay/size 3.6e4 / 
replay/inserts 3900 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 3.6e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3900 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 /
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 383.22 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7407 / timer/agent.policy_total 16.13 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1950 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4.1e-4 / 
timer/agent.train_count 1950 / timer/agent.train_total 246.25 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / 
timer/dataset_eval_max 3.7e-5 / fps 25.99

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 36000 Counter(36000) 35937
eval_Episode has 500 steps and return 88.0.
train_Episode has 500 steps and return 49.0.
Starting evaluation at step 36500 Counter(36500) 36437
Saved chunk: 20230921T222521F370557-0VCuO6mACbrMQsEoaPZz0d-74lBQPl5GksPWmR58le3wq-1024.npz
eval_Episode has 500 steps and return 60.0.
train_Episode has 500 steps and return 161.0.
Saved chunk: 20230921T222547F580636-3Gqtv4Zd38HJSNZv4pgYfx-3V6HnIZBjRKOY6xECf0h1y-1024.npz
Starting evaluation at step 37000 Counter(37000) 36937
eval_Episode has 500 steps and return 53.0.
train_Episode has 500 steps and return 56.0.
Starting evaluation at step 37500 Counter(37500) 37437
Saved chunk: 20230921T222639F656741-74lBQPl5GksPWmR58le3wq-5crxLLUuA0HnifyIBzmMFH-1024.npz
eval_Episode has 500 steps and return 80.0.
train_Episode has 500 steps and return 142.0.
Saved chunk: 20230921T222707F525152-3V6HnIZBjRKOY6xECf0h1y-4T8Ejs38oQBPIuR6UGr1j9-1024.npz
Starting evaluation at step 38000 Counter(38000) 37937
eval_Episode has 500 steps and return 68.0.
train_Episode has 500 steps and return 137.0.
Starting evaluation at step 38500 Counter(38500) 38437
Saved chunk: 20230921T222757F348668-5crxLLUuA0HnifyIBzmMFH-6HRN0PpcDIm7WxsPWbgIZW-1024.npz
eval_Episode has 500 steps and return 116.0.
train_Episode has 500 steps and return 130.0.
Saved chunk: 20230921T222826F694592-4T8Ejs38oQBPIuR6UGr1j9-3KqMUVDiDyflzB4fQulP03-1024.npz
Starting evaluation at step 39000 Counter(39000) 38937
eval_Episode has 500 steps and return 55.0.
train_Episode has 500 steps and return 85.0.
Starting evaluation at step 39500 Counter(39500) 39437
Saved chunk: 20230921T222914F880463-6HRN0PpcDIm7WxsPWbgIZW-3qw60brbaIqtNheEaU1ymo-1024.npz
eval_Episode has 500 steps and return 267.0.
train_Episode has 500 steps and return 99.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 79514 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 267 / eval_episode/reward_rate 0.27 / episode/length 500 / episode/score 99 / episode/reward_rate 0.1 / train/action_mag 2.61 / train/action_max 2.53 / train/action_mean 0.35 / train/action_min -2.2 / train/action_std 0.86 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.14 / train/actor_opt_grad_steps 1.8e4 / train/actor_opt_loss -195.15 / train/adv_mag 1.24 / train/adv_max 1.22 / train/adv_mean 0.02 / train/adv_min -0.6 / 
train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 9.7e-10 / train/cont_loss_std 1.9e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.37 / 
train/dyn_loss_std 5.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.6 / train/extr_critic_critic_opt_grad_steps 1.8e4 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 36.02 / train/extr_critic_max 36.02 / train/extr_critic_mean 19.29 / train/extr_critic_min 8.02 / train/extr_critic_std 4.84 / train/extr_return_normed_mag 2.25 / train/extr_return_normed_max 2.25 / train/extr_return_normed_mean 0.54 / 
train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 46.73 / train/extr_return_raw_max 46.73 / train/extr_return_raw_mean 19.6 / train/extr_return_raw_min 8.76 / train/extr_return_raw_std 5.34 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.06 / train/extr_reward_min -1.2e-8 / train/extr_reward_std 0.29 / train/image_loss_mean 0.68 / train/image_loss_std 0.7 / train/model_loss_mean 2.12 / train/model_loss_std 3.61 / 
train/model_opt_grad_norm 10.09 / train/model_opt_grad_steps 1.8e4 / train/model_opt_loss 1.5e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7291.67 / train/policy_entropy_mag 1.17 / train/policy_entropy_max 1.16 / 
train/policy_entropy_mean -0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.37 / train/policy_logprob_mag 7.74 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.43 / train/policy_logprob_min -7.74 / train/policy_logprob_std 0.8 / 
train/policy_randomness_mag 0.89 / train/policy_randomness_max 0.89 / train/policy_randomness_mean 0.2 / train/policy_randomness_min 3.4e-3 / train/policy_randomness_std 0.16 / train/post_ent_mag 49.55 / train/post_ent_max 49.55 / train/post_ent_mean 29 / 
train/post_ent_min 16.54 / train/post_ent_std 4.26 / train/prior_ent_mag 61.79 / train/prior_ent_max 61.79 / train/prior_ent_mean 31.57 / train/prior_ent_min 21.07 / train/prior_ent_std 5.47 / train/rep_loss_mean 2.37 / train/rep_loss_std 5.2 / train/reward_avg 0.05 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.52 / train/reward_pred 0.05 / train/reward_rate 0.03 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.48 / report/cont_avg 1 / report/cont_loss_mean 6.9e-10 / report/cont_loss_std 1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.9e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.48 / report/dyn_loss_std 5.94 / report/image_loss_mean 0.61 / report/image_loss_std 0.83 / report/model_loss_mean 2.12 / report/model_loss_std 4.24 / report/post_ent_mag 51.8 / report/post_ent_max 51.8 / 
report/post_ent_mean 29.34 / report/post_ent_min 14.04 / report/post_ent_std 4.97 / report/prior_ent_mag 62.6 / report/prior_ent_max 62.6 / report/prior_ent_mean 32.23 / report/prior_ent_min 20.74 / report/prior_ent_std 6.05 / report/rep_loss_mean 2.48 / 
report/rep_loss_std 5.94 / report/reward_avg 0.05 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.4 / report/reward_pred 0.06 / report/reward_rate 0.03 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-10 / eval/cont_loss_std 4.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.27 / eval/dyn_loss_std 4.33 / eval/image_loss_mean 0.43 / eval/image_loss_std 0.68 / eval/model_loss_mean 1.79 / eval/model_loss_std 3.09 / eval/post_ent_mag 52.02 / eval/post_ent_max 52.02 / eval/post_ent_mean 27.99 / 
eval/post_ent_min 18.37 / eval/post_ent_std 3.91 / eval/prior_ent_mag 62.6 / eval/prior_ent_max 62.6 / eval/prior_ent_mean 30.79 / eval/prior_ent_min 22.11 / eval/prior_ent_std 5.3 / eval/rep_loss_mean 2.27 / eval/rep_loss_std 4.33 / eval/reward_avg 0 / 
eval/reward_loss_mean 1.8e-5 / eval/reward_loss_std 5.5e-4 / eval/reward_max_data 0 / eval/reward_max_pred 0.02 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.8e-5 / eval/reward_pos_acc nan / eval/reward_pos_loss nan / eval/reward_pred 1.9e-5 / eval/reward_rate 0 / 
replay/size 4e4 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3856 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 376.27 / timer/replay._sample_frac 1.25 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7864 / timer/agent.policy_total 16.83 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.1e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1928 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.6e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1928 / timer/agent.train_total 243.44 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.2 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.7

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T222945F693324-3KqMUVDiDyflzB4fQulP03-76ODWGr39D0OJcJbsP52Hu-1024.npz
Starting evaluation at step 40000 Counter(40000) 39937
eval_Episode has 500 steps and return 104.0.
train_Episode has 500 steps and return 132.0.
Starting evaluation at step 40500 Counter(40500) 40437
Saved chunk: 20230921T223032F192090-3qw60brbaIqtNheEaU1ymo-6FOuO5wc1ODc67zlK6AvAA-1024.npz
eval_Episode has 500 steps and return 83.0.
train_Episode has 500 steps and return 45.0.
Saved chunk: 20230921T223105F219271-76ODWGr39D0OJcJbsP52Hu-15MYOrLkUwGcpRx2lv3WCH-1024.npz
Starting evaluation at step 41000 Counter(41000) 40937
eval_Episode has 500 steps and return 0.0.
train_Episode has 500 steps and return 57.0.
Starting evaluation at step 41500 Counter(41500) 41437
Saved chunk: 20230921T223150F559286-6FOuO5wc1ODc67zlK6AvAA-1w61nkHyn460JE3yKWes0y-1024.npz
eval_Episode has 500 steps and return 92.0.
train_Episode has 500 steps and return 135.0.
Saved chunk: 20230921T223224F627455-15MYOrLkUwGcpRx2lv3WCH-2IQB6NvBxzas7SITJVa4Qn-1024.npz
Starting evaluation at step 42000 Counter(42000) 41937
eval_Episode has 500 steps and return 142.0.
train_Episode has 500 steps and return 113.0.
Starting evaluation at step 42500 Counter(42500) 42437
Saved chunk: 20230921T223308F235839-1w61nkHyn460JE3yKWes0y-5i6qPWsWrik9z7Uy0JcvNC-1024.npz
eval_Episode has 500 steps and return 102.0.
train_Episode has 500 steps and return 97.0.
Starting evaluation at step 43000 Counter(43000) 42937
eval_Episode has 500 steps and return 85.0.
Saved chunk: 20230921T223343F746694-2IQB6NvBxzas7SITJVa4Qn-20f3nAQqZ585yo0L7MYR0Q-1024.npz
train_Episode has 500 steps and return 124.0.
Starting evaluation at step 43500 Counter(43500) 43437
Saved chunk: 20230921T223425F583377-5i6qPWsWrik9z7Uy0JcvNC-3YniXCFB76QPxbt7As5UOj-1024.npz
eval_Episode has 500 steps and return 125.0.
train_Episode has 500 steps and return 136.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 87242 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 125 / eval_episode/reward_rate 0.13 / episode/length 500 / episode/score 136 / episode/reward_rate 0.14 / train/action_mag 2.32 / train/action_max 2.27 / train/action_mean 0.32 / train/action_min -1.98 / train/action_std 0.87 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 2e4 / train/actor_opt_loss -177.27 / train/adv_mag 1.26 / train/adv_max 1.25 / train/adv_mean 0.02 / train/adv_min -0.62 / 
train/adv_std 0.08 / train/cont_avg 1 / train/cont_loss_mean 7.6e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.36 / 
train/dyn_loss_std 5.26 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.6 / train/extr_critic_critic_opt_grad_steps 2e4 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 49.24 / train/extr_critic_max 49.24 / train/extr_critic_mean 25.26 / train/extr_critic_min 11.79 / train/extr_critic_std 5.7 / train/extr_return_normed_mag 2.3 / train/extr_return_normed_max 2.3 / train/extr_return_normed_mean 0.51 / 
train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 60.16 / train/extr_return_raw_max 60.16 / train/extr_return_raw_mean 25.61 / train/extr_return_raw_min 12.89 / train/extr_return_raw_std 6.32 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.07 / train/extr_reward_min -2.3e-8 / train/extr_reward_std 0.33 / train/image_loss_mean 0.63 / train/image_loss_std 0.66 / train/model_loss_mean 2.07 / train/model_loss_std 3.62 / 
train/model_opt_grad_norm 10.29 / train/model_opt_grad_steps 2e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6804.12 / train/policy_entropy_mag 1.04 / train/policy_entropy_max 1.01 / 
train/policy_entropy_mean -0.43 / train/policy_entropy_min -0.87 / train/policy_entropy_std 0.33 / train/policy_logprob_mag 7.74 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.43 / train/policy_logprob_min -7.74 / train/policy_logprob_std 0.78 / 
train/policy_randomness_mag 0.82 / train/policy_randomness_max 0.82 / train/policy_randomness_mean 0.2 / train/policy_randomness_min 3.9e-3 / train/policy_randomness_std 0.14 / train/post_ent_mag 51.49 / train/post_ent_max 51.49 / train/post_ent_mean 30.82 / 
train/post_ent_min 17.09 / train/post_ent_std 4.81 / train/prior_ent_mag 62.96 / train/prior_ent_max 62.96 / train/prior_ent_mean 33.35 / train/prior_ent_min 21.78 / train/prior_ent_std 5.77 / train/rep_loss_mean 2.36 / train/rep_loss_std 5.26 / train/reward_avg 0.07 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.46 / train/reward_pred 0.07 / train/reward_rate 0.04 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.56 / report/cont_avg 1 / report/cont_loss_mean 6.3e-10 / report/cont_loss_std 9.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.63 / report/dyn_loss_std 5.48 / report/image_loss_mean 0.7 / report/image_loss_std 0.79 / report/model_loss_mean 2.3 / report/model_loss_std 3.86 / report/post_ent_mag 42.83 / report/post_ent_max 42.83 / 
report/post_ent_mean 31.7 / report/post_ent_min 18.21 / report/post_ent_std 4.81 / report/prior_ent_mag 63.58 / report/prior_ent_max 63.58 / report/prior_ent_mean 34.49 / report/prior_ent_min 23.08 / report/prior_ent_std 5.76 / report/rep_loss_mean 2.63 / 
report/rep_loss_std 5.48 / report/reward_avg 0.04 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.4e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.5 / report/reward_pred 0.04 / report/reward_rate 0.03 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-10 / eval/cont_loss_std 7.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 4.37 / eval/dyn_loss_std 7.91 / eval/image_loss_mean 1.4 / eval/image_loss_std 2.77 / eval/model_loss_mean 4.04 / eval/model_loss_std 7.09 / eval/post_ent_mag 53.66 / eval/post_ent_max 53.66 / eval/post_ent_mean 31.3 / eval/post_ent_min 14.56 / 
eval/post_ent_std 5.93 / eval/prior_ent_mag 63.58 / eval/prior_ent_max 63.58 / eval/prior_ent_mean 34.75 / eval/prior_ent_min 23.04 / eval/prior_ent_std 5.85 / eval/rep_loss_mean 4.37 / eval/rep_loss_std 7.91 / eval/reward_avg 2e-3 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.54 / eval/reward_max_data 1 / eval/reward_max_pred 1.9e-3 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.2e-6 / eval/reward_pos_acc 0 / eval/reward_pos_loss 11.94 / eval/reward_pred 3.1e-6 / eval/reward_rate 2e-3 / replay/size 4.4e4 / 
replay/inserts 3864 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 
2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3864 / timer/env.step_total 19.36 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 /
timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 381.66 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.1 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7872 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1932 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1932 / timer/agent.train_total 243.88 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.75

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 44000 Counter(44000) 43937
eval_Episode has 500 steps and return 103.0.
Saved chunk: 20230921T223505F608858-20f3nAQqZ585yo0L7MYR0Q-5MHJhvyHEYl1q297VPLIVE-1024.npz
train_Episode has 500 steps and return 98.0.
Starting evaluation at step 44500 Counter(44500) 44437
Saved chunk: 20230921T223542F529345-3YniXCFB76QPxbt7As5UOj-3eSr2KdiCM9xNSPNIcAeoN-1024.npz
eval_Episode has 500 steps and return 144.0.
train_Episode has 500 steps and return 105.0.
Starting evaluation at step 45000 Counter(45000) 44937
eval_Episode has 500 steps and return 110.0.
Saved chunk: 20230921T223625F115422-5MHJhvyHEYl1q297VPLIVE-0r6jeuW4fo21BJGP91ofzP-1024.npz
train_Episode has 500 steps and return 119.0.
Starting evaluation at step 45500 Counter(45500) 45437
Saved chunk: 20230921T223700F668005-3eSr2KdiCM9xNSPNIcAeoN-00kPQ02AJmGS7kIYdKuEir-1024.npz
eval_Episode has 500 steps and return 106.0.
train_Episode has 500 steps and return 111.0.
Starting evaluation at step 46000 Counter(46000) 45937
eval_Episode has 500 steps and return 114.0.
Saved chunk: 20230921T223744F101056-0r6jeuW4fo21BJGP91ofzP-6kzTFOjbvp64paKrEPii5v-1024.npz
train_Episode has 500 steps and return 101.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T223903F004737-6kzTFOjbvp64paKrEPii5v-0000000000000000000000-20.npz
Saved chunk: 20230921T223818F088037-00kPQ02AJmGS7kIYdKuEir-0000000000000000000000-611.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 46500 Counter(46500) 46437
Saved chunk: 20230921T223818F088037-00kPQ02AJmGS7kIYdKuEir-1YxAc86aFJVxxLi3FgznJm-1024.npz
eval_Episode has 500 steps and return 108.0.
train_Episode has 500 steps and return 112.0.
Starting evaluation at step 47000 Counter(47000) 46937
eval_Episode has 500 steps and return 140.0.
train_Episode has 500 steps and return 113.0.
Saved chunk: 20230921T223903F004737-6kzTFOjbvp64paKrEPii5v-2e4CrqvUUNIdw0EUknTP4c-1024.npz
Starting evaluation at step 47500 Counter(47500) 47437
Saved chunk: 20230921T223935F490921-1YxAc86aFJVxxLi3FgznJm-0iyh3jCwdXQ4E0kKMQ6S6P-1024.npz
eval_Episode has 500 steps and return 167.0.
────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 95002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 167 / eval_episode/reward_rate 0.17 / episode/length 500 / episode/score 113 / episode/reward_rate 0.12 / train/action_mag 2.08 / train/action_max 2.01 / train/action_mean 0.33 / train/action_min -1.94 / train/action_std 0.86 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.2e4 / train/actor_opt_loss -177.95 / train/adv_mag 1.19 / train/adv_max 1.19 / train/adv_mean 0.02 / train/adv_min -0.52 / 
train/adv_std 0.07 / train/cont_avg 1 / train/cont_loss_mean 6.2e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.37 / 
train/dyn_loss_std 5.32 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.61 / train/extr_critic_critic_opt_grad_steps 2.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 62.37 / train/extr_critic_max 62.37 / train/extr_critic_mean 33.17 / train/extr_critic_min 17.62 / train/extr_critic_std 7.25 / train/extr_return_normed_mag 2.04 / train/extr_return_normed_max 2.04 / train/extr_return_normed_mean 0.48 / 
train/extr_return_normed_min -0.07 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 73.65 / train/extr_return_raw_max 73.65 / train/extr_return_raw_mean 33.64 / train/extr_return_raw_min 19.57 / train/extr_return_raw_std 7.89 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.09 / train/extr_reward_min -3.1e-9 / train/extr_reward_std 0.38 / train/image_loss_mean 0.6 / train/image_loss_std 0.64 / train/model_loss_mean 2.05 / train/model_loss_std 3.66 / 
train/model_opt_grad_norm 10.02 / train/model_opt_grad_steps 2.2e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5463.92 / train/policy_entropy_mag 0.9 / train/policy_entropy_max 0.79 / 
train/policy_entropy_mean -0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.3 / train/policy_logprob_mag 7.55 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.46 / train/policy_logprob_min -7.55 / train/policy_logprob_std 0.77 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 3.4e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 53.37 / train/post_ent_max 53.37 / train/post_ent_mean 32.36 / 
train/post_ent_min 17.37 / train/post_ent_std 5.22 / train/prior_ent_mag 64.29 / train/prior_ent_max 64.29 / train/prior_ent_mean 34.83 / train/prior_ent_min 22.23 / train/prior_ent_std 5.98 / train/rep_loss_mean 2.37 / train/rep_loss_std 5.32 / train/reward_avg 0.08 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 0.99 / train/reward_pos_loss 0.43 / train/reward_pred 0.08 / train/reward_rate 0.05 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.61 / report/cont_avg 1 / report/cont_loss_mean 5.3e-10 / report/cont_loss_std 8.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.42 / report/dyn_loss_std 5.58 / report/image_loss_mean 0.57 / report/image_loss_std 0.62 / report/model_loss_mean 2.05 / report/model_loss_std 3.8 / report/post_ent_mag 54.92 / report/post_ent_max 54.92 / 
report/post_ent_mean 32.85 / report/post_ent_min 16.9 / report/post_ent_std 6.19 / report/prior_ent_mag 64.13 / report/prior_ent_max 64.13 / report/prior_ent_mean 35.51 / report/prior_ent_min 20.07 / report/prior_ent_std 6.89 / report/rep_loss_mean 2.42 / 
report/rep_loss_std 5.58 / report/reward_avg 0.07 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.46 / report/reward_pred 0.07 / report/reward_rate 0.04 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-10 / eval/cont_loss_std 3.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.39 / eval/dyn_loss_std 4.69 / eval/image_loss_mean 0.62 / eval/image_loss_std 1.2 / eval/model_loss_mean 2.06 / eval/model_loss_std 3.63 / eval/post_ent_mag 55.24 / eval/post_ent_max 55.24 / eval/post_ent_mean 
30.61 / eval/post_ent_min 19.91 / eval/post_ent_std 4.63 / eval/prior_ent_mag 64.13 / eval/prior_ent_max 64.13 / eval/prior_ent_mean 33.28 / eval/prior_ent_min 23.92 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 2.39 / eval/rep_loss_std 4.69 / eval/reward_avg 9.8e-3 / 
eval/reward_loss_mean 5.2e-3 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.68 / eval/reward_pred 9.7e-3 / eval/reward_rate 6.8e-3 / 
replay/size 4.7e4 / replay/inserts 3880 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 4.8e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.28 / timer/env.step_count 3880 / timer/env.step_total 19.49 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.59 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7888 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1940 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1940 / timer/agent.train_total 245.09 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.12 /
timer/agent.report_frac 4e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 
3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.76

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 121.0.
Starting evaluation at step 48000 Counter(48000) 47937
eval_Episode has 500 steps and return 147.0.
train_Episode has 500 steps and return 200.0.
Saved chunk: 20230921T224021F964716-2e4CrqvUUNIdw0EUknTP4c-0JRonfycaqApwBH09tRNuy-1024.npz
Starting evaluation at step 48500 Counter(48500) 48437
Saved chunk: 20230921T224052F805311-0iyh3jCwdXQ4E0kKMQ6S6P-2rEO78NTT9tzHIC2E2fQ9K-1024.npz
eval_Episode has 500 steps and return 199.0.
train_Episode has 500 steps and return 238.0.
Starting evaluation at step 49000 Counter(49000) 48937
eval_Episode has 500 steps and return 192.0.
train_Episode has 500 steps and return 176.0.
Saved chunk: 20230921T224141F822692-0JRonfycaqApwBH09tRNuy-5EXTUColst7wjstRL2gXWZ-1024.npz
Starting evaluation at step 49500 Counter(49500) 49437
eval_Episode has 500 steps and return 174.0.
Saved chunk: 20230921T224211F218879-2rEO78NTT9tzHIC2E2fQ9K-0rH0imJe6lhP4yHydx5ZAH-1024.npz
train_Episode has 500 steps and return 238.0.
Starting evaluation at step 50000 Counter(50000) 49937
eval_Episode has 500 steps and return 180.0.
train_Episode has 500 steps and return 244.0.
Saved chunk: 20230921T224301F036576-5EXTUColst7wjstRL2gXWZ-4RVfPgA5PtlfUvfangUI0U-1024.npz
Starting evaluation at step 50500 Counter(50500) 50437
eval_Episode has 500 steps and return 113.0.
Saved chunk: 20230921T224328F858204-0rH0imJe6lhP4yHydx5ZAH-7bQkatueXBXmaSz1AD9A8X-1024.npz
train_Episode has 500 steps and return 197.0.
Starting evaluation at step 51000 Counter(51000) 50937
eval_Episode has 500 steps and return 188.0.
train_Episode has 500 steps and return 190.0.
Saved chunk: 20230921T224420F217090-4RVfPgA5PtlfUvfangUI0U-6LC2sDSfdIq7SFuO4uwqpT-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 102806 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 190 / episode/reward_rate 0.2 / eval_episode/length 500 / eval_episode/score 188 / eval_episode/reward_rate 0.19 / train/action_mag 1.96 / train/action_max 1.91 / train/action_mean 0.29 / train/action_min -1.81 / train/action_std 0.87 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 2.4e4 / train/actor_opt_loss -190.25 / train/adv_mag 0.9 / train/adv_max 0.89 / train/adv_mean 0.02 / train/adv_min -0.45 / 
train/adv_std 0.06 / train/cont_avg 1 / train/cont_loss_mean 5.1e-10 / train/cont_loss_std 1.5e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.35 / 
train/dyn_loss_std 5.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.59 / train/extr_critic_critic_opt_grad_steps 2.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 76.88 / train/extr_critic_max 76.88 / train/extr_critic_mean 45.5 / train/extr_critic_min 23.64 / train/extr_critic_std 9.79 / train/extr_return_normed_mag 1.77 / train/extr_return_normed_max 1.77 / train/extr_return_normed_mean 0.52 / 
train/extr_return_normed_min -0.09 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 87.92 / train/extr_return_raw_max 87.92 / train/extr_return_raw_mean 46.16 / train/extr_return_raw_min 25.74 / train/extr_return_raw_std 10.41 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.11 / train/extr_reward_min -2.4e-9 / train/extr_reward_std 0.42 / train/image_loss_mean 0.57 / train/image_loss_std 0.62 / train/model_loss_mean 2.01 / train/model_loss_std 3.67 / 
train/model_opt_grad_norm 9.24 / train/model_opt_grad_steps 2.4e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5743.59 / train/policy_entropy_mag 0.88 / train/policy_entropy_max 0.66 / 
train/policy_entropy_mean -0.52 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 7.51 / train/policy_logprob_max 1.37 / train/policy_logprob_mean 0.52 / train/policy_logprob_min -7.51 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.67 / train/policy_randomness_max 0.67 / train/policy_randomness_mean 0.16 / train/policy_randomness_min 2.5e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 54.11 / train/post_ent_max 54.11 / train/post_ent_mean 33.84 / 
train/post_ent_min 17.94 / train/post_ent_std 5.56 / train/prior_ent_mag 65.23 / train/prior_ent_max 65.23 / train/prior_ent_mean 36.28 / train/prior_ent_min 23.17 / train/prior_ent_std 6.19 / train/rep_loss_mean 2.35 / train/rep_loss_std 5.36 / train/reward_avg 0.1 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.38 / train/reward_pred 0.1 / train/reward_rate 0.05 / 
train_stats/mean_log_entropy -0.65 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.8e-10 / report/cont_loss_std 9.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.8e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.27 / report/dyn_loss_std 5.36 / report/image_loss_mean 0.56 / report/image_loss_std 0.7 / report/model_loss_mean 1.96 / report/model_loss_std 3.72 / report/post_ent_mag 56.43 / report/post_ent_max 56.43 / 
report/post_ent_mean 35.8 / report/post_ent_min 18.44 / report/post_ent_std 5.52 / report/prior_ent_mag 66.25 / report/prior_ent_max 66.25 / report/prior_ent_mean 37.89 / report/prior_ent_min 26.17 / report/prior_ent_std 5.94 / report/rep_loss_mean 2.27 / 
report/rep_loss_std 5.36 / report/reward_avg 0.21 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.21 / report/reward_pred 0.21 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-10 / eval/cont_loss_std 4.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.46 / eval/dyn_loss_std 6.77 / eval/image_loss_mean 0.99 / eval/image_loss_std 2.03 / eval/model_loss_mean 3.07 / eval/model_loss_std 5.62 / eval/post_ent_mag 56.42 / eval/post_ent_max 56.42 / eval/post_ent_mean 
33.18 / eval/post_ent_min 15.87 / eval/post_ent_std 5.59 / eval/prior_ent_mag 66.25 / eval/prior_ent_max 66.25 / eval/prior_ent_mean 36.12 / eval/prior_ent_min 25.17 / eval/prior_ent_std 6.09 / eval/rep_loss_mean 3.46 / eval/rep_loss_std 6.77 / eval/reward_avg 0.01 / 
eval/reward_loss_mean 7.4e-3 / eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.85 / eval/reward_pred 9.7e-3 / eval/reward_rate 7.8e-3 / 
replay/size 5.1e4 / replay/inserts 3902 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.2e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3902 / timer/env.step_total 19.6 / timer/env.step_frac 0.07 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.69 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.1 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7409 / timer/agent.policy_total 16.09 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1951 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1951 / timer/agent.train_total 246.3 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 26

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 51500 Counter(51500) 51437
eval_Episode has 500 steps and return 204.0.
train_Episode has 500 steps and return 157.0.
Starting evaluation at step 52000 Counter(52000) 51937
Saved chunk: 20230921T224446F417484-7bQkatueXBXmaSz1AD9A8X-5ZYq36LEQNaHyiuPuFnReo-1024.npz
eval_Episode has 500 steps and return 205.0.
train_Episode has 500 steps and return 202.0.
Saved chunk: 20230921T224539F130020-6LC2sDSfdIq7SFuO4uwqpT-3tvQxjmSGmnpQV0lXMokwM-1024.npz
Starting evaluation at step 52500 Counter(52500) 52437
eval_Episode has 500 steps and return 135.0.
train_Episode has 500 steps and return 144.0.
Starting evaluation at step 53000 Counter(53000) 52937
Saved chunk: 20230921T224639F973669-5ZYq36LEQNaHyiuPuFnReo-5x1A2CbsoOpwTb7H1UaHUY-1024.npz
eval_Episode has 500 steps and return 207.0.
train_Episode has 500 steps and return 148.0.
Saved chunk: 20230921T224659F071915-3tvQxjmSGmnpQV0lXMokwM-0SdTVjj8NX2yOydXqjN0QE-1024.npz
Starting evaluation at step 53500 Counter(53500) 53437
eval_Episode has 500 steps and return 289.0.
train_Episode has 500 steps and return 299.0.
Starting evaluation at step 54000 Counter(54000) 53937
Saved chunk: 20230921T224757F722113-5x1A2CbsoOpwTb7H1UaHUY-27J4xIqKMYMyrZ2cVlCek5-1024.npz
eval_Episode has 500 steps and return 333.0.
train_Episode has 500 steps and return 212.0.
Saved chunk: 20230921T224818F311509-0SdTVjj8NX2yOydXqjN0QE-1Frh7zHAgXLQ2ZTaWuBbKH-1024.npz
Starting evaluation at step 54500 Counter(54500) 54437
eval_Episode has 500 steps and return 194.0.
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 55000 Counter(55000) 54937
Saved chunk: 20230921T224915F236785-27J4xIqKMYMyrZ2cVlCek5-56qdgAdg56ncqkMnVdW38G-1024.npz
eval_Episode has 500 steps and return 327.0.
train_Episode has 500 steps and return 334.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 110514 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 327 / eval_episode/reward_rate 0.33 / episode/length 500 / episode/score 334 / episode/reward_rate 0.34 / train/action_mag 1.87 / train/action_max 1.8 / train/action_mean 0.27 / train/action_min -1.77 / train/action_std 0.87 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2.6e4 / train/actor_opt_loss -170.86 / train/adv_mag 0.82 / train/adv_max 0.82 / train/adv_mean 0.02 / train/adv_min -0.39 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 4.5e-10 / train/cont_loss_std 1.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.5e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.33 / 
train/dyn_loss_std 5.37 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.55 / train/extr_critic_critic_opt_grad_steps 2.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 95.49 / train/extr_critic_max 95.49 / train/extr_critic_mean 61.52 / train/extr_critic_min 33.96 / train/extr_critic_std 12.11 / train/extr_return_normed_mag 1.64 / train/extr_return_normed_max 1.64 / train/extr_return_normed_mean 0.53 / 
train/extr_return_normed_min -0.09 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 107.54 / train/extr_return_raw_max 107.54 / train/extr_return_raw_mean 62.24 / train/extr_return_raw_min 36.59 / train/extr_return_raw_std 12.74 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.13 / train/extr_reward_min 0 / train/extr_reward_std 0.46 / train/image_loss_mean 0.55 / train/image_loss_std 0.6 / train/model_loss_mean 1.97 / train/model_loss_std 3.67 / 
train/model_opt_grad_norm 9.67 / train/model_opt_grad_steps 2.6e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5625 / train/policy_entropy_mag 0.88 / train/policy_entropy_max 0.58 / 
train/policy_entropy_mean -0.57 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.25 / train/policy_logprob_mag 7.46 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.57 / train/policy_logprob_min -7.46 / train/policy_logprob_std 0.75 / 
train/policy_randomness_mag 0.64 / train/policy_randomness_max 0.64 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 1.8e-3 / train/policy_randomness_std 0.11 / train/post_ent_mag 54.47 / train/post_ent_max 54.47 / train/post_ent_mean 35.36 / 
train/post_ent_min 18.53 / train/post_ent_std 5.79 / train/prior_ent_mag 66.17 / train/prior_ent_max 66.17 / train/prior_ent_mean 37.75 / train/prior_ent_min 24.04 / train/prior_ent_std 6.3 / train/rep_loss_mean 2.33 / train/rep_loss_std 5.37 / train/reward_avg 0.12 / 
train/reward_loss_mean 0.02 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.35 / train/reward_pred 0.12 / train/reward_rate 0.06 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.68 / report/cont_avg 1 / report/cont_loss_mean 3.5e-10 / report/cont_loss_std 1.2e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.26 / report/dyn_loss_std 4.99 / report/image_loss_mean 0.47 / report/image_loss_std 0.74 / report/model_loss_mean 1.84 / report/model_loss_std 3.58 / report/post_ent_mag 57.32 / report/post_ent_max 57.32 / 
report/post_ent_mean 34.98 / report/post_ent_min 17.83 / report/post_ent_std 6.2 / report/prior_ent_mag 66.45 / report/prior_ent_max 66.45 / report/prior_ent_mean 37.38 / report/prior_ent_min 24.18 / report/prior_ent_std 6.89 / report/rep_loss_mean 2.26 / 
report/rep_loss_std 4.99 / report/reward_avg 0.13 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.21 / report/reward_pred 0.13 / report/reward_rate 0.07 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-10 / eval/cont_loss_std 5.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.15 / eval/dyn_loss_std 4.42 / eval/image_loss_mean 0.48 / eval/image_loss_std 0.51 / eval/model_loss_mean 1.81 / eval/model_loss_std 2.94 / eval/post_ent_mag 57.69 / eval/post_ent_max 57.69 / eval/post_ent_mean 
34.84 / eval/post_ent_min 18.82 / eval/post_ent_std 6.32 / eval/prior_ent_mag 66.45 / eval/prior_ent_max 66.45 / eval/prior_ent_mean 37.13 / eval/prior_ent_min 20.23 / eval/prior_ent_std 6.94 / eval/rep_loss_mean 2.15 / eval/rep_loss_std 4.42 / eval/reward_avg 0.22 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.21 / eval/reward_pred 0.22 / eval/reward_rate 0.12 / 
replay/size 5.5e4 / replay/inserts 3854 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 5.6e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3854 / timer/env.step_total 19.34 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 378.74 / timer/replay._sample_frac 1.26 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-4 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.93 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.8e-4 / timer/agent.train_count 1927 / timer/agent.train_total 243.32 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.05 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.69

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T224937F349547-1Frh7zHAgXLQ2ZTaWuBbKH-4Xd7RnQ3W6SPmzOj1oB7VM-1024.npz
Starting evaluation at step 55500 Counter(55500) 55437
eval_Episode has 500 steps and return 292.0.
train_Episode has 500 steps and return 259.0.
Starting evaluation at step 56000 Counter(56000) 55937
Saved chunk: 20230921T225032F646020-56qdgAdg56ncqkMnVdW38G-5qHjGYqbpi77aXUZ0KmmHj-1024.npz
eval_Episode has 500 steps and return 300.0.
train_Episode has 500 steps and return 222.0.
Saved chunk: 20230921T225056F803688-4Xd7RnQ3W6SPmzOj1oB7VM-40pDWnzvpXTYepjQtgKeh8-1024.npz
Starting evaluation at step 56500 Counter(56500) 56437
eval_Episode has 500 steps and return 123.0.
train_Episode has 500 steps and return 319.0.
Starting evaluation at step 57000 Counter(57000) 56937
Saved chunk: 20230921T225151F017417-5qHjGYqbpi77aXUZ0KmmHj-65cStyprsUYerfAPr4PxVl-1024.npz
eval_Episode has 500 steps and return 267.0.
train_Episode has 500 steps and return 282.0.
Saved chunk: 20230921T225216F306692-40pDWnzvpXTYepjQtgKeh8-0H6PB84TiD0G6QqafSUv7T-1024.npz
Starting evaluation at step 57500 Counter(57500) 57437
eval_Episode has 500 steps and return 264.0.
train_Episode has 500 steps and return 235.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T225308F675694-65cStyprsUYerfAPr4PxVl-0000000000000000000000-870.npz
Saved chunk: 20230921T225335F457747-0H6PB84TiD0G6QqafSUv7T-0000000000000000000000-456.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 58000 Counter(58000) 57937
Saved chunk: 20230921T225308F675694-65cStyprsUYerfAPr4PxVl-40AtqWU3jvWaG9hhf31SsG-1024.npz
eval_Episode has 500 steps and return 310.0.
train_Episode has 500 steps and return 311.0.
Saved chunk: 20230921T225335F457747-0H6PB84TiD0G6QqafSUv7T-31lnMVuBYtl3tdceuQkNWb-1024.npz
Starting evaluation at step 58500 Counter(58500) 58437
eval_Episode has 500 steps and return 320.0.
train_Episode has 500 steps and return 246.0.
Starting evaluation at step 59000 Counter(59000) 58937
Saved chunk: 20230921T225426F283508-40AtqWU3jvWaG9hhf31SsG-0APOLyJ1Zvdp8EoV3x8GTI-1024.npz
eval_Episode has 500 steps and return 247.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 118222 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 247 / eval_episode/reward_rate 0.25 / episode/length 500 / episode/score 246 / episode/reward_rate 0.26 / train/action_mag 1.92 / train/action_max 1.81 / train/action_mean 0.23 / train/action_min -1.83 / train/action_std 0.88 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 2.8e4 / train/actor_opt_loss -151.05 / train/adv_mag 0.8 / train/adv_max 0.8 / train/adv_mean 0.02 / train/adv_min -0.39 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 4e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.32 / 
train/dyn_loss_std 5.36 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.56 / train/extr_critic_critic_opt_grad_steps 2.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 117.15 / train/extr_critic_max 117.15 / train/extr_critic_mean 78.27 / train/extr_critic_min 44.02 / train/extr_critic_std 14.34 / train/extr_return_normed_mag 1.53 / train/extr_return_normed_max 1.53 / train/extr_return_normed_mean 0.53 / 
train/extr_return_normed_min -0.1 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 128.36 / train/extr_return_raw_max 128.36 / train/extr_return_raw_mean 79.04 / train/extr_return_raw_min 47.45 / train/extr_return_raw_std 14.99 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.15 / train/extr_reward_min 0 / train/extr_reward_std 0.51 / train/image_loss_mean 0.52 / train/image_loss_std 0.59 / train/model_loss_mean 1.94 / train/model_loss_std 3.66 / 
train/model_opt_grad_norm 8.66 / train/model_opt_grad_steps 2.8e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5699.48 / train/policy_entropy_mag 0.88 / train/policy_entropy_max 0.65 / 
train/policy_entropy_mean -0.58 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.26 / train/policy_logprob_mag 7.54 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.58 / train/policy_logprob_min -7.54 / train/policy_logprob_std 0.75 / 
train/policy_randomness_mag 0.67 / train/policy_randomness_max 0.67 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 1.4e-3 / train/policy_randomness_std 0.11 / train/post_ent_mag 56.17 / train/post_ent_max 56.17 / train/post_ent_mean 36.51 / 
train/post_ent_min 18.8 / train/post_ent_std 6 / train/prior_ent_mag 67.04 / train/prior_ent_max 67.04 / train/prior_ent_mean 38.84 / train/prior_ent_min 24.1 / train/prior_ent_std 6.41 / train/rep_loss_mean 2.32 / train/rep_loss_std 5.36 / train/reward_avg 0.14 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.32 / train/reward_pred 0.14 / train/reward_rate 0.08 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.69 / report/cont_avg 1 / report/cont_loss_mean 3.1e-10 / report/cont_loss_std 6.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.23 / report/dyn_loss_std 5.41 / report/image_loss_mean 0.51 / report/image_loss_std 0.58 / report/model_loss_mean 1.87 / report/model_loss_std 3.59 / report/post_ent_mag 58.26 / report/post_ent_max 58.26 / 
report/post_ent_mean 35.54 / report/post_ent_min 19.88 / report/post_ent_std 6.86 / report/prior_ent_mag 68.26 / report/prior_ent_max 68.26 / report/prior_ent_mean 37.58 / report/prior_ent_min 21.21 / report/prior_ent_std 7.45 / report/rep_loss_mean 2.23 / 
report/rep_loss_std 5.41 / report/reward_avg 0.14 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.26 / report/reward_pred 0.14 / report/reward_rate 0.07 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-10 / eval/cont_loss_std 1.4e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 2.89 / eval/dyn_loss_std 5.85 / eval/image_loss_mean 0.69 / eval/image_loss_std 1.1 / eval/model_loss_mean 2.44 / eval/model_loss_std 4.23 / eval/post_ent_mag 58.42 / eval/post_ent_max 58.42 / eval/post_ent_mean 33.7 / eval/post_ent_min 18.44 / 
eval/post_ent_std 6.68 / eval/prior_ent_mag 68.26 / eval/prior_ent_max 68.26 / eval/prior_ent_mean 36.26 / eval/prior_ent_min 20.47 / eval/prior_ent_std 7.3 / eval/rep_loss_mean 2.89 / eval/rep_loss_std 5.85 / eval/reward_avg 0.03 / eval/reward_loss_mean 0.01 / 
eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.46 / eval/reward_pred 0.03 / eval/reward_rate 0.02 / replay/size 5.9e4 / replay/inserts 3854 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3854 / timer/env.step_total 19.3 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 381.88 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7862 / timer/agent.policy_total 16.97 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4e-4 / 
timer/agent.train_count 1927 / timer/agent.train_total 243.37 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / 
timer/dataset_eval_max 3.8e-5 / fps 25.69

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 299.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T225454F538328-31lnMVuBYtl3tdceuQkNWb-5aeLG1RIl3vOa9LUfPch0z-1024.npz
Starting evaluation at step 59500 Counter(59500) 59437
eval_Episode has 500 steps and return 336.0.
train_Episode has 500 steps and return 320.0.
Starting evaluation at step 60000 Counter(60000) 59937
Saved chunk: 20230921T225543F575183-0APOLyJ1Zvdp8EoV3x8GTI-3fGkiHV6r4SdnBlfVYbB3X-1024.npz
eval_Episode has 500 steps and return 333.0.
train_Episode has 500 steps and return 253.0.
Saved chunk: 20230921T225614F095641-5aeLG1RIl3vOa9LUfPch0z-4fVkpttWxc8qsr4GPEwcNj-1024.npz
Starting evaluation at step 60500 Counter(60500) 60437
eval_Episode has 500 steps and return 286.0.
train_Episode has 500 steps and return 322.0.
Starting evaluation at step 61000 Counter(61000) 60937
Saved chunk: 20230921T225701F920986-3fGkiHV6r4SdnBlfVYbB3X-5DJlY45FLjFMV6jjd7HeWH-1024.npz
eval_Episode has 500 steps and return 312.0.
train_Episode has 500 steps and return 222.0.
Saved chunk: 20230921T225734F074392-4fVkpttWxc8qsr4GPEwcNj-1bHVwmAbsE1uaROOXlCSPZ-1024.npz
Starting evaluation at step 61500 Counter(61500) 61437
eval_Episode has 500 steps and return 201.0.
train_Episode has 500 steps and return 381.0.
Starting evaluation at step 62000 Counter(62000) 61937
Saved chunk: 20230921T225820F126236-5DJlY45FLjFMV6jjd7HeWH-2cDj91uJXcMNyblh35oxAk-1024.npz
eval_Episode has 500 steps and return 226.0.
train_Episode has 500 steps and return 342.0.
Saved chunk: 20230921T225853F122772-1bHVwmAbsE1uaROOXlCSPZ-5s14bfQTkGvUB67IHCE7mk-1024.npz
Starting evaluation at step 62500 Counter(62500) 62437
eval_Episode has 500 steps and return 307.0.
train_Episode has 500 steps and return 357.0.
Starting evaluation at step 63000 Counter(63000) 62937
Saved chunk: 20230921T225937F533551-2cDj91uJXcMNyblh35oxAk-4KuDbOnMiQoLjnx5lJVdKS-1024.npz
eval_Episode has 500 steps and return 274.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 126002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 357 / episode/reward_rate 0.36 / eval_episode/length 500 / eval_episode/score 274 / eval_episode/reward_rate 0.28 / train_stats/mean_log_entropy -0.73 / train/action_mag 1.95 / train/action_max 1.8 / train/action_mean 0.22 / 
train/action_min -1.87 / train/action_std 0.87 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 3e4 / train/actor_opt_loss -143.5 / train/adv_mag 0.88 / train/adv_max 0.88 
/ train/adv_mean 0.01 / train/adv_min -0.43 / train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 3.6e-10 / train/cont_loss_std 1.4e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-10 / train/cont_pred 1 / 
train/cont_rate 1 / train/dyn_loss_mean 2.3 / train/dyn_loss_std 5.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.58 / train/extr_critic_critic_opt_grad_steps
3e4 / train/extr_critic_critic_opt_loss 1e4 / train/extr_critic_mag 138.42 / train/extr_critic_max 138.42 / train/extr_critic_mean 95.32 / train/extr_critic_min 55.4 / train/extr_critic_std 16.28 / train/extr_return_normed_mag 1.46 / train/extr_return_normed_max 1.46 / 
train/extr_return_normed_mean 0.53 / train/extr_return_normed_min -0.12 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 149.19 / train/extr_return_raw_max 149.19 / train/extr_return_raw_mean 96.16 / train/extr_return_raw_min 59.26
/ train/extr_return_raw_std 17.01 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.19 / train/extr_reward_min 0 / train/extr_reward_std 0.56 / train/image_loss_mean 0.5 / train/image_loss_std 0.57 / train/model_loss_mean 1.91 / 
train/model_loss_std 3.64 / train/model_opt_grad_norm 9.22 / train/model_opt_grad_steps 3e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6769.23 / train/policy_entropy_mag 0.88 / train/policy_entropy_max 
0.71 / train/policy_entropy_mean -0.62 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.25 / train/policy_logprob_mag 7.25 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.62 / train/policy_logprob_min -7.25 / train/policy_logprob_std 0.75 / 
train/policy_randomness_mag 0.69 / train/policy_randomness_max 0.69 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 1.2e-3 / train/policy_randomness_std 0.11 / train/post_ent_mag 56.55 / train/post_ent_max 56.55 / train/post_ent_mean 37.68 / 
train/post_ent_min 19.41 / train/post_ent_std 6.05 / train/prior_ent_mag 67.99 / train/prior_ent_max 67.99 / train/prior_ent_mean 39.95 / train/prior_ent_min 24.83 / train/prior_ent_std 6.43 / train/rep_loss_mean 2.3 / train/rep_loss_std 5.35 / train/reward_avg 0.18 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.28 / train/reward_pred 0.18 / train/reward_rate 0.1 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-10 / report/cont_loss_std 5.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 2.36 / report/dyn_loss_std 5.46 / report/image_loss_mean 0.52 / report/image_loss_std 0.54 / report/model_loss_mean 1.98 / report/model_loss_std 3.75 / report/post_ent_mag 47.31 / report/post_ent_max 47.31 / report/post_ent_mean 39.82 / 
report/post_ent_min 22.52 / report/post_ent_std 5.08 / report/prior_ent_mag 68.79 / report/prior_ent_max 68.79 / report/prior_ent_mean 41.89 / report/prior_ent_min 25.97 / report/prior_ent_std 5.59 / report/rep_loss_mean 2.36 / report/rep_loss_std 5.46 / report/reward_avg
0.14 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.3 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 0.98 / report/reward_pos_loss 0.53 / report/reward_pred 0.14 / 
report/reward_rate 0.08 / eval/cont_avg 1 / eval/cont_loss_mean 2.4e-10 / eval/cont_loss_std 9.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.4e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.72 / 
eval/dyn_loss_std 5.96 / eval/image_loss_mean 0.56 / eval/image_loss_std 0.74 / eval/model_loss_mean 2.22 / eval/model_loss_std 4.11 / eval/post_ent_mag 60.08 / eval/post_ent_max 60.08 / eval/post_ent_mean 34.73 / eval/post_ent_min 15.29 / eval/post_ent_std 7.25 / 
eval/prior_ent_mag 68.79 / eval/prior_ent_max 68.79 / eval/prior_ent_mean 37.35 / eval/prior_ent_min 21.71 / eval/prior_ent_std 7.59 / eval/rep_loss_mean 2.72 / eval/rep_loss_std 5.96 / eval/reward_avg 0.05 / eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.37 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 0.97 / eval/reward_pos_loss 0.55 / eval/reward_pred 0.04 / eval/reward_rate 0.03 / replay/size 6.3e4 / replay/inserts 3890 / replay/samples 3.1e4 /
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.4e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 303.05 / timer/env.step_count 3890 / timer/env.step_total 19.48 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.4e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.37 / timer/replay._sample_frac 1.27 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7898 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.08 / timer/dataset_train_count 1945 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 4.9e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1945 / timer/agent.train_total 245.94 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.76 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 244.0.
Saved chunk: 20230921T230011F984426-5s14bfQTkGvUB67IHCE7mk-1kggrQjY4jQ2S0ANFOuG7T-1024.npz
Starting evaluation at step 63500 Counter(63500) 63437
eval_Episode has 500 steps and return 240.0.
train_Episode has 500 steps and return 321.0.
Starting evaluation at step 64000 Counter(64000) 63937
Saved chunk: 20230921T230054F903777-4KuDbOnMiQoLjnx5lJVdKS-6bj7xiCdFvKx7pyw4dCWIE-1024.npz
eval_Episode has 500 steps and return 337.0.
train_Episode has 500 steps and return 328.0.
Starting evaluation at step 64500 Counter(64500) 64437
eval_Episode has 500 steps and return 337.0.
Saved chunk: 20230921T230131F731785-1kggrQjY4jQ2S0ANFOuG7T-4tpCuzcjz0viwTmHOYOZLw-1024.npz
train_Episode has 500 steps and return 271.0.
Starting evaluation at step 65000 Counter(65000) 64937
Saved chunk: 20230921T230213F283553-6bj7xiCdFvKx7pyw4dCWIE-7eMuHscV2upXyP0gSJszcw-1024.npz
eval_Episode has 500 steps and return 333.0.
train_Episode has 500 steps and return 306.0.
Starting evaluation at step 65500 Counter(65500) 65437
eval_Episode has 500 steps and return 369.0.
Saved chunk: 20230921T230254F330111-4tpCuzcjz0viwTmHOYOZLw-6HqOTV4sLlNXc9d6NTuMul-1024.npz
train_Episode has 500 steps and return 307.0.
Starting evaluation at step 66000 Counter(66000) 65937
Saved chunk: 20230921T230330F801920-7eMuHscV2upXyP0gSJszcw-5ILrzeHMHaZ5v6IZYY2tAH-1024.npz
eval_Episode has 500 steps and return 333.0.
train_Episode has 500 steps and return 342.0.
Starting evaluation at step 66500 Counter(66500) 66437
eval_Episode has 500 steps and return 342.0.
Saved chunk: 20230921T230413F212425-6HqOTV4sLlNXc9d6NTuMul-4FoJUv4uyHWme1whjJlPWX-1024.npz
train_Episode has 500 steps and return 274.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 133814 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 274 / episode/reward_rate 0.28 / eval_episode/length 500 / eval_episode/score 342 / eval_episode/reward_rate 0.35 / train/action_mag 2.05 / train/action_max 1.91 / train/action_mean 0.18 / train/action_min -1.94 / train/action_std 0.87 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 3.2e4 / train/actor_opt_loss -131.77 / train/adv_mag 0.87 / train/adv_max 0.86 / train/adv_mean 0.01 / train/adv_min -0.45 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 3e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.31 / 
train/dyn_loss_std 5.41 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.56 / train/extr_critic_critic_opt_grad_steps 3.2e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 161.49 / train/extr_critic_max 161.49 / train/extr_critic_mean 112 / train/extr_critic_min 65.84 / train/extr_critic_std 18.99 / train/extr_return_normed_mag 1.42 / train/extr_return_normed_max 1.42 / train/extr_return_normed_mean 0.52 / 
train/extr_return_normed_min -0.11 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 172.39 / train/extr_return_raw_max 172.39 / train/extr_return_raw_mean 112.9 / train/extr_return_raw_min 70.88 / train/extr_return_raw_std 19.8 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.22 / train/extr_reward_min 0 / train/extr_reward_std 0.6 / train/image_loss_mean 0.49 / train/image_loss_std 0.58 / train/model_loss_mean 1.91 / train/model_loss_std 3.68 / 
train/model_opt_grad_norm 8.73 / train/model_opt_grad_steps 3.2e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 5.1e-3 / train/model_opt_model_opt_grad_scale 6102.56 / train/policy_entropy_mag 0.91 / train/policy_entropy_max 0.82 / 
train/policy_entropy_mean -0.62 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 7.61 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.62 / train/policy_logprob_min -7.61 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 8.9e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 57.58 / train/post_ent_max 57.58 / train/post_ent_mean 38.48 / 
train/post_ent_min 19.66 / train/post_ent_std 6.05 / train/prior_ent_mag 68.83 / train/prior_ent_max 68.83 / train/prior_ent_mean 40.72 / train/prior_ent_min 25.16 / train/prior_ent_std 6.41 / train/rep_loss_mean 2.31 / train/rep_loss_std 5.41 / train/reward_avg 0.21 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.25 / train/reward_pred 0.21 / train/reward_rate 0.11 / 
train_stats/mean_log_entropy -0.74 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-10 / report/cont_loss_std 2.7e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.24 / report/dyn_loss_std 5.66 / report/image_loss_mean 0.51 / report/image_loss_std 0.73 / report/model_loss_mean 1.87 / report/model_loss_std 3.94 / report/post_ent_mag 60.19 / report/post_ent_max 60.19 / 
report/post_ent_mean 36.36 / report/post_ent_min 18.38 / report/post_ent_std 6.72 / report/prior_ent_mag 69.26 / report/prior_ent_max 69.26 / report/prior_ent_mean 38.67 / report/prior_ent_min 20.78 / report/prior_ent_std 7.38 / report/rep_loss_mean 2.24 / 
report/rep_loss_std 5.66 / report/reward_avg 0.1 / report/reward_loss_mean 0.01 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.2 / report/reward_pred 0.1 / report/reward_rate 0.05 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-10 / eval/cont_loss_std 8.3e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 2.48 / eval/dyn_loss_std 5.71 / eval/image_loss_mean 0.52 / eval/image_loss_std 0.61 / eval/model_loss_mean 2.04 / eval/model_loss_std 3.84 / eval/post_ent_mag 60.23 / eval/post_ent_max 60.23 / eval/post_ent_mean 37.91 / eval/post_ent_min 15.02 / 
eval/post_ent_std 6.2 / eval/prior_ent_mag 69.26 / eval/prior_ent_max 69.26 / eval/prior_ent_mean 40.58 / eval/prior_ent_min 24.72 / eval/prior_ent_std 6.6 / eval/rep_loss_mean 2.48 / eval/rep_loss_std 5.71 / eval/reward_avg 0.04 / eval/reward_loss_mean 0.03 / 
eval/reward_loss_std 0.27 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.38 / eval/reward_pred 0.05 / eval/reward_rate 0.03 / replay/size 6.7e4 / replay/inserts 3906
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 6.7e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3906 / timer/env.step_total 19.55 / timer/env.step_frac 0.07 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.28 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.7e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7413 / timer/agent.policy_total 16.04 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 
1953 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1953 / timer/agent.train_total 246.33 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 26.04

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 67000 Counter(67000) 66937
Saved chunk: 20230921T230448F124924-5ILrzeHMHaZ5v6IZYY2tAH-1YT4okyGcvYIVSRaN7Me0A-1024.npz
eval_Episode has 500 steps and return 285.0.
train_Episode has 500 steps and return 337.0.
Starting evaluation at step 67500 Counter(67500) 67437
eval_Episode has 500 steps and return 325.0.
Saved chunk: 20230921T230532F170086-4FoJUv4uyHWme1whjJlPWX-2y5nnZxyoOWu3UpETOSqpB-1024.npz
train_Episode has 500 steps and return 341.0.
Starting evaluation at step 68000 Counter(68000) 67937
Saved chunk: 20230921T230606F268015-1YT4okyGcvYIVSRaN7Me0A-2uyng9dpwGk3F6XNyP0ulc-1024.npz
eval_Episode has 500 steps and return 344.0.
train_Episode has 500 steps and return 471.0.
Starting evaluation at step 68500 Counter(68500) 68437
eval_Episode has 500 steps and return 333.0.
Saved chunk: 20230921T230652F138314-2y5nnZxyoOWu3UpETOSqpB-6URv1clSzXl1QVCr5JJVBx-1024.npz
train_Episode has 500 steps and return 291.0.
Starting evaluation at step 69000 Counter(69000) 68937
Saved chunk: 20230921T230724F133151-2uyng9dpwGk3F6XNyP0ulc-5iXp8ljRKpUgqV9pgrhEwf-1024.npz
eval_Episode has 500 steps and return 325.0.
train_Episode has 500 steps and return 336.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 69500 Counter(69500) 69437
Saved chunk: 20230921T230841F629497-5iXp8ljRKpUgqV9pgrhEwf-0000000000000000000000-105.npz
Saved chunk: 20230921T230811F321861-6URv1clSzXl1QVCr5JJVBx-0000000000000000000000-892.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
eval_Episode has 500 steps and return 329.0.
Saved chunk: 20230921T230811F321861-6URv1clSzXl1QVCr5JJVBx-6T4QhvgM1z5PpZYGXPa3qM-1024.npz
train_Episode has 500 steps and return 334.0.
Starting evaluation at step 70000 Counter(70000) 69937
Saved chunk: 20230921T230841F629497-5iXp8ljRKpUgqV9pgrhEwf-7pQ9R8jlGCYNN6VlG2nOpX-1024.npz
eval_Episode has 500 steps and return 414.0.
train_Episode has 500 steps and return 341.0.
Starting evaluation at step 70500 Counter(70500) 70437
eval_Episode has 500 steps and return 282.0.
train_Episode has 500 steps and return 326.0.
Saved chunk: 20230921T230930F653932-6T4QhvgM1z5PpZYGXPa3qM-04c9bfKKnJEKpTgbpxYWc5-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 141514 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 282 / eval_episode/reward_rate 0.29 / episode/length 500 / episode/score 326 / episode/reward_rate 0.33 / train/action_mag 2.08 / train/action_max 2.01 / train/action_mean 0.19 / train/action_min -1.86 / train/action_std 0.87 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 3.4e4 / train/actor_opt_loss -114.26 / train/adv_mag 0.81 / train/adv_max 0.8 / train/adv_mean 0.01 / train/adv_min -0.47 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.6e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.27 / 
train/dyn_loss_std 5.33 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.55 / train/extr_critic_critic_opt_grad_steps 3.4e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 182.3 / train/extr_critic_max 182.3 / train/extr_critic_mean 127.36 / train/extr_critic_min 74.23 / train/extr_critic_std 21.66 / train/extr_return_normed_mag 1.37 / train/extr_return_normed_max 1.37 / train/extr_return_normed_mean 0.51 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 192.48 / train/extr_return_raw_max 192.48 / train/extr_return_raw_mean 128.24 / train/extr_return_raw_min 78.89 / train/extr_return_raw_std 22.37 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.24 / train/extr_reward_min 0 / train/extr_reward_std 0.63 / train/image_loss_mean 0.47 / train/image_loss_std 0.55 / train/model_loss_mean 1.86 / train/model_loss_std 3.61 / 
train/model_opt_grad_norm 8.66 / train/model_opt_grad_steps 3.4e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5494.79 / train/policy_entropy_mag 0.93 / train/policy_entropy_max 0.86 / 
train/policy_entropy_mean -0.62 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.28 / train/policy_logprob_mag 7.45 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.62 / train/policy_logprob_min -7.45 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.76 / train/policy_randomness_max 0.76 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 6.9e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 58.53 / train/post_ent_max 58.53 / train/post_ent_mean 39.02 / 
train/post_ent_min 19.89 / train/post_ent_std 6.07 / train/prior_ent_mag 69.62 / train/prior_ent_max 69.62 / train/prior_ent_mean 41.2 / train/prior_ent_min 25.53 / train/prior_ent_std 6.45 / train/rep_loss_mean 2.27 / train/rep_loss_std 5.33 / train/reward_avg 0.23 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.25 / train/reward_pred 0.23 / train/reward_rate 0.12 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.74 / report/cont_avg 1 / report/cont_loss_mean 2.4e-10 / report/cont_loss_std 6.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.13 / report/dyn_loss_std 5.02 / report/image_loss_mean 0.45 / report/image_loss_std 0.54 / report/model_loss_mean 1.77 / report/model_loss_std 3.45 / report/post_ent_mag 61.31 / report/post_ent_max 61.31 / 
report/post_ent_mean 41.63 / report/post_ent_min 22.16 / report/post_ent_std 4.55 / report/prior_ent_mag 69.41 / report/prior_ent_max 69.41 / report/prior_ent_mean 43.47 / report/prior_ent_min 29.19 / report/prior_ent_std 4.9 / report/rep_loss_mean 2.13 / 
report/rep_loss_std 5.02 / report/reward_avg 0.24 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.27 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 0.01 / report/reward_pos_acc 0.99 / 
report/reward_pos_loss 0.24 / report/reward_pred 0.23 / report/reward_rate 0.12 / eval/cont_avg 1 / eval/cont_loss_mean 1.6e-10 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.6e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.44 / eval/dyn_loss_std 5.54 / eval/image_loss_mean 0.48 / eval/image_loss_std 0.57 / eval/model_loss_mean 1.96 / eval/model_loss_std 3.72 / eval/post_ent_mag 61.64 / eval/post_ent_max 61.64 / eval/post_ent_mean 
39.48 / eval/post_ent_min 18.57 / eval/post_ent_std 6.16 / eval/prior_ent_mag 69.41 / eval/prior_ent_max 69.41 / eval/prior_ent_mean 41.68 / eval/prior_ent_min 26.14 / eval/prior_ent_std 6.42 / eval/rep_loss_mean 2.44 / eval/rep_loss_std 5.54 / eval/reward_avg 0.08 / 
eval/reward_loss_mean 0.02 / eval/reward_loss_std 0.2 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.51 / eval/reward_pred 0.08 / eval/reward_rate 0.04 / replay/size 
7.1e4 / replay/inserts 3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3850 / timer/env.step_total 19.41 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 3.8e-3 / timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.16 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7858 / timer/agent.policy_total 17.29 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1925 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1925 / timer/agent.train_total 242.8 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.21 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 71000 Counter(71000) 70937
Saved chunk: 20230921T230959F363406-7pQ9R8jlGCYNN6VlG2nOpX-5Rr10WJ2BhdSeFGZHqrP7a-1024.npz
eval_Episode has 500 steps and return 286.0.
train_Episode has 500 steps and return 308.0.
Starting evaluation at step 71500 Counter(71500) 71437
eval_Episode has 500 steps and return 436.0.
train_Episode has 500 steps and return 613.0.
Saved chunk: 20230921T231049F537411-04c9bfKKnJEKpTgbpxYWc5-39k4bZujmPTeYV37VMr36c-1024.npz
Starting evaluation at step 72000 Counter(72000) 71937
Saved chunk: 20230921T231117F485979-5Rr10WJ2BhdSeFGZHqrP7a-3cYeefNKKGJa9XzEHu0zqi-1024.npz
eval_Episode has 500 steps and return 712.0.
train_Episode has 500 steps and return 328.0.
Starting evaluation at step 72500 Counter(72500) 72437
eval_Episode has 500 steps and return 334.0.
train_Episode has 500 steps and return 322.0.
Saved chunk: 20230921T231209F446679-39k4bZujmPTeYV37VMr36c-2Hb9mxGw33VMVFptTtsKTl-1024.npz
Starting evaluation at step 73000 Counter(73000) 72937
eval_Episode has 500 steps and return 277.0.
Saved chunk: 20230921T231235F193068-3cYeefNKKGJa9XzEHu0zqi-7jvyMCyaZUI7AS4DhzCGDs-1024.npz
train_Episode has 500 steps and return 344.0.
Starting evaluation at step 73500 Counter(73500) 73437
eval_Episode has 500 steps and return 380.0.
train_Episode has 500 steps and return 386.0.
Saved chunk: 20230921T231328F630070-2Hb9mxGw33VMVFptTtsKTl-5UXgAVRWSgY4wM134fLcEi-1024.npz
Starting evaluation at step 74000 Counter(74000) 73937
eval_Episode has 500 steps and return 360.0.
train_Episode has 500 steps and return 372.0.
Starting evaluation at step 74500 Counter(74500) 74437
Saved chunk: 20230921T231352F796380-7jvyMCyaZUI7AS4DhzCGDs-4JaeBP04EvBB00QstZZ2Hw-1024.npz
eval_Episode has 500 steps and return 415.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 149230 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 415 / eval_episode/reward_rate 0.42 / episode/length 500 / episode/score 372 / episode/reward_rate 0.38 / train/action_mag 2.05 / train/action_max 1.99 / train/action_mean 0.17 / train/action_min -1.8 / train/action_std 0.88 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 3.6e4 / train/actor_opt_loss -111.41 / train/adv_mag 0.78 / train/adv_max 0.77 / train/adv_mean 0.01 / train/adv_min -0.46 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.4e-10 / train/cont_loss_std 9.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.26 / 
train/dyn_loss_std 5.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.5 / train/extr_critic_critic_opt_grad_steps 3.6e4 / train/extr_critic_critic_opt_loss 1e4 
/ train/extr_critic_mag 205.28 / train/extr_critic_max 205.28 / train/extr_critic_mean 144.08 / train/extr_critic_min 87.29 / train/extr_critic_std 23.38 / train/extr_return_normed_mag 1.38 / train/extr_return_normed_max 1.38 / train/extr_return_normed_mean 0.52 / 
train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 214.8 / train/extr_return_raw_max 214.8 / train/extr_return_raw_mean 145.01 / train/extr_return_raw_min 92.4 / train/extr_return_raw_std 24.14 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.27 / train/extr_reward_min 0 / train/extr_reward_std 0.66 / train/image_loss_mean 0.45 / train/image_loss_std 0.54 / train/model_loss_mean 1.84 / train/model_loss_std 3.62 / 
train/model_opt_grad_norm 8.97 / train/model_opt_grad_steps 3.6e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5751.3 / train/policy_entropy_mag 0.92 / train/policy_entropy_max 0.82 / 
train/policy_entropy_mean -0.63 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 7.45 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.63 / train/policy_logprob_min -7.45 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.74 / train/policy_randomness_max 0.74 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 5.5e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 57.55 / train/post_ent_max 57.55 / train/post_ent_mean 39.79 / 
train/post_ent_min 20.2 / train/post_ent_std 5.96 / train/prior_ent_mag 70.34 / train/prior_ent_max 70.34 / train/prior_ent_mean 41.91 / train/prior_ent_min 25.6 / train/prior_ent_std 6.38 / train/rep_loss_mean 2.26 / train/rep_loss_std 5.35 / train/reward_avg 0.26 / 
train/reward_loss_mean 0.03 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.23 / train/reward_pred 0.26 / train/reward_rate 0.14 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.78 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 5.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.42 / report/dyn_loss_std 6.08 / report/image_loss_mean 0.44 / report/image_loss_std 0.59 / report/model_loss_mean 1.93 / report/model_loss_std 4.09 / report/post_ent_mag 61.72 / report/post_ent_max 61.72 / 
report/post_ent_mean 38.67 / report/post_ent_min 19 / report/post_ent_std 6.99 / report/prior_ent_mag 70.7 / report/prior_ent_max 70.7 / report/prior_ent_mean 40.83 / report/prior_ent_min 26.19 / report/prior_ent_std 7.13 / report/rep_loss_mean 2.42 / report/rep_loss_std 
6.08 / report/reward_avg 0.45 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.14 / 
report/reward_pred 0.45 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 2e-10 / eval/cont_loss_std 8.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 2.44 / eval/dyn_loss_std 5.71 / eval/image_loss_mean 0.45 / eval/image_loss_std 0.62 / eval/model_loss_mean 1.94 / eval/model_loss_std 3.84 / eval/post_ent_mag 61.72 / eval/post_ent_max 61.72 / eval/post_ent_mean 38.08 / eval/post_ent_min 18.53 / 
eval/post_ent_std 6.64 / eval/prior_ent_mag 70.7 / eval/prior_ent_max 70.7 / eval/prior_ent_mean 40.48 / eval/prior_ent_min 26.53 / eval/prior_ent_std 7.06 / eval/rep_loss_mean 2.44 / eval/rep_loss_std 5.71 / eval/reward_avg 0.08 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.36 / eval/reward_pred 0.08 / eval/reward_rate 0.04 / replay/size 7.5e4 / replay/inserts 3858 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3858 / timer/env.step_total 19.41 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 3.8e-3 / 
timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.37 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-4 / timer/replay._sample_max 0.11 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7866 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.4e-3 / timer/dataset_train_count 
1929 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1929 / timer/agent.train_total 243.33 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.71

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 430.0.
Saved chunk: 20230921T231447F678088-5UXgAVRWSgY4wM134fLcEi-46lNLeYf0vzW7vkLocUL2Q-1024.npz
Starting evaluation at step 75000 Counter(75000) 74937
eval_Episode has 500 steps and return 452.0.
train_Episode has 500 steps and return 443.0.
Starting evaluation at step 75500 Counter(75500) 75437
Saved chunk: 20230921T231545F358568-4JaeBP04EvBB00QstZZ2Hw-24KfnEGSAbNYBA39YLD9ya-1024.npz
eval_Episode has 500 steps and return 501.0.
train_Episode has 500 steps and return 569.0.
Saved chunk: 20230921T231607F075075-46lNLeYf0vzW7vkLocUL2Q-0QumnVKnhFSqqT6skm37pY-1024.npz
Starting evaluation at step 76000 Counter(76000) 75937
eval_Episode has 500 steps and return 457.0.
train_Episode has 500 steps and return 564.0.
Starting evaluation at step 76500 Counter(76500) 76437
Saved chunk: 20230921T231703F743532-24KfnEGSAbNYBA39YLD9ya-5zI8feUAMsNwiwRAH6PiS5-1024.npz
eval_Episode has 500 steps and return 443.0.
train_Episode has 500 steps and return 475.0.
Saved chunk: 20230921T231726F429667-0QumnVKnhFSqqT6skm37pY-5o78a7oKuswE82no5zdlST-1024.npz
Starting evaluation at step 77000 Counter(77000) 76937
eval_Episode has 500 steps and return 456.0.
train_Episode has 500 steps and return 425.0.
Starting evaluation at step 77500 Counter(77500) 77437
Saved chunk: 20230921T231821F266578-5zI8feUAMsNwiwRAH6PiS5-6adz5tviD1W5wpWNjurDmi-1024.npz
eval_Episode has 500 steps and return 577.0.
train_Episode has 500 steps and return 353.0.
Saved chunk: 20230921T231845F491242-5o78a7oKuswE82no5zdlST-6XlwzQKz3gImuKbt7MUiJw-1024.npz
Starting evaluation at step 78000 Counter(78000) 77937
eval_Episode has 500 steps and return 459.0.
train_Episode has 500 steps and return 338.0.
Starting evaluation at step 78500 Counter(78500) 78437
Saved chunk: 20230921T231938F638160-6adz5tviD1W5wpWNjurDmi-3ebF3eUQpyAmU6rYv1jj8w-1024.npz
eval_Episode has 500 steps and return 571.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 157002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 338 / episode/reward_rate 0.34 / eval_episode/length 500 / eval_episode/score 571 / eval_episode/reward_rate 0.57 / train/action_mag 2.19 / train/action_max 2.14 / train/action_mean 0.15 / train/action_min -1.88 / train/action_std 0.87 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 3.8e4 / train/actor_opt_loss -99.67 / train/adv_mag 0.85 / train/adv_max 0.84 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.4e-10 / train/cont_loss_std 1.1e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.4e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.23 / 
train/dyn_loss_std 5.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.53 / train/extr_critic_critic_opt_grad_steps 3.8e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 230.68 / train/extr_critic_max 230.68 / train/extr_critic_mean 161.94 / train/extr_critic_min 93.93 / train/extr_critic_std 26.4 / train/extr_return_normed_mag 1.35 / train/extr_return_normed_max 1.35 / train/extr_return_normed_mean 0.51 / 
train/extr_return_normed_min -0.14 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 239.6 / train/extr_return_raw_max 239.6 / train/extr_return_raw_mean 162.88 / train/extr_return_raw_min 104.11 / train/extr_return_raw_std 27.25 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.3 / train/extr_reward_min -6.1e-10 / train/extr_reward_std 0.69 / train/image_loss_mean 0.44 / train/image_loss_std 0.53 / train/model_loss_mean 1.81 / train/model_loss_std 3.56 / 
train/model_opt_grad_norm 8.33 / train/model_opt_grad_steps 3.8e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6820.51 / train/policy_entropy_mag 0.95 / train/policy_entropy_max 0.89 / 
train/policy_entropy_mean -0.61 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.3 / train/policy_logprob_mag 7.5 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.61 / train/policy_logprob_min -7.5 / train/policy_logprob_std 0.77 / 
train/policy_randomness_mag 0.77 / train/policy_randomness_max 0.77 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 4.4e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 58.51 / train/post_ent_max 58.51 / train/post_ent_mean 40.32 / 
train/post_ent_min 20.51 / train/post_ent_std 5.81 / train/prior_ent_mag 70.98 / train/prior_ent_max 70.98 / train/prior_ent_mean 42.4 / train/prior_ent_min 26.13 / train/prior_ent_std 6.26 / train/rep_loss_mean 2.23 / train/rep_loss_std 5.25 / train/reward_avg 0.29 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.22 / train/reward_pred 0.29 / train/reward_rate 0.15 / 
train_stats/mean_log_entropy -0.78 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.7e-10 / report/cont_loss_std 3.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.27 / report/dyn_loss_std 5.48 / report/image_loss_mean 0.46 / report/image_loss_std 0.63 / report/model_loss_mean 1.86 / report/model_loss_std 3.81 / report/post_ent_mag 54.28 / report/post_ent_max 54.28 / 
report/post_ent_mean 39.93 / report/post_ent_min 19.55 / report/post_ent_std 6.26 / report/prior_ent_mag 71.23 / report/prior_ent_max 71.23 / report/prior_ent_mean 42.05 / report/prior_ent_min 23.83 / report/prior_ent_std 6.61 / report/rep_loss_mean 2.27 / 
report/rep_loss_std 5.48 / report/reward_avg 0.2 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.22 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.7e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.32 / report/reward_pred 0.2 / report/reward_rate 0.11 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-10 / eval/cont_loss_std 6.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-10 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 4.23 / eval/dyn_loss_std 9.58 / eval/image_loss_mean 1.1 / eval/image_loss_std 2.75 / eval/model_loss_mean 3.7 / eval/model_loss_std 8.2 / eval/post_ent_mag 56.32 / eval/post_ent_max 56.32 / eval/post_ent_mean 39.92 / eval/post_ent_min 18.59 / 
eval/post_ent_std 6.44 / eval/prior_ent_mag 71.23 / eval/prior_ent_max 71.23 / eval/prior_ent_mean 43.12 / eval/prior_ent_min 27.92 / eval/prior_ent_std 5.66 / eval/rep_loss_mean 4.23 / eval/rep_loss_std 9.58 / eval/reward_avg 0.14 / eval/reward_loss_mean 0.05 / 
eval/reward_loss_std 0.59 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.7e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.62 / eval/reward_pred 0.14 / eval/reward_rate 0.08 / replay/size 7.8e4 / replay/inserts 
3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 7.9e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.92 / timer/env.step_count 3886 / timer/env.step_total 19.38 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.08 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.32 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7894 / timer/agent.policy_total 16.99 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.8e-3 / timer/dataset_train_count 
1943 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4.7e-4 / timer/agent.train_count 1943 / timer/agent.train_total 245.15 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.74

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 331.0.
Saved chunk: 20230921T232004F286700-6XlwzQKz3gImuKbt7MUiJw-0gOeDtlHVPZPeKu2UQXeUN-1024.npz
Starting evaluation at step 79000 Counter(79000) 78937
eval_Episode has 500 steps and return 461.0.
train_Episode has 500 steps and return 436.0.
Starting evaluation at step 79500 Counter(79500) 79437
Saved chunk: 20230921T232055F861509-3ebF3eUQpyAmU6rYv1jj8w-68yqV8DnnzhBlq1Ja4nVv0-1024.npz
eval_Episode has 500 steps and return 450.0.
train_Episode has 500 steps and return 557.0.
Saved chunk: 20230921T232123F894927-0gOeDtlHVPZPeKu2UQXeUN-34StAjtNgnCw7aDflbQ3dw-1024.npz
Starting evaluation at step 80000 Counter(80000) 79937
eval_Episode has 500 steps and return 490.0.
train_Episode has 500 steps and return 541.0.
Starting evaluation at step 80500 Counter(80500) 80437
Saved chunk: 20230921T232214F149052-68yqV8DnnzhBlq1Ja4nVv0-0VDVlwT06jHvnsXBxs4lsC-1024.npz
eval_Episode has 500 steps and return 461.0.
train_Episode has 500 steps and return 544.0.
Saved chunk: 20230921T232242F955305-34StAjtNgnCw7aDflbQ3dw-6RrzVIZfMcTnrM4QfuHh2S-1024.npz
Starting evaluation at step 81000 Counter(81000) 80937
eval_Episode has 500 steps and return 718.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T232401F934009-6RrzVIZfMcTnrM4QfuHh2S-0000000000000000000000-204.npz
Saved chunk: 20230921T232331F594041-0VDVlwT06jHvnsXBxs4lsC-0000000000000000000000-865.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 701.0.
Starting evaluation at step 81500 Counter(81500) 81437
Saved chunk: 20230921T232331F594041-0VDVlwT06jHvnsXBxs4lsC-3tjRUb9HAftI5mWWNXmZte-1024.npz
eval_Episode has 500 steps and return 804.0.
train_Episode has 500 steps and return 667.0.
Saved chunk: 20230921T232401F934009-6RrzVIZfMcTnrM4QfuHh2S-1racOEShFgRKGjpBbovwIH-1024.npz
Starting evaluation at step 82000 Counter(82000) 81937
eval_Episode has 500 steps and return 703.0.
train_Episode has 500 steps and return 707.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 164822 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 707 / episode/reward_rate 0.71 / eval_episode/length 500 / eval_episode/score 703 / eval_episode/reward_rate 0.7 / train/action_mag 2.03 / train/action_max 1.98 / train/action_mean 0.15 / train/action_min -1.77 / train/action_std 0.87 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.23 / train/actor_opt_grad_steps 4e4 / train/actor_opt_loss -111.9 / train/adv_mag 0.82 / train/adv_max 0.81 / train/adv_mean 0.01 / train/adv_min -0.47 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2.8e-10 / train/cont_loss_std 2.8e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.21 / 
train/dyn_loss_std 5.2 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.53 / train/extr_critic_critic_opt_grad_steps 4e4 / train/extr_critic_critic_opt_loss 1e4 / 
train/extr_critic_mag 257.47 / train/extr_critic_max 257.47 / train/extr_critic_mean 182.35 / train/extr_critic_min 112 / train/extr_critic_std 28.94 / train/extr_return_normed_mag 1.31 / train/extr_return_normed_max 1.31 / train/extr_return_normed_mean 0.5 / 
train/extr_return_normed_min -0.1 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 266.52 / train/extr_return_raw_max 266.52 / train/extr_return_raw_mean 183.53 / train/extr_return_raw_min 122.12 / train/extr_return_raw_std 29.93 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.34 / train/extr_reward_min 0 / train/extr_reward_std 0.72 / train/image_loss_mean 0.42 / train/image_loss_std 0.51 / train/model_loss_mean 1.79 / train/model_loss_std 3.5 / 
train/model_opt_grad_norm 8.61 / train/model_opt_grad_steps 4e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5974.36 / train/policy_entropy_mag 0.92 / train/policy_entropy_max 0.78 / 
train/policy_entropy_mean -0.66 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.27 / train/policy_logprob_mag 7.47 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.66 / train/policy_logprob_min -7.47 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.4e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 58.88 / train/post_ent_max 58.88 / train/post_ent_mean 40.91 / 
train/post_ent_min 21.03 / train/post_ent_std 5.64 / train/prior_ent_mag 71.37 / train/prior_ent_max 71.37 / train/prior_ent_mean 42.94 / train/prior_ent_min 26.63 / train/prior_ent_std 6.12 / train/rep_loss_mean 2.21 / train/rep_loss_std 5.2 / train/reward_avg 0.34 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.21 / train/reward_pred 0.33 / train/reward_rate 0.17 / 
train_stats/mean_log_entropy -0.81 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.1e-10 / report/cont_loss_std 6.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.23 / report/dyn_loss_std 5.3 / report/image_loss_mean 0.41 / report/image_loss_std 0.64 / report/model_loss_mean 1.78 / report/model_loss_std 3.7 / report/post_ent_mag 50.84 / report/post_ent_max 50.84 / 
report/post_ent_mean 41.83 / report/post_ent_min 20.03 / report/post_ent_std 5.35 / report/prior_ent_mag 71.87 / report/prior_ent_max 71.87 / report/prior_ent_mean 43.77 / report/prior_ent_min 27.88 / report/prior_ent_std 5.95 / report/rep_loss_mean 2.23 / 
report/rep_loss_std 5.3 / report/reward_avg 0.3 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.18 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.22 / report/reward_pred 0.3 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-10 / eval/cont_loss_std 1.7e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 3.79 / eval/dyn_loss_std 7.79 / eval/image_loss_mean 0.99 / eval/image_loss_std 2.04 / eval/model_loss_mean 3.31 / eval/model_loss_std 6.34 / eval/post_ent_mag 61.06 / eval/post_ent_max 61.06 / eval/post_ent_mean 40.42 / eval/post_ent_min 18.87 / 
eval/post_ent_std 6.72 / eval/prior_ent_mag 71.87 / eval/prior_ent_max 71.87 / eval/prior_ent_mean 43.16 / eval/prior_ent_min 23.96 / eval/prior_ent_std 6.12 / eval/rep_loss_mean 3.79 / eval/rep_loss_std 7.79 / eval/reward_avg 0.19 / eval/reward_loss_mean 0.04 / 
eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.29 / eval/reward_pred 0.19 / eval/reward_rate 0.1 / replay/size 8.2e4 / replay/inserts 
3910 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.3e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3910 / timer/env.step_total 19.5 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.01 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7417 / timer/agent.policy_total 16.09 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1955 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / 
timer/agent.train_count 1955 / timer/agent.train_total 246.53 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / 
timer/dataset_eval_max 3.4e-5 / fps 26.06

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 82500 Counter(82500) 82437
Saved chunk: 20230921T232449F137528-3tjRUb9HAftI5mWWNXmZte-63wYUFB4zxbCor9lzLnb36-1024.npz
eval_Episode has 500 steps and return 406.0.
train_Episode has 500 steps and return 570.0.
Saved chunk: 20230921T232520F949353-1racOEShFgRKGjpBbovwIH-4d9FyLWWwvuMgD7rzpkeCs-1024.npz
Starting evaluation at step 83000 Counter(83000) 82937
eval_Episode has 500 steps and return 443.0.
train_Episode has 500 steps and return 586.0.
Starting evaluation at step 83500 Counter(83500) 83437
Saved chunk: 20230921T232606F918867-63wYUFB4zxbCor9lzLnb36-2ahJajQZDvJSkWMRdaPB0l-1024.npz
eval_Episode has 500 steps and return 374.0.
train_Episode has 500 steps and return 425.0.
Saved chunk: 20230921T232640F532929-4d9FyLWWwvuMgD7rzpkeCs-6uuXM6OTA8q0jQvHORe1zj-1024.npz
Starting evaluation at step 84000 Counter(84000) 83937
eval_Episode has 500 steps and return 570.0.
train_Episode has 500 steps and return 720.0.
Starting evaluation at step 84500 Counter(84500) 84437
Saved chunk: 20230921T232724F574831-2ahJajQZDvJSkWMRdaPB0l-7EN3KnXqTqpNe3S48PSlxQ-1024.npz
eval_Episode has 500 steps and return 566.0.
train_Episode has 500 steps and return 700.0.
Saved chunk: 20230921T232759F698064-6uuXM6OTA8q0jQvHORe1zj-0odGMcIl73XYOPzGkiGNys-1024.npz
Starting evaluation at step 85000 Counter(85000) 84937
eval_Episode has 500 steps and return 724.0.
train_Episode has 500 steps and return 698.0.
Starting evaluation at step 85500 Counter(85500) 85437
Saved chunk: 20230921T232842F053285-7EN3KnXqTqpNe3S48PSlxQ-0xSp8Q67XCH8y1UXXMoFTE-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 705.0.
Starting evaluation at step 86000 Counter(86000) 85937
eval_Episode has 500 steps and return 718.0.
Saved chunk: 20230921T232918F605411-0odGMcIl73XYOPzGkiGNys-5PC0Nts86jDck4V5EAvcrj-1024.npz
train_Episode has 500 steps and return 836.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 172550 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 718 / eval_episode/reward_rate 0.72 / episode/length 500 / episode/score 836 / episode/reward_rate 0.84 / train/action_mag 2.13 / train/action_max 2.05 / train/action_mean 0.15 / train/action_min -1.87 / train/action_std 0.86 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 4.2e4 / train/actor_opt_loss -110.2 / train/adv_mag 0.87 / train/adv_max 0.86 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2e-10 / train/cont_loss_std 7.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.18 / 
train/dyn_loss_std 5.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.58 / train/extr_critic_critic_opt_grad_steps 4.2e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 293.3 / train/extr_critic_max 293.3 / train/extr_critic_mean 203.8 / train/extr_critic_min 113.38 / train/extr_critic_std 35.31 / train/extr_return_normed_mag 1.24 / train/extr_return_normed_max 1.24 / train/extr_return_normed_mean 0.46 / 
train/extr_return_normed_min -0.12 / train/extr_return_normed_std 0.29 / train/extr_return_rate 1 / train/extr_return_raw_mag 301.8 / train/extr_return_raw_max 301.8 / train/extr_return_raw_mean 205.23 / train/extr_return_raw_min 132.66 / train/extr_return_raw_std 36.61 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.37 / train/extr_reward_min -6.2e-10 / train/extr_reward_std 0.75 / train/image_loss_mean 0.42 / train/image_loss_std 0.51 / train/model_loss_mean 1.77 / train/model_loss_std 3.47 / 
train/model_opt_grad_norm 8.24 / train/model_opt_grad_steps 4.2e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7616.58 / train/policy_entropy_mag 0.92 / train/policy_entropy_max 0.85 / 
train/policy_entropy_mean -0.66 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.28 / train/policy_logprob_mag 7.58 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.66 / train/policy_logprob_min -7.58 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.1 / train/policy_randomness_min 3.2e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 59.29 / train/post_ent_max 59.29 / train/post_ent_mean 41.2 / 
train/post_ent_min 21.18 / train/post_ent_std 5.54 / train/prior_ent_mag 71.6 / train/prior_ent_max 71.6 / train/prior_ent_mean 43.21 / train/prior_ent_min 26.67 / train/prior_ent_std 6.05 / train/rep_loss_mean 2.18 / train/rep_loss_std 5.13 / train/reward_avg 0.37 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.2 / train/reward_pred 0.37 / train/reward_rate 0.19 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.82 / report/cont_avg 1 / report/cont_loss_mean 2.5e-10 / report/cont_loss_std 1.8e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.21 / report/dyn_loss_std 5.3 / report/image_loss_mean 0.51 / report/image_loss_std 0.51 / report/model_loss_mean 1.85 / report/model_loss_std 3.54 / report/post_ent_mag 62.98 / report/post_ent_max 62.98 / 
report/post_ent_mean 40.63 / report/post_ent_min 21.91 / report/post_ent_std 5.76 / report/prior_ent_mag 71.82 / report/prior_ent_max 71.82 / report/prior_ent_mean 42.76 / report/prior_ent_min 25.96 / report/prior_ent_std 6.24 / report/rep_loss_mean 2.21 / 
report/rep_loss_std 5.3 / report/reward_avg 0.18 / report/reward_loss_mean 0.02 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.2 / report/reward_pred 0.18 / report/reward_rate 0.1 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 2.13 / eval/dyn_loss_std 4.75 / eval/image_loss_mean 0.41 / eval/image_loss_std 0.47 / eval/model_loss_mean 1.71 / eval/model_loss_std 3.19 / eval/post_ent_mag 63.16 / eval/post_ent_max 63.16 / eval/post_ent_mean 42.18 / eval/post_ent_min 24.72 / 
eval/post_ent_std 5.02 / eval/prior_ent_mag 71.82 / eval/prior_ent_max 71.82 / eval/prior_ent_mean 44.14 / eval/prior_ent_min 24.68 / eval/prior_ent_std 5.62 / eval/rep_loss_mean 2.13 / eval/rep_loss_std 4.75 / eval/reward_avg 0.17 / eval/reward_loss_mean 0.02 / 
eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.23 / eval/reward_pred 0.17 / eval/reward_rate 0.09 / replay/size 8.6e4 / replay/inserts 3864 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 8.7e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3864 / timer/env.step_total 19.27 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.53 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7872 / timer/agent.policy_total 16.98 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 
1932 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1932 / timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.22 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.75

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 86500 Counter(86500) 86437
Saved chunk: 20230921T232959F255814-0xSp8Q67XCH8y1UXXMoFTE-6Qjtwb3nbggK0y6nHL2UVJ-1024.npz
eval_Episode has 500 steps and return 720.0.
train_Episode has 500 steps and return 705.0.
Starting evaluation at step 87000 Counter(87000) 86937
eval_Episode has 500 steps and return 838.0.
Saved chunk: 20230921T233040F609118-5PC0Nts86jDck4V5EAvcrj-1tBxH9DzesS6H1WKgYREtT-1024.npz
train_Episode has 500 steps and return 686.0.
Starting evaluation at step 87500 Counter(87500) 87437
Saved chunk: 20230921T233117F254645-6Qjtwb3nbggK0y6nHL2UVJ-2g8C3Y66L4D0eFxqSKH9bp-1024.npz
eval_Episode has 500 steps and return 697.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 88000 Counter(88000) 87937
eval_Episode has 500 steps and return 709.0.
Saved chunk: 20230921T233200F460931-1tBxH9DzesS6H1WKgYREtT-1U6oJzuVfAJ4Jerj7aurqj-1024.npz
train_Episode has 500 steps and return 720.0.
Starting evaluation at step 88500 Counter(88500) 88437
Saved chunk: 20230921T233234F884740-2g8C3Y66L4D0eFxqSKH9bp-4c1EBEoDK3P9eJUPC2BVAq-1024.npz
eval_Episode has 500 steps and return 696.0.
train_Episode has 500 steps and return 712.0.
Starting evaluation at step 89000 Counter(89000) 88937
eval_Episode has 500 steps and return 835.0.
Saved chunk: 20230921T233319F405817-1U6oJzuVfAJ4Jerj7aurqj-439H1Gh6iWlI3rDMufcz1U-1024.npz
train_Episode has 500 steps and return 706.0.
Starting evaluation at step 89500 Counter(89500) 89437
Saved chunk: 20230921T233352F200754-4c1EBEoDK3P9eJUPC2BVAq-2p6Lsd7qiqVJStaDHlT1V3-1024.npz
eval_Episode has 500 steps and return 809.0.
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 90000 Counter(90000) 89937
eval_Episode has 500 steps and return 709.0.
Saved chunk: 20230921T233438F296665-439H1Gh6iWlI3rDMufcz1U-0i918KkycybdhcIWeXj0pn-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 180274 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 709 / eval_episode/reward_rate 0.71 / episode/length 500 / episode/score 837 / episode/reward_rate 0.84 / train/action_mag 2.23 / train/action_max 2.21 / train/action_mean 0.14 / train/action_min -1.83 / train/action_std 0.86 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.25 / train/actor_opt_grad_steps 4.4e4 / train/actor_opt_loss -109.24 / train/adv_mag 0.86 / train/adv_max 0.86 / train/adv_mean 0.01 / train/adv_min -0.47 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.9e-10 / train/cont_loss_std 7.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.9e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.16 / 
train/dyn_loss_std 5.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.66 / train/extr_critic_critic_opt_grad_steps 4.4e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 341.75 / train/extr_critic_max 341.75 / train/extr_critic_mean 231.59 / train/extr_critic_min 122.73 / train/extr_critic_std 45.34 / train/extr_return_normed_mag 1.17 / train/extr_return_normed_max 1.17 / train/extr_return_normed_mean 0.43 / 
train/extr_return_normed_min -0.1 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 349.74 / train/extr_return_raw_max 349.74 / train/extr_return_raw_mean 233.37 / train/extr_return_raw_min 149.04 / train/extr_return_raw_std 47.23 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.42 / train/extr_reward_min 0 / train/extr_reward_std 0.79 / train/image_loss_mean 0.4 / train/image_loss_std 0.5 / train/model_loss_mean 1.74 / train/model_loss_std 3.42 / 
train/model_opt_grad_norm 8.14 / train/model_opt_grad_steps 4.4e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6424.87 / train/policy_entropy_mag 0.95 / train/policy_entropy_max 0.91 / 
train/policy_entropy_mean -0.6 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.33 / train/policy_logprob_mag 7.56 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.6 / train/policy_logprob_min -7.56 / train/policy_logprob_std 0.78 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 3.8e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 58.97 / train/post_ent_max 58.97 / train/post_ent_mean 41.37 / 
train/post_ent_min 21.57 / train/post_ent_std 5.41 / train/prior_ent_mag 71.75 / train/prior_ent_max 71.75 / train/prior_ent_mean 43.34 / train/prior_ent_min 27.01 / train/prior_ent_std 5.97 / train/rep_loss_mean 2.16 / train/rep_loss_std 5.05 / train/reward_avg 0.42 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.19 / train/reward_pred 0.42 / train/reward_rate 0.22 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.82 / report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 5.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.46 / report/dyn_loss_std 6.47 / report/image_loss_mean 0.49 / report/image_loss_std 0.56 / report/model_loss_mean 2 / report/model_loss_std 4.28 / report/post_ent_mag 63.02 / report/post_ent_max 63.02 / 
report/post_ent_mean 39.35 / report/post_ent_min 16.77 / report/post_ent_std 7.51 / report/prior_ent_mag 71.38 / report/prior_ent_max 71.38 / report/prior_ent_mean 41.65 / report/prior_ent_min 23.73 / report/prior_ent_std 7.66 / report/rep_loss_mean 2.46 / 
report/rep_loss_std 6.47 / report/reward_avg 0.32 / report/reward_loss_mean 0.03 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.18 / report/reward_pred 0.31 / report/reward_rate 0.16 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-10 / eval/cont_loss_std 9.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-10 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 2.45 / eval/dyn_loss_std 5.76 / eval/image_loss_mean 0.54 / eval/image_loss_std 0.75 / eval/model_loss_mean 2.06 / eval/model_loss_std 3.91 / eval/post_ent_mag 63.31 / eval/post_ent_max 63.31 / eval/post_ent_mean 41.4 / eval/post_ent_min 22.12 / 
eval/post_ent_std 5.31 / eval/prior_ent_mag 71.38 / eval/prior_ent_max 71.38 / eval/prior_ent_mean 43.57 / eval/prior_ent_min 28.69 / eval/prior_ent_std 5.47 / eval/rep_loss_mean 2.45 / eval/rep_loss_std 5.76 / eval/reward_avg 0.23 / eval/reward_loss_mean 0.05 / 
eval/reward_loss_std 0.32 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.32 / eval/reward_pred 0.23 / eval/reward_rate 0.12 / replay/size 9e4 / replay/inserts 
3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.1e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3862 / timer/env.step_total 19.29 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 0.09 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.51 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7870 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 
1931 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1931 / timer/agent.train_total 243.47 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.74

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 659.0.
Starting evaluation at step 90500 Counter(90500) 90437
Saved chunk: 20230921T233509F558940-2p6Lsd7qiqVJStaDHlT1V3-58t1g2SwdMMyiUJXEFTubD-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 798.0.
Starting evaluation at step 91000 Counter(91000) 90937
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230921T233557F155700-0i918KkycybdhcIWeXj0pn-2G1fsRIv8AbW2AkqDO52Uh-1024.npz
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 91500 Counter(91500) 91437
Saved chunk: 20230921T233627F722320-58t1g2SwdMMyiUJXEFTubD-0bTgS9UrXDtMyVHCaCY0QT-1024.npz
eval_Episode has 500 steps and return 715.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 92000 Counter(92000) 91937
eval_Episode has 500 steps and return 695.0.
Saved chunk: 20230921T233717F055502-2G1fsRIv8AbW2AkqDO52Uh-3hwvVWIaoo3jV7IXnCbBi5-1024.npz
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 92500 Counter(92500) 92437
Saved chunk: 20230921T233745F290712-0bTgS9UrXDtMyVHCaCY0QT-4iXuWnt0QykRdaPedSZFKh-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 701.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230921T233902F723602-4iXuWnt0QykRdaPedSZFKh-0000000000000000000000-100.npz
Saved chunk: 20230921T233836F042705-3hwvVWIaoo3jV7IXnCbBi5-0000000000000000000000-640.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 93000 Counter(93000) 92937
eval_Episode has 500 steps and return 833.0.
Saved chunk: 20230921T233836F042705-3hwvVWIaoo3jV7IXnCbBi5-6XajFLzOymSetF2r9VNTS8-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 93500 Counter(93500) 93437
Saved chunk: 20230921T233902F723602-4iXuWnt0QykRdaPedSZFKh-0Tur0wAI7RtFJjPzxnyxYa-1024.npz
eval_Episode has 500 steps and return 821.0.
train_Episode has 500 steps and return 821.0.
Starting evaluation at step 94000 Counter(94000) 93937
eval_Episode has 500 steps and return 829.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 188002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 821 / episode/reward_rate 0.82 / eval_episode/length 500 / eval_episode/score 829 / eval_episode/reward_rate 0.83 / train/action_mag 2.1 / train/action_max 2.05 / train/action_mean 0.13 / train/action_min -1.84 / train/action_std 0.84 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.27 / train/actor_opt_grad_steps 4.5e4 / train/actor_opt_loss -122.61 / train/adv_mag 0.85 / train/adv_max 0.84 / train/adv_mean 0.01 / train/adv_min -0.47 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 2e-10 / train/cont_loss_std 9.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.14 / 
train/dyn_loss_std 5.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.65 / train/extr_critic_critic_opt_grad_steps 4.5e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 397.05 / train/extr_critic_max 397.05 / train/extr_critic_mean 264.97 / train/extr_critic_min 135.31 / train/extr_critic_std 57.02 / train/extr_return_normed_mag 1.11 / train/extr_return_normed_max 1.11 / train/extr_return_normed_mean 0.42 / 
train/extr_return_normed_min -0.09 / train/extr_return_normed_std 0.3 / train/extr_return_rate 1 / train/extr_return_raw_mag 403.3 / train/extr_return_raw_max 403.3 / train/extr_return_raw_mean 267.48 / train/extr_return_raw_min 165.68 / train/extr_return_raw_std 59.07 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.45 / train/extr_reward_min 0 / train/extr_reward_std 0.8 / train/image_loss_mean 0.39 / train/image_loss_std 0.5 / train/model_loss_mean 1.72 / train/model_loss_std 3.39 / 
train/model_opt_grad_norm 8.27 / train/model_opt_grad_steps 4.5e4 / train/model_opt_loss 9026.92 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5231.96 / train/policy_entropy_mag 0.92 / train/policy_entropy_max 0.84 / 
train/policy_entropy_mean -0.61 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.3 / train/policy_logprob_mag 7.67 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.61 / train/policy_logprob_min -7.67 / train/policy_logprob_std 0.77 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 4e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 59.28 / train/post_ent_max 59.28 / train/post_ent_mean 41.55 / 
train/post_ent_min 21.66 / train/post_ent_std 5.26 / train/prior_ent_mag 71.95 / train/prior_ent_max 71.95 / train/prior_ent_mean 43.49 / train/prior_ent_min 26.94 / train/prior_ent_std 5.87 / train/rep_loss_mean 2.14 / train/rep_loss_std 5.02 / train/reward_avg 0.46 / 
train/reward_loss_mean 0.04 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.18 / train/reward_pred 0.46 / train/reward_rate 0.23 / 
train_stats/mean_log_entropy -0.82 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 5.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.96 / report/dyn_loss_std 4.49 / report/image_loss_mean 0.33 / report/image_loss_std 0.45 / report/model_loss_mean 1.55 / report/model_loss_std 3.07 / report/post_ent_mag 63.92 / report/post_ent_max 63.92 / 
report/post_ent_mean 42.32 / report/post_ent_min 24.27 / report/post_ent_std 5 / report/prior_ent_mag 72.19 / report/prior_ent_max 72.19 / report/prior_ent_mean 43.93 / report/prior_ent_min 27.08 / report/prior_ent_std 5.83 / report/rep_loss_mean 1.96 / 
report/rep_loss_std 4.49 / report/reward_avg 0.49 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.15 / report/reward_pred 0.49 / report/reward_rate 0.25 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-10 / eval/cont_loss_std 5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.24 / eval/dyn_loss_std 5.04 / eval/image_loss_mean 0.4 / eval/image_loss_std 0.46 / eval/model_loss_mean 1.79 / eval/model_loss_std 3.32 / eval/post_ent_mag 63.92 / eval/post_ent_max 63.92 / eval/post_ent_mean 41.48 / 
eval/post_ent_min 22.58 / eval/post_ent_std 5.4 / eval/prior_ent_mag 72.19 / eval/prior_ent_max 72.19 / eval/prior_ent_mean 43.25 / eval/prior_ent_min 26.61 / eval/prior_ent_std 6.25 / eval/rep_loss_mean 2.24 / eval/rep_loss_std 5.04 / eval/reward_avg 0.21 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.28 / eval/reward_pred 0.21 / eval/reward_rate 0.11 / replay/size
9.4e4 / replay/inserts 3864 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.5e4 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.4 / timer/env.step_count 3864 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.14 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.8e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7872 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1932 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1932 / timer/agent.train_total 243.78 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.13 /
timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.72

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230921T233955F106529-6XajFLzOymSetF2r9VNTS8-5iakqCVPJB0nwgG6yOFIXc-1024.npz
Starting evaluation at step 94500 Counter(94500) 94437
Saved chunk: 20230921T234020F219234-0Tur0wAI7RtFJjPzxnyxYa-7m3TgOLPM05KnEw10bDhlQ-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 810.0.
Starting evaluation at step 95000 Counter(95000) 94937
eval_Episode has 500 steps and return 827.0.
train_Episode has 500 steps and return 563.0.
Saved chunk: 20230921T234114F643728-5iakqCVPJB0nwgG6yOFIXc-72B4GkQz4TnSIZ6tIt6rV9-1024.npz
Starting evaluation at step 95500 Counter(95500) 95437
Saved chunk: 20230921T234138F363704-7m3TgOLPM05KnEw10bDhlQ-65xEHXfEr91aPqVVmu6JPt-1024.npz
eval_Episode has 500 steps and return 724.0.
train_Episode has 500 steps and return 805.0.
Starting evaluation at step 96000 Counter(96000) 95937
eval_Episode has 500 steps and return 826.0.
train_Episode has 500 steps and return 803.0.
Saved chunk: 20230921T234233F885242-72B4GkQz4TnSIZ6tIt6rV9-32tQDg3RbUPsuOBc7BP6AF-1024.npz
Starting evaluation at step 96500 Counter(96500) 96437
eval_Episode has 500 steps and return 838.0.
Saved chunk: 20230921T234255F909196-65xEHXfEr91aPqVVmu6JPt-6nRscdHtGWX7tqyBxb7A84-1024.npz
train_Episode has 500 steps and return 673.0.
Starting evaluation at step 97000 Counter(97000) 96937
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 673.0.
Saved chunk: 20230921T234352F740544-32tQDg3RbUPsuOBc7BP6AF-075FNkH6hZ5WKtkXyZNW0i-1024.npz
Starting evaluation at step 97500 Counter(97500) 97437
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 826.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 195826 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 826 / episode/reward_rate 0.82 / eval_episode/length 500 / eval_episode/score 836 / eval_episode/reward_rate 0.83 / train/action_mag 2 / train/action_max 1.98 / train/action_mean 0.13 / train/action_min -1.69 / train/action_std 0.83 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.26 / train/actor_opt_grad_steps 4.7e4 / train/actor_opt_loss -124.71 / train/adv_mag 0.84 / train/adv_max 0.83 / train/adv_mean 0.01 / train/adv_min -0.51 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.8e-10 / train/cont_loss_std 8.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.8e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.11 / 
train/dyn_loss_std 4.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.66 / train/extr_critic_critic_opt_grad_steps 4.7e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 456.99 / train/extr_critic_max 456.99 / train/extr_critic_mean 313.16 / train/extr_critic_min 162.12 / train/extr_critic_std 70.46 / train/extr_return_normed_mag 1.07 / train/extr_return_normed_max 1.07 / train/extr_return_normed_mean 0.45 / 
train/extr_return_normed_min -0.11 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 461.71 / train/extr_return_raw_max 461.71 / train/extr_return_raw_mean 316.15 / train/extr_return_raw_min 187.57 / train/extr_return_raw_std 72.5 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.49 / train/extr_reward_min 0 / train/extr_reward_std 0.83 / train/image_loss_mean 0.38 / train/image_loss_std 0.49 / train/model_loss_mean 1.69 / train/model_loss_std 3.34 / 
train/model_opt_grad_norm 7.91 / train/model_opt_grad_steps 4.7e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6487.18 / train/policy_entropy_mag 0.9 / train/policy_entropy_max 0.78 / 
train/policy_entropy_mean -0.62 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.29 / train/policy_logprob_mag 7.55 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.62 / train/policy_logprob_min -7.55 / train/policy_logprob_std 0.77 / 
train/policy_randomness_mag 0.72 / train/policy_randomness_max 0.72 / train/policy_randomness_mean 0.11 / train/policy_randomness_min 3.8e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 59.77 / train/post_ent_max 59.77 / train/post_ent_mean 41.57 / 
train/post_ent_min 21.84 / train/post_ent_std 5.21 / train/prior_ent_mag 72.07 / train/prior_ent_max 72.07 / train/prior_ent_mean 43.47 / train/prior_ent_min 27.11 / train/prior_ent_std 5.86 / train/rep_loss_mean 2.11 / train/rep_loss_std 4.93 / train/reward_avg 0.5 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.17 / train/reward_pred 0.5 / train/reward_rate 0.26 / 
train_stats/mean_log_entropy -0.81 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-10 / report/cont_loss_std 5.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.08 / report/dyn_loss_std 5.2 / report/image_loss_mean 0.36 / report/image_loss_std 0.58 / report/model_loss_mean 1.68 / report/model_loss_std 3.59 / report/post_ent_mag 64.08 / report/post_ent_max 64.08 / 
report/post_ent_mean 42.04 / report/post_ent_min 23.51 / report/post_ent_std 5.03 / report/prior_ent_mag 71.93 / report/prior_ent_max 71.93 / report/prior_ent_mean 43.67 / report/prior_ent_min 27.76 / report/prior_ent_std 5.65 / report/rep_loss_mean 2.08 / 
report/rep_loss_std 5.2 / report/reward_avg 0.62 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.25 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.2 / report/reward_pred 0.61 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-10 / eval/cont_loss_std 3.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.21 / eval/dyn_loss_std 4.87 / eval/image_loss_mean 0.4 / eval/image_loss_std 0.48 / eval/model_loss_mean 1.76 / eval/model_loss_std 3.27 / eval/post_ent_mag 64.08 / eval/post_ent_max 64.08 / eval/post_ent_mean 41.84 / 
eval/post_ent_min 14.53 / eval/post_ent_std 5.19 / eval/prior_ent_mag 71.93 / eval/prior_ent_max 71.93 / eval/prior_ent_mean 43.69 / eval/prior_ent_min 27.15 / eval/prior_ent_std 5.73 / eval/rep_loss_mean 2.21 / eval/rep_loss_std 4.87 / eval/reward_avg 0.37 / 
eval/reward_loss_mean 0.03 / eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.37 / eval/reward_rate 0.19 / replay/size 
9.8e4 / replay/inserts 3912 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 9.8e4 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3912 / timer/env.step_total 19.41 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.87 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.5e-3 / timer/replay._sample_max 0.11 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7419 / timer/agent.policy_total 16.04 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1956 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.7e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1956 / timer/agent.train_total 246.67 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 26.08

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 98000 Counter(98000) 97937
Saved chunk: 20230921T234413F199460-6nRscdHtGWX7tqyBxb7A84-0iMFIiXsf1nyBvBxaIsLv7-1024.npz
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 824.0.
Saved chunk: 20230921T234511F511281-075FNkH6hZ5WKtkXyZNW0i-0e6xe9CZmpf4cjmsAYlFWD-1024.npz
Starting evaluation at step 98500 Counter(98500) 98437
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 99000 Counter(99000) 98937
Saved chunk: 20230921T234606F250539-0iMFIiXsf1nyBvBxaIsLv7-0HK8HEsI2yjELpmP5zgdPV-1024.npz
eval_Episode has 500 steps and return 659.0.
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230921T234631F074223-0e6xe9CZmpf4cjmsAYlFWD-3QbtUo4SxSyqm6Ty3ytNCR-1024.npz
Starting evaluation at step 99500 Counter(99500) 99437
eval_Episode has 500 steps and return 799.0.
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 100000 Counter(100000) 99937
Saved chunk: 20230921T234723F796532-0HK8HEsI2yjELpmP5zgdPV-4SbvidEgoUJdyojLc78RuN-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 826.0.
Saved chunk: 20230921T234750F019449-3QbtUo4SxSyqm6Ty3ytNCR-0ijH3jQk30iE1IJmHCVror-1024.npz
Starting evaluation at step 100500 Counter(100500) 100437
eval_Episode has 500 steps and return 814.0.
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 101000 Counter(101000) 100937
Saved chunk: 20230921T234841F168561-4SbvidEgoUJdyojLc78RuN-6m88YDwXNAE6wGwSEetBbx-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 803.0.
Saved chunk: 20230921T234909F026629-0ijH3jQk30iE1IJmHCVror-5dSEFATnyTxuvJGSZMcHDr-1024.npz
Starting evaluation at step 101500 Counter(101500) 101437
eval_Episode has 500 steps and return 822.0.
train_Episode has 500 steps and return 826.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 203550 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 822 / eval_episode/reward_rate 0.82 / episode/length 500 / episode/score 826 / episode/reward_rate 0.82 / train/action_mag 2.01 / train/action_max 1.99 / train/action_mean 0.12 / train/action_min -1.69 / train/action_std 0.81 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.22 / train/actor_opt_grad_steps 4.9e4 / train/actor_opt_loss -124.35 / train/adv_mag 0.84 / train/adv_max 0.82 / train/adv_mean 0.01 / train/adv_min -0.5 / 
train/adv_std 0.05 / train/cont_avg 1 / train/cont_loss_mean 1.7e-10 / train/cont_loss_std 8.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.7e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.09 / 
train/dyn_loss_std 4.86 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.61 / train/extr_critic_critic_opt_grad_steps 4.9e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 522.54 / train/extr_critic_max 522.54 / train/extr_critic_mean 371.85 / train/extr_critic_min 190.71 / train/extr_critic_std 82.12 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.48 / 
train/extr_return_normed_min -0.1 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 524.63 / train/extr_return_raw_max 524.63 / train/extr_return_raw_mean 375.26 / train/extr_return_raw_min 220.62 / train/extr_return_raw_std 83.76 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.53 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.37 / train/image_loss_std 0.48 / train/model_loss_mean 1.67 / train/model_loss_std 3.28 / 
train/model_opt_grad_norm 8.09 / train/model_opt_grad_steps 4.9e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6010.36 / train/policy_entropy_mag 0.9 / train/policy_entropy_max 0.79 / 
train/policy_entropy_mean -0.61 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.29 / train/policy_logprob_mag 7.55 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.61 / train/policy_logprob_min -7.55 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.73 / train/policy_randomness_max 0.73 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 6.3e-4 / train/policy_randomness_std 0.12 / train/post_ent_mag 58.97 / train/post_ent_max 58.97 / train/post_ent_mean 41.8 / 
train/post_ent_min 21.96 / train/post_ent_std 4.99 / train/prior_ent_mag 72.04 / train/prior_ent_max 72.04 / train/prior_ent_mean 43.66 / train/prior_ent_min 27.39 / train/prior_ent_std 5.68 / train/rep_loss_mean 2.09 / train/rep_loss_std 4.86 / train/reward_avg 0.54 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.17 / train/reward_pred 0.54 / train/reward_rate 0.28 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.79 / report/cont_avg 1 / report/cont_loss_mean 1.3e-10 / report/cont_loss_std 3.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.03 / report/dyn_loss_std 4.59 / report/image_loss_mean 0.36 / report/image_loss_std 0.47 / report/model_loss_mean 1.62 / report/model_loss_std 3.14 / report/post_ent_mag 63.87 / report/post_ent_max 63.87 / 
report/post_ent_mean 42.33 / report/post_ent_min 22.32 / report/post_ent_std 5.02 / report/prior_ent_mag 71.11 / report/prior_ent_max 71.11 / report/prior_ent_mean 44.19 / report/prior_ent_min 28.87 / report/prior_ent_std 5.59 / report/rep_loss_mean 2.03 / 
report/rep_loss_std 4.59 / report/reward_avg 0.45 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.17 / report/reward_pred 0.45 / report/reward_rate 0.23 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 4.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.55 / eval/dyn_loss_std 5.73 / eval/image_loss_mean 0.46 / eval/image_loss_std 0.89 / eval/model_loss_mean 2.05 / eval/model_loss_std 4.05 / eval/post_ent_mag 50.27 / eval/post_ent_max 50.27 / eval/post_ent_mean 
41.09 / eval/post_ent_min 19.71 / eval/post_ent_std 6.16 / eval/prior_ent_mag 71.11 / eval/prior_ent_max 71.11 / eval/prior_ent_mean 43.44 / eval/prior_ent_min 25.87 / eval/prior_ent_std 6.22 / eval/rep_loss_mean 2.55 / eval/rep_loss_std 5.73 / eval/reward_avg 0.38 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.28 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.8e-3 / eval/reward_pos_acc 0.98 / eval/reward_pos_loss 0.27 / eval/reward_pred 0.37 / eval/reward_rate 0.2 / 
replay/size 1e5 / replay/inserts 3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3862 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7870 / timer/agent.policy_total 16.94 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1931 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1931 / timer/agent.train_total 243.59 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.74

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 102000 Counter(102000) 101937
Saved chunk: 20230921T234958F592924-6m88YDwXNAE6wGwSEetBbx-1h0M8KIoPNW3PyP4ff0muu-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230921T235027F925738-5dSEFATnyTxuvJGSZMcHDr-6wlk1TK1WHp4NukINZmiZI-1024.npz
Starting evaluation at step 102500 Counter(102500) 102437
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 652.0.
Starting evaluation at step 103000 Counter(103000) 102937
Saved chunk: 20230921T235116F657095-1h0M8KIoPNW3PyP4ff0muu-4wsOHDjBFlhotvcCX3F5NF-1024.npz
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 820.0.
Saved chunk: 20230921T235147F754043-6wlk1TK1WHp4NukINZmiZI-1hozBcfBreB3mcmEEAIyc0-1024.npz
Starting evaluation at step 103500 Counter(103500) 103437
eval_Episode has 500 steps and return 660.0.
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 104000 Counter(104000) 103937
Saved chunk: 20230921T235234F349745-4wsOHDjBFlhotvcCX3F5NF-70TqzgzBvr9l25ddsSVipS-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 830.0.
Saved chunk: 20230921T235306F815818-1hozBcfBreB3mcmEEAIyc0-2rL8ErlOUcHK7Fy5JaSbip-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 104500 Counter(104500) 104437
Saved chunk: 20230921T235352F643144-70TqzgzBvr9l25ddsSVipS-0000000000000000000000-359.npz
Saved chunk: 20230921T235426F611777-2rL8ErlOUcHK7Fy5JaSbip-0000000000000000000000-52.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
eval_Episode has 500 steps and return 818.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 105000 Counter(105000) 104937
Saved chunk: 20230921T235352F643144-70TqzgzBvr9l25ddsSVipS-7qRe3zLCnIZ2ND9Hkic4gH-1024.npz
eval_Episode has 500 steps and return 823.0.
train_Episode has 500 steps and return 822.0.
Saved chunk: 20230921T235426F611777-2rL8ErlOUcHK7Fy5JaSbip-22FXFFvQbn1NHf3EwqthHV-1024.npz
Starting evaluation at step 105500 Counter(105500) 105437
eval_Episode has 500 steps and return 822.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 211234 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 822 / eval_episode/reward_rate 0.82 / episode/length 500 / episode/score 822 / episode/reward_rate 0.82 / train/action_mag 2.07 / train/action_max 2.05 / train/action_mean 0.1 / train/action_min -1.72 / train/action_std 0.8 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.2 / train/actor_opt_grad_steps 5.1e4 / train/actor_opt_loss -91.56 / train/adv_mag 0.77 / train/adv_max 0.74 / train/adv_mean 9.5e-3 / train/adv_min -0.49 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.07 / 
train/dyn_loss_std 4.79 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.5 / train/extr_critic_critic_opt_grad_steps 5.1e4 / train/extr_critic_critic_opt_loss 1e4 
/ train/extr_critic_mag 568.65 / train/extr_critic_max 568.65 / train/extr_critic_mean 427.65 / train/extr_critic_min 229.41 / train/extr_critic_std 83.64 / train/extr_return_normed_mag 1.04 / train/extr_return_normed_max 1.04 / train/extr_return_normed_mean 0.53 / 
train/extr_return_normed_min -0.13 / train/extr_return_normed_std 0.31 / train/extr_return_rate 1 / train/extr_return_raw_mag 568.33 / train/extr_return_raw_max 568.33 / train/extr_return_raw_mean 430.21 / train/extr_return_raw_min 252.67 / train/extr_return_raw_std 84.7 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.55 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.36 / train/image_loss_std 0.48 / train/model_loss_mean 1.66 / train/model_loss_std 3.24 / 
train/model_opt_grad_norm 7.79 / train/model_opt_grad_steps 5.1e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6250 / train/policy_entropy_mag 0.91 / train/policy_entropy_max 0.84 / train/policy_entropy_mean
-0.55 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.3 / train/policy_logprob_mag 7.43 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.56 / train/policy_logprob_min -7.43 / train/policy_logprob_std 0.77 / train/policy_randomness_mag 0.75 / 
train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.14 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.13 / train/post_ent_mag 59.77 / train/post_ent_max 59.77 / train/post_ent_mean 42.04 / train/post_ent_min 22.21 / train/post_ent_std 
4.87 / train/prior_ent_mag 72.01 / train/prior_ent_max 72.01 / train/prior_ent_mean 43.87 / train/prior_ent_min 27.81 / train/prior_ent_std 5.59 / train/rep_loss_mean 2.07 / train/rep_loss_std 4.79 / train/reward_avg 0.57 / train/reward_loss_mean 0.05 / 
train/reward_loss_std 0.18 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.17 / train/reward_pred 0.57 / train/reward_rate 0.29 / eval_stats/mean_log_entropy 
0 / train_stats/mean_log_entropy -0.66 / report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 1.4e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / report/cont_pred 1 / report/cont_rate 1 /
report/dyn_loss_mean 1.92 / report/dyn_loss_std 3.9 / report/image_loss_mean 0.32 / report/image_loss_std 0.43 / report/model_loss_mean 1.55 / report/model_loss_std 2.69 / report/post_ent_mag 51.99 / report/post_ent_max 51.99 / report/post_ent_mean 43.55 / 
report/post_ent_min 29.44 / report/post_ent_std 2.65 / report/prior_ent_mag 72.02 / report/prior_ent_max 72.02 / report/prior_ent_mean 45.03 / report/prior_ent_min 37.04 / report/prior_ent_std 3.96 / report/rep_loss_mean 1.92 / report/rep_loss_std 3.9 / report/reward_avg 
1.04 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.22 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 0.15 / report/reward_pred 1.04 / 
report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.34 / 
eval/dyn_loss_std 5.45 / eval/image_loss_mean 0.44 / eval/image_loss_std 0.61 / eval/model_loss_mean 1.89 / eval/model_loss_std 3.72 / eval/post_ent_mag 64.77 / eval/post_ent_max 64.77 / eval/post_ent_mean 40.6 / eval/post_ent_min 22.01 / eval/post_ent_std 6.1 / 
eval/prior_ent_mag 72.02 / eval/prior_ent_max 72.02 / eval/prior_ent_mean 42.48 / eval/prior_ent_min 26.41 / eval/prior_ent_std 6.76 / eval/rep_loss_mean 2.34 / eval/rep_loss_std 5.45 / eval/reward_avg 0.36 / eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.21 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3e-3 / eval/reward_pos_acc 0.99 / eval/reward_pos_loss 0.21 / eval/reward_pred 0.36 / eval/reward_rate 0.19 / replay/size 1.1e5 / replay/inserts 3842 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3842 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 6.2e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.91 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.11 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 0.13 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1921 / 
timer/agent.train_total 243.39 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.96 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 8.9e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 106000 Counter(106000) 105937
Saved chunk: 20230921T235510F297068-7qRe3zLCnIZ2ND9Hkic4gH-14mfVFuwUThpJ0AsdHC0Bv-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230921T235545F843813-22FXFFvQbn1NHf3EwqthHV-3KFKwaVAzH5Crcjk4YrD2T-1024.npz
Starting evaluation at step 106500 Counter(106500) 106437
eval_Episode has 500 steps and return 800.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 107000 Counter(107000) 106937
Saved chunk: 20230921T235628F509544-14mfVFuwUThpJ0AsdHC0Bv-2PcTZ94A8WYlF23GA0tXGa-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 818.0.
Starting evaluation at step 107500 Counter(107500) 107437
eval_Episode has 500 steps and return 823.0.
Saved chunk: 20230921T235705F866928-3KFKwaVAzH5Crcjk4YrD2T-0affI1O8tkKV6e7siYojsq-1024.npz
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 108000 Counter(108000) 107937
Saved chunk: 20230921T235746F305235-2PcTZ94A8WYlF23GA0tXGa-57VCFBsM6yKABvKX7QlK87-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 108500 Counter(108500) 108437
eval_Episode has 500 steps and return 832.0.
Saved chunk: 20230921T235828F470802-0affI1O8tkKV6e7siYojsq-76XwkS6acHGnRhn18sVctE-1024.npz
train_Episode has 500 steps and return 819.0.
Starting evaluation at step 109000 Counter(109000) 108937
Saved chunk: 20230921T235903F918209-57VCFBsM6yKABvKX7QlK87-14XtRcVh16N3KELfwwqmjt-1024.npz
eval_Episode has 500 steps and return 819.0.
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 109500 Counter(109500) 109437
eval_Episode has 500 steps and return 670.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 219002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 830 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 670 / eval_episode/reward_rate 0.67 / train/action_mag 2 / train/action_max 1.99 / train/action_mean 0.11 / train/action_min -1.66 / train/action_std 0.79 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.19 / train/actor_opt_grad_steps 5.3e4 / train/actor_opt_loss -82.75 / train/adv_mag 0.78 / train/adv_max 0.77 / train/adv_mean 8.6e-3 / train/adv_min -0.5 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.6e-10 / train/cont_loss_std 1.3e-9 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.6e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.04 / 
train/dyn_loss_std 4.74 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.48 / train/extr_critic_critic_opt_grad_steps 5.3e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 621.57 / train/extr_critic_max 621.57 / train/extr_critic_mean 474.13 / train/extr_critic_min 266.11 / train/extr_critic_std 91.15 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.52 / 
train/extr_return_normed_min -0.12 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 620.38 / train/extr_return_raw_max 620.38 / train/extr_return_raw_mean 476.56 / train/extr_return_raw_min 296.48 / train/extr_return_raw_std 92.05
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.59 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.35 / train/image_loss_std 0.46 / train/model_loss_mean 1.63 / train/model_loss_std 3.19 / 
train/model_opt_grad_norm 8.05 / train/model_opt_grad_steps 5.3e4 / train/model_opt_loss 9233.89 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5692.31 / train/policy_entropy_mag 0.91 / train/policy_entropy_max 0.85 / 
train/policy_entropy_mean -0.58 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.28 / train/policy_logprob_mag 7.51 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.58 / train/policy_logprob_min -7.51 / train/policy_logprob_std 0.76 / 
train/policy_randomness_mag 0.75 / train/policy_randomness_max 0.75 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 1.1e-3 / train/policy_randomness_std 0.12 / train/post_ent_mag 59.87 / train/post_ent_max 59.87 / train/post_ent_mean 42.04 / 
train/post_ent_min 22.84 / train/post_ent_std 4.72 / train/prior_ent_mag 72.08 / train/prior_ent_max 72.08 / train/prior_ent_mean 43.82 / train/prior_ent_min 28.24 / train/prior_ent_std 5.52 / train/rep_loss_mean 2.04 / train/rep_loss_std 4.74 / train/reward_avg 0.62 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.16 / train/reward_pred 0.62 / train/reward_rate 0.31 
/ train_stats/mean_log_entropy -0.69 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.4e-10 / report/cont_loss_std 9.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.23 / report/dyn_loss_std 5.45 / report/image_loss_mean 0.4 / report/image_loss_std 0.55 / report/model_loss_mean 1.79 / report/model_loss_std 3.71 / report/post_ent_mag 50.62 / report/post_ent_max 50.62 / 
report/post_ent_mean 42.38 / report/post_ent_min 21.27 / report/post_ent_std 5.31 / report/prior_ent_mag 72.37 / report/prior_ent_max 72.37 / report/prior_ent_mean 44.3 / report/prior_ent_min 25.28 / report/prior_ent_std 5.76 / report/rep_loss_mean 2.23 / 
report/rep_loss_std 5.45 / report/reward_avg 0.56 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.2 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.18 / report/reward_pred 0.55 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 8.6e-11 / eval/cont_loss_std 3.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 2.68 / eval/dyn_loss_std 5.8 / eval/image_loss_mean 0.57 / eval/image_loss_std 0.88 / eval/model_loss_mean 2.21 / eval/model_loss_std 4.13 / eval/post_ent_mag 64.58 / eval/post_ent_max 64.58 / eval/post_ent_mean 40.86 / eval/post_ent_min 22.14 / 
eval/post_ent_std 5.99 / eval/prior_ent_mag 72.37 / eval/prior_ent_max 72.37 / eval/prior_ent_mean 43.28 / eval/prior_ent_min 27.5 / eval/prior_ent_std 6.12 / eval/rep_loss_mean 2.68 / eval/rep_loss_std 5.8 / eval/reward_avg 0.29 / eval/reward_loss_mean 0.03 / 
eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.18 / eval/reward_pred 0.29 / eval/reward_rate 0.15 / replay/size 1.1e5 / replay/inserts 3884 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.49 / timer/env.step_count 3884 / timer/env.step_total 19.26 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.85 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.12 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7892 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1942
/ timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1942 / timer/agent.train_total 245.71 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230921T235947F603042-76XwkS6acHGnRhn18sVctE-2TknanjNegOxxyDXfokT1s-1024.npz
train_Episode has 500 steps and return 800.0.
Starting evaluation at step 110000 Counter(110000) 109937
Saved chunk: 20230922T000021F543188-14XtRcVh16N3KELfwwqmjt-3XM9lpEda4pOcWJoXkEhPe-1024.npz
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 110500 Counter(110500) 110437
eval_Episode has 500 steps and return 810.0.
Saved chunk: 20230922T000107F363409-2TknanjNegOxxyDXfokT1s-6vmedkLuZ5OIccH9Ezlxl5-1024.npz
train_Episode has 500 steps and return 814.0.
Starting evaluation at step 111000 Counter(111000) 110937
Saved chunk: 20230922T000139F819037-3XM9lpEda4pOcWJoXkEhPe-2uTFIk4LBmyN16QQn9Z1a3-1024.npz
eval_Episode has 500 steps and return 834.0.
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 111500 Counter(111500) 111437
eval_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T000226F646640-6vmedkLuZ5OIccH9Ezlxl5-4ME6au15IIjGSf3iN2sM1x-1024.npz
train_Episode has 500 steps and return 823.0.
Starting evaluation at step 112000 Counter(112000) 111937
Saved chunk: 20230922T000257F478054-2uTFIk4LBmyN16QQn9Z1a3-3thdCqrpO9RnAVqvrEeGJx-1024.npz
eval_Episode has 500 steps and return 831.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 112500 Counter(112500) 112437
eval_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T000345F754748-4ME6au15IIjGSf3iN2sM1x-7tXlLcdjKhxMtPFUYNrMMf-1024.npz
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 113000 Counter(113000) 112937
Saved chunk: 20230922T000414F979472-3thdCqrpO9RnAVqvrEeGJx-7uk96H4iEDuDq9e0hNoL2O-1024.npz
eval_Episode has 500 steps and return 825.0.
train_Episode has 500 steps and return 839.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 226806 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 825 / eval_episode/reward_rate 0.82 / train/action_mag 2.18 / train/action_max 2.14 / train/action_mean 0.11 / train/action_min -1.94 / train/action_std 0.8 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.16 / train/actor_opt_grad_steps 5.5e4 / train/actor_opt_loss -53.31 / train/adv_mag 0.68 / train/adv_max 0.63 / train/adv_mean 5.5e-3 / train/adv_min -0.52 /
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.3e-10 / train/cont_loss_std 6.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.3e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.02 / 
train/dyn_loss_std 4.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.41 / train/extr_critic_critic_opt_grad_steps 5.5e4 / train/extr_critic_critic_opt_loss 
8590.61 / train/extr_critic_mag 635.92 / train/extr_critic_max 635.92 / train/extr_critic_mean 513.67 / train/extr_critic_min 309.03 / train/extr_critic_std 88.57 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.55 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 636.69 / train/extr_return_raw_max 636.69 / train/extr_return_raw_mean 515.15 / train/extr_return_raw_min 327.68 / train/extr_return_raw_std 88.97
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.63 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.35 / train/image_loss_std 0.46 / train/model_loss_mean 1.61 / train/model_loss_std 3.15 / 
train/model_opt_grad_norm 7.76 / train/model_opt_grad_steps 5.5e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6564.1 / train/policy_entropy_mag 0.99 / train/policy_entropy_max 0.98 / 
train/policy_entropy_mean -0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.39 / train/policy_logprob_mag 7.68 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.39 / train/policy_logprob_min -7.68 / train/policy_logprob_std 0.81 / 
train/policy_randomness_mag 0.81 / train/policy_randomness_max 0.81 / train/policy_randomness_mean 0.22 / train/policy_randomness_min 9.4e-4 / train/policy_randomness_std 0.17 / train/post_ent_mag 59.28 / train/post_ent_max 59.28 / train/post_ent_mean 41.99 / 
train/post_ent_min 22.45 / train/post_ent_std 4.79 / train/prior_ent_mag 72.01 / train/prior_ent_max 72.01 / train/prior_ent_mean 43.77 / train/prior_ent_min 27.87 / train/prior_ent_std 5.59 / train/rep_loss_mean 2.02 / train/rep_loss_std 4.66 / train/reward_avg 0.65 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.17 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.65 / train/reward_rate 0.33 
/ train_stats/mean_log_entropy -0.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.2e-10 / report/cont_loss_std 6.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.99 / report/dyn_loss_std 5.11 / report/image_loss_mean 0.28 / report/image_loss_std 0.46 / report/model_loss_mean 1.53 / report/model_loss_std 3.44 / report/post_ent_mag 64.64 / report/post_ent_max 64.64 / 
report/post_ent_mean 40.22 / report/post_ent_min 21.25 / report/post_ent_std 5.21 / report/prior_ent_mag 71.58 / report/prior_ent_max 71.58 / report/prior_ent_mean 41.82 / report/prior_ent_min 26.49 / report/prior_ent_std 6.19 / report/rep_loss_mean 1.99 / 
report/rep_loss_std 5.11 / report/reward_avg 0.87 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.87 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 1.2e-10 / eval/cont_loss_std 6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.2e-10 / eval/cont_pred 
1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.03 / eval/dyn_loss_std 4.48 / eval/image_loss_mean 0.36 / eval/image_loss_std 0.45 / eval/model_loss_mean 1.62 / eval/model_loss_std 3.01 / eval/post_ent_mag 51.88 / eval/post_ent_max 51.88 / eval/post_ent_mean 43.05 / 
eval/post_ent_min 24.09 / eval/post_ent_std 4.37 / eval/prior_ent_mag 71.58 / eval/prior_ent_max 71.58 / eval/prior_ent_mean 44.73 / eval/prior_ent_min 28.12 / eval/prior_ent_std 5.2 / eval/rep_loss_mean 2.03 / eval/rep_loss_std 4.48 / eval/reward_avg 0.52 / 
eval/reward_loss_mean 0.04 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 0.52 / eval/reward_rate 0.26 / 
replay/size 1.1e5 / replay/inserts 3902 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3902 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.28 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.2e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7409 / timer/agent.policy_total 16.15 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1951 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1951 / timer/agent.train_total 246.5 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 26.01

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 113500 Counter(113500) 113437
eval_Episode has 500 steps and return 833.0.
Saved chunk: 20230922T000504F817447-7tXlLcdjKhxMtPFUYNrMMf-7ntPhxQpfGgqQnpwDD5MqQ-1024.npz
train_Episode has 500 steps and return 823.0.
Starting evaluation at step 114000 Counter(114000) 113937
Saved chunk: 20230922T000532F432991-7uk96H4iEDuDq9e0hNoL2O-0WmvNLGfik8JGD8SBwfFFF-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 114500 Counter(114500) 114437
eval_Episode has 500 steps and return 819.0.
Saved chunk: 20230922T000624F643548-7ntPhxQpfGgqQnpwDD5MqQ-4X9VpOw0BpqwX210vstdPo-1024.npz
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 115000 Counter(115000) 114937
Saved chunk: 20230922T000650F918869-0WmvNLGfik8JGD8SBwfFFF-1mP5ZQoXbe80V1TdH8qGij-1024.npz
eval_Episode has 500 steps and return 834.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 115500 Counter(115500) 115437
eval_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T000743F936114-4X9VpOw0BpqwX210vstdPo-4cMMkZkjI77YzqBs18TIIy-1024.npz
train_Episode has 500 steps and return 824.0.
Starting evaluation at step 116000 Counter(116000) 115937
Saved chunk: 20230922T000808F619740-1mP5ZQoXbe80V1TdH8qGij-1pt8NL0lQ3MYQcOrkPuvRQ-1024.npz
eval_Episode has 500 steps and return 827.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T000903F139499-4cMMkZkjI77YzqBs18TIIy-0000000000000000000000-388.npz
Saved chunk: 20230922T000926F190997-1pt8NL0lQ3MYQcOrkPuvRQ-0000000000000000000000-95.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 116500 Counter(116500) 116437
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T000903F139499-4cMMkZkjI77YzqBs18TIIy-4FAz5se93PjxjWtchbfp9u-1024.npz
Starting evaluation at step 117000 Counter(117000) 116937
Saved chunk: 20230922T000926F190997-1pt8NL0lQ3MYQcOrkPuvRQ-1LtIcza1EnQpTNfCBlb9rM-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 824.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 234502 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 837 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 824 / episode/reward_rate 0.82 / train/action_mag 2.12 / train/action_max 2.05 / train/action_mean 0.11 / train/action_min -1.91 / train/action_std 0.79 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.15 / train/actor_opt_grad_steps 5.7e4 / train/actor_opt_loss -34.05 / train/adv_mag 0.7 / train/adv_max 0.65 / train/adv_mean 3.6e-3 / train/adv_min -0.51 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.2e-10 / train/cont_loss_std 6.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.2e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 2.01 / 
train/dyn_loss_std 4.65 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.33 / train/extr_critic_critic_opt_grad_steps 5.7e4 / train/extr_critic_critic_opt_loss 
8455.05 / train/extr_critic_mag 644.55 / train/extr_critic_max 644.55 / train/extr_critic_mean 533.89 / train/extr_critic_min 340.64 / train/extr_critic_std 80.62 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.55 
/ train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 643.1 / train/extr_return_raw_max 643.1 / train/extr_return_raw_mean 534.74 / train/extr_return_raw_min 361.13 / train/extr_return_raw_std 81.03
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.67 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.34 / train/image_loss_std 0.45 / train/model_loss_mean 1.6 / train/model_loss_std 3.13 / 
train/model_opt_grad_norm 7.43 / train/model_opt_grad_steps 5.7e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7239.58 / train/policy_entropy_mag 1 / train/policy_entropy_max 0.95 / 
train/policy_entropy_mean -0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.39 / train/policy_logprob_mag 7.69 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.47 / train/policy_logprob_min -7.69 / train/policy_logprob_std 0.81 / 
train/policy_randomness_mag 0.8 / train/policy_randomness_max 0.8 / train/policy_randomness_mean 0.18 / train/policy_randomness_min 6.8e-4 / train/policy_randomness_std 0.17 / train/post_ent_mag 59.9 / train/post_ent_max 59.9 / train/post_ent_mean 41.99 / 
train/post_ent_min 22.92 / train/post_ent_std 4.7 / train/prior_ent_mag 72.03 / train/prior_ent_max 72.03 / train/prior_ent_mean 43.73 / train/prior_ent_min 27.97 / train/prior_ent_std 5.54 / train/rep_loss_mean 2.01 / train/rep_loss_std 4.65 / train/reward_avg 0.68 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.16 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.68 / train/reward_rate 0.34 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.17 / report/cont_avg 1 / report/cont_loss_mean 2.4e-10 / report/cont_loss_std 3.5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.98 / report/dyn_loss_std 5.13 / report/image_loss_mean 0.37 / report/image_loss_std 0.59 / report/model_loss_mean 1.6 / report/model_loss_std 3.58 / report/post_ent_mag 63.94 / report/post_ent_max 63.94 / 
report/post_ent_mean 41.88 / report/post_ent_min 22 / report/post_ent_std 4.49 / report/prior_ent_mag 71.86 / report/prior_ent_max 71.86 / report/prior_ent_mean 43.51 / report/prior_ent_min 29.81 / report/prior_ent_std 5.38 / report/rep_loss_mean 1.98 / 
report/rep_loss_std 5.13 / report/reward_avg 0.63 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.63 / report/reward_rate 0.32 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 5.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.03 / eval/dyn_loss_std 4.46 / eval/image_loss_mean 0.36 / eval/image_loss_std 0.38 / eval/model_loss_mean 1.63 / eval/model_loss_std 2.96 / eval/post_ent_mag 64.78 / eval/post_ent_max 64.78 / eval/post_ent_mean 
43.54 / eval/post_ent_min 26.08 / eval/post_ent_std 3.54 / eval/prior_ent_mag 71.86 / eval/prior_ent_max 71.86 / eval/prior_ent_mean 45.26 / eval/prior_ent_min 33.85 / eval/prior_ent_std 4.72 / eval/rep_loss_mean 2.03 / eval/rep_loss_std 4.46 / eval/reward_avg 0.64 / 
eval/reward_loss_mean 0.05 / eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.15 / eval/reward_pred 0.64 / eval/reward_rate 0.32 / 
replay/size 1.2e5 / replay/inserts 3848 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3848 / timer/env.step_total 19.18 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.15 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7856 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1924 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1924 / timer/agent.train_total 243.31 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.65

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 117500 Counter(117500) 117437
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 824.0.
Saved chunk: 20230922T001022F389745-4FAz5se93PjxjWtchbfp9u-6Bcb7pGSkvC0vy6L2hiH71-1024.npz
Starting evaluation at step 118000 Counter(118000) 117937
Saved chunk: 20230922T001043F850808-1LtIcza1EnQpTNfCBlb9rM-2R0gYZlUCyAR6fshb0fGuG-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 118500 Counter(118500) 118437
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T001142F359439-6Bcb7pGSkvC0vy6L2hiH71-76s3iOn0WjroJuKxWxCQxc-1024.npz
Starting evaluation at step 119000 Counter(119000) 118937
Saved chunk: 20230922T001202F388324-2R0gYZlUCyAR6fshb0fGuG-3riRht0bljhNVqYRxCEvc7-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 119500 Counter(119500) 119437
eval_Episode has 500 steps and return 820.0.
train_Episode has 500 steps and return 622.0.
Saved chunk: 20230922T001301F699330-76s3iOn0WjroJuKxWxCQxc-486uRp6ogLpL6zg7ndlV3A-1024.npz
Starting evaluation at step 120000 Counter(120000) 119937
eval_Episode has 500 steps and return 828.0.
Saved chunk: 20230922T001320F121746-3riRht0bljhNVqYRxCEvc7-56ItqrWwa05yzr4ptpOwuw-1024.npz
train_Episode has 500 steps and return 820.0.
Starting evaluation at step 120500 Counter(120500) 120437
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T001420F870002-486uRp6ogLpL6zg7ndlV3A-7KXmZnpWmILagiqGUQIAVA-1024.npz
Starting evaluation at step 121000 Counter(121000) 120937
eval_Episode has 500 steps and return 830.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 242194 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 830 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 838 / episode/reward_rate 0.84 / train/action_mag 2.31 / train/action_max 2.14 / train/action_mean 0.11 / train/action_min -2.08 / train/action_std 0.78 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 5.9e4 / train/actor_opt_loss -32.73 / train/adv_mag 0.81 / train/adv_max 0.78 / train/adv_mean 3.5e-3 / train/adv_min -0.5 / 
train/adv_std 0.04 / train/cont_avg 1 / train/cont_loss_mean 1.1e-10 / train/cont_loss_std 6.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1.1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.99 / 
train/dyn_loss_std 4.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.34 / train/extr_critic_critic_opt_grad_steps 5.9e4 / train/extr_critic_critic_opt_loss 
9450.32 / train/extr_critic_mag 660.7 / train/extr_critic_max 660.7 / train/extr_critic_mean 544.54 / train/extr_critic_min 316.03 / train/extr_critic_std 81.31 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.02 / train/extr_return_normed_mean 0.56 / 
train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 656.47 / train/extr_return_raw_max 656.47 / train/extr_return_raw_mean 545.37 / train/extr_return_raw_min 371.23 / train/extr_return_raw_std 81.64
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.68 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.33 / train/image_loss_std 0.45 / train/model_loss_mean 1.57 / train/model_loss_std 3.09 / 
train/model_opt_grad_norm 7.7 / train/model_opt_grad_steps 5.9e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7630.21 / train/policy_entropy_mag 1.09 / train/policy_entropy_max 1.07 / 
train/policy_entropy_mean -0.59 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.32 / train/policy_logprob_mag 7.39 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.59 / train/policy_logprob_min -7.39 / train/policy_logprob_std 0.78 / 
train/policy_randomness_mag 0.85 / train/policy_randomness_max 0.85 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 5.9e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 59.96 / train/post_ent_max 59.96 / train/post_ent_mean 42.04 / 
train/post_ent_min 23.21 / train/post_ent_std 4.57 / train/prior_ent_mag 71.95 / train/prior_ent_max 71.95 / train/prior_ent_mean 43.76 / train/prior_ent_min 28.38 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.99 / train/rep_loss_std 4.59 / train/reward_avg 0.69 / 
train/reward_loss_mean 0.05 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.15 / train/reward_pred 0.69 / train/reward_rate 0.35 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.56 / report/cont_avg 1 / report/cont_loss_mean 1e-10 / report/cont_loss_std 3.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.97 / report/dyn_loss_std 4.44 / report/image_loss_mean 0.3 / report/image_loss_std 0.37 / report/model_loss_mean 1.51 / report/model_loss_std 2.94 / report/post_ent_mag 64.28 / report/post_ent_max 64.28 / 
report/post_ent_mean 40.82 / report/post_ent_min 20.04 / report/post_ent_std 5.88 / report/prior_ent_mag 72 / report/prior_ent_max 72 / report/prior_ent_mean 42.64 / report/prior_ent_min 24.53 / report/prior_ent_std 6.55 / report/rep_loss_mean 1.97 / report/rep_loss_std 
4.44 / report/reward_avg 0.57 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.14 / 
report/reward_pred 0.56 / report/reward_rate 0.29 / eval/cont_avg 1 / eval/cont_loss_mean 8.2e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 2.07 / eval/dyn_loss_std 4.53 / eval/image_loss_mean 0.34 / eval/image_loss_std 0.47 / eval/model_loss_mean 1.62 / eval/model_loss_std 3.09 / eval/post_ent_mag 64.34 / eval/post_ent_max 64.34 / eval/post_ent_mean 41.21 / eval/post_ent_min 24.46 / 
eval/post_ent_std 5.38 / eval/prior_ent_mag 72 / eval/prior_ent_max 72 / eval/prior_ent_mean 43.16 / eval/prior_ent_min 28.17 / eval/prior_ent_std 6.01 / eval/rep_loss_mean 2.07 / eval/rep_loss_std 4.53 / eval/reward_avg 0.47 / eval/reward_loss_mean 0.04 / 
eval/reward_loss_std 0.2 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.17 / eval/reward_pred 0.47 / eval/reward_rate 0.24 / replay/size 1.2e5 / replay/inserts 3846 /
replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3846 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.44 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7854 / timer/agent.policy_total 17.03 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.7e-3 / timer/dataset_train_count 
1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1923 / timer/agent.train_total 243.55 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 824.0.
Starting evaluation at step 121500 Counter(121500) 121437
Saved chunk: 20230922T001437F714673-56ItqrWwa05yzr4ptpOwuw-0OXzPMobDEyfTuuZjmKmep-1024.npz
eval_Episode has 500 steps and return 827.0.
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T001540F076010-7KXmZnpWmILagiqGUQIAVA-3pSRTOHkvmlHZ8u6mFNnot-1024.npz
Starting evaluation at step 122000 Counter(122000) 121937
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 122500 Counter(122500) 122437
Saved chunk: 20230922T001631F660668-0OXzPMobDEyfTuuZjmKmep-1JLaILSpRQDzgjeCc2orEM-1024.npz
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T001700F221137-3pSRTOHkvmlHZ8u6mFNnot-6M0vrTpNS4Igyw9KIlMhKf-1024.npz
Starting evaluation at step 123000 Counter(123000) 122937
eval_Episode has 500 steps and return 825.0.
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 123500 Counter(123500) 123437
Saved chunk: 20230922T001749F469000-1JLaILSpRQDzgjeCc2orEM-6sYsSgTDy1vDgQtNcdcZBd-1024.npz
eval_Episode has 500 steps and return 824.0.
train_Episode has 500 steps and return 833.0.
Saved chunk: 20230922T001819F502922-6M0vrTpNS4Igyw9KIlMhKf-5NrldBgzpZvwAVJeglur3d-1024.npz
Starting evaluation at step 124000 Counter(124000) 123937
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 672.0.
Starting evaluation at step 124500 Counter(124500) 124437
Saved chunk: 20230922T001907F108984-6sYsSgTDy1vDgQtNcdcZBd-4Av0sgczTRBjjSG4donfFK-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T001938F738140-5NrldBgzpZvwAVJeglur3d-3QOmH5Y0oeLWGXlVBXcT8w-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 249982 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 834 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 837 / eval_episode/reward_rate 0.84 / train/action_mag 2.36 / train/action_max 2.28 / train/action_mean 0.09 / train/action_min -1.93 / train/action_std 0.76 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.18 / train/actor_opt_grad_steps 6.1e4 / train/actor_opt_loss -29.22 / train/adv_mag 0.65 / train/adv_max 0.6 / train/adv_mean 3.1e-3 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 1e-10 / train/cont_loss_std 6.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 1e-10 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.97 / 
train/dyn_loss_std 4.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.3 / train/extr_critic_critic_opt_grad_steps 6.1e4 / train/extr_critic_critic_opt_loss 
9758.1 / train/extr_critic_mag 677.1 / train/extr_critic_max 677.1 / train/extr_critic_mean 559.49 / train/extr_critic_min 366.74 / train/extr_critic_std 79.62 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.58 / 
train/extr_return_normed_min -0.15 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 672.27 / train/extr_return_raw_max 672.27 / train/extr_return_raw_mean 560.24 / train/extr_return_raw_min 382.94 / train/extr_return_raw_std 79.95
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.72 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.32 / train/image_loss_std 0.44 / train/model_loss_mean 1.56 / train/model_loss_std 3.06 / 
train/model_opt_grad_norm 7.61 / train/model_opt_grad_steps 6.1e4 / train/model_opt_loss 9243.14 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5948.72 / train/policy_entropy_mag 1.09 / train/policy_entropy_max 1.09 / 
train/policy_entropy_mean -0.59 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.33 / train/policy_logprob_mag 7.46 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.59 / train/policy_logprob_min -7.46 / train/policy_logprob_std 0.78 / 
train/policy_randomness_mag 0.86 / train/policy_randomness_max 0.86 / train/policy_randomness_mean 0.13 / train/policy_randomness_min 4.7e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 59.61 / train/post_ent_max 59.61 / train/post_ent_mean 42.04 / 
train/post_ent_min 23.37 / train/post_ent_std 4.5 / train/prior_ent_mag 71.81 / train/prior_ent_max 71.81 / train/prior_ent_mean 43.72 / train/prior_ent_min 28.84 / train/prior_ent_std 5.45 / train/rep_loss_mean 1.97 / train/rep_loss_std 4.55 / train/reward_avg 0.74 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.74 / train/reward_rate 0.38 / 
train_stats/mean_log_entropy -0.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.6e-10 / report/cont_loss_std 2.9e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-10 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.93 / report/dyn_loss_std 4.08 / report/image_loss_mean 0.32 / report/image_loss_std 0.38 / report/model_loss_mean 1.52 / report/model_loss_std 2.7 / report/post_ent_mag 65.82 / report/post_ent_max 65.82 / 
report/post_ent_mean 41.19 / report/post_ent_min 21.93 / report/post_ent_std 5.37 / report/prior_ent_mag 71.89 / report/prior_ent_max 71.89 / report/prior_ent_mean 42.97 / report/prior_ent_min 26.38 / report/prior_ent_std 6.11 / report/rep_loss_mean 1.93 / 
report/rep_loss_std 4.08 / report/reward_avg 0.54 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.54 / report/reward_rate 0.27 / eval/cont_avg 1 / eval/cont_loss_mean 1.3e-10 / eval/cont_loss_std 7.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.3e-10 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.11 / eval/dyn_loss_std 5.45 / eval/image_loss_mean 0.34 / eval/image_loss_std 0.54 / eval/model_loss_mean 1.67 / eval/model_loss_std 3.71 / eval/post_ent_mag 52.86 / eval/post_ent_max 52.86 / eval/post_ent_mean 
41.57 / eval/post_ent_min 21.72 / eval/post_ent_std 4.53 / eval/prior_ent_mag 71.89 / eval/prior_ent_max 71.89 / eval/prior_ent_mean 43.43 / eval/prior_ent_min 30.97 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 2.11 / eval/rep_loss_std 5.45 / eval/reward_avg 0.76 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.2 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 0.76 / eval/reward_rate 0.38 / replay/size
1.2e5 / replay/inserts 3894 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3894 / timer/env.step_total 19.46 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.79 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7401 / timer/agent.policy_total 16.27 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1947 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1947 / timer/agent.train_total 246.29 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.95

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 125000 Counter(125000) 124937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 828.0.
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 125500 Counter(125500) 125437
Saved chunk: 20230922T002024F770618-4Av0sgczTRBjjSG4donfFK-4uVW7yZ5VmrUqpQdg32G5e-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T002057F833554-3QOmH5Y0oeLWGXlVBXcT8w-2xRVV8RAYs6MwXGIHjTL0W-1024.npz
Starting evaluation at step 126000 Counter(126000) 125937
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 126500 Counter(126500) 126437
Saved chunk: 20230922T002143F338176-4uVW7yZ5VmrUqpQdg32G5e-2FEqhYiAMmh4Tp9BhwE2nq-1024.npz
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 832.0.
Saved chunk: 20230922T002218F110666-2xRVV8RAYs6MwXGIHjTL0W-7epqCQUUSJ5r3XYLh5OCJ8-1024.npz
Starting evaluation at step 127000 Counter(127000) 126937
eval_Episode has 500 steps and return 819.0.
train_Episode has 500 steps and return 805.0.
Starting evaluation at step 127500 Counter(127500) 127437
Saved chunk: 20230922T002301F103519-2FEqhYiAMmh4Tp9BhwE2nq-6NKeUFDW5oplQ0crYw3mJS-1024.npz
eval_Episode has 500 steps and return 815.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T002337F386396-7epqCQUUSJ5r3XYLh5OCJ8-0000000000000000000000-724.npz
Saved chunk: 20230922T002418F811137-6NKeUFDW5oplQ0crYw3mJS-0000000000000000000000-354.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 128000 Counter(128000) 127937
Saved chunk: 20230922T002337F386396-7epqCQUUSJ5r3XYLh5OCJ8-4RdALj5toFHgYCI4PGANSd-1024.npz
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 128500 Counter(128500) 128437
Saved chunk: 20230922T002418F811137-6NKeUFDW5oplQ0crYw3mJS-4rYs2vbIRnuBUxcyuOAN9W-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 809.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 257666 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 835 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 809 / episode/reward_rate 0.81 / train/action_mag 2.34 / train/action_max 2.34 / train/action_mean 0.09 / train/action_min -1.57 / train/action_std 0.75 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.17 / train/actor_opt_grad_steps 6.3e4 / train/actor_opt_loss -20.61 / train/adv_mag 0.57 / train/adv_max 0.51 / train/adv_mean 2.3e-3 / train/adv_min -0.49 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 9.6e-11 / train/cont_loss_std 5.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.95 / 
train/dyn_loss_std 4.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.3 / train/extr_critic_critic_opt_grad_steps 6.3e4 / train/extr_critic_critic_opt_loss 
9603.83 / train/extr_critic_mag 677.29 / train/extr_critic_max 677.29 / train/extr_critic_mean 569.74 / train/extr_critic_min 385.83 / train/extr_critic_std 74.87 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.05 / train/extr_return_normed_mean 0.59 
/ train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 673.14 / train/extr_return_raw_max 673.14 / train/extr_return_raw_mean 570.25 / train/extr_return_raw_min 397.99 / train/extr_return_raw_std 
75.24 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.77 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.32 / train/image_loss_std 0.44 / train/model_loss_mean 1.54 / train/model_loss_std 3.01 / 
train/model_opt_grad_norm 7.9 / train/model_opt_grad_steps 6.3e4 / train/model_opt_loss 9977.73 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6458.33 / train/policy_entropy_mag 1.05 / train/policy_entropy_max 1.05 / 
train/policy_entropy_mean -0.61 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.31 / train/policy_logprob_mag 7.5 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.61 / train/policy_logprob_min -7.5 / train/policy_logprob_std 0.77 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.12 / train/policy_randomness_min 3.5e-4 / train/policy_randomness_std 0.13 / train/post_ent_mag 59.24 / train/post_ent_max 59.24 / train/post_ent_mean 42.02 / 
train/post_ent_min 23.75 / train/post_ent_std 4.42 / train/prior_ent_mag 71.63 / train/prior_ent_max 71.63 / train/prior_ent_mean 43.65 / train/prior_ent_min 28.87 / train/prior_ent_std 5.41 / train/rep_loss_mean 1.95 / train/rep_loss_std 4.47 / train/reward_avg 0.78 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.77 / train/reward_rate 0.39 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.6 / report/cont_avg 1 / report/cont_loss_mean 8.3e-11 / report/cont_loss_std 2.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.88 / report/dyn_loss_std 4.02 / report/image_loss_mean 0.29 / report/image_loss_std 0.38 / report/model_loss_mean 1.48 / report/model_loss_std 2.7 / report/post_ent_mag 53.14 / report/post_ent_max 53.14 / 
report/post_ent_mean 42.87 / report/post_ent_min 19.56 / report/post_ent_std 3.83 / report/prior_ent_mag 71.89 / report/prior_ent_max 71.89 / report/prior_ent_mean 44.55 / report/prior_ent_min 28.97 / report/prior_ent_std 5.07 / report/rep_loss_mean 1.88 / 
report/rep_loss_std 4.02 / report/reward_avg 0.94 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.93 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-10 / eval/cont_loss_std 3.9e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-10 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.25 / eval/dyn_loss_std 5 / eval/image_loss_mean 0.41 / eval/image_loss_std 0.58 / eval/model_loss_mean 1.82 / eval/model_loss_std 3.41 / eval/post_ent_mag 53.83 / eval/post_ent_max 53.83 / eval/post_ent_mean 42.73 / 
eval/post_ent_min 20.93 / eval/post_ent_std 3.46 / eval/prior_ent_mag 71.89 / eval/prior_ent_max 71.89 / eval/prior_ent_mean 44.63 / eval/prior_ent_min 33.21 / eval/prior_ent_std 4.54 / eval/rep_loss_mean 2.25 / eval/rep_loss_std 5 / eval/reward_avg 0.71 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.2 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.7 / eval/reward_rate 0.36 / replay/size 
1.3e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3842 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.98 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.4 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1921 / timer/agent.train_total 242.72 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.23 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 129000 Counter(129000) 128937
eval_Episode has 500 steps and return 814.0.
Saved chunk: 20230922T002456F803970-4RdALj5toFHgYCI4PGANSd-4qIi6Vz8LlxRif4bJ9al5c-1024.npz
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 129500 Counter(129500) 129437
Saved chunk: 20230922T002536F596202-4rYs2vbIRnuBUxcyuOAN9W-4uZV7hiSUHVyTybwMgjV0v-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 130000 Counter(130000) 129937
eval_Episode has 500 steps and return 829.0.
Saved chunk: 20230922T002619F972963-4qIi6Vz8LlxRif4bJ9al5c-6AlPQfnixMEULBYrqVhZA8-1024.npz
train_Episode has 500 steps and return 821.0.
Starting evaluation at step 130500 Counter(130500) 130437
Saved chunk: 20230922T002655F061264-4uZV7hiSUHVyTybwMgjV0v-4Sr5xbe2gGQHIiLdus6aLm-1024.npz
eval_Episode has 500 steps and return 823.0.
train_Episode has 500 steps and return 815.0.
Starting evaluation at step 131000 Counter(131000) 130937
eval_Episode has 500 steps and return 827.0.
Saved chunk: 20230922T002739F459059-6AlPQfnixMEULBYrqVhZA8-1dTBttr912BQDRSiDPdj9b-1024.npz
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 131500 Counter(131500) 131437
Saved chunk: 20230922T002812F856606-4Sr5xbe2gGQHIiLdus6aLm-5jRzVc3FWZ0Aory9dtODxD-1024.npz
eval_Episode has 500 steps and return 822.0.
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 132000 Counter(132000) 131937
eval_Episode has 500 steps and return 828.0.
Saved chunk: 20230922T002858F686705-1dTBttr912BQDRSiDPdj9b-2yUlApviAuVvFeG2DtRBRS-1024.npz
train_Episode has 500 steps and return 820.0.
Starting evaluation at step 132500 Counter(132500) 132437
Saved chunk: 20230922T002930F577618-5jRzVc3FWZ0Aory9dtODxD-5FsT1AHuslr9b3d16oJOdB-1024.npz
eval_Episode has 500 steps and return 821.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 265354 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 821 / eval_episode/reward_rate 0.82 / episode/length 500 / episode/score 820 / episode/reward_rate 0.82 / train/action_mag 2.07 / train/action_max 2.06 / train/action_mean 0.1 / train/action_min -1.53 / train/action_std 0.75 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.13 / train/actor_opt_grad_steps 6.5e4 / train/actor_opt_loss -10.68 / train/adv_mag 0.56 / train/adv_max 0.48 / train/adv_mean 1.2e-3 / train/adv_min -0.48 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 9.1e-11 / train/cont_loss_std 5.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.94 / 
train/dyn_loss_std 4.48 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.24 / train/extr_critic_critic_opt_grad_steps 6.5e4 / train/extr_critic_critic_opt_loss 
9591.47 / train/extr_critic_mag 672.05 / train/extr_critic_max 672.05 / train/extr_critic_mean 571.58 / train/extr_critic_min 389.08 / train/extr_critic_std 74.1 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.59 /
train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.4 / train/extr_return_raw_max 668.4 / train/extr_return_raw_mean 571.85 / train/extr_return_raw_min 403.57 / train/extr_return_raw_std 74.51 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.77 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.31 / train/image_loss_std 0.43 / train/model_loss_mean 1.54 / train/model_loss_std 3.01 / 
train/model_opt_grad_norm 7.79 / train/model_opt_grad_steps 6.5e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8333.33 / train/policy_entropy_mag 0.94 / train/policy_entropy_max 0.91 / 
train/policy_entropy_mean -0.53 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.32 / train/policy_logprob_mag 7.56 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.53 / train/policy_logprob_min -7.56 / train/policy_logprob_std 0.78 / 
train/policy_randomness_mag 0.78 / train/policy_randomness_max 0.78 / train/policy_randomness_mean 0.15 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.14 / train/post_ent_mag 59.2 / train/post_ent_max 59.2 / train/post_ent_mean 41.97 / 
train/post_ent_min 23.66 / train/post_ent_std 4.5 / train/prior_ent_mag 71.45 / train/prior_ent_max 71.45 / train/prior_ent_mean 43.61 / train/prior_ent_min 29.25 / train/prior_ent_std 5.46 / train/rep_loss_mean 1.94 / train/rep_loss_std 4.48 / train/reward_avg 0.78 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.78 / train/reward_rate 0.39 
/ eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy -0.29 / report/cont_avg 1 / report/cont_loss_mean 7.2e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.95 / report/dyn_loss_std 4.62 / report/image_loss_mean 0.3 / report/image_loss_std 0.43 / report/model_loss_mean 1.57 / report/model_loss_std 3.14 / report/post_ent_mag 51.1 / report/post_ent_max 51.1 / 
report/post_ent_mean 42.18 / report/post_ent_min 26.81 / report/post_ent_std 2.99 / report/prior_ent_mag 70.88 / report/prior_ent_max 70.88 / report/prior_ent_mean 43.63 / report/prior_ent_min 32.51 / report/prior_ent_std 4.42 / report/rep_loss_mean 1.95 / 
report/rep_loss_std 4.62 / report/reward_avg 1.15 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.26 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.15 / report/reward_pred 1.15 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.88 / eval/dyn_loss_std 4.33 / eval/image_loss_mean 0.3 / eval/image_loss_std 0.48 / eval/model_loss_mean 1.49 / eval/model_loss_std 2.95 / eval/post_ent_mag 51.29 / eval/post_ent_max 51.29 / eval/post_ent_mean 
42.32 / eval/post_ent_min 26.58 / eval/post_ent_std 4.18 / eval/prior_ent_mag 70.88 / eval/prior_ent_max 70.88 / eval/prior_ent_mean 43.78 / eval/prior_ent_min 29.38 / eval/prior_ent_std 5.17 / eval/rep_loss_mean 1.88 / eval/rep_loss_std 4.33 / eval/reward_avg 0.99 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.09 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 0.99 / eval/reward_rate 0.5 / 
replay/size 1.3e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3844 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.57 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7852 / timer/agent.policy_total 17.24 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1922 / timer/agent.train_total 243.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 133000 Counter(133000) 132937
eval_Episode has 500 steps and return 820.0.
Saved chunk: 20230922T003017F944262-2yUlApviAuVvFeG2DtRBRS-3XKOYRu4SOz2BpRmZMKeEr-1024.npz
train_Episode has 500 steps and return 824.0.
Starting evaluation at step 133500 Counter(133500) 133437
Saved chunk: 20230922T003048F170110-5FsT1AHuslr9b3d16oJOdB-63Pl66BM1qfpturdUWbIlJ-1024.npz
eval_Episode has 500 steps and return 823.0.
train_Episode has 500 steps and return 811.0.
Starting evaluation at step 134000 Counter(134000) 133937
eval_Episode has 500 steps and return 814.0.
Saved chunk: 20230922T003137F892380-3XKOYRu4SOz2BpRmZMKeEr-5w0BkOdLofe6A0XlctKxvY-1024.npz
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 134500 Counter(134500) 134437
Saved chunk: 20230922T003206F776528-63Pl66BM1qfpturdUWbIlJ-1fQkHMZ5yePDxNKWLA7CIU-1024.npz
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 817.0.
Starting evaluation at step 135000 Counter(135000) 134937
eval_Episode has 500 steps and return 829.0.
Saved chunk: 20230922T003257F248804-5w0BkOdLofe6A0XlctKxvY-1xiEWV8vnb8YHHm0Ti8cLP-1024.npz
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 135500 Counter(135500) 135437
Saved chunk: 20230922T003324F420676-1fQkHMZ5yePDxNKWLA7CIU-4oBy6hrEMJwEHbWrtm19aS-1024.npz
eval_Episode has 500 steps and return 818.0.
train_Episode has 500 steps and return 818.0.
Starting evaluation at step 136000 Counter(136000) 135937
eval_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T003416F403630-1xiEWV8vnb8YHHm0Ti8cLP-4TKdIF4hachovqlwPRoHXl-1024.npz
train_Episode has 500 steps and return 821.0.
Starting evaluation at step 136500 Counter(136500) 136437
Saved chunk: 20230922T003442F003684-4oBy6hrEMJwEHbWrtm19aS-6JT34hQRlSv692XyboEbSd-1024.npz
eval_Episode has 500 steps and return 833.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 273054 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 821 / episode/reward_rate 0.82 / eval_episode/length 500 / eval_episode/score 833 / eval_episode/reward_rate 0.83 / train/action_mag 2.28 / train/action_max 2.2 / train/action_mean 0.09 / train/action_min -2.04 / train/action_std 0.78 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 6.7e4 / train/actor_opt_loss -8.66 / train/adv_mag 0.53 / train/adv_max 0.44 / train/adv_mean 9.9e-4 / train/adv_min -0.48 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 9.5e-11 / train/cont_loss_std 9.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 9.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.91 / 
train/dyn_loss_std 4.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.24 / train/extr_critic_critic_opt_grad_steps 6.7e4 / train/extr_critic_critic_opt_loss 
9649.63 / train/extr_critic_mag 669.16 / train/extr_critic_max 669.16 / train/extr_critic_mean 573.37 / train/extr_critic_min 393.8 / train/extr_critic_std 75.34 / train/extr_return_normed_mag 1.03 / train/extr_return_normed_max 1.03 / train/extr_return_normed_mean 0.61 /
train/extr_return_normed_min -0.18 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 665.72 / train/extr_return_raw_max 665.72 / train/extr_return_raw_mean 573.59 / train/extr_return_raw_min 401.09 / train/extr_return_raw_std 75.68
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.81 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.3 / train/image_loss_std 0.42 / train/model_loss_mean 1.5 / train/model_loss_std 2.93 / 
train/model_opt_grad_norm 7.46 / train/model_opt_grad_steps 6.7e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7409.33 / train/policy_entropy_mag 1.05 / train/policy_entropy_max 1.04 / 
train/policy_entropy_mean -0.37 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.49 / train/policy_logprob_mag 7.89 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.37 / train/policy_logprob_min -7.89 / train/policy_logprob_std 0.86 / 
train/policy_randomness_mag 0.84 / train/policy_randomness_max 0.84 / train/policy_randomness_mean 0.22 / train/policy_randomness_min 3e-4 / train/policy_randomness_std 0.21 / train/post_ent_mag 58.65 / train/post_ent_max 58.65 / train/post_ent_mean 41.75 / 
train/post_ent_min 23.86 / train/post_ent_std 4.56 / train/prior_ent_mag 71.24 / train/prior_ent_max 71.24 / train/prior_ent_mean 43.36 / train/prior_ent_min 29.16 / train/prior_ent_std 5.55 / train/rep_loss_mean 1.91 / train/rep_loss_std 4.35 / train/reward_avg 0.83 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.82 / train/reward_rate 0.42 / 
train_stats/mean_log_entropy 0.14 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.3e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.32 / report/image_loss_mean 0.25 / report/image_loss_std 0.42 / report/model_loss_mean 1.32 / report/model_loss_std 2.29 / report/post_ent_mag 54.94 / report/post_ent_max 54.94 / 
report/post_ent_mean 41.91 / report/post_ent_min 23.75 / report/post_ent_std 4.28 / report/prior_ent_mag 71.1 / report/prior_ent_max 71.1 / report/prior_ent_mean 43.26 / report/prior_ent_min 26.45 / report/prior_ent_std 5.52 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 3.32 / report/reward_avg 1.1 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 1.1 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 8e-11 / eval/cont_loss_std 2.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 2.05 / eval/dyn_loss_std 5.06 / eval/image_loss_mean 0.37 / eval/image_loss_std 0.54 / eval/model_loss_mean 1.64 / eval/model_loss_std 3.46 / eval/post_ent_mag 50.24 / eval/post_ent_max 50.24 / eval/post_ent_mean 43.52 / eval/post_ent_min 25.59 / 
eval/post_ent_std 3.34 / eval/prior_ent_mag 71.1 / eval/prior_ent_max 71.1 / eval/prior_ent_mean 45.22 / eval/prior_ent_min 37.78 / eval/prior_ent_std 4.43 / eval/rep_loss_mean 2.05 / eval/rep_loss_std 5.06 / eval/reward_avg 0.45 / eval/reward_loss_mean 0.04 / 
eval/reward_loss_std 0.18 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.46 / eval/reward_rate 0.23 / replay/size 1.4e5 / replay/inserts 
3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3850 / timer/env.step_total 19.24 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.96 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7858 / timer/agent.policy_total 17.18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 
1925 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1925 / timer/agent.train_total 243.23 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.66

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 137000 Counter(137000) 136937
eval_Episode has 500 steps and return 820.0.
Saved chunk: 20230922T003535F351934-4TKdIF4hachovqlwPRoHXl-60CoUcArVRhPC02MWSPCBN-1024.npz
train_Episode has 500 steps and return 815.0.
Starting evaluation at step 137500 Counter(137500) 137437
Saved chunk: 20230922T003559F409673-6JT34hQRlSv692XyboEbSd-404XwNZ4C4B4jryKypWKCr-1024.npz
eval_Episode has 500 steps and return 820.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 138000 Counter(138000) 137937
eval_Episode has 500 steps and return 833.0.
Saved chunk: 20230922T003655F456567-60CoUcArVRhPC02MWSPCBN-451p9cDzU4sa0uv60JZRC2-1024.npz
train_Episode has 500 steps and return 825.0.
Starting evaluation at step 138500 Counter(138500) 138437
Saved chunk: 20230922T003718F044819-404XwNZ4C4B4jryKypWKCr-3TS1Lyq8kQQQzQxy60ttoO-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 139000 Counter(139000) 138937
eval_Episode has 500 steps and return 811.0.
Saved chunk: 20230922T003814F720831-451p9cDzU4sa0uv60JZRC2-0nYOb5JJeIsbZVqUSIJrH7-1024.npz
train_Episode has 500 steps and return 831.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T003933F885204-0nYOb5JJeIsbZVqUSIJrH7-0000000000000000000000-36.npz
Saved chunk: 20230922T003835F729437-3TS1Lyq8kQQQzQxy60ttoO-0000000000000000000000-613.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 139500 Counter(139500) 139437
Saved chunk: 20230922T003835F729437-3TS1Lyq8kQQQzQxy60ttoO-1JJhPf3O2Uk12v4J1pdZub-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 140000 Counter(140000) 139937
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T003933F885204-0nYOb5JJeIsbZVqUSIJrH7-4bu7iDbqx0fHXFEGrFYONg-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 280842 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 841 / eval_episode/reward_rate 0.84 / train/action_mag 2.74 / train/action_max 2.48 / train/action_mean 0.1 / train/action_min -2.66 / train/action_std 0.8 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 6.9e4 / train/actor_opt_loss -10.12 / train/adv_mag 0.56 / train/adv_max 0.47 / train/adv_mean 1.1e-3 / train/adv_min -0.49 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 7.9e-11 / train/cont_loss_std 5.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.9 / 
train/dyn_loss_std 4.34 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.23 / train/extr_critic_critic_opt_grad_steps 6.9e4 / train/extr_critic_critic_opt_loss 
9711.94 / train/extr_critic_mag 667.82 / train/extr_critic_max 667.82 / train/extr_critic_mean 577.65 / train/extr_critic_min 399.31 / train/extr_critic_std 74.24 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.02 / train/extr_return_normed_mean 0.62 
/ train/extr_return_normed_min -0.16 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 664.49 / train/extr_return_raw_max 664.49 / train/extr_return_raw_mean 577.89 / train/extr_return_raw_min 409.57 / train/extr_return_raw_std 
74.52 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.82 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.3 / train/image_loss_std 0.41 / train/model_loss_mean 1.5 / train/model_loss_std 2.91 / 
train/model_opt_grad_norm 7.74 / train/model_opt_grad_steps 6.9e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7435.9 / train/policy_entropy_mag 1.23 / train/policy_entropy_max 1.23 / 
train/policy_entropy_mean -0.3 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.6 / train/policy_logprob_mag 7.91 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.3 / train/policy_logprob_min -7.91 / train/policy_logprob_std 0.93 / 
train/policy_randomness_mag 0.92 / train/policy_randomness_max 0.92 / train/policy_randomness_mean 0.25 / train/policy_randomness_min 2.6e-4 / train/policy_randomness_std 0.26 / train/post_ent_mag 59.09 / train/post_ent_max 59.09 / train/post_ent_mean 41.77 / 
train/post_ent_min 24.15 / train/post_ent_std 4.46 / train/prior_ent_mag 71.05 / train/prior_ent_max 71.05 / train/prior_ent_mean 43.34 / train/prior_ent_min 29.54 / train/prior_ent_std 5.48 / train/rep_loss_mean 1.9 / train/rep_loss_std 4.34 / train/reward_avg 0.83 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.83 / train/reward_rate 0.42 / 
train_stats/mean_log_entropy 0.36 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.4e-11 / report/cont_loss_std 3.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.84 / report/image_loss_mean 0.24 / report/image_loss_std 0.29 / report/model_loss_mean 1.32 / report/model_loss_std 2.5 / report/post_ent_mag 52.04 / report/post_ent_max 52.04 / 
report/post_ent_mean 41.69 / report/post_ent_min 25.33 / report/post_ent_std 4.39 / report/prior_ent_mag 70.67 / report/prior_ent_max 70.67 / report/prior_ent_mean 43.08 / report/prior_ent_min 28.04 / report/prior_ent_std 5.57 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.84 / report/reward_avg 1.09 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.08 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 8.8e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.14 / eval/dyn_loss_std 4.76 / eval/image_loss_mean 0.36 / eval/image_loss_std 0.76 / eval/model_loss_mean 1.7 / eval/model_loss_std 3.46 / eval/post_ent_mag 53.47 / eval/post_ent_max 53.47 / eval/post_ent_mean 
43.5 / eval/post_ent_min 26.82 / eval/post_ent_std 3.46 / eval/prior_ent_mag 70.67 / eval/prior_ent_max 70.67 / eval/prior_ent_mean 45.22 / eval/prior_ent_min 36.87 / eval/prior_ent_std 4.53 / eval/rep_loss_mean 2.14 / eval/rep_loss_std 4.76 / eval/reward_avg 0.62 / 
eval/reward_loss_mean 0.05 / eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.16 / eval/reward_pred 0.62 / eval/reward_rate 0.32 / 
replay/size 1.4e5 / replay/inserts 3894 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3894 / timer/env.step_total 19.43 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.46 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7401 / timer/agent.policy_total 16.33 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1947 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1947 / timer/agent.train_total 246.18 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.96

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 140500 Counter(140500) 140437
Saved chunk: 20230922T003953F503986-1JJhPf3O2Uk12v4J1pdZub-2Svjm83sWDwIbzKgPRGY39-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 825.0.
Starting evaluation at step 141000 Counter(141000) 140937
eval_Episode has 500 steps and return 821.0.
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T004053F078043-4bu7iDbqx0fHXFEGrFYONg-6JfBF5R4xDPgopytAYR80T-1024.npz
Starting evaluation at step 141500 Counter(141500) 141437
Saved chunk: 20230922T004111F708409-2Svjm83sWDwIbzKgPRGY39-7BeGA6C700qJDDz4amSEM7-1024.npz
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 142000 Counter(142000) 141937
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T004213F168673-6JfBF5R4xDPgopytAYR80T-1vSYVlG7UgL62n6eL5JrCM-1024.npz
Starting evaluation at step 142500 Counter(142500) 142437
Saved chunk: 20230922T004229F568524-7BeGA6C700qJDDz4amSEM7-4pxYSGIDA3LV2OW4DOKgs5-1024.npz
eval_Episode has 500 steps and return 820.0.
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 143000 Counter(143000) 142937
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 824.0.
Saved chunk: 20230922T004332F413462-1vSYVlG7UgL62n6eL5JrCM-0FROhU2ZmwCzqoDWRSjIyb-1024.npz
Starting evaluation at step 143500 Counter(143500) 143437
eval_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T004347F197870-4pxYSGIDA3LV2OW4DOKgs5-4FB6e4p2JAWziBXAx8Skxr-1024.npz
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 144000 Counter(144000) 143937
eval_Episode has 500 steps and return 835.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 288542 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 835 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 829 / episode/reward_rate 0.83 / train/action_mag 3.11 / train/action_max 2.86 / train/action_mean 0.09 / train/action_min -3.03 / train/action_std 0.83 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 7.1e4 / train/actor_opt_loss -9.88 / train/adv_mag 0.57 / train/adv_max 0.47 / train/adv_mean 1.1e-3 / train/adv_min -0.51 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 8.2e-11 / train/cont_loss_std 7.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 8.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.89 / 
train/dyn_loss_std 4.28 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.23 / train/extr_critic_critic_opt_grad_steps 7.1e4 / train/extr_critic_critic_opt_loss 
9871.26 / train/extr_critic_mag 668.42 / train/extr_critic_max 668.42 / train/extr_critic_mean 580.17 / train/extr_critic_min 398.05 / train/extr_critic_std 75.27 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.02 / train/extr_return_normed_mean 0.62 
/ train/extr_return_normed_min -0.17 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 665.2 / train/extr_return_raw_max 665.2 / train/extr_return_raw_mean 580.4 / train/extr_return_raw_min 407.15 / train/extr_return_raw_std 75.55 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.85 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.29 / train/image_loss_std 0.41 / train/model_loss_mean 1.48 / train/model_loss_std 2.87 / 
train/model_opt_grad_norm 7.23 / train/model_opt_grad_steps 7.1e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.33 / train/policy_entropy_max 1.33 / 
train/policy_entropy_mean -0.22 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.68 / train/policy_logprob_mag 8.12 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.22 / train/policy_logprob_min -8.12 / train/policy_logprob_std 0.98 / 
train/policy_randomness_mag 0.96 / train/policy_randomness_max 0.96 / train/policy_randomness_mean 0.29 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.29 / train/post_ent_mag 58.67 / train/post_ent_max 58.67 / train/post_ent_mean 41.6 / 
train/post_ent_min 24.16 / train/post_ent_std 4.58 / train/prior_ent_mag 70.77 / train/prior_ent_max 70.77 / train/prior_ent_mean 43.17 / train/prior_ent_min 29.5 / train/prior_ent_std 5.58 / train/rep_loss_mean 1.89 / train/rep_loss_std 4.28 / train/reward_avg 0.86 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.86 / train/reward_rate 0.43 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.38 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.89 / report/dyn_loss_std 4.25 / report/image_loss_mean 0.31 / report/image_loss_std 0.41 / report/model_loss_mean 1.5 / report/model_loss_std 2.87 / report/post_ent_mag 64.3 / report/post_ent_max 64.3 / report/post_ent_mean 
41.61 / report/post_ent_min 20.41 / report/post_ent_std 4.16 / report/prior_ent_mag 70.83 / report/prior_ent_max 70.83 / report/prior_ent_mean 43.12 / report/prior_ent_min 30.69 / report/prior_ent_std 5.31 / report/rep_loss_mean 1.89 / report/rep_loss_std 4.25 / 
report/reward_avg 0.87 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / 
report/reward_pred 0.87 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 4.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.88 / eval/dyn_loss_std 3.79 / eval/image_loss_mean 0.27 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.46 / eval/model_loss_std 2.45 / eval/post_ent_mag 53.41 / eval/post_ent_max 53.41 / eval/post_ent_mean 42.42 / eval/post_ent_min 31.67 / 
eval/post_ent_std 3.47 / eval/prior_ent_mag 70.83 / eval/prior_ent_max 70.83 / eval/prior_ent_mean 44.07 / eval/prior_ent_min 38.23 / eval/prior_ent_std 4.97 / eval/rep_loss_mean 1.88 / eval/rep_loss_std 3.79 / eval/reward_avg 1.03 / eval/reward_loss_mean 0.07 / 
eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.02 / eval/reward_rate 0.51 / replay/size 1.4e5 / replay/inserts 
3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3850 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.1 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.66 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.8e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7858 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 
1925 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1925 / timer/agent.train_total 243.21 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.66

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 833.0.
Saved chunk: 20230922T004451F468525-0FROhU2ZmwCzqoDWRSjIyb-0qMZxcftOWxnTPE8spZWFu-1024.npz
Starting evaluation at step 144500 Counter(144500) 144437
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 145000 Counter(145000) 144937
Saved chunk: 20230922T004504F698267-4FB6e4p2JAWziBXAx8Skxr-5XethXNCT6ObiWZ4SWtEJp-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 825.0.
Saved chunk: 20230922T004611F281233-0qMZxcftOWxnTPE8spZWFu-2WVmuJ1OjHfrn12gzl2vxJ-1024.npz
Starting evaluation at step 145500 Counter(145500) 145437
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 146000 Counter(146000) 145937
Saved chunk: 20230922T004658F509687-5XethXNCT6ObiWZ4SWtEJp-1hJzQ2hBS8XjlloJJVUxO4-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 825.0.
Saved chunk: 20230922T004730F591178-2WVmuJ1OjHfrn12gzl2vxJ-3hGsFc3IQ274XiNb7BXHVU-1024.npz
Starting evaluation at step 146500 Counter(146500) 146437
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 147000 Counter(147000) 146937
Saved chunk: 20230922T004816F129833-1hJzQ2hBS8XjlloJJVUxO4-2vxIBxPezHo9QabvC1bHWF-1024.npz
eval_Episode has 500 steps and return 795.0.
train_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T004849F773663-3hGsFc3IQ274XiNb7BXHVU-132ITx0VDnZHxexaPOeAxW-1024.npz
Starting evaluation at step 147500 Counter(147500) 147437
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 148000 Counter(148000) 147937
Saved chunk: 20230922T004933F666108-2vxIBxPezHo9QabvC1bHWF-2F7y3PQjajzd4zCuoDuxZQ-1024.npz
eval_Episode has 500 steps and return 821.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 296246 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 834 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 821 / eval_episode/reward_rate 0.82 / train/action_mag 3.2 / train/action_max 3 / train/action_mean 0.08 / train/action_min -3.07 / train/action_std 0.83 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.11 / train/actor_opt_grad_steps 7.3e4 / train/actor_opt_loss -11.49 / train/adv_mag 0.57 / train/adv_max 0.48 / train/adv_mean 1.2e-3 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 7.5e-11 / train/cont_loss_std 5.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.87 / 
train/dyn_loss_std 4.24 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.24 / train/extr_critic_critic_opt_grad_steps 7.3e4 / train/extr_critic_critic_opt_loss 
9929.2 / train/extr_critic_mag 669.73 / train/extr_critic_max 669.73 / train/extr_critic_mean 584.77 / train/extr_critic_min 401.21 / train/extr_critic_std 74.31 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.63 /
train/extr_return_normed_min -0.2 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 666.18 / train/extr_return_raw_max 666.18 / train/extr_return_raw_mean 585.03 / train/extr_return_raw_min 408.16 / train/extr_return_raw_std 74.59 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.89 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.29 / train/image_loss_std 0.4 / train/model_loss_mean 1.47 / train/model_loss_std 2.85 / 
train/model_opt_grad_norm 7.35 / train/model_opt_grad_steps 7.2e4 / train/model_opt_loss 7589.42 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5155.44 / train/policy_entropy_mag 1.35 / train/policy_entropy_max 1.35 / 
train/policy_entropy_mean -0.21 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.67 / train/policy_logprob_mag 8.04 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.21 / train/policy_logprob_min -8.04 / train/policy_logprob_std 0.98 / 
train/policy_randomness_mag 0.97 / train/policy_randomness_max 0.97 / train/policy_randomness_mean 0.29 / train/policy_randomness_min 2.8e-4 / train/policy_randomness_std 0.29 / train/post_ent_mag 58.1 / train/post_ent_max 58.1 / train/post_ent_mean 41.6 / 
train/post_ent_min 24.11 / train/post_ent_std 4.48 / train/prior_ent_mag 70.51 / train/prior_ent_max 70.51 / train/prior_ent_mean 43.13 / train/prior_ent_min 29.95 / train/prior_ent_std 5.51 / train/rep_loss_mean 1.87 / train/rep_loss_std 4.24 / train/reward_avg 0.9 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.15 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.14 / train/reward_pred 0.9 / train/reward_rate 0.45 / 
train_stats/mean_log_entropy 0.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.9e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.84 / report/dyn_loss_std 3.89 / report/image_loss_mean 0.29 / report/image_loss_std 0.42 / report/model_loss_mean 1.45 / report/model_loss_std 2.68 / report/post_ent_mag 51.25 / report/post_ent_max 51.25 / 
report/post_ent_mean 42.34 / report/post_ent_min 24.44 / report/post_ent_std 4.46 / report/prior_ent_mag 70.47 / report/prior_ent_max 70.47 / report/prior_ent_mean 43.92 / report/prior_ent_min 29.84 / report/prior_ent_std 5.23 / report/rep_loss_mean 1.84 / 
report/rep_loss_std 3.89 / report/reward_avg 0.79 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.4e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.78 / report/reward_rate 0.4 / eval/cont_avg 1 / eval/cont_loss_mean 7.9e-11 / eval/cont_loss_std 6.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.9e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.93 / eval/dyn_loss_std 4.32 / eval/image_loss_mean 0.32 / eval/image_loss_std 0.42 / eval/model_loss_mean 1.53 / eval/model_loss_std 2.97 / eval/post_ent_mag 52.85 / eval/post_ent_max 52.85 / eval/post_ent_mean 43.3 / 
eval/post_ent_min 27.54 / eval/post_ent_std 3.74 / eval/prior_ent_mag 70.47 / eval/prior_ent_max 70.47 / eval/prior_ent_mean 44.94 / eval/prior_ent_min 38.44 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 1.93 / eval/rep_loss_std 4.32 / eval/reward_avg 0.63 / 
eval/reward_loss_mean 0.06 / eval/reward_loss_std 0.27 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.18 / eval/reward_pred 0.63 / eval/reward_rate 0.32 / replay/size
1.5e5 / replay/inserts 3852 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3852 / timer/env.step_total 19.11 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.69 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7860 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / 
timer/dataset_train_count 1926 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1926 / timer/agent.train_total 243.4 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.67

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T005008F824330-132ITx0VDnZHxexaPOeAxW-60CWhlKDcHiCNYI79fl59K-1024.npz
Starting evaluation at step 148500 Counter(148500) 148437
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 149000 Counter(149000) 148937
Saved chunk: 20230922T005051F122105-2F7y3PQjajzd4zCuoDuxZQ-26YMoSaSosBiOL7WUvWpbw-1024.npz
eval_Episode has 500 steps and return 834.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 149500 Counter(149500) 149437
eval_Episode has 500 steps and return 821.0.
Saved chunk: 20230922T005128F673597-60CWhlKDcHiCNYI79fl59K-0ObvlfscELr6niSY02yc6R-1024.npz
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 150000 Counter(150000) 149937
Saved chunk: 20230922T005209F784605-26YMoSaSosBiOL7WUvWpbw-0heFotX40cawZd40f6bHo6-1024.npz
eval_Episode has 500 steps and return 826.0.
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 150500 Counter(150500) 150437
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T005251F497187-0ObvlfscELr6niSY02yc6R-0DQUkFVzhF1mtJyH4Pypoj-1024.npz
train_Episode has 500 steps and return 839.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T005410F742205-0DQUkFVzhF1mtJyH4Pypoj-0000000000000000000000-372.npz
Saved chunk: 20230922T005327F439234-0heFotX40cawZd40f6bHo6-0000000000000000000000-872.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 151000 Counter(151000) 150937
Saved chunk: 20230922T005327F439234-0heFotX40cawZd40f6bHo6-2k40ZQDqfkq5w755ftU1Yv-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 151500 Counter(151500) 151437
eval_Episode has 500 steps and return 821.0.
Saved chunk: 20230922T005410F742205-0DQUkFVzhF1mtJyH4Pypoj-2ciotFa7c1j9JpaK7ptS9E-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 152000 Counter(152000) 151937
Saved chunk: 20230922T005445F419621-2k40ZQDqfkq5w755ftU1Yv-1LL1RdHe1Tey9YoALJW0rF-1024.npz
eval_Episode has 500 steps and return 842.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 304002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 842 / eval_episode/reward_rate 0.84 / train/action_mag 3.34 / train/action_max 3.09 / train/action_mean 0.08 / train/action_min -3.22 / train/action_std 0.84 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 7.4e4 / train/actor_opt_loss -9.97 / train/adv_mag 0.57 / train/adv_max 0.49 / train/adv_mean 1.1e-3 / train/adv_min -0.51 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 7.2e-11 / train/cont_loss_std 5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 7.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.86 / 
train/dyn_loss_std 4.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.23 / train/extr_critic_critic_opt_grad_steps 7.4e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 670.95 / train/extr_critic_max 670.95 / train/extr_critic_mean 588.14 / train/extr_critic_min 401.58 / train/extr_critic_std 74.48 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.64 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.43 / train/extr_return_raw_max 667.43 / train/extr_return_raw_mean 588.37 / train/extr_return_raw_min 408.74 / train/extr_return_raw_std 74.74
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.91 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.28 / train/image_loss_std 0.4 / train/model_loss_mean 1.46 / train/model_loss_std 2.84 / 
train/model_opt_grad_norm 7.09 / train/model_opt_grad_steps 7.4e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7061.86 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / 
train/policy_entropy_mean -0.17 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.7 / train/policy_logprob_mag 8.2 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.17 / train/policy_logprob_min -8.2 / train/policy_logprob_std 1 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.31 / train/policy_randomness_min 2.2e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 58.58 / train/post_ent_max 58.58 / train/post_ent_mean 41.51 / 
train/post_ent_min 23.97 / train/post_ent_std 4.56 / train/prior_ent_mag 70.23 / train/prior_ent_max 70.23 / train/prior_ent_mean 43.02 / train/prior_ent_min 30.04 / train/prior_ent_std 5.58 / train/rep_loss_mean 1.86 / train/rep_loss_std 4.22 / train/reward_avg 0.91 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.91 / train/reward_rate 0.46 / 
train_stats/mean_log_entropy 0.28 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.9e-11 / report/cont_loss_std 3.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.9 / report/dyn_loss_std 4.02 / report/image_loss_mean 0.3 / report/image_loss_std 0.29 / report/model_loss_mean 1.49 / report/model_loss_std 2.61 / report/post_ent_mag 53.64 / report/post_ent_max 53.64 / 
report/post_ent_mean 43.31 / report/post_ent_min 27.93 / report/post_ent_std 3.71 / report/prior_ent_mag 69.64 / report/prior_ent_max 69.64 / report/prior_ent_mean 44.84 / report/prior_ent_min 37.88 / report/prior_ent_std 4.83 / report/rep_loss_mean 1.9 / 
report/rep_loss_std 4.02 / report/reward_avg 0.7 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.2 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.8e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.15 / report/reward_pred 0.7 / report/reward_rate 0.36 / eval/cont_avg 1 / eval/cont_loss_mean 8.6e-11 / eval/cont_loss_std 2.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.79 / eval/dyn_loss_std 4.03 / eval/image_loss_mean 0.28 / eval/image_loss_std 0.4 / eval/model_loss_mean 1.43 / eval/model_loss_std 2.71 / eval/post_ent_mag 53.59 / eval/post_ent_max 53.59 / eval/post_ent_mean 42.43 / eval/post_ent_min 28.87 / 
eval/post_ent_std 3.58 / eval/prior_ent_mag 69.64 / eval/prior_ent_max 69.64 / eval/prior_ent_mean 43.82 / eval/prior_ent_min 37.78 / eval/prior_ent_std 4.79 / eval/rep_loss_mean 1.79 / eval/rep_loss_std 4.03 / eval/reward_avg 1.13 / eval/reward_loss_mean 0.07 / 
eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.13 / eval/reward_rate 0.57 / replay/size 1.5e5 / replay/inserts 3878 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.61 / timer/env.step_count 3878 / timer/env.step_total 19.33 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.39 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / 
timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7886 / timer/agent.policy_total 17.39 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1939 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.5e-4 / 
timer/agent.train_count 1939 / timer/agent.train_total 245.47 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.1e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 152500 Counter(152500) 152437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T005530F177312-2ciotFa7c1j9JpaK7ptS9E-567B7l1at0Zc0GqgJ8YXFY-1024.npz
train_Episode has 500 steps and return 815.0.
Starting evaluation at step 153000 Counter(153000) 152937
Saved chunk: 20230922T005602F938711-1LL1RdHe1Tey9YoALJW0rF-1Sx3fRj2oMWBrkK3y8sFLM-1024.npz
eval_Episode has 500 steps and return 812.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 153500 Counter(153500) 153437
eval_Episode has 500 steps and return 786.0.
Saved chunk: 20230922T005650F136286-567B7l1at0Zc0GqgJ8YXFY-3lVH5ftTx2xrbROI1O4ERR-1024.npz
train_Episode has 500 steps and return 808.0.
Starting evaluation at step 154000 Counter(154000) 153937
Saved chunk: 20230922T005721F441674-1Sx3fRj2oMWBrkK3y8sFLM-6ymEbB4dSapeIRo9ylBgQa-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 154500 Counter(154500) 154437
eval_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T005809F314194-3lVH5ftTx2xrbROI1O4ERR-2eQDD7O3ts0wGjgOl9Ub8l-1024.npz
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 155000 Counter(155000) 154937
Saved chunk: 20230922T005839F023854-6ymEbB4dSapeIRo9ylBgQa-1UZov0M8VStOvRaBKHFwpy-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 155500 Counter(155500) 155437
eval_Episode has 500 steps and return 822.0.
Saved chunk: 20230922T005928F424794-2eQDD7O3ts0wGjgOl9Ub8l-3pRWOllWksZPWFC5GBvWD5-1024.npz
train_Episode has 500 steps and return 832.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 311798 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 832 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 822 / eval_episode/reward_rate 0.82 / train/action_mag 3.3 / train/action_max 3.06 / train/action_mean 0.06 / train/action_min -3.15 / train/action_std 0.84 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 7.6e4 / train/actor_opt_loss -9.34 / train/adv_mag 0.61 / train/adv_max 0.51 / train/adv_mean 1e-3 / train/adv_min -0.49 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6.7e-11 / train/cont_loss_std 4.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / 
train/dyn_loss_std 4.19 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.23 / train/extr_critic_critic_opt_grad_steps 7.6e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 671.29 / train/extr_critic_max 671.29 / train/extr_critic_mean 590.5 / train/extr_critic_min 381.47 / train/extr_critic_std 74.97 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.65 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.77 / train/extr_return_raw_max 667.77 / train/extr_return_raw_mean 590.72 / train/extr_return_raw_min 399.38 / train/extr_return_raw_std 75.2 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.94 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.28 / train/image_loss_std 0.4 / train/model_loss_mean 1.45 / train/model_loss_std 2.82 / 
train/model_opt_grad_norm 7.31 / train/model_opt_grad_steps 7.6e4 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7435.9 / train/policy_entropy_mag 1.36 / train/policy_entropy_max 1.36 / 
train/policy_entropy_mean -0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.69 / train/policy_logprob_mag 8.25 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.16 / train/policy_logprob_min -8.25 / train/policy_logprob_std 0.99 / 
train/policy_randomness_mag 0.98 / train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.31 / train/policy_randomness_min 2e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 58.26 / train/post_ent_max 58.26 / train/post_ent_mean 41.28 / 
train/post_ent_min 24.44 / train/post_ent_std 4.55 / train/prior_ent_mag 70.15 / train/prior_ent_max 70.15 / train/prior_ent_mean 42.78 / train/prior_ent_min 29.93 / train/prior_ent_std 5.6 / train/rep_loss_mean 1.84 / train/rep_loss_std 4.19 / train/reward_avg 0.94 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.94 / train/reward_rate 0.47 / 
train_stats/mean_log_entropy 0.25 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 8.1e-11 / report/cont_loss_std 8.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.98 / report/dyn_loss_std 4.8 / report/image_loss_mean 0.31 / report/image_loss_std 0.51 / report/model_loss_mean 1.56 / report/model_loss_std 3.3 / report/post_ent_mag 52.84 / report/post_ent_max 52.84 / 
report/post_ent_mean 41.23 / report/post_ent_min 24.26 / report/post_ent_std 4.75 / report/prior_ent_mag 70.27 / report/prior_ent_max 70.27 / report/prior_ent_mean 42.91 / report/prior_ent_min 26.27 / report/prior_ent_std 5.87 / report/rep_loss_mean 1.98 / 
report/rep_loss_std 4.8 / report/reward_avg 0.81 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.8e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.14 / report/reward_pred 0.81 / report/reward_rate 0.41 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.6 / eval/dyn_loss_std 3.22 / eval/image_loss_mean 0.22 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.08 / eval/post_ent_mag 51.63 / eval/post_ent_max 51.63 / eval/post_ent_mean 41.57 / eval/post_ent_min 33.28 / 
eval/post_ent_std 4 / eval/prior_ent_mag 70.27 / eval/prior_ent_max 70.27 / eval/prior_ent_mean 42.81 / eval/prior_ent_min 37.11 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.6 / eval/rep_loss_std 3.22 / eval/reward_avg 1.29 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.29 / eval/reward_rate 0.65 / replay/size 1.6e5 / replay/inserts 3898
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3898 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.37 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7405 / timer/agent.policy_total 16.16 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 
1949 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1949 / timer/agent.train_total 246.52 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.98

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 156000 Counter(156000) 155937
Saved chunk: 20230922T005956F599667-1UZov0M8VStOvRaBKHFwpy-3upuVIaJNlLDbHcGCKJhlp-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 156500 Counter(156500) 156437
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T010047F525705-3pRWOllWksZPWFC5GBvWD5-0c8Fb8rcdWtOaVknDpKpBz-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 157000 Counter(157000) 156937
Saved chunk: 20230922T010114F980996-3upuVIaJNlLDbHcGCKJhlp-0KZ9pZc2cYPCLZvmLYyqyA-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 811.0.
Starting evaluation at step 157500 Counter(157500) 157437
eval_Episode has 500 steps and return 827.0.
Saved chunk: 20230922T010208F700076-0c8Fb8rcdWtOaVknDpKpBz-3OycFQd8ZvXCCfN3NpAB4r-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 158000 Counter(158000) 157937
Saved chunk: 20230922T010233F843144-0KZ9pZc2cYPCLZvmLYyqyA-3pLsmYOXJYz0XagrLlEE6s-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 158500 Counter(158500) 158437
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T010327F927692-3OycFQd8ZvXCCfN3NpAB4r-7sJEf5XbtuRuSWh9h35bZV-1024.npz
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 159000 Counter(159000) 158937
Saved chunk: 20230922T010351F470913-3pLsmYOXJYz0XagrLlEE6s-6RQswiQ8n61mIrFTbeJwod-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 159500 Counter(159500) 159437
eval_Episode has 500 steps and return 829.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 319462 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 829 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 836 / episode/reward_rate 0.83 / train/action_mag 3.24 / train/action_max 3 / train/action_mean -7.3e-3 / train/action_min -3.11 / train/action_std 0.84 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 7.8e4 / train/actor_opt_loss -5.28 / train/adv_mag 0.54 / train/adv_max 0.44 / train/adv_mean 5.8e-4 / train/adv_min -0.48 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 6.3e-11 / train/cont_loss_std 4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 6.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.83 / 
train/dyn_loss_std 4.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 7.8e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 671.64 / train/extr_critic_max 671.64 / train/extr_critic_mean 591.31 / train/extr_critic_min 378.6 / train/extr_critic_std 77.71 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.97 / train/extr_return_raw_max 667.97 / train/extr_return_raw_mean 591.45 / train/extr_return_raw_min 386.36 / train/extr_return_raw_std 77.99
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.95 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.27 / train/image_loss_std 0.39 / train/model_loss_mean 1.44 / train/model_loss_std 2.76 / 
train/model_opt_grad_norm 7.25 / train/model_opt_grad_steps 7.8e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.36 / train/policy_entropy_max 1.36 / 
train/policy_entropy_mean -0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.68 / train/policy_logprob_mag 8.07 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.16 / train/policy_logprob_min -8.07 / train/policy_logprob_std 0.98 / 
train/policy_randomness_mag 0.97 / train/policy_randomness_max 0.97 / train/policy_randomness_mean 0.31 / train/policy_randomness_min 1.8e-4 / train/policy_randomness_std 0.3 / train/post_ent_mag 57.59 / train/post_ent_max 57.59 / train/post_ent_mean 41.3 / 
train/post_ent_min 24.45 / train/post_ent_std 4.53 / train/prior_ent_mag 70.13 / train/prior_ent_max 70.13 / train/prior_ent_mean 42.78 / train/prior_ent_min 30.09 / train/prior_ent_std 5.6 / train/rep_loss_mean 1.83 / train/rep_loss_std 4.11 / train/reward_avg 0.95 / 
train/reward_loss_mean 0.06 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.95 / train/reward_rate 0.48 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.27 / report/cont_avg 1 / report/cont_loss_mean 4e-10 / report/cont_loss_std 1.1e-8 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-10 / report/cont_pred 1
/ report/cont_rate 1 / report/dyn_loss_mean 1.92 / report/dyn_loss_std 4.26 / report/image_loss_mean 0.3 / report/image_loss_std 0.4 / report/model_loss_mean 1.52 / report/model_loss_std 2.83 / report/post_ent_mag 53.97 / report/post_ent_max 53.97 / report/post_ent_mean 
41.41 / report/post_ent_min 27.05 / report/post_ent_std 3.87 / report/prior_ent_mag 70.46 / report/prior_ent_max 70.46 / report/prior_ent_mean 43 / report/prior_ent_min 34.71 / report/prior_ent_std 5.27 / report/rep_loss_mean 1.92 / report/rep_loss_std 4.26 / 
report/reward_avg 0.92 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.4e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred
0.92 / report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 
/ eval/dyn_loss_std 3.29 / eval/image_loss_mean 0.25 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.33 / eval/model_loss_std 2.13 / eval/post_ent_mag 53.43 / eval/post_ent_max 53.43 / eval/post_ent_mean 41.54 / eval/post_ent_min 31.65 / eval/post_ent_std 4 / 
eval/prior_ent_mag 70.46 / eval/prior_ent_max 70.46 / eval/prior_ent_mean 42.85 / eval/prior_ent_min 36.53 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 3.29 / eval/reward_avg 1.17 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.11 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.17 / eval/reward_rate 0.59 / replay/size 1.6e5 / replay/inserts 3832 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3832 / timer/env.step_total 19.02 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.3e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 382.84 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.8e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1916 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.53 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.13 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T010447F230734-7sJEf5XbtuRuSWh9h35bZV-60s2tjwVtJNJTTW8YpJKBm-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 160000 Counter(160000) 159937
Saved chunk: 20230922T010509F203904-6RQswiQ8n61mIrFTbeJwod-0lflerBz9WfOX4MF9EZx4M-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 160500 Counter(160500) 160437
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T010606F906351-60s2tjwVtJNJTTW8YpJKBm-57AQZvWPxH5rabVSbUfX6k-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 161000 Counter(161000) 160937
Saved chunk: 20230922T010627F694207-0lflerBz9WfOX4MF9EZx4M-3IfvlsI1YOciLT2JZgrbpy-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 161500 Counter(161500) 161437
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T010726F602628-57AQZvWPxH5rabVSbUfX6k-7H3tcnQPg5WuTMkb0GOt1A-1024.npz
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 162000 Counter(162000) 161937
Saved chunk: 20230922T010745F553745-3IfvlsI1YOciLT2JZgrbpy-3Gkxfrg3H5nOEIH4GEcQQ2-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 831.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 162500 Counter(162500) 162437
Saved chunk: 20230922T010845F912737-7H3tcnQPg5WuTMkb0GOt1A-0000000000000000000000-708.npz
Saved chunk: 20230922T010903F245644-3Gkxfrg3H5nOEIH4GEcQQ2-0000000000000000000000-107.npz
eval_Episode has 500 steps and return 836.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T010845F912737-7H3tcnQPg5WuTMkb0GOt1A-2FoGZe18pVwMQq9G0xUHo7-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 163000 Counter(163000) 162937
Saved chunk: 20230922T010903F245644-3Gkxfrg3H5nOEIH4GEcQQ2-0Kiurw2UL7CtO4p7aascKC-1024.npz
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 163500 Counter(163500) 163437
eval_Episode has 500 steps and return 840.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 327142 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 837 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 840 / eval_episode/reward_rate 0.84 / train/action_mag 3.36 / train/action_max 3.08 / train/action_mean -0.03 / train/action_min -3.27 / train/action_std 0.85 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 8e4 / train/actor_opt_loss -8.08 / train/adv_mag 0.51 / train/adv_max 0.42 / train/adv_mean 8.6e-4 / train/adv_min -0.47 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.84 / 
train/dyn_loss_std 4.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 8e4 / train/extr_critic_critic_opt_loss 1e4 /
train/extr_critic_mag 671.47 / train/extr_critic_max 671.47 / train/extr_critic_mean 589.88 / train/extr_critic_min 369.75 / train/extr_critic_std 80.63 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.68 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.86 / train/extr_return_raw_max 667.86 / train/extr_return_raw_mean 590.08 / train/extr_return_raw_min 370.81 / train/extr_return_raw_std 80.82
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 0.94 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.27 / train/image_loss_std 0.39 / train/model_loss_mean 1.44 / train/model_loss_std 2.78 / 
train/model_opt_grad_norm 7.16 / train/model_opt_grad_steps 8e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.37 / train/policy_entropy_max 1.37 / train/policy_entropy_mean 
-0.13 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.71 / train/policy_logprob_mag 8.16 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.13 / train/policy_logprob_min -8.16 / train/policy_logprob_std 1.01 / train/policy_randomness_mag 0.98 / 
train/policy_randomness_max 0.98 / train/policy_randomness_mean 0.33 / train/policy_randomness_min 1.7e-4 / train/policy_randomness_std 0.31 / train/post_ent_mag 58.41 / train/post_ent_max 58.41 / train/post_ent_mean 41.31 / train/post_ent_min 24.43 / train/post_ent_std 
4.58 / train/prior_ent_mag 70.16 / train/prior_ent_max 70.16 / train/prior_ent_mean 42.78 / train/prior_ent_min 30.02 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.84 / train/rep_loss_std 4.14 / train/reward_avg 0.94 / train/reward_loss_mean 0.06 / 
train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.94 / train/reward_rate 0.47 / train_stats/mean_log_entropy 
0.32 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 3.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.84 / report/image_loss_mean 0.25 / report/image_loss_std 0.35 / report/model_loss_mean 1.31 / report/model_loss_std 2.59 / report/post_ent_mag 52.73 / report/post_ent_max 52.73 / report/post_ent_mean 42.18 / 
report/post_ent_min 25.21 / report/post_ent_std 4.03 / report/prior_ent_mag 70.1 / report/prior_ent_max 70.1 / report/prior_ent_mean 43.48 / report/prior_ent_min 37.09 / report/prior_ent_std 5.24 / report/rep_loss_mean 1.65 / report/rep_loss_std 3.84 / report/reward_avg 
1.05 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.05 / 
report/reward_rate 0.53 / eval/cont_avg 1 / eval/cont_loss_mean 1.4e-10 / eval/cont_loss_std 2.5e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.4e-10 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.74 / 
eval/dyn_loss_std 3.84 / eval/image_loss_mean 0.24 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.36 / eval/model_loss_std 2.57 / eval/post_ent_mag 52.79 / eval/post_ent_max 52.79 / eval/post_ent_mean 41.53 / eval/post_ent_min 25.63 / eval/post_ent_std 4.09 / 
eval/prior_ent_mag 70.1 / eval/prior_ent_max 70.1 / eval/prior_ent_mean 42.82 / eval/prior_ent_min 37.09 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 1.74 / eval/rep_loss_std 3.84 / eval/reward_avg 1.26 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.13 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 1.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.25 / eval/reward_rate 0.63 / replay/size 1.6e5 / replay/inserts 3840 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3840 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.4e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.24 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.28 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 0.1 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1920 / 
timer/agent.train_total 243.1 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 812.0.
Saved chunk: 20230922T011005F361440-2FoGZe18pVwMQq9G0xUHo7-35tgz9L5UAILG8wANlCWtD-1024.npz
Starting evaluation at step 164000 Counter(164000) 163937
eval_Episode has 500 steps and return 827.0.
Saved chunk: 20230922T011021F111810-0Kiurw2UL7CtO4p7aascKC-1Wd3NtvxdL2zQUHK2lWVq6-1024.npz
train_Episode has 500 steps and return 825.0.
Starting evaluation at step 164500 Counter(164500) 164437
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T011125F271438-35tgz9L5UAILG8wANlCWtD-0mzN6psZ0uD2IzRZGU8FBh-1024.npz
Starting evaluation at step 165000 Counter(165000) 164937
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T011139F582758-1Wd3NtvxdL2zQUHK2lWVq6-1XOWCyT7w3Fn3wuJACiRbK-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 165500 Counter(165500) 165437
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T011244F689946-0mzN6psZ0uD2IzRZGU8FBh-0znXP3u8Fl80lVSHeGcZdI-1024.npz
Starting evaluation at step 166000 Counter(166000) 165937
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T011257F396963-1XOWCyT7w3Fn3wuJACiRbK-5s97QDRuqIpLWY5drmQeDB-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 166500 Counter(166500) 166437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T011404F045250-0znXP3u8Fl80lVSHeGcZdI-6WJ2zdI7VJS088yXQ9X4ye-1024.npz
Starting evaluation at step 167000 Counter(167000) 166937
eval_Episode has 500 steps and return 828.0.
train_Episode has 500 steps and return 838.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 334926 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 838 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 828 / eval_episode/reward_rate 0.83 / train/action_mag 3.62 / train/action_max 3.37 / train/action_mean 3.5e-3 / train/action_min -3.51 / train/action_std 0.87
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 8.2e4 / train/actor_opt_loss -9.29 / train/adv_mag 0.52 / train/adv_max 0.43 / train/adv_mean 9.5e-4 / train/adv_min -0.46 
/ train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.9e-11 / train/cont_loss_std 4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.22 / train/extr_critic_critic_opt_grad_steps 8.2e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 672.06 / train/extr_critic_max 672.06 / train/extr_critic_mean 597.46 / train/extr_critic_min 389.73 / train/extr_critic_std 76.09 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.6 / train/extr_return_raw_max 668.6 / train/extr_return_raw_mean 597.67 / train/extr_return_raw_min 392.01 / train/extr_return_raw_std 76.16 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.01 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.37 / train/model_loss_mean 1.41 / train/model_loss_std 2.65 / 
train/model_opt_grad_norm 7.04 / train/model_opt_grad_steps 8.2e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7435.9 / train/policy_entropy_mag 1.39 / train/policy_entropy_max 1.39 / 
train/policy_entropy_mean -0.03 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.78 / train/policy_logprob_mag 8.23 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.03 / train/policy_logprob_min -8.23 / train/policy_logprob_std 1.06 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.37 / train/policy_randomness_min 1.3e-4 / train/policy_randomness_std 0.34 / train/post_ent_mag 58.16 / train/post_ent_max 58.16 / train/post_ent_mean 41.14 / 
train/post_ent_min 24.87 / train/post_ent_std 4.53 / train/prior_ent_mag 70.09 / train/prior_ent_max 70.09 / train/prior_ent_mean 42.59 / train/prior_ent_min 30.64 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.95 / train/reward_avg 1.01 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.01 / train/reward_rate 0.51 / 
train_stats/mean_log_entropy 0.35 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.5e-11 / report/cont_loss_std 6.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 3.94 / report/image_loss_mean 0.29 / report/image_loss_std 0.46 / report/model_loss_mean 1.44 / report/model_loss_std 2.8 / report/post_ent_mag 62.88 / report/post_ent_max 62.88 / 
report/post_ent_mean 41.19 / report/post_ent_min 27.48 / report/post_ent_std 4.9 / report/prior_ent_mag 70.65 / report/prior_ent_max 70.65 / report/prior_ent_mean 42.62 / report/prior_ent_min 31.51 / report/prior_ent_std 5.83 / report/rep_loss_mean 1.79 / 
report/rep_loss_std 3.94 / report/reward_avg 0.83 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.29 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.18 / report/reward_pred 0.82 / report/reward_rate 0.42 / eval/cont_avg 1 / eval/cont_loss_mean 7.4e-11 / eval/cont_loss_std 4.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.68 / eval/dyn_loss_std 3.44 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.32 / eval/model_loss_std 2.31 / eval/post_ent_mag 54.04 / eval/post_ent_max 54.04 / eval/post_ent_mean 
41.89 / eval/post_ent_min 27.52 / eval/post_ent_std 4.32 / eval/prior_ent_mag 70.65 / eval/prior_ent_max 70.65 / eval/prior_ent_mean 43.37 / eval/prior_ent_min 36.9 / eval/prior_ent_std 5.5 / eval/rep_loss_mean 1.68 / eval/rep_loss_std 3.44 / eval/reward_avg 1.21 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.2 / eval/reward_rate 0.61 / replay/size 
1.7e5 / replay/inserts 3892 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3892 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.01 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7399 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / 
timer/dataset_train_count 1946 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1946 / timer/agent.train_total 246.45 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.24 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.94

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 167500 Counter(167500) 167437
Saved chunk: 20230922T011415F171370-5s97QDRuqIpLWY5drmQeDB-0iX0iMzaas22CweBrTkAHR-1024.npz
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 810.0.
Saved chunk: 20230922T011523F179416-6WJ2zdI7VJS088yXQ9X4ye-5EdWjV5Sv1PYDhGoXJhGVJ-1024.npz
Starting evaluation at step 168000 Counter(168000) 167937
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 168500 Counter(168500) 168437
Saved chunk: 20230922T011608F940967-0iX0iMzaas22CweBrTkAHR-1IwdzXzYHZwrj0osVc6bw0-1024.npz
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T011643F336747-5EdWjV5Sv1PYDhGoXJhGVJ-4Cx4ADX7Cd4iLMOtHgNwX5-1024.npz
Starting evaluation at step 169000 Counter(169000) 168937
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 169500 Counter(169500) 169437
Saved chunk: 20230922T011726F937251-1IwdzXzYHZwrj0osVc6bw0-5veCVDJRAVdBWotWXCWLs4-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 832.0.
Saved chunk: 20230922T011802F703519-4Cx4ADX7Cd4iLMOtHgNwX5-603wB88SwKACekSTtVVwco-1024.npz
Starting evaluation at step 170000 Counter(170000) 169937
eval_Episode has 500 steps and return 823.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 170500 Counter(170500) 170437
Saved chunk: 20230922T011844F659121-5veCVDJRAVdBWotWXCWLs4-7mv7SHSMhou0lB6xLwxngN-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 171000 Counter(171000) 170937
eval_Episode has 500 steps and return 829.0.
Saved chunk: 20230922T011921F904900-603wB88SwKACekSTtVVwco-2kumMC3ybipu1riSD8X2mH-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 342614 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 829 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / train/action_mag 3.67 / train/action_max 3.43 / train/action_mean 0.07 / train/action_min -3.53 / train/action_std 0.88 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 8.4e4 / train/actor_opt_loss -5.39 / train/adv_mag 0.57 / train/adv_max 0.46 / train/adv_mean 5.6e-4 / train/adv_min -0.53 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.8e-11 / train/cont_loss_std 4.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.8 / 
train/dyn_loss_std 4.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.21 / train/extr_critic_critic_opt_grad_steps 8.4e4 / train/extr_critic_critic_opt_loss 1e4
/ train/extr_critic_mag 672.4 / train/extr_critic_max 672.4 / train/extr_critic_mean 598.69 / train/extr_critic_min 414.19 / train/extr_critic_std 72.86 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.21 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.53 / train/extr_return_raw_max 668.53 / train/extr_return_raw_mean 598.8 / train/extr_return_raw_min 416.52 / train/extr_return_raw_std 73.12 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.38 / train/model_loss_mean 1.41 / train/model_loss_std 2.7 / 
train/model_opt_grad_norm 6.69 / train/model_opt_grad_steps 8.4e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / train/policy_entropy_mean 
-0.02 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.79 / train/policy_logprob_mag 8.22 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.02 / train/policy_logprob_min -8.22 / train/policy_logprob_std 1.07 / train/policy_randomness_mag 0.99 / 
train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.37 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.35 / train/post_ent_mag 57.99 / train/post_ent_max 57.99 / train/post_ent_mean 40.99 / train/post_ent_min 24.8 / train/post_ent_std 
4.69 / train/prior_ent_mag 69.98 / train/prior_ent_max 69.98 / train/prior_ent_mean 42.43 / train/prior_ent_min 30.36 / train/prior_ent_std 5.77 / train/rep_loss_mean 1.8 / train/rep_loss_std 4.02 / train/reward_avg 1 / train/reward_loss_mean 0.07 / train/reward_loss_std 
0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1 / train/reward_rate 0.5 / eval_stats/mean_log_entropy 0 / 
train_stats/mean_log_entropy 0.44 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 7.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.71 / report/dyn_loss_std 3.91 / report/image_loss_mean 0.2 / report/image_loss_std 0.36 / report/model_loss_mean 1.32 / report/model_loss_std 2.62 / report/post_ent_mag 55.3 / report/post_ent_max 55.3 / report/post_ent_mean 39.72 / 
report/post_ent_min 24.47 / report/post_ent_std 4.72 / report/prior_ent_mag 70.15 / report/prior_ent_max 70.15 / report/prior_ent_mean 41.11 / report/prior_ent_min 29.55 / report/prior_ent_std 6.01 / report/rep_loss_mean 1.71 / report/rep_loss_std 3.91 / report/reward_avg
1.35 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.21 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 3.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.35 / 
report/reward_rate 0.68 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / 
eval/dyn_loss_std 3.46 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.24 / eval/model_loss_std 2.26 / eval/post_ent_mag 54.13 / eval/post_ent_max 54.13 / eval/post_ent_mean 41 / eval/post_ent_min 30.27 / eval/post_ent_std 4.25 / 
eval/prior_ent_mag 70.15 / eval/prior_ent_max 70.15 / eval/prior_ent_mean 42.31 / eval/prior_ent_min 36.53 / eval/prior_ent_std 5.54 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.46 / eval/reward_avg 1.29 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.15 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.29 / eval/reward_rate 0.65 / replay/size 1.7e5 / replay/inserts 3844 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3844 / timer/env.step_total 19.08 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.8e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.23 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.13 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7852 / timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 1922 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1922 / timer/agent.train_total 243.45 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 171500 Counter(171500) 171437
Saved chunk: 20230922T012002F228511-7mv7SHSMhou0lB6xLwxngN-4oeGGlDbjkPq2TwTXE9lVR-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 172000 Counter(172000) 171937
eval_Episode has 500 steps and return 832.0.
Saved chunk: 20230922T012044F400827-2kumMC3ybipu1riSD8X2mH-0MxHXZM0vIZkg3AxjKM3uJ-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 172500 Counter(172500) 172437
Saved chunk: 20230922T012120F736759-4oeGGlDbjkPq2TwTXE9lVR-6AETcEEE8g39M2DFE73pbo-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 173000 Counter(173000) 172937
eval_Episode has 500 steps and return 829.0.
Saved chunk: 20230922T012204F755528-0MxHXZM0vIZkg3AxjKM3uJ-4cdis1aFsE6WF440hIRtoz-1024.npz
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 173500 Counter(173500) 173437
Saved chunk: 20230922T012238F745147-6AETcEEE8g39M2DFE73pbo-1SFtFFlEXQgS3aVfxtC1AY-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 174000 Counter(174000) 173937
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T012324F126577-4cdis1aFsE6WF440hIRtoz-3O2vttXKS3R4bpdYpfuz9K-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T012356F495716-1SFtFFlEXQgS3aVfxtC1AY-0000000000000000000000-867.npz
Saved chunk: 20230922T012443F533034-3O2vttXKS3R4bpdYpfuz9K-0000000000000000000000-20.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 174500 Counter(174500) 174437
Saved chunk: 20230922T012356F495716-1SFtFFlEXQgS3aVfxtC1AY-72kuiXbihzU4qRq2AqF5eJ-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 825.0.
Starting evaluation at step 175000 Counter(175000) 174937
eval_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T012443F533034-3O2vttXKS3R4bpdYpfuz9K-04hFmh270K5jYtbHIeONSd-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 350278 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 825 / episode/reward_rate 0.82 / eval_episode/length 500 / eval_episode/score 834 / eval_episode/reward_rate 0.83 / train/action_mag 3.67 / train/action_max 3.44 / train/action_mean 0.06 / train/action_min -3.52 / train/action_std 0.87 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 8.6e4 / train/actor_opt_loss -6.48 / train/adv_mag 0.59 / train/adv_max 0.48 / train/adv_mean 6.6e-4 / train/adv_min -0.53 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.6e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.81 / 
train/dyn_loss_std 4.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.2 / train/extr_critic_critic_opt_grad_steps 8.6e4 / train/extr_critic_critic_opt_loss 1e4 
/ train/extr_critic_mag 671.99 / train/extr_critic_max 671.99 / train/extr_critic_mean 598.39 / train/extr_critic_min 406.79 / train/extr_critic_std 73.35 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.44 / train/extr_return_raw_max 668.44 / train/extr_return_raw_mean 598.53 / train/extr_return_raw_min 410.26 / train/extr_return_raw_std 73.55
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.38 / train/model_loss_mean 1.42 / train/model_loss_std 2.69 / 
train/model_opt_grad_norm 7.07 / train/model_opt_grad_steps 8.6e4 / train/model_opt_loss 1.4e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.4 / train/policy_entropy_max 1.4 / train/policy_entropy_mean 
-8.4e-3 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.78 / train/policy_logprob_mag 8.21 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 9e-3 / train/policy_logprob_min -8.21 / train/policy_logprob_std 1.05 / train/policy_randomness_mag 0.99 / 
train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.38 / train/policy_randomness_min 1.1e-4 / train/policy_randomness_std 0.34 / train/post_ent_mag 58.11 / train/post_ent_max 58.11 / train/post_ent_mean 40.94 / train/post_ent_min 24.79 / train/post_ent_std 
4.75 / train/prior_ent_mag 70.16 / train/prior_ent_max 70.16 / train/prior_ent_mean 42.39 / train/prior_ent_min 30.01 / train/prior_ent_std 5.86 / train/rep_loss_mean 1.81 / train/rep_loss_std 4.01 / train/reward_avg 0.99 / train/reward_loss_mean 0.07 / 
train/reward_loss_std 0.14 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 0.99 / train/reward_rate 0.5 / train_stats/mean_log_entropy 
0.32 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.91 / report/dyn_loss_std 4.67 / report/image_loss_mean 0.25 / report/image_loss_std 0.38 / report/model_loss_mean 1.46 / report/model_loss_std 3.1 / report/post_ent_mag 54.11 / report/post_ent_max 54.11 / report/post_ent_mean 40.81 / 
report/post_ent_min 25.71 / report/post_ent_std 4.85 / report/prior_ent_mag 69.89 / report/prior_ent_max 69.89 / report/prior_ent_mean 42.41 / report/prior_ent_min 27.18 / report/prior_ent_std 6.02 / report/rep_loss_mean 1.91 / report/rep_loss_std 4.67 / report/reward_avg
0.93 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 0.93 / 
report/reward_rate 0.47 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / 
eval/dyn_loss_std 2.59 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.68 / eval/post_ent_mag 54.31 / eval/post_ent_max 54.31 / eval/post_ent_mean 40.75 / eval/post_ent_min 31.31 / eval/post_ent_std 4.66 / 
eval/prior_ent_mag 69.89 / eval/prior_ent_max 69.89 / eval/prior_ent_mean 41.98 / eval/prior_ent_min 36.24 / eval/prior_ent_std 5.98 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.59 / eval/reward_avg 1.39 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.16 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.39 / eval/reward_rate 0.7 / replay/size 1.8e5 / replay/inserts 3832 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3832 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.31 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.3e-3 / timer/replay._sample_max 0.14 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.44 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.16 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1916 / 
timer/agent.train_total 242.87 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 175500 Counter(175500) 175437
Saved chunk: 20230922T012514F604227-72kuiXbihzU4qRq2AqF5eJ-6mjO2oxBKx6fLJobmTqaoB-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 176000 Counter(176000) 175937
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T012603F169547-04hFmh270K5jYtbHIeONSd-7fwbirui0jqcuk4lJ12mIH-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 176500 Counter(176500) 176437
Saved chunk: 20230922T012633F320994-6mjO2oxBKx6fLJobmTqaoB-2Rc4sUsjs9IVndYLskXYt7-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 177000 Counter(177000) 176937
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T012723F519345-7fwbirui0jqcuk4lJ12mIH-1gOCo7yGzqOxWL0p6CtaMq-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 177500 Counter(177500) 177437
Saved chunk: 20230922T012751F312579-2Rc4sUsjs9IVndYLskXYt7-1gbdIQIIxY6mvpJS8RF8si-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 178000 Counter(178000) 177937
eval_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T012842F931901-1gOCo7yGzqOxWL0p6CtaMq-6ErBmpD8I4sAuyeGMgeBbY-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 178500 Counter(178500) 178437
Saved chunk: 20230922T012909F067413-1gbdIQIIxY6mvpJS8RF8si-78cHoxFAmnYC7ZAlSQH5zd-1024.npz
eval_Episode has 500 steps and return 831.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 179000 Counter(179000) 178937
eval_Episode has 500 steps and return 841.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 358002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 841 / eval_episode/reward_rate 0.84 / train/action_mag 3.81 / train/action_max 3.61 / train/action_mean 0.06 / train/action_min -3.64 / train/action_std 0.89 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 8.8e4 / train/actor_opt_loss -6.44 / train/adv_mag 0.58 / train/adv_max 0.46 / train/adv_mean 6.3e-4 / train/adv_min -0.52 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.6e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.9 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 8.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.93 / train/extr_critic_max 671.93 / train/extr_critic_mean 603.63 / train/extr_critic_min 410.58 / train/extr_critic_std 71.66 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.18 / train/extr_return_raw_max 668.18 / train/extr_return_raw_mean 603.76 / train/extr_return_raw_min 413.41 / train/extr_return_raw_std 71.85
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.05 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.36 / train/model_loss_mean 1.39 / train/model_loss_std 2.61 / 
train/model_opt_grad_norm 6.77 / train/model_opt_grad_steps 8.8e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7409.33 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.08 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.84 / train/policy_logprob_mag 8.41 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.08 / train/policy_logprob_min -8.41 / train/policy_logprob_std 1.09 / 
train/policy_randomness_mag 0.99 / train/policy_randomness_max 0.99 / train/policy_randomness_mean 0.42 / train/policy_randomness_min 6.4e-5 / train/policy_randomness_std 0.36 / train/post_ent_mag 57.89 / train/post_ent_max 57.89 / train/post_ent_mean 40.85 / 
train/post_ent_min 25.28 / train/post_ent_std 4.7 / train/prior_ent_mag 70.19 / train/prior_ent_max 70.19 / train/prior_ent_mean 42.27 / train/prior_ent_min 30.53 / train/prior_ent_std 5.82 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.9 / train/reward_avg 1.04 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.04 / train/reward_rate 0.53 / 
train_stats/mean_log_entropy 0.47 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.7e-11 / report/cont_loss_std 9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.55 / report/image_loss_mean 0.23 / report/image_loss_std 0.4 / report/model_loss_mean 1.27 / report/model_loss_std 2.41 / report/post_ent_mag 61.98 / report/post_ent_max 61.98 / 
report/post_ent_mean 39.02 / report/post_ent_min 17.09 / report/post_ent_std 5.23 / report/prior_ent_mag 69.7 / report/prior_ent_max 69.7 / report/prior_ent_mean 40.48 / report/prior_ent_min 26.76 / report/prior_ent_std 6.14 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.55 / report/reward_avg 1.02 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.02 / report/reward_rate 0.51 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.7 / eval/image_loss_mean 0.22 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.29 / eval/model_loss_std 2.45 / eval/post_ent_mag 53.04 / eval/post_ent_max 53.04 / eval/post_ent_mean 
40.83 / eval/post_ent_min 31.72 / eval/post_ent_std 4.38 / eval/prior_ent_mag 69.7 / eval/prior_ent_max 69.7 / eval/prior_ent_mean 42.06 / eval/prior_ent_min 36.29 / eval/prior_ent_std 5.53 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.7 / eval/reward_avg 1.31 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.19 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.3 / eval/reward_rate 0.66 / replay/size 
1.8e5 / replay/inserts 3862 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.55 / timer/env.step_count 3862 / timer/env.step_total 19.41 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.86 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7870 / timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1931 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1931 / timer/agent.train_total 244.48 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T013002F133732-6ErBmpD8I4sAuyeGMgeBbY-3CYFP06L6eEsil9yAJRqKP-1024.npz
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 179500 Counter(179500) 179437
Saved chunk: 20230922T013026F681380-78cHoxFAmnYC7ZAlSQH5zd-119IqHs7ayUrvv9egdXmK7-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 180000 Counter(180000) 179937
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T013122F133845-3CYFP06L6eEsil9yAJRqKP-1Ly0HuogSuwE8WFG2laDQ8-1024.npz
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 180500 Counter(180500) 180437
Saved chunk: 20230922T013145F284402-119IqHs7ayUrvv9egdXmK7-5rBgdAQ3H0HM3OxfVIsFxv-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 181000 Counter(181000) 180937
eval_Episode has 500 steps and return 835.0.
Saved chunk: 20230922T013241F581637-1Ly0HuogSuwE8WFG2laDQ8-0AJnRkpNaWBS7OCIqQIvVD-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 181500 Counter(181500) 181437
Saved chunk: 20230922T013303F135144-5rBgdAQ3H0HM3OxfVIsFxv-6UXsdq2e0Yn1aymfZXwLRX-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 182000 Counter(182000) 181937
eval_Episode has 500 steps and return 832.0.
Saved chunk: 20230922T013400F961117-0AJnRkpNaWBS7OCIqQIvVD-1uh8IiBPclNhrZhlWQ6lb0-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 182500 Counter(182500) 182437
Saved chunk: 20230922T013420F883336-6UXsdq2e0Yn1aymfZXwLRX-3SOYEI1Iea0TsrcU68oyvd-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 828.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 365786 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 828 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 843 / eval_episode/reward_rate 0.84 / train/action_mag 3.93 / train/action_max 3.68 / train/action_mean 0.06 / train/action_min -3.78 / train/action_std 0.91 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 9e4 / train/actor_opt_loss -9.84 / train/adv_mag 0.6 / train/adv_max 0.49 / train/adv_mean 9.7e-4 / train/adv_min -0.51 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.6e-11 / train/cont_loss_std 3.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.79 / 
train/dyn_loss_std 3.95 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.21 / train/extr_critic_critic_opt_grad_steps 9e4 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.97 / train/extr_critic_max 671.97 / train/extr_critic_mean 600.36 / train/extr_critic_min 405.63 / train/extr_critic_std 72.9 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.67 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.55 / train/extr_return_raw_max 668.55 / train/extr_return_raw_mean 600.55 / train/extr_return_raw_min 414.6 / train/extr_return_raw_std 72.97 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.02 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.26 / train/image_loss_std 0.38 / train/model_loss_mean 1.4 / train/model_loss_std 2.65 / 
train/model_opt_grad_norm 7.21 / train/model_opt_grad_steps 9e4 / train/model_opt_loss 7195.3 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5154.64 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.09 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.48 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.08 / train/policy_logprob_min -8.48 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.42 / train/policy_randomness_min 5.7e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 59.14 / train/post_ent_max 59.14 / train/post_ent_mean 40.79 / train/post_ent_min
24.77 / train/post_ent_std 4.77 / train/prior_ent_mag 70.02 / train/prior_ent_max 70.02 / train/prior_ent_mean 42.22 / train/prior_ent_min 30.47 / train/prior_ent_std 5.87 / train/rep_loss_mean 1.79 / train/rep_loss_std 3.95 / train/reward_avg 1.01 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.01 / train/reward_rate 0.51 / 
train_stats/mean_log_entropy 0.41 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.61 / report/image_loss_mean 0.22 / report/image_loss_std 0.38 / report/model_loss_mean 1.28 / report/model_loss_std 2.42 / report/post_ent_mag 64.74 / report/post_ent_max 64.74 / 
report/post_ent_mean 40.14 / report/post_ent_min 26.15 / report/post_ent_std 4.5 / report/prior_ent_mag 69.56 / report/prior_ent_max 69.56 / report/prior_ent_mean 41.26 / report/prior_ent_min 29.86 / report/prior_ent_std 5.75 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.61 / report/reward_avg 1.2 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 1.19 / report/reward_rate 0.6 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 3.08 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.17 / eval/model_loss_std 2.14 / eval/post_ent_mag 53.72 / eval/post_ent_max 53.72 / eval/post_ent_mean 38.97 / eval/post_ent_min 30.8 / 
eval/post_ent_std 3.73 / eval/prior_ent_mag 69.56 / eval/prior_ent_max 69.56 / eval/prior_ent_mean 39.96 / eval/prior_ent_min 35.95 / eval/prior_ent_std 5.31 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 3.08 / eval/reward_avg 1.66 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.66 / eval/reward_rate 0.83 / replay/size 1.8e5 / replay/inserts 
3892 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3892 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.96 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7399 / timer/agent.policy_total 16.27 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6e-3 / timer/dataset_train_count 
1946 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1946 / timer/agent.train_total 246.44 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.94

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 183000 Counter(183000) 182937
eval_Episode has 500 steps and return 826.0.
Saved chunk: 20230922T013520F074921-1uh8IiBPclNhrZhlWQ6lb0-4CnyrdaN6TX2agQTrxHmzP-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 183500 Counter(183500) 183437
Saved chunk: 20230922T013538F414782-3SOYEI1Iea0TsrcU68oyvd-6ExJPhapA0G2yhfYeM5Oab-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 184000 Counter(184000) 183937
eval_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T013640F115513-4CnyrdaN6TX2agQTrxHmzP-6om7MoMghOMuWS4TIim37h-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 184500 Counter(184500) 184437
Saved chunk: 20230922T013656F982812-6ExJPhapA0G2yhfYeM5Oab-2TKCnVMzMkreksX7ZJnaT5-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 185000 Counter(185000) 184937
eval_Episode has 500 steps and return 835.0.
Saved chunk: 20230922T013759F467729-6om7MoMghOMuWS4TIim37h-5XZ2fhbdHQyUsNwBXmBA8z-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 185500 Counter(185500) 185437
Saved chunk: 20230922T013814F750007-2TKCnVMzMkreksX7ZJnaT5-4OGMrfTZHhhAfVNvmUzASb-1024.npz
eval_Episode has 500 steps and return 718.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T013918F746245-5XZ2fhbdHQyUsNwBXmBA8z-0000000000000000000000-356.npz
Saved chunk: 20230922T013932F440779-4OGMrfTZHhhAfVNvmUzASb-0000000000000000000000-102.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 186000 Counter(186000) 185937
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T013918F746245-5XZ2fhbdHQyUsNwBXmBA8z-2tFwqDMYhFtHPqPxBstz3U-1024.npz
Starting evaluation at step 186500 Counter(186500) 186437
Saved chunk: 20230922T013932F440779-4OGMrfTZHhhAfVNvmUzASb-6mANbC0SHO7A5JiQcZodEm-1024.npz
eval_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 373470 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 840 / episode/reward_rate 0.84 / train/action_mag 4 / train/action_max 3.77 / train/action_mean 0.05 / train/action_min -3.81 / train/action_std 0.91 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 9.2e4 / train/actor_opt_loss -5.58 / train/adv_mag 0.59 / train/adv_max 0.5 / train/adv_mean 5.4e-4 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.7e-11 / train/cont_loss_std 5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.88 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 9.2e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.91 / train/extr_critic_max 671.91 / train/extr_critic_mean 605.23 / train/extr_critic_min 411.61 / train/extr_critic_std 69.28 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.84 / train/extr_return_raw_max 668.84 / train/extr_return_raw_mean 605.33 / train/extr_return_raw_min 418.64 / train/extr_return_raw_std 69.48
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.06 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.36 / train/model_loss_mean 1.38 / train/model_loss_std 2.6 / 
train/model_opt_grad_norm 6.71 / train/model_opt_grad_steps 9.2e4 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7421.88 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.08 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.52 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.08 / train/policy_logprob_min -8.52 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.42 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.45 / train/post_ent_max 57.45 / train/post_ent_mean 40.85 / train/post_ent_min
25.53 / train/post_ent_std 4.71 / train/prior_ent_mag 69.96 / train/prior_ent_max 69.96 / train/prior_ent_mean 42.26 / train/prior_ent_min 31.1 / train/prior_ent_std 5.84 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.88 / train/reward_avg 1.05 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.05 / train/reward_rate 0.53 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.35 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 7.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 4.09 / report/image_loss_mean 0.22 / report/image_loss_std 0.53 / report/model_loss_mean 1.3 / report/model_loss_std 2.9 / report/post_ent_mag 55.38 / report/post_ent_max 55.38 / 
report/post_ent_mean 38.34 / report/post_ent_min 23.74 / report/post_ent_std 4.95 / report/prior_ent_mag 70.32 / report/prior_ent_max 70.32 / report/prior_ent_mean 39.77 / report/prior_ent_min 28.52 / report/prior_ent_std 6.33 / report/rep_loss_mean 1.69 / 
report/rep_loss_std 4.09 / report/reward_avg 1.23 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.8e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.23 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 6.1e-11 / eval/cont_loss_std 3.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.67 / eval/dyn_loss_std 3.4 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.26 / eval/model_loss_mean 1.31 / eval/model_loss_std 2.28 / eval/post_ent_mag 55.42 / eval/post_ent_max 55.42 / eval/post_ent_mean 
41.73 / eval/post_ent_min 32.35 / eval/post_ent_std 4.14 / eval/prior_ent_mag 70.32 / eval/prior_ent_max 70.32 / eval/prior_ent_mean 43.09 / eval/prior_ent_min 36.34 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 1.67 / eval/rep_loss_std 3.4 / eval/reward_avg 1.07 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.07 / eval/reward_rate 0.54 / replay/size 
1.9e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3842 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.94 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.22 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.35 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 187000 Counter(187000) 186937
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T014038F098804-2tFwqDMYhFtHPqPxBstz3U-1lEPaZoAqmGocxHa47HryZ-1024.npz
Starting evaluation at step 187500 Counter(187500) 187437
Saved chunk: 20230922T014050F257056-6mANbC0SHO7A5JiQcZodEm-5ieQO7f5oUMr6Uh97lnKaZ-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 188000 Counter(188000) 187937
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T014158F352916-1lEPaZoAqmGocxHa47HryZ-5JRRJVHjUblzBgK0akfS23-1024.npz
Starting evaluation at step 188500 Counter(188500) 188437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T014209F000703-5ieQO7f5oUMr6Uh97lnKaZ-4hE3rbghjqjlfUD8Nrkac6-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 189000 Counter(189000) 188937
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T014317F783235-5JRRJVHjUblzBgK0akfS23-4hYpyuRJ5U0F6xc0CKioXU-1024.npz
Starting evaluation at step 189500 Counter(189500) 189437
eval_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T014326F849076-4hE3rbghjqjlfUD8Nrkac6-1hH3m13K7RVFtzVeUMuQmw-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 190000 Counter(190000) 189937
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T014437F059082-4hYpyuRJ5U0F6xc0CKioXU-16m8rkJekHV2hVgKe270Yq-1024.npz
Starting evaluation at step 190500 Counter(190500) 190437
eval_Episode has 500 steps and return 829.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 381146 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 837 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 829 / eval_episode/reward_rate 0.83 / train/action_mag 4.01 / train/action_max 3.75 / train/action_mean 0.06 / train/action_min -3.88 / train/action_std 0.94 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 9.4e4 / train/actor_opt_loss -6.78 / train/adv_mag 0.58 / train/adv_max 0.48 / train/adv_mean 6.5e-4 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.1e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.78 / 
train/dyn_loss_std 3.89 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 9.4e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.86 / train/extr_critic_max 671.86 / train/extr_critic_mean 604.28 / train/extr_critic_min 411.89 / train/extr_critic_std 71.04 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.68 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.6 / train/extr_return_raw_max 668.6 / train/extr_return_raw_mean 604.41 / train/extr_return_raw_min 419.54 / train/extr_return_raw_std 71.18 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.05 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.37 / train/model_loss_mean 1.38 / train/model_loss_std 2.61 / 
train/model_opt_grad_norm 6.97 / train/model_opt_grad_steps 9.4e4 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8880.21 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.14 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.48 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.14 / train/policy_logprob_min -8.48 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 5.4e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 58.51 / train/post_ent_max 58.51 / train/post_ent_mean 40.7 / train/post_ent_min 
25.06 / train/post_ent_std 4.74 / train/prior_ent_mag 69.88 / train/prior_ent_max 69.88 / train/prior_ent_mean 42.11 / train/prior_ent_min 30.47 / train/prior_ent_std 5.85 / train/rep_loss_mean 1.78 / train/rep_loss_std 3.89 / train/reward_avg 1.04 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.04 / train/reward_rate 0.53 / 
train_stats/mean_log_entropy 0.46 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.07 / report/dyn_loss_std 4.96 / report/image_loss_mean 0.32 / report/image_loss_std 0.61 / report/model_loss_mean 1.61 / report/model_loss_std 3.4 / report/post_ent_mag 64.34 / report/post_ent_max 64.34 / 
report/post_ent_mean 41.74 / report/post_ent_min 22.39 / report/post_ent_std 4.8 / report/prior_ent_mag 69.52 / report/prior_ent_max 69.52 / report/prior_ent_mean 43.43 / report/prior_ent_min 29.05 / report/prior_ent_std 5.92 / report/rep_loss_mean 2.07 / 
report/rep_loss_std 4.96 / report/reward_avg 0.75 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.75 / report/reward_rate 0.38 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 3.04 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.21 / eval/model_loss_std 2 / eval/post_ent_mag 55.59 / eval/post_ent_max 55.59 / eval/post_ent_mean 40.43 
/ eval/post_ent_min 33.04 / eval/post_ent_std 3.74 / eval/prior_ent_mag 69.52 / eval/prior_ent_max 69.52 / eval/prior_ent_mean 41.58 / eval/prior_ent_min 35.95 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 3.04 / eval/reward_avg 1.49 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / replay/size
1.9e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3838 / timer/env.step_total 19.06 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.34 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.34 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.6e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.6e-5 / timer/dataset_eval_min 4.6e-5 / timer/dataset_eval_max 4.6e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 191000 Counter(191000) 190937
Saved chunk: 20230922T014444F551030-1hH3m13K7RVFtzVeUMuQmw-2GxAPo9P6dP2riGkce7O1p-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T014556F324837-16m8rkJekHV2hVgKe270Yq-3YptW4t30gwzuXBcxGp57H-1024.npz
Starting evaluation at step 191500 Counter(191500) 191437
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 192000 Counter(192000) 191937
Saved chunk: 20230922T014638F739253-2GxAPo9P6dP2riGkce7O1p-1ig3SwtujzjFDJNMW4UDFk-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 192500 Counter(192500) 192437
eval_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T014716F716302-3YptW4t30gwzuXBcxGp57H-431FlaSI2a1hTg7WiWiKPP-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 193000 Counter(193000) 192937
Saved chunk: 20230922T014756F564666-1ig3SwtujzjFDJNMW4UDFk-4JEe3CVfvl6Sznar42bwEV-1024.npz
eval_Episode has 500 steps and return 831.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 193500 Counter(193500) 193437
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T014839F397366-431FlaSI2a1hTg7WiWiKPP-1Dxg7aYwHa08mtuxTD1mey-1024.npz
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 194000 Counter(194000) 193937
Saved chunk: 20230922T014914F228846-4JEe3CVfvl6Sznar42bwEV-2NgI1K41L3mR8GUdyLk8GK-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 840.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 388926 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 840 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / train/action_mag 4.18 / train/action_max 3.95 / train/action_mean 0.06 / train/action_min -4.01 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 9.6e4 / train/actor_opt_loss -7.18 / train/adv_mag 0.63 / train/adv_max 0.51 / train/adv_mean 6.8e-4 / train/adv_min -0.53 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 3.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.8 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.19 / train/extr_critic_critic_opt_grad_steps 9.6e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.81 / train/extr_critic_max 671.81 / train/extr_critic_mean 607.57 / train/extr_critic_min 422.78 / train/extr_critic_std 66.74 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.68 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.43 / train/extr_return_raw_max 668.43 / train/extr_return_raw_mean 607.7 / train/extr_return_raw_min 432.05 / train/extr_return_raw_std 66.87 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.06 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.25 / train/image_loss_std 0.36 / train/model_loss_mean 1.37 / train/model_loss_std 2.55 / 
train/model_opt_grad_norm 7.21 / train/model_opt_grad_steps 9.6e4 / train/model_opt_loss 8153.76 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6000 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.16 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 4.8e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 58 / train/post_ent_max 58 / train/post_ent_mean 40.75 / train/post_ent_min 25.81 
/ train/post_ent_std 4.7 / train/prior_ent_mag 69.68 / train/prior_ent_max 69.68 / train/prior_ent_mean 42.13 / train/prior_ent_min 31.06 / train/prior_ent_std 5.82 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.8 / train/reward_avg 1.05 / train/reward_loss_mean 0.07 /
train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.05 / train/reward_rate 0.53 / train_stats/mean_log_entropy 
0.57 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.58 / report/image_loss_mean 0.22 / report/image_loss_std 0.27 / report/model_loss_mean 1.27 / report/model_loss_std 2.34 / report/post_ent_mag 53.03 / report/post_ent_max 53.03 / report/post_ent_mean 40.96 / 
report/post_ent_min 29.58 / report/post_ent_std 4.26 / report/prior_ent_mag 69.42 / report/prior_ent_max 69.42 / report/prior_ent_mean 42.15 / report/prior_ent_min 36.02 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.62 / report/rep_loss_std 3.58 / report/reward_avg
1.31 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.32 / 
report/reward_rate 0.66 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.39 / 
eval/dyn_loss_std 2.14 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.43 / eval/post_ent_mag 54.1 / eval/post_ent_max 54.1 / eval/post_ent_mean 39.37 / eval/post_ent_min 30.38 / eval/post_ent_std 4.22 / 
eval/prior_ent_mag 69.42 / eval/prior_ent_max 69.42 / eval/prior_ent_mean 40.4 / eval/prior_ent_min 35.83 / eval/prior_ent_std 5.63 / eval/rep_loss_mean 1.39 / eval/rep_loss_std 2.14 / eval/reward_avg 1.63 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.11 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size 1.9e5 / replay/inserts 3890 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3890 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.63 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.18 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 1945 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.3 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.93

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 194500 Counter(194500) 194437
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T014958F551328-1Dxg7aYwHa08mtuxTD1mey-5vKwyUxgz6LhHF7wUyV9gy-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 195000 Counter(195000) 194937
Saved chunk: 20230922T015031F876857-2NgI1K41L3mR8GUdyLk8GK-4JsnqIFbZJUSYc67IKI3Ek-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 195500 Counter(195500) 195437
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T015118F458425-5vKwyUxgz6LhHF7wUyV9gy-1kAEStAfuSCQNYav9qNrix-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 196000 Counter(196000) 195937
Saved chunk: 20230922T015150F444052-4JsnqIFbZJUSYc67IKI3Ek-06XSPISFRhOWGaYyK3iY5s-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 196500 Counter(196500) 196437
eval_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T015238F063224-1kAEStAfuSCQNYav9qNrix-1nFlK7SMakb6zWtpBov5rh-1024.npz
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 197000 Counter(197000) 196937
Saved chunk: 20230922T015308F342344-06XSPISFRhOWGaYyK3iY5s-0rGnetwuhBMzc15rJS9td1-1024.npz
eval_Episode has 500 steps and return 842.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T015426F001467-0rGnetwuhBMzc15rJS9td1-0000000000000000000000-361.npz
Saved chunk: 20230922T015357F350254-1nFlK7SMakb6zWtpBov5rh-0000000000000000000000-692.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 812.0.
Starting evaluation at step 197500 Counter(197500) 197437
eval_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T015357F350254-1nFlK7SMakb6zWtpBov5rh-074G12n0XsmH5pBJrhAEqe-1024.npz
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 198000 Counter(198000) 197937
Saved chunk: 20230922T015426F001467-0rGnetwuhBMzc15rJS9td1-0niIT18DpgAeVKE80FADyj-1024.npz
eval_Episode has 500 steps and return 843.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 396606 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 843 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 828 / episode/reward_rate 0.83 / train/action_mag 4.02 / train/action_max 3.84 / train/action_mean 0.05 / train/action_min -3.74 / train/action_std 0.92 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 9.8e4 / train/actor_opt_loss -5.09 / train/adv_mag 0.56 / train/adv_max 0.45 / train/adv_mean 4.9e-4 / train/adv_min -0.5 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5.1e-11 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.76 / 
train/dyn_loss_std 3.85 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.16 / train/extr_critic_critic_opt_grad_steps 9.8e4 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.76 / train/extr_critic_max 671.76 / train/extr_critic_mean 610.11 / train/extr_critic_min 426.63 / train/extr_critic_std 66.9 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.78 / train/extr_return_raw_max 668.78 / train/extr_return_raw_mean 610.2 / train/extr_return_raw_min 432.09 / train/extr_return_raw_std 67.05 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.11 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.36 / train/model_loss_mean 1.37 / train/model_loss_std 2.58 / 
train/model_opt_grad_norm 6.78 / train/model_opt_grad_steps 9.8e4 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9427.08 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.11 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.38 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.11 / train/policy_logprob_min -8.38 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.43 / train/policy_randomness_min 3.4e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 57.33 / train/post_ent_max 57.33 / train/post_ent_mean 40.57 / train/post_ent_min
24.82 / train/post_ent_std 4.66 / train/prior_ent_mag 69.47 / train/prior_ent_max 69.47 / train/prior_ent_mean 41.94 / train/prior_ent_min 30.65 / train/prior_ent_std 5.8 / train/rep_loss_mean 1.76 / train/rep_loss_std 3.85 / train/reward_avg 1.1 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.1 / train/reward_rate 0.55 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.36 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 4.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 3.22 / report/image_loss_mean 0.19 / report/image_loss_std 0.29 / report/model_loss_mean 1.22 / report/model_loss_std 2.13 / report/post_ent_mag 53.82 / report/post_ent_max 53.82 / 
report/post_ent_mean 40.08 / report/post_ent_min 29.55 / report/post_ent_std 4.42 / report/prior_ent_mag 69.32 / report/prior_ent_max 69.32 / report/prior_ent_mean 41.13 / report/prior_ent_min 35.88 / report/prior_ent_std 5.78 / report/rep_loss_mean 1.58 / 
report/rep_loss_std 3.22 / report/reward_avg 1.39 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 6.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.39 / report/reward_rate 0.7 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / eval/dyn_loss_std 3.42 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.28 / eval/model_loss_std 2.23 / eval/post_ent_mag 54.12 / eval/post_ent_max 54.12 / eval/post_ent_mean 41.06 / 
eval/post_ent_min 32.68 / eval/post_ent_std 4.07 / eval/prior_ent_mag 69.32 / eval/prior_ent_max 69.32 / eval/prior_ent_mean 42.23 / eval/prior_ent_min 35.98 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 3.42 / eval/reward_avg 1.33 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.33 / eval/reward_rate 0.67 / 
replay/size 2e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3840 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.72 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.2e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.33 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.21 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 198500 Counter(198500) 198437
eval_Episode has 500 steps and return 825.0.
Saved chunk: 20230922T015516F770519-074G12n0XsmH5pBJrhAEqe-4QxXlo8ehsazT9178Ogl9g-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 199000 Counter(199000) 198937
Saved chunk: 20230922T015543F842879-0niIT18DpgAeVKE80FADyj-4xv09kvWscFbcmUN9iGPJ9-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 199500 Counter(199500) 199437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T015636F873293-4QxXlo8ehsazT9178Ogl9g-55dlhWw1KAXJhfb2xv9WGQ-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 200000 Counter(200000) 199937
Saved chunk: 20230922T015702F532911-4xv09kvWscFbcmUN9iGPJ9-2Q6P1KnSSAVLu3Zctci5rR-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 200500 Counter(200500) 200437
eval_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T015756F244089-55dlhWw1KAXJhfb2xv9WGQ-0YYBLHpYNzuauEmHca5y3q-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 201000 Counter(201000) 200937
Saved chunk: 20230922T015820F243458-2Q6P1KnSSAVLu3Zctci5rR-2VPV0WgEMirTpfMGDQpmqs-1024.npz
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 201500 Counter(201500) 201437
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T015915F467725-0YYBLHpYNzuauEmHca5y3q-5EktbUy7dvT0ZdKgm7KMIt-1024.npz
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 202000 Counter(202000) 201937
Saved chunk: 20230922T015937F918024-2VPV0WgEMirTpfMGDQpmqs-1vGtCoHI4kdZKRVmD2SZGe-1024.npz
eval_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 404290 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 829 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / train/action_mag 4.03 / train/action_max 3.9 / train/action_mean 0.05 / train/action_min -3.73 / train/action_std 0.93 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -6.92 / train/adv_mag 0.57 / train/adv_max 0.48 / train/adv_mean 6.7e-4 / train/adv_min -0.48 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.77 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.35 / train/extr_critic_max 671.35 / train/extr_critic_mean 611.32 / train/extr_critic_min 428.23 / train/extr_critic_std 65.54 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.67 / train/extr_return_raw_max 668.67 / train/extr_return_raw_mean 611.44 / train/extr_return_raw_min 438.01 / train/extr_return_raw_std 65.64
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.12 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.34 / train/model_loss_mean 1.35 / train/model_loss_std 2.52 / 
train/model_opt_grad_norm 6.82 / train/model_opt_grad_steps 9.9e4 / train/model_opt_loss 8832.51 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6562.5 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.12 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.68 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.12 / train/policy_logprob_min -8.68 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 3.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.04 / train/post_ent_max 57.04 / train/post_ent_mean 40.49 / train/post_ent_min
25.69 / train/post_ent_std 4.69 / train/prior_ent_mag 69.62 / train/prior_ent_max 69.62 / train/prior_ent_mean 41.84 / train/prior_ent_min 30.99 / train/prior_ent_std 5.84 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.77 / train/reward_avg 1.11 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.11 / train/reward_rate 0.56 / 
train_stats/mean_log_entropy 0.42 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / report/dyn_loss_std 2.63 / report/image_loss_mean 0.17 / report/image_loss_std 0.16 / report/model_loss_mean 1.17 / report/model_loss_std 1.69 / report/post_ent_mag 64.33 / report/post_ent_max 64.33 / 
report/post_ent_mean 39.8 / report/post_ent_min 24.45 / report/post_ent_std 4.8 / report/prior_ent_mag 69.54 / report/prior_ent_max 69.54 / report/prior_ent_mean 40.89 / report/prior_ent_min 29.62 / report/prior_ent_std 5.9 / report/rep_loss_mean 1.56 / 
report/rep_loss_std 2.63 / report/reward_avg 1.16 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.16 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.38 / eval/dyn_loss_std 2.31 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.55 / eval/post_ent_mag 52.84 / eval/post_ent_max 52.84 / eval/post_ent_mean 
38.28 / eval/post_ent_min 30.94 / eval/post_ent_std 3.66 / eval/prior_ent_mag 69.54 / eval/prior_ent_max 69.54 / eval/prior_ent_mean 39.15 / eval/prior_ent_min 35.9 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 1.38 / eval/rep_loss_std 2.31 / eval/reward_avg 1.7 / 
eval/reward_loss_mean 0.12 / eval/reward_loss_std 0.34 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.7 / eval/reward_rate 0.85 / replay/size
2e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3842 / timer/env.step_total 19.33 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.86 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.02 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 202500 Counter(202500) 202437
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T020034F623800-5EktbUy7dvT0ZdKgm7KMIt-3q432Ae90PNav9YmZGFpu0-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 203000 Counter(203000) 202937
Saved chunk: 20230922T020055F588486-1vGtCoHI4kdZKRVmD2SZGe-0u472GtCtiHq4BSchheIQy-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 203500 Counter(203500) 203437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T020154F889848-3q432Ae90PNav9YmZGFpu0-68HZBxF5ifL9jFfFuBDKqd-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 204000 Counter(204000) 203937
Saved chunk: 20230922T020214F304430-0u472GtCtiHq4BSchheIQy-49QFVOgNIMBD0B3h1za7Jv-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 204500 Counter(204500) 204437
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T020314F278955-68HZBxF5ifL9jFfFuBDKqd-5iDm6MCXYHbvAYHWqRp6fL-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 205000 Counter(205000) 204937
Saved chunk: 20230922T020332F097254-49QFVOgNIMBD0B3h1za7Jv-36mKCe7HPHmjo9TcTRH5j2-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 205500 Counter(205500) 205437
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T020433F524083-5iDm6MCXYHbvAYHWqRp6fL-1bp9GhwSI9FcK1zuSQEuhp-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 206000 Counter(206000) 205937
Saved chunk: 20230922T020449F777703-36mKCe7HPHmjo9TcTRH5j2-1EtDKfbkDWN08lTPcbCScx-1024.npz
eval_Episode has 500 steps and return 842.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 412002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 841 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 842 / eval_episode/reward_rate 0.84 / train/action_mag 4.1 / train/action_max 3.8 / train/action_mean 0.05 / train/action_min -3.97 / train/action_std 0.95 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -4.97 / train/adv_mag 0.61 / train/adv_max 0.5 / train/adv_mean 4.4e-4 / train/adv_min -0.51 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 4.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.4 / train/extr_critic_max 671.4 / train/extr_critic_mean 613.71 / train/extr_critic_min 424.2 / train/extr_critic_std 64.47 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.7 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.36 / train/extr_return_raw_max 668.36 / train/extr_return_raw_mean 613.79 / train/extr_return_raw_min 435.44 / train/extr_return_raw_std 64.63
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.14 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.35 / train/model_loss_mean 1.35 / train/model_loss_std 2.51 / 
train/model_opt_grad_norm 6.72 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 9483.36 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7046.63 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.21 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.57 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.21 / train/policy_logprob_min -8.57 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 3.3e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 57.18 / train/post_ent_max 57.18 / train/post_ent_mean 40.48 / train/post_ent_min 
25.82 / train/post_ent_std 4.67 / train/prior_ent_mag 69.47 / train/prior_ent_max 69.47 / train/prior_ent_mean 41.82 / train/prior_ent_min 31.16 / train/prior_ent_std 5.83 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.75 / train/reward_avg 1.13 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.13 / train/reward_rate 0.57 / 
train_stats/mean_log_entropy 0.56 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 8.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / report/dyn_loss_std 3.49 / report/image_loss_mean 0.22 / report/image_loss_std 0.39 / report/model_loss_mean 1.35 / report/model_loss_std 2.37 / report/post_ent_mag 64.01 / report/post_ent_max 64.01 / 
report/post_ent_mean 39.46 / report/post_ent_min 25.65 / report/post_ent_std 4.35 / report/prior_ent_mag 69.97 / report/prior_ent_max 69.97 / report/prior_ent_mean 40.86 / report/prior_ent_min 31.41 / report/prior_ent_std 5.76 / report/rep_loss_mean 1.75 / 
report/rep_loss_std 3.49 / report/reward_avg 1.27 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 4.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.37 / eval/dyn_loss_std 2.19 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.15 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.42 / eval/post_ent_mag 54.29 / eval/post_ent_max 54.29 / eval/post_ent_mean 39.33 / 
eval/post_ent_min 31.24 / eval/post_ent_std 4.02 / eval/prior_ent_mag 69.97 / eval/prior_ent_max 69.97 / eval/prior_ent_mean 40.37 / eval/prior_ent_min 35.77 / eval/prior_ent_std 5.56 / eval/rep_loss_mean 1.37 / eval/rep_loss_std 2.19 / eval/reward_avg 1.54 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.54 / eval/reward_rate 0.77 / replay/size
2.1e5 / replay/inserts 3856 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.93 / timer/env.step_count 3856 / timer/env.step_total 19.2 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.63 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7864 / timer/agent.policy_total 17.25 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1928 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1928 / timer/agent.train_total 244.01 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 206500 Counter(206500) 206437
eval_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T020552F630313-1bp9GhwSI9FcK1zuSQEuhp-7CassFBpbas7ToxieyOrA9-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 207000 Counter(207000) 206937
Saved chunk: 20230922T020607F304759-1EtDKfbkDWN08lTPcbCScx-7zleRDKIBzMBJmEuroIK6d-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 207500 Counter(207500) 207437
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T020712F839965-7CassFBpbas7ToxieyOrA9-7p3tyAYq4jPQcNx1XEWgOe-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 208000 Counter(208000) 207937
Saved chunk: 20230922T020726F003315-7zleRDKIBzMBJmEuroIK6d-1W4Mw2aobDLNEbSUtMxsNc-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 208500 Counter(208500) 208437
eval_Episode has 500 steps and return 838.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T020832F116843-7p3tyAYq4jPQcNx1XEWgOe-3SOvsn4Kcnv89jAHZdSvTH-1024.npz
Saved chunk: 20230922T020843F712309-1W4Mw2aobDLNEbSUtMxsNc-0000000000000000000000-620.npz
Saved chunk: 20230922T020951F275956-3SOvsn4Kcnv89jAHZdSvTH-0000000000000000000000-4.npz
train_Episode has 500 steps and return 843.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 209000 Counter(209000) 208937
Saved chunk: 20230922T020843F712309-1W4Mw2aobDLNEbSUtMxsNc-3rWfxGG6XzxIQJXbCGCD4g-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 209500 Counter(209500) 209437
eval_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 419782 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 838 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / train/action_mag 3.97 / train/action_max 3.66 / train/action_mean 0.06 / train/action_min -3.86 / train/action_std 0.92 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.12 / train/actor_opt_grad_steps 1e5 / train/actor_opt_loss -5.67 / train/adv_mag 0.6 / train/adv_max 0.5 / train/adv_mean 5.4e-4 / train/adv_min -0.48 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.8e-11 / train/cont_loss_std 4.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.75 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.15 / train/extr_critic_max 671.15 / train/extr_critic_mean 612.61 / train/extr_critic_min 416.18 / train/extr_critic_std 64.35 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.69 / 
train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.51 / train/extr_return_raw_max 668.51 / train/extr_return_raw_mean 612.71 / train/extr_return_raw_min 435.29 / train/extr_return_raw_std 64.45
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.12 / train/extr_reward_min 0 / train/extr_reward_std 0.97 / train/image_loss_mean 0.23 / train/image_loss_std 0.35 / train/model_loss_mean 1.35 / train/model_loss_std 2.51 / 
train/model_opt_grad_norm 6.86 / train/model_opt_grad_steps 1e5 / train/model_opt_loss 8719.83 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6469.07 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.12 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.63 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.12 / train/policy_logprob_min -8.63 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 2.7e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 57.34 / train/post_ent_max 57.34 / train/post_ent_mean 40.39 / train/post_ent_min
25.27 / train/post_ent_std 4.72 / train/prior_ent_mag 69.27 / train/prior_ent_max 69.27 / train/prior_ent_mean 41.75 / train/prior_ent_min 30.87 / train/prior_ent_std 5.85 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.75 / train/reward_avg 1.11 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.11 / train/reward_rate 0.56 / 
train_stats/mean_log_entropy 0.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 9.9e-11 / report/cont_loss_std 9.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 9.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.8 / report/image_loss_mean 0.27 / report/image_loss_std 0.28 / report/model_loss_mean 1.36 / report/model_loss_std 2.51 / report/post_ent_mag 52.76 / report/post_ent_max 52.76 / 
report/post_ent_mean 41.16 / report/post_ent_min 21.05 / report/post_ent_std 4.94 / report/prior_ent_mag 69.29 / report/prior_ent_max 69.29 / report/prior_ent_mean 42.57 / report/prior_ent_min 24.18 / report/prior_ent_std 5.88 / report/rep_loss_mean 1.7 / 
report/rep_loss_std 3.8 / report/reward_avg 0.94 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.23 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 5.7e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.15 / report/reward_pred 0.94 / report/reward_rate 0.48 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.51 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.29 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.73 / eval/post_ent_mag 52.32 / eval/post_ent_max 52.32 / eval/post_ent_mean 
39.06 / eval/post_ent_min 32.69 / eval/post_ent_std 3.26 / eval/prior_ent_mag 69.29 / eval/prior_ent_max 69.29 / eval/prior_ent_mean 40.1 / eval/prior_ent_min 35.6 / eval/prior_ent_std 4.95 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.51 / eval/reward_avg 1.79 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.79 / eval/reward_rate 0.89 / 
replay/size 2.1e5 / replay/inserts 3890 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3890 / timer/env.step_total 19.34 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.3 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.8e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.43 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1945 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.27 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.3e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.3e-5 / 
timer/dataset_eval_min 4.3e-5 / timer/dataset_eval_max 4.3e-5 / fps 25.92

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T020951F275956-3SOvsn4Kcnv89jAHZdSvTH-3wCyfzW7NvECtqo4ZXoUzR-1024.npz
Starting evaluation at step 210000 Counter(210000) 209937
Saved chunk: 20230922T021001F602270-3rWfxGG6XzxIQJXbCGCD4g-4aDCBoypshqtBkaT8QIw9g-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 210500 Counter(210500) 210437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T021111F469714-3wCyfzW7NvECtqo4ZXoUzR-4azlidTLCErNd1moStk6z4-1024.npz
Starting evaluation at step 211000 Counter(211000) 210937
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T021120F082336-4aDCBoypshqtBkaT8QIw9g-0yvFvjnGETerAu03nuVdf3-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 211500 Counter(211500) 211437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T021230F944684-4azlidTLCErNd1moStk6z4-3fe2QiXzpncXdMLOBXF6w4-1024.npz
Starting evaluation at step 212000 Counter(212000) 211937
eval_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T021237F887960-0yvFvjnGETerAu03nuVdf3-7Ae6S62K3wwtqa0hyiOACG-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 212500 Counter(212500) 212437
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T021350F123483-3fe2QiXzpncXdMLOBXF6w4-11UCVNP7muwlwrYO26dyQS-1024.npz
Starting evaluation at step 213000 Counter(213000) 212937
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T021355F506452-7Ae6S62K3wwtqa0hyiOACG-3IEwncAiT9P3qH8uU9iJkg-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 213500 Counter(213500) 213437
eval_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 427446 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / train/action_mag 4.14 / train/action_max 3.65 / train/action_mean 0.04 / train/action_min -4.07 / train/action_std 0.94 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.46 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 3.9e-4 / train/adv_min -0.46 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.72 / 
train/dyn_loss_std 3.69 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.99 / train/extr_critic_max 671.99 / train/extr_critic_mean 616.29 / train/extr_critic_min 432 / train/extr_critic_std 63.09 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.71 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.12 / train/extr_return_raw_max 669.12 / train/extr_return_raw_mean 616.36 / train/extr_return_raw_min 439.27 / train/extr_return_raw_std 63.22
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.15 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.35 / train/model_loss_mean 1.34 / train/model_loss_std 2.48 / 
train/model_opt_grad_norm 6.42 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8411.46 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.22 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.22 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 2.7e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.57 / train/post_ent_max 56.57 / train/post_ent_mean 40.36 / train/post_ent_min
25.85 / train/post_ent_std 4.64 / train/prior_ent_mag 68.88 / train/prior_ent_max 68.88 / train/prior_ent_mean 41.7 / train/prior_ent_min 31.36 / train/prior_ent_std 5.79 / train/rep_loss_mean 1.72 / train/rep_loss_std 3.69 / train/reward_avg 1.14 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.14 / train/reward_rate 0.57 / 
train_stats/mean_log_entropy 0.38 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.01 / report/image_loss_mean 0.23 / report/image_loss_std 0.31 / report/model_loss_mean 1.3 / report/model_loss_std 2.03 / report/post_ent_mag 62.75 / report/post_ent_max 62.75 / 
report/post_ent_mean 41.08 / report/post_ent_min 26.44 / report/post_ent_std 4.71 / report/prior_ent_mag 68.67 / report/prior_ent_max 68.67 / report/prior_ent_mean 42.39 / report/prior_ent_min 24.99 / report/prior_ent_std 5.81 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.01 / report/reward_avg 1.1 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.3e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 1.1 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.6 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.14 / eval/model_loss_std 1.69 / eval/post_ent_mag 53.3 / eval/post_ent_max 53.3 / eval/post_ent_mean 38.71 / eval/post_ent_min 31.69 / 
eval/post_ent_std 3.83 / eval/prior_ent_mag 68.67 / eval/prior_ent_max 68.67 / eval/prior_ent_mean 39.76 / eval/prior_ent_min 35.81 / eval/prior_ent_std 5.3 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.6 / eval/reward_avg 1.62 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size 2.1e5 / replay/inserts 3832 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3832 / timer/env.step_total 19.02 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.41 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 1916
/ timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.66 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.5e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 214000 Counter(214000) 213937
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T021509F235882-11UCVNP7muwlwrYO26dyQS-3qINw5CrmuL7I6sdD4LjQq-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 214500 Counter(214500) 214437
Saved chunk: 20230922T021513F075826-3IEwncAiT9P3qH8uU9iJkg-7a9Cnxxh1I8SeFrkuNGU0t-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 215000 Counter(215000) 214937
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T021633F654102-3qINw5CrmuL7I6sdD4LjQq-1WZtJ4zlHaebcioMiEJnf1-1024.npz
train_Episode has 500 steps and return 799.0.
Starting evaluation at step 215500 Counter(215500) 215437
Saved chunk: 20230922T021708F116515-7a9Cnxxh1I8SeFrkuNGU0t-0kbdKN6h1RNf5uaxe7YHpv-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 216000 Counter(216000) 215937
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T021752F966278-1WZtJ4zlHaebcioMiEJnf1-0yjUYUhZsNoo65Fn7cxxdx-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 216500 Counter(216500) 216437
Saved chunk: 20230922T021825F771249-0kbdKN6h1RNf5uaxe7YHpv-0eKYiCipZcvlMTuN9IHjkd-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 217000 Counter(217000) 216937
eval_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T021912F233281-0yjUYUhZsNoo65Fn7cxxdx-0Ty1JaImLE7NP0Q65DUlCo-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 217500 Counter(217500) 217437
Saved chunk: 20230922T021943F355854-0eKYiCipZcvlMTuN9IHjkd-7rGdY5AYhskF5B8gJ3saAH-1024.npz
eval_Episode has 500 steps and return 0.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 435146 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 0 / eval_episode/reward_rate 0 / train/action_mag 4.19 / train/action_max 3.6 / train/action_mean 0.04 / train/action_min -4.12 / train/action_std 0.92 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -4.43 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 3.9e-4 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5.2e-11 / train/cont_loss_std 5.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.62 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.63 / train/extr_critic_max 672.63 / train/extr_critic_mean 618.26 / train/extr_critic_min 433.15 / train/extr_critic_std 62.55 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.75 / train/extr_return_raw_max 669.75 / train/extr_return_raw_mean 618.33 / train/extr_return_raw_min 439.08 / train/extr_return_raw_std 62.72
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.16 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.34 / train/model_loss_mean 1.33 / train/model_loss_std 2.42 / 
train/model_opt_grad_norm 6.34 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 8146.43 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6145.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.19 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.81 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.19 / train/policy_logprob_min -8.81 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.47 / train/policy_randomness_min 1.6e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 56.3 / train/post_ent_max 56.3 / train/post_ent_mean 40.36 / train/post_ent_min 
26.25 / train/post_ent_std 4.62 / train/prior_ent_mag 68.68 / train/prior_ent_max 68.68 / train/prior_ent_mean 41.69 / train/prior_ent_min 31.56 / train/prior_ent_std 5.74 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.62 / train/reward_avg 1.15 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.15 / train/reward_rate 0.58 / 
train_stats/mean_log_entropy 0.29 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.96 / report/dyn_loss_std 4.65 / report/image_loss_mean 0.27 / report/image_loss_std 0.37 / report/model_loss_mean 1.49 / report/model_loss_std 3.06 / report/post_ent_mag 62.78 / report/post_ent_max 62.78 / 
report/post_ent_mean 40.83 / report/post_ent_min 20.31 / report/post_ent_std 5.63 / report/prior_ent_mag 68.8 / report/prior_ent_max 68.8 / report/prior_ent_mean 42.45 / report/prior_ent_min 29.47 / report/prior_ent_std 6.36 / report/rep_loss_mean 1.96 / 
report/rep_loss_std 4.65 / report/reward_avg 0.67 / report/reward_loss_mean 0.04 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.67 / report/reward_rate 0.34 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 3.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.28 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.52 / eval/post_ent_mag 53.17 / eval/post_ent_max 53.17 / eval/post_ent_mean 
38.86 / eval/post_ent_min 30.72 / eval/post_ent_std 3.86 / eval/prior_ent_mag 68.8 / eval/prior_ent_max 68.8 / eval/prior_ent_mean 39.94 / eval/prior_ent_min 35.98 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.28 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.6e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size
2.2e5 / replay/inserts 3850 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3850 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.14 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7858 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1925 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1925 / timer/agent.train_total 243.39 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.25 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.66

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 825.0.
Starting evaluation at step 218000 Counter(218000) 217937
eval_Episode has 500 steps and return 257.0.
Saved chunk: 20230922T022031F254527-0Ty1JaImLE7NP0Q65DUlCo-7u7i2zTbWom8icuQavttsQ-1024.npz
train_Episode has 500 steps and return 167.0.
Starting evaluation at step 218500 Counter(218500) 218437
Saved chunk: 20230922T022100F837401-7rGdY5AYhskF5B8gJ3saAH-1kysUzbWTWJQQpaVOyoLaZ-1024.npz
eval_Episode has 500 steps and return 623.0.
train_Episode has 500 steps and return 635.0.
Starting evaluation at step 219000 Counter(219000) 218937
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T022151F294968-7u7i2zTbWom8icuQavttsQ-4RHp5qce674KyUrctKc1OA-1024.npz
train_Episode has 500 steps and return 805.0.
Starting evaluation at step 219500 Counter(219500) 219437
Saved chunk: 20230922T022219F488800-1kysUzbWTWJQQpaVOyoLaZ-7GtOSSQiI6psYnwPEFsQnn-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 220000 Counter(220000) 219937
eval_Episode has 500 steps and return 830.0.
Saved chunk: 20230922T022310F659875-4RHp5qce674KyUrctKc1OA-2gLtZjwCPyV4Z7ncYMUVUE-1024.npz
train_Episode has 500 steps and return 782.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 220500 Counter(220500) 220437
Saved chunk: 20230922T022337F300043-7GtOSSQiI6psYnwPEFsQnn-0000000000000000000000-879.npz
Saved chunk: 20230922T022429F964235-2gLtZjwCPyV4Z7ncYMUVUE-0000000000000000000000-340.npz
Saved chunk: 20230922T022337F300043-7GtOSSQiI6psYnwPEFsQnn-6od2iAaWU9HIeWWeBWOBnp-1024.npz
eval_Episode has 500 steps and return 830.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 221000 Counter(221000) 220937
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T022429F964235-2gLtZjwCPyV4Z7ncYMUVUE-6CJcL8XvAomWeeP8pOixf7-1024.npz
train_Episode has 500 steps and return 841.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 442922 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 841 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 842 / eval_episode/reward_rate 0.84 / train/action_mag 4.24 / train/action_max 3.75 / train/action_mean 0.03 / train/action_min -4.18 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.98 / train/adv_mag 0.49 / train/adv_max 0.42 / train/adv_mean 3.3e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.9e-11 / train/cont_loss_std 3.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.75 / 
train/dyn_loss_std 3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.74 / train/extr_critic_max 672.74 / train/extr_critic_mean 616.73 / train/extr_critic_min 415.33 / train/extr_critic_std 66.17 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.97 / train/extr_return_raw_max 669.97 / train/extr_return_raw_mean 616.79 / train/extr_return_raw_min 422.88 / train/extr_return_raw_std 66.33
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.15 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.37 / train/model_loss_mean 1.36 / train/model_loss_std 2.49 / 
train/model_opt_grad_norm 6.31 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7435.9 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.24 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.65 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.24 / train/policy_logprob_min -8.65 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.49 / train/policy_randomness_min 1.9e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 56.46 / train/post_ent_max 56.46 / train/post_ent_mean 40.54 / train/post_ent_min
25.92 / train/post_ent_std 4.53 / train/prior_ent_mag 68.99 / train/prior_ent_max 68.99 / train/prior_ent_mean 41.9 / train/prior_ent_min 31.81 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.75 / train/rep_loss_std 3.68 / train/reward_avg 1.13 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.13 / train/reward_pred 1.13 / train/reward_rate 0.57 / 
train_stats/mean_log_entropy 0.38 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 3.73 / report/image_loss_mean 0.25 / report/image_loss_std 0.39 / report/model_loss_mean 1.39 / report/model_loss_std 2.51 / report/post_ent_mag 62.41 / report/post_ent_max 62.41 / 
report/post_ent_mean 40.83 / report/post_ent_min 22.83 / report/post_ent_std 5.16 / report/prior_ent_mag 68.85 / report/prior_ent_max 68.85 / report/prior_ent_mean 42.25 / report/prior_ent_min 27.93 / report/prior_ent_std 6.1 / report/rep_loss_mean 1.79 / 
report/rep_loss_std 3.73 / report/reward_avg 1.02 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.02 / report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.42 / eval/dyn_loss_std 2.46 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.6 / eval/post_ent_mag 51.85 / eval/post_ent_max 51.85 / eval/post_ent_mean 
39.2 / eval/post_ent_min 33.41 / eval/post_ent_std 3.68 / eval/prior_ent_mag 68.85 / eval/prior_ent_max 68.85 / eval/prior_ent_mean 40.3 / eval/prior_ent_min 35.74 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 1.42 / eval/rep_loss_std 2.46 / eval/reward_avg 1.57 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.57 / eval/reward_rate 0.79 / replay/size
2.2e5 / replay/inserts 3888 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3888 / timer/env.step_total 19.3 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.7 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-4 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7395 / timer/agent.policy_total 16.51 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1944 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1944 / timer/agent.train_total 246.05 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.91

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 221500 Counter(221500) 221437
Saved chunk: 20230922T022455F058261-6od2iAaWU9HIeWWeBWOBnp-52HjUqsh6ObOFIQq3GhpLH-1024.npz
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 222000 Counter(222000) 221937
eval_Episode has 500 steps and return 607.0.
Saved chunk: 20230922T022549F344221-6CJcL8XvAomWeeP8pOixf7-3MBmmbJF7rjEmXE9ZWZDLa-1024.npz
train_Episode has 500 steps and return 578.0.
Starting evaluation at step 222500 Counter(222500) 222437
Saved chunk: 20230922T022613F567361-52HjUqsh6ObOFIQq3GhpLH-15Uee6zQ157gzANdOORw5a-1024.npz
eval_Episode has 500 steps and return 648.0.
train_Episode has 500 steps and return 632.0.
Starting evaluation at step 223000 Counter(223000) 222937
eval_Episode has 500 steps and return 542.0.
Saved chunk: 20230922T022709F489132-3MBmmbJF7rjEmXE9ZWZDLa-6ub3O4G3J59nVwps2r6Oyf-1024.npz
train_Episode has 500 steps and return 638.0.
Starting evaluation at step 223500 Counter(223500) 223437
Saved chunk: 20230922T022731F407596-15Uee6zQ157gzANdOORw5a-5luTAkNhuYFswcK5t01qNZ-1024.npz
eval_Episode has 500 steps and return 757.0.
train_Episode has 500 steps and return 634.0.
Starting evaluation at step 224000 Counter(224000) 223937
eval_Episode has 500 steps and return 635.0.
Saved chunk: 20230922T022828F635296-6ub3O4G3J59nVwps2r6Oyf-1jCT2iTY8cDlRd65O9UdAr-1024.npz
train_Episode has 500 steps and return 606.0.
Starting evaluation at step 224500 Counter(224500) 224437
Saved chunk: 20230922T022849F006712-5luTAkNhuYFswcK5t01qNZ-3TXdkPA54Qv8ieuABIvB5C-1024.npz
eval_Episode has 500 steps and return 627.0.
train_Episode has 500 steps and return 620.0.
Starting evaluation at step 225000 Counter(225000) 224937
eval_Episode has 500 steps and return 635.0.
Saved chunk: 20230922T022947F824191-1jCT2iTY8cDlRd65O9UdAr-5ucgvgXV966b6G7m3sNeCZ-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 450618 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 635 / eval_episode/reward_rate 0.64 / episode/length 500 / episode/score 620 / episode/reward_rate 0.62 / train/action_mag 4.29 / train/action_max 3.94 / train/action_mean 0.01 / train/action_min -4.2 / train/action_std 0.99 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -3.54 / train/adv_mag 0.59 / train/adv_max 0.52 / train/adv_mean 2.7e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 3.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.6 / train/extr_critic_max 672.6 / train/extr_critic_mean 615.15 / train/extr_critic_min 381.81 / train/extr_critic_std 69.75 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.05 / train/extr_return_raw_max 670.05 / train/extr_return_raw_mean 615.2 / train/extr_return_raw_min 393.36 / train/extr_return_raw_std 69.9 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.16 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.35 / train/model_loss_mean 1.34 / train/model_loss_std 2.47 / 
train/model_opt_grad_norm 6.44 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9114.58 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.29 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.97 / train/policy_logprob_mag 8.53 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.28 / train/policy_logprob_min -8.53 / train/policy_logprob_std 1.2 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.42 / train/post_ent_mag 56.55 / train/post_ent_max 56.55 / train/post_ent_mean 40.32 / train/post_ent_min
25.86 / train/post_ent_std 4.63 / train/prior_ent_mag 68.91 / train/prior_ent_max 68.91 / train/prior_ent_mean 41.67 / train/prior_ent_min 31.29 / train/prior_ent_std 5.77 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.68 / train/reward_avg 1.15 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.15 / train/reward_rate 0.58 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.34 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.6 / report/dyn_loss_std 3.49 / report/image_loss_mean 0.2 / report/image_loss_std 0.47 / report/model_loss_mean 1.25 / report/model_loss_std 2.45 / report/post_ent_mag 52.03 / report/post_ent_max 52.03 / 
report/post_ent_mean 39.46 / report/post_ent_min 23.29 / report/post_ent_std 4.09 / report/prior_ent_mag 69.09 / report/prior_ent_max 69.09 / report/prior_ent_mean 40.55 / report/prior_ent_min 34.79 / report/prior_ent_std 5.55 / report/rep_loss_mean 1.6 / 
report/rep_loss_std 3.49 / report/reward_avg 1.61 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.2e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.61 / report/reward_rate 0.8 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 4.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.4 / eval/dyn_loss_std 2.44 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.14 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.55 / eval/post_ent_mag 54.52 / eval/post_ent_max 54.52 / eval/post_ent_mean 38.75 / 
eval/post_ent_min 31.94 / eval/post_ent_std 4.05 / eval/prior_ent_mag 69.09 / eval/prior_ent_max 69.09 / eval/prior_ent_mean 39.59 / eval/prior_ent_min 34.81 / eval/prior_ent_std 5.58 / eval/rep_loss_mean 1.4 / eval/rep_loss_std 2.44 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size
2.3e5 / replay/inserts 3848 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3848 / timer/env.step_total 19.24 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.51 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7856 / timer/agent.policy_total 17.11 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1924 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1924 / timer/agent.train_total 243.32 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.65

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 641.0.
Starting evaluation at step 225500 Counter(225500) 225437
Saved chunk: 20230922T023006F645210-3TXdkPA54Qv8ieuABIvB5C-0OJ3sfUqhTFNXaKHo299EL-1024.npz
eval_Episode has 500 steps and return 611.0.
train_Episode has 500 steps and return 631.0.
Starting evaluation at step 226000 Counter(226000) 225937
eval_Episode has 500 steps and return 644.0.
Saved chunk: 20230922T023106F920635-5ucgvgXV966b6G7m3sNeCZ-1LaTGow4bqq3lWP4vsR6ir-1024.npz
train_Episode has 500 steps and return 623.0.
Starting evaluation at step 226500 Counter(226500) 226437
Saved chunk: 20230922T023125F060479-0OJ3sfUqhTFNXaKHo299EL-1HzdAVE6XSqlUMEYkMqbeb-1024.npz
eval_Episode has 500 steps and return 642.0.
train_Episode has 500 steps and return 640.0.
Starting evaluation at step 227000 Counter(227000) 226937
eval_Episode has 500 steps and return 400.0.
Saved chunk: 20230922T023227F190177-1LaTGow4bqq3lWP4vsR6ir-57gYdzNkTdqOyvzMrzjuFE-1024.npz
train_Episode has 500 steps and return 635.0.
Starting evaluation at step 227500 Counter(227500) 227437
Saved chunk: 20230922T023242F939213-1HzdAVE6XSqlUMEYkMqbeb-11cRI1FwQtw2VBB0k2IXue-1024.npz
eval_Episode has 500 steps and return 344.0.
train_Episode has 500 steps and return 456.0.
Starting evaluation at step 228000 Counter(228000) 227937
eval_Episode has 500 steps and return 582.0.
Saved chunk: 20230922T023346F460758-57gYdzNkTdqOyvzMrzjuFE-3EGZOy39j57RbxqJmmKd0E-1024.npz
train_Episode has 500 steps and return 364.0.
Starting evaluation at step 228500 Counter(228500) 228437
Saved chunk: 20230922T023400F583816-11cRI1FwQtw2VBB0k2IXue-4OE5E7EmwgHLd3FzNz7kux-1024.npz
eval_Episode has 500 steps and return 699.0.
train_Episode has 500 steps and return 604.0.
Starting evaluation at step 229000 Counter(229000) 228937
eval_Episode has 500 steps and return 596.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 458310 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 604 / episode/reward_rate 0.6 / eval_episode/length 500 / eval_episode/score 596 / eval_episode/reward_rate 0.59 / train/action_mag 4.28 / train/action_max 3.98 / train/action_mean 7.9e-3 / train/action_min -4.14 / train/action_std 0.99 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -2.76 / train/adv_mag 0.53 / train/adv_max 0.45 / train/adv_mean 2e-4 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.7e-11 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.74 / 
train/dyn_loss_std 3.68 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.14 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.96 / train/extr_critic_max 671.96 / train/extr_critic_mean 615.33 / train/extr_critic_min 378.55 / train/extr_critic_std 68.02 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.54 / train/extr_return_raw_max 669.54 / train/extr_return_raw_mean 615.37 / train/extr_return_raw_min 392.45 / train/extr_return_raw_std 68.13
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.15 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.36 / train/model_loss_mean 1.35 / train/model_loss_std 2.47 / 
train/model_opt_grad_norm 6.59 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8281.25 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.26 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.97 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.26 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.2 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.42 / train/post_ent_mag 56.07 / train/post_ent_max 56.07 / train/post_ent_mean 40.34 / train/post_ent_min 
25.97 / train/post_ent_std 4.74 / train/prior_ent_mag 68.87 / train/prior_ent_max 68.87 / train/prior_ent_mean 41.7 / train/prior_ent_min 31.29 / train/prior_ent_std 5.87 / train/rep_loss_mean 1.74 / train/rep_loss_std 3.68 / train/reward_avg 1.13 / train/reward_loss_mean
0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.13 / train/reward_rate 0.57 / 
train_stats/mean_log_entropy 0.17 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.86 / report/dyn_loss_std 4.39 / report/image_loss_mean 0.26 / report/image_loss_std 0.35 / report/model_loss_mean 1.44 / report/model_loss_std 2.9 / report/post_ent_mag 53.98 / report/post_ent_max 53.98 / 
report/post_ent_mean 40.45 / report/post_ent_min 24.25 / report/post_ent_std 5.25 / report/prior_ent_mag 68.69 / report/prior_ent_max 68.69 / report/prior_ent_mean 42 / report/prior_ent_min 32.7 / report/prior_ent_std 6.23 / report/rep_loss_mean 1.86 / report/rep_loss_std
4.39 / report/reward_avg 0.96 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / 
report/reward_pred 0.96 / report/reward_rate 0.49 / eval/cont_avg 1 / eval/cont_loss_mean 1.1e-10 / eval/cont_loss_std 1.8e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.1e-10 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.72 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.82 / eval/post_ent_mag 53.61 / eval/post_ent_max 53.61 / eval/post_ent_mean 38.16 / eval/post_ent_min 30.84 / 
eval/post_ent_std 3.58 / eval/prior_ent_mag 68.69 / eval/prior_ent_max 68.69 / eval/prior_ent_mean 39.19 / eval/prior_ent_min 34.49 / eval/prior_ent_std 5.16 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.72 / eval/reward_avg 1.74 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.73 / eval/reward_rate 0.87 / replay/size 2.3e5 / replay/inserts 3846 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3846 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.65 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7854 / timer/agent.policy_total 17.1 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / timer/dataset_train_count 
1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1923 / timer/agent.train_total 243.35 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.64

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T023505F566168-3EGZOy39j57RbxqJmmKd0E-2x0tgLIrgNVB7DFkXuj9wT-1024.npz
train_Episode has 500 steps and return 639.0.
Starting evaluation at step 229500 Counter(229500) 229437
Saved chunk: 20230922T023518F170027-4OE5E7EmwgHLd3FzNz7kux-3LMWLwnqvHfUbEBGerXygV-1024.npz
eval_Episode has 500 steps and return 653.0.
train_Episode has 500 steps and return 598.0.
Starting evaluation at step 230000 Counter(230000) 229937
eval_Episode has 500 steps and return 816.0.
Saved chunk: 20230922T023625F468476-2x0tgLIrgNVB7DFkXuj9wT-27oIK6vHrQWBZOlmscS3hD-1024.npz
train_Episode has 500 steps and return 801.0.
Starting evaluation at step 230500 Counter(230500) 230437
Saved chunk: 20230922T023636F610264-3LMWLwnqvHfUbEBGerXygV-1ALUAN6eYUl5E73ppCftMF-1024.npz
eval_Episode has 500 steps and return 827.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 231000 Counter(231000) 230937
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T023744F879622-27oIK6vHrQWBZOlmscS3hD-6n8yYoT9G1BCRtA9cNC4Dd-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 231500 Counter(231500) 231437
Saved chunk: 20230922T023754F373845-1ALUAN6eYUl5E73ppCftMF-51Xu9myr3GQvLY9RLrJ36r-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 232000 Counter(232000) 231937
eval_Episode has 500 steps and return 825.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T023912F016155-51Xu9myr3GQvLY9RLrJ36r-0000000000000000000000-615.npz
Saved chunk: 20230922T023904F053211-6n8yYoT9G1BCRtA9cNC4Dd-0000000000000000000000-676.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T023904F053211-6n8yYoT9G1BCRtA9cNC4Dd-0L1k2TKng1FtShKyTQs2u3-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 232500 Counter(232500) 232437
Saved chunk: 20230922T023912F016155-51Xu9myr3GQvLY9RLrJ36r-4MnmQUXCt8GSIj2QnCECng-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 233000 Counter(233000) 232937
eval_Episode has 500 steps and return 846.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 466002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 837 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 846 / eval_episode/reward_rate 0.84 / train/action_mag 4.11 / train/action_max 3.98 / train/action_mean 0.04 / train/action_min -3.84 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.1e5 / train/actor_opt_loss -5.62 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 5.1e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 5e-11 / train/cont_loss_std 5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.27 / train/extr_critic_max 672.27 / train/extr_critic_mean 617.52 / train/extr_critic_min 426.03 / train/extr_critic_std 65.5 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.5 / train/extr_return_raw_max 669.5 / train/extr_return_raw_mean 617.62 / train/extr_return_raw_min 428.01 / train/extr_return_raw_std 65.54 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.18 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.34 / train/model_loss_mean 1.33 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 6.38 / train/model_opt_grad_steps 1.1e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.21 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.61 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.21 / train/policy_logprob_min -8.61 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 56.35 / train/post_ent_max 56.35 / train/post_ent_mean 40.05 / train/post_ent_min 
25.98 / train/post_ent_std 4.85 / train/prior_ent_mag 68.85 / train/prior_ent_max 68.85 / train/prior_ent_mean 41.38 / train/prior_ent_min 31.11 / train/prior_ent_std 5.97 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.59 / train/reward_avg 1.16 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.16 / train/reward_rate 0.58 / 
train_stats/mean_log_entropy 0.53 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.79 / report/dyn_loss_std 4.22 / report/image_loss_mean 0.24 / report/image_loss_std 0.54 / report/model_loss_mean 1.39 / report/model_loss_std 2.93 / report/post_ent_mag 62.62 / report/post_ent_max 62.62 / 
report/post_ent_mean 41.06 / report/post_ent_min 24.83 / report/post_ent_std 4.82 / report/prior_ent_mag 68.69 / report/prior_ent_max 68.69 / report/prior_ent_mean 42.53 / report/prior_ent_min 30.79 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.79 / 
report/rep_loss_std 4.22 / report/reward_avg 1.14 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.2e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.14 / report/reward_rate 0.57 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.31 / eval/dyn_loss_std 1.59 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.14 / eval/model_loss_mean 1.03 / eval/model_loss_std 1.06 / eval/post_ent_mag 52.41 / eval/post_ent_max 52.41 / eval/post_ent_mean 
36.93 / eval/post_ent_min 30.75 / eval/post_ent_std 3.48 / eval/prior_ent_mag 68.69 / eval/prior_ent_max 68.69 / eval/prior_ent_mean 37.89 / eval/prior_ent_min 34 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 1.31 / eval/rep_loss_std 1.59 / eval/reward_avg 1.91 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.02 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.3e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.91 / eval/reward_rate 0.96 / replay/size
2.3e5 / replay/inserts 3846 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.14 / timer/env.step_count 3846 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.76 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 9e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7854 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1923 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1923 / timer/agent.train_total 243.42 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / 
timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T024023F339071-0L1k2TKng1FtShKyTQs2u3-1ibekfWy3Tu6XrcTPGnMCc-1024.npz
Starting evaluation at step 233500 Counter(233500) 233437
Saved chunk: 20230922T024029F742780-4MnmQUXCt8GSIj2QnCECng-01U39LOA7Rwuxa5FJ80rTR-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 234000 Counter(234000) 233937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 234500 Counter(234500) 234437
Saved chunk: 20230922T024143F397436-1ibekfWy3Tu6XrcTPGnMCc-6GkDoFjMCoCZZIYjHFxfwU-1024.npz
eval_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T024148F283682-01U39LOA7Rwuxa5FJ80rTR-1XGAov7RXd4xyfnUaJiKEQ-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 235000 Counter(235000) 234937
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 235500 Counter(235500) 235437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T024306F079538-1XGAov7RXd4xyfnUaJiKEQ-5r76ISZ9me4igknC33Q2nG-1024.npz
Saved chunk: 20230922T024302F790425-6GkDoFjMCoCZZIYjHFxfwU-1CvejmJhovPnA054Lv9jSS-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 236000 Counter(236000) 235937
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 236500 Counter(236500) 236437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T024423F788329-5r76ISZ9me4igknC33Q2nG-6pVJJpGQI9Cy0Sed8MFW0d-1024.npz
Saved chunk: 20230922T024425F439063-1CvejmJhovPnA054Lv9jSS-13j6NnA5ymxP5ILN8mmuwK-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 473786 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 835 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / train/action_mag 4.24 / train/action_max 4.05 / train/action_mean 0.04 / train/action_min -3.99 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -3.59 / train/adv_mag 0.49 / train/adv_max 0.39 / train/adv_mean 2.9e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.73 / 
train/dyn_loss_std 3.66 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.94 / train/extr_critic_max 671.94 / train/extr_critic_mean 616.6 / train/extr_critic_min 437.32 / train/extr_critic_std 64 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669 / train/extr_return_raw_max 669 / train/extr_return_raw_mean 616.65 / train/extr_return_raw_min 439.94 / train/extr_return_raw_std 64.11 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.16 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.24 / train/image_loss_std 0.36 / train/model_loss_mean 1.35 / train/model_loss_std 2.46 / 
train/model_opt_grad_norm 6.56 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.25 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.96 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.25 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.19 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.49 / train/policy_randomness_min 5.1e-5 / train/policy_randomness_std 0.42 / train/post_ent_mag 55.98 / train/post_ent_max 55.98 / train/post_ent_mean 40.16 / train/post_ent_min
26.01 / train/post_ent_std 4.85 / train/prior_ent_mag 68.78 / train/prior_ent_max 68.78 / train/prior_ent_mean 41.51 / train/prior_ent_min 31.57 / train/prior_ent_std 5.99 / train/rep_loss_mean 1.73 / train/rep_loss_std 3.66 / train/reward_avg 1.15 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.15 / train/reward_rate 0.58 / 
train_stats/mean_log_entropy 0.75 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 7.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.82 / report/dyn_loss_std 4.25 / report/image_loss_mean 0.22 / report/image_loss_std 0.33 / report/model_loss_mean 1.39 / report/model_loss_std 2.8 / report/post_ent_mag 52.95 / report/post_ent_max 52.95 / 
report/post_ent_mean 39.49 / report/post_ent_min 21.66 / report/post_ent_std 5.2 / report/prior_ent_mag 68.72 / report/prior_ent_max 68.72 / report/prior_ent_mean 41.01 / report/prior_ent_min 25.95 / report/prior_ent_std 6.14 / report/rep_loss_mean 1.82 / 
report/rep_loss_std 4.25 / report/reward_avg 1.24 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.24 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 5.9e-11 / eval/cont_loss_std 1e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.9e-11 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.32 / eval/dyn_loss_std 1.48 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.04 / eval/model_loss_std 0.99 / eval/post_ent_mag 52.37 / eval/post_ent_max 52.37 / eval/post_ent_mean 37.23 / 
eval/post_ent_min 31 / eval/post_ent_std 3.93 / eval/prior_ent_mag 68.72 / eval/prior_ent_max 68.72 / eval/prior_ent_mean 38.36 / eval/prior_ent_min 34.42 / eval/prior_ent_std 5.45 / eval/rep_loss_mean 1.32 / eval/rep_loss_std 1.48 / eval/reward_avg 1.85 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.03 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.85 / eval/reward_rate 0.92 / replay/size 
2.4e5 / replay/inserts 3892 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3892 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.53 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.14 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7399 / timer/agent.policy_total 16.19 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / 
timer/dataset_train_count 1946 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.8e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1946 / timer/agent.train_total 246.43 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.94

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 237000 Counter(237000) 236937
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 237500 Counter(237500) 237437
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T024544F620095-13j6NnA5ymxP5ILN8mmuwK-66mW5pp1vQRbJNswidobPB-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 238000 Counter(238000) 237937
Saved chunk: 20230922T024541F441931-6pVJJpGQI9Cy0Sed8MFW0d-2Iq4DKjl4KyIIOUNAFkFm0-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 238500 Counter(238500) 238437
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T024704F820813-66mW5pp1vQRbJNswidobPB-1ZfXlf6jk7YCc6ELjMkmWn-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 239000 Counter(239000) 238937
Saved chunk: 20230922T024735F602241-2Iq4DKjl4KyIIOUNAFkFm0-34sUamsq3aVQKkcI4EdhBl-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 239500 Counter(239500) 239437
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T024824F191634-1ZfXlf6jk7YCc6ELjMkmWn-6G1ncN4RIayhdx80RICcBZ-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 240000 Counter(240000) 239937
Saved chunk: 20230922T024853F393252-34sUamsq3aVQKkcI4EdhBl-6f5KRCPO2Uh9Z7tSLXznny-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 240500 Counter(240500) 240437
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T024943F390512-6G1ncN4RIayhdx80RICcBZ-2MX0sKSG5fNbDLBegFeqC8-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 481474 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / train/action_mag 3.97 / train/action_max 3.76 / train/action_mean 0.04 / train/action_min -3.77 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -2.43 / train/adv_mag 0.48 / train/adv_max 0.37 / train/adv_mean 2e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.4e-11 / train/cont_loss_std 3.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.52 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.4 / train/extr_critic_max 671.4 / train/extr_critic_mean 619.85 / train/extr_critic_min 443.63 / train/extr_critic_std 61.77 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.23 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.6 / train/extr_return_raw_max 668.6 / train/extr_return_raw_mean 619.88 / train/extr_return_raw_min 446.92 / train/extr_return_raw_std 61.84 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.2 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.33 / train/model_loss_mean 1.32 / train/model_loss_std 2.36 / 
train/model_opt_grad_norm 6.53 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.14 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.14 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 4.5e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 56.67 / train/post_ent_max 56.67 / train/post_ent_mean 40.07 / train/post_ent_min
26.67 / train/post_ent_std 4.7 / train/prior_ent_mag 68.58 / train/prior_ent_max 68.58 / train/prior_ent_mean 41.38 / train/prior_ent_min 31.87 / train/prior_ent_std 5.85 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.52 / train/reward_avg 1.19 / train/reward_loss_mean 
0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.19 / train/reward_rate 0.6 / 
train_stats/mean_log_entropy 0.54 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.39 / report/image_loss_mean 0.21 / report/image_loss_std 0.34 / report/model_loss_mean 1.29 / report/model_loss_std 2.25 / report/post_ent_mag 54.56 / report/post_ent_max 54.56 / 
report/post_ent_mean 40.07 / report/post_ent_min 28.44 / report/post_ent_std 4.53 / report/prior_ent_mag 68.76 / report/prior_ent_max 68.76 / report/prior_ent_mean 41.28 / report/prior_ent_min 34.36 / report/prior_ent_std 5.95 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.39 / report/reward_avg 1.25 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.3e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.25 / report/reward_rate 0.63 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 2.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.42 / eval/dyn_loss_std 2.49 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.31 / eval/model_loss_mean 1.1 / eval/model_loss_std 1.65 / eval/post_ent_mag 53.75 / eval/post_ent_max 53.75 / eval/post_ent_mean 
38.42 / eval/post_ent_min 28.21 / eval/post_ent_std 3.59 / eval/prior_ent_mag 68.76 / eval/prior_ent_max 68.76 / eval/prior_ent_mean 39.22 / eval/prior_ent_min 34.68 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 1.42 / eval/rep_loss_std 2.49 / eval/reward_avg 1.76 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.76 / eval/reward_rate 0.88 / 
replay/size 2.4e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3844 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.48 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7852 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 3.8e-4 / timer/agent.train_count 1922 / timer/agent.train_total 243.32 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 241000 Counter(241000) 240937
Saved chunk: 20230922T025010F939210-6f5KRCPO2Uh9Z7tSLXznny-4LfxcG1bNZVcJaEohym69W-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 241500 Counter(241500) 241437
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T025102F445773-2MX0sKSG5fNbDLBegFeqC8-1ydHYz4VKqPfPdQ3X0RLiH-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 242000 Counter(242000) 241937
Saved chunk: 20230922T025129F336283-4LfxcG1bNZVcJaEohym69W-0Cpcwh56IhyGE27FZyRdOA-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 242500 Counter(242500) 242437
eval_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T025222F728833-1ydHYz4VKqPfPdQ3X0RLiH-0SRP6MXf7YSnPMlcr8k6VE-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 243000 Counter(243000) 242937
Saved chunk: 20230922T025247F251443-0Cpcwh56IhyGE27FZyRdOA-68cYN6WnmGgiuSCnI0t33J-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 243500 Counter(243500) 243437
eval_Episode has 500 steps and return 835.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T025405F013973-68cYN6WnmGgiuSCnI0t33J-0000000000000000000000-874.npz
Saved chunk: 20230922T025342F023212-0SRP6MXf7YSnPMlcr8k6VE-0000000000000000000000-1012.npz
Saved chunk: 20230922T025342F023212-0SRP6MXf7YSnPMlcr8k6VE-1nujbhpE882kycsgIcLqrT-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 244000 Counter(244000) 243937
Saved chunk: 20230922T025405F013973-68cYN6WnmGgiuSCnI0t33J-6VXDmIOUTX6i7OWwxBcCbY-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 244500 Counter(244500) 244437
eval_Episode has 500 steps and return 846.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 489154 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 846 / eval_episode/reward_rate 0.84 / train/action_mag 4.16 / train/action_max 3.86 / train/action_mean 0.04 / train/action_min -4.07 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -5.17 / train/adv_mag 0.52 / train/adv_max 0.4 / train/adv_mean 4.3e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.13 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.72 / train/extr_critic_max 670.72 / train/extr_critic_mean 619.11 / train/extr_critic_min 446.82 / train/extr_critic_std 60.92 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.24 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.69 / train/extr_return_raw_max 667.69 / train/extr_return_raw_mean 619.19 / train/extr_return_raw_min 448.8 / train/extr_return_raw_std 61 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.18 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.23 / train/image_loss_std 0.34 / train/model_loss_mean 1.33 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 6.09 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7916.67 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.31 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.96 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.31 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.19 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 6.2e-5 / train/policy_randomness_std 0.42 / train/post_ent_mag 56 / train/post_ent_max 56 / train/post_ent_mean 40.34 / train/post_ent_min 26.75
/ train/post_ent_std 4.58 / train/prior_ent_mag 68.45 / train/prior_ent_max 68.45 / train/prior_ent_mean 41.66 / train/prior_ent_min 31.75 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.59 / train/reward_avg 1.17 / train/reward_loss_mean 0.07
/ train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.16 / train/reward_rate 0.59 / train_stats/mean_log_entropy 
0.77 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.77 / report/dyn_loss_std 3.9 / report/image_loss_mean 0.22 / report/image_loss_std 0.3 / report/model_loss_mean 1.34 / report/model_loss_std 2.56 / report/post_ent_mag 51.51 / report/post_ent_max 51.51 / report/post_ent_mean 40.36 / 
report/post_ent_min 27.4 / report/post_ent_std 4.38 / report/prior_ent_mag 68.09 / report/prior_ent_max 68.09 / report/prior_ent_mean 41.8 / report/prior_ent_min 29.45 / report/prior_ent_std 5.53 / report/rep_loss_mean 1.77 / report/rep_loss_std 3.9 / report/reward_avg 
1.01 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.01 / 
report/reward_rate 0.51 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.77 / 
eval/dyn_loss_std 7.35 / eval/image_loss_mean 0.68 / eval/image_loss_std 2.88 / eval/model_loss_mean 2.44 / eval/model_loss_std 7.09 / eval/post_ent_mag 52.7 / eval/post_ent_max 52.7 / eval/post_ent_mean 36.78 / eval/post_ent_min 17.12 / eval/post_ent_std 3.63 / 
eval/prior_ent_mag 68.09 / eval/prior_ent_max 68.09 / eval/prior_ent_mean 38.2 / eval/prior_ent_min 30.92 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 2.77 / eval/rep_loss_std 7.35 / eval/reward_avg 1.81 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.81 / eval/reward_rate 0.9 / replay/size 2.4e5 / replay/inserts 3840 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3840 / timer/env.step_total 19.29 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.31 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.38 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3
/ timer/agent.policy_max 0.15 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1920 / 
timer/agent.train_total 242.98 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T025501F432475-1nujbhpE882kycsgIcLqrT-0IQ5Nb7Jwe2IakSqXH2H88-1024.npz
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 245000 Counter(245000) 244937
Saved chunk: 20230922T025522F925957-6VXDmIOUTX6i7OWwxBcCbY-71kff3z1brgWSI3Cc9kU21-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 245500 Counter(245500) 245437
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T025621F487533-0IQ5Nb7Jwe2IakSqXH2H88-5HqGpoiQQrvJaMDU7PVD0z-1024.npz
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 246000 Counter(246000) 245937
Saved chunk: 20230922T025641F391044-71kff3z1brgWSI3Cc9kU21-6PtCbt0Wwnr85b3PxTqnzD-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 246500 Counter(246500) 246437
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T025740F936030-5HqGpoiQQrvJaMDU7PVD0z-3M2ra2aYRSaN8YlVxgVkUi-1024.npz
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 247000 Counter(247000) 246937
Saved chunk: 20230922T025759F209580-6PtCbt0Wwnr85b3PxTqnzD-6Fzo03ZiYxtyjbxyi1WCZb-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 247500 Counter(247500) 247437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T025900F109128-3M2ra2aYRSaN8YlVxgVkUi-4Ffsv8nMpYBhFmrjy4JXVn-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 248000 Counter(248000) 247937
Saved chunk: 20230922T025916F795271-6Fzo03ZiYxtyjbxyi1WCZb-5plB9ortuhTzHOBaOppQBF-1024.npz
eval_Episode has 500 steps and return 840.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 496946 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 840 / eval_episode/reward_rate 0.84 / train/action_mag 4.12 / train/action_max 3.94 / train/action_mean 0.04 / train/action_min -3.91 / train/action_std 0.97 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -4.36 / train/adv_mag 0.5 / train/adv_max 0.37 / train/adv_mean 3.7e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4.2e-11 / train/cont_loss_std 3.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.7 / 
train/dyn_loss_std 3.57 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.91 / train/extr_critic_max 670.91 / train/extr_critic_mean 620.81 / train/extr_critic_min 449.9 / train/extr_critic_std 60.98 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.08 / train/extr_return_raw_max 668.08 / train/extr_return_raw_mean 620.87 / train/extr_return_raw_min 450.37 / train/extr_return_raw_std 61.04
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.21 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.33 / train/model_loss_mean 1.32 / train/model_loss_std 2.39 / 
train/model_opt_grad_norm 6.4 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9487.18 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.26 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.26 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 5.9e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 56 / train/post_ent_max 56 / train/post_ent_mean 40.07 / train/post_ent_min 25.96 
/ train/post_ent_std 4.59 / train/prior_ent_mag 68.23 / train/prior_ent_max 68.23 / train/prior_ent_mean 41.39 / train/prior_ent_min 31.44 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.7 / train/rep_loss_std 3.57 / train/reward_avg 1.2 / train/reward_loss_mean 0.08 /
train/reward_loss_std 0.12 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.2 / train/reward_rate 0.6 / train_stats/mean_log_entropy 0.64
/ eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 8.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.06 / report/image_loss_mean 0.19 / report/image_loss_std 0.33 / report/model_loss_mean 1.25 / report/model_loss_std 2.09 / report/post_ent_mag 54.2 / report/post_ent_max 54.2 / report/post_ent_mean 40.34 / 
report/post_ent_min 21.71 / report/post_ent_std 4.74 / report/prior_ent_mag 68.24 / report/prior_ent_max 68.24 / report/prior_ent_mean 41.48 / report/prior_ent_min 34.69 / report/prior_ent_std 6.07 / report/rep_loss_mean 1.63 / report/rep_loss_std 3.06 / report/reward_avg
1.3 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.7e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.3 / 
report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 2.2e-11 / eval/cont_loss_std 5e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 3.38 / 
eval/dyn_loss_std 9.7 / eval/image_loss_mean 0.72 / eval/image_loss_std 2.7 / eval/model_loss_mean 2.84 / eval/model_loss_std 8.4 / eval/post_ent_mag 51.75 / eval/post_ent_max 51.75 / eval/post_ent_mean 39.1 / eval/post_ent_min 19.38 / eval/post_ent_std 4.15 / 
eval/prior_ent_mag 68.24 / eval/prior_ent_max 68.24 / eval/prior_ent_mean 40.79 / eval/prior_ent_min 34.72 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 3.38 / eval/rep_loss_std 9.7 / eval/reward_avg 1.68 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.04 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.68 / eval/reward_rate 0.84 / replay/size 2.5e5 / replay/inserts 3896 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3896 / timer/env.step_total 19.38 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.07 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.6e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7403 / timer/agent.policy_total 16.27 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1948 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1948 / timer/agent.train_total 246.28 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.97

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 248500 Counter(248500) 248437
eval_Episode has 500 steps and return 820.0.
Saved chunk: 20230922T030019F182356-4Ffsv8nMpYBhFmrjy4JXVn-2RPaCzhVxAlruJwJZ4XjuX-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 249000 Counter(249000) 248937
Saved chunk: 20230922T030034F349224-5plB9ortuhTzHOBaOppQBF-3T0iifOR284ocWcwLtynjd-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 249500 Counter(249500) 249437
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T030139F231927-2RPaCzhVxAlruJwJZ4XjuX-645GU7qyABzmXL2i5fC6Nn-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 250000 Counter(250000) 249937
Saved chunk: 20230922T030152F919423-3T0iifOR284ocWcwLtynjd-2dyLlIZP0R7KKFBNWXBlik-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 250500 Counter(250500) 250437
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T030258F658286-645GU7qyABzmXL2i5fC6Nn-6GcnMw2kzbnP4pIhd8tNQ8-1024.npz
Starting evaluation at step 251000 Counter(251000) 250937
Saved chunk: 20230922T030310F723053-2dyLlIZP0R7KKFBNWXBlik-5IAWUIPhloduKVniZ8ZoIf-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 251500 Counter(251500) 251437
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T030417F923095-6GcnMw2kzbnP4pIhd8tNQ8-1gHOqMCbyOBkoUahCNffkk-1024.npz
Starting evaluation at step 252000 Counter(252000) 251937
Saved chunk: 20230922T030428F423369-5IAWUIPhloduKVniZ8ZoIf-23OpR9iLafz3fxtUgCVaNi-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 784.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 504634 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 784 / episode/reward_rate 0.78 / eval_episode/length 500 / eval_episode/score 843 / eval_episode/reward_rate 0.84 / train/action_mag 3.92 / train/action_max 3.7 / train/action_mean 0.04 / train/action_min -3.76 / train/action_std 0.93 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.2e5 / train/actor_opt_loss -3.52 / train/adv_mag 0.53 / train/adv_max 0.42 / train/adv_mean 3.2e-4 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.63 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.52 / train/extr_critic_max 670.52 / train/extr_critic_mean 620.15 / train/extr_critic_min 445.86 / train/extr_critic_std 59.85 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.72 / 
train/extr_return_normed_min -0.26 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.84 / train/extr_return_raw_max 667.84 / train/extr_return_raw_mean 620.2 / train/extr_return_raw_min 454.18 / train/extr_return_raw_std 59.93 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.18 / train/extr_reward_min 0 / train/extr_reward_std 0.96 / train/image_loss_mean 0.23 / train/image_loss_std 0.36 / train/model_loss_mean 1.33 / train/model_loss_std 2.44 / 
train/model_opt_grad_norm 6.41 / train/model_opt_grad_steps 1.2e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7890.62 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.12 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.53 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.12 / train/policy_logprob_min -8.53 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 4.6e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 55.56 / train/post_ent_max 55.56 / train/post_ent_mean 40.16 / train/post_ent_min
26.43 / train/post_ent_std 4.66 / train/prior_ent_mag 68.21 / train/prior_ent_max 68.21 / train/prior_ent_mean 41.47 / train/prior_ent_min 31.73 / train/prior_ent_std 5.78 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.63 / train/reward_avg 1.17 / 
train/reward_loss_mean 0.07 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.17 / train/reward_rate 0.59 / 
train_stats/mean_log_entropy 0.48 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.1e-11 / report/cont_loss_std 3.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.76 / report/image_loss_mean 0.2 / report/image_loss_std 0.23 / report/model_loss_mean 1.27 / report/model_loss_std 2.42 / report/post_ent_mag 54.1 / report/post_ent_max 54.1 / 
report/post_ent_mean 40.5 / report/post_ent_min 29.45 / report/post_ent_std 4.61 / report/prior_ent_mag 67.93 / report/prior_ent_max 67.93 / report/prior_ent_mean 41.82 / report/prior_ent_min 34.72 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.76 / report/reward_avg 1.17 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.17 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.74 / eval/dyn_loss_std 4.2 / eval/image_loss_mean 0.25 / eval/image_loss_std 0.44 / eval/model_loss_mean 1.37 / eval/model_loss_std 2.81 / eval/post_ent_mag 53.7 / eval/post_ent_max 53.7 / eval/post_ent_mean 40.26 / 
eval/post_ent_min 27.58 / eval/post_ent_std 4.34 / eval/prior_ent_mag 67.93 / eval/prior_ent_max 67.93 / eval/prior_ent_mean 41.58 / eval/prior_ent_min 29.41 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 1.74 / eval/rep_loss_std 4.2 / eval/reward_avg 1.26 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.26 / eval/reward_rate 0.63 / 
replay/size 2.5e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3844 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.68 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7852 / timer/agent.policy_total 17.18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 3.9e-4 / timer/agent.train_count 1922 / timer/agent.train_total 243.29 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 252500 Counter(252500) 252437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T030536F997014-1gHOqMCbyOBkoUahCNffkk-1FwVRnEldpjje25zyBtRXr-1024.npz
Starting evaluation at step 253000 Counter(253000) 252937
Saved chunk: 20230922T030545F954594-23OpR9iLafz3fxtUgCVaNi-4r1sCNvKNDl1JHo4qpFv0i-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 253500 Counter(253500) 253437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T030657F200750-1FwVRnEldpjje25zyBtRXr-5tBNsP9D5wAA3v3k33hRF4-1024.npz
Starting evaluation at step 254000 Counter(254000) 253937
Saved chunk: 20230922T030704F664367-4r1sCNvKNDl1JHo4qpFv0i-5IUKDnM4rogzm6QYwiZjg7-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 254500 Counter(254500) 254437
eval_Episode has 500 steps and return 835.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T030816F623439-5tBNsP9D5wAA3v3k33hRF4-0AYE59gcg4UkhMXy6qBx1y-1024.npz
Starting evaluation at step 255000 Counter(255000) 254937
Saved chunk: 20230922T030822F469176-5IUKDnM4rogzm6QYwiZjg7-2j8x84h8N4jVPtYN3jI7AY-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 832.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T030935F764842-0AYE59gcg4UkhMXy6qBx1y-0000000000000000000000-324.npz
Saved chunk: 20230922T030940F062683-2j8x84h8N4jVPtYN3jI7AY-0000000000000000000000-109.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 255500 Counter(255500) 255437
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 256000 Counter(256000) 255937
Saved chunk: 20230922T030935F764842-0AYE59gcg4UkhMXy6qBx1y-6mUbmHwJzyjNUU0B3kC2qI-1024.npz
Saved chunk: 20230922T030940F062683-2j8x84h8N4jVPtYN3jI7AY-1EHwl8Acq7CfJXEOeUcdsG-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 831.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 512318 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 839 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 831 / episode/reward_rate 0.83 / train/action_mag 4.06 / train/action_max 3.79 / train/action_mean 0.04 / train/action_min -3.94 / train/action_std 0.95 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -3.49 / train/adv_mag 0.51 / train/adv_max 0.41 / train/adv_mean 3e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 4e-11 / train/cont_loss_std 3.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / 
train/dyn_loss_std 3.55 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.51 / train/extr_critic_max 670.51 / train/extr_critic_mean 622.25 / train/extr_critic_min 452.16 / train/extr_critic_std 58.06 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.25 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.63 / train/extr_return_raw_max 667.63 / train/extr_return_raw_mean 622.3 / train/extr_return_raw_min 457.9 / train/extr_return_raw_std 58.15 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.21 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.34 / train/model_loss_mean 1.31 / train/model_loss_std 2.38 / 
train/model_opt_grad_norm 6.24 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 9560.78 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7279.79 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.2 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.2 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.47 / train/policy_randomness_min 3.5e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 55.42 / train/post_ent_max 55.42 / train/post_ent_mean 39.92 / train/post_ent_min 
26.66 / train/post_ent_std 4.62 / train/prior_ent_mag 67.82 / train/prior_ent_max 67.82 / train/prior_ent_mean 41.22 / train/prior_ent_min 31.54 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.55 / train/reward_avg 1.2 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.2 / train/reward_rate 0.6 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.56 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 2.85 / report/image_loss_mean 0.19 / report/image_loss_std 0.28 / report/model_loss_mean 1.24 / report/model_loss_std 1.93 / report/post_ent_mag 62.14 / report/post_ent_max 62.14 / 
report/post_ent_mean 38.9 / report/post_ent_min 21.9 / report/post_ent_std 4.08 / report/prior_ent_mag 67.6 / report/prior_ent_max 67.6 / report/prior_ent_mean 40.16 / report/prior_ent_min 33.04 / report/prior_ent_std 5.37 / report/rep_loss_mean 1.61 / report/rep_loss_std
2.85 / report/reward_avg 1.48 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.4e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / 
report/reward_pred 1.48 / report/reward_rate 0.74 / eval/cont_avg 1 / eval/cont_loss_mean 3.6e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 3.24 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.12 / eval/post_ent_mag 51.64 / eval/post_ent_max 51.64 / eval/post_ent_mean 38.48 / eval/post_ent_min 30.05 / 
eval/post_ent_std 4.34 / eval/prior_ent_mag 67.6 / eval/prior_ent_max 67.6 / eval/prior_ent_mean 39.61 / eval/prior_ent_min 34.23 / eval/prior_ent_std 5.71 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 3.24 / eval/reward_avg 1.55 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.28 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.56 / eval/reward_rate 0.78 / replay/size 2.6e5 / replay/inserts 3842 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3842 / timer/env.step_total 19.11 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.96 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.4e-3 / timer/replay._sample_max 0.15 / timer/agent.save_count 1 / 
timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.22 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1921 / timer/agent.train_total 243.31 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / 
timer/dataset_eval_max 3.8e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 256500 Counter(256500) 256437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 257000 Counter(257000) 256937
Saved chunk: 20230922T031057F765715-1EHwl8Acq7CfJXEOeUcdsG-7IAcXsGr4EVh5akcGWoR9X-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T031055F010366-6mUbmHwJzyjNUU0B3kC2qI-014OHy7fjWe6XHlrCKl09v-1024.npz
Starting evaluation at step 257500 Counter(257500) 257437
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 258000 Counter(258000) 257937
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T031216F507702-7IAcXsGr4EVh5akcGWoR9X-4JMpX8qDVm4ost261Zw2Mh-1024.npz
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T031218F691436-014OHy7fjWe6XHlrCKl09v-3xll1z7aotWojPQ69yXYNV-1024.npz
Starting evaluation at step 258500 Counter(258500) 258437
eval_Episode has 500 steps and return 834.0.
train_Episode has 500 steps and return 823.0.
Starting evaluation at step 259000 Counter(259000) 258937
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T031334F279958-4JMpX8qDVm4ost261Zw2Mh-3MezDWHcenVJcip6LT4pBU-1024.npz
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T031338F007827-3xll1z7aotWojPQ69yXYNV-3q0J8FPPB5VrUle5Xw8hx7-1024.npz
Starting evaluation at step 259500 Counter(259500) 259437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 260000 Counter(260000) 259937
eval_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 520002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 4.14 / train/action_max 3.85 / train/action_mean 0.04 / train/action_min -4.01 / train/action_std 0.98 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -3.52 / train/adv_mag 0.52 / train/adv_max 0.43 / train/adv_mean 2.8e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.8e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.71 / 
train/dyn_loss_std 3.59 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.36 / train/extr_critic_max 670.36 / train/extr_critic_mean 621.77 / train/extr_critic_min 447.03 / train/extr_critic_std 59.11 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.73 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.75 / train/extr_return_raw_max 667.75 / train/extr_return_raw_mean 621.82 / train/extr_return_raw_min 451.91 / train/extr_return_raw_std 59.19
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.21 / train/extr_reward_min 0 / train/extr_reward_std 0.95 / train/image_loss_mean 0.22 / train/image_loss_std 0.34 / train/model_loss_mean 1.32 / train/model_loss_std 2.41 / 
train/model_opt_grad_norm 6.45 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7708.33 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.66 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.66 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 3.9e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 55.3 / train/post_ent_max 55.3 / train/post_ent_mean 39.74 / train/post_ent_min 
26.34 / train/post_ent_std 4.77 / train/prior_ent_mag 67.69 / train/prior_ent_max 67.69 / train/prior_ent_mean 41.05 / train/prior_ent_min 31.43 / train/prior_ent_std 5.87 / train/rep_loss_mean 1.71 / train/rep_loss_std 3.59 / train/reward_avg 1.19 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.13 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.19 / train/reward_rate 0.6 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.71 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.3 / report/image_loss_mean 0.22 / report/image_loss_std 0.3 / report/model_loss_mean 1.29 / report/model_loss_std 2.26 / report/post_ent_mag 51.66 / report/post_ent_max 51.66 / 
report/post_ent_mean 40.6 / report/post_ent_min 29.66 / report/post_ent_std 4.84 / report/prior_ent_mag 67.54 / report/prior_ent_max 67.54 / report/prior_ent_mean 41.8 / report/prior_ent_min 33.83 / report/prior_ent_std 5.97 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 3.3 / report/reward_avg 1.15 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.22 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.4e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 1.14 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.91 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.28 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.95 / eval/post_ent_mag 52.1 / eval/post_ent_max 52.1 / eval/post_ent_mean 39.35 / eval/post_ent_min 31.39 / 
eval/post_ent_std 3.64 / eval/prior_ent_mag 67.54 / eval/prior_ent_max 67.54 / eval/prior_ent_mean 40.33 / eval/prior_ent_min 34.16 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.91 / eval/reward_avg 1.65 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.65 / eval/reward_rate 0.83 / replay/size 2.6e5 / replay/inserts 3842 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.18 / timer/env.step_count 3842 / timer/env.step_total 19.09 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 7.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.06 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.07 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.48 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 838.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T031457F328226-3q0J8FPPB5VrUle5Xw8hx7-1QMBwD7JwZ1AxVJo7PVOF4-1024.npz
Starting evaluation at step 260500 Counter(260500) 260437
Saved chunk: 20230922T031452F055421-3MezDWHcenVJcip6LT4pBU-2foGBfLnjskdaZtzUm9rY8-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 261000 Counter(261000) 260937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T031617F379404-1QMBwD7JwZ1AxVJo7PVOF4-6J43JodYjrmD2quuORGVD1-1024.npz
Starting evaluation at step 261500 Counter(261500) 261437
Saved chunk: 20230922T031646F107505-2foGBfLnjskdaZtzUm9rY8-79I7oWo5hvYf2LbgEk0qAJ-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 262000 Counter(262000) 261937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T031736F878970-6J43JodYjrmD2quuORGVD1-38md5L4J9RXc98yYyM9M4f-1024.npz
Starting evaluation at step 262500 Counter(262500) 262437
Saved chunk: 20230922T031803F921370-79I7oWo5hvYf2LbgEk0qAJ-1uXejph7cjCeORqzXlme9v-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 263000 Counter(263000) 262937
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T031856F099929-38md5L4J9RXc98yYyM9M4f-1ZD3nFUqJB7e0NIpctHPgl-1024.npz
Starting evaluation at step 263500 Counter(263500) 263437
Saved chunk: 20230922T031921F616690-1uXejph7cjCeORqzXlme9v-57aJ25RdISROSh23VeZSIG-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 839.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 527786 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / train/action_mag 3.85 / train/action_max 3.59 / train/action_mean 0.02 / train/action_min -3.71 / train/action_std 0.89 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -1.16 / train/adv_mag 0.52 / train/adv_max 0.41 / train/adv_mean 1.3e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.69 / 
train/dyn_loss_std 3.53 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.15 / train/extr_critic_max 670.15 / train/extr_critic_mean 623.2 / train/extr_critic_min 453.37 / train/extr_critic_std 57.71 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.61 / train/extr_return_raw_max 667.61 / train/extr_return_raw_mean 623.22 / train/extr_return_raw_min 456.72 / train/extr_return_raw_std 57.79
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.23 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.22 / train/image_loss_std 0.33 / train/model_loss_mean 1.31 / train/model_loss_std 2.36 / 
train/model_opt_grad_norm 6.05 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8273.2 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean -0.05 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.82 / train/policy_logprob_mag 8.39 / train/policy_logprob_max 1.38 / train/policy_logprob_mean 0.05 / train/policy_logprob_min -8.39 / train/policy_logprob_std 1.08 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.36 / train/policy_randomness_min 4.3e-5 / train/policy_randomness_std 0.35 / train/post_ent_mag 54.91 / train/post_ent_max 54.91 / train/post_ent_mean 39.71 / train/post_ent_min
26.77 / train/post_ent_std 4.75 / train/prior_ent_mag 67.54 / train/prior_ent_max 67.54 / train/prior_ent_mean 41.01 / train/prior_ent_min 31.79 / train/prior_ent_std 5.87 / train/rep_loss_mean 1.69 / train/rep_loss_std 3.53 / train/reward_avg 1.21 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.21 / train/reward_rate 0.61 / 
train_stats/mean_log_entropy 0.35 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.89 / report/image_loss_mean 0.2 / report/image_loss_std 0.46 / report/model_loss_mean 1.3 / report/model_loss_std 2.78 / report/post_ent_mag 54.3 / report/post_ent_max 54.3 / 
report/post_ent_mean 38.78 / report/post_ent_min 21.05 / report/post_ent_std 3.97 / report/prior_ent_mag 67.36 / report/prior_ent_max 67.36 / report/prior_ent_mean 39.95 / report/prior_ent_min 34.34 / report/prior_ent_std 5.41 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.89 / report/reward_avg 1.43 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.31 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 1.43 / report/reward_rate 0.72 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.65 / eval/dyn_loss_std 3.3 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.37 / eval/model_loss_mean 1.28 / eval/model_loss_std 2.27 / eval/post_ent_mag 50.2 / eval/post_ent_max 50.2 / eval/post_ent_mean 38.38 / eval/post_ent_min 25.19 / 
eval/post_ent_std 4.01 / eval/prior_ent_mag 67.36 / eval/prior_ent_max 67.36 / eval/prior_ent_mean 39.55 / eval/prior_ent_min 28.62 / eval/prior_ent_std 5.35 / eval/rep_loss_mean 1.65 / eval/rep_loss_std 3.3 / eval/reward_avg 1.62 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.2e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size 2.6e5 / replay/inserts 3892 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3892 / timer/env.step_total 19.34 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.19 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7399 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 
1946 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1946 / timer/agent.train_total 246.33 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.94

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 264000 Counter(264000) 263937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 833.0.
Saved chunk: 20230922T032015F229237-1ZD3nFUqJB7e0NIpctHPgl-0eUV4yog9ltd2HDbQIPAjg-1024.npz
Starting evaluation at step 264500 Counter(264500) 264437
Saved chunk: 20230922T032039F146358-57aJ25RdISROSh23VeZSIG-6IJQAlrRVzzqJWYqAkytMM-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 265000 Counter(265000) 264937
eval_Episode has 500 steps and return 834.0.
train_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T032135F390105-0eUV4yog9ltd2HDbQIPAjg-68ame6ID9fAmKh2cVbE7dj-1024.npz
Starting evaluation at step 265500 Counter(265500) 265437
Saved chunk: 20230922T032157F930155-6IJQAlrRVzzqJWYqAkytMM-5zgi7bqbJr55WEbr7vyxc2-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 266000 Counter(266000) 265937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T032254F874490-68ame6ID9fAmKh2cVbE7dj-5xsilKiLcaGGLM9QOkVAh4-1024.npz
Starting evaluation at step 266500 Counter(266500) 266437
Saved chunk: 20230922T032315F766035-5zgi7bqbJr55WEbr7vyxc2-7wTmp5OgR4Cn0rriZIYpbD-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 843.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T032414F070827-5xsilKiLcaGGLM9QOkVAh4-0000000000000000000000-660.npz
Saved chunk: 20230922T032433F338361-7wTmp5OgR4Cn0rriZIYpbD-0000000000000000000000-368.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 267000 Counter(267000) 266937
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T032414F070827-5xsilKiLcaGGLM9QOkVAh4-1euctTEPz3GBXQNAHAYZV6-1024.npz
Starting evaluation at step 267500 Counter(267500) 267437
Saved chunk: 20230922T032433F338361-7wTmp5OgR4Cn0rriZIYpbD-37RPkLBeHpl5cNNJY9skm6-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 836.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 535470 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 841 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 836 / episode/reward_rate 0.83 / train/action_mag 3.9 / train/action_max 3.56 / train/action_mean 0.02 / train/action_min -3.84 / train/action_std 0.92 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -2 / train/adv_mag 0.53 / train/adv_max 0.41 / train/adv_mean 1.7e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.49 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.78 / train/extr_critic_max 669.78 / train/extr_critic_mean 624.17 / train/extr_critic_min 452.12 / train/extr_critic_std 57.3 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.29 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.08 / train/extr_return_raw_max 667.08 / train/extr_return_raw_mean 624.2 / train/extr_return_raw_min 455.27 / train/extr_return_raw_std 57.42 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.25 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.3 / train/model_loss_std 2.34 / 
train/model_opt_grad_norm 6.4 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 8521.45 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6536.46 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.13 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.47 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.13 / train/policy_logprob_min -8.47 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 2.6e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.26 / train/post_ent_max 55.26 / train/post_ent_mean 39.61 / train/post_ent_min
26.42 / train/post_ent_std 4.7 / train/prior_ent_mag 67.48 / train/prior_ent_max 67.48 / train/prior_ent_mean 40.89 / train/prior_ent_min 31.82 / train/prior_ent_std 5.83 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.49 / train/reward_avg 1.24 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.51 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.75 / report/dyn_loss_std 3.72 / report/image_loss_mean 0.21 / report/image_loss_std 0.44 / report/model_loss_mean 1.35 / report/model_loss_std 2.59 / report/post_ent_mag 52.43 / report/post_ent_max 52.43 / 
report/post_ent_mean 39.54 / report/post_ent_min 27.72 / report/post_ent_std 4.3 / report/prior_ent_mag 67.77 / report/prior_ent_max 67.77 / report/prior_ent_mean 40.85 / report/prior_ent_min 34.78 / report/prior_ent_std 5.74 / report/rep_loss_mean 1.75 / 
report/rep_loss_std 3.72 / report/reward_avg 1.39 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.39 / report/reward_rate 0.7 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.73 / eval/dyn_loss_std 3.73 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.4 / eval/model_loss_mean 1.35 / eval/model_loss_std 2.53 / eval/post_ent_mag 52.4 / eval/post_ent_max 52.4 / eval/post_ent_mean 38.76 / 
eval/post_ent_min 21.05 / eval/post_ent_std 4.3 / eval/prior_ent_mag 67.77 / eval/prior_ent_max 67.77 / eval/prior_ent_mean 40.05 / eval/prior_ent_min 29.83 / eval/prior_ent_std 5.72 / eval/rep_loss_mean 1.73 / eval/rep_loss_std 3.73 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / replay/size 
2.7e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3842 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.81 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.3e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.26 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.4e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.4e-5 / 
timer/dataset_eval_min 4.4e-5 / timer/dataset_eval_max 4.4e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 268000 Counter(268000) 267937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T032533F302528-1euctTEPz3GBXQNAHAYZV6-04dmEd94E3m2WWfxeUjr7W-1024.npz
Starting evaluation at step 268500 Counter(268500) 268437
Saved chunk: 20230922T032550F965281-37RPkLBeHpl5cNNJY9skm6-379jJHQFNWdxqdPK6WXHOJ-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 269000 Counter(269000) 268937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 833.0.
Saved chunk: 20230922T032653F440998-04dmEd94E3m2WWfxeUjr7W-2Kkgxf05n07tRyeDqupAU2-1024.npz
Starting evaluation at step 269500 Counter(269500) 269437
Saved chunk: 20230922T032709F647895-379jJHQFNWdxqdPK6WXHOJ-7xnr4oO85V25lSGVQrmozY-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 270000 Counter(270000) 269937
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T032812F701857-2Kkgxf05n07tRyeDqupAU2-6WASuYsW0VD2oqtCtePeCY-1024.npz
Starting evaluation at step 270500 Counter(270500) 270437
Saved chunk: 20230922T032827F324630-7xnr4oO85V25lSGVQrmozY-6SJXUJJCErekjLxzUGkmep-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 271000 Counter(271000) 270937
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T032931F965517-6WASuYsW0VD2oqtCtePeCY-4n0t0T4JxCwk08m0re9plD-1024.npz
Starting evaluation at step 271500 Counter(271500) 271437
Saved chunk: 20230922T032945F043622-6SJXUJJCErekjLxzUGkmep-01oj8PMyN2vzq2dFg4RRTc-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 843.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 543158 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / train/action_mag 4.04 / train/action_max 3.78 / train/action_mean 0.04 / train/action_min -3.93 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.3e5 / train/actor_opt_loss -3.24 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 2.5e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.47 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.86 / train/extr_critic_max 669.86 / train/extr_critic_mean 625.01 / train/extr_critic_min 458.11 / train/extr_critic_std 56.39 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.27 / train/extr_return_raw_max 667.27 / train/extr_return_raw_mean 625.06 / train/extr_return_raw_min 460.27 / train/extr_return_raw_std 56.48
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.24 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.3 / train/model_loss_std 2.33 / 
train/model_opt_grad_norm 6.19 / train/model_opt_grad_steps 1.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9300.52 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.26 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.66 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.26 / train/policy_logprob_min -8.66 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 1.9e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.96 / train/post_ent_max 54.96 / train/post_ent_mean 39.41 / train/post_ent_min 
26.61 / train/post_ent_std 4.83 / train/prior_ent_mag 67.39 / train/prior_ent_max 67.39 / train/prior_ent_mean 40.7 / train/prior_ent_min 31.5 / train/prior_ent_std 5.95 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.47 / train/reward_avg 1.23 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.23 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.63 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 2.95 / report/image_loss_mean 0.2 / report/image_loss_std 0.3 / report/model_loss_mean 1.24 / report/model_loss_std 1.99 / report/post_ent_mag 53.37 / report/post_ent_max 53.37 / 
report/post_ent_mean 38.78 / report/post_ent_min 25.2 / report/post_ent_std 5.11 / report/prior_ent_mag 67.27 / report/prior_ent_max 67.27 / report/prior_ent_mean 39.98 / report/prior_ent_min 31.41 / report/prior_ent_std 6.29 / report/rep_loss_mean 1.59 / 
report/rep_loss_std 2.95 / report/reward_avg 1.32 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.32 / report/reward_rate 0.66 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.63 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.75 / eval/post_ent_mag 52.92 / eval/post_ent_max 52.92 / eval/post_ent_mean 
39.39 / eval/post_ent_min 31.28 / eval/post_ent_std 4.04 / eval/prior_ent_mag 67.27 / eval/prior_ent_max 67.27 / eval/prior_ent_mean 40.41 / eval/prior_ent_min 34.3 / eval/prior_ent_std 5.34 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.63 / eval/reward_avg 1.55 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8.9e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.55 / eval/reward_rate 0.78 / replay/size
2.7e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3844 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 7.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.33 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.16 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7852 / timer/agent.policy_total 17.05 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / 
timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1922 / timer/agent.train_total 243.42 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.26 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 272000 Counter(272000) 271937
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T033051F078311-4n0t0T4JxCwk08m0re9plD-6FUbiIogr0R55lT5CUNgbE-1024.npz
Starting evaluation at step 272500 Counter(272500) 272437
Saved chunk: 20230922T033102F586653-01oj8PMyN2vzq2dFg4RRTc-3hzkBV1uLnsoVNOzjoJviu-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 273000 Counter(273000) 272937
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T033211F318216-6FUbiIogr0R55lT5CUNgbE-0rEKl06UqeqvNW4cI7wctP-1024.npz
Starting evaluation at step 273500 Counter(273500) 273437
Saved chunk: 20230922T033221F299310-3hzkBV1uLnsoVNOzjoJviu-6ibWQxy639LpD6IBJVmmmy-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 274000 Counter(274000) 273937
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T033330F561952-0rEKl06UqeqvNW4cI7wctP-2BIoWSAhQKFyDoyjD2Ys06-1024.npz
Starting evaluation at step 274500 Counter(274500) 274437
Saved chunk: 20230922T033338F995567-6ibWQxy639LpD6IBJVmmmy-2GiWKidcBgM8db3OQlD5OU-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 275000 Counter(275000) 274937
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T033449F622932-2BIoWSAhQKFyDoyjD2Ys06-12eO1lCZxCs9dYmBmmLvvl-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 550946 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 833 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 4 / train/action_max 3.77 / train/action_mean 0.03 / train/action_min -3.86 / train/action_std 0.94 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -2.18 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 1.7e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.68 / 
train/dyn_loss_std 3.46 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.97 / train/extr_critic_max 669.97 / train/extr_critic_mean 624.92 / train/extr_critic_min 453.14 / train/extr_critic_std 56.86 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.19 / train/extr_return_raw_max 667.19 / train/extr_return_raw_mean 624.95 / train/extr_return_raw_min 456.18 / train/extr_return_raw_std 56.95
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.26 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.3 / train/model_loss_std 2.32 / 
train/model_opt_grad_norm 6.3 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 9660.17 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.19 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.54 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.19 / train/policy_logprob_min -8.54 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.46 / train/policy_randomness_min 1.9e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.73 / train/post_ent_max 54.73 / train/post_ent_mean 39.31 / train/post_ent_min
26.53 / train/post_ent_std 4.95 / train/prior_ent_mag 67.32 / train/prior_ent_max 67.32 / train/prior_ent_mean 40.59 / train/prior_ent_min 31.42 / train/prior_ent_std 6.06 / train/rep_loss_mean 1.68 / train/rep_loss_std 3.46 / train/reward_avg 1.25 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.25 / train/reward_rate 0.63 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.65 / report/cont_avg 1 / report/cont_loss_mean 2e-10 / report/cont_loss_std 5.4e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-10 / report/cont_pred 1
/ report/cont_rate 1 / report/dyn_loss_mean 2.04 / report/dyn_loss_std 4.63 / report/image_loss_mean 0.27 / report/image_loss_std 0.35 / report/model_loss_mean 1.57 / report/model_loss_std 3.03 / report/post_ent_mag 51.47 / report/post_ent_max 51.47 / report/post_ent_mean
39.88 / report/post_ent_min 26.28 / report/post_ent_std 5.07 / report/prior_ent_mag 67.22 / report/prior_ent_max 67.22 / report/prior_ent_mean 41.45 / report/prior_ent_min 29.45 / report/prior_ent_std 6.11 / report/rep_loss_mean 2.04 / report/rep_loss_std 4.63 / 
report/reward_avg 1.08 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.19 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / report/reward_pos_loss 0.14 / 
report/reward_pred 1.08 / report/reward_rate 0.54 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 3.18 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.07 / eval/post_ent_mag 49.13 / eval/post_ent_max 49.13 / eval/post_ent_mean 38.22 / eval/post_ent_min 31.48 / 
eval/post_ent_std 4.19 / eval/prior_ent_mag 67.22 / eval/prior_ent_max 67.22 / eval/prior_ent_mean 39.23 / eval/prior_ent_min 33.92 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 3.18 / eval/reward_avg 1.58 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.58 / eval/reward_rate 0.79 / replay/size 2.8e5 / replay/inserts 3894 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3894 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.42 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7401 / timer/agent.policy_total 16.19 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 
1947 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1947 / timer/agent.train_total 246.42 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 2.7e-5 / timer/dataset_eval_frac 9.1e-8 / timer/dataset_eval_avg 2.7e-5 / timer/dataset_eval_min 2.7e-5 / timer/dataset_eval_max 2.7e-5 / fps 25.96

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 275500 Counter(275500) 275437
Saved chunk: 20230922T033456F479158-2GiWKidcBgM8db3OQlD5OU-4GFqd5nDwaCMGb1HGJOuze-1024.npz
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 276000 Counter(276000) 275937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T033608F704981-12eO1lCZxCs9dYmBmmLvvl-3ZtU9rvrc2rpV6U4PcEQQT-1024.npz
Starting evaluation at step 276500 Counter(276500) 276437
Saved chunk: 20230922T033616F163696-4GFqd5nDwaCMGb1HGJOuze-2lcX6upsVRSlTaDXxk8qYN-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 277000 Counter(277000) 276937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 277500 Counter(277500) 277437
Saved chunk: 20230922T033734F259778-2lcX6upsVRSlTaDXxk8qYN-1H33Df7llRgDXkhI3DqYpW-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T033730F484633-3ZtU9rvrc2rpV6U4PcEQQT-5BBs2rxLlr5QMrwo4b5hAg-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 278000 Counter(278000) 277937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 830.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 278500 Counter(278500) 278437
Saved chunk: 20230922T033853F146135-5BBs2rxLlr5QMrwo4b5hAg-0000000000000000000000-996.npz
Saved chunk: 20230922T033851F977077-1H33Df7llRgDXkhI3DqYpW-0000000000000000000000-627.npz
Saved chunk: 20230922T033851F977077-1H33Df7llRgDXkhI3DqYpW-1aAmi3BSdvHJ1Pa3pRyc0u-1024.npz
eval_Episode has 500 steps and return 846.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T033853F146135-5BBs2rxLlr5QMrwo4b5hAg-54YdykJ50gbpJ1DdpmxviH-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 279000 Counter(279000) 278937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 558578 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 3.97 / train/action_max 3.73 / train/action_mean 0.03 / train/action_min -3.82 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -3 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 2.6e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.86 / train/extr_critic_max 669.86 / train/extr_critic_mean 623.34 / train/extr_critic_min 452.17 / train/extr_critic_std 57.96 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.2 / train/extr_return_raw_max 667.2 / train/extr_return_raw_mean 623.38 / train/extr_return_raw_min 452.89 / train/extr_return_raw_std 58.02 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.24 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.32 / train/model_loss_mean 1.29 / train/model_loss_std 2.3 / 
train/model_opt_grad_norm 6.22 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.62 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.16 / train/policy_logprob_min -8.62 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 1.7e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.7 / train/post_ent_max 55.7 / train/post_ent_mean 39.3 / train/post_ent_min 
26.46 / train/post_ent_std 4.98 / train/prior_ent_mag 67.24 / train/prior_ent_max 67.24 / train/prior_ent_mean 40.57 / train/prior_ent_min 31.06 / train/prior_ent_std 6.08 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.43 / train/reward_avg 1.23 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.23 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.68 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 7.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.63 / report/dyn_loss_std 3.8 / report/image_loss_mean 0.18 / report/image_loss_std 0.25 / report/model_loss_mean 1.24 / report/model_loss_std 2.47 / report/post_ent_mag 54.02 / report/post_ent_max 54.02 / 
report/post_ent_mean 38.66 / report/post_ent_min 28.28 / report/post_ent_std 4.38 / report/prior_ent_mag 67.23 / report/prior_ent_max 67.23 / report/prior_ent_mean 39.83 / report/prior_ent_min 30.6 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.63 / 
report/rep_loss_std 3.8 / report/reward_avg 1.47 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.3e-5 / report/reward_pos_acc 1 / report/reward_pos_loss
0.11 / report/reward_pred 1.47 / report/reward_rate 0.73 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.32 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.1 / eval/model_loss_std 1.51 / eval/post_ent_mag 54.07 / eval/post_ent_max 54.07 / eval/post_ent_mean 38.14 / eval/post_ent_min 30.46 / 
eval/post_ent_std 4.68 / eval/prior_ent_mag 67.23 / eval/prior_ent_max 67.23 / eval/prior_ent_mean 39.15 / eval/prior_ent_min 33.82 / eval/prior_ent_std 5.97 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.32 / eval/reward_avg 1.53 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / replay/size 2.8e5 / replay/inserts 3816 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3816 / timer/env.step_total 18.93 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.88 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.16 / timer/agent.save_count 1 / 
timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7824 / timer/agent.policy_total 17.21 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / 
timer/agent.train_count 1908 / timer/agent.train_total 241.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.44

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 279500 Counter(279500) 279437
Saved chunk: 20230922T034009F958790-1aAmi3BSdvHJ1Pa3pRyc0u-7c1jqbIcxeDdB1WxyhCAZx-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 835.0.
Saved chunk: 20230922T034012F670928-54YdykJ50gbpJ1DdpmxviH-41DhN3zwpfDLkBnpNYscuv-1024.npz
Starting evaluation at step 280000 Counter(280000) 279937
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 280500 Counter(280500) 280437
Saved chunk: 20230922T034128F695560-7c1jqbIcxeDdB1WxyhCAZx-01BpaOaP0i7DFQEB8Wb85g-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 826.0.
Saved chunk: 20230922T034132F998285-41DhN3zwpfDLkBnpNYscuv-3HJrdUTNSqNuZlxIgMMdGJ-1024.npz
Starting evaluation at step 281000 Counter(281000) 280937
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 281500 Counter(281500) 281437
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T034246F594306-01BpaOaP0i7DFQEB8Wb85g-5RWX1i7ZAJpX7PyTrhLEQL-1024.npz
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T034252F409502-3HJrdUTNSqNuZlxIgMMdGJ-5YO2MtkxT1BLmFxESFC8Ct-1024.npz
Starting evaluation at step 282000 Counter(282000) 281937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 282500 Counter(282500) 282437
eval_Episode has 500 steps and return 838.0.
Saved chunk: 20230922T034404F344745-5RWX1i7ZAJpX7PyTrhLEQL-4yx1CNJqDIT7jth4sTWZJW-1024.npz
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T034411F752902-5YO2MtkxT1BLmFxESFC8Ct-1fMyZYrvWJtl40MIrVKxll-1024.npz
Starting evaluation at step 283000 Counter(283000) 282937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 566262 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 846 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 4.1 / train/action_max 3.81 / train/action_mean 0.03 / train/action_min -3.97 / train/action_std 0.96 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -3.42 / train/adv_mag 0.53 / train/adv_max 0.41 / train/adv_mean 2.7e-4 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.95 / train/extr_critic_max 669.95 / train/extr_critic_mean 627.2 / train/extr_critic_min 459.31 / train/extr_critic_std 55.39 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.28 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.16 / train/extr_return_raw_max 667.16 / train/extr_return_raw_mean 627.24 / train/extr_return_raw_min 462.86 / train/extr_return_raw_std 55.48
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.21 / train/image_loss_std 0.32 / train/model_loss_mean 1.29 / train/model_loss_std 2.29 / 
train/model_opt_grad_norm 6.18 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.28 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.28 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.97 / train/post_ent_max 54.97 / train/post_ent_mean 39.29 / train/post_ent_min 
26.91 / train/post_ent_std 4.85 / train/prior_ent_mag 67.15 / train/prior_ent_max 67.15 / train/prior_ent_mean 40.55 / train/prior_ent_min 31.75 / train/prior_ent_std 5.97 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.43 / train/reward_avg 1.27 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.63 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / report/dyn_loss_std 3.86 / report/image_loss_mean 0.23 / report/image_loss_std 0.36 / report/model_loss_mean 1.37 / report/model_loss_std 2.58 / report/post_ent_mag 50.83 / report/post_ent_max 50.83 / 
report/post_ent_mean 38.82 / report/post_ent_min 25.97 / report/post_ent_std 4.72 / report/prior_ent_mag 66.68 / report/prior_ent_max 66.68 / report/prior_ent_mean 40.17 / report/prior_ent_min 31.5 / report/prior_ent_std 5.81 / report/rep_loss_mean 1.77 / 
report/rep_loss_std 3.86 / report/reward_avg 1.28 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 1.5e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.35 / eval/dyn_loss_std 2.05 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.05 / eval/model_loss_std 1.38 / eval/post_ent_mag 50.78 / eval/post_ent_max 50.78 / eval/post_ent_mean 
36.38 / eval/post_ent_min 31.97 / eval/post_ent_std 3.13 / eval/prior_ent_mag 66.68 / eval/prior_ent_max 66.68 / eval/prior_ent_mean 37.31 / eval/prior_ent_min 33.81 / eval/prior_ent_std 4.74 / eval/rep_loss_mean 1.35 / eval/rep_loss_std 2.05 / eval/reward_avg 1.91 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.03 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.91 / eval/reward_rate 0.95 / replay/size
2.8e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3842 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.61 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.8e-4 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.14 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.46 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 283500 Counter(283500) 283437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T034530F910445-1fMyZYrvWJtl40MIrVKxll-6OFMx14iIoETcgtvnst762-1024.npz
Starting evaluation at step 284000 Counter(284000) 283937
Saved chunk: 20230922T034521F994024-4yx1CNJqDIT7jth4sTWZJW-6RqkuADNMTLWvDlmKkogJ2-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 284500 Counter(284500) 284437
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T034651F103516-6OFMx14iIoETcgtvnst762-64nPlheBaCWhfMVy6oOlR4-1024.npz
Starting evaluation at step 285000 Counter(285000) 284937
Saved chunk: 20230922T034716F117052-6RqkuADNMTLWvDlmKkogJ2-5hBwgO19jcf0IcsxYsTC1I-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 285500 Counter(285500) 285437
eval_Episode has 500 steps and return 823.0.
train_Episode has 500 steps and return 777.0.
Saved chunk: 20230922T034810F421997-64nPlheBaCWhfMVy6oOlR4-2GVamp5JQGrACRIxNBAtHD-1024.npz
Starting evaluation at step 286000 Counter(286000) 285937
Saved chunk: 20230922T034833F853468-5hBwgO19jcf0IcsxYsTC1I-5ANmHabKZlD6LlBPu5lUKG-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 286500 Counter(286500) 286437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T034929F695663-2GVamp5JQGrACRIxNBAtHD-700rcPpIb4tlHYRxjw6s8o-1024.npz
Starting evaluation at step 287000 Counter(287000) 286937
Saved chunk: 20230922T034951F568410-5ANmHabKZlD6LlBPu5lUKG-5Kdebp8hsFwGDIfzMYvS3U-1024.npz
eval_Episode has 500 steps and return 848.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 574002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 848 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / train/action_mag 3.91 / train/action_max 3.68 / train/action_mean 0.02 / train/action_min -3.79 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.1 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -2.74 / train/adv_mag 0.55 / train/adv_max 0.43 / train/adv_mean 2.4e-4 / train/adv_min -0.48 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.67 / 
train/dyn_loss_std 3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.84 / train/extr_critic_max 669.84 / train/extr_critic_mean 626.11 / train/extr_critic_min 455.32 / train/extr_critic_std 56.13 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.5 / train/extr_return_raw_max 667.5 / train/extr_return_raw_mean 626.14 / train/extr_return_raw_min 459.44 / train/extr_return_raw_std 56.22 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.27 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.21 / train/image_loss_std 0.33 / train/model_loss_mean 1.29 / train/model_loss_std 2.3 / 
train/model_opt_grad_norm 6.01 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 9546.91 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.13 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.62 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.13 / train/policy_logprob_min -8.62 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.44 / train/policy_randomness_min 1.8e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 54.7 / train/post_ent_max 54.7 / train/post_ent_mean 39.31 / train/post_ent_min 
26.57 / train/post_ent_std 4.93 / train/prior_ent_mag 67.02 / train/prior_ent_max 67.02 / train/prior_ent_mean 40.58 / train/prior_ent_min 31.37 / train/prior_ent_std 6.03 / train/rep_loss_mean 1.67 / train/rep_loss_std 3.43 / train/reward_avg 1.26 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.26 / train/reward_rate 0.63 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.61 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / report/dyn_loss_std 3 / report/image_loss_mean 0.17 / report/image_loss_std 0.17 / report/model_loss_mean 1.18 / report/model_loss_std 1.93 / report/post_ent_mag 53 / report/post_ent_max 53 / report/post_ent_mean 38.37 
/ report/post_ent_min 27.64 / report/post_ent_std 4.95 / report/prior_ent_mag 66.83 / report/prior_ent_max 66.83 / report/prior_ent_mean 39.59 / report/prior_ent_min 30.5 / report/prior_ent_std 6.17 / report/rep_loss_mean 1.56 / report/rep_loss_std 3 / report/reward_avg 
1.32 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.32 / 
report/reward_rate 0.66 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / 
eval/dyn_loss_std 3.19 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.17 / eval/model_loss_std 2.05 / eval/post_ent_mag 50.86 / eval/post_ent_max 50.86 / eval/post_ent_mean 39.06 / eval/post_ent_min 28.04 / eval/post_ent_std 3.86 / 
eval/prior_ent_mag 66.83 / eval/prior_ent_max 66.83 / eval/prior_ent_mean 40.18 / eval/prior_ent_min 30 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 3.19 / eval/reward_avg 1.57 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.11 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 8.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.57 / eval/reward_rate 0.79 / replay/size 2.9e5 / replay/inserts 3870 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302 / timer/env.step_count 3870 / timer/env.step_total 19.22 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.9e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.82 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7878 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 1935 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1935 / timer/agent.train_total 245.19 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 287500 Counter(287500) 287437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T035048F872558-700rcPpIb4tlHYRxjw6s8o-3OyxUURaaVkoox1XkyZs2T-1024.npz
Starting evaluation at step 288000 Counter(288000) 287937
Saved chunk: 20230922T035109F115170-5Kdebp8hsFwGDIfzMYvS3U-7g0eQbzZ3vDu0k24veL5FN-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 288500 Counter(288500) 288437
eval_Episode has 500 steps and return 761.0.
train_Episode has 500 steps and return 824.0.
Saved chunk: 20230922T035209F137603-3OyxUURaaVkoox1XkyZs2T-2MNlH3Ibia8MDccqcEQZGI-1024.npz
Starting evaluation at step 289000 Counter(289000) 288937
Saved chunk: 20230922T035227F958198-7g0eQbzZ3vDu0k24veL5FN-3Ny2KmPJc4WwKnP8R8K3iZ-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 289500 Counter(289500) 289437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T035328F539961-2MNlH3Ibia8MDccqcEQZGI-3re2PoKsF1tyyfroJ4k96t-1024.npz
Starting evaluation at step 290000 Counter(290000) 289937
Saved chunk: 20230922T035345F730361-3Ny2KmPJc4WwKnP8R8K3iZ-7wHydr4IRvEMqxpMrxwSpa-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 840.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T035503F454635-7wHydr4IRvEMqxpMrxwSpa-0000000000000000000000-363.npz
Saved chunk: 20230922T035447F813900-3re2PoKsF1tyyfroJ4k96t-0000000000000000000000-308.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 290500 Counter(290500) 290437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T035447F813900-3re2PoKsF1tyyfroJ4k96t-2iGV528oTkaCPoesAoIktP-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 581770 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 834 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / train/action_mag 3.92 / train/action_max 3.69 / train/action_mean 0.03 / train/action_min -3.78 / train/action_std 0.94 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.4e5 / train/actor_opt_loss -1.35 / train/adv_mag 0.53 / train/adv_max 0.41 / train/adv_mean 9.5e-5 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 2.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.4e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 670.28 / train/extr_critic_max 670.28 / train/extr_critic_mean 625.87 / train/extr_critic_min 457.41 / train/extr_critic_std 56.26 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.74 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.74 / train/extr_return_raw_max 667.74 / train/extr_return_raw_mean 625.89 / train/extr_return_raw_min 459.36 / train/extr_return_raw_std 56.38
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.25 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.31 / train/model_loss_mean 1.28 / train/model_loss_std 2.27 / 
train/model_opt_grad_norm 6.07 / train/model_opt_grad_steps 1.4e5 / train/model_opt_loss 9504.77 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.14 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.36 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.14 / train/policy_logprob_min -8.36 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 2e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 55.16 / train/post_ent_max 55.16 / train/post_ent_mean 39.3 / train/post_ent_min 
26.41 / train/post_ent_std 4.91 / train/prior_ent_mag 66.87 / train/prior_ent_max 66.87 / train/prior_ent_mean 40.57 / train/prior_ent_min 31.29 / train/prior_ent_std 6 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.4 / train/reward_avg 1.24 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.24 / train/reward_rate 0.62 / 
train_stats/mean_log_entropy 0.59 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-11 / report/cont_loss_std 7.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.45 / report/dyn_loss_std 2.67 / report/image_loss_mean 0.15 / report/image_loss_std 0.17 / report/model_loss_mean 1.12 / report/model_loss_std 1.72 / report/post_ent_mag 53.61 / report/post_ent_max 53.61 / 
report/post_ent_mean 38.24 / report/post_ent_min 31.4 / report/post_ent_std 4.75 / report/prior_ent_mag 66.68 / report/prior_ent_max 66.68 / report/prior_ent_mean 39.24 / report/prior_ent_min 33.95 / report/prior_ent_std 5.98 / report/rep_loss_mean 1.45 / 
report/rep_loss_std 2.67 / report/reward_avg 1.54 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.54 / report/reward_rate 0.77 / eval/cont_avg 1 / eval/cont_loss_mean 3.9e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 3.09 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.17 / eval/model_loss_std 2.06 / eval/post_ent_mag 52.02 / eval/post_ent_max 52.02 / eval/post_ent_mean 
39.66 / eval/post_ent_min 30.18 / eval/post_ent_std 4.09 / eval/prior_ent_mag 66.68 / eval/prior_ent_max 66.68 / eval/prior_ent_mean 40.67 / eval/prior_ent_min 34.34 / eval/prior_ent_std 5.35 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 3.09 / eval/reward_avg 1.33 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.33 / eval/reward_rate 0.66 / 
replay/size 2.9e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3884 / timer/env.step_total 19.42 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.68 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.32 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.12 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / 
timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 291000 Counter(291000) 290937
Saved chunk: 20230922T035503F454635-7wHydr4IRvEMqxpMrxwSpa-1Uh7cjzl8AbWboElNxh6Wz-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 291500 Counter(291500) 291437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 802.0.
Saved chunk: 20230922T035607F228368-2iGV528oTkaCPoesAoIktP-3lC3nR0k34SLZmfZdsoBLQ-1024.npz
Starting evaluation at step 292000 Counter(292000) 291937
Saved chunk: 20230922T035622F180900-1Uh7cjzl8AbWboElNxh6Wz-3ndIXeFUaj28kIXCbFDcau-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 292500 Counter(292500) 292437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T035727F521322-3lC3nR0k34SLZmfZdsoBLQ-3SbJNXNFNpTfgmjmZYnURP-1024.npz
Starting evaluation at step 293000 Counter(293000) 292937
Saved chunk: 20230922T035740F049682-3ndIXeFUaj28kIXCbFDcau-5pt6JVAkAqAfhCneiIW0AL-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 293500 Counter(293500) 293437
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 836.0.
Saved chunk: 20230922T035846F859917-3SbJNXNFNpTfgmjmZYnURP-0j4CPTjms4Tn80Bm31eoXW-1024.npz
Starting evaluation at step 294000 Counter(294000) 293937
Saved chunk: 20230922T035857F839758-5pt6JVAkAqAfhCneiIW0AL-35vCeJBcSMJ9SkEjR39NrS-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 809.0.
Starting evaluation at step 294500 Counter(294500) 294437
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 589454 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 3.97 / train/action_max 3.75 / train/action_mean 0.03 / train/action_min -3.86 / train/action_std 0.98 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -2.55 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 1.6e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.39 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.03 / train/extr_critic_max 670.03 / train/extr_critic_mean 628.17 / train/extr_critic_min 461.35 / train/extr_critic_std 55.07 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.51 / train/extr_return_raw_max 667.51 / train/extr_return_raw_mean 628.2 / train/extr_return_raw_min 462.49 / train/extr_return_raw_std 55.15 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 7.1e-4 / train/extr_reward_std 0.92 / train/image_loss_mean 0.2 / train/image_loss_std 0.31 / train/model_loss_mean 1.27 / train/model_loss_std 2.27 / 
train/model_opt_grad_norm 6.26 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 9739.58 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.32 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.57 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.32 / train/policy_logprob_min -8.57 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 3.2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 55.09 / train/post_ent_max 55.09 / train/post_ent_mean 39.2 / train/post_ent_min 
26.48 / train/post_ent_std 4.84 / train/prior_ent_mag 66.93 / train/prior_ent_max 66.93 / train/prior_ent_mean 40.45 / train/prior_ent_min 31.38 / train/prior_ent_std 5.94 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.39 / train/reward_avg 1.27 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.61 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 3.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 2.05 / report/dyn_loss_std 4.91 / report/image_loss_mean 0.27 / report/image_loss_std 0.41 / report/model_loss_mean 1.56 / report/model_loss_std 3.26 / report/post_ent_mag 61.23 / report/post_ent_max 61.23 / 
report/post_ent_mean 39.93 / report/post_ent_min 20.8 / report/post_ent_std 5.15 / report/prior_ent_mag 67.01 / report/prior_ent_max 67.01 / report/prior_ent_mean 41.47 / report/prior_ent_min 31.75 / report/prior_ent_std 5.96 / report/rep_loss_mean 2.05 / 
report/rep_loss_std 4.91 / report/reward_avg 0.84 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.14 / report/reward_pred 0.84 / report/reward_rate 0.43 / eval/cont_avg 1 / eval/cont_loss_mean 2.5e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.94 / eval/dyn_loss_std 8.02 / eval/image_loss_mean 0.79 / eval/image_loss_std 3.35 / eval/model_loss_mean 2.64 / eval/model_loss_std 7.87 / eval/post_ent_mag 51.9 / eval/post_ent_max 51.9 / eval/post_ent_mean 
37.27 / eval/post_ent_min 16.69 / eval/post_ent_std 4.81 / eval/prior_ent_mag 67.01 / eval/prior_ent_max 67.01 / eval/prior_ent_mean 38.71 / eval/prior_ent_min 30.74 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 2.94 / eval/rep_loss_std 8.02 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size 
2.9e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3842 / timer/env.step_total 19.08 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.15 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.15 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 5.9e-3 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.49 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T040006F154298-0j4CPTjms4Tn80Bm31eoXW-19ZmiIMwZWfKQxhdSeb2wE-1024.npz
Starting evaluation at step 295000 Counter(295000) 294937
Saved chunk: 20230922T040015F565386-35vCeJBcSMJ9SkEjR39NrS-4q105ibvfxUq0xTRyvlzDS-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 295500 Counter(295500) 295437
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T040126F246861-19ZmiIMwZWfKQxhdSeb2wE-5nKGWKboHmdV9vLUIQKvRO-1024.npz
Starting evaluation at step 296000 Counter(296000) 295937
Saved chunk: 20230922T040134F149857-4q105ibvfxUq0xTRyvlzDS-0JlW6C980fF7G9hgGTnhgN-1024.npz
eval_Episode has 500 steps and return 833.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 296500 Counter(296500) 296437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T040245F789512-5nKGWKboHmdV9vLUIQKvRO-7u10laL9hIDaB2EKhAyILx-1024.npz
Starting evaluation at step 297000 Counter(297000) 296937
Saved chunk: 20230922T040252F099453-0JlW6C980fF7G9hgGTnhgN-1secSPCc0E9B4WFjR1SDW9-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 297500 Counter(297500) 297437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T040405F170078-7u10laL9hIDaB2EKhAyILx-0gnsnWeRXMoqNCvHtKPRrY-1024.npz
Starting evaluation at step 298000 Counter(298000) 297937
Saved chunk: 20230922T040409F953309-1secSPCc0E9B4WFjR1SDW9-5S6R7z9JnV3fu6hTU0zfLc-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 298500 Counter(298500) 298437
eval_Episode has 500 steps and return 849.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 597134 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / train/action_mag 3.91 / train/action_max 3.71 / train/action_mean 0.02 / train/action_min -3.75 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -2.08 / train/adv_mag 0.53 / train/adv_max 0.38 / train/adv_mean 1.7e-4 / train/adv_min -0.5 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.43 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.81 / train/extr_critic_max 669.81 / train/extr_critic_mean 626.44 / train/extr_critic_min 456.86 / train/extr_critic_std 55.95 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.41 / train/extr_return_raw_max 667.41 / train/extr_return_raw_mean 626.47 / train/extr_return_raw_min 455.74 / train/extr_return_raw_std 56.04
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.25 / train/extr_reward_min 0 / train/extr_reward_std 0.94 / train/image_loss_mean 0.21 / train/image_loss_std 0.32 / train/model_loss_mean 1.28 / train/model_loss_std 2.3 / 
train/model_opt_grad_norm 5.41 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 7599.41 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 5937.5 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.15 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.52 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.15 / train/policy_logprob_min -8.52 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 2.3e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 55.09 / train/post_ent_max 55.09 / train/post_ent_mean 39.29 / train/post_ent_min
26.5 / train/post_ent_std 4.93 / train/prior_ent_mag 66.76 / train/prior_ent_max 66.76 / train/prior_ent_mean 40.55 / train/prior_ent_min 31.44 / train/prior_ent_std 6.01 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.43 / train/reward_avg 1.23 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.23 / train/reward_rate 0.62 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.61 / report/cont_avg 1 / report/cont_loss_mean 1.7e-11 / report/cont_loss_std 7.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.64 / report/image_loss_mean 0.16 / report/image_loss_std 0.33 / report/model_loss_mean 1.18 / report/model_loss_std 1.83 / report/post_ent_mag 52.51 / report/post_ent_max 52.51 / 
report/post_ent_mean 37.4 / report/post_ent_min 30.62 / report/post_ent_std 3.52 / report/prior_ent_mag 66.34 / report/prior_ent_max 66.34 / report/prior_ent_mean 38.57 / report/prior_ent_min 33.9 / report/prior_ent_std 5.02 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 2.64 / report/reward_avg 1.77 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.77 / report/reward_rate 0.88 / eval/cont_avg 1 / eval/cont_loss_mean 1.8e-11 / eval/cont_loss_std 5.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.73 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.28 / eval/model_loss_mean 1.22 / eval/model_loss_std 1.85 / eval/post_ent_mag 49.91 / eval/post_ent_max 49.91 / eval/post_ent_mean 
37.57 / eval/post_ent_min 22.79 / eval/post_ent_std 3.76 / eval/prior_ent_mag 66.34 / eval/prior_ent_max 66.34 / eval/prior_ent_mean 38.71 / eval/prior_ent_min 32.35 / eval/prior_ent_std 5.05 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.73 / eval/reward_avg 1.79 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.27 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.79 / eval/reward_rate 0.9 / 
replay/size 3e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3840 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.1e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.75 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.6e-3 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.39 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 299000 Counter(299000) 298937
Saved chunk: 20230922T040527F539751-5S6R7z9JnV3fu6hTU0zfLc-4237hpetj8J4EP3m9UL41D-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T040524F326521-0gnsnWeRXMoqNCvHtKPRrY-4QRyJIbRjIbgJkcfacBomy-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 299500 Counter(299500) 299437
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 300000 Counter(300000) 299937
Saved chunk: 20230922T040646F288168-4237hpetj8J4EP3m9UL41D-24UUITXezxaDJ8JeWlkP9z-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T040648F022970-4QRyJIbRjIbgJkcfacBomy-79fdkYOG100KyLmA1ihbcA-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 300500 Counter(300500) 300437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 301000 Counter(301000) 300937
Saved chunk: 20230922T040804F176748-24UUITXezxaDJ8JeWlkP9z-6vU6B8U6CUqcd6c9LTsh1j-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T040807F451478-79fdkYOG100KyLmA1ihbcA-0kJVrMhOozQaOGNObJFpDs-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 301500 Counter(301500) 301437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T040922F050272-6vU6B8U6CUqcd6c9LTsh1j-0000000000000000000000-622.npz
Saved chunk: 20230922T040926F866322-0kJVrMhOozQaOGNObJFpDs-0000000000000000000000-644.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 302000 Counter(302000) 301937
Saved chunk: 20230922T040922F050272-6vU6B8U6CUqcd6c9LTsh1j-3cd3bWsqIPTGlLLigWXALG-1024.npz
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T040926F866322-0kJVrMhOozQaOGNObJFpDs-385JTPFtaw76nmCvpTVDRF-1024.npz
train_Episode has 500 steps and return 846.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 604898 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / train/action_mag 3.93 / train/action_max 3.74 / train/action_mean 0.03 / train/action_min -3.78 / train/action_std 0.94 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -2.31 / train/adv_mag 0.54 / train/adv_max 0.41 / train/adv_mean 1.7e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.66 / 
train/dyn_loss_std 3.4 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.71 / train/extr_critic_max 669.71 / train/extr_critic_mean 627.74 / train/extr_critic_min 460.44 / train/extr_critic_std 54.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.39 / train/extr_return_raw_max 667.39 / train/extr_return_raw_mean 627.76 / train/extr_return_raw_min 462.46 / train/extr_return_raw_std 55.04
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.28 / train/model_loss_std 2.28 / 
train/model_opt_grad_norm 5.88 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 8330.56 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 6520.62 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.22 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.48 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.22 / train/policy_logprob_min -8.48 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 3.4e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 54.79 / train/post_ent_max 54.79 / train/post_ent_mean 39.16 / train/post_ent_min
26.88 / train/post_ent_std 4.86 / train/prior_ent_mag 66.55 / train/prior_ent_max 66.55 / train/prior_ent_mean 40.4 / train/prior_ent_min 31.74 / train/prior_ent_std 5.95 / train/rep_loss_mean 1.66 / train/rep_loss_std 3.4 / train/reward_avg 1.27 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / 
train_stats/mean_log_entropy 0.64 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 6e-11 / report/cont_loss_std 9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 6e-11 / report/cont_pred 1 
/ report/cont_rate 1 / report/dyn_loss_mean 1.7 / report/dyn_loss_std 3.71 / report/image_loss_mean 0.21 / report/image_loss_std 0.3 / report/model_loss_mean 1.29 / report/model_loss_std 2.43 / report/post_ent_mag 61.61 / report/post_ent_max 61.61 / report/post_ent_mean 
40.09 / report/post_ent_min 28.9 / report/post_ent_std 5.24 / report/prior_ent_mag 66.25 / report/prior_ent_max 66.25 / report/prior_ent_mean 41.43 / report/prior_ent_min 32.88 / report/prior_ent_std 6.11 / report/rep_loss_mean 1.7 / report/rep_loss_std 3.71 / 
report/reward_avg 1.04 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred
1.04 / report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.83 
/ eval/dyn_loss_std 3.74 / eval/image_loss_mean 0.33 / eval/image_loss_std 1 / eval/model_loss_mean 1.51 / eval/model_loss_std 2.97 / eval/post_ent_mag 52.6 / eval/post_ent_max 52.6 / eval/post_ent_mean 39.44 / eval/post_ent_min 25.83 / eval/post_ent_std 4.77 / 
eval/prior_ent_mag 66.25 / eval/prior_ent_max 66.25 / eval/prior_ent_mean 40.91 / eval/prior_ent_min 33.57 / eval/prior_ent_std 5.79 / eval/rep_loss_mean 1.83 / eval/rep_loss_std 3.74 / eval/reward_avg 1.43 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.1 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.43 / eval/reward_rate 0.72 / replay/size 3e5 / replay/inserts 3882 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3882 / timer/env.step_total 19.28 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.03 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.21 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7389 / timer/agent.policy_total 16.29 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.1 / timer/dataset_train_count 1941 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1941 / 
timer/agent.train_total 246.32 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.87

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 302500 Counter(302500) 302437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 303000 Counter(303000) 302937
Saved chunk: 20230922T041039F997168-3cd3bWsqIPTGlLLigWXALG-5VWdT20jUn12vWOG8uAZxM-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T041046F370232-385JTPFtaw76nmCvpTVDRF-6TUj3c9DCppisJMs814pBa-1024.npz
Starting evaluation at step 303500 Counter(303500) 303437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 304000 Counter(304000) 303937
Saved chunk: 20230922T041158F759301-5VWdT20jUn12vWOG8uAZxM-5lYFgN11rjwXUQsajzheNK-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T041206F719722-6TUj3c9DCppisJMs814pBa-6s0cmoPZt8AaMtkER0lpjP-1024.npz
Starting evaluation at step 304500 Counter(304500) 304437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 305000 Counter(305000) 304937
eval_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T041316F601721-5lYFgN11rjwXUQsajzheNK-2zqW63uEzQGf8HB1gMtu8D-1024.npz
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T041326F058309-6s0cmoPZt8AaMtkER0lpjP-3teIwY7XH7IsAsDUISoUo0-1024.npz
Starting evaluation at step 305500 Counter(305500) 305437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 306000 Counter(306000) 305937
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T041434F404574-2zqW63uEzQGf8HB1gMtu8D-7kOkFt7MngXBw33wI5s51y-1024.npz
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T041445F432678-3teIwY7XH7IsAsDUISoUo0-0vFAd2pLHTVKkAWfhvZtPg-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 612574 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / train/action_mag 3.99 / train/action_max 3.81 / train/action_mean 0.03 / train/action_min -3.86 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -3.02 / train/adv_mag 0.52 / train/adv_max 0.39 / train/adv_mean 2.3e-4 / train/adv_min -0.48 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.75 / train/extr_critic_max 669.75 / train/extr_critic_mean 629.65 / train/extr_critic_min 465.61 / train/extr_critic_std 53.36 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.3 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.39 / train/extr_return_raw_max 667.39 / train/extr_return_raw_mean 629.69 / train/extr_return_raw_min 466.42 / train/extr_return_raw_std 53.45 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.3 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.31 / train/model_loss_mean 1.27 / train/model_loss_std 2.25 / 
train/model_opt_grad_norm 6.06 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 1.3e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.26 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.65 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.26 / train/policy_logprob_min -8.65 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 3.5e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 54.82 / train/post_ent_max 54.82 / train/post_ent_mean 39.39 / train/post_ent_min 
27.69 / train/post_ent_std 4.69 / train/prior_ent_mag 66.47 / train/prior_ent_max 66.47 / train/prior_ent_mean 40.62 / train/prior_ent_min 32.12 / train/prior_ent_std 5.79 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.35 / train/reward_avg 1.28 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.28 / train/reward_rate 0.64 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.63 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 1.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.74 / report/dyn_loss_std 3.83 / report/image_loss_mean 0.23 / report/image_loss_std 0.42 / report/model_loss_mean 1.33 / report/model_loss_std 2.66 / report/post_ent_mag 52.81 / report/post_ent_max 52.81 / 
report/post_ent_mean 41.12 / report/post_ent_min 26.23 / report/post_ent_std 4.74 / report/prior_ent_mag 66.71 / report/prior_ent_max 66.71 / report/prior_ent_mean 42.49 / report/prior_ent_min 33.3 / report/prior_ent_std 5.83 / report/rep_loss_mean 1.74 / 
report/rep_loss_std 3.83 / report/reward_avg 0.79 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.3e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 0.78 / report/reward_rate 0.39 / eval/cont_avg 1 / eval/cont_loss_mean 8.8e-11 / eval/cont_loss_std 1.5e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 2.07 / eval/dyn_loss_std 4.5 / eval/image_loss_mean 0.4 / eval/image_loss_std 0.99 / eval/model_loss_mean 1.72 / eval/model_loss_std 3.44 / eval/post_ent_mag 52.65 / eval/post_ent_max 52.65 / eval/post_ent_mean 39.12 / eval/post_ent_min 22.12 / 
eval/post_ent_std 4.54 / eval/prior_ent_mag 66.71 / eval/prior_ent_max 66.71 / eval/prior_ent_mean 40.61 / eval/prior_ent_min 32.41 / eval/prior_ent_std 5.8 / eval/rep_loss_mean 2.07 / eval/rep_loss_std 4.5 / eval/reward_avg 1.28 / eval/reward_loss_mean 0.07 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.28 / eval/reward_rate 0.64 / replay/size 3.1e5 / replay/inserts 3838 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3838 / timer/env.step_total 19.18 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.84 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.13 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.8e-3 / timer/dataset_train_count 
1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.31 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 306500 Counter(306500) 306437
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 307000 Counter(307000) 306937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T041604F660052-0vFAd2pLHTVKkAWfhvZtPg-42BeIHBqRK9vBPcij3LdgG-1024.npz
Starting evaluation at step 307500 Counter(307500) 307437
Saved chunk: 20230922T041552F103152-7kOkFt7MngXBw33wI5s51y-6Jhqk0R8RIMI1WMIxQDVw5-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 308000 Counter(308000) 307937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T041725F021113-42BeIHBqRK9vBPcij3LdgG-2buPwBtretNUwdpfULdGQc-1024.npz
Starting evaluation at step 308500 Counter(308500) 308437
Saved chunk: 20230922T041746F378207-6Jhqk0R8RIMI1WMIxQDVw5-25c4aPmhnEnaZFlYr39J64-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 309000 Counter(309000) 308937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T041844F343998-2buPwBtretNUwdpfULdGQc-7ljf37aGndlTyeiDojDY6b-1024.npz
Starting evaluation at step 309500 Counter(309500) 309437
Saved chunk: 20230922T041904F129594-25c4aPmhnEnaZFlYr39J64-5fLLlxs40Pab3m7kvN1eUX-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 310000 Counter(310000) 309937
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 841.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 620254 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 842 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 841 / episode/reward_rate 0.84 / train/action_mag 3.98 / train/action_max 3.77 / train/action_mean 0.03 / train/action_min -3.84 / train/action_std 0.94 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.5e5 / train/actor_opt_loss -2.13 / train/adv_mag 0.51 / train/adv_max 0.37 / train/adv_mean 1.4e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.03 / train/extr_critic_max 670.03 / train/extr_critic_mean 628.31 / train/extr_critic_min 456.84 / train/extr_critic_std 55.07 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.27 / train/extr_return_raw_max 667.27 / train/extr_return_raw_mean 628.33 / train/extr_return_raw_min 458.38 / train/extr_return_raw_std 55.17
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.3 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.2 / train/image_loss_std 0.31 / train/model_loss_mean 1.26 / train/model_loss_std 2.24 / 
train/model_opt_grad_norm 6.36 / train/model_opt_grad_steps 1.5e5 / train/model_opt_loss 9340.56 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.24 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.24 / train/policy_logprob_min -8.69 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.49 / train/policy_randomness_min 3.1e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 54.08 / train/post_ent_max 54.08 / train/post_ent_mean 39.31 / train/post_ent_min
26.83 / train/post_ent_std 4.64 / train/prior_ent_mag 66.48 / train/prior_ent_max 66.48 / train/prior_ent_mean 40.55 / train/prior_ent_min 31.5 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.35 / train/reward_avg 1.28 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.28 / train/reward_rate 0.64 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.46 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 2.85 / report/image_loss_mean 0.19 / report/image_loss_std 0.34 / report/model_loss_mean 1.19 / report/model_loss_std 1.93 / report/post_ent_mag 52.75 / report/post_ent_max 52.75 / 
report/post_ent_mean 40.29 / report/post_ent_min 30.95 / report/post_ent_std 4.17 / report/prior_ent_mag 66.53 / report/prior_ent_max 66.53 / report/prior_ent_mean 41.41 / report/prior_ent_min 34.4 / report/prior_ent_std 5.35 / report/rep_loss_mean 1.55 / 
report/rep_loss_std 2.85 / report/reward_avg 1.29 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 8.2e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.29 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 3e-11 / eval/cont_loss_std 1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3e-11 / eval/cont_pred 1 / 
eval/cont_rate 1 / eval/dyn_loss_mean 3.09 / eval/dyn_loss_std 7.77 / eval/image_loss_mean 0.75 / eval/image_loss_std 2.65 / eval/model_loss_mean 2.69 / eval/model_loss_std 7.09 / eval/post_ent_mag 51.94 / eval/post_ent_max 51.94 / eval/post_ent_mean 38.74 / 
eval/post_ent_min 22.06 / eval/post_ent_std 4.44 / eval/prior_ent_mag 66.53 / eval/prior_ent_max 66.53 / eval/prior_ent_mean 40.38 / eval/prior_ent_min 34.26 / eval/prior_ent_std 5.33 / eval/rep_loss_mean 3.09 / eval/rep_loss_std 7.77 / eval/reward_avg 1.41 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.41 / eval/reward_rate 0.71 / 
replay/size 3.1e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3840 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.62 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.46 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.07 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T042003F572915-7ljf37aGndlTyeiDojDY6b-4HsBS4HIYjAMVf7W8Y1dfc-1024.npz
Starting evaluation at step 310500 Counter(310500) 310437
Saved chunk: 20230922T042021F848467-5fLLlxs40Pab3m7kvN1eUX-0yhzChQga2nailCg7rpx1t-1024.npz
eval_Episode has 500 steps and return 851.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 311000 Counter(311000) 310937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T042123F719223-4HsBS4HIYjAMVf7W8Y1dfc-79xbIwXA2BiqgvjddqNy0q-1024.npz
Starting evaluation at step 311500 Counter(311500) 311437
Saved chunk: 20230922T042140F504610-0yhzChQga2nailCg7rpx1t-5qMKdLJkPaHCBPOC8L2ZJW-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 312000 Counter(312000) 311937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T042243F178040-79xbIwXA2BiqgvjddqNy0q-3soqAEJz4bRlQR0aX07Fda-1024.npz
Starting evaluation at step 312500 Counter(312500) 312437
Saved chunk: 20230922T042258F310071-5qMKdLJkPaHCBPOC8L2ZJW-3WdnxYIYnbaiDN6D5yzYqB-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 313000 Counter(313000) 312937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T042402F439301-3soqAEJz4bRlQR0aX07Fda-0000000000000000000000-980.npz
Saved chunk: 20230922T042415F939021-3WdnxYIYnbaiDN6D5yzYqB-0000000000000000000000-881.npz
Saved chunk: 20230922T042402F439301-3soqAEJz4bRlQR0aX07Fda-5eDmKIhPKG68sJQUa0JvxI-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 313500 Counter(313500) 313437
Saved chunk: 20230922T042415F939021-3WdnxYIYnbaiDN6D5yzYqB-7MA6iMTd4Bafy2KhNLe6hn-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 314000 Counter(314000) 313937
eval_Episode has 500 steps and return 849.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 628002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 4.07 / train/action_max 3.9 / train/action_mean 0.03 / train/action_min -3.88 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -3.66 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 2.7e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 2.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.64 / 
train/dyn_loss_std 3.35 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.81 / train/extr_critic_max 669.81 / train/extr_critic_mean 628.52 / train/extr_critic_min 462.9 / train/extr_critic_std 54.57 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.75 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.23 / train/extr_return_raw_max 667.23 / train/extr_return_raw_mean 628.56 / train/extr_return_raw_min 462.7 / train/extr_return_raw_std 54.63 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.29 / train/extr_reward_min 0 / train/extr_reward_std 0.93 / train/image_loss_mean 0.2 / train/image_loss_std 0.31 / train/model_loss_mean 1.26 / train/model_loss_std 2.23 / 
train/model_opt_grad_norm 5.81 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7963.92 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.34 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.83 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.34 / train/policy_logprob_min -8.83 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 4.2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.92 / train/post_ent_max 52.92 / train/post_ent_mean 39.45 / train/post_ent_min
27.5 / train/post_ent_std 4.56 / train/prior_ent_mag 66.46 / train/prior_ent_max 66.46 / train/prior_ent_mean 40.68 / train/prior_ent_min 31.93 / train/prior_ent_std 5.67 / train/rep_loss_mean 1.64 / train/rep_loss_std 3.35 / train/reward_avg 1.27 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.27 / train/reward_rate 0.64 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.69 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.25 / report/image_loss_mean 0.22 / report/image_loss_std 0.27 / report/model_loss_mean 1.29 / report/model_loss_std 2.12 / report/post_ent_mag 52.51 / report/post_ent_max 52.51 / 
report/post_ent_mean 39.95 / report/post_ent_min 25.62 / report/post_ent_std 4.86 / report/prior_ent_mag 66.33 / report/prior_ent_max 66.33 / report/prior_ent_mean 41.17 / report/prior_ent_min 34.55 / report/prior_ent_std 5.94 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 3.25 / report/reward_avg 1.2 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.2 / report/reward_rate 0.6 / eval/cont_avg 1 / eval/cont_loss_mean 1.9e-11 / eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 1.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.41 / eval/dyn_loss_std 2.11 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.14 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.37 / eval/post_ent_mag 50.95 / eval/post_ent_max 50.95 / eval/post_ent_mean 37.84 / eval/post_ent_min 31.16 / 
eval/post_ent_std 3.18 / eval/prior_ent_mag 66.33 / eval/prior_ent_max 66.33 / eval/prior_ent_mean 38.75 / eval/prior_ent_min 34.58 / eval/prior_ent_std 4.7 / eval/rep_loss_mean 1.41 / eval/rep_loss_std 2.11 / eval/reward_avg 1.83 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.5e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.83 / eval/reward_rate 0.91 / replay/size 3.1e5 / replay/inserts 3874 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.28 / timer/env.step_count 3874 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.34 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7882 / timer/agent.policy_total 17.24 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1937 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1937 / timer/agent.train_total 245.31 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 
4e-5 / fps 25.63

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T042521F700336-5eDmKIhPKG68sJQUa0JvxI-6t6zjql4JvrHg3Et692FCF-1024.npz
Starting evaluation at step 314500 Counter(314500) 314437
Saved chunk: 20230922T042533F676558-7MA6iMTd4Bafy2KhNLe6hn-32CSRYT35R5VX0YjqWJAPO-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 315000 Counter(315000) 314937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 832.0.
Saved chunk: 20230922T042641F793633-6t6zjql4JvrHg3Et692FCF-0DKekY4VCqPyYkh8pw2un0-1024.npz
Starting evaluation at step 315500 Counter(315500) 315437
Saved chunk: 20230922T042652F294480-32CSRYT35R5VX0YjqWJAPO-2r4mCRW6UpRd2tSBN2sbSS-1024.npz
eval_Episode has 500 steps and return 829.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 316000 Counter(316000) 315937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T042801F233385-0DKekY4VCqPyYkh8pw2un0-2vyMgRUHHJLhxgvNfBBnoj-1024.npz
Starting evaluation at step 316500 Counter(316500) 316437
Saved chunk: 20230922T042810F113343-2r4mCRW6UpRd2tSBN2sbSS-735WAlb2UDlVyLvtuAd7kV-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 317000 Counter(317000) 316937
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T042920F513259-2vyMgRUHHJLhxgvNfBBnoj-7Ffa8v74Vtn8XhYtLEh3gr-1024.npz
Starting evaluation at step 317500 Counter(317500) 317437
Saved chunk: 20230922T042927F869938-735WAlb2UDlVyLvtuAd7kV-5AZ9h9MflGRvYZUuOgN1Q6-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 635782 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 848 / eval_episode/reward_rate 0.85 / train/action_mag 4.15 / train/action_max 3.93 / train/action_mean 0.03 / train/action_min -4.01 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -3.3 / train/adv_mag 0.52 / train/adv_max 0.38 / train/adv_mean 2.1e-4 / train/adv_min -0.48 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 2.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.29 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.78 / train/extr_critic_max 669.78 / train/extr_critic_mean 630.04 / train/extr_critic_min 465.72 / train/extr_critic_std 53.05 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.14 / train/extr_return_raw_max 667.14 / train/extr_return_raw_mean 630.08 / train/extr_return_raw_min 465.57 / train/extr_return_raw_std 53.11
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.31 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.2 / train/image_loss_std 0.3 / train/model_loss_mean 1.25 / train/model_loss_std 2.2 / 
train/model_opt_grad_norm 5.92 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9458.76 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 3.4e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 53.86 / train/post_ent_max 53.86 / train/post_ent_mean 39.46 / train/post_ent_min
27.43 / train/post_ent_std 4.47 / train/prior_ent_mag 66.16 / train/prior_ent_max 66.16 / train/prior_ent_mean 40.68 / train/prior_ent_min 32.09 / train/prior_ent_std 5.58 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.29 / train/reward_avg 1.29 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.29 / train/reward_rate 0.65 / 
train_stats/mean_log_entropy 0.71 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 2.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.65 / report/dyn_loss_std 3.35 / report/image_loss_mean 0.2 / report/image_loss_std 0.25 / report/model_loss_mean 1.26 / report/model_loss_std 2.2 / report/post_ent_mag 51.27 / report/post_ent_max 51.27 / 
report/post_ent_mean 40.15 / report/post_ent_min 29.31 / report/post_ent_std 4.93 / report/prior_ent_mag 66.29 / report/prior_ent_max 66.29 / report/prior_ent_mean 41.38 / report/prior_ent_min 31.41 / report/prior_ent_std 6.05 / report/rep_loss_mean 1.65 / 
report/rep_loss_std 3.35 / report/reward_avg 1.09 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.9e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.1 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.76 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.79 / eval/post_ent_mag 52.02 / eval/post_ent_max 52.02 / eval/post_ent_mean 39.18 / eval/post_ent_min 31.4 / 
eval/post_ent_std 4.03 / eval/prior_ent_mag 66.29 / eval/prior_ent_max 66.29 / eval/prior_ent_mean 40.25 / eval/prior_ent_min 34.79 / eval/prior_ent_std 5.47 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.76 / eval/reward_avg 1.54 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / replay/size 3.2e5 / replay/inserts 3890 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.01 / timer/env.step_count 3890 / timer/env.step_total 19.44 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.19 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.7e-4 / timer/replay._sample_max 0.16 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.2 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.7e-3 / timer/dataset_train_count 
1945 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.23 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.93

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 318000 Counter(318000) 317937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T043039F697031-7Ffa8v74Vtn8XhYtLEh3gr-4rr8KBk14bMl0ejGyuFAvQ-1024.npz
Starting evaluation at step 318500 Counter(318500) 318437
Saved chunk: 20230922T043045F465376-5AZ9h9MflGRvYZUuOgN1Q6-5DZXfOULBrvOesiRnnoPjM-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 319000 Counter(319000) 318937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T043159F918602-4rr8KBk14bMl0ejGyuFAvQ-7H2iqRQVDIDRygF0Tw2yPz-1024.npz
Starting evaluation at step 319500 Counter(319500) 319437
Saved chunk: 20230922T043204F161453-5DZXfOULBrvOesiRnnoPjM-0xABfc5gGpUwIGMwy9X47w-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 320000 Counter(320000) 319937
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 320500 Counter(320500) 320437
Saved chunk: 20230922T043321F970412-0xABfc5gGpUwIGMwy9X47w-1pZpZkMHAs3XqZ6J0e9Oha-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T043319F301890-7H2iqRQVDIDRygF0Tw2yPz-4SXVR7xpSDssva53bXxJdl-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 321000 Counter(321000) 320937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 321500 Counter(321500) 321437
Saved chunk: 20230922T043439F706006-1pZpZkMHAs3XqZ6J0e9Oha-7pEc73AIVHz5057n6tcUHK-1024.npz
eval_Episode has 500 steps and return 474.0.
Saved chunk: 20230922T043441F980438-4SXVR7xpSDssva53bXxJdl-1E7LfQB4W0H34jbdsmSSOK-1024.npz
train_Episode has 500 steps and return 846.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 643466 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 474 / eval_episode/reward_rate 0.48 / episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / train/action_mag 4.17 / train/action_max 3.93 / train/action_mean 0.03 / train/action_min -4.04 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -1.84 / train/adv_mag 0.53 / train/adv_max 0.39 / train/adv_mean 6.4e-5 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.65 / 
train/dyn_loss_std 3.38 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.58 / train/extr_critic_max 669.58 / train/extr_critic_mean 629.29 / train/extr_critic_min 461.55 / train/extr_critic_std 54.16 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.2 / train/extr_return_raw_max 667.2 / train/extr_return_raw_mean 629.3 / train/extr_return_raw_min 463.54 / train/extr_return_raw_std 54.25 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.31 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.2 / train/image_loss_std 0.32 / train/model_loss_mean 1.26 / train/model_loss_std 2.26 / 
train/model_opt_grad_norm 5.75 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 9333.73 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2.4e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.73 / train/post_ent_max 54.73 / train/post_ent_mean 39.42 / train/post_ent_min
27.25 / train/post_ent_std 4.41 / train/prior_ent_mag 66.24 / train/prior_ent_max 66.24 / train/prior_ent_mean 40.65 / train/prior_ent_min 32.13 / train/prior_ent_std 5.54 / train/rep_loss_mean 1.65 / train/rep_loss_std 3.38 / train/reward_avg 1.29 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.29 / train/reward_rate 0.65 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.68 / report/cont_avg 1 / report/cont_loss_mean 3.7e-11 / report/cont_loss_std 3.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 3.53 / report/image_loss_mean 0.18 / report/image_loss_std 0.27 / report/model_loss_mean 1.23 / report/model_loss_std 2.34 / report/post_ent_mag 52.28 / report/post_ent_max 52.28 / 
report/post_ent_mean 39.42 / report/post_ent_min 32.48 / report/post_ent_std 4.29 / report/prior_ent_mag 65.78 / report/prior_ent_max 65.78 / report/prior_ent_mean 40.59 / report/prior_ent_min 34.98 / report/prior_ent_std 5.47 / report/rep_loss_mean 1.59 / 
report/rep_loss_std 3.53 / report/reward_avg 1.34 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.34 / report/reward_rate 0.67 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.71 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.74 / eval/post_ent_mag 50.44 / eval/post_ent_max 50.44 / eval/post_ent_mean 
39.08 / eval/post_ent_min 33.43 / eval/post_ent_std 3.5 / eval/prior_ent_mag 65.78 / eval/prior_ent_max 65.78 / eval/prior_ent_mean 40.09 / eval/prior_ent_min 35.42 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.71 / eval/reward_avg 1.62 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.63 / eval/reward_rate 0.81 / 
replay/size 3.2e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3842 / timer/env.step_total 19.05 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.4e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.3 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-4 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.01 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.62 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 322000 Counter(322000) 321937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 322500 Counter(322500) 322437
Saved chunk: 20230922T043557F295762-7pEc73AIVHz5057n6tcUHK-1CU1XGQd5DmTnMVXxVR03o-1024.npz
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T043601F098430-1E7LfQB4W0H34jbdsmSSOK-4QxLDdLLAYtVgERkyq4yTX-1024.npz
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 323000 Counter(323000) 322937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 323500 Counter(323500) 323437
Saved chunk: 20230922T043716F065813-1CU1XGQd5DmTnMVXxVR03o-6jkMDKnuuYXstDwIIOFTIo-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T043721F448842-4QxLDdLLAYtVgERkyq4yTX-4wRsFvxlm71DZGeb2iCHQj-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 324000 Counter(324000) 323937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 324500 Counter(324500) 324437
Saved chunk: 20230922T043833F860447-6jkMDKnuuYXstDwIIOFTIo-3gOd8s1HfRvlTcJdG3BZvP-1024.npz
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T043840F748894-4wRsFvxlm71DZGeb2iCHQj-25ipbxxkfpGDPizdW2sSJZ-1024.npz
train_Episode has 500 steps and return 842.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T043951F613514-3gOd8s1HfRvlTcJdG3BZvP-0000000000000000000000-116.npz
Saved chunk: 20230922T044000F074224-25ipbxxkfpGDPizdW2sSJZ-0000000000000000000000-292.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 325000 Counter(325000) 324937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 325500 Counter(325500) 325437
Saved chunk: 20230922T043951F613514-3gOd8s1HfRvlTcJdG3BZvP-7bDOQ100HwTKC76cmYWBe2-1024.npz
eval_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 651138 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 839 / episode/reward_rate 0.84 / train/action_mag 4 / train/action_max 3.84 / train/action_mean 0.02 / train/action_min -3.81 / train/action_std 0.95 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -1.78 / train/adv_mag 0.52 / train/adv_max 0.39 / train/adv_mean 9.9e-5 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 2.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.63 / 
train/dyn_loss_std 3.3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.57 / train/extr_critic_max 669.57 / train/extr_critic_mean 630.93 / train/extr_critic_min 464.46 / train/extr_critic_std 52.15 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.26 / train/extr_return_raw_max 667.26 / train/extr_return_raw_mean 630.94 / train/extr_return_raw_min 467.02 / train/extr_return_raw_std 52.21
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.32 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.19 / train/image_loss_std 0.29 / train/model_loss_mean 1.25 / train/model_loss_std 2.2 / 
train/model_opt_grad_norm 5.83 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 9257.42 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.73 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.73 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 2.3e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.43 / train/post_ent_max 54.43 / train/post_ent_mean 39.42 / train/post_ent_min 
27.3 / train/post_ent_std 4.38 / train/prior_ent_mag 66.06 / train/prior_ent_max 66.06 / train/prior_ent_mean 40.64 / train/prior_ent_min 32.55 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.63 / train/rep_loss_std 3.3 / train/reward_avg 1.29 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.29 / train/reward_rate 0.65 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.57 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.88 / report/dyn_loss_std 4.77 / report/image_loss_mean 0.25 / report/image_loss_std 0.46 / report/model_loss_mean 1.46 / report/model_loss_std 3.19 / report/post_ent_mag 51.73 / report/post_ent_max 51.73 / 
report/post_ent_mean 37.63 / report/post_ent_min 20.38 / report/post_ent_std 4.83 / report/prior_ent_mag 65.72 / report/prior_ent_max 65.72 / report/prior_ent_mean 39.27 / report/prior_ent_min 24.79 / report/prior_ent_std 5.63 / report/rep_loss_mean 1.88 / 
report/rep_loss_std 4.77 / report/reward_avg 1.28 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.2e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 5.9e-11 / eval/cont_loss_std 6.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.86 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.15 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.81 / eval/post_ent_mag 51.77 / eval/post_ent_max 51.77 / eval/post_ent_mean 
39.28 / eval/post_ent_min 30.97 / eval/post_ent_std 4.26 / eval/prior_ent_mag 65.72 / eval/prior_ent_max 65.72 / eval/prior_ent_mean 40.34 / eval/prior_ent_min 35.21 / eval/prior_ent_std 5.43 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.86 / eval/reward_avg 1.4 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.4 / eval/reward_rate 0.7 / replay/size 
3.3e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3836 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.07 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.09 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.35 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.13 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1918 / timer/agent.train_total 243.1 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.7e-8 / timer/dataset_eval_avg 2.9e-5 / 
timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T044000F074224-25ipbxxkfpGDPizdW2sSJZ-74L2q5TGLBHhGiNFDWOBRD-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 326000 Counter(326000) 325937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 326500 Counter(326500) 326437
Saved chunk: 20230922T044109F564688-7bDOQ100HwTKC76cmYWBe2-0t3Sz6ucY1oRTR7tMbVBp7-1024.npz
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T044120F450429-74L2q5TGLBHhGiNFDWOBRD-6bGcLLgz6ELLB66viBpSod-1024.npz
Starting evaluation at step 327000 Counter(327000) 326937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 327500 Counter(327500) 327437
Saved chunk: 20230922T044228F457155-0t3Sz6ucY1oRTR7tMbVBp7-2Owr3V5pdJQSDFttZa0RJf-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T044240F019775-6bGcLLgz6ELLB66viBpSod-6pannqWXB8aorOzIPENPu0-1024.npz
Starting evaluation at step 328000 Counter(328000) 327937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 328500 Counter(328500) 328437
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T044346F236316-2Owr3V5pdJQSDFttZa0RJf-5zsYE9iXAJWOUy4LhOPRbJ-1024.npz
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T044359F382807-6pannqWXB8aorOzIPENPu0-7eF3KdEFFO05M3Cw2qKl08-1024.npz
Starting evaluation at step 329000 Counter(329000) 328937
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 658914 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 838 / eval_episode/reward_rate 0.84 / train/action_mag 4.05 / train/action_max 3.89 / train/action_mean 0.02 / train/action_min -3.86 / train/action_std 0.96 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.6e5 / train/actor_opt_loss -2.56 / train/adv_mag 0.52 / train/adv_max 0.38 / train/adv_mean 1.6e-4 / train/adv_min -0.48 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.51 / train/extr_critic_max 669.51 / train/extr_critic_mean 631.43 / train/extr_critic_min 468.62 / train/extr_critic_std 51.51 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.32 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.07 / train/extr_return_raw_max 667.07 / train/extr_return_raw_mean 631.45 / train/extr_return_raw_min 468.07 / train/extr_return_raw_std 51.59
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.32 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.19 / train/image_loss_std 0.29 / train/model_loss_mean 1.24 / train/model_loss_std 2.16 / 
train/model_opt_grad_norm 5.8 / train/model_opt_grad_steps 1.6e5 / train/model_opt_loss 9196.52 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.33 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.74 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.33 / train/policy_logprob_min -8.74 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.53 / train/policy_randomness_min 1.9e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.31 / train/post_ent_max 54.31 / train/post_ent_mean 39.35 / train/post_ent_min 
27.53 / train/post_ent_std 4.39 / train/prior_ent_mag 65.83 / train/prior_ent_max 65.83 / train/prior_ent_mean 40.56 / train/prior_ent_min 32.61 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.25 / train/reward_avg 1.3 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.3 / train/reward_rate 0.65 / 
train_stats/mean_log_entropy 0.6 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.5e-11 / report/cont_loss_std 5.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.78 / report/dyn_loss_std 3.86 / report/image_loss_mean 0.22 / report/image_loss_std 0.38 / report/model_loss_mean 1.35 / report/model_loss_std 2.59 / report/post_ent_mag 61.35 / report/post_ent_max 61.35 / 
report/post_ent_mean 39.25 / report/post_ent_min 26.51 / report/post_ent_std 4.93 / report/prior_ent_mag 65.35 / report/prior_ent_max 65.35 / report/prior_ent_mean 40.66 / report/prior_ent_min 31.68 / report/prior_ent_std 5.78 / report/rep_loss_mean 1.78 / 
report/rep_loss_std 3.86 / report/reward_avg 1.05 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.05 / report/reward_rate 0.53 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 6.6e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.89 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.95 / eval/post_ent_mag 52.92 / eval/post_ent_max 52.92 / eval/post_ent_mean 
37.39 / eval/post_ent_min 27.61 / eval/post_ent_std 3.2 / eval/prior_ent_mag 65.35 / eval/prior_ent_max 65.35 / eval/prior_ent_mean 38.51 / eval/prior_ent_min 30.75 / eval/prior_ent_std 4.61 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.89 / eval/reward_avg 1.73 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 2.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.73 / eval/reward_rate 0.87 / 
replay/size 3.3e5 / replay/inserts 3888 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3888 / timer/env.step_total 19.45 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.7 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.9e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7395 / timer/agent.policy_total 16.14 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.6e-3 / 
timer/dataset_train_count 1944 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1944 / timer/agent.train_total 246.34 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.7e-5 / timer/dataset_eval_frac 1.6e-7 / timer/dataset_eval_avg 4.7e-5 / timer/dataset_eval_min 4.7e-5 / timer/dataset_eval_max 4.7e-5 / fps 25.92

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 329500 Counter(329500) 329437
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T044503F986532-5zsYE9iXAJWOUy4LhOPRbJ-4sdea6GV3czSmrC5640lgc-1024.npz
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T044518F608922-7eF3KdEFFO05M3Cw2qKl08-5v0AbLazQA5RnDKVdTFElk-1024.npz
Starting evaluation at step 330000 Counter(330000) 329937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 330500 Counter(330500) 330437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T044638F738912-5v0AbLazQA5RnDKVdTFElk-3X3uxET9pGQV9EwybCGxsB-1024.npz
Starting evaluation at step 331000 Counter(331000) 330937
Saved chunk: 20230922T044622F439716-4sdea6GV3czSmrC5640lgc-6K4UYH1pJxbbg57WtsT4uG-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 331500 Counter(331500) 331437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T044758F266288-3X3uxET9pGQV9EwybCGxsB-0VFT64jwdEVo6WtpwztzaD-1024.npz
Starting evaluation at step 332000 Counter(332000) 331937
Saved chunk: 20230922T044815F919855-6K4UYH1pJxbbg57WtsT4uG-1157JuXwx2FM0NLZZpnrl6-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 332500 Counter(332500) 332437
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T044917F553274-0VFT64jwdEVo6WtpwztzaD-0uvV53miAJ0RBsWI3Hg275-1024.npz
Starting evaluation at step 333000 Counter(333000) 332937
Saved chunk: 20230922T044933F658767-1157JuXwx2FM0NLZZpnrl6-5fx0D9lKhFmT79UESkRe1w-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 666590 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / train/action_mag 4.17 / train/action_max 3.84 / train/action_mean 0.02 / train/action_min -4.09 / train/action_std 0.97 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -5.1 / train/adv_mag 0.52 / train/adv_max 0.39 / train/adv_mean 4e-4 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.23 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.16 / train/extr_critic_max 670.16 / train/extr_critic_mean 631.94 / train/extr_critic_min 467.58 / train/extr_critic_std 52.82 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.78 / train/extr_return_raw_max 667.78 / train/extr_return_raw_mean 632 / train/extr_return_raw_min 466.85 / train/extr_return_raw_std 52.9 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.34 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.19 / train/image_loss_std 0.29 / train/model_loss_mean 1.24 / train/model_loss_std 2.16 / 
train/model_opt_grad_norm 5.83 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 9210.94 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7395.83 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.36 / train/post_ent_max 54.36 / train/post_ent_mean 39.23 / train/post_ent_min
27.35 / train/post_ent_std 4.36 / train/prior_ent_mag 65.65 / train/prior_ent_max 65.65 / train/prior_ent_mean 40.44 / train/prior_ent_min 32.16 / train/prior_ent_std 5.46 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.23 / train/reward_avg 1.32 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.52 / report/cont_avg 1 / report/cont_loss_mean 7.4e-11 / report/cont_loss_std 1.1e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / report/dyn_loss_std 4.03 / report/image_loss_mean 0.23 / report/image_loss_std 0.34 / report/model_loss_mean 1.36 / report/model_loss_std 2.69 / report/post_ent_mag 50.96 / report/post_ent_max 50.96 / 
report/post_ent_mean 38.84 / report/post_ent_min 26.28 / report/post_ent_std 4.38 / report/prior_ent_mag 65.68 / report/prior_ent_max 65.68 / report/prior_ent_mean 40.1 / report/prior_ent_min 30.01 / report/prior_ent_std 5.57 / report/rep_loss_mean 1.77 / 
report/rep_loss_std 4.03 / report/reward_avg 1.13 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.2e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.13 / report/reward_rate 0.57 / eval/cont_avg 1 / eval/cont_loss_mean 2.9e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.59 / eval/dyn_loss_std 3.21 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.38 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.15 / eval/post_ent_mag 51.39 / eval/post_ent_max 51.39 / eval/post_ent_mean 
38.4 / eval/post_ent_min 27.94 / eval/post_ent_std 3.52 / eval/prior_ent_mag 65.68 / eval/prior_ent_max 65.68 / eval/prior_ent_mean 39.47 / eval/prior_ent_min 31.55 / eval/prior_ent_std 4.92 / eval/rep_loss_mean 1.59 / eval/rep_loss_std 3.21 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size
3.3e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3838 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.1 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.5e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.3 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.15 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 333500 Counter(333500) 333437
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T045036F834812-0uvV53miAJ0RBsWI3Hg275-4JMUrJhtjqteGWt8g46gMo-1024.npz
Starting evaluation at step 334000 Counter(334000) 333937
Saved chunk: 20230922T045051F369939-5fx0D9lKhFmT79UESkRe1w-2xHbQBX3aek57kSDaEMCPo-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 334500 Counter(334500) 334437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T045157F135360-4JMUrJhtjqteGWt8g46gMo-3V4XP6tANcoC1TwCQQ68CQ-1024.npz
Starting evaluation at step 335000 Counter(335000) 334937
Saved chunk: 20230922T045210F202675-2xHbQBX3aek57kSDaEMCPo-44ssoLxi3se3fSsUaqBxNY-1024.npz
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 335500 Counter(335500) 335437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 839.0.
Saved chunk: 20230922T045316F570975-3V4XP6tANcoC1TwCQQ68CQ-0LcVcFcsnsrl3T1r3loCJp-1024.npz
Starting evaluation at step 336000 Counter(336000) 335937
Saved chunk: 20230922T045328F071859-44ssoLxi3se3fSsUaqBxNY-59wtD7Xd5aNLlMdWAtv578-1024.npz
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 847.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 336500 Counter(336500) 336437
Saved chunk: 20230922T045435F875754-0LcVcFcsnsrl3T1r3loCJp-0000000000000000000000-628.npz
Saved chunk: 20230922T045445F778864-59wtD7Xd5aNLlMdWAtv578-0000000000000000000000-375.npz
eval_Episode has 500 steps and return 847.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T045435F875754-0LcVcFcsnsrl3T1r3loCJp-5fWbqkYgyTYR2H9tsDDTVP-1024.npz
Starting evaluation at step 337000 Counter(337000) 336937
Saved chunk: 20230922T045445F778864-59wtD7Xd5aNLlMdWAtv578-37NsKaebIGQHFRNAZJFYqF-1024.npz
eval_Episode has 500 steps and return 842.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 674258 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 842 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 4.24 / train/action_max 3.66 / train/action_mean 8.9e-3 / train/action_min -4.2 / train/action_std 0.97 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -3.14 / train/adv_mag 0.53 / train/adv_max 0.39 / train/adv_mean 2e-4 / train/adv_min -0.48 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.35 / train/extr_critic_max 671.35 / train/extr_critic_mean 632.7 / train/extr_critic_min 463.51 / train/extr_critic_std 53.44 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.84 / train/extr_return_raw_max 668.84 / train/extr_return_raw_mean 632.73 / train/extr_return_raw_min 464.92 / train/extr_return_raw_std 53.53
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.33 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.19 / train/image_loss_std 0.31 / train/model_loss_mean 1.24 / train/model_loss_std 2.18 / 
train/model_opt_grad_norm 5.86 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8619.79 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.39 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 1.2e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 54.08 / train/post_ent_max 54.08 / train/post_ent_mean 39.28 / train/post_ent_min 
27.09 / train/post_ent_std 4.34 / train/prior_ent_mag 65.63 / train/prior_ent_max 65.63 / train/prior_ent_mean 40.49 / train/prior_ent_min 32.23 / train/prior_ent_std 5.42 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.25 / train/reward_avg 1.31 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.31 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.55 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 3.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 2.97 / report/image_loss_mean 0.2 / report/image_loss_std 0.27 / report/model_loss_mean 1.25 / report/model_loss_std 1.97 / report/post_ent_mag 51.67 / report/post_ent_max 51.67 / 
report/post_ent_mean 40.7 / report/post_ent_min 32.88 / report/post_ent_std 4.66 / report/prior_ent_mag 65.48 / report/prior_ent_max 65.48 / report/prior_ent_mean 41.9 / report/prior_ent_min 34.78 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.62 / 
report/rep_loss_std 2.97 / report/reward_avg 1.21 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.21 / report/reward_rate 0.61 / eval/cont_avg 1 / eval/cont_loss_mean 3.7e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.84 / eval/dyn_loss_std 3.87 / eval/image_loss_mean 0.23 / eval/image_loss_std 0.41 / eval/model_loss_mean 1.42 / eval/model_loss_std 2.6 / eval/post_ent_mag 52.44 / eval/post_ent_max 52.44 / eval/post_ent_mean 
38.5 / eval/post_ent_min 27.16 / eval/post_ent_std 3.94 / eval/prior_ent_mag 65.48 / eval/prior_ent_max 65.48 / eval/prior_ent_mean 39.84 / eval/prior_ent_min 30.22 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 1.84 / eval/rep_loss_std 3.87 / eval/reward_avg 1.39 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.13 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.39 / eval/reward_rate 0.7 / replay/size
3.4e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.6e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3834 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.14 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.59 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.08 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / 
timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 337500 Counter(337500) 337437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T045555F394638-5fWbqkYgyTYR2H9tsDDTVP-1BaFzsbAyRaXVQTY1qdZ11-1024.npz
Starting evaluation at step 338000 Counter(338000) 337937
Saved chunk: 20230922T045603F754168-37NsKaebIGQHFRNAZJFYqF-7IgGX0nEMhh7UX0mQMqUJ0-1024.npz
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 338500 Counter(338500) 338437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T045715F834073-1BaFzsbAyRaXVQTY1qdZ11-1qXpH0egPvWohtpvjjOYvU-1024.npz
Starting evaluation at step 339000 Counter(339000) 338937
Saved chunk: 20230922T045722F655965-7IgGX0nEMhh7UX0mQMqUJ0-45HwuXCxo40nr0pdtwIVVt-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 339500 Counter(339500) 339437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T045835F291119-1qXpH0egPvWohtpvjjOYvU-0G3fEFftEaY7T9yH1JbEbS-1024.npz
Starting evaluation at step 340000 Counter(340000) 339937
Saved chunk: 20230922T045840F561191-45HwuXCxo40nr0pdtwIVVt-4vxuNgS9MehSuWEggzKhC6-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 340500 Counter(340500) 340437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T045954F589420-0G3fEFftEaY7T9yH1JbEbS-2z5Aq8WdF8ug8DVXx6ErFk-1024.npz
Starting evaluation at step 341000 Counter(341000) 340937
Saved chunk: 20230922T045958F269756-4vxuNgS9MehSuWEggzKhC6-4pfpONoi6oXFkYP8SqsB0M-1024.npz
eval_Episode has 500 steps and return 847.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 682002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / train/action_mag 4.23 / train/action_max 3.69 / train/action_mean 7.9e-3 / train/action_min -4.19 / train/action_std 0.97
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -3.62 / train/adv_mag 0.49 / train/adv_max 0.38 / train/adv_mean 2.5e-4 / train/adv_min -0.45 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 
/ train/dyn_loss_std 3.21 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.63 / train/extr_critic_max 671.63 / train/extr_critic_mean 634.77 / train/extr_critic_min 468.75 / train/extr_critic_std 51.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.33 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.37 / train/extr_return_raw_max 669.37 / train/extr_return_raw_mean 634.81 / train/extr_return_raw_min 468.69 / train/extr_return_raw_std 52.01
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.36 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.24 / train/model_loss_std 2.14 / 
train/model_opt_grad_norm 5.81 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 8788.66 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.7e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.18 / train/post_ent_max 54.18 / train/post_ent_mean 39.22 / train/post_ent_min
27.09 / train/post_ent_std 4.32 / train/prior_ent_mag 65.67 / train/prior_ent_max 65.67 / train/prior_ent_mean 40.43 / train/prior_ent_min 32.07 / train/prior_ent_std 5.43 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.21 / train/reward_avg 1.34 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.34 / train/reward_rate 0.67 / 
train_stats/mean_log_entropy 0.49 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.46 / report/image_loss_mean 0.22 / report/image_loss_std 0.47 / report/model_loss_mean 1.28 / report/model_loss_std 2.45 / report/post_ent_mag 51.96 / report/post_ent_max 51.96 / 
report/post_ent_mean 40.17 / report/post_ent_min 29.58 / report/post_ent_std 4.25 / report/prior_ent_mag 65.76 / report/prior_ent_max 65.76 / report/prior_ent_mean 41.33 / report/prior_ent_min 34.97 / report/prior_ent_std 5.3 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.46 / report/reward_avg 1.28 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 3.2e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 3.08 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.33 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.08 / eval/post_ent_mag 52.85 / eval/post_ent_max 52.85 / eval/post_ent_mean 
38.77 / eval/post_ent_min 31.5 / eval/post_ent_std 3.87 / eval/prior_ent_mag 65.76 / eval/prior_ent_max 65.76 / eval/prior_ent_mean 39.9 / eval/prior_ent_min 34.96 / eval/prior_ent_std 5.29 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.08 / eval/reward_avg 1.53 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.53 / eval/reward_rate 0.76 / replay/size
3.4e5 / replay/inserts 3872 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.48 / timer/env.step_count 3872 / timer/env.step_total 19.22 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.94 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.9e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7880 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1936 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1936 / timer/agent.train_total 245.68 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 341500 Counter(341500) 341437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 342000 Counter(342000) 341937
Saved chunk: 20230922T050115F885354-4pfpONoi6oXFkYP8SqsB0M-5wlGl0fjPtY7KO9dOWDOVw-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T050113F736929-2z5Aq8WdF8ug8DVXx6ErFk-4KOQRELW8zphYZyULF5SiG-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 342500 Counter(342500) 342437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 343000 Counter(343000) 342937
Saved chunk: 20230922T050234F814183-5wlGl0fjPtY7KO9dOWDOVw-0QKOYpXv8KpgsKRzFIrQ08-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T050237F642484-4KOQRELW8zphYZyULF5SiG-5ctZEZ3QYH7CY6vPWzo2kf-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 343500 Counter(343500) 343437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 344000 Counter(344000) 343937
Saved chunk: 20230922T050354F149242-0QKOYpXv8KpgsKRzFIrQ08-1LwiQMDL6HP5WeDQbJOoSo-1024.npz
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T050358F513618-5ctZEZ3QYH7CY6vPWzo2kf-57ejYKFWanurGV2dV5MSCb-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 344500 Counter(344500) 344437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 841.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 689738 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 841 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / train/action_mag 4.19 / train/action_max 3.77 / train/action_mean 0.02 / train/action_min -4.11 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -2.43 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 1.2e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.22 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.6 / train/extr_critic_max 672.6 / train/extr_critic_mean 635.93 / train/extr_critic_min 466.77 / train/extr_critic_std 51.86 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.89 / train/extr_return_raw_max 669.89 / train/extr_return_raw_mean 635.95 / train/extr_return_raw_min 467.97 / train/extr_return_raw_std 51.9 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.36 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.19 / train/image_loss_std 0.29 / train/model_loss_mean 1.24 / train/model_loss_std 2.15 / 
train/model_opt_grad_norm 5.98 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.42 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 2.2e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.8 / train/post_ent_max 53.8 / train/post_ent_mean 39.29 / train/post_ent_min 
27.83 / train/post_ent_std 4.28 / train/prior_ent_mag 65.61 / train/prior_ent_max 65.61 / train/prior_ent_mean 40.5 / train/prior_ent_min 32.45 / train/prior_ent_std 5.39 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.22 / train/reward_avg 1.34 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.34 / train/reward_rate 0.67 / 
train_stats/mean_log_entropy 0.49 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.77 / report/dyn_loss_std 3.88 / report/image_loss_mean 0.22 / report/image_loss_std 0.31 / report/model_loss_mean 1.35 / report/model_loss_std 2.54 / report/post_ent_mag 56.73 / report/post_ent_max 56.73 / 
report/post_ent_mean 39.09 / report/post_ent_min 15.33 / report/post_ent_std 5.45 / report/prior_ent_mag 65.6 / report/prior_ent_max 65.6 / report/prior_ent_mean 40.53 / report/prior_ent_min 22.44 / report/prior_ent_std 6.15 / report/rep_loss_mean 1.77 / 
report/rep_loss_std 3.88 / report/reward_avg 1.09 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-7 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.09 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.71 / eval/dyn_loss_std 4.07 / eval/image_loss_mean 0.22 / eval/image_loss_std 0.51 / eval/model_loss_mean 1.31 / eval/model_loss_std 2.85 / eval/post_ent_mag 52.24 / eval/post_ent_max 52.24 / eval/post_ent_mean 
40.03 / eval/post_ent_min 19.83 / eval/post_ent_std 4.58 / eval/prior_ent_mag 65.6 / eval/prior_ent_max 65.6 / eval/prior_ent_mean 41.21 / eval/prior_ent_min 35.13 / eval/prior_ent_std 5.59 / eval/rep_loss_mean 1.71 / eval/rep_loss_std 4.07 / eval/reward_avg 1.12 / 
eval/reward_loss_mean 0.07 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.8e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.12 / eval/reward_rate 0.56 / replay/size
3.4e5 / replay/inserts 3868 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3868 / timer/env.step_total 19.16 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.7 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.7e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7375 / timer/agent.policy_total 16.06 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6e-3 / 
timer/dataset_train_count 1934 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1934 / timer/agent.train_total 246.68 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.64 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.79

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 345000 Counter(345000) 344937
Saved chunk: 20230922T050511F744642-1LwiQMDL6HP5WeDQbJOoSo-0XnmqXMtTYCo9cajXcmiaF-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T050517F646155-57ejYKFWanurGV2dV5MSCb-2w7eZXbV5XznaDVY95Ly8p-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 345500 Counter(345500) 345437
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 346000 Counter(346000) 345937
Saved chunk: 20230922T050630F137386-0XnmqXMtTYCo9cajXcmiaF-0YzFi0G38fJ8s6fXmBXGRC-1024.npz
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T050637F626115-2w7eZXbV5XznaDVY95Ly8p-48W9xUoUdOvh0XJn1zs55Y-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 346500 Counter(346500) 346437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 347000 Counter(347000) 346937
Saved chunk: 20230922T050748F152294-0YzFi0G38fJ8s6fXmBXGRC-1rOT9iOSXXz6Lt42jaksol-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T050757F145971-48W9xUoUdOvh0XJn1zs55Y-2vP7rMpPtzt0i3q4fN9IXh-1024.npz
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 347500 Counter(347500) 347437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 348000 Counter(348000) 347937
Saved chunk: 20230922T050905F967329-1rOT9iOSXXz6Lt42jaksol-2db247jdXIuDDj3iepM0E1-1024.npz
eval_Episode has 500 steps and return 846.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T050916F523670-2vP7rMpPtzt0i3q4fN9IXh-0000000000000000000000-964.npz
Saved chunk: 20230922T051023F715500-2db247jdXIuDDj3iepM0E1-0000000000000000000000-111.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T050916F523670-2vP7rMpPtzt0i3q4fN9IXh-7x9l02DqqQG0Cv1TEnMxEN-1024.npz
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 348500 Counter(348500) 348437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 697406 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 846 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / train/action_mag 4.24 / train/action_max 4.03 / train/action_mean 0.03 / train/action_min -4.1 / train/action_std 1.02 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -0.83 / train/adv_mag 0.5 / train/adv_max 0.37 / train/adv_mean -5.2e-5 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.62 / 
train/dyn_loss_std 3.25 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.24 / train/extr_critic_max 671.24 / train/extr_critic_mean 632.47 / train/extr_critic_min 465.37 / train/extr_critic_std 53.58 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.76 / 
train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.68 / train/extr_return_raw_max 668.68 / train/extr_return_raw_mean 632.47 / train/extr_return_raw_min 466.02 / train/extr_return_raw_std 53.65
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.34 / train/extr_reward_min 0 / train/extr_reward_std 0.92 / train/image_loss_mean 0.19 / train/image_loss_std 0.3 / train/model_loss_mean 1.24 / train/model_loss_std 2.17 / 
train/model_opt_grad_norm 5.67 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.95 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.6e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.33 / train/post_ent_max 54.33 / train/post_ent_mean 39.29 / train/post_ent_min
27.31 / train/post_ent_std 4.27 / train/prior_ent_mag 65.57 / train/prior_ent_max 65.57 / train/prior_ent_mean 40.5 / train/prior_ent_min 32.42 / train/prior_ent_std 5.36 / train/rep_loss_mean 1.62 / train/rep_loss_std 3.25 / train/reward_avg 1.32 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.32 / train/reward_rate 0.66 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.72 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 5.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.91 / report/dyn_loss_std 4.33 / report/image_loss_mean 0.26 / report/image_loss_std 0.36 / report/model_loss_mean 1.48 / report/model_loss_std 2.83 / report/post_ent_mag 51.52 / report/post_ent_max 51.52 / 
report/post_ent_mean 39.9 / report/post_ent_min 23.78 / report/post_ent_std 4.56 / report/prior_ent_mag 65.51 / report/prior_ent_max 65.51 / report/prior_ent_mean 41.4 / report/prior_ent_min 30.3 / report/prior_ent_std 5.49 / report/rep_loss_mean 1.91 / 
report/rep_loss_std 4.33 / report/reward_avg 1.14 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.14 / report/reward_rate 0.58 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 3.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.66 / eval/dyn_loss_std 3.62 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.44 / eval/model_loss_mean 1.28 / eval/model_loss_std 2.53 / eval/post_ent_mag 51.15 / eval/post_ent_max 51.15 / eval/post_ent_mean 
37.99 / eval/post_ent_min 27.89 / eval/post_ent_std 3.7 / eval/prior_ent_mag 65.51 / eval/prior_ent_max 65.51 / eval/prior_ent_mean 39.11 / eval/prior_ent_min 35.3 / eval/prior_ent_std 5.03 / eval/rep_loss_mean 1.66 / eval/rep_loss_std 3.62 / eval/reward_avg 1.59 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 7.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.59 / eval/reward_rate 0.8 / 
replay/size 3.5e5 / replay/inserts 3834 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3834 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.03 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.71 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.12 / timer/agent.save_frac 3.9e-4 / timer/agent.save_avg 0.12 / timer/agent.save_min 0.12 / timer/agent.save_max 0.12 / timer/agent.policy_count 7842 / timer/agent.policy_total 17.42 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1917 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / 
timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1917 / timer/agent.train_total 243.07 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 9.9e-8 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 
3e-5 / timer/dataset_eval_max 3e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 349000 Counter(349000) 348937
Saved chunk: 20230922T051023F715500-2db247jdXIuDDj3iepM0E1-2D5nEP3ecwZl3A4xHV06dg-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T051036F084500-7x9l02DqqQG0Cv1TEnMxEN-0U8xfUGM9M1QDL54xLsYjI-1024.npz
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 349500 Counter(349500) 349437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 350000 Counter(350000) 349937
Saved chunk: 20230922T051142F698966-2D5nEP3ecwZl3A4xHV06dg-5lTka682X6vxzHLTdEHI6g-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T051156F435115-0U8xfUGM9M1QDL54xLsYjI-2ycI2MBGCctAuKFm6xGYbN-1024.npz
Starting evaluation at step 350500 Counter(350500) 350437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 351000 Counter(351000) 350937
Saved chunk: 20230922T051300F617961-5lTka682X6vxzHLTdEHI6g-3k19AfDrWw9091C0xdnku0-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T051315F857227-2ycI2MBGCctAuKFm6xGYbN-4hWYx7AIuIcTzn6jDcS7ga-1024.npz
Starting evaluation at step 351500 Counter(351500) 351437
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 352000 Counter(352000) 351937
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T051418F419789-3k19AfDrWw9091C0xdnku0-1dVYvgqQCAzTQyeqeYuw9c-1024.npz
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T051435F158875-4hWYx7AIuIcTzn6jDcS7ga-6nN6nF4l0Qbe3rnFdEcfVx-1024.npz
Starting evaluation at step 352500 Counter(352500) 352437
eval_Episode has 500 steps and return 847.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 705082 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / train/action_mag 4.25 / train/action_max 3.72 / train/action_mean 7.6e-3 / train/action_min -4.2 / train/action_std 0.97 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 1.7e5 / train/actor_opt_loss -3.77 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 2.7e-4 / train/adv_min -0.45 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.45 / train/extr_critic_max 671.45 / train/extr_critic_mean 635.94 / train/extr_critic_min 470.66 / train/extr_critic_std 50.49 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.31 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.02 / train/extr_return_raw_max 669.02 / train/extr_return_raw_mean 635.98 / train/extr_return_raw_min 472.59 / train/extr_return_raw_std 50.54
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.37 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.18 / train/image_loss_std 0.27 / train/model_loss_mean 1.23 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 6.14 / train/model_opt_grad_steps 1.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9843.75 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.37 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.62 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.37 / train/policy_logprob_min -8.62 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 1.4e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.39 / train/post_ent_max 54.39 / train/post_ent_mean 39.32 / train/post_ent_min
27.84 / train/post_ent_std 4.13 / train/prior_ent_mag 65.29 / train/prior_ent_max 65.29 / train/prior_ent_mean 40.52 / train/prior_ent_min 32.87 / train/prior_ent_std 5.24 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.13 / train/reward_avg 1.35 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.35 / train/reward_rate 0.68 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.46 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.8 / report/dyn_loss_std 4.37 / report/image_loss_mean 0.23 / report/image_loss_std 0.43 / report/model_loss_mean 1.39 / report/model_loss_std 2.96 / report/post_ent_mag 52.05 / report/post_ent_max 52.05 / 
report/post_ent_mean 39.3 / report/post_ent_min 26.69 / report/post_ent_std 4.16 / report/prior_ent_mag 65.28 / report/prior_ent_max 65.28 / report/prior_ent_mean 40.56 / report/prior_ent_min 28.85 / report/prior_ent_std 5.2 / report/rep_loss_mean 1.8 / 
report/rep_loss_std 4.37 / report/reward_avg 1.07 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.14 / report/reward_pred 1.07 / report/reward_rate 0.54 / eval/cont_avg 1 / eval/cont_loss_mean 2.6e-11 / eval/cont_loss_std 9.8e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.91 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.89 / eval/post_ent_mag 52.27 / eval/post_ent_max 52.27 / eval/post_ent_mean 39.34 / eval/post_ent_min 31.71 / 
eval/post_ent_std 4.03 / eval/prior_ent_mag 65.28 / eval/prior_ent_max 65.28 / eval/prior_ent_mean 40.29 / eval/prior_ent_min 35.58 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.91 / eval/reward_avg 1.36 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.36 / eval/reward_rate 0.68 / replay/size 3.5e5 / replay/inserts 3838 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3838 / timer/env.step_total 19.23 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.69 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 8.9e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.18 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.19 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 353000 Counter(353000) 352937
eval_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T051536F135897-1dVYvgqQCAzTQyeqeYuw9c-0Ne1yguw2DI0F9uxS0Tn3A-1024.npz
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T051554F419319-6nN6nF4l0Qbe3rnFdEcfVx-1T3TkkfV0cFBwfwH1j6Jiq-1024.npz
Starting evaluation at step 353500 Counter(353500) 353437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 848.0.
Starting evaluation at step 354000 Counter(354000) 353937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T051714F863813-1T3TkkfV0cFBwfwH1j6Jiq-00CDgFGVZ2xO42mg77aAvI-1024.npz
Starting evaluation at step 354500 Counter(354500) 354437
Saved chunk: 20230922T051654F944871-0Ne1yguw2DI0F9uxS0Tn3A-1wg5x23YgJBBKBmkSiyi7r-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 355000 Counter(355000) 354937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T051834F239522-00CDgFGVZ2xO42mg77aAvI-2FKjzjrG4dzeRMm7AGjeQH-1024.npz
Starting evaluation at step 355500 Counter(355500) 355437
Saved chunk: 20230922T051848F289986-1wg5x23YgJBBKBmkSiyi7r-1mwj3vcstb80kszEu2HNK0-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 356000 Counter(356000) 355937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T051953F487631-2FKjzjrG4dzeRMm7AGjeQH-7g2eYsZ5QY6KDwPiBJUC20-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 712858 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 847 / episode/reward_rate 0.85 / eval_episode/length 500 / eval_episode/score 848 / eval_episode/reward_rate 0.85 / train/action_mag 4.35 / train/action_max 4.13 / train/action_mean 0.03 / train/action_min -4.15 / train/action_std 1.03 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -1.71 / train/adv_mag 0.47 / train/adv_max 0.36 / train/adv_mean 3.3e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.7e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.01 / train/extr_critic_max 671.01 / train/extr_critic_mean 634.11 / train/extr_critic_min 468.07 / train/extr_critic_std 52.65 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.35 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.51 / train/extr_return_raw_max 668.51 / train/extr_return_raw_mean 634.11 / train/extr_return_raw_min 468.29 / train/extr_return_raw_std 52.7 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.36 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.23 / train/model_loss_std 2.12 / 
train/model_opt_grad_norm 5.56 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 9339.29 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7577.32 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.95 / train/policy_logprob_mag 8.92 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.92 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.7e-5 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.54 / train/post_ent_max 54.54 / train/post_ent_mean 39.27 / train/post_ent_min
27.49 / train/post_ent_std 4.15 / train/prior_ent_mag 65.52 / train/prior_ent_max 65.52 / train/prior_ent_mean 40.47 / train/prior_ent_min 32.68 / train/prior_ent_std 5.26 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.17 / train/reward_avg 1.35 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.35 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy 0.58 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.5 / report/dyn_loss_std 2.45 / report/image_loss_mean 0.16 / report/image_loss_std 0.33 / report/model_loss_mean 1.15 / report/model_loss_std 1.74 / report/post_ent_mag 53.29 / report/post_ent_max 53.29 / 
report/post_ent_mean 39.48 / report/post_ent_min 34.23 / report/post_ent_std 3.77 / report/prior_ent_mag 65.08 / report/prior_ent_max 65.08 / report/prior_ent_mean 40.51 / report/prior_ent_min 35.65 / report/prior_ent_std 5.04 / report/rep_loss_mean 1.5 / 
report/rep_loss_std 2.45 / report/reward_avg 1.52 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.52 / report/reward_rate 0.76 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 7.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.49 / eval/dyn_loss_std 2.65 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.76 / eval/post_ent_mag 53.36 / eval/post_ent_max 53.36 / eval/post_ent_mean 
38.56 / eval/post_ent_min 30.73 / eval/post_ent_std 3.5 / eval/prior_ent_mag 65.08 / eval/prior_ent_max 65.08 / eval/prior_ent_mean 39.6 / eval/prior_ent_min 35.69 / eval/prior_ent_std 4.9 / eval/rep_loss_mean 1.49 / eval/rep_loss_std 2.65 / eval/reward_avg 1.67 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.67 / eval/reward_rate 0.83 / 
replay/size 3.6e5 / replay/inserts 3888 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3888 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.61 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7395 / timer/agent.policy_total 16.39 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1944 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1944 / timer/agent.train_total 246.26 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.27 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.91

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 356500 Counter(356500) 356437
Saved chunk: 20230922T052005F929961-1mwj3vcstb80kszEu2HNK0-62LNeSfyuY0B7vrYxVa5NC-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 357000 Counter(357000) 356937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T052112F638448-7g2eYsZ5QY6KDwPiBJUC20-6v0DpCJa0ewQu6BhdMUQFs-1024.npz
Starting evaluation at step 357500 Counter(357500) 357437
Saved chunk: 20230922T052124F437428-62LNeSfyuY0B7vrYxVa5NC-7dqzSgoyVGNdzTp9OPIXUM-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 358000 Counter(358000) 357937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T052232F970365-6v0DpCJa0ewQu6BhdMUQFs-2TymWaydauqH9VGCnxrVMn-1024.npz
Starting evaluation at step 358500 Counter(358500) 358437
Saved chunk: 20230922T052242F330091-7dqzSgoyVGNdzTp9OPIXUM-5WBdiMU6JRTZJCSiOrJceE-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 359000 Counter(359000) 358937
eval_Episode has 500 steps and return 824.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T052352F275018-2TymWaydauqH9VGCnxrVMn-144DaDlgYajSbrZqX4zKoM-1024.npz
Starting evaluation at step 359500 Counter(359500) 359437
Saved chunk: 20230922T052400F125574-5WBdiMU6JRTZJCSiOrJceE-2h0B7O9oDWnDJMWGgdo32w-1024.npz
eval_Episode has 500 steps and return 847.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T052511F459310-144DaDlgYajSbrZqX4zKoM-0000000000000000000000-276.npz
Saved chunk: 20230922T052517F722449-2h0B7O9oDWnDJMWGgdo32w-0000000000000000000000-370.npz
train_Episode has 500 steps and return 845.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 360000 Counter(360000) 359937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 720538 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 846 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / train/action_mag 4.22 / train/action_max 3.76 / train/action_mean 0.01 / train/action_min -4.16 / train/action_std 0.97 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -3.11 / train/adv_mag 0.51 / train/adv_max 0.38 / train/adv_mean 1.9e-4 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.61 / 
train/dyn_loss_std 3.17 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.22 / train/extr_critic_max 671.22 / train/extr_critic_mean 635.58 / train/extr_critic_min 466.49 / train/extr_critic_std 51.03 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.68 / train/extr_return_raw_max 668.68 / train/extr_return_raw_mean 635.61 / train/extr_return_raw_min 469.22 / train/extr_return_raw_std 51.1 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.37 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / train/model_loss_mean 1.23 / train/model_loss_std 2.12 / 
train/model_opt_grad_norm 6.04 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.3e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 54.08 / train/post_ent_max 54.08 / train/post_ent_mean 39.24 / train/post_ent_min
27.63 / train/post_ent_std 4.15 / train/prior_ent_mag 65.16 / train/prior_ent_max 65.16 / train/prior_ent_mean 40.44 / train/prior_ent_min 32.71 / train/prior_ent_std 5.24 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.17 / train/reward_avg 1.35 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.35 / train/reward_rate 0.68 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.44 / report/cont_avg 1 / report/cont_loss_mean 2.3e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.5 / report/dyn_loss_std 2.88 / report/image_loss_mean 0.15 / report/image_loss_std 0.35 / report/model_loss_mean 1.15 / report/model_loss_std 2.03 / report/post_ent_mag 48.69 / report/post_ent_max 48.69 / 
report/post_ent_mean 37.77 / report/post_ent_min 31.99 / report/post_ent_std 3.22 / report/prior_ent_mag 65.29 / report/prior_ent_max 65.29 / report/prior_ent_mean 38.79 / report/prior_ent_min 35.37 / report/prior_ent_std 4.58 / report/rep_loss_mean 1.5 / 
report/rep_loss_std 2.88 / report/reward_avg 1.71 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.04 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.11 / report/reward_pred 1.71 / report/reward_rate 0.85 / eval/cont_avg 1 / eval/cont_loss_mean 4e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.46 / eval/dyn_loss_std 2.47 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.61 / eval/post_ent_mag 53.16 / eval/post_ent_max 53.16 / eval/post_ent_mean 37.86 / eval/post_ent_min 32.14 / 
eval/post_ent_std 3.5 / eval/prior_ent_mag 65.29 / eval/prior_ent_max 65.29 / eval/prior_ent_mean 38.88 / eval/prior_ent_min 35.49 / eval/prior_ent_std 4.87 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.47 / eval/reward_avg 1.66 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 4.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.66 / eval/reward_rate 0.83 / replay/size 3.6e5 / replay/inserts 
3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3840 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.24 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.18 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.33 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 3.9e-4 / 
timer/agent.train_count 1920 / timer/agent.train_total 243 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / 
timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max
3.5e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T052511F459310-144DaDlgYajSbrZqX4zKoM-47HL7BhIXw0f4o0bgdl0BE-1024.npz
Starting evaluation at step 360500 Counter(360500) 360437
Saved chunk: 20230922T052517F722449-2h0B7O9oDWnDJMWGgdo32w-2S3TIqCWXpzt2fgGChgMx8-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 361000 Counter(361000) 360937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T052631F848188-47HL7BhIXw0f4o0bgdl0BE-3cvSuUFsOZGOXGes2VJ5Xr-1024.npz
Starting evaluation at step 361500 Counter(361500) 361437
Saved chunk: 20230922T052636F591501-2S3TIqCWXpzt2fgGChgMx8-6SyKiXprIwbPuGpk1UeeJt-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 362000 Counter(362000) 361937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 362500 Counter(362500) 362437
Saved chunk: 20230922T052751F359005-3cvSuUFsOZGOXGes2VJ5Xr-3I5ZlnnUvTasZQmsdQie4D-1024.npz
Saved chunk: 20230922T052754F532444-6SyKiXprIwbPuGpk1UeeJt-29m0OF2lrRQK0X4FUAMVJy-1024.npz
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 363000 Counter(363000) 362937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 848.0.
Starting evaluation at step 363500 Counter(363500) 363437
Saved chunk: 20230922T052912F239624-29m0OF2lrRQK0X4FUAMVJy-2bpQX49drDwEDK1Ths5ZoJ-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T052910F647928-3I5ZlnnUvTasZQmsdQie4D-4nRRJNVF4JeydRI1DYuTJ4-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 364000 Counter(364000) 363937
eval_Episode has 500 steps and return 849.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 728218 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / train/action_mag 4.3 / train/action_max 3.88 / train/action_mean 9.3e-3 / train/action_min -4.25 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -3.46 / train/adv_mag 0.48 / train/adv_max 0.38 / train/adv_mean 2.1e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.13 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.97 / train/extr_critic_max 670.97 / train/extr_critic_mean 634.71 / train/extr_critic_min 467.3 / train/extr_critic_std 51.92 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.52 / train/extr_return_raw_max 668.52 / train/extr_return_raw_mean 634.74 / train/extr_return_raw_min 468.79 / train/extr_return_raw_std 51.97
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.38 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.23 / train/model_loss_std 2.09 / 
train/model_opt_grad_norm 5.94 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.4e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.92 / train/post_ent_max 53.92 / train/post_ent_mean 39 / train/post_ent_min 
27.69 / train/post_ent_std 4.19 / train/prior_ent_mag 65.12 / train/prior_ent_max 65.12 / train/prior_ent_mean 40.21 / train/prior_ent_min 32.57 / train/prior_ent_std 5.3 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.13 / train/reward_avg 1.36 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.36 / train/reward_rate 0.68 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.51 / report/cont_avg 1 / report/cont_loss_mean 1.3e-11 / report/cont_loss_std 4.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 4.04 / report/image_loss_mean 0.19 / report/image_loss_std 0.47 / report/model_loss_mean 1.27 / report/model_loss_std 2.8 / report/post_ent_mag 52.17 / report/post_ent_max 52.17 / 
report/post_ent_mean 37.64 / report/post_ent_min 25.65 / report/post_ent_std 3.49 / report/prior_ent_mag 65.14 / report/prior_ent_max 65.14 / report/prior_ent_mean 38.78 / report/prior_ent_min 31.68 / report/prior_ent_std 4.83 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 4.04 / report/reward_avg 1.56 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.56 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 2.3e-11 / eval/cont_loss_std 9.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.35 / eval/dyn_loss_std 1.96 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.04 / eval/model_loss_std 1.31 / eval/post_ent_mag 50.5 / eval/post_ent_max 50.5 / eval/post_ent_mean 37.1
/ eval/post_ent_min 32.53 / eval/post_ent_std 2.51 / eval/prior_ent_mag 65.14 / eval/prior_ent_max 65.14 / eval/prior_ent_mean 38.07 / eval/prior_ent_min 35.41 / eval/prior_ent_std 4.15 / eval/rep_loss_mean 1.35 / eval/rep_loss_std 1.96 / eval/reward_avg 1.91 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.02 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 3.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.91 / eval/reward_rate 0.96 / 
replay/size 3.6e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3840 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 7.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.15 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.9e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6e-3 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.33 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 364500 Counter(364500) 364437
Saved chunk: 20230922T053029F920904-2bpQX49drDwEDK1Ths5ZoJ-1vlCVW9ofnxuu7Zg2rlmR7-1024.npz
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T053033F260423-4nRRJNVF4JeydRI1DYuTJ4-0HcH3VQqRkzOmtduf2UEVI-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 365000 Counter(365000) 364937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 365500 Counter(365500) 365437
Saved chunk: 20230922T053148F551813-1vlCVW9ofnxuu7Zg2rlmR7-5vRvk7RcFji0mYG4Rk7xvt-1024.npz
eval_Episode has 500 steps and return 792.0.
Saved chunk: 20230922T053153F468657-0HcH3VQqRkzOmtduf2UEVI-7MR8tvPVJLa50OdjlOyMaW-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 366000 Counter(366000) 365937
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 366500 Counter(366500) 366437
Saved chunk: 20230922T053306F408356-5vRvk7RcFji0mYG4Rk7xvt-22kYjk0ONLi83hNXTkTT8h-1024.npz
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T053312F830819-7MR8tvPVJLa50OdjlOyMaW-5PfjdSM5qABQWUHEn4lsau-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 367000 Counter(367000) 366937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 821.0.
Starting evaluation at step 367500 Counter(367500) 367437
Saved chunk: 20230922T053424F133502-22kYjk0ONLi83hNXTkTT8h-74m5cRD8XfUh1qTEaTffGm-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T053432F120606-5PfjdSM5qABQWUHEn4lsau-4fRXB1eQgmGaiFL4CuvRvl-1024.npz
train_Episode has 500 steps and return 846.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 735998 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 846 / eval_episode/reward_rate 0.84 / train/action_mag 4.25 / train/action_max 3.89 / train/action_mean 7.2e-3 / train/action_min -4.16 / train/action_std 0.98
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -2.16 / train/adv_mag 0.47 / train/adv_max 0.36 / train/adv_mean 9.6e-5 / train/adv_min -0.42 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 /
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.26 / train/extr_critic_max 671.26 / train/extr_critic_mean 635.95 / train/extr_critic_min 466.38 / train/extr_critic_std 50.65 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.69 / train/extr_return_raw_max 668.69 / train/extr_return_raw_mean 635.97 / train/extr_return_raw_min 467.08 / train/extr_return_raw_std 50.72
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.37 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.77 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.79 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.79 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.6e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.41 / train/post_ent_max 53.41 / train/post_ent_mean 39.1 / train/post_ent_min 
28.12 / train/post_ent_std 4.22 / train/prior_ent_mag 65.07 / train/prior_ent_max 65.07 / train/prior_ent_mean 40.29 / train/prior_ent_min 33.03 / train/prior_ent_std 5.33 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.1 / train/reward_avg 1.36 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.35 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy 0.43 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.1e-11 / report/cont_loss_std 2.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.57 / report/image_loss_mean 0.2 / report/image_loss_std 0.33 / report/model_loss_mean 1.3 / report/model_loss_std 2.38 / report/post_ent_mag 51.18 / report/post_ent_max 51.18 / 
report/post_ent_mean 38.07 / report/post_ent_min 24.09 / report/post_ent_std 3.85 / report/prior_ent_mag 64.65 / report/prior_ent_max 64.65 / report/prior_ent_mean 39.36 / report/prior_ent_min 31.8 / report/prior_ent_std 4.93 / report/rep_loss_mean 1.69 / 
report/rep_loss_std 3.57 / report/reward_avg 1.42 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.42 / report/reward_rate 0.71 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.45 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.6 / eval/post_ent_mag 51.68 / eval/post_ent_max 51.68 / eval/post_ent_mean 
38.95 / eval/post_ent_min 29.45 / eval/post_ent_std 3.99 / eval/prior_ent_mag 64.65 / eval/prior_ent_max 64.65 / eval/prior_ent_mean 39.95 / eval/prior_ent_min 35.08 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.45 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.1 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.5 / eval/reward_rate 0.75 / 
replay/size 3.7e5 / replay/inserts 3890 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3890 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.91 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.25 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.1e-3 / 
timer/dataset_train_count 1945 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.41 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.92

Starting evaluation at step 368000 Counter(368000) 367937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 368500 Counter(368500) 368437
Saved chunk: 20230922T053541F761195-74m5cRD8XfUh1qTEaTffGm-0dNVzs7taDGYFr6t5aFMz9-1024.npz
eval_Episode has 500 steps and return 828.0.
Saved chunk: 20230922T053551F283782-4fRXB1eQgmGaiFL4CuvRvl-6MF2wd43FSUWCTikcVTlWf-1024.npz
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 369000 Counter(369000) 368937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 369500 Counter(369500) 369437
Saved chunk: 20230922T053700F673981-0dNVzs7taDGYFr6t5aFMz9-6yxmdEwlXTUqIvKmQRU5GF-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T053711F792431-6MF2wd43FSUWCTikcVTlWf-0s2KJgnUmLgBHh1nGqyea3-1024.npz
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 370000 Counter(370000) 369937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 370500 Counter(370500) 370437
Saved chunk: 20230922T053818F574712-6yxmdEwlXTUqIvKmQRU5GF-4wph1aLl23nZXTYclUqxmW-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T053831F241188-0s2KJgnUmLgBHh1nGqyea3-7ldw2Vib8AS6LHFleeN3AE-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 371000 Counter(371000) 370937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 846.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T053950F586800-7ldw2Vib8AS6LHFleeN3AE-0000000000000000000000-612.npz
Saved chunk: 20230922T053936F389195-4wph1aLl23nZXTYclUqxmW-0000000000000000000000-629.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 371500 Counter(371500) 371437
Saved chunk: 20230922T053936F389195-4wph1aLl23nZXTYclUqxmW-2JzNyArHCpTEy8osbTirLq-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T053950F586800-7ldw2Vib8AS6LHFleeN3AE-08gr4BR7qRxAc12fsZuURm-1024.npz
train_Episode has 500 steps and return 843.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 743662 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / eval_stats/mean_log_entropy 0 / train/action_mag 4.27 / train/action_max 3.8 / train/action_mean 0.01 / train/action_min 
-4.21 / train/action_std 0.98 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.8e5 / train/actor_opt_loss -4.21 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 
3.2e-4 / train/adv_min -0.44 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / 
train/dyn_loss_mean 1.61 / train/dyn_loss_std 3.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.8e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 671.27 / train/extr_critic_max 671.27 / train/extr_critic_mean 634.44 / train/extr_critic_min 466.65 / train/extr_critic_std 52.02 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / 
train/extr_return_normed_mean 0.77 / train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.19 / train/extr_return_raw_max 669.19 / train/extr_return_raw_mean 634.48 / train/extr_return_raw_min 
469.26 / train/extr_return_raw_std 52.08 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.35 / train/extr_reward_min 0 / train/extr_reward_std 0.91 / train/image_loss_mean 0.19 / train/image_loss_std 0.29 / train/model_loss_mean 1.23 / 
train/model_loss_std 2.11 / train/model_opt_grad_norm 5.97 / train/model_opt_grad_steps 1.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 
1.42 / train/policy_entropy_mean 0.37 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.83 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.37 / train/policy_logprob_min -8.83 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 2.2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.86 / train/post_ent_max 53.86 / train/post_ent_mean 39.06 / train/post_ent_min
27.95 / train/post_ent_std 4.28 / train/prior_ent_mag 64.94 / train/prior_ent_max 64.94 / train/prior_ent_mean 40.26 / train/prior_ent_min 32.49 / train/prior_ent_std 5.35 / train/rep_loss_mean 1.61 / train/rep_loss_std 3.16 / train/reward_avg 1.33 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.11 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.33 / train/reward_rate 0.67 / 
train_stats/mean_log_entropy 0.37 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.57 / report/image_loss_mean 0.21 / report/image_loss_std 0.31 / report/model_loss_mean 1.29 / report/model_loss_std 2.39 / report/post_ent_mag 52.61 / report/post_ent_max 52.61 / report/post_ent_mean 40.95 / 
report/post_ent_min 27.5 / report/post_ent_std 4.77 / report/prior_ent_mag 64.36 / report/prior_ent_max 64.36 / report/prior_ent_mean 42.16 / report/prior_ent_min 34.91 / report/prior_ent_std 5.62 / report/rep_loss_mean 1.69 / report/rep_loss_std 3.57 / report/reward_avg 
1.04 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.04 / 
report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 8.1e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.43 / 
eval/dyn_loss_std 2.02 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.16 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.32 / eval/post_ent_mag 52.1 / eval/post_ent_max 52.1 / eval/post_ent_mean 38.68 / eval/post_ent_min 31.56 / eval/post_ent_std 3.84 / 
eval/prior_ent_mag 64.36 / eval/prior_ent_max 64.36 / eval/prior_ent_mean 39.61 / eval/prior_ent_min 35.11 / eval/prior_ent_std 5.09 / eval/rep_loss_mean 1.43 / eval/rep_loss_std 2.02 / eval/reward_avg 1.62 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.04 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.5e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size 3.7e5 / replay/inserts 3832 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3832 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.12 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.89 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.1e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.49 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.15 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 2.4e-4 / timer/agent.train_count 1916 / 
timer/agent.train_total 242.44 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.16 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 372000 Counter(372000) 371937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 372500 Counter(372500) 372437
Saved chunk: 20230922T054054F247415-2JzNyArHCpTEy8osbTirLq-1q86iEGMCb6PdXKrWvZvtS-1024.npz
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T054110F006595-08gr4BR7qRxAc12fsZuURm-4efdnTOsPc7BgWYUCk8Zrc-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 373000 Counter(373000) 372937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 373500 Counter(373500) 373437
Saved chunk: 20230922T054213F110619-1q86iEGMCb6PdXKrWvZvtS-3wEQykzsG90mfxsc2AV6cU-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T054230F452737-4efdnTOsPc7BgWYUCk8Zrc-6g6Rjwh6uVb6wfrl0djtS4-1024.npz
Starting evaluation at step 374000 Counter(374000) 373937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 826.0.
Starting evaluation at step 374500 Counter(374500) 374437
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T054330F904122-3wEQykzsG90mfxsc2AV6cU-6zvD0WBwgVAIXdvfGWOHCr-1024.npz
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T054349F829628-6g6Rjwh6uVb6wfrl0djtS4-7xBJiHdyr7mOon7eUz4N1r-1024.npz
Starting evaluation at step 375000 Counter(375000) 374937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 375500 Counter(375500) 375437
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T054448F702135-6zvD0WBwgVAIXdvfGWOHCr-1zGP22tIjZTjIGs8j6dipw-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 751342 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / train/action_mag 4.27 / train/action_max 4.06 / train/action_mean 0.01 / train/action_min -4.1 / train/action_std 1.01 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -1.48 / train/adv_mag 0.46 / train/adv_max 0.36 / train/adv_mean 7.2e-6 / train/adv_min -0.4 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 3.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3.08 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.22 / train/extr_critic_max 671.22 / train/extr_critic_mean 637.04 / train/extr_critic_min 468.75 / train/extr_critic_std 49.8 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.93 / train/extr_return_raw_max 668.93 / train/extr_return_raw_mean 637.04 / train/extr_return_raw_min 471.32 / train/extr_return_raw_std 49.84
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.05 / 
train/model_opt_grad_norm 5.58 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 9309.58 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7708.33 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.87 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.87 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.2e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.49 / train/post_ent_max 53.49 / train/post_ent_mean 38.76 / train/post_ent_min 
27.62 / train/post_ent_std 4.3 / train/prior_ent_mag 64.74 / train/prior_ent_max 64.74 / train/prior_ent_mean 39.93 / train/prior_ent_min 32.2 / train/prior_ent_std 5.37 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.08 / train/reward_avg 1.37 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.68 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 9.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.58 / report/image_loss_mean 0.2 / report/image_loss_std 0.26 / report/model_loss_mean 1.26 / report/model_loss_std 2.33 / report/post_ent_mag 50.76 / report/post_ent_max 50.76 / 
report/post_ent_mean 40.28 / report/post_ent_min 25.43 / report/post_ent_std 4.68 / report/prior_ent_mag 64.5 / report/prior_ent_max 64.5 / report/prior_ent_mean 41.48 / report/prior_ent_min 34.85 / report/prior_ent_std 5.59 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 3.58 / report/reward_avg 1.1 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.6e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.1 / report/reward_rate 0.55 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 3.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.39 / eval/dyn_loss_std 1.85 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.12 / eval/model_loss_mean 1.07 / eval/model_loss_std 1.25 / eval/post_ent_mag 50.71 / eval/post_ent_max 50.71 / eval/post_ent_mean 37.66 / eval/post_ent_min 30.65 / 
eval/post_ent_std 4.01 / eval/prior_ent_mag 64.5 / eval/prior_ent_max 64.5 / eval/prior_ent_mean 38.72 / eval/prior_ent_min 34.94 / eval/prior_ent_std 5.36 / eval/rep_loss_mean 1.39 / eval/rep_loss_std 1.85 / eval/reward_avg 1.67 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 7.7e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.67 / eval/reward_rate 0.83 / replay/size 3.8e5 / replay/inserts 3840 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3840 / timer/env.step_total 19.08 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.86 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.3e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.15 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.3e-3 / timer/dataset_train_count 
1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.47 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T054509F094417-7xBJiHdyr7mOon7eUz4N1r-6vGqFTJZ8iWpeOyiZXLag2-1024.npz
Starting evaluation at step 376000 Counter(376000) 375937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 807.0.
Starting evaluation at step 376500 Counter(376500) 376437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T054629F205894-6vGqFTJZ8iWpeOyiZXLag2-5B9czeO8OLrEyMCsSXHS2P-1024.npz
Starting evaluation at step 377000 Counter(377000) 376937
Saved chunk: 20230922T054606F338682-1zGP22tIjZTjIGs8j6dipw-3kQKufg7G1mstWGDowAE5P-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 377500 Counter(377500) 377437
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T054748F712955-5B9czeO8OLrEyMCsSXHS2P-424DldiTR2eixYA9ymAMKQ-1024.npz
Starting evaluation at step 378000 Counter(378000) 377937
Saved chunk: 20230922T054800F660829-3kQKufg7G1mstWGDowAE5P-6QUYvO2CCVZwdNkp32K4va-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 378500 Counter(378500) 378437
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T054908F034133-424DldiTR2eixYA9ymAMKQ-1cJYrokv7dFaPJBH1f4AXp-1024.npz
Starting evaluation at step 379000 Counter(379000) 378937
Saved chunk: 20230922T054918F441636-6QUYvO2CCVZwdNkp32K4va-6znSExPOGfYikM1jPzKJkL-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 379500 Counter(379500) 379437
eval_Episode has 500 steps and return 849.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 759026 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / train/action_mag 4.24 / train/action_max 3.82 / train/action_mean 0.01 / train/action_min -4.17 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -3.4 / train/adv_mag 0.66 / train/adv_max 0.56 / train/adv_mean 2.2e-4 / train/adv_min -0.51 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.14 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.18 / train/extr_critic_max 671.18 / train/extr_critic_mean 636.65 / train/extr_critic_min 442.16 / train/extr_critic_std 50.33 / train/extr_return_normed_mag 1.05 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.14 / train/extr_return_raw_max 669.14 / train/extr_return_raw_mean 636.68 / train/extr_return_raw_min 457.62 / train/extr_return_raw_std 50.32
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.27 / train/model_loss_mean 1.22 / train/model_loss_std 2.09 / 
train/model_opt_grad_norm 5.6 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9687.5 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.42 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.81 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.81 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 8.1e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.57 / train/post_ent_max 53.57 / train/post_ent_mean 38.66 / train/post_ent_min 
27.92 / train/post_ent_std 4.4 / train/prior_ent_mag 64.82 / train/prior_ent_max 64.82 / train/prior_ent_mean 39.86 / train/prior_ent_min 32.61 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.14 / train/reward_avg 1.37 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.36 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy 0.51 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 8.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.58 / report/image_loss_mean 0.2 / report/image_loss_std 0.29 / report/model_loss_mean 1.27 / report/model_loss_std 2.37 / report/post_ent_mag 51.04 / report/post_ent_max 51.04 / 
report/post_ent_mean 39.91 / report/post_ent_min 27.19 / report/post_ent_std 4.78 / report/prior_ent_mag 64.82 / report/prior_ent_max 64.82 / report/prior_ent_mean 41.08 / report/prior_ent_min 30.9 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.58 / report/reward_avg 0.99 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.7e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 0.99 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / eval/cont_pred 1
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.37 / eval/dyn_loss_std 1.95 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.06 / eval/model_loss_std 1.29 / eval/post_ent_mag 51.73 / eval/post_ent_max 51.73 / eval/post_ent_mean 37.19 / 
eval/post_ent_min 31.45 / eval/post_ent_std 3.32 / eval/prior_ent_mag 64.82 / eval/prior_ent_max 64.82 / eval/prior_ent_mean 37.94 / eval/prior_ent_min 34.23 / eval/prior_ent_std 4.69 / eval/rep_loss_mean 1.37 / eval/rep_loss_std 1.95 / eval/reward_avg 1.87 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.03 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.5e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.87 / eval/reward_rate 0.94 / replay/size
3.8e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3842 / timer/env.step_total 19.24 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.41 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.15 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.12 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T055027F222007-1cJYrokv7dFaPJBH1f4AXp-1ip9Zniz7kkAP6NK7LeM7k-1024.npz
Starting evaluation at step 380000 Counter(380000) 379937
Saved chunk: 20230922T055036F028196-6znSExPOGfYikM1jPzKJkL-2FZvlYmhoI6JWy4fJgQqvb-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 380500 Counter(380500) 380437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T055147F395325-1ip9Zniz7kkAP6NK7LeM7k-4RKptOKIyJh9ERPo7vryuy-1024.npz
Starting evaluation at step 381000 Counter(381000) 380937
Saved chunk: 20230922T055154F710566-2FZvlYmhoI6JWy4fJgQqvb-3zAXoKhB5NAijJ1ayzH0QN-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 381500 Counter(381500) 381437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T055306F771752-4RKptOKIyJh9ERPo7vryuy-05vmnQNFKPlgPPPeonfhf8-1024.npz
Starting evaluation at step 382000 Counter(382000) 381937
Saved chunk: 20230922T055312F493226-3zAXoKhB5NAijJ1ayzH0QN-09xQtYWK84HjgGwI5bSLyU-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 382500 Counter(382500) 382437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 844.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T055430F263286-09xQtYWK84HjgGwI5bSLyU-0000000000000000000000-888.npz
Saved chunk: 20230922T055426F091114-05vmnQNFKPlgPPPeonfhf8-0000000000000000000000-948.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T055426F091114-05vmnQNFKPlgPPPeonfhf8-0ditbOvuofnLiCXXmH1mmM-1024.npz
Starting evaluation at step 383000 Counter(383000) 382937
Saved chunk: 20230922T055430F263286-09xQtYWK84HjgGwI5bSLyU-3bU25zhFvjqk7P8JYlSIqC-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 766794 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / train/action_mag 4.21 / train/action_max 3.98 / train/action_mean 0.02 / train/action_min -4.01 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -13.1 / train/adv_mag 0.63 / train/adv_max 0.56 / train/adv_mean 1.2e-3 / train/adv_min -0.42 / 
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 4.2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.11 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.79 / train/extr_critic_max 671.79 / train/extr_critic_mean 634.08 / train/extr_critic_min 405.12 / train/extr_critic_std 56.99 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.32 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.87 / train/extr_return_raw_max 669.87 / train/extr_return_raw_mean 634.29 / train/extr_return_raw_min 428.92 / train/extr_return_raw_std 56.67
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.07 / 
train/model_opt_grad_norm 5.56 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 9029.81 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.94 / train/post_ent_max 52.94 / train/post_ent_mean 38.51 / train/post_ent_min 
27.91 / train/post_ent_std 4.53 / train/prior_ent_mag 64.66 / train/prior_ent_max 64.66 / train/prior_ent_mean 39.7 / train/prior_ent_min 32.28 / train/prior_ent_std 5.59 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.1 / train/reward_avg 1.37 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.54 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 1.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.48 / report/dyn_loss_std 2.97 / report/image_loss_mean 0.15 / report/image_loss_std 0.19 / report/model_loss_mean 1.13 / report/model_loss_std 1.92 / report/post_ent_mag 51.73 / report/post_ent_max 51.73 / 
report/post_ent_mean 38.45 / report/post_ent_min 28.74 / report/post_ent_std 4.03 / report/prior_ent_mag 64.49 / report/prior_ent_max 64.49 / report/prior_ent_mean 39.47 / report/prior_ent_min 33.88 / report/prior_ent_std 5.17 / report/rep_loss_mean 1.48 / 
report/rep_loss_std 2.97 / report/reward_avg 1.55 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 4.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.55 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 2.7e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.39 / eval/dyn_loss_std 2.31 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.11 / eval/model_loss_mean 1.06 / eval/model_loss_std 1.45 / eval/post_ent_mag 52.47 / eval/post_ent_max 52.47 / eval/post_ent_mean 
37.59 / eval/post_ent_min 31 / eval/post_ent_std 4.22 / eval/prior_ent_mag 64.49 / eval/prior_ent_max 64.49 / eval/prior_ent_mean 38.55 / eval/prior_ent_min 33.83 / eval/prior_ent_std 5.37 / eval/rep_loss_mean 1.39 / eval/rep_loss_std 2.31 / eval/reward_avg 1.66 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 1.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.66 / eval/reward_rate 0.83 / 
replay/size 3.8e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3884 / timer/env.step_total 19.37 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.2e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.14 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.9e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.43 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.05 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 383500 Counter(383500) 383437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 384000 Counter(384000) 383937
Saved chunk: 20230922T055545F503236-0ditbOvuofnLiCXXmH1mmM-5iROp7HM2xvxh2x2XLUsQj-1024.npz
Saved chunk: 20230922T055548F120254-3bU25zhFvjqk7P8JYlSIqC-1eJdXcIVlIWa3MnF9eEerM-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 384500 Counter(384500) 384437
eval_Episode has 500 steps and return 832.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 385000 Counter(385000) 384937
Saved chunk: 20230922T055707F017893-1eJdXcIVlIWa3MnF9eEerM-4P14wpBmn1pJllYwez9Ovv-1024.npz
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T055705F963337-5iROp7HM2xvxh2x2XLUsQj-0WKELGmEypfcQJOre64o6g-1024.npz
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 385500 Counter(385500) 385437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 386000 Counter(386000) 385937
Saved chunk: 20230922T055824F894629-4P14wpBmn1pJllYwez9Ovv-73FBVj02OWnUyI6pm2E4Dn-1024.npz
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T055828F775043-0WKELGmEypfcQJOre64o6g-6KJgs4gMoiL8FpDeIN0rBP-1024.npz
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 386500 Counter(386500) 386437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 387000 Counter(387000) 386937
Saved chunk: 20230922T055942F687733-73FBVj02OWnUyI6pm2E4Dn-45v1BFpIqj6NuSOq0VPoZg-1024.npz
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T055948F143396-6KJgs4gMoiL8FpDeIN0rBP-1nyRVgHXperXF486w0X7ba-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 774470 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 843 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 833 / episode/reward_rate 0.83 / train/action_mag 4.32 / train/action_max 3.74 / train/action_mean 7.2e-3 / train/action_min -4.27 / train/action_std 0.98
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -7.38 / train/adv_mag 0.5 / train/adv_max 0.36 / train/adv_mean 6.3e-4 / train/adv_min -0.44 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.71 / train/extr_critic_max 672.71 / train/extr_critic_mean 637.17 / train/extr_critic_min 462.2 / train/extr_critic_std 51.95 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.77 / train/extr_return_raw_max 670.77 / train/extr_return_raw_mean 637.27 / train/extr_return_raw_min 464.44 / train/extr_return_raw_std 51.93
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.04 / 
train/model_opt_grad_norm 5.73 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.39 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.39 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.55 / train/policy_randomness_min 1.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.66 / train/post_ent_max 53.66 / train/post_ent_mean 38.29 / train/post_ent_min
27.6 / train/post_ent_std 4.55 / train/prior_ent_mag 64.64 / train/prior_ent_max 64.64 / train/prior_ent_mean 39.47 / train/prior_ent_min 31.79 / train/prior_ent_std 5.63 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.05 / train/reward_avg 1.37 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.28 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.73 / report/image_loss_mean 0.15 / report/image_loss_std 0.23 / report/model_loss_mean 1.15 / report/model_loss_std 1.79 / report/post_ent_mag 50.65 / report/post_ent_max 50.65 / 
report/post_ent_mean 37.52 / report/post_ent_min 31.63 / report/post_ent_std 4.35 / report/prior_ent_mag 64.67 / report/prior_ent_max 64.67 / report/prior_ent_mean 38.66 / report/prior_ent_min 33.51 / report/prior_ent_std 5.61 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 2.73 / report/reward_avg 1.57 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.57 / report/reward_rate 0.79 / eval/cont_avg 1 / eval/cont_loss_mean 2.1e-11 / eval/cont_loss_std 5.9e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 2.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.39 / eval/dyn_loss_std 2.19 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.14 / eval/model_loss_mean 1.06 / eval/model_loss_std 1.41 / eval/post_ent_mag 52.44 / eval/post_ent_max 52.44 / eval/post_ent_mean 
36.68 / eval/post_ent_min 31.69 / eval/post_ent_std 3.36 / eval/prior_ent_mag 64.67 / eval/prior_ent_max 64.67 / eval/prior_ent_mean 37.66 / eval/prior_ent_min 33.67 / eval/prior_ent_std 4.73 / eval/rep_loss_mean 1.39 / eval/rep_loss_std 2.19 / eval/reward_avg 1.86 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.86 / eval/reward_rate 0.93 / replay/size 
3.9e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3838 / timer/env.step_total 19.15 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 3.7e-3 / timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.46 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.9e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.15 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 387500 Counter(387500) 387437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 388000 Counter(388000) 387937
Saved chunk: 20230922T060100F263742-45v1BFpIqj6NuSOq0VPoZg-27nO1tpSCtF2KzIsmCIff3-1024.npz
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T060107F209860-1nyRVgHXperXF486w0X7ba-6iNorU7SgLcCHL8QRTP3aD-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 388500 Counter(388500) 388437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 389000 Counter(389000) 388937
Saved chunk: 20230922T060219F039264-27nO1tpSCtF2KzIsmCIff3-3OfLt8TOp7TXqp8ciYkGHm-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T060227F590495-6iNorU7SgLcCHL8QRTP3aD-54LFCoOd2nfAz8iIIaINkM-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 389500 Counter(389500) 389437
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 390000 Counter(390000) 389937
Saved chunk: 20230922T060336F813234-3OfLt8TOp7TXqp8ciYkGHm-4ozXprR8vdCxQmxcLgNtLT-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T060346F892857-54LFCoOd2nfAz8iIIaINkM-76wYyzDfodtl0TUXZ8IMaN-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 390500 Counter(390500) 390437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 391000 Counter(391000) 390937
Saved chunk: 20230922T060454F480805-4ozXprR8vdCxQmxcLgNtLT-0Ut15H5kym0tAxTaWMj1l6-1024.npz
eval_Episode has 500 steps and return 849.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 782154 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / train/action_mag 4.3 / train/action_max 4.16 / train/action_mean 0.03 / train/action_min -4.08 / train/action_std 1.03 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 1.9e5 / train/actor_opt_loss -1.49 / train/adv_mag 0.47 / train/adv_max 0.34 / train/adv_mean 1.3e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 1.9e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.78 / train/extr_critic_max 672.78 / train/extr_critic_mean 637.14 / train/extr_critic_min 472.37 / train/extr_critic_std 51.19 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.36 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 670.35 / train/extr_return_raw_max 670.35 / train/extr_return_raw_mean 637.14 / train/extr_return_raw_min 471.54 / train/extr_return_raw_std 51.2 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.36 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.61 / train/model_opt_grad_steps 1.9e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.94 / train/policy_logprob_mag 8.87 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.87 / train/policy_logprob_std 1.18 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 6.2e-6 / train/policy_randomness_std 0.41 / train/post_ent_mag 54.17 / train/post_ent_max 54.17 / train/post_ent_mean 38.44 / train/post_ent_min
27.84 / train/post_ent_std 4.68 / train/prior_ent_mag 64.69 / train/prior_ent_max 64.69 / train/prior_ent_mean 39.63 / train/prior_ent_min 31.89 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.34 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.34 / train/reward_rate 0.67 / 
train_stats/mean_log_entropy 0.73 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 8.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 3.02 / report/image_loss_mean 0.17 / report/image_loss_std 0.25 / report/model_loss_mean 1.2 / report/model_loss_std 1.99 / report/post_ent_mag 50.27 / report/post_ent_max 50.27 / 
report/post_ent_mean 37.37 / report/post_ent_min 23.12 / report/post_ent_std 4.23 / report/prior_ent_mag 64.37 / report/prior_ent_max 64.37 / report/prior_ent_mean 38.47 / report/prior_ent_min 33.53 / report/prior_ent_std 5.26 / report/rep_loss_mean 1.57 / 
report/rep_loss_std 3.02 / report/reward_avg 1.54 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.55 / report/reward_rate 0.77 / eval/cont_avg 1 / eval/cont_loss_mean 7.7e-11 / eval/cont_loss_std 1.4e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.7e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.42 / eval/dyn_loss_std 2.07 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.37 / eval/post_ent_mag 51.81 / eval/post_ent_max 51.81 / eval/post_ent_mean 37.83 / 
eval/post_ent_min 29.21 / eval/post_ent_std 4.27 / eval/prior_ent_mag 64.37 / eval/prior_ent_max 64.37 / eval/prior_ent_mean 38.81 / eval/prior_ent_min 33.4 / eval/prior_ent_std 5.36 / eval/rep_loss_mean 1.42 / eval/rep_loss_std 2.07 / eval/reward_avg 1.64 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.64 / eval/reward_rate 0.82 / replay/size
3.9e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3842 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.58 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.3 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.03 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.6e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / timer/dataset_eval_max 2.9e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T060506F056882-76wYyzDfodtl0TUXZ8IMaN-6UoX8hCVaalB99lVoU5s55-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 391500 Counter(391500) 391437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 392000 Counter(392000) 391937
Saved chunk: 20230922T060612F023754-0Ut15H5kym0tAxTaWMj1l6-26pav0SAITiyzpjM4DokuZ-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T060626F152615-6UoX8hCVaalB99lVoU5s55-2k7ADvMlr72ERbhEndqWgX-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 392500 Counter(392500) 392437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 393000 Counter(393000) 392937
Saved chunk: 20230922T060730F937959-26pav0SAITiyzpjM4DokuZ-3jZRjdIeK3o6X7DJBBhL2K-1024.npz
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T060745F718233-2k7ADvMlr72ERbhEndqWgX-55xKSEfEJH2bE3iGPejeo3-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 393500 Counter(393500) 393437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 394000 Counter(394000) 393937
Saved chunk: 20230922T060848F798824-3jZRjdIeK3o6X7DJBBhL2K-3GWGdbNTDX0HFhywOC1tl6-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T060905F092921-55xKSEfEJH2bE3iGPejeo3-3CbqkvERQkS9r2l9RxNBsp-1024.npz
train_Episode has 500 steps and return 844.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 394500 Counter(394500) 394437
Saved chunk: 20230922T061006F549145-3GWGdbNTDX0HFhywOC1tl6-0000000000000000000000-123.npz
Saved chunk: 20230922T061024F349307-3CbqkvERQkS9r2l9RxNBsp-0000000000000000000000-260.npz
eval_Episode has 500 steps and return 841.0.
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 846.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 789918 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 841 / eval_episode/reward_rate 0.84 / train/action_mag 4.28 / train/action_max 3.88 / train/action_mean 0.01 / train/action_min -4.21 / train/action_std 1.01 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -0.93 / train/adv_mag 0.48 / train/adv_max 0.34 / train/adv_mean -4.1e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.97 / train/extr_critic_max 671.97 / train/extr_critic_mean 637.09 / train/extr_critic_min 469.33 / train/extr_critic_std 51.02 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.69 / train/extr_return_raw_max 669.69 / train/extr_return_raw_mean 637.08 / train/extr_return_raw_min 468.15 / train/extr_return_raw_std 51.1 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.27 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 6.01 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.45 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.75 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.45 / train/policy_logprob_min -8.75 / train/policy_logprob_std 1.16 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 8.6e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.58 / train/post_ent_max 53.58 / train/post_ent_mean 38.16 / train/post_ent_min 27.05 / train/post_ent_std 4.62 
/ train/prior_ent_mag 64.44 / train/prior_ent_max 64.44 / train/prior_ent_mean 39.35 / train/prior_ent_min 31.6 / train/prior_ent_std 5.67 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.37 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.1
/ train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / train_stats/mean_log_entropy 0.55 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.2e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.2e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.67 / report/dyn_loss_std 3.22 / report/image_loss_mean 0.2 / report/image_loss_std 0.34 / report/model_loss_mean 1.28 / report/model_loss_std 2.19 / report/post_ent_mag 50.46 / report/post_ent_max 50.46 / report/post_ent_mean 39.06 / 
report/post_ent_min 23.18 / report/post_ent_std 4.39 / report/prior_ent_mag 64.95 / report/prior_ent_max 64.95 / report/prior_ent_mean 40.31 / report/prior_ent_min 29.84 / report/prior_ent_std 5.42 / report/rep_loss_mean 1.67 / report/rep_loss_std 3.22 / report/reward_avg
1.29 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.8e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.29 / 
report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 2.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.46 / 
eval/dyn_loss_std 2.55 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.23 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.7 / eval/post_ent_mag 50.71 / eval/post_ent_max 50.71 / eval/post_ent_mean 38.71 / eval/post_ent_min 29.48 / eval/post_ent_std 4 / 
eval/prior_ent_mag 64.95 / eval/prior_ent_max 64.95 / eval/prior_ent_mean 39.83 / eval/prior_ent_min 33.4 / eval/prior_ent_std 5.18 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.55 / eval/reward_avg 1.49 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / replay/size 3.9e5 / replay/inserts 3882 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3882 / timer/env.step_total 19.61 / timer/env.step_frac 0.07 / timer/env.step_avg 5.1e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.15 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.26 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7389 / timer/agent.policy_total 16.59 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / 
timer/agent.policy_max 0.16 / timer/dataset_train_count 1941 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1941 / 
timer/agent.train_total 245.54 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 /
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.88

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 395000 Counter(395000) 394937
Saved chunk: 20230922T061006F549145-3GWGdbNTDX0HFhywOC1tl6-1vCtJE5sY5RujWgvK78bSG-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T061024F349307-3CbqkvERQkS9r2l9RxNBsp-7cHmglHgpwNQrPbHFcUEwH-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 395500 Counter(395500) 395437
eval_Episode has 500 steps and return 851.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 396000 Counter(396000) 395937
Saved chunk: 20230922T061125F257216-1vCtJE5sY5RujWgvK78bSG-6PMV9EbMkZbNrw94odFsZ8-1024.npz
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T061144F740928-7cHmglHgpwNQrPbHFcUEwH-20zZguZBLKz2S0G3RBwM3t-1024.npz
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 396500 Counter(396500) 396437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 397000 Counter(397000) 396937
Saved chunk: 20230922T061243F240914-6PMV9EbMkZbNrw94odFsZ8-6rTeia55Ehyby36qtBT96Y-1024.npz
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T061304F227186-20zZguZBLKz2S0G3RBwM3t-6KGbs3p4YJdsVDQfme7rZW-1024.npz
Starting evaluation at step 397500 Counter(397500) 397437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 398000 Counter(398000) 397937
Saved chunk: 20230922T061400F888977-6rTeia55Ehyby36qtBT96Y-0PwTMwH07EF9PDfbJykNgD-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T061423F356717-6KGbs3p4YJdsVDQfme7rZW-60UAfVbDfyVh5vdVkzGKmB-1024.npz
Starting evaluation at step 398500 Counter(398500) 398437
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 847.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 797606 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 841 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 847 / episode/reward_rate 0.85 / train/action_mag 4.27 / train/action_max 4.15 / train/action_mean 0.03 / train/action_min -4.05 / train/action_std 1.03 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -0.57 / train/adv_mag 0.49 / train/adv_max 0.35 / train/adv_mean -9.6e-5 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.69 / train/extr_critic_max 671.69 / train/extr_critic_mean 637.45 / train/extr_critic_min 473.22 / train/extr_critic_std 49.9 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.34 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.32 / train/extr_return_raw_max 669.32 / train/extr_return_raw_mean 637.43 / train/extr_return_raw_min 472.63 / train/extr_return_raw_std 49.97
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.07 / 
train/model_opt_grad_norm 5.24 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.52 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.96 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.52 / train/policy_logprob_min -8.96 / train/policy_logprob_std 1.17 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 1e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.15 / train/post_ent_max 53.15 / train/post_ent_mean 38.21 / train/post_ent_min 27.29 / train/post_ent_std 4.61 / 
train/prior_ent_mag 64.4 / train/prior_ent_max 64.4 / train/prior_ent_mean 39.39 / train/prior_ent_min 31.71 / train/prior_ent_std 5.67 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.09 / train/reward_avg 1.38 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 /
train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy
0.85 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 7.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.53 / 
report/dyn_loss_std 2.92 / report/image_loss_mean 0.15 / report/image_loss_std 0.26 / report/model_loss_mean 1.18 / report/model_loss_std 1.96 / report/post_ent_mag 50.05 / report/post_ent_max 50.05 / report/post_ent_mean 37.93 / report/post_ent_min 30.5 / 
report/post_ent_std 4.12 / report/prior_ent_mag 64.16 / report/prior_ent_max 64.16 / report/prior_ent_mean 38.95 / report/prior_ent_min 33.12 / report/prior_ent_std 5.24 / report/rep_loss_mean 1.53 / report/rep_loss_std 2.92 / report/reward_avg 1.6 / 
report/reward_loss_mean 0.1 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.02 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.6 / report/reward_rate
0.8 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.37 / eval/dyn_loss_std 2.18 / 
eval/image_loss_mean 0.12 / eval/image_loss_std 0.16 / eval/model_loss_mean 1.05 / eval/model_loss_std 1.43 / eval/post_ent_mag 51.5 / eval/post_ent_max 51.5 / eval/post_ent_mean 36.28 / eval/post_ent_min 30.92 / eval/post_ent_std 3.96 / eval/prior_ent_mag 64.16 / 
eval/prior_ent_max 64.16 / eval/prior_ent_mean 37.24 / eval/prior_ent_min 33.22 / eval/prior_ent_std 5.26 / eval/rep_loss_mean 1.37 / eval/rep_loss_std 2.18 / eval/reward_avg 1.76 / eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / 
eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.9e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.76 / eval/reward_rate 0.88 / replay/size 4e5 / replay/inserts 3844 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 
/ replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / 
eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3844 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / 
timer/replay._sample_total 391.89 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 
7852 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1922 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / 
timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.6e-4 / timer/agent.train_count 1922 / timer/agent.train_total 243.21 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 
0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / 
timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 399000 Counter(399000) 398937
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T061518F489454-0PwTMwH07EF9PDfbJykNgD-7AChySj2eBt5Tx6TQfDobF-1024.npz
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T061542F477197-60UAfVbDfyVh5vdVkzGKmB-7h9KTO797uqNyDSqSV6QWN-1024.npz
Starting evaluation at step 399500 Counter(399500) 399437
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 816.0.
Starting evaluation at step 400000 Counter(400000) 399937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T061702F881293-7h9KTO797uqNyDSqSV6QWN-7xYTy9jo5ddEIZ9CXCC2iO-1024.npz
Starting evaluation at step 400500 Counter(400500) 400437
Saved chunk: 20230922T061637F151210-7AChySj2eBt5Tx6TQfDobF-1xXr6HNUkkWsOSG89hG652-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 401000 Counter(401000) 400937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T061822F237404-7xYTy9jo5ddEIZ9CXCC2iO-7ztCUag4uf1VpdABp8mWsm-1024.npz
Starting evaluation at step 401500 Counter(401500) 401437
Saved chunk: 20230922T061830F526679-1xXr6HNUkkWsOSG89hG652-5RAWMd3nYHXRraVc7vEq8j-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 402000 Counter(402000) 401937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T061941F437989-7ztCUag4uf1VpdABp8mWsm-0cfjXnTrTmClfQEwJv0Hp9-1024.npz
Starting evaluation at step 402500 Counter(402500) 402437
Saved chunk: 20230922T061948F168117-5RAWMd3nYHXRraVc7vEq8j-1TNdKSN3DDCQvmea9i3Evj-1024.npz
eval_Episode has 500 steps and return 847.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 805286 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 844 / episode/reward_rate 0.84 / train/action_mag 4.23 / train/action_max 3.8 / train/action_mean 6.2e-3 / train/action_min -4.15 / train/action_std 0.97 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -1.96 / train/adv_mag 0.48 / train/adv_max 0.37 / train/adv_mean 7.6e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 671.63 / train/extr_critic_max 671.63 / train/extr_critic_mean 636.63 / train/extr_critic_min 467.87 / train/extr_critic_std 50.58 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.13 / train/extr_return_raw_max 669.13 / train/extr_return_raw_mean 636.64 / train/extr_return_raw_min 467.51 / train/extr_return_raw_std 50.66
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.59 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.42 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.8 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.8 / train/policy_logprob_std 1.14 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.94 / train/post_ent_max 52.94 / train/post_ent_mean 38.31 / train/post_ent_min 27.03 / train/post_ent_std 4.61 /
train/prior_ent_mag 64.28 / train/prior_ent_max 64.28 / train/prior_ent_mean 39.5 / train/prior_ent_min 31.24 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.1 / train/reward_avg 1.37 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / 
train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy
0.4 / report/cont_avg 1 / report/cont_loss_mean 2e-11 / report/cont_loss_std 8.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.47 / 
report/dyn_loss_std 2.44 / report/image_loss_mean 0.14 / report/image_loss_std 0.14 / report/model_loss_mean 1.11 / report/model_loss_std 1.55 / report/post_ent_mag 60.49 / report/post_ent_max 60.49 / report/post_ent_mean 37.35 / report/post_ent_min 24.69 / 
report/post_ent_std 4.28 / report/prior_ent_mag 64.15 / report/prior_ent_max 64.15 / report/prior_ent_mean 38.49 / report/prior_ent_min 32.55 / report/prior_ent_std 5.37 / report/rep_loss_mean 1.47 / report/rep_loss_std 2.44 / report/reward_avg 1.54 / 
report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.8e-8 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.54 / 
report/reward_rate 0.77 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / 
eval/dyn_loss_std 3.09 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.2 / eval/model_loss_std 2.05 / eval/post_ent_mag 50.85 / eval/post_ent_max 50.85 / eval/post_ent_mean 37.96 / eval/post_ent_min 30.58 / eval/post_ent_std 4.39 / 
eval/prior_ent_mag 64.15 / eval/prior_ent_max 64.15 / eval/prior_ent_mean 39.06 / eval/prior_ent_min 32.77 / eval/prior_ent_std 5.5 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.09 / eval/reward_avg 1.45 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.23 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.5e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.45 / eval/reward_rate 0.73 / replay/size 4e5 / replay/inserts 3840 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3840 / timer/env.step_total 19.13 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.1e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 388.76 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 1920 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.3e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 403000 Counter(403000) 402937
eval_Episode has 500 steps and return 841.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T062100F593598-0cfjXnTrTmClfQEwJv0Hp9-4u8WNn0dKCypFrJIQDBq8E-1024.npz
Starting evaluation at step 403500 Counter(403500) 403437
Saved chunk: 20230922T062105F778601-1TNdKSN3DDCQvmea9i3Evj-4HLD6dYXIPgiWCqu4x4XPp-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 404000 Counter(404000) 403937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T062221F102154-4u8WNn0dKCypFrJIQDBq8E-1LjZ1m52B6shM5RBElP6yc-1024.npz
Starting evaluation at step 404500 Counter(404500) 404437
Saved chunk: 20230922T062224F719969-4HLD6dYXIPgiWCqu4x4XPp-1J2YuEy5uim0LUll7aXOYd-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 405000 Counter(405000) 404937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 405500 Counter(405500) 405437
Saved chunk: 20230922T062342F364351-1J2YuEy5uim0LUll7aXOYd-0xPYJeE3WnCPMjPi7qPR3K-1024.npz
eval_Episode has 500 steps and return 608.0.
Saved chunk: 20230922T062340F300943-1LjZ1m52B6shM5RBElP6yc-5qKiqgEGLU9gsTAQh65lZh-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 406000 Counter(406000) 405937
eval_Episode has 500 steps and return 666.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T062459F958804-0xPYJeE3WnCPMjPi7qPR3K-0000000000000000000000-883.npz
Saved chunk: 20230922T062502F841820-5qKiqgEGLU9gsTAQh65lZh-0000000000000000000000-596.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 609.0.
Starting evaluation at step 406500 Counter(406500) 406437
Saved chunk: 20230922T062459F958804-0xPYJeE3WnCPMjPi7qPR3K-5UfLptQFlPAqzHXyYeHQgq-1024.npz
eval_Episode has 500 steps and return 746.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 813002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 609 / episode/reward_rate 0.61 / eval_episode/length 500 / eval_episode/score 746 / eval_episode/reward_rate 0.74 / train/action_mag 4.18 / train/action_max 3.9 / train/action_mean 2.6e-3 / train/action_min -4.05 / train/action_std 0.98 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -3.01 / train/adv_mag 0.51 / train/adv_max 0.39 / train/adv_mean 1.8e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4
/ train/extr_critic_mag 671.17 / train/extr_critic_max 671.17 / train/extr_critic_mean 636.29 / train/extr_critic_min 458.22 / train/extr_critic_std 51.6 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.13 / train/extr_return_raw_max 669.13 / train/extr_return_raw_mean 636.32 / train/extr_return_raw_min 459.46 / train/extr_return_raw_std 51.68
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.04 / 
train/model_opt_grad_norm 5.73 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.76 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.76 / train/policy_logprob_std 1.14 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.87 / train/post_ent_max 52.87 / train/post_ent_mean 38.17 / train/post_ent_min 27.12 / train/post_ent_std 4.69
/ train/prior_ent_mag 64.24 / train/prior_ent_max 64.24 / train/prior_ent_mean 39.35 / train/prior_ent_min 31.24 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.07 / train/reward_avg 1.37 / train/reward_loss_mean 0.08 / train/reward_loss_std 
0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / train_stats/mean_log_entropy 0.47 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 1.9e-10 / report/cont_loss_std 5e-9 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.9e-10 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.51 / report/dyn_loss_std 2.43 / report/image_loss_mean 0.16 / report/image_loss_std 0.28 / report/model_loss_mean 1.18 / report/model_loss_std 1.75 / report/post_ent_mag 51.94 / report/post_ent_max 51.94 / report/post_ent_mean 37.69 / 
report/post_ent_min 30.23 / report/post_ent_std 4.8 / report/prior_ent_mag 64.32 / report/prior_ent_max 64.32 / report/prior_ent_mean 38.73 / report/prior_ent_min 32.53 / report/prior_ent_std 5.77 / report/rep_loss_mean 1.51 / report/rep_loss_std 2.43 / report/reward_avg 
1.51 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.38 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 0.05 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.52 / 
report/reward_rate 0.76 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.46 / 
eval/dyn_loss_std 2.24 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.49 / eval/post_ent_mag 51.79 / eval/post_ent_max 51.79 / eval/post_ent_mean 36.32 / eval/post_ent_min 29.3 / eval/post_ent_std 3.12 / 
eval/prior_ent_mag 64.32 / eval/prior_ent_max 64.32 / eval/prior_ent_mean 37.31 / eval/prior_ent_min 32.52 / eval/prior_ent_std 4.56 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.24 / eval/reward_avg 1.85 / eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.12 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.88 / eval/reward_neg_loss 0.09 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.85 / eval/reward_rate 0.92 / replay/size 4.1e5 / replay/inserts 3858 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.25 / timer/env.step_count 3858 / timer/env.step_total 19.47 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / timer/env.step_max 0.16 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.68 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6e-3 / timer/replay._sample_max 0.04 / timer/agent.save_count 1 / timer/agent.save_total 0.1 / 
timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7866 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / 
timer/agent.policy_max 0.1 / timer/dataset_train_count 1929 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.5e-4 / timer/agent.train_count 1929 / 
timer/agent.train_total 244 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / 
timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.1e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3.1e-5 / timer/dataset_eval_min 3.1e-5 / timer/dataset_eval_max 3.1e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T062502F841820-5qKiqgEGLU9gsTAQh65lZh-4wwSY89xBs6m3R0EqI8OLw-1024.npz
train_Episode has 500 steps and return 625.0.
Starting evaluation at step 407000 Counter(407000) 406937
eval_Episode has 500 steps and return 617.0.
train_Episode has 500 steps and return 625.0.
Starting evaluation at step 407500 Counter(407500) 407437
Saved chunk: 20230922T062617F661639-5UfLptQFlPAqzHXyYeHQgq-4rPvBr6YuaAbtCUDENHTIq-1024.npz
eval_Episode has 500 steps and return 753.0.
Saved chunk: 20230922T062623F057319-4wwSY89xBs6m3R0EqI8OLw-596VJY6NXnzx8ocpGBRVBQ-1024.npz
train_Episode has 500 steps and return 628.0.
Starting evaluation at step 408000 Counter(408000) 407937
eval_Episode has 500 steps and return 621.0.
train_Episode has 500 steps and return 622.0.
Starting evaluation at step 408500 Counter(408500) 408437
Saved chunk: 20230922T062736F519122-4rPvBr6YuaAbtCUDENHTIq-6PTIZgxMy7pC1d7HhIaCYm-1024.npz
eval_Episode has 500 steps and return 751.0.
Saved chunk: 20230922T062742F502909-596VJY6NXnzx8ocpGBRVBQ-2nBMCW6RLZYyxYsPBBw6Zz-1024.npz
train_Episode has 500 steps and return 618.0.
Starting evaluation at step 409000 Counter(409000) 408937
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 409500 Counter(409500) 409437
Saved chunk: 20230922T062854F291419-6PTIZgxMy7pC1d7HhIaCYm-6BD9Vcblgoai73vllRLaFJ-1024.npz
eval_Episode has 500 steps and return 751.0.
Saved chunk: 20230922T062901F799850-2nBMCW6RLZYyxYsPBBw6Zz-650dw9tzx38xr4kOK84YqU-1024.npz
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 410000 Counter(410000) 409937
eval_Episode has 500 steps and return 680.0.
train_Episode has 500 steps and return 710.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 820786 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 710 / episode/reward_rate 0.71 / eval_episode/length 500 / eval_episode/score 680 / eval_episode/reward_rate 0.68 / train/action_mag 4.15 / train/action_max 3.78 / train/action_mean -0.02 / train/action_min -4.07 / train/action_std 0.95 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2e5 / train/actor_opt_loss -2.56 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 1.6e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.8e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.8e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 671.33 / train/extr_critic_max 671.33 / train/extr_critic_mean 635.73 / train/extr_critic_min 426.94 / train/extr_critic_std 55 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.44 / train/extr_return_raw_max 669.44 / train/extr_return_raw_mean 635.76 / train/extr_return_raw_min 431.3 / train/extr_return_raw_std 55.06 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 7.9e-6 / train/extr_reward_std 0.88 / train/image_loss_mean 0.18 / train/image_loss_std 0.3 / train/model_loss_mean 1.22 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.81 / train/model_opt_grad_steps 2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean 
0.35 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.62 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.35 / train/policy_logprob_min -8.62 / train/policy_logprob_std 1.13 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.54 / train/policy_randomness_min 2.2e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 53.22 / train/post_ent_max 53.22 / train/post_ent_mean 37.96 / train/post_ent_min 27.01 / train/post_ent_std 4.59
/ train/prior_ent_mag 64.25 / train/prior_ent_max 64.25 / train/prior_ent_mean 39.15 / train/prior_ent_min 31.14 / train/prior_ent_std 5.65 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.1 / train/reward_avg 1.38 / train/reward_loss_mean 0.08 / train/reward_loss_std 
0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / train_stats/mean_log_entropy 0.16 / 
eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.2e-11 / report/cont_loss_std 4.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.2e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.66 / report/dyn_loss_std 2.97 / report/image_loss_mean 0.2 / report/image_loss_std 0.35 / report/model_loss_mean 1.28 / report/model_loss_std 2.04 / report/post_ent_mag 51.45 / report/post_ent_max 51.45 / report/post_ent_mean 38.58 / 
report/post_ent_min 27.02 / report/post_ent_std 4.58 / report/prior_ent_mag 64.58 / report/prior_ent_max 64.58 / report/prior_ent_mean 39.96 / report/prior_ent_min 32.28 / report/prior_ent_std 5.65 / report/rep_loss_mean 1.66 / report/rep_loss_std 2.97 / report/reward_avg
1.23 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.27 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 0.13 / report/reward_pred 1.23 / 
report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / 
eval/dyn_loss_std 2.61 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.71 / eval/post_ent_mag 47.9 / eval/post_ent_max 47.9 / eval/post_ent_mean 37.87 / eval/post_ent_min 30.04 / eval/post_ent_std 4.1 / 
eval/prior_ent_mag 64.58 / eval/prior_ent_max 64.58 / eval/prior_ent_mean 38.92 / eval/prior_ent_min 32.05 / eval/prior_ent_std 5.2 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.61 / eval/reward_avg 1.56 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.56 / eval/reward_rate 0.78 / replay/size 4.1e5 / replay/inserts 3892 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3892 / timer/env.step_total 19.34 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / timer/env.step_max 6.6e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.11 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.3e-4 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7399 / timer/agent.policy_total 16.3 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / timer/dataset_train_count 1946 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1946 / timer/agent.train_total 246.26 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.94

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 410500 Counter(410500) 410437
Saved chunk: 20230922T063011F861134-6BD9Vcblgoai73vllRLaFJ-0IMjmT4p45ZAKLHFfUmVaU-1024.npz
eval_Episode has 500 steps and return 746.0.
Saved chunk: 20230922T063020F911065-650dw9tzx38xr4kOK84YqU-3Dg9Zt1J1AnjemjUyxinLq-1024.npz
train_Episode has 500 steps and return 744.0.
Starting evaluation at step 411000 Counter(411000) 410937
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 719.0.
Starting evaluation at step 411500 Counter(411500) 411437
Saved chunk: 20230922T063130F310843-0IMjmT4p45ZAKLHFfUmVaU-2Yq82fhzsq7mm5dJ86AcGm-1024.npz
eval_Episode has 500 steps and return 724.0.
Saved chunk: 20230922T063141F030003-3Dg9Zt1J1AnjemjUyxinLq-67a0ydW2WVa32r5f8iUssW-1024.npz
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 412000 Counter(412000) 411937
eval_Episode has 500 steps and return 620.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 412500 Counter(412500) 412437
Saved chunk: 20230922T063248F327386-2Yq82fhzsq7mm5dJ86AcGm-2YhJQKDkMNwjwk0gsC29eJ-1024.npz
eval_Episode has 500 steps and return 599.0.
Saved chunk: 20230922T063300F514909-67a0ydW2WVa32r5f8iUssW-4yl0ip1SgtfraG6qdhCk8d-1024.npz
train_Episode has 500 steps and return 712.0.
Starting evaluation at step 413000 Counter(413000) 412937
eval_Episode has 500 steps and return 643.0.
train_Episode has 500 steps and return 706.0.
Starting evaluation at step 413500 Counter(413500) 413437
Saved chunk: 20230922T063406F150916-2YhJQKDkMNwjwk0gsC29eJ-6OJoRxL2RU4kxWhhtmh8bx-1024.npz
eval_Episode has 500 steps and return 589.0.
Saved chunk: 20230922T063419F888829-4yl0ip1SgtfraG6qdhCk8d-0QETegoFy9UMtKEV8EbU0u-1024.npz
train_Episode has 500 steps and return 617.0.
Starting evaluation at step 414000 Counter(414000) 413937
eval_Episode has 500 steps and return 621.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 828466 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 621 / eval_episode/reward_rate 0.62 / episode/length 500 / episode/score 617 / episode/reward_rate 0.62 / train/action_mag 4.08 / train/action_max 3.78 / train/action_mean -0.03 / train/action_min -3.99 / train/action_std 0.92 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -0.68 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean -9.6e-6 / train/adv_min -0.42 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 
/ train/dyn_loss_std 2.99 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.41 / train/extr_critic_max 671.41 / train/extr_critic_mean 636.73 / train/extr_critic_min 418.02 / train/extr_critic_std 54 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.62 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.41 / train/extr_return_raw_max 669.41 / train/extr_return_raw_mean 636.73 / train/extr_return_raw_min 420.64 / train/extr_return_raw_std 54.08
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.2 / train/model_loss_std 2 / 
train/model_opt_grad_norm 5.59 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.68 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.68 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 1.2e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 53.19 / train/post_ent_max 53.19 / train/post_ent_mean 38.14 / train/post_ent_min 
27.61 / train/post_ent_std 4.65 / train/prior_ent_mag 64.11 / train/prior_ent_max 64.11 / train/prior_ent_mean 39.31 / train/prior_ent_min 31.33 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.58 / train/rep_loss_std 2.99 / train/reward_avg 1.38 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.14 / report/cont_avg 1 / report/cont_loss_mean 1.6e-11 / report/cont_loss_std 5.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 3 / report/image_loss_mean 0.14 / report/image_loss_std 0.19 / report/model_loss_mean 1.14 / report/model_loss_std 1.95 / report/post_ent_mag 52.01 / report/post_ent_max 52.01 / 
report/post_ent_mean 36.6 / report/post_ent_min 29.85 / report/post_ent_std 3.77 / report/prior_ent_mag 64.1 / report/prior_ent_max 64.1 / report/prior_ent_mean 37.75 / report/prior_ent_min 31.78 / report/prior_ent_std 5.12 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 3 / report/reward_avg 1.61 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-6 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.11 / report/reward_pred 1.61 / report/reward_rate 0.8 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.42 / eval/dyn_loss_std 2.31 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.49 / eval/post_ent_mag 51.21 / eval/post_ent_max 51.21 / eval/post_ent_mean 38.13 / eval/post_ent_min 30.1 / 
eval/post_ent_std 3.91 / eval/prior_ent_mag 64.1 / eval/prior_ent_max 64.1 / eval/prior_ent_mean 39.11 / eval/prior_ent_min 32.47 / eval/prior_ent_std 5.04 / eval/rep_loss_mean 1.42 / eval/rep_loss_std 2.31 / eval/reward_avg 1.62 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.9e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size 4.1e5 / replay/inserts 3840 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3840 / timer/env.step_total 19.29 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.56 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.16 / timer/dataset_train_count 
1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1920 / timer/agent.train_total 242.85 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 624.0.
Starting evaluation at step 414500 Counter(414500) 414437
Saved chunk: 20230922T063523F812788-6OJoRxL2RU4kxWhhtmh8bx-3UQg2KfKdfnZI2upXIufv8-1024.npz
eval_Episode has 500 steps and return 737.0.
Saved chunk: 20230922T063539F024019-0QETegoFy9UMtKEV8EbU0u-6EOI6KQaKiyuDsL5QOzKPt-1024.npz
train_Episode has 500 steps and return 745.0.
Starting evaluation at step 415000 Counter(415000) 414937
eval_Episode has 500 steps and return 631.0.
train_Episode has 500 steps and return 574.0.
Starting evaluation at step 415500 Counter(415500) 415437
Saved chunk: 20230922T063642F372933-3UQg2KfKdfnZI2upXIufv8-1xR7Splf3n5OjhNgZDIxmn-1024.npz
eval_Episode has 500 steps and return 630.0.
Saved chunk: 20230922T063659F276919-6EOI6KQaKiyuDsL5QOzKPt-6ba1QwQv5x6LJ8rHseACcG-1024.npz
train_Episode has 500 steps and return 726.0.
Starting evaluation at step 416000 Counter(416000) 415937
eval_Episode has 500 steps and return 617.0.
train_Episode has 500 steps and return 602.0.
Starting evaluation at step 416500 Counter(416500) 416437
Saved chunk: 20230922T063800F342571-1xR7Splf3n5OjhNgZDIxmn-5QXQsD1DspSyc8SwxqJtdZ-1024.npz
eval_Episode has 500 steps and return 629.0.
Saved chunk: 20230922T063818F718533-6ba1QwQv5x6LJ8rHseACcG-7GLYn3T7peQe4SNOoxVGeN-1024.npz
train_Episode has 500 steps and return 616.0.
Starting evaluation at step 417000 Counter(417000) 416937
eval_Episode has 500 steps and return 725.0.
train_Episode has 500 steps and return 724.0.
Starting evaluation at step 417500 Counter(417500) 417437
Saved chunk: 20230922T063918F063448-5QXQsD1DspSyc8SwxqJtdZ-50qQmxj3DuCl0xGOuhDfiK-1024.npz
eval_Episode has 500 steps and return 711.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T063937F927266-7GLYn3T7peQe4SNOoxVGeN-0000000000000000000000-933.npz
Saved chunk: 20230922T064035F586526-50qQmxj3DuCl0xGOuhDfiK-0000000000000000000000-118.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T063937F927266-7GLYn3T7peQe4SNOoxVGeN-2dXUUiS6iC8lOvFx06Zi1Q-1024.npz
train_Episode has 500 steps and return 729.0.
Starting evaluation at step 418000 Counter(418000) 417937
eval_Episode has 500 steps and return 724.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 836118 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 729 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 724 / eval_episode/reward_rate 0.72 / train/action_mag 4.1 / train/action_max 3.82 / train/action_mean -0.02 / train/action_min -3.97 / train/action_std 0.93 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -2.46 / train/adv_mag 0.49 / train/adv_max 0.4 / train/adv_mean 1.6e-4 / train/adv_min -0.41 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.25 / train/extr_critic_max 671.25 / train/extr_critic_mean 636.31 / train/extr_critic_min 423.18 / train/extr_critic_std 54.03 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.58 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.29 / train/extr_return_raw_max 669.29 / train/extr_return_raw_mean 636.34 / train/extr_return_raw_min 424.31 / train/extr_return_raw_std 54.1 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.04 / 
train/model_opt_grad_norm 5.88 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.3 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.7 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.3 / train/policy_logprob_min -8.7 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 1.2e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 52.8 / train/post_ent_max 52.8 / train/post_ent_mean 38.04 / train/post_ent_min 
27.21 / train/post_ent_std 4.6 / train/prior_ent_mag 64.18 / train/prior_ent_max 64.18 / train/prior_ent_mean 39.23 / train/prior_ent_min 30.96 / train/prior_ent_std 5.65 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.06 / train/reward_avg 1.38 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.1 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.77 / report/image_loss_mean 0.16 / report/image_loss_std 0.3 / report/model_loss_mean 1.21 / report/model_loss_std 2.49 / report/post_ent_mag 51.01 / report/post_ent_max 51.01 / 
report/post_ent_mean 36.33 / report/post_ent_min 27.2 / report/post_ent_std 4.73 / report/prior_ent_mag 63.64 / report/prior_ent_max 63.64 / report/prior_ent_mean 37.52 / report/prior_ent_min 31.34 / report/prior_ent_std 5.82 / report/rep_loss_mean 1.62 / 
report/rep_loss_std 3.77 / report/reward_avg 1.39 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 3.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.39 / report/reward_rate 0.69 / eval/cont_avg 1 / eval/cont_loss_mean 4.7e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.43 / eval/dyn_loss_std 2.42 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.22 / eval/model_loss_mean 1.1 / eval/model_loss_std 1.6 / eval/post_ent_mag 50.84 / eval/post_ent_max 50.84 / eval/post_ent_mean 
38.23 / eval/post_ent_min 29.94 / eval/post_ent_std 3.6 / eval/prior_ent_mag 63.64 / eval/prior_ent_max 63.64 / eval/prior_ent_mean 39.18 / eval/prior_ent_min 32.17 / eval/prior_ent_std 4.78 / eval/rep_loss_mean 1.43 / eval/rep_loss_std 2.42 / eval/reward_avg 1.62 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size 
4.2e5 / replay/inserts 3826 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.8 / timer/env.step_count 3826 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.1e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.34 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.8e-4 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.4e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7834 / timer/agent.policy_total 17.21 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.09 / timer/dataset_train_count 1913 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / 
timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1913 / timer/agent.train_total 243.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 1.8 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.44

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 418500 Counter(418500) 418437
Saved chunk: 20230922T064035F586526-50qQmxj3DuCl0xGOuhDfiK-1VKMcpvX92mvl4zgHSZdwM-1024.npz
eval_Episode has 500 steps and return 663.0.
Saved chunk: 20230922T064057F150415-2dXUUiS6iC8lOvFx06Zi1Q-1iJ0ABKrUWlif8wdIVQBP1-1024.npz
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 419000 Counter(419000) 418937
eval_Episode has 500 steps and return 730.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 419500 Counter(419500) 419437
Saved chunk: 20230922T064156F152060-1VKMcpvX92mvl4zgHSZdwM-0wkKj7iohNR29GuTrCqv2l-1024.npz
eval_Episode has 500 steps and return 692.0.
train_Episode has 500 steps and return 645.0.
Saved chunk: 20230922T064219F284603-1iJ0ABKrUWlif8wdIVQBP1-33IWrgMwVwGzVvASwMdNJ0-1024.npz
Starting evaluation at step 420000 Counter(420000) 419937
eval_Episode has 500 steps and return 724.0.
train_Episode has 500 steps and return 635.0.
Starting evaluation at step 420500 Counter(420500) 420437
Saved chunk: 20230922T064313F992929-0wkKj7iohNR29GuTrCqv2l-1949Unj4G0QLXoDnu9pfDK-1024.npz
eval_Episode has 500 steps and return 678.0.
train_Episode has 500 steps and return 732.0.
Saved chunk: 20230922T064338F580644-33IWrgMwVwGzVvASwMdNJ0-10P1mPTQt8RXoQxQvlB0nk-1024.npz
Starting evaluation at step 421000 Counter(421000) 420937
eval_Episode has 500 steps and return 737.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 421500 Counter(421500) 421437
eval_Episode has 500 steps and return 733.0.
Saved chunk: 20230922T064431F688371-1949Unj4G0QLXoDnu9pfDK-5PWJIYPwfvAety9Rvk4lgz-1024.npz
train_Episode has 500 steps and return 728.0.
Saved chunk: 20230922T064457F800598-10P1mPTQt8RXoQxQvlB0nk-6PrlCuL2usAXlR2BYEq9E1-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 843898 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 728 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 733 / eval_episode/reward_rate 0.73 / train/action_mag 4.12 / train/action_max 3.82 / train/action_mean -0.02 / train/action_min -3.98 / train/action_std 0.92 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -2.77 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean 1.9e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.1 / train/extr_critic_max 671.1 / train/extr_critic_mean 636.27 / train/extr_critic_min 426.71 / train/extr_critic_std 53.56 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.59 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.19 / train/extr_return_raw_max 669.19 / train/extr_return_raw_mean 636.29 / train/extr_return_raw_min 428.67 / train/extr_return_raw_std 53.6 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.05 / 
train/model_opt_grad_norm 5.65 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.3 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.87 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.3 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.51 / train/policy_randomness_min 1.1e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 53.39 / train/post_ent_max 53.39 / train/post_ent_mean 38.16 / train/post_ent_min
27.42 / train/post_ent_std 4.61 / train/prior_ent_mag 64.29 / train/prior_ent_max 64.29 / train/prior_ent_mean 39.35 / train/prior_ent_min 31.35 / train/prior_ent_std 5.66 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.07 / train/reward_avg 1.37 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.21 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 5.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.59 / report/dyn_loss_std 3.26 / report/image_loss_mean 0.2 / report/image_loss_std 0.36 / report/model_loss_mean 1.23 / report/model_loss_std 2.25 / report/post_ent_mag 61.31 / report/post_ent_max 61.31 / 
report/post_ent_mean 36.81 / report/post_ent_min 24.09 / report/post_ent_std 4.52 / report/prior_ent_mag 64.17 / report/prior_ent_max 64.17 / report/prior_ent_mean 38.03 / report/prior_ent_min 30.26 / report/prior_ent_std 5.64 / report/rep_loss_mean 1.59 / 
report/rep_loss_std 3.26 / report/reward_avg 1.39 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.1e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.39 / report/reward_rate 0.7 / eval/cont_avg 1 / eval/cont_loss_mean 5e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5e-11 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 1.47 / eval/dyn_loss_std 2.26 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.12 / eval/model_loss_std 1.57 / eval/post_ent_mag 51.81 / eval/post_ent_max 51.81 / eval/post_ent_mean 37.02 / 
eval/post_ent_min 29.69 / eval/post_ent_std 4.2 / eval/prior_ent_mag 64.17 / eval/prior_ent_max 64.17 / eval/prior_ent_mean 38.07 / eval/prior_ent_min 32.27 / eval/prior_ent_std 5.47 / eval/rep_loss_mean 1.47 / eval/rep_loss_std 2.26 / eval/reward_avg 1.65 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 4.3e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.65 / eval/reward_rate 0.83 / replay/size 
4.2e5 / replay/inserts 3890 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.5e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.11 / timer/env.step_count 3890 / timer/env.step_total 19.29 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.1 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.13 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.6e-3 / 
timer/dataset_train_count 1945 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.57 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.92

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 422000 Counter(422000) 421937
eval_Episode has 500 steps and return 735.0.
train_Episode has 500 steps and return 730.0.
Starting evaluation at step 422500 Counter(422500) 422437
eval_Episode has 500 steps and return 717.0.
Saved chunk: 20230922T064549F295118-5PWJIYPwfvAety9Rvk4lgz-6mWxYih8nQOdWFD4CoCoAo-1024.npz
train_Episode has 500 steps and return 733.0.
Saved chunk: 20230922T064616F922736-6PrlCuL2usAXlR2BYEq9E1-5fsKBZGXVK3yWu5jJNv5iE-1024.npz
Starting evaluation at step 423000 Counter(423000) 422937
eval_Episode has 500 steps and return 669.0.
train_Episode has 500 steps and return 716.0.
Starting evaluation at step 423500 Counter(423500) 423437
eval_Episode has 500 steps and return 697.0.
train_Episode has 500 steps and return 733.0.
Saved chunk: 20230922T064737F485048-5fsKBZGXVK3yWu5jJNv5iE-3KCn6tWu42yk8bn75njw2P-1024.npz
Starting evaluation at step 424000 Counter(424000) 423937
Saved chunk: 20230922T064708F110942-6mWxYih8nQOdWFD4CoCoAo-6JQlL2N1rvm8WMcnANrwsK-1024.npz
eval_Episode has 500 steps and return 734.0.
train_Episode has 500 steps and return 729.0.
Starting evaluation at step 424500 Counter(424500) 424437
eval_Episode has 500 steps and return 739.0.
train_Episode has 500 steps and return 659.0.
Saved chunk: 20230922T064856F844379-3KCn6tWu42yk8bn75njw2P-08qtzJzDYPANsgBwwoGdBR-1024.npz
Starting evaluation at step 425000 Counter(425000) 424937
Saved chunk: 20230922T064901F465969-6JQlL2N1rvm8WMcnANrwsK-0iCbyoSLJiFgA7ls7D7VlM-1024.npz
eval_Episode has 500 steps and return 725.0.
train_Episode has 500 steps and return 732.0.
Starting evaluation at step 425500 Counter(425500) 425437
eval_Episode has 500 steps and return 737.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 851578 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 737 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 732 / episode/reward_rate 0.73 / train/action_mag 4.06 / train/action_max 3.79 / train/action_mean -0.02 / train/action_min -3.93 / train/action_std 0.91 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -2.89 / train/adv_mag 0.49 / train/adv_max 0.37 / train/adv_mean 2e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.25 / train/extr_critic_max 671.25 / train/extr_critic_mean 637.13 / train/extr_critic_min 431.36 / train/extr_critic_std 52.99 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.2 / train/extr_return_raw_max 669.2 / train/extr_return_raw_mean 637.16 / train/extr_return_raw_min 433.93 / train/extr_return_raw_std 53.01 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.41 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.04 / 
train/model_opt_grad_norm 5.37 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.31 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.85 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.31 / train/policy_logprob_min -8.85 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 9.7e-6 / train/policy_randomness_std 0.37 / train/post_ent_mag 52.59 / train/post_ent_max 52.59 / train/post_ent_mean 37.98 / train/post_ent_min
27.14 / train/post_ent_std 4.58 / train/prior_ent_mag 64.2 / train/prior_ent_max 64.2 / train/prior_ent_mean 39.18 / train/prior_ent_min 31.09 / train/prior_ent_std 5.65 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.05 / train/reward_avg 1.39 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.7 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.13 / report/cont_avg 1 / report/cont_loss_mean 2.9e-11 / report/cont_loss_std 1.9e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 2.91 / report/image_loss_mean 0.14 / report/image_loss_std 0.17 / report/model_loss_mean 1.15 / report/model_loss_std 1.86 / report/post_ent_mag 53.53 / report/post_ent_max 53.53 / 
report/post_ent_mean 37.56 / report/post_ent_min 14.56 / report/post_ent_std 4.8 / report/prior_ent_mag 64.59 / report/prior_ent_max 64.59 / report/prior_ent_mean 38.69 / report/prior_ent_min 24.09 / report/prior_ent_std 5.85 / report/rep_loss_mean 1.54 / 
report/rep_loss_std 2.91 / report/reward_avg 1.52 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.6e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.52 / report/reward_rate 0.76 / eval/cont_avg 1 / eval/cont_loss_mean 6.3e-11 / eval/cont_loss_std 3.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.8 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.81 / eval/post_ent_mag 52.49 / eval/post_ent_max 52.49 / eval/post_ent_mean 
38.25 / eval/post_ent_min 31.01 / eval/post_ent_std 3.88 / eval/prior_ent_mag 64.59 / eval/prior_ent_max 64.59 / eval/prior_ent_mean 39.27 / eval/prior_ent_min 32.27 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.8 / eval/reward_avg 1.49 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.15 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / replay/size
4.3e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3840 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.2e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.69 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.9e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.14 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.6e-3 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.38 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / timer/dataset_eval_max 4.1e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 736.0.
Saved chunk: 20230922T065016F043997-08qtzJzDYPANsgBwwoGdBR-5Xt5Bomh1XkrDf2UDMzrZP-1024.npz
Starting evaluation at step 426000 Counter(426000) 425937
Saved chunk: 20230922T065019F104315-0iCbyoSLJiFgA7ls7D7VlM-6Ohs12W8q2fMu9X0A8aYC8-1024.npz
eval_Episode has 500 steps and return 737.0.
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 426500 Counter(426500) 426437
eval_Episode has 500 steps and return 722.0.
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 427000 Counter(427000) 426937
Saved chunk: 20230922T065137F689573-6Ohs12W8q2fMu9X0A8aYC8-07SVSpIZ4hxXeWsYemDpUx-1024.npz
eval_Episode has 500 steps and return 731.0.
Saved chunk: 20230922T065136F154751-5Xt5Bomh1XkrDf2UDMzrZP-0J6MNh73U0HrD4v0MmuK94-1024.npz
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 427500 Counter(427500) 427437
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 428000 Counter(428000) 427937
Saved chunk: 20230922T065255F688652-07SVSpIZ4hxXeWsYemDpUx-4nNQxv2VFrCTOiQn8BSZ6K-1024.npz
eval_Episode has 500 steps and return 730.0.
Saved chunk: 20230922T065259F125638-0J6MNh73U0HrD4v0MmuK94-6gqPmyrprNl0kJuFyZXDGl-1024.npz
train_Episode has 500 steps and return 730.0.
Starting evaluation at step 428500 Counter(428500) 428437
eval_Episode has 500 steps and return 737.0.
train_Episode has 500 steps and return 730.0.
Starting evaluation at step 429000 Counter(429000) 428937
Saved chunk: 20230922T065413F463159-4nNQxv2VFrCTOiQn8BSZ6K-6kM3LVwp7vCUIWZXD7XtP4-1024.npz
eval_Episode has 500 steps and return 740.0.
Saved chunk: 20230922T065418F430291-6gqPmyrprNl0kJuFyZXDGl-1KD4UEnQ1K5cmu6cGQ7gv9-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T065531F077633-6kM3LVwp7vCUIWZXD7XtP4-0000000000000000000000-377.npz
Saved chunk: 20230922T065537F613251-1KD4UEnQ1K5cmu6cGQ7gv9-0000000000000000000000-244.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 429500 Counter(429500) 429437
eval_Episode has 500 steps and return 738.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 859250 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 738 / episode/reward_rate 0.74 / eval_episode/length 500 / eval_episode/score 738 / eval_episode/reward_rate 0.74 / train/action_mag 3.94 / train/action_max 3.7 / train/action_mean -0.02 / train/action_min -3.77 / train/action_std 0.9 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.1e5 / train/actor_opt_loss -2.55 / train/adv_mag 0.51 / train/adv_max 0.39 / train/adv_mean 2e-4 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.1e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.28 / train/extr_critic_max 671.28 / train/extr_critic_mean 634.81 / train/extr_critic_min 431.71 / train/extr_critic_std 55.25 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.77 / 
train/extr_return_normed_min -0.57 / train/extr_return_normed_std 0.37 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.4 / train/extr_return_raw_max 669.4 / train/extr_return_raw_mean 634.84 / train/extr_return_raw_min 433.96 / train/extr_return_raw_std 55.29 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.38 / train/extr_reward_min 0 / train/extr_reward_std 0.9 / train/image_loss_mean 0.18 / train/image_loss_std 0.27 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.38 / train/model_opt_grad_steps 2.1e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.21 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.83 / train/policy_logprob_mag 8.41 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.21 / train/policy_logprob_min -8.41 / train/policy_logprob_std 1.09 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 9.5e-6 / train/policy_randomness_std 0.36 / train/post_ent_mag 53.6 / train/post_ent_max 53.6 / train/post_ent_mean 38.07 / train/post_ent_min 
26.6 / train/post_ent_std 4.63 / train/prior_ent_mag 64.4 / train/prior_ent_max 64.4 / train/prior_ent_mean 39.28 / train/prior_ent_min 30.8 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.36 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.36 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy -0.09 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 2.1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 2.7 / report/image_loss_mean 0.17 / report/image_loss_std 0.22 / report/model_loss_mean 1.22 / report/model_loss_std 1.79 / report/post_ent_mag 60.02 / report/post_ent_max 60.02 / 
report/post_ent_mean 39.04 / report/post_ent_min 24.34 / report/post_ent_std 4.21 / report/prior_ent_mag 64.69 / report/prior_ent_max 64.69 / report/prior_ent_mean 40.26 / report/prior_ent_min 29.88 / report/prior_ent_std 5.36 / report/rep_loss_mean 1.61 / 
report/rep_loss_std 2.7 / report/reward_avg 1.29 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.17 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.2e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 1.28 / report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 6.2e-11 / eval/cont_loss_std 3.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.46 / eval/dyn_loss_std 2.23 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.18 / eval/model_loss_mean 1.11 / eval/model_loss_std 1.44 / eval/post_ent_mag 49.59 / eval/post_ent_max 49.59 / eval/post_ent_mean 37.6 / eval/post_ent_min 30.32 / 
eval/post_ent_std 4.06 / eval/prior_ent_mag 64.69 / eval/prior_ent_max 64.69 / eval/prior_ent_mean 38.65 / eval/prior_ent_min 32.39 / eval/prior_ent_std 5.37 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.23 / eval/reward_avg 1.62 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / replay/size 4.3e5 / replay/inserts 3836 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3836 / timer/env.step_total 19.38 / timer/env.step_frac 0.06 / timer/env.step_avg 5.1e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 385.94 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.6e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.33 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.7e-4 / 
timer/agent.train_count 1918 / timer/agent.train_total 242.74 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / 
timer/dataset_eval_max 3.2e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 430000 Counter(430000) 429937
Saved chunk: 20230922T065531F077633-6kM3LVwp7vCUIWZXD7XtP4-6syOmqAktqbhg4zLNzkx1H-1024.npz
eval_Episode has 500 steps and return 741.0.
Saved chunk: 20230922T065537F613251-1KD4UEnQ1K5cmu6cGQ7gv9-37BHJ4kOpAyokZ3zEDFbyQ-1024.npz
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 430500 Counter(430500) 430437
eval_Episode has 500 steps and return 734.0.
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 431000 Counter(431000) 430937
Saved chunk: 20230922T065649F984642-6syOmqAktqbhg4zLNzkx1H-37dgugeKuT24ah1IGYQy84-1024.npz
eval_Episode has 500 steps and return 739.0.
Saved chunk: 20230922T065658F119976-37BHJ4kOpAyokZ3zEDFbyQ-6ULQu7JS7wErGeed1f4UmI-1024.npz
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 431500 Counter(431500) 431437
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 432000 Counter(432000) 431937
Saved chunk: 20230922T065807F760228-37dgugeKuT24ah1IGYQy84-4rtAcTLUCRrOkd8sjS84G0-1024.npz
eval_Episode has 500 steps and return 737.0.
Saved chunk: 20230922T065817F269724-6ULQu7JS7wErGeed1f4UmI-4gVRztp1MFgvXeKpthsM8I-1024.npz
train_Episode has 500 steps and return 736.0.
Starting evaluation at step 432500 Counter(432500) 432437
eval_Episode has 500 steps and return 735.0.
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 433000 Counter(433000) 432937
Saved chunk: 20230922T065925F233684-4rtAcTLUCRrOkd8sjS84G0-74fgIqpTQomljgUSTfbMGR-1024.npz
eval_Episode has 500 steps and return 740.0.
Saved chunk: 20230922T065936F324435-4gVRztp1MFgvXeKpthsM8I-6LthPH63ay27beQP7xKhD1-1024.npz
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 433500 Counter(433500) 433437
eval_Episode has 500 steps and return 739.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 867002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 741 / episode/reward_rate 0.74 / eval_episode/length 500 / eval_episode/score 739 / eval_episode/reward_rate 0.74 / train/action_mag 3.89 / train/action_max 3.7 / train/action_mean -9.8e-3 / train/action_min -3.65 / train/action_std 0.87
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -1.35 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean 9e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.65 / train/extr_critic_max 671.65 / train/extr_critic_mean 637.22 / train/extr_critic_min 437.68 / train/extr_critic_std 52.78 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.92 / train/extr_return_raw_max 669.92 / train/extr_return_raw_mean 637.23 / train/extr_return_raw_min 439.11 / train/extr_return_raw_std 52.84
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.62 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.16 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.8 / train/policy_logprob_mag 8.43 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.16 / train/policy_logprob_min -8.43 / train/policy_logprob_std 1.07 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.45 / train/policy_randomness_min 1.2e-5 / train/policy_randomness_std 0.35 / train/post_ent_mag 53.58 / train/post_ent_max 53.58 / train/post_ent_mean 38.08 / train/post_ent_min
27.23 / train/post_ent_std 4.57 / train/prior_ent_mag 64.34 / train/prior_ent_max 64.34 / train/prior_ent_mean 39.27 / train/prior_ent_min 31.09 / train/prior_ent_std 5.63 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.09 / train/reward_avg 1.37 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy -0.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 7.1e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 2.88 / report/image_loss_mean 0.15 / report/image_loss_std 0.24 / report/model_loss_mean 1.19 / report/model_loss_std 1.87 / report/post_ent_mag 51.22 / report/post_ent_max 51.22 / 
report/post_ent_mean 37.86 / report/post_ent_min 28.02 / report/post_ent_std 4.48 / report/prior_ent_mag 64.56 / report/prior_ent_max 64.56 / report/prior_ent_mean 39.02 / report/prior_ent_min 32.36 / report/prior_ent_std 5.76 / report/rep_loss_mean 1.58 / 
report/rep_loss_std 2.88 / report/reward_avg 1.56 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.8e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.56 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 4.6e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.6e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.79 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.37 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.9 / eval/post_ent_mag 52.24 / eval/post_ent_max 52.24 / eval/post_ent_mean 
37.83 / eval/post_ent_min 29.59 / eval/post_ent_std 4.4 / eval/prior_ent_mag 64.56 / eval/prior_ent_max 64.56 / eval/prior_ent_mean 38.88 / eval/prior_ent_min 32.04 / eval/prior_ent_std 5.56 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.79 / eval/reward_avg 1.53 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.2e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.53 / eval/reward_rate 0.77 / replay/size
4.3e5 / replay/inserts 3876 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.6e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.83 / timer/env.step_count 3876 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 6.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.93 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.4e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7884 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.3e-3 / 
timer/dataset_train_count 1938 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1938 / timer/agent.train_total 245.32 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.68

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 434000 Counter(434000) 433937
Saved chunk: 20230922T070042F464933-74fgIqpTQomljgUSTfbMGR-2vPJmBnJCjLGN4RQ3FeaVY-1024.npz
eval_Episode has 500 steps and return 734.0.
Saved chunk: 20230922T070055F084645-6LthPH63ay27beQP7xKhD1-7xRs9yiR4uzUgwywGGf4Ot-1024.npz
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 434500 Counter(434500) 434437
eval_Episode has 500 steps and return 732.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 435000 Counter(435000) 434937
Saved chunk: 20230922T070201F190572-2vPJmBnJCjLGN4RQ3FeaVY-5N45eTPJ2Jn2NWJ74Jwf5g-1024.npz
eval_Episode has 500 steps and return 736.0.
Saved chunk: 20230922T070215F491122-7xRs9yiR4uzUgwywGGf4Ot-3GdZn7oB2UPpsyd4WjuzFO-1024.npz
train_Episode has 500 steps and return 731.0.
Starting evaluation at step 435500 Counter(435500) 435437
eval_Episode has 500 steps and return 277.0.
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 436000 Counter(436000) 435937
Saved chunk: 20230922T070318F890544-5N45eTPJ2Jn2NWJ74Jwf5g-768SDX81uExne67Pkc7R0f-1024.npz
eval_Episode has 500 steps and return 728.0.
Saved chunk: 20230922T070334F664880-3GdZn7oB2UPpsyd4WjuzFO-7hSvR3hetnRnejcDj5Hu3s-1024.npz
train_Episode has 500 steps and return 722.0.
Starting evaluation at step 436500 Counter(436500) 436437
eval_Episode has 500 steps and return 734.0.
train_Episode has 500 steps and return 735.0.
Starting evaluation at step 437000 Counter(437000) 436937
Saved chunk: 20230922T070436F410493-768SDX81uExne67Pkc7R0f-1JDfLqUY5BBGDC8NokxfXt-1024.npz
eval_Episode has 500 steps and return 739.0.
Saved chunk: 20230922T070453F820449-7hSvR3hetnRnejcDj5Hu3s-3cXYNjieWiavi4tnFb4QZx-1024.npz
train_Episode has 500 steps and return 735.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 874790 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 735 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 739 / eval_episode/reward_rate 0.74 / train/action_mag 3.8 / train/action_max 3.57 / train/action_mean -0.02 / train/action_min -3.59 / train/action_std 0.84 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -1.5 / train/adv_mag 0.51 / train/adv_max 0.4 / train/adv_mean 1.4e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.1 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 672.02 / train/extr_critic_max 672.02 / train/extr_critic_mean 637.75 / train/extr_critic_min 441.99 / train/extr_critic_std 51.29 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.98 / train/extr_return_raw_max 669.98 / train/extr_return_raw_mean 637.77 / train/extr_return_raw_min 443.88 / train/extr_return_raw_std 51.35
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.43 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.03 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.75 / train/policy_logprob_mag 8.47 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.03 / train/policy_logprob_min -8.47 / train/policy_logprob_std 1.03 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.4 / train/policy_randomness_min 1.6e-5 / train/policy_randomness_std 0.33 / train/post_ent_mag 52.59 / train/post_ent_max 52.59 / train/post_ent_mean 38.22 / train/post_ent_min 
27.09 / train/post_ent_std 4.56 / train/prior_ent_mag 64.18 / train/prior_ent_max 64.18 / train/prior_ent_mean 39.41 / train/prior_ent_min 30.99 / train/prior_ent_std 5.6 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.1 / train/reward_avg 1.36 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.36 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy -0.23 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.9e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.9e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.56 / report/dyn_loss_std 3.01 / report/image_loss_mean 0.19 / report/image_loss_std 0.29 / report/model_loss_mean 1.21 / report/model_loss_std 2.01 / report/post_ent_mag 52.75 / report/post_ent_max 52.75 / 
report/post_ent_mean 37.42 / report/post_ent_min 19.83 / report/post_ent_std 5.21 / report/prior_ent_mag 64.14 / report/prior_ent_max 64.14 / report/prior_ent_mean 38.58 / report/prior_ent_min 22.5 / report/prior_ent_std 6.18 / report/rep_loss_mean 1.56 / 
report/rep_loss_std 3.01 / report/reward_avg 1.39 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.39 / report/reward_rate 0.7 / eval/cont_avg 1 / eval/cont_loss_mean 3.3e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.3e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.38 / eval/dyn_loss_std 2.08 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.05 / eval/model_loss_std 1.38 / eval/post_ent_mag 50.27 / eval/post_ent_max 50.27 / eval/post_ent_mean 36.11 / 
eval/post_ent_min 29.47 / eval/post_ent_std 3.24 / eval/prior_ent_mag 64.14 / eval/prior_ent_max 64.14 / eval/prior_ent_mean 37.1 / eval/prior_ent_min 32.11 / eval/prior_ent_std 4.52 / eval/rep_loss_mean 1.38 / eval/rep_loss_std 2.08 / eval/reward_avg 1.87 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.87 / eval/reward_rate 0.94 / replay/size
4.4e5 / replay/inserts 3894 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3894 / timer/env.step_total 19.36 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.39 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.5e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7401 / timer/agent.policy_total 16.58 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.15 / 
timer/dataset_train_count 1947 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.8e-4 / timer/agent.train_count 1947 / timer/agent.train_total 246.19 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.5e-5 / timer/dataset_eval_frac 1.5e-7 / timer/dataset_eval_avg 4.5e-5 / timer/dataset_eval_min 4.5e-5 / timer/dataset_eval_max 4.5e-5 / fps 25.95

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 437500 Counter(437500) 437437
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 438000 Counter(438000) 437937
Saved chunk: 20230922T070554F047718-1JDfLqUY5BBGDC8NokxfXt-6Y9e4ymYvhA4erfy5IO3Tb-1024.npz
eval_Episode has 500 steps and return 727.0.
Saved chunk: 20230922T070612F929064-3cXYNjieWiavi4tnFb4QZx-2QUXrDmkggLg8MxZEmgaWo-1024.npz
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 438500 Counter(438500) 438437
eval_Episode has 500 steps and return 707.0.
train_Episode has 500 steps and return 696.0.
Starting evaluation at step 439000 Counter(439000) 438937
Saved chunk: 20230922T070712F814523-6Y9e4ymYvhA4erfy5IO3Tb-6dhanFoS8XxaWJhLgOTZl1-1024.npz
eval_Episode has 500 steps and return 740.0.
Saved chunk: 20230922T070733F334786-2QUXrDmkggLg8MxZEmgaWo-3IszuETGuwuE5ZSzM8LlBZ-1024.npz
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 439500 Counter(439500) 439437
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 748.0.
Starting evaluation at step 440000 Counter(440000) 439937
Saved chunk: 20230922T070830F615208-6dhanFoS8XxaWJhLgOTZl1-6oZgZTX0arODzAkljYBMXr-1024.npz
eval_Episode has 500 steps and return 736.0.
Saved chunk: 20230922T070852F646318-3IszuETGuwuE5ZSzM8LlBZ-3JCekXUkRv1DxpA4ccPUk8-1024.npz
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 440500 Counter(440500) 440437
eval_Episode has 500 steps and return 738.0.
train_Episode has 500 steps and return 744.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T070948F326345-6oZgZTX0arODzAkljYBMXr-0000000000000000000000-636.npz
Saved chunk: 20230922T071011F852912-3JCekXUkRv1DxpA4ccPUk8-0000000000000000000000-580.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 441000 Counter(441000) 440937
Saved chunk: 20230922T070948F326345-6oZgZTX0arODzAkljYBMXr-34VKtyQ5PyveYNPJL9bH4N-1024.npz
eval_Episode has 500 steps and return 743.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 882470 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 743 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 744 / episode/reward_rate 0.74 / train/action_mag 3.88 / train/action_max 3.74 / train/action_mean -8e-3 / train/action_min -3.62 / train/action_std 0.89 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -1.53 / train/adv_mag 0.53 / train/adv_max 0.43 / train/adv_mean 9e-5 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.75 / train/extr_critic_max 671.75 / train/extr_critic_mean 638.67 / train/extr_critic_min 440.35 / train/extr_critic_std 51.53 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.81 / train/extr_return_raw_max 669.81 / train/extr_return_raw_mean 638.69 / train/extr_return_raw_min 441.28 / train/extr_return_raw_std 51.56
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.42 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.05 / 
train/model_opt_grad_norm 5.62 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.22 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.8 / train/policy_logprob_mag 8.56 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.22 / train/policy_logprob_min -8.56 / train/policy_logprob_std 1.07 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.48 / train/policy_randomness_min 2.3e-5 / train/policy_randomness_std 0.35 / train/post_ent_mag 52.77 / train/post_ent_max 52.77 / train/post_ent_mean 38.04 / train/post_ent_min
26.99 / train/post_ent_std 4.49 / train/prior_ent_mag 64.05 / train/prior_ent_max 64.05 / train/prior_ent_mean 39.22 / train/prior_ent_min 31.02 / train/prior_ent_std 5.55 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.07 / train/reward_avg 1.4 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.7 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.08 / report/cont_avg 1 / report/cont_loss_mean 2.7e-11 / report/cont_loss_std 7.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.7e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.85 / report/dyn_loss_std 4.23 / report/image_loss_mean 0.25 / report/image_loss_std 0.61 / report/model_loss_mean 1.44 / report/model_loss_std 3.01 / report/post_ent_mag 52.5 / report/post_ent_max 52.5 / 
report/post_ent_mean 39.26 / report/post_ent_min 24.11 / report/post_ent_std 5.1 / report/prior_ent_mag 64.35 / report/prior_ent_max 64.35 / report/prior_ent_mean 40.62 / report/prior_ent_min 32.06 / report/prior_ent_std 5.85 / report/rep_loss_mean 1.85 / 
report/rep_loss_std 4.23 / report/reward_avg 1.2 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.26 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.2e-3 / report/reward_pos_acc 1 / report/reward_pos_loss
0.13 / report/reward_pred 1.2 / report/reward_rate 0.6 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 9.7e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.36 / eval/dyn_loss_std 2.01 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.12 / eval/model_loss_mean 1.03 / eval/model_loss_std 1.29 / eval/post_ent_mag 52.03 / eval/post_ent_max 52.03 / eval/post_ent_mean 37.1 / eval/post_ent_min 30.28 / 
eval/post_ent_std 3.41 / eval/prior_ent_mag 64.35 / eval/prior_ent_max 64.35 / eval/prior_ent_mean 37.97 / eval/prior_ent_min 32.01 / eval/prior_ent_std 4.71 / eval/rep_loss_mean 1.36 / eval/rep_loss_std 2.01 / eval/reward_avg 1.79 / eval/reward_loss_mean 0.1 / 
eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.79 / eval/reward_rate 0.9 / replay/size 4.4e5 / replay/inserts 
3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.12 / timer/env.step_count 3840 / timer/env.step_total 19.12 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 0.05 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 386.89 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.17 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.45 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.4e-4 / 
timer/agent.train_count 1920 / timer/agent.train_total 243.11 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.28 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.9e-5 / timer/dataset_eval_frac 9.8e-8 / timer/dataset_eval_avg 2.9e-5 / timer/dataset_eval_min 2.9e-5 / 
timer/dataset_eval_max 2.9e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T071011F852912-3JCekXUkRv1DxpA4ccPUk8-47HURXbVloHUR3bsuIvOk1-1024.npz
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 441500 Counter(441500) 441437
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 442000 Counter(442000) 441937
Saved chunk: 20230922T071106F053310-34VKtyQ5PyveYNPJL9bH4N-3gkljyMKhbVWD0QO4Maxlj-1024.npz
eval_Episode has 500 steps and return 741.0.
Saved chunk: 20230922T071132F115199-47HURXbVloHUR3bsuIvOk1-2FxF3H34IvtQQCuQ26CNvZ-1024.npz
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 442500 Counter(442500) 442437
eval_Episode has 500 steps and return 730.0.
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 443000 Counter(443000) 442937
Saved chunk: 20230922T071224F859098-3gkljyMKhbVWD0QO4Maxlj-2WNGrC320e41S2Vd0G0nlP-1024.npz
eval_Episode has 500 steps and return 744.0.
train_Episode has 500 steps and return 740.0.
Saved chunk: 20230922T071251F581897-2FxF3H34IvtQQCuQ26CNvZ-4h0kJiTL0SzCU6ccJVPfeQ-1024.npz
Starting evaluation at step 443500 Counter(443500) 443437
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 444000 Counter(444000) 443937
Saved chunk: 20230922T071342F682459-2WNGrC320e41S2Vd0G0nlP-3vgP9LsIxytFukfFoxwmtv-1024.npz
eval_Episode has 500 steps and return 739.0.
train_Episode has 500 steps and return 738.0.
Saved chunk: 20230922T071410F932826-4h0kJiTL0SzCU6ccJVPfeQ-3nw4hbkGhonF0qosh4ybIe-1024.npz
Starting evaluation at step 444500 Counter(444500) 444437
eval_Episode has 500 steps and return 728.0.
train_Episode has 500 steps and return 746.0.
Starting evaluation at step 445000 Counter(445000) 444937
eval_Episode has 500 steps and return 747.0.
Saved chunk: 20230922T071500F410173-3vgP9LsIxytFukfFoxwmtv-636zIPJlQtw0K8eFBcRO0S-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 890154 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 746 / episode/reward_rate 0.74 / eval_episode/length 500 / eval_episode/score 747 / eval_episode/reward_rate 0.75 / train/action_mag 4.04 / train/action_max 3.71 / train/action_mean -0.02 / train/action_min -3.92 / train/action_std 0.93 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -2.89 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 2e-4 / train/adv_min -0.45 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.25 / train/extr_critic_max 671.25 / train/extr_critic_mean 637.31 / train/extr_critic_min 440.1 / train/extr_critic_std 52.6 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.41 / train/extr_return_raw_max 669.41 / train/extr_return_raw_mean 637.34 / train/extr_return_raw_min 441.42 / train/extr_return_raw_std 52.64
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.21 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.63 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.31 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.85 / train/policy_logprob_mag 8.45 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.31 / train/policy_logprob_min -8.45 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.52 / train/policy_randomness_min 1.8e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 52.86 / train/post_ent_max 52.86 / train/post_ent_mean 37.98 / train/post_ent_min
27.11 / train/post_ent_std 4.58 / train/prior_ent_mag 64.23 / train/prior_ent_max 64.23 / train/prior_ent_mean 39.17 / train/prior_ent_min 31 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.09 / train/reward_avg 1.38 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.46 / report/dyn_loss_std 2.29 / report/image_loss_mean 0.15 / report/image_loss_std 0.22 / report/model_loss_mean 1.11 / report/model_loss_std 1.54 / report/post_ent_mag 51.4 / report/post_ent_max 51.4 / 
report/post_ent_mean 37.71 / report/post_ent_min 22.35 / report/post_ent_std 4.7 / report/prior_ent_mag 64.21 / report/prior_ent_max 64.21 / report/prior_ent_mean 38.7 / report/prior_ent_min 31.7 / report/prior_ent_std 5.73 / report/rep_loss_mean 1.46 / 
report/rep_loss_std 2.29 / report/reward_avg 1.54 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.54 / report/reward_rate 0.77 / eval/cont_avg 1 / eval/cont_loss_mean 3.1e-11 / eval/cont_loss_std 9.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.51 / eval/dyn_loss_std 2.78 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.16 / eval/model_loss_std 1.83 / eval/post_ent_mag 52.14 / eval/post_ent_max 52.14 / eval/post_ent_mean 
37.11 / eval/post_ent_min 30.15 / eval/post_ent_std 4 / eval/prior_ent_mag 64.21 / eval/prior_ent_max 64.21 / eval/prior_ent_mean 38.17 / eval/prior_ent_min 31.06 / eval/prior_ent_std 5.2 / eval/rep_loss_mean 1.51 / eval/rep_loss_std 2.78 / eval/reward_avg 1.62 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.7e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / replay/size
4.5e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3842 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.35 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4e-3 / timer/replay._sample_max 0.17 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.14 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 739.0.
Saved chunk: 20230922T071530F118142-3nw4hbkGhonF0qosh4ybIe-7eg0PKcleAp3EnZ86bPd7C-1024.npz
Starting evaluation at step 445500 Counter(445500) 445437
eval_Episode has 500 steps and return 741.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 446000 Counter(446000) 445937
eval_Episode has 500 steps and return 746.0.
Saved chunk: 20230922T071617F841169-636zIPJlQtw0K8eFBcRO0S-7IYqFrKKGJj1qKcrQBwCL3-1024.npz
train_Episode has 500 steps and return 742.0.
Saved chunk: 20230922T071650F197858-7eg0PKcleAp3EnZ86bPd7C-0nqE01wgZDvh4fUhJDqSba-1024.npz
Starting evaluation at step 446500 Counter(446500) 446437
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 447000 Counter(447000) 446937
eval_Episode has 500 steps and return 745.0.
train_Episode has 500 steps and return 744.0.
Saved chunk: 20230922T071809F637515-0nqE01wgZDvh4fUhJDqSba-4yYdBTYCQLNdB8gmv2AtNL-1024.npz
Starting evaluation at step 447500 Counter(447500) 447437
Saved chunk: 20230922T071736F706426-7IYqFrKKGJj1qKcrQBwCL3-2vfDHNmBN3ALSrDAnrY36K-1024.npz
eval_Episode has 500 steps and return 738.0.
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 448000 Counter(448000) 447937
eval_Episode has 500 steps and return 740.0.
train_Episode has 500 steps and return 705.0.
Starting evaluation at step 448500 Counter(448500) 448437
Saved chunk: 20230922T071930F013654-2vfDHNmBN3ALSrDAnrY36K-03w3ej4EdKtbeGao9BiHum-1024.npz
eval_Episode has 500 steps and return 750.0.
Saved chunk: 20230922T071929F031952-4yYdBTYCQLNdB8gmv2AtNL-4hmdRrvD5s8F3PBwOFz7QH-1024.npz
train_Episode has 500 steps and return 731.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 897930 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 731 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 750 / eval_episode/reward_rate 0.75 / train/action_mag 4.08 / train/action_max 3.76 / train/action_mean -0.02 / train/action_min -3.96 / train/action_std 0.93 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -2.61 / train/adv_mag 0.5 / train/adv_max 0.41 / train/adv_mean 1.8e-4 / train/adv_min -0.44 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.76 / train/extr_critic_max 671.76 / train/extr_critic_mean 637.37 / train/extr_critic_min 439.97 / train/extr_critic_std 51.43 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.72 / train/extr_return_raw_max 669.72 / train/extr_return_raw_mean 637.4 / train/extr_return_raw_min 442.69 / train/extr_return_raw_std 51.47 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.07 / 
train/model_opt_grad_norm 5.56 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.28 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.57 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.28 / train/policy_logprob_min -8.57 / train/policy_logprob_std 1.11 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.37 / train/post_ent_mag 52.73 / train/post_ent_max 52.73 / train/post_ent_mean 38.01 / train/post_ent_min 
27.27 / train/post_ent_std 4.66 / train/prior_ent_mag 64.14 / train/prior_ent_max 64.14 / train/prior_ent_mean 39.2 / train/prior_ent_min 31.09 / train/prior_ent_std 5.71 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.09 / train/reward_avg 1.37 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.22 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.3e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 2.86 / report/image_loss_mean 0.18 / report/image_loss_std 0.23 / report/model_loss_mean 1.17 / report/model_loss_std 1.87 / report/post_ent_mag 51.56 / report/post_ent_max 51.56 / 
report/post_ent_mean 38.84 / report/post_ent_min 29.74 / report/post_ent_std 5.36 / report/prior_ent_mag 63.99 / report/prior_ent_max 63.99 / report/prior_ent_mean 40.02 / report/prior_ent_min 30.92 / report/prior_ent_std 6.34 / report/rep_loss_mean 1.55 / 
report/rep_loss_std 2.86 / report/reward_avg 1.01 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.3e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.01 / report/reward_rate 0.5 / eval/cont_avg 1 / eval/cont_loss_mean 3.4e-11 / eval/cont_loss_std 9.2e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.4e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.41 / eval/dyn_loss_std 2.15 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.07 / eval/model_loss_std 1.42 / eval/post_ent_mag 50.73 / eval/post_ent_max 50.73 / eval/post_ent_mean 38.3 / 
eval/post_ent_min 26.51 / eval/post_ent_std 4.4 / eval/prior_ent_mag 63.99 / eval/prior_ent_max 63.99 / eval/prior_ent_mean 39.33 / eval/prior_ent_min 31.66 / eval/prior_ent_std 5.6 / eval/rep_loss_mean 1.41 / eval/rep_loss_std 2.15 / eval/reward_avg 1.46 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.46 / eval/reward_rate 0.73 / replay/size
4.5e5 / replay/inserts 3888 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3888 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 6.5e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.98 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7395 / timer/agent.policy_total 16.34 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.3e-3 / 
timer/dataset_train_count 1944 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1944 / timer/agent.train_total 246.2 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.92

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 449000 Counter(449000) 448937
eval_Episode has 500 steps and return 738.0.
train_Episode has 500 steps and return 745.0.
Starting evaluation at step 449500 Counter(449500) 449437
Saved chunk: 20230922T072047F566057-03w3ej4EdKtbeGao9BiHum-5NqUCOSelMS77A5EP5w3e3-1024.npz
eval_Episode has 500 steps and return 743.0.
Saved chunk: 20230922T072051F520468-4hmdRrvD5s8F3PBwOFz7QH-3iDis7e3lHbvhNAzCbNRDt-1024.npz
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 450000 Counter(450000) 449937
eval_Episode has 500 steps and return 747.0.
train_Episode has 500 steps and return 743.0.
Starting evaluation at step 450500 Counter(450500) 450437
Saved chunk: 20230922T072206F364452-5NqUCOSelMS77A5EP5w3e3-0g7Aqm2xDHgL6q6T3Bf6tg-1024.npz
eval_Episode has 500 steps and return 749.0.
Saved chunk: 20230922T072211F908778-3iDis7e3lHbvhNAzCbNRDt-0DNWqMEI1feBfJSm1Jrw2A-1024.npz
train_Episode has 500 steps and return 741.0.
Starting evaluation at step 451000 Counter(451000) 450937
eval_Episode has 500 steps and return 746.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 451500 Counter(451500) 451437
Saved chunk: 20230922T072324F240757-0g7Aqm2xDHgL6q6T3Bf6tg-4sa4adqOKfiimkYYIx0wwL-1024.npz
eval_Episode has 500 steps and return 747.0.
Saved chunk: 20230922T072331F309374-0DNWqMEI1feBfJSm1Jrw2A-0HA016VadCZ4XdlfucVtTk-1024.npz
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 452000 Counter(452000) 451937
eval_Episode has 500 steps and return 745.0.
train_Episode has 500 steps and return 736.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 452500 Counter(452500) 452437
Saved chunk: 20230922T072441F904922-4sa4adqOKfiimkYYIx0wwL-0000000000000000000000-895.npz
Saved chunk: 20230922T072450F530515-0HA016VadCZ4XdlfucVtTk-0000000000000000000000-916.npz
Saved chunk: 20230922T072441F904922-4sa4adqOKfiimkYYIx0wwL-2VhKXTBJzsNWWrFJpGV3DU-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
eval_Episode has 500 steps and return 749.0.
Saved chunk: 20230922T072450F530515-0HA016VadCZ4XdlfucVtTk-1DJTOWtykQiJLitcxb4imv-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 905602 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 749 / eval_episode/reward_rate 0.75 / episode/length 500 / episode/score 736 / episode/reward_rate 0.73 / train/action_mag 4.08 / train/action_max 3.91 / train/action_mean -0.02 / train/action_min -3.86 / train/action_std 0.96 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.2e5 / train/actor_opt_loss -1.18 / train/adv_mag 0.5 / train/adv_max 0.4 / train/adv_mean -1.8e-6 / train/adv_min -0.43 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.2e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.1 / train/extr_critic_max 671.1 / train/extr_critic_mean 637.46 / train/extr_critic_min 442.26 / train/extr_critic_std 51.65 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.55 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.07 / train/extr_return_raw_max 669.07 / train/extr_return_raw_mean 637.46 / train/extr_return_raw_min 443.29 / train/extr_return_raw_std 51.71
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.22 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.46 / train/model_opt_grad_steps 2.2e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.77 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.77 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.6e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 52.79 / train/post_ent_max 52.79 / train/post_ent_mean 37.9 / train/post_ent_min 
27 / train/post_ent_std 4.62 / train/prior_ent_mag 64.14 / train/prior_ent_max 64.14 / train/prior_ent_mean 39.09 / train/prior_ent_min 30.95 / train/prior_ent_std 5.68 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.38 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.35 / report/cont_avg 1 / report/cont_loss_mean 3.1e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.27 / report/image_loss_mean 0.19 / report/image_loss_std 0.22 / report/model_loss_mean 1.25 / report/model_loss_std 2.08 / report/post_ent_mag 60.84 / report/post_ent_max 60.84 / 
report/post_ent_mean 37.49 / report/post_ent_min 27.6 / report/post_ent_std 4.05 / report/prior_ent_mag 64.22 / report/prior_ent_max 64.22 / report/prior_ent_mean 38.74 / report/prior_ent_min 31.66 / report/prior_ent_std 5.11 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.27 / report/reward_avg 1.35 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.3e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.35 / report/reward_rate 0.68 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.4 / eval/dyn_loss_std 2.18 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.19 / eval/model_loss_mean 1.08 / eval/model_loss_std 1.44 / eval/post_ent_mag 50.62 / eval/post_ent_max 50.62 / eval/post_ent_mean 
36.7 / eval/post_ent_min 26.56 / eval/post_ent_std 3.56 / eval/prior_ent_mag 64.22 / eval/prior_ent_max 64.22 / eval/prior_ent_mean 37.67 / eval/prior_ent_min 31.72 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.4 / eval/rep_loss_std 2.18 / eval/reward_avg 1.79 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.04 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 3.2e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.79 / eval/reward_rate 0.89 / replay/size 
4.5e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3836 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.1e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.38 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.7e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 1 / timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.44 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 6.3e-4 / timer/agent.train_count 1918 / timer/agent.train_total 242.97 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / 
timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.56

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 738.0.
Starting evaluation at step 453000 Counter(453000) 452937
eval_Episode has 500 steps and return 727.0.
train_Episode has 500 steps and return 742.0.
Starting evaluation at step 453500 Counter(453500) 453437
Saved chunk: 20230922T072559F666214-2VhKXTBJzsNWWrFJpGV3DU-6yMckfoX68fiCvdPR0TBH7-1024.npz
eval_Episode has 500 steps and return 746.0.
Saved chunk: 20230922T072609F977022-1DJTOWtykQiJLitcxb4imv-2o0cYccZZrxOBghmq5gUDu-1024.npz
train_Episode has 500 steps and return 724.0.
Starting evaluation at step 454000 Counter(454000) 453937
eval_Episode has 500 steps and return 477.0.
train_Episode has 500 steps and return 394.0.
Starting evaluation at step 454500 Counter(454500) 454437
Saved chunk: 20230922T072718F685843-6yMckfoX68fiCvdPR0TBH7-1UG3mk1EYIOaIVxuzJsalf-1024.npz
eval_Episode has 500 steps and return 746.0.
Saved chunk: 20230922T072730F398961-2o0cYccZZrxOBghmq5gUDu-1ASZuxVFhwjq3CmPdRE0Q8-1024.npz
train_Episode has 500 steps and return 747.0.
Starting evaluation at step 455000 Counter(455000) 454937
eval_Episode has 500 steps and return 722.0.
train_Episode has 500 steps and return 729.0.
Starting evaluation at step 455500 Counter(455500) 455437
Saved chunk: 20230922T072836F492375-1UG3mk1EYIOaIVxuzJsalf-3ptKBlh6q1xmjBjkzGSXpT-1024.npz
eval_Episode has 500 steps and return 723.0.
Saved chunk: 20230922T072849F739386-1ASZuxVFhwjq3CmPdRE0Q8-2YGmN1LNcnxhquw8Vtuffp-1024.npz
train_Episode has 500 steps and return 697.0.
Starting evaluation at step 456000 Counter(456000) 455937
eval_Episode has 500 steps and return 743.0.
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 456500 Counter(456500) 456437
Saved chunk: 20230922T072954F227212-3ptKBlh6q1xmjBjkzGSXpT-36SfSgx7zJfxItc0BDgUq3-1024.npz
eval_Episode has 500 steps and return 830.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 913278 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 733 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 830 / eval_episode/reward_rate 0.83 / train/action_mag 4.12 / train/action_max 3.98 / train/action_mean -0.04 / train/action_min -3.93 / train/action_std 0.99 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -3.74 / train/adv_mag 0.62 / train/adv_max 0.53 / train/adv_mean 2.5e-4 / train/adv_min -0.47 
/ train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 /
train/dyn_loss_std 3.12 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.12 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.2e4 / train/extr_critic_mag 670.77 / train/extr_critic_max 670.77 / train/extr_critic_mean 632.3 / train/extr_critic_min 382.78 / train/extr_critic_std 61.46 / train/extr_return_normed_mag 1.08 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.61 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.98 / train/extr_return_raw_max 668.98 / train/extr_return_raw_mean 632.37 / train/extr_return_raw_min 389.85 / train/extr_return_raw_std 61.39
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.61 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.44 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.7 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.44 / train/policy_logprob_min -8.7 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.7e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.77 / train/post_ent_max 52.77 / train/post_ent_mean 37.89 / train/post_ent_min
26.76 / train/post_ent_std 4.65 / train/prior_ent_mag 64.41 / train/prior_ent_max 64.41 / train/prior_ent_mean 39.09 / train/prior_ent_min 30.71 / train/prior_ent_std 5.72 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.12 / train/reward_avg 1.36 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.36 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy 0.29 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 7.9e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.64 / report/dyn_loss_std 3.46 / report/image_loss_mean 0.18 / report/image_loss_std 0.26 / report/model_loss_mean 1.25 / report/model_loss_std 2.24 / report/post_ent_mag 52.11 / report/post_ent_max 52.11 / 
report/post_ent_mean 38.72 / report/post_ent_min 27.94 / report/post_ent_std 4.14 / report/prior_ent_mag 64.82 / report/prior_ent_max 64.82 / report/prior_ent_mean 39.94 / report/prior_ent_min 31.43 / report/prior_ent_std 5.36 / report/rep_loss_mean 1.64 / 
report/rep_loss_std 3.46 / report/reward_avg 1.33 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.33 / report/reward_rate 0.67 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.48 / eval/dyn_loss_std 2.81 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.39 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.95 / eval/post_ent_mag 49.81 / eval/post_ent_max 49.81 / eval/post_ent_mean 
37.58 / eval/post_ent_min 30.67 / eval/post_ent_std 3.45 / eval/prior_ent_mag 64.82 / eval/prior_ent_max 64.82 / eval/prior_ent_mean 38.6 / eval/prior_ent_min 31.32 / eval/prior_ent_std 4.73 / eval/rep_loss_mean 1.48 / eval/rep_loss_std 2.81 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.61 / eval/reward_rate 0.8 / 
replay/size 4.6e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3838 / timer/env.step_total 19.27 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 384.09 / timer/replay._sample_frac 1.28 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.1e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.29 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.8e-3 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.09 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T073009F072255-2YGmN1LNcnxhquw8Vtuffp-1eJZyWzmFjVbWeIvUUgC24-1024.npz
train_Episode has 500 steps and return 827.0.
Starting evaluation at step 457000 Counter(457000) 456937
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 819.0.
Starting evaluation at step 457500 Counter(457500) 457437
Saved chunk: 20230922T073111F936457-36SfSgx7zJfxItc0BDgUq3-1HdMDwHuXMNmGIpcB4rRbH-1024.npz
eval_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T073129F231422-1eJZyWzmFjVbWeIvUUgC24-31CVRnasQlsyrliLSN0lPe-1024.npz
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 458000 Counter(458000) 457937
eval_Episode has 500 steps and return 838.0.
train_Episode has 500 steps and return 821.0.
Starting evaluation at step 458500 Counter(458500) 458437
Saved chunk: 20230922T073230F867794-1HdMDwHuXMNmGIpcB4rRbH-5Np5g6B3ZSNYa0da5a5Zox-1024.npz
eval_Episode has 500 steps and return 824.0.
Saved chunk: 20230922T073248F809806-31CVRnasQlsyrliLSN0lPe-5bZSHarc6ga6PflFdPkf2m-1024.npz
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 459000 Counter(459000) 458937
eval_Episode has 500 steps and return 729.0.
train_Episode has 500 steps and return 726.0.
Starting evaluation at step 459500 Counter(459500) 459437
Saved chunk: 20230922T073348F652041-5Np5g6B3ZSNYa0da5a5Zox-3v8jshbo2hfa37Mlgzw5pv-1024.npz
eval_Episode has 500 steps and return 727.0.
Saved chunk: 20230922T073408F069204-5bZSHarc6ga6PflFdPkf2m-3GIbCKXcek3hg2ePuud62N-1024.npz
train_Episode has 500 steps and return 727.0.
Starting evaluation at step 460000 Counter(460000) 459937
eval_Episode has 500 steps and return 666.0.
train_Episode has 500 steps and return 731.0.
Starting evaluation at step 460500 Counter(460500) 460437
Saved chunk: 20230922T073506F298782-3v8jshbo2hfa37Mlgzw5pv-36UfrRuIWssif1rM03qrle-1024.npz
eval_Episode has 500 steps and return 730.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 921002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 731 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 730 / eval_episode/reward_rate 0.73 / train/action_mag 4.1 / train/action_max 3.82 / train/action_mean -0.03 / train/action_min -4.01 / train/action_std 0.98 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -19.23 / train/adv_mag 0.68 / train/adv_max 0.59 / train/adv_mean 1.8e-3 / train/adv_min -0.55 /
train/adv_std 0.03 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.8e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.11 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.15 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.17 / train/extr_critic_max 671.17 / train/extr_critic_mean 631.27 / train/extr_critic_min 352.12 / train/extr_critic_std 64.78 / train/extr_return_normed_mag 1.07 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.69 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.65 / train/extr_return_raw_max 669.65 / train/extr_return_raw_mean 631.61 / train/extr_return_raw_min 360.31 / train/extr_return_raw_std 64.23
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.08 / 
train/model_opt_grad_norm 5.45 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.41 / train/policy_entropy_max 1.41 / 
train/policy_entropy_mean 0.42 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.72 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.72 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 5.4e-6 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.25 / train/post_ent_max 53.25 / train/post_ent_mean 37.88 / train/post_ent_min
27.21 / train/post_ent_std 4.67 / train/prior_ent_mag 64.34 / train/prior_ent_max 64.34 / train/prior_ent_mean 39.07 / train/prior_ent_min 30.87 / train/prior_ent_std 5.75 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.11 / train/reward_avg 1.36 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.36 / train/reward_rate 0.68 / 
train_stats/mean_log_entropy 0.41 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 8.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.68 / report/dyn_loss_std 3.55 / report/image_loss_mean 0.18 / report/image_loss_std 0.32 / report/model_loss_mean 1.26 / report/model_loss_std 2.4 / report/post_ent_mag 59.76 / report/post_ent_max 59.76 / 
report/post_ent_mean 38.29 / report/post_ent_min 25.99 / report/post_ent_std 4.58 / report/prior_ent_mag 64.01 / report/prior_ent_max 64.01 / report/prior_ent_mean 39.51 / report/prior_ent_min 30.32 / report/prior_ent_std 5.58 / report/rep_loss_mean 1.68 / 
report/rep_loss_std 3.55 / report/reward_avg 1.04 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.15 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.13 / report/reward_pred 1.04 / report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 5.6e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.6e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.5 / eval/dyn_loss_std 2.69 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.15 / eval/model_loss_std 1.7 / eval/post_ent_mag 51.81 / eval/post_ent_max 51.81 / eval/post_ent_mean 37.64 / eval/post_ent_min 26.78 / 
eval/post_ent_std 4.27 / eval/prior_ent_mag 64.01 / eval/prior_ent_max 64.01 / eval/prior_ent_mean 38.69 / eval/prior_ent_min 30.62 / eval/prior_ent_std 5.38 / eval/rep_loss_mean 1.5 / eval/rep_loss_std 2.69 / eval/reward_avg 1.61 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.1e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.61 / eval/reward_rate 0.8 / replay/size 4.6e5 / replay/inserts 3862 /
replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.68 / timer/env.step_count 3862 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.06 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.5e-3 / timer/replay._sample_max 0.19 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7870 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 / timer/dataset_train_count 
1931 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1931 / timer/agent.train_total 244.82 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.29 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 4.1e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.3e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.3e-5 / timer/dataset_eval_min 3.3e-5 / timer/dataset_eval_max 3.3e-5 / fps 25.6

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T073527F348802-3GIbCKXcek3hg2ePuud62N-6lGLVOaoUzwxi8bFGkHJtZ-1024.npz
train_Episode has 500 steps and return 678.0.
Starting evaluation at step 461000 Counter(461000) 460937
eval_Episode has 500 steps and return 709.0.
train_Episode has 500 steps and return 729.0.
Starting evaluation at step 461500 Counter(461500) 461437
Saved chunk: 20230922T073623F957038-36UfrRuIWssif1rM03qrle-5O9VkZ6m0pwL7hmZjn9GCV-1024.npz
eval_Episode has 500 steps and return 716.0.
Saved chunk: 20230922T073647F658399-6lGLVOaoUzwxi8bFGkHJtZ-7x0T64l3PHdtDX1v1sNIhU-1024.npz
train_Episode has 500 steps and return 719.0.
Starting evaluation at step 462000 Counter(462000) 461937
eval_Episode has 500 steps and return 719.0.
train_Episode has 500 steps and return 714.0.
Starting evaluation at step 462500 Counter(462500) 462437
Saved chunk: 20230922T073742F898050-5O9VkZ6m0pwL7hmZjn9GCV-2gepJcopl3xMHUiZtBOot9-1024.npz
eval_Episode has 500 steps and return 729.0.
Saved chunk: 20230922T073807F081563-7x0T64l3PHdtDX1v1sNIhU-5GoZFsmdFia8flLy8PcusY-1024.npz
train_Episode has 500 steps and return 714.0.
Starting evaluation at step 463000 Counter(463000) 462937
eval_Episode has 500 steps and return 226.0.
train_Episode has 500 steps and return 644.0.
Starting evaluation at step 463500 Counter(463500) 463437
Saved chunk: 20230922T073900F725875-2gepJcopl3xMHUiZtBOot9-0bsx1rF5XjPlVWReuyt5Tx-1024.npz
eval_Episode has 500 steps and return 700.0.
Saved chunk: 20230922T073926F434967-5GoZFsmdFia8flLy8PcusY-183FO0RJTsWWhWAfbVg5vF-1024.npz
train_Episode has 500 steps and return 707.0.
Starting evaluation at step 464000 Counter(464000) 463937
eval_Episode has 500 steps and return 706.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T074018F418676-0bsx1rF5XjPlVWReuyt5Tx-0000000000000000000000-631.npz
Saved chunk: 20230922T074045F585985-183FO0RJTsWWhWAfbVg5vF-0000000000000000000000-228.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 928770 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 707 / episode/reward_rate 0.71 / eval_episode/length 500 / eval_episode/score 706 / eval_episode/reward_rate 0.71 / train/action_mag 4.22 / train/action_max 4.05 / train/action_mean -0.04 / train/action_min -3.95 / train/action_std 0.99 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -5.23 / train/adv_mag 0.54 / train/adv_max 0.42 / train/adv_mean 4.1e-4 / train/adv_min -0.49 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.83 / train/extr_critic_max 671.83 / train/extr_critic_mean 634.86 / train/extr_critic_min 404.36 / train/extr_critic_std 57.91 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.63 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.98 / train/extr_return_raw_max 669.98 / train/extr_return_raw_mean 634.92 / train/extr_return_raw_min 406.86 / train/extr_return_raw_std 57.86
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.26 / train/model_loss_mean 1.21 / train/model_loss_std 2.02 / 
train/model_opt_grad_norm 5.66 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.42 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.42 / train/policy_logprob_min -8.69 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 5.1e-6 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.23 / train/post_ent_max 53.23 / train/post_ent_mean 37.82 / train/post_ent_min
27.28 / train/post_ent_std 4.65 / train/prior_ent_mag 64.43 / train/prior_ent_max 64.43 / train/prior_ent_mean 39.01 / train/prior_ent_min 30.95 / train/prior_ent_std 5.73 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.04 / train/reward_avg 1.37 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.29 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.69 / report/dyn_loss_std 3.45 / report/image_loss_mean 0.23 / report/image_loss_std 0.42 / report/model_loss_mean 1.3 / report/model_loss_std 2.36 / report/post_ent_mag 51.59 / report/post_ent_max 51.59 / 
report/post_ent_mean 40.32 / report/post_ent_min 30.34 / report/post_ent_std 4.86 / report/prior_ent_mag 64.57 / report/prior_ent_max 64.57 / report/prior_ent_mean 41.67 / report/prior_ent_min 32.13 / report/prior_ent_std 5.82 / report/rep_loss_mean 1.69 / 
report/rep_loss_std 3.45 / report/reward_avg 0.88 / report/reward_loss_mean 0.05 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 0.88 / report/reward_rate 0.44 / eval/cont_avg 1 / eval/cont_loss_mean 3.8e-11 / eval/cont_loss_std 8.3e-11 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.35 / eval/dyn_loss_std 2.07 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.13 / eval/model_loss_mean 1.03 / eval/model_loss_std 1.33 / eval/post_ent_mag 50.67 / eval/post_ent_max 50.67 / eval/post_ent_mean 
36.94 / eval/post_ent_min 28.16 / eval/post_ent_std 4.04 / eval/prior_ent_mag 64.57 / eval/prior_ent_max 64.57 / eval/prior_ent_mean 37.87 / eval/prior_ent_min 32.04 / eval/prior_ent_std 5.13 / eval/rep_loss_mean 1.35 / eval/rep_loss_std 2.07 / eval/reward_avg 1.7 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 9.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.7 / eval/reward_rate 0.85 / 
replay/size 4.6e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3884 / timer/env.step_total 19.44 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.13 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.47 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.2e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.48 / timer/agent.policy_frac 0.05 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1942 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.01 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / 
timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 736.0.
Starting evaluation at step 464500 Counter(464500) 464437
Saved chunk: 20230922T074018F418676-0bsx1rF5XjPlVWReuyt5Tx-0uS0FRFot8wZjwyi1nyehO-1024.npz
eval_Episode has 500 steps and return 718.0.
Saved chunk: 20230922T074045F585985-183FO0RJTsWWhWAfbVg5vF-7tZZahIcJqnprTaZ4qvovJ-1024.npz
train_Episode has 500 steps and return 733.0.
Starting evaluation at step 465000 Counter(465000) 464937
eval_Episode has 500 steps and return 724.0.
train_Episode has 500 steps and return 727.0.
Starting evaluation at step 465500 Counter(465500) 465437
Saved chunk: 20230922T074137F248297-0uS0FRFot8wZjwyi1nyehO-6Lwxc1lBUnppNoHv1rRpI2-1024.npz
eval_Episode has 500 steps and return 715.0.
Saved chunk: 20230922T074206F145901-7tZZahIcJqnprTaZ4qvovJ-55DrnQ9XQXN9z2KyJKtQUe-1024.npz
train_Episode has 500 steps and return 720.0.
Starting evaluation at step 466000 Counter(466000) 465937
eval_Episode has 500 steps and return 716.0.
train_Episode has 500 steps and return 707.0.
Starting evaluation at step 466500 Counter(466500) 466437
Saved chunk: 20230922T074255F139949-6Lwxc1lBUnppNoHv1rRpI2-2BUgvW3yq9Wh06x1z7cYkT-1024.npz
eval_Episode has 500 steps and return 702.0.
train_Episode has 500 steps and return 731.0.
Saved chunk: 20230922T074325F531507-55DrnQ9XQXN9z2KyJKtQUe-1tTKFvXXUkOqSdCZlsAez5-1024.npz
Starting evaluation at step 467000 Counter(467000) 466937
eval_Episode has 500 steps and return 702.0.
train_Episode has 500 steps and return 506.0.
Starting evaluation at step 467500 Counter(467500) 467437
Saved chunk: 20230922T074412F864179-2BUgvW3yq9Wh06x1z7cYkT-34prp5uA0B7YUAnBFCAuTr-1024.npz
eval_Episode has 500 steps and return 701.0.
train_Episode has 500 steps and return 469.0.
Saved chunk: 20230922T074444F773106-1tTKFvXXUkOqSdCZlsAez5-4jVun198m71yWCTT1MC32h-1024.npz
Starting evaluation at step 468000 Counter(468000) 467937
eval_Episode has 500 steps and return 548.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 936454 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 469 / episode/reward_rate 0.47 / eval_episode/length 500 / eval_episode/score 548 / eval_episode/reward_rate 0.55 / train/action_mag 4.36 / train/action_max 4.21 / train/action_mean -0.04 / train/action_min -4.12 / train/action_std 1.06 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -0.71 / train/adv_mag 0.54 / train/adv_max 0.41 / train/adv_mean -9.4e-5 / train/adv_min -0.48
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 
/ train/dyn_loss_std 3.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.2 / train/extr_critic_max 671.2 / train/extr_critic_mean 635.59 / train/extr_critic_min 413.78 / train/extr_critic_std 56.54 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.11 / train/extr_return_raw_max 669.11 / train/extr_return_raw_mean 635.57 / train/extr_return_raw_min 415.63 / train/extr_return_raw_std 56.69
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.42 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.2 / train/model_loss_std 2.02 / 
train/model_opt_grad_norm 5.43 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.56 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.94 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.56 / train/policy_logprob_min -8.94 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.63 / train/policy_randomness_min 5.8e-6 / train/policy_randomness_std 0.41 / train/post_ent_mag 52.97 / train/post_ent_max 52.97 / train/post_ent_mean 37.78 / train/post_ent_min
27.23 / train/post_ent_std 4.61 / train/prior_ent_mag 64.42 / train/prior_ent_max 64.42 / train/prior_ent_mean 38.97 / train/prior_ent_min 31.1 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.03 / train/reward_avg 1.4 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.4 / train/reward_rate 0.7 / 
train_stats/mean_log_entropy 0.4 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 6.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.08 / report/image_loss_mean 0.17 / report/image_loss_std 0.22 / report/model_loss_mean 1.22 / report/model_loss_std 2 / report/post_ent_mag 51.27 / report/post_ent_max 51.27 / 
report/post_ent_mean 38.14 / report/post_ent_min 29.34 / report/post_ent_std 5.15 / report/prior_ent_mag 64.03 / report/prior_ent_max 64.03 / report/prior_ent_mean 39.34 / report/prior_ent_min 32.12 / report/prior_ent_std 6.22 / report/rep_loss_mean 1.61 / 
report/rep_loss_std 3.08 / report/reward_avg 1.28 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.12 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 7.2e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 9e-11 / eval/cont_loss_std 1.2e-9 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9e-11 / eval/cont_pred 1 /
eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.83 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.17 / eval/model_loss_std 1.95 / eval/post_ent_mag 51.3 / eval/post_ent_max 51.3 / eval/post_ent_mean 37.87 / 
eval/post_ent_min 26.15 / eval/post_ent_std 4.23 / eval/prior_ent_mag 64.03 / eval/prior_ent_max 64.03 / eval/prior_ent_mean 38.83 / eval/prior_ent_min 32.05 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.83 / eval/reward_avg 1.62 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 5.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.62 / eval/reward_rate 0.81 / 
replay/size 4.7e5 / replay/inserts 3842 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3842 / timer/env.step_total 19.07 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 6.1e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.89 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.8e-3 / timer/replay._sample_max 0.18 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7850 / timer/agent.policy_total 17.12 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.1e-3 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.4 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.61

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 552.0.
Starting evaluation at step 468500 Counter(468500) 468437
eval_Episode has 500 steps and return 452.0.
Saved chunk: 20230922T074530F533855-34prp5uA0B7YUAnBFCAuTr-68MXpqC4iuyQv6ZqyUKAm3-1024.npz
train_Episode has 500 steps and return 438.0.
Saved chunk: 20230922T074603F867155-4jVun198m71yWCTT1MC32h-1m5gjMRLWjCuNRMM0CMG3C-1024.npz
Starting evaluation at step 469000 Counter(469000) 468937
eval_Episode has 500 steps and return 806.0.
train_Episode has 500 steps and return 463.0.
Starting evaluation at step 469500 Counter(469500) 469437
eval_Episode has 500 steps and return 468.0.
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 470000 Counter(470000) 469937
Saved chunk: 20230922T074649F181013-68MXpqC4iuyQv6ZqyUKAm3-38Cv4TLHWEoKEYjNjjRKaT-1024.npz
eval_Episode has 500 steps and return 718.0.
Saved chunk: 20230922T074724F307676-1m5gjMRLWjCuNRMM0CMG3C-1CRTjr9aQ1YZBSVcF6bzE4-1024.npz
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 470500 Counter(470500) 470437
eval_Episode has 500 steps and return 739.0.
train_Episode has 500 steps and return 745.0.
Starting evaluation at step 471000 Counter(471000) 470937
Saved chunk: 20230922T074842F511881-38Cv4TLHWEoKEYjNjjRKaT-4ZRvmGF5Todyh313g2JTC9-1024.npz
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T074846F987285-1CRTjr9aQ1YZBSVcF6bzE4-4dgnchMr8OZxzMhmTtCGZz-1024.npz
train_Episode has 500 steps and return 692.0.
Starting evaluation at step 471500 Counter(471500) 471437
eval_Episode has 500 steps and return 828.0.
train_Episode has 500 steps and return 828.0.
Starting evaluation at step 472000 Counter(472000) 471937
Saved chunk: 20230922T075000F229816-4ZRvmGF5Todyh313g2JTC9-6TWCBuriBisfjW2IrjbONi-1024.npz
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T075006F279408-4dgnchMr8OZxzMhmTtCGZz-4PEPIOWrYwye5MNaYPQMmO-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 944134 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 828 / episode/reward_rate 0.83 / eval_episode/length 500 / eval_episode/score 831 / eval_episode/reward_rate 0.83 / train/action_mag 4.36 / train/action_max 4.22 / train/action_mean -0.03 / train/action_min -4.1 / train/action_std 1.04 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.3e5 / train/actor_opt_loss -5.1 / train/adv_mag 0.5 / train/adv_max 0.42 / train/adv_mean 3.6e-4 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.09 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.3e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.29 / train/extr_critic_max 671.29 / train/extr_critic_mean 635.61 / train/extr_critic_min 420.4 / train/extr_critic_std 55.25 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.54 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.13 / train/extr_return_raw_max 669.13 / train/extr_return_raw_mean 635.67 / train/extr_return_raw_min 423.13 / train/extr_return_raw_std 55.25
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.18 / train/image_loss_std 0.29 / train/model_loss_mean 1.22 / train/model_loss_std 2.06 / 
train/model_opt_grad_norm 5.51 / train/model_opt_grad_steps 2.3e5 / train/model_opt_loss 9762.42 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7994.79 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.52 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.91 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.52 / train/policy_logprob_min -8.91 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 5.2e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.55 / train/post_ent_max 52.55 / train/post_ent_mean 37.83 / train/post_ent_min 
27.4 / train/post_ent_std 4.56 / train/prior_ent_mag 64.41 / train/prior_ent_max 64.41 / train/prior_ent_mean 39.04 / train/prior_ent_min 31.26 / train/prior_ent_std 5.67 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.09 / train/reward_avg 1.38 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.34 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 5.4e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.62 / report/dyn_loss_std 3.68 / report/image_loss_mean 0.18 / report/image_loss_std 0.29 / report/model_loss_mean 1.24 / report/model_loss_std 2.46 / report/post_ent_mag 49.52 / report/post_ent_max 49.52 / 
report/post_ent_mean 38.36 / report/post_ent_min 29.38 / report/post_ent_std 4.43 / report/prior_ent_mag 64.52 / report/prior_ent_max 64.52 / report/prior_ent_mean 39.58 / report/prior_ent_min 30.42 / report/prior_ent_std 5.49 / report/rep_loss_mean 1.62 / 
report/rep_loss_std 3.68 / report/reward_avg 1.23 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.14 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.8e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.13 / report/reward_pred 1.23 / report/reward_rate 0.62 / eval/cont_avg 1 / eval/cont_loss_mean 3.9e-11 / eval/cont_loss_std 1.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.55 / eval/dyn_loss_std 2.82 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.86 / eval/post_ent_mag 50.81 / eval/post_ent_max 50.81 / eval/post_ent_mean 
37.11 / eval/post_ent_min 29.34 / eval/post_ent_std 4.11 / eval/prior_ent_mag 64.52 / eval/prior_ent_max 64.52 / eval/prior_ent_mean 38.31 / eval/prior_ent_min 32.18 / eval/prior_ent_std 5.4 / eval/rep_loss_mean 1.55 / eval/rep_loss_std 2.82 / eval/reward_avg 1.61 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.17 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.94 / eval/reward_neg_loss 0.04 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.61 / eval/reward_rate 0.81 / 
replay/size 4.7e5 / replay/inserts 3840 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3840 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.2e-3 / timer/env.step_max 6.6e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.82 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7848 / timer/agent.policy_total 17.27 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 9.1e-3 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.5e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.19 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 472500 Counter(472500) 472437
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 473000 Counter(473000) 472937
Saved chunk: 20230922T075117F852721-6TWCBuriBisfjW2IrjbONi-3shSMXOC0LYWDGexpNbOeB-1024.npz
eval_Episode has 500 steps and return 837.0.
Saved chunk: 20230922T075125F464301-4PEPIOWrYwye5MNaYPQMmO-5PdRPxQbKhG5wJQuP5w4TW-1024.npz
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 473500 Counter(473500) 473437
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 831.0.
Starting evaluation at step 474000 Counter(474000) 473937
Saved chunk: 20230922T075236F829202-3shSMXOC0LYWDGexpNbOeB-7pVanz93kj1K6XISWNnwqJ-1024.npz
eval_Episode has 500 steps and return 821.0.
Saved chunk: 20230922T075245F992436-5PdRPxQbKhG5wJQuP5w4TW-6ucRz3nLlGcrUZKRUXgiYH-1024.npz
train_Episode has 500 steps and return 833.0.
Starting evaluation at step 474500 Counter(474500) 474437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 475000 Counter(475000) 474937
Saved chunk: 20230922T075354F695506-7pVanz93kj1K6XISWNnwqJ-3FSChmbX7f2bwCczDAPkpB-1024.npz
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T075405F430670-6ucRz3nLlGcrUZKRUXgiYH-1qawTh7arXlfpp8t4d80yj-1024.npz
train_Episode has 500 steps and return 813.0.
Starting evaluation at step 475500 Counter(475500) 475437
eval_Episode has 500 steps and return 844.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T075524F516125-1qawTh7arXlfpp8t4d80yj-0000000000000000000000-564.npz
Saved chunk: 20230922T075512F336148-3FSChmbX7f2bwCczDAPkpB-0000000000000000000000-890.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 838.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 951906 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 838 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / train/action_mag 4.27 / train/action_max 4.17 / train/action_mean -0.01 / train/action_min -3.97 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -2.07 / train/adv_mag 0.52 / train/adv_max 0.41 / train/adv_mean 6.7e-5 / train/adv_min -0.47 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.08 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.52 / train/extr_critic_max 671.52 / train/extr_critic_mean 637.32 / train/extr_critic_min 439.75 / train/extr_critic_std 52.46 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.51 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669.05 / train/extr_return_raw_max 669.05 / train/extr_return_raw_mean 637.33 / train/extr_return_raw_min 440.54 / train/extr_return_raw_std 52.55
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.42 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.2 / train/model_loss_std 2.01 / 
train/model_opt_grad_norm 5.44 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.1e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 9407.22 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.8 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.8 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 4.9e-6 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.41 / train/post_ent_max 53.41 / train/post_ent_mean 37.7 / train/post_ent_min 
26.74 / train/post_ent_std 4.6 / train/prior_ent_mag 64.38 / train/prior_ent_max 64.38 / train/prior_ent_mean 38.89 / train/prior_ent_min 31.23 / train/prior_ent_std 5.69 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.01 / train/reward_avg 1.39 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.7 / 
train_stats/mean_log_entropy 0.47 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.47 / report/dyn_loss_std 2.52 / report/image_loss_mean 0.15 / report/image_loss_std 0.2 / report/model_loss_mean 1.12 / report/model_loss_std 1.66 / report/post_ent_mag 50.2 / report/post_ent_max 50.2 / 
report/post_ent_mean 37.42 / report/post_ent_min 27.32 / report/post_ent_std 3.98 / report/prior_ent_mag 63.88 / report/prior_ent_max 63.88 / report/prior_ent_mean 38.43 / report/prior_ent_min 32.09 / report/prior_ent_std 5.02 / report/rep_loss_mean 1.47 / 
report/rep_loss_std 2.52 / report/reward_avg 1.65 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.12 / report/reward_pred 1.65 / report/reward_rate 0.82 / eval/cont_avg 1 / eval/cont_loss_mean 3.5e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 3.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.77 / eval/dyn_loss_std 3.92 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.34 / eval/model_loss_mean 1.34 / eval/model_loss_std 2.58 / eval/post_ent_mag 52.14 / eval/post_ent_max 52.14 / eval/post_ent_mean 38.01 / eval/post_ent_min 26.04 / 
eval/post_ent_std 4.42 / eval/prior_ent_mag 63.88 / eval/prior_ent_max 63.88 / eval/prior_ent_mean 39.3 / eval/prior_ent_min 31.81 / eval/prior_ent_std 5.57 / eval/rep_loss_mean 1.77 / eval/rep_loss_std 3.92 / eval/reward_avg 1.28 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.28 / eval/reward_rate 0.64 / replay/size 4.8e5 / replay/inserts 3886 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.09 / timer/env.step_count 3886 / timer/env.step_total 19.35 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.2e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.47 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.9e-4 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / 
timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.43 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1943 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 4.2e-4 / 
timer/agent.train_count 1943 / timer/agent.train_total 246.18 / timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 476000 Counter(476000) 475937
Saved chunk: 20230922T075512F336148-3FSChmbX7f2bwCczDAPkpB-2IASUACwxuNM6iQpz0gC3F-1024.npz
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T075524F516125-1qawTh7arXlfpp8t4d80yj-3pWIYufcBQHBQZowD9Sq8U-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 476500 Counter(476500) 476437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 477000 Counter(477000) 476937
Saved chunk: 20230922T075630F999833-2IASUACwxuNM6iQpz0gC3F-1SwaugGg1pyMNteKjfjSFg-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T075644F884775-3pWIYufcBQHBQZowD9Sq8U-0XjqaXiII1zNlR0EEQglew-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 477500 Counter(477500) 477437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 478000 Counter(478000) 477937
Saved chunk: 20230922T075748F995560-1SwaugGg1pyMNteKjfjSFg-1HBXG9wrQAzobRGDw35VaL-1024.npz
eval_Episode has 500 steps and return 719.0.
Saved chunk: 20230922T075804F420504-0XjqaXiII1zNlR0EEQglew-2DmOnsgycgeMBucQSn1ydV-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 478500 Counter(478500) 478437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 772.0.
Starting evaluation at step 479000 Counter(479000) 478937
Saved chunk: 20230922T075906F733825-1HBXG9wrQAzobRGDw35VaL-0zQDzbwnJdgRq3GhTdz3s6-1024.npz
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T075923F673813-2DmOnsgycgeMBucQSn1ydV-26qv3eLAt4pPflfTohvYRv-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 479500 Counter(479500) 479437
eval_Episode has 500 steps and return 835.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 959584 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 835 / eval_episode/reward_rate 0.83 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / train/action_mag 4.3 / train/action_max 4.17 / train/action_mean -0.02 / train/action_min -4.07 / train/action_std 1.03 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -0.85 / train/adv_mag 0.53 / train/adv_max 0.43 / train/adv_mean -6.1e-5 / train/adv_min -0.48 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.6 / 
train/dyn_loss_std 3.16 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.1 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.84 / train/extr_critic_max 670.84 / train/extr_critic_mean 635.73 / train/extr_critic_min 435.05 / train/extr_critic_std 53.75 / train/extr_return_normed_mag 1.02 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.53 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.82 / train/extr_return_raw_max 668.82 / train/extr_return_raw_mean 635.72 / train/extr_return_raw_min 434.63 / train/extr_return_raw_std 53.87
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.39 / train/extr_reward_min 0 / train/extr_reward_std 0.89 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.22 / train/model_loss_std 2.11 / 
train/model_opt_grad_norm 5.54 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.5 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.89 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.5 / train/policy_logprob_min -8.89 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 9.9e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.2 / train/post_ent_max 52.2 / train/post_ent_mean 37.83 / train/post_ent_min 
27.03 / train/post_ent_std 4.56 / train/prior_ent_mag 64.16 / train/prior_ent_max 64.16 / train/prior_ent_mean 39.02 / train/prior_ent_min 31.07 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.6 / train/rep_loss_std 3.16 / train/reward_avg 1.37 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.37 / train/reward_rate 0.69 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.55 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 5.7e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.35 / report/dyn_loss_std 1.93 / report/image_loss_mean 0.11 / report/image_loss_std 0.1 / report/model_loss_mean 1.02 / report/model_loss_std 1.23 / report/post_ent_mag 60.75 / report/post_ent_max 60.75 / 
report/post_ent_mean 36.52 / report/post_ent_min 26.73 / report/post_ent_std 3.39 / report/prior_ent_mag 64.22 / report/prior_ent_max 64.22 / report/prior_ent_mean 37.5 / report/prior_ent_min 31.59 / report/prior_ent_std 4.7 / report/rep_loss_mean 1.35 / 
report/rep_loss_std 1.93 / report/reward_avg 1.74 / report/reward_loss_mean 0.11 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 5.6e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.74 / report/reward_rate 0.87 / eval/cont_avg 1 / eval/cont_loss_mean 5.7e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 2.15 / eval/dyn_loss_std 4.56 / eval/image_loss_mean 0.33 / eval/image_loss_std 0.86 / eval/model_loss_mean 1.71 / eval/model_loss_std 3.37 / eval/post_ent_mag 50.17 / eval/post_ent_max 50.17 / eval/post_ent_mean 
37.84 / eval/post_ent_min 22.21 / eval/post_ent_std 4 / eval/prior_ent_mag 64.22 / eval/prior_ent_max 64.22 / eval/prior_ent_mean 39.49 / eval/prior_ent_min 31.89 / eval/prior_ent_std 5.15 / eval/rep_loss_mean 2.15 / eval/rep_loss_std 4.56 / eval/reward_avg 1.42 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.22 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.42 / eval/reward_rate 0.71 / 
replay/size 4.8e5 / replay/inserts 3839 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3839 / timer/env.step_total 19.27 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.47 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.2e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7847 / timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.3e-3 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.1e-4 / timer/agent.train_count 1919 / timer/agent.train_total 243.02 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.2e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.2e-5 / timer/dataset_eval_min 4.2e-5 / timer/dataset_eval_max 4.2e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 480000 Counter(480000) 479937
Saved chunk: 20230922T080024F446599-0zQDzbwnJdgRq3GhTdz3s6-5Ayxl6arGvExOK4rVE3FLn-1024.npz
eval_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T080042F875593-26qv3eLAt4pPflfTohvYRv-5cpAyuZrFK9vCUFdXYMMy5-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 480500 Counter(480500) 480437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 834.0.
Starting evaluation at step 481000 Counter(481000) 480937
Saved chunk: 20230922T080143F145200-5Ayxl6arGvExOK4rVE3FLn-0HDuZGblsstND6KnwMmD70-1024.npz
eval_Episode has 500 steps and return 670.0.
Saved chunk: 20230922T080203F263502-5cpAyuZrFK9vCUFdXYMMy5-4I8s1lrb7TQjsLqMpTwTH9-1024.npz
train_Episode has 500 steps and return 737.0.
Starting evaluation at step 481500 Counter(481500) 481437
eval_Episode has 500 steps and return 746.0.
train_Episode has 500 steps and return 751.0.
Starting evaluation at step 482000 Counter(482000) 481937
Saved chunk: 20230922T080301F018819-0HDuZGblsstND6KnwMmD70-7Dbw7hqki9xgPpm7pXaQ1Q-1024.npz
eval_Episode has 500 steps and return 751.0.
Saved chunk: 20230922T080322F619984-4I8s1lrb7TQjsLqMpTwTH9-0NQesDzQQlftdrVgLJr6H7-1024.npz
train_Episode has 500 steps and return 750.0.
Starting evaluation at step 482500 Counter(482500) 482437
eval_Episode has 500 steps and return 751.0.
train_Episode has 500 steps and return 441.0.
Starting evaluation at step 483000 Counter(483000) 482937
Saved chunk: 20230922T080418F704556-7Dbw7hqki9xgPpm7pXaQ1Q-4SRv8bNviekbS9OWVyprCv-1024.npz
eval_Episode has 500 steps and return 749.0.
Saved chunk: 20230922T080441F829449-0NQesDzQQlftdrVgLJr6H7-6ezlwaz8gycFuQ11idXypk-1024.npz
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 483500 Counter(483500) 483437
eval_Episode has 500 steps and return 748.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 967262 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 740 / episode/reward_rate 0.74 / eval_episode/length 500 / eval_episode/score 748 / eval_episode/reward_rate 0.75 / train/action_mag 4.26 / train/action_max 4.08 / train/action_mean -0.03 / train/action_min -4.02 / train/action_std 0.99 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -5.39 / train/adv_mag 0.53 / train/adv_max 0.45 / train/adv_mean 4.2e-4 / train/adv_min -0.44 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 
/ train/dyn_loss_std 3.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.09 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.63 / train/extr_critic_max 670.63 / train/extr_critic_mean 636.1 / train/extr_critic_min 422.02 / train/extr_critic_std 54.95 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.56 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.73 / train/extr_return_raw_max 668.73 / train/extr_return_raw_mean 636.16 / train/extr_return_raw_min 423.46 / train/extr_return_raw_std 54.95
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.41 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / train/model_loss_std 2.03 / 
train/model_opt_grad_norm 5.23 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.87 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.87 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.93 / train/post_ent_max 52.93 / train/post_ent_mean 37.72 / train/post_ent_min 
27.4 / train/post_ent_std 4.52 / train/prior_ent_mag 64.41 / train/prior_ent_max 64.41 / train/prior_ent_mean 38.9 / train/prior_ent_min 31.34 / train/prior_ent_std 5.64 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.04 / train/reward_avg 1.39 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy -0.18 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 2.79 / report/image_loss_mean 0.15 / report/image_loss_std 0.26 / report/model_loss_mean 1.16 / report/model_loss_std 1.88 / report/post_ent_mag 52.92 / report/post_ent_max 52.92 / 
report/post_ent_mean 37.4 / report/post_ent_min 29.55 / report/post_ent_std 4.68 / report/prior_ent_mag 63.88 / report/prior_ent_max 63.88 / report/prior_ent_mean 38.55 / report/prior_ent_min 32.25 / report/prior_ent_std 5.83 / report/rep_loss_mean 1.54 / 
report/rep_loss_std 2.79 / report/reward_avg 1.55 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.9e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.55 / report/reward_rate 0.78 / eval/cont_avg 1 / eval/cont_loss_mean 4.1e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 3.17 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.22 / eval/model_loss_std 2.06 / eval/post_ent_mag 50.34 / eval/post_ent_max 50.34 / eval/post_ent_mean 
36.55 / eval/post_ent_min 28.66 / eval/post_ent_std 3.38 / eval/prior_ent_mag 63.88 / eval/prior_ent_max 63.88 / eval/prior_ent_mean 37.67 / eval/prior_ent_min 32.21 / eval/prior_ent_std 4.81 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.17 / eval/reward_avg 1.76 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.98 / eval/reward_neg_loss 0.01 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.76 / eval/reward_rate 0.88 / replay/size
4.8e5 / replay/inserts 3839 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300 / timer/env.step_count 3839 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.1e-3 / timer/env.step_max 0.16 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 387.74 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.1e-3 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7847 / timer/agent.policy_total 17.08 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 8.8e-3 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 7.9e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 4.9e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.23 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 740.0.
Starting evaluation at step 484000 Counter(484000) 483937
Saved chunk: 20230922T080536F376556-4SRv8bNviekbS9OWVyprCv-3RkvzeADSxyJimwTr2YMsz-1024.npz
eval_Episode has 500 steps and return 822.0.
Saved chunk: 20230922T080601F011413-6ezlwaz8gycFuQ11idXypk-4KFZdT6mRfRolDv8uS4LuK-1024.npz
train_Episode has 500 steps and return 824.0.
Starting evaluation at step 484500 Counter(484500) 484437
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 485000 Counter(485000) 484937
Saved chunk: 20230922T080655F131160-3RkvzeADSxyJimwTr2YMsz-7qkOhiPSTN0N92HBxlp8Ay-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T080721F459481-4KFZdT6mRfRolDv8uS4LuK-5I5FVAssV9B59K9iNlCObn-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 485500 Counter(485500) 485437
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 486000 Counter(486000) 485937
Saved chunk: 20230922T080813F011304-7qkOhiPSTN0N92HBxlp8Ay-5JNz9zEzYn3Qpn8anfh7uf-1024.npz
eval_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T080840F810524-5I5FVAssV9B59K9iNlCObn-5JVnRxEurfEc2E1s74M7wc-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 486500 Counter(486500) 486437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 487000 Counter(487000) 486937
Saved chunk: 20230922T080930F785915-5JNz9zEzYn3Qpn8anfh7uf-7M2H3d8U3HjHCYmjG0XEST-1024.npz
eval_Episode has 500 steps and return 736.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T081000F107128-5JVnRxEurfEc2E1s74M7wc-0000000000000000000000-900.npz
Saved chunk: 20230922T081048F431622-7M2H3d8U3HjHCYmjG0XEST-0000000000000000000000-125.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T081000F107128-5JVnRxEurfEc2E1s74M7wc-0Eq5y7F7TxhWmy0BkefwrZ-1024.npz
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 487500 Counter(487500) 487437
eval_Episode has 500 steps and return 715.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 975002 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 734 / episode/reward_rate 0.73 / eval_episode/length 500 / eval_episode/score 715 / eval_episode/reward_rate 0.71 / train/action_mag 4.37 / train/action_max 4.25 / train/action_mean -2.9e-3 / train/action_min -4.1 / train/action_std 1.04
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -2.91 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 1.3e-4 / train/adv_min -0.46 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.59 / 
train/dyn_loss_std 3.07 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.16 / train/extr_critic_max 671.16 / train/extr_critic_mean 637.88 / train/extr_critic_min 469.46 / train/extr_critic_std 48.67 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.45 / train/extr_return_raw_max 668.45 / train/extr_return_raw_mean 637.9 / train/extr_return_raw_min 469.17 / train/extr_return_raw_std 48.69 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.41 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.21 / train/model_loss_std 2.04 / 
train/model_opt_grad_norm 5.69 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 8950.25 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7422.68 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.55 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.93 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.55 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.17 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.62 / train/policy_randomness_min 8.7e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.66 / train/post_ent_max 52.66 / train/post_ent_mean 37.82 / train/post_ent_min 
27.27 / train/post_ent_std 4.51 / train/prior_ent_mag 64.39 / train/prior_ent_max 64.39 / train/prior_ent_mean 39.01 / train/prior_ent_min 31.5 / train/prior_ent_std 5.61 / train/rep_loss_mean 1.59 / train/rep_loss_std 3.07 / train/reward_avg 1.39 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.8e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.7 / 
train_stats/mean_log_entropy 0.69 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.4e-11 / report/cont_loss_std 8.5e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 3.28 / report/image_loss_mean 0.17 / report/image_loss_std 0.31 / report/model_loss_mean 1.21 / report/model_loss_std 2.21 / report/post_ent_mag 61.36 / report/post_ent_max 61.36 / 
report/post_ent_mean 36.94 / report/post_ent_min 27.57 / report/post_ent_std 4.04 / report/prior_ent_mag 64.51 / report/prior_ent_max 64.51 / report/prior_ent_mean 38.09 / report/prior_ent_min 32.1 / report/prior_ent_std 5.21 / report/rep_loss_mean 1.58 / 
report/rep_loss_std 3.28 / report/reward_avg 1.48 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.98 / report/reward_neg_loss 8.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.49 / report/reward_rate 0.74 / eval/cont_avg 1 / eval/cont_loss_mean 8.3e-11 / eval/cont_loss_std 5.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 3.18 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.19 / eval/model_loss_std 2.05 / eval/post_ent_mag 50.42 / eval/post_ent_max 50.42 / eval/post_ent_mean 
36.88 / eval/post_ent_min 29.04 / eval/post_ent_std 3.57 / eval/prior_ent_mag 64.51 / eval/prior_ent_max 64.51 / eval/prior_ent_mean 38.05 / eval/prior_ent_min 31.7 / eval/prior_ent_std 4.89 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 3.18 / eval/reward_avg 1.63 / 
eval/reward_loss_mean 0.11 / eval/reward_loss_std 0.25 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.96 / eval/reward_neg_loss 0.09 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.64 / eval/reward_rate 0.82 / 
replay/size 4.9e5 / replay/inserts 3870 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 302.5 / timer/env.step_count 3870 / timer/env.step_total 19.32 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.11 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.52 / timer/replay._sample_frac 1.29 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.4e-3 / timer/replay._sample_max 0.04 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7878 / timer/agent.policy_total 17.62 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.17 / timer/dataset_train_count 1935 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / 
timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1935 / timer/agent.train_total 245.07 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.13 
/ timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / 
timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 690.0.
Starting evaluation at step 488000 Counter(488000) 487937
Saved chunk: 20230922T081048F431622-7M2H3d8U3HjHCYmjG0XEST-3DK6hYDvv3bqYRDVdHELwG-1024.npz
eval_Episode has 500 steps and return 718.0.
Saved chunk: 20230922T081119F471270-0Eq5y7F7TxhWmy0BkefwrZ-31kvzEzpfFPCATQneld38J-1024.npz
train_Episode has 500 steps and return 707.0.
Starting evaluation at step 488500 Counter(488500) 488437
eval_Episode has 500 steps and return 707.0.
train_Episode has 500 steps and return 710.0.
Starting evaluation at step 489000 Counter(489000) 488937
Saved chunk: 20230922T081207F595658-3DK6hYDvv3bqYRDVdHELwG-6UYZA2iuhtzIKOMjFGJ3F3-1024.npz
eval_Episode has 500 steps and return 749.0.
Saved chunk: 20230922T081240F148235-31kvzEzpfFPCATQneld38J-6KFuA22mdypz7Ncn5EAxpw-1024.npz
train_Episode has 500 steps and return 761.0.
Starting evaluation at step 489500 Counter(489500) 489437
eval_Episode has 500 steps and return 645.0.
train_Episode has 500 steps and return 722.0.
Starting evaluation at step 490000 Counter(490000) 489937
Saved chunk: 20230922T081325F520361-6UYZA2iuhtzIKOMjFGJ3F3-2m9hktpFUZr83reqd1sMMm-1024.npz
eval_Episode has 500 steps and return 720.0.
train_Episode has 500 steps and return 665.0.
Starting evaluation at step 490500 Counter(490500) 490437
Saved chunk: 20230922T081359F518691-6KFuA22mdypz7Ncn5EAxpw-55NIuYbth82rtjL980GilX-1024.npz
eval_Episode has 500 steps and return 825.0.
train_Episode has 500 steps and return 646.0.
Starting evaluation at step 491000 Counter(491000) 490937
eval_Episode has 500 steps and return 823.0.
Saved chunk: 20230922T081443F219642-2m9hktpFUZr83reqd1sMMm-48x3UIzXW98EsoBCxLLn6V-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 982770 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 646 / episode/reward_rate 0.64 / eval_episode/length 500 / eval_episode/score 823 / eval_episode/reward_rate 0.82 / train/action_mag 4.32 / train/action_max 4.15 / train/action_mean -5e-3 / train/action_min -4.12 / train/action_std 1.03 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.4e5 / train/actor_opt_loss -2.6 / train/adv_mag 0.48 / train/adv_max 0.37 / train/adv_mean 1.1e-4 / train/adv_min -0.44 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.4e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.47 / train/extr_critic_max 670.47 / train/extr_critic_mean 638.69 / train/extr_critic_min 458.99 / train/extr_critic_std 48.78 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.49 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.34 / train/extr_return_raw_max 668.34 / train/extr_return_raw_mean 638.71 / train/extr_return_raw_min 459.64 / train/extr_return_raw_std 48.83
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.43 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.2 / train/model_loss_std 2.03 / 
train/model_opt_grad_norm 5.44 / train/model_opt_grad_steps 2.4e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.53 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.98 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.53 / train/policy_logprob_min -8.98 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.62 / train/policy_randomness_min 6.6e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.23 / train/post_ent_max 53.23 / train/post_ent_mean 37.71 / train/post_ent_min 
27.11 / train/post_ent_std 4.43 / train/prior_ent_mag 64.41 / train/prior_ent_max 64.41 / train/prior_ent_mean 38.89 / train/prior_ent_min 31.14 / train/prior_ent_std 5.55 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.04 / train/reward_avg 1.4 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.4 / train/reward_rate 0.7 / 
train_stats/mean_log_entropy 0.39 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.5e-11 / report/cont_loss_std 1.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.39 / report/dyn_loss_std 2.12 / report/image_loss_mean 0.12 / report/image_loss_std 0.13 / report/model_loss_mean 1.06 / report/model_loss_std 1.36 / report/post_ent_mag 50.7 / report/post_ent_max 50.7 / 
report/post_ent_mean 37.7 / report/post_ent_min 32.37 / report/post_ent_std 3.46 / report/prior_ent_mag 64.53 / report/prior_ent_max 64.53 / report/prior_ent_mean 38.75 / report/prior_ent_min 34.8 / report/prior_ent_std 4.79 / report/rep_loss_mean 1.39 / 
report/rep_loss_std 2.12 / report/reward_avg 1.74 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 1.8e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.73 / report/reward_rate 0.87 / eval/cont_avg 1 / eval/cont_loss_mean 5.1e-11 / eval/cont_loss_std 4.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.1e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.65 / eval/dyn_loss_std 3.55 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.44 / eval/post_ent_mag 52.65 / eval/post_ent_max 52.65 / eval/post_ent_mean 
38.29 / eval/post_ent_min 25.58 / eval/post_ent_std 4.13 / eval/prior_ent_mag 64.53 / eval/prior_ent_max 64.53 / eval/prior_ent_mean 39.54 / eval/prior_ent_min 32.66 / eval/prior_ent_std 5.21 / eval/rep_loss_mean 1.65 / eval/rep_loss_std 3.55 / eval/reward_avg 1.27 / 
eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.19 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.9e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.27 / eval/reward_rate 0.64 / replay/size
4.9e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.04 / timer/env.step_count 3884 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.1e-3 / timer/env.step_max 8.7e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 398.09 / timer/replay._sample_frac 1.33 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.7e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.45 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1942 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.17 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.9e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 822.0.
Starting evaluation at step 491500 Counter(491500) 491437
eval_Episode has 500 steps and return 832.0.
Saved chunk: 20230922T081518F795761-55NIuYbth82rtjL980GilX-2ootnxdn4qo6nat04uRhfM-1024.npz
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 492000 Counter(492000) 491937
eval_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T081600F860128-48x3UIzXW98EsoBCxLLn6V-2UGNIUD4F3UzXm0ttCQPfq-1024.npz
train_Episode has 500 steps and return 836.0.
Starting evaluation at step 492500 Counter(492500) 492437
eval_Episode has 500 steps and return 840.0.
Saved chunk: 20230922T081642F381500-2ootnxdn4qo6nat04uRhfM-0SqXI0rUGUJbvhzNE0a2YO-1024.npz
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 493000 Counter(493000) 492937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 493500 Counter(493500) 493437
Saved chunk: 20230922T081719F821823-2UGNIUD4F3UzXm0ttCQPfq-7s2Eft61fRWaiXUSigwMBd-1024.npz
eval_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T081801F864263-0SqXI0rUGUJbvhzNE0a2YO-6pUjBHkpkjYpQaYnpGiYrI-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 494000 Counter(494000) 493937
eval_Episode has 500 steps and return 812.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 494500 Counter(494500) 494437
Saved chunk: 20230922T081912F935585-7s2Eft61fRWaiXUSigwMBd-4a1LgBgCOybjGoqpFzofob-1024.npz
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T081921F093200-6pUjBHkpkjYpQaYnpGiYrI-3qBFMfdGA46Ks2DC7eQfLZ-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 495000 Counter(495000) 494937
eval_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 990456 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / train/action_mag 4.13 / train/action_max 3.99 / train/action_mean 7.4e-3 / train/action_min -3.86 / train/action_std 0.93
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -3.12 / train/adv_mag 0.5 / train/adv_max 0.37 / train/adv_mean 2.4e-4 / train/adv_min -0.45 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 2.9e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 2.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.16 / train/extr_critic_max 671.16 / train/extr_critic_mean 638.21 / train/extr_critic_min 475.54 / train/extr_critic_std 48.61 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 669 / train/extr_return_raw_max 669 / train/extr_return_raw_mean 638.25 / train/extr_return_raw_min 474.9 / train/extr_return_raw_std 48.66 / 
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.41 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / train/model_loss_std 2.02 / 
train/model_opt_grad_norm 5.63 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.27 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.86 / train/policy_logprob_mag 8.66 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.27 / train/policy_logprob_min -8.66 / train/policy_logprob_std 1.12 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.5 / train/policy_randomness_min 6.2e-6 / train/policy_randomness_std 0.37 / train/post_ent_mag 53.58 / train/post_ent_max 53.58 / train/post_ent_mean 37.77 / train/post_ent_min 
27.14 / train/post_ent_std 4.41 / train/prior_ent_mag 64.34 / train/prior_ent_max 64.34 / train/prior_ent_mean 38.96 / train/prior_ent_min 31.24 / train/prior_ent_std 5.53 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.03 / train/reward_avg 1.38 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy -0.05 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.6e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.6e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.66 / report/dyn_loss_std 3.45 / report/image_loss_mean 0.19 / report/image_loss_std 0.25 / report/model_loss_mean 1.25 / report/model_loss_std 2.26 / report/post_ent_mag 49.89 / report/post_ent_max 49.89 / 
report/post_ent_mean 38.12 / report/post_ent_min 26.42 / report/post_ent_std 5.06 / report/prior_ent_mag 64.12 / report/prior_ent_max 64.12 / report/prior_ent_mean 39.43 / report/prior_ent_min 31.84 / report/prior_ent_std 6.02 / report/rep_loss_mean 1.66 / 
report/rep_loss_std 3.45 / report/reward_avg 1.11 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.4e-4 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.11 / report/reward_rate 0.56 / eval/cont_avg 1 / eval/cont_loss_mean 4.9e-11 / eval/cont_loss_std 1.1e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.4 / eval/dyn_loss_std 2.13 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.48 / eval/post_ent_mag 49.94 / eval/post_ent_max 49.94 / eval/post_ent_mean 
37.88 / eval/post_ent_min 27.05 / eval/post_ent_std 3.47 / eval/prior_ent_mag 64.12 / eval/prior_ent_max 64.12 / eval/prior_ent_mean 38.87 / eval/prior_ent_min 35.07 / eval/prior_ent_std 4.75 / eval/rep_loss_mean 1.4 / eval/rep_loss_std 2.13 / eval/reward_avg 1.7 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.18 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.02 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.71 / eval/reward_rate 0.85 / replay/size
5e5 / replay/inserts 3843 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3843 / timer/env.step_total 19.1 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.01 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.29 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7851 / timer/agent.policy_total 17.16 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1921 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.2e-5 / timer/dataset_train_max 4.3e-4 / timer/agent.train_count 1921 / timer/agent.train_total 243.26 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.62

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 823.0.
Starting evaluation at step 495500 Counter(495500) 495437
Saved chunk: 20230922T082030F500241-4a1LgBgCOybjGoqpFzofob-1Mt58EjrYMZSyvNVT9opzw-1024.npz
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T082040F193587-3qBFMfdGA46Ks2DC7eQfLZ-6HmjyLSADM0VV7GyidJwpo-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 496000 Counter(496000) 495937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 496500 Counter(496500) 496437
Saved chunk: 20230922T082149F083446-1Mt58EjrYMZSyvNVT9opzw-2bHjbRV4xyocg6iDjKTEJp-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T082200F404899-6HmjyLSADM0VV7GyidJwpo-4w9KpUvpweOv16o71E2oAn-1024.npz
train_Episode has 500 steps and return 835.0.
Starting evaluation at step 497000 Counter(497000) 496937
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 497500 Counter(497500) 497437
Saved chunk: 20230922T082307F029842-2bHjbRV4xyocg6iDjKTEJp-6ac4Ft6odV2oqPWeqr4Ion-1024.npz
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T082319F804846-4w9KpUvpweOv16o71E2oAn-3HtdUZiwOW9FtjNMvtMD42-1024.npz
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 498000 Counter(498000) 497937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 498500 Counter(498500) 498437
Saved chunk: 20230922T082426F600638-6ac4Ft6odV2oqPWeqr4Ion-5yiLWLH6osIRt27AK9lXF1-1024.npz
eval_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T082440F916260-3HtdUZiwOW9FtjNMvtMD42-4RdJ1LsgMHpPKsHfe8JZfH-1024.npz
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T082544F010014-5yiLWLH6osIRt27AK9lXF1-0000000000000000000000-384.npz
Saved chunk: 20230922T082559F835006-4RdJ1LsgMHpPKsHfe8JZfH-0000000000000000000000-212.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 499000 Counter(499000) 498937
eval_Episode has 500 steps and return 844.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 998086 ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 844 / eval_episode/reward_rate 0.84 / train/action_mag 4.33 / train/action_max 4.19 / train/action_mean 9.8e-3 / train/action_min -4.06 / train/action_std 1.01
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -1.28 / train/adv_mag 0.5 / train/adv_max 0.37 / train/adv_mean -1.2e-5 / train/adv_min -0.45 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 671.22 / train/extr_critic_max 671.22 / train/extr_critic_mean 638.53 / train/extr_critic_min 478.83 / train/extr_critic_std 47.84 / train/extr_return_normed_mag 1 / train/extr_return_normed_max 1 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.39 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.67 / train/extr_return_raw_max 668.67 / train/extr_return_raw_mean 638.52 / train/extr_return_raw_min 476.73 / train/extr_return_raw_std 47.91
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.4 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.26 / train/model_loss_mean 1.2 / train/model_loss_std 1.99 / 
train/model_opt_grad_norm 5.38 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 8855.26 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.89 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.89 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 1.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 53.56 / train/post_ent_max 53.56 / train/post_ent_mean 37.87 / train/post_ent_min
27.44 / train/post_ent_std 4.36 / train/prior_ent_mag 64.33 / train/prior_ent_max 64.33 / train/prior_ent_mean 39.05 / train/prior_ent_min 31.58 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.58 / train/rep_loss_std 3 / train/reward_avg 1.38 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.38 / train/reward_rate 0.69 / 
train_stats/mean_log_entropy 0.65 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 2.1e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.48 / report/dyn_loss_std 2.75 / report/image_loss_mean 0.15 / report/image_loss_std 0.22 / report/model_loss_mean 1.12 / report/model_loss_std 1.79 / report/post_ent_mag 61.36 / report/post_ent_max 61.36 / 
report/post_ent_mean 36.58 / report/post_ent_min 27.32 / report/post_ent_std 4.21 / report/prior_ent_mag 64.35 / report/prior_ent_max 64.35 / report/prior_ent_mean 37.63 / report/prior_ent_min 31.49 / report/prior_ent_std 5.29 / report/rep_loss_mean 1.48 / 
report/rep_loss_std 2.75 / report/reward_avg 1.53 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.52 / report/reward_rate 0.76 / eval/cont_avg 1 / eval/cont_loss_mean 5.3e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 2.75 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.91 / eval/post_ent_mag 51 / eval/post_ent_max 51 / eval/post_ent_mean 37.72 / 
eval/post_ent_min 26.62 / eval/post_ent_std 3.36 / eval/prior_ent_mag 64.35 / eval/prior_ent_max 64.35 / eval/prior_ent_mean 38.77 / eval/prior_ent_min 35.12 / eval/prior_ent_std 4.74 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 2.75 / eval/reward_avg 1.68 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.14 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 0.03 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.68 / eval/reward_rate 0.84 / replay/size
5e5 / replay/inserts 3815 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.05 / timer/env.step_count 3815 / timer/env.step_total 19.17 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.52 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.22 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7823 / timer/agent.policy_total 17.09 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1908 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 5e-4 / timer/agent.train_count 1908 / timer/agent.train_total 243.37 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 2.05 / timer/agent.report_count 2 / timer/agent.report_total 0.11 /
timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.6e-5 / timer/dataset_eval_frac 8.8e-8 / timer/dataset_eval_avg 2.6e-5 / 
timer/dataset_eval_min 2.6e-5 / timer/dataset_eval_max 2.6e-5 / fps 25.43

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 499500 Counter(499500) 499437
Saved chunk: 20230922T082544F010014-5yiLWLH6osIRt27AK9lXF1-3XAlg1RyE7Pq57Xep0m2pH-1024.npz
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T082559F835006-4RdJ1LsgMHpPKsHfe8JZfH-78n3pUl34Fbgywsi5l9f5c-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 500000 Counter(500000) 499937
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 500500 Counter(500500) 500437
Saved chunk: 20230922T082702F819285-3XAlg1RyE7Pq57Xep0m2pH-1hRVIMoSAq6HioiJbPCeiU-1024.npz
eval_Episode has 500 steps and return 831.0.
Saved chunk: 20230922T082720F336853-78n3pUl34Fbgywsi5l9f5c-4DrLH6mTUV5Gpeen6wZLRZ-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 501000 Counter(501000) 500937
eval_Episode has 500 steps and return 845.0.
Starting evaluation at step 501500 Counter(501500) 501437
Saved chunk: 20230922T082820F636812-1hRVIMoSAq6HioiJbPCeiU-51LQZkEz6WWv3B1EjlyNlt-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T082839F682593-4DrLH6mTUV5Gpeen6wZLRZ-3xHqWZLjZu3AbNnixNJdNv-1024.npz
Starting evaluation at step 502000 Counter(502000) 501937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 502500 Counter(502500) 502437
Saved chunk: 20230922T082938F396563-51LQZkEz6WWv3B1EjlyNlt-0u9yT1lEuiQZeYwTX1Qrun-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T082958F971921-3xHqWZLjZu3AbNnixNJdNv-5Ynj1clt3NQdA0kMiVlyCR-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1005866 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / train/action_mag 4.19 / train/action_max 4.02 / train/action_mean 2.3e-3 / train/action_min -3.95 / train/action_std 0.97
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -2.78 / train/adv_mag 0.52 / train/adv_max 0.39 / train/adv_mean 1.6e-4 / train/adv_min -0.46 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 
/ train/dyn_loss_std 3.03 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.85 / train/extr_critic_max 670.85 / train/extr_critic_mean 640.15 / train/extr_critic_min 477.1 / train/extr_critic_std 47.14 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.8 / train/extr_return_raw_max 668.8 / train/extr_return_raw_mean 640.17 / train/extr_return_raw_min 476.48 / train/extr_return_raw_std 47.18 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.44 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / train/model_loss_std 2.02 / 
train/model_opt_grad_norm 5.16 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 8874.67 / train/model_opt_model_opt_grad_overflow 5.2e-3 / train/model_opt_model_opt_grad_scale 7396.91 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.4 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.71 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.4 / train/policy_logprob_min -8.71 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 1.3e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 52.98 / train/post_ent_max 52.98 / train/post_ent_mean 37.81 / train/post_ent_min
27.23 / train/post_ent_std 4.25 / train/prior_ent_mag 64.32 / train/prior_ent_max 64.32 / train/prior_ent_mean 38.99 / train/prior_ent_min 31.46 / train/prior_ent_std 5.4 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.03 / train/reward_avg 1.41 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.41 / train/reward_rate 0.71 / 
train_stats/mean_log_entropy 0.24 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3e-11 / report/cont_loss_std 9.3e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / report/dyn_loss_std 3.1 / report/image_loss_mean 0.18 / report/image_loss_std 0.23 / report/model_loss_mean 1.2 / report/model_loss_std 2 / report/post_ent_mag 50.16 / report/post_ent_max 50.16 / report/post_ent_mean 
38.78 / report/post_ent_min 28.67 / report/post_ent_std 4.3 / report/prior_ent_mag 64.28 / report/prior_ent_max 64.28 / report/prior_ent_mean 39.93 / report/prior_ent_min 32.58 / report/prior_ent_std 5.28 / report/rep_loss_mean 1.57 / report/rep_loss_std 3.1 / 
report/reward_avg 1.28 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 3.1e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred
1.28 / report/reward_rate 0.64 / eval/cont_avg 1 / eval/cont_loss_mean 4.5e-11 / eval/cont_loss_std 4.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.86 
/ eval/dyn_loss_std 3.77 / eval/image_loss_mean 0.26 / eval/image_loss_std 0.66 / eval/model_loss_mean 1.46 / eval/model_loss_std 2.76 / eval/post_ent_mag 52.27 / eval/post_ent_max 52.27 / eval/post_ent_mean 38.61 / eval/post_ent_min 22.66 / eval/post_ent_std 4.51 / 
eval/prior_ent_mag 64.28 / eval/prior_ent_max 64.28 / eval/prior_ent_mean 40.05 / eval/prior_ent_min 33.58 / eval/prior_ent_std 5.63 / eval/rep_loss_mean 1.86 / eval/rep_loss_std 3.77 / eval/reward_avg 1.34 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.12 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.34 / eval/reward_rate 0.67 / replay/size 5e5 / replay/inserts 3890 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3890 / timer/env.step_total 19.28 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.6e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.28 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.8e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7397 / timer/agent.policy_total 16.26 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 6.4e-3 / timer/dataset_train_count 1945 / 
timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1945 / timer/agent.train_total 246.28 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.13 / timer/agent.report_frac 4.2e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.07 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / timer/dataset_eval_max 3.7e-5 / fps 25.93

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 503000 Counter(503000) 502937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 503500 Counter(503500) 503437
Saved chunk: 20230922T083055F904836-0u9yT1lEuiQZeYwTX1Qrun-6G5EN1aegqqIrL4kPWb8fQ-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T083117F946052-5Ynj1clt3NQdA0kMiVlyCR-7vH1200fRgReYfrUXoUrsj-1024.npz
Starting evaluation at step 504000 Counter(504000) 503937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 504500 Counter(504500) 504437
Saved chunk: 20230922T083214F762179-6G5EN1aegqqIrL4kPWb8fQ-6hdjxM9GK4tlaRUCBVYFgT-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T083238F486589-7vH1200fRgReYfrUXoUrsj-61s2W8A4d00wKpYE0SUbkx-1024.npz
Starting evaluation at step 505000 Counter(505000) 504937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 505500 Counter(505500) 505437
Saved chunk: 20230922T083332F549253-6hdjxM9GK4tlaRUCBVYFgT-4awI9SiobxATyH7pJo9JmL-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T083357F822312-61s2W8A4d00wKpYE0SUbkx-1yR975NN5V53XUTaYL6X4F-1024.npz
Starting evaluation at step 506000 Counter(506000) 505937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 506500 Counter(506500) 506437
Saved chunk: 20230922T083450F311737-4awI9SiobxATyH7pJo9JmL-2EicXwDrctx9f2nJ7xnAmu-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 842.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1013542 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 848 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / train/action_mag 4.26 / train/action_max 4.12 / train/action_mean 9.8e-3 / train/action_min -3.97 / train/action_std 0.98
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -1.35 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 1.5e-5 / train/adv_min -0.46 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3.06 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.87 / train/extr_critic_max 670.87 / train/extr_critic_mean 638.36 / train/extr_critic_min 477.55 / train/extr_critic_std 48.59 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.78 / 
train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.7 / train/extr_return_raw_max 668.7 / train/extr_return_raw_mean 638.36 / train/extr_return_raw_min 475.69 / train/extr_return_raw_std 48.67 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.41 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / train/model_loss_std 2.03 / 
train/model_opt_grad_norm 5.39 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.41 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.41 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.56 / train/policy_randomness_min 2e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 52.73 / train/post_ent_max 52.73 / train/post_ent_mean 37.92 / train/post_ent_min 
27.42 / train/post_ent_std 4.32 / train/prior_ent_mag 64.34 / train/prior_ent_max 64.34 / train/prior_ent_mean 39.1 / train/prior_ent_min 31.3 / train/prior_ent_std 5.44 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.06 / train/reward_avg 1.39 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.69 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.2 / report/cont_avg 1 / report/cont_loss_mean 4.3e-11 / report/cont_loss_std 2.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.47 / report/dyn_loss_std 2.55 / report/image_loss_mean 0.13 / report/image_loss_std 0.14 / report/model_loss_mean 1.11 / report/model_loss_std 1.63 / report/post_ent_mag 49.83 / report/post_ent_max 49.83 / 
report/post_ent_mean 36.89 / report/post_ent_min 31.05 / report/post_ent_std 3.64 / report/prior_ent_mag 64.47 / report/prior_ent_max 64.47 / report/prior_ent_mean 37.95 / report/prior_ent_min 32.14 / report/prior_ent_std 5.02 / report/rep_loss_mean 1.47 / 
report/rep_loss_std 2.55 / report/reward_avg 1.69 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.08 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 4.1e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.69 / report/reward_rate 0.85 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.19 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.42 / eval/model_loss_mean 1.26 / eval/model_loss_std 2.24 / eval/post_ent_mag 51.53 / eval/post_ent_max 51.53 / eval/post_ent_mean 
38.38 / eval/post_ent_min 30.49 / eval/post_ent_std 4.2 / eval/prior_ent_mag 64.47 / eval/prior_ent_max 64.47 / eval/prior_ent_mean 39.63 / eval/prior_ent_min 33.15 / eval/prior_ent_std 5.52 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.19 / eval/reward_avg 1.41 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.12 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.4e-4 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.4 / eval/reward_rate 0.7 / replay/size 
5.1e5 / replay/inserts 3838 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3838 / timer/env.step_total 19.26 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.88 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.3e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7846 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1919 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1919 / timer/agent.train_total 242.96 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.4e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.4e-5 / timer/dataset_eval_min 3.4e-5 / timer/dataset_eval_max 3.4e-5 / fps 25.59

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T083516F990999-1yR975NN5V53XUTaYL6X4F-0KaK6PhkiUsQLzeGCUjcw4-1024.npz
Starting evaluation at step 507000 Counter(507000) 506937
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 507500 Counter(507500) 507437
Saved chunk: 20230922T083607F889255-2EicXwDrctx9f2nJ7xnAmu-0fKjbD8EK4ZYOyEGz9Jd2l-1024.npz
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T083637F241803-0KaK6PhkiUsQLzeGCUjcw4-4kU8EAhEJOxi4vXNVIlnFM-1024.npz
Starting evaluation at step 508000 Counter(508000) 507937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 508500 Counter(508500) 508437
Saved chunk: 20230922T083726F816945-0fKjbD8EK4ZYOyEGz9Jd2l-5Wq7jqUZmagPgOFe7FHgDi-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T083756F803423-4kU8EAhEJOxi4vXNVIlnFM-1Vthz1Bk9Ze1QIzbKpijWe-1024.npz
Starting evaluation at step 509000 Counter(509000) 508937
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 509500 Counter(509500) 509437
Saved chunk: 20230922T083844F690101-5Wq7jqUZmagPgOFe7FHgDi-21mMy7TWmQGFGH5qryvQVu-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T083916F102608-1Vthz1Bk9Ze1QIzbKpijWe-5N3bSAw01POhNFdIj9rcBZ-1024.npz
Starting evaluation at step 510000 Counter(510000) 509937
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 842.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 510500 Counter(510500) 510437
Saved chunk: 20230922T084002F394903-21mMy7TWmQGFGH5qryvQVu-0000000000000000000000-643.npz
Saved chunk: 20230922T084035F377034-5N3bSAw01POhNFdIj9rcBZ-0000000000000000000000-548.npz
Saved chunk: 20230922T084002F394903-21mMy7TWmQGFGH5qryvQVu-5SYROGzcTcnMYhxAxNxGdC-1024.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 847.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1021206 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 845 / eval_episode/reward_rate 0.84 / episode/length 500 / episode/score 847 / episode/reward_rate 0.85 / train/action_mag 4.3 / train/action_max 4.13 / train/action_mean -5.6e-3 / train/action_min -4.11 / train/action_std 1.01
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.5e5 / train/actor_opt_loss -2.11 / train/adv_mag 0.48 / train/adv_max 0.37 / train/adv_mean 7.3e-5 / train/adv_min -0.43 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 
/ train/dyn_loss_std 3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.5e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.71 / train/extr_critic_max 670.71 / train/extr_critic_mean 639.45 / train/extr_critic_min 476.38 / train/extr_critic_std 47.94 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.41 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.73 / train/extr_return_raw_max 668.73 / train/extr_return_raw_mean 639.47 / train/extr_return_raw_min 473.97 / train/extr_return_raw_std 48.02
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.44 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.19 / train/model_loss_std 1.99 / 
train/model_opt_grad_norm 5.18 / train/model_opt_grad_steps 2.5e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 9.03 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -9.03 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 2.9e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.87 / train/post_ent_max 52.87 / train/post_ent_mean 37.79 / train/post_ent_min
27.23 / train/post_ent_std 4.23 / train/prior_ent_mag 64.15 / train/prior_ent_max 64.15 / train/prior_ent_mean 38.96 / train/prior_ent_min 31.35 / train/prior_ent_std 5.35 / train/rep_loss_mean 1.57 / train/rep_loss_std 3 / train/reward_avg 1.41 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.3e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.41 / train/reward_rate 0.71 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.55 / report/cont_avg 1 / report/cont_loss_mean 1.2e-11 / report/cont_loss_std 4.2e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.42 / report/dyn_loss_std 2.09 / report/image_loss_mean 0.13 / report/image_loss_std 0.15 / report/model_loss_mean 1.08 / report/model_loss_std 1.37 / report/post_ent_mag 51.03 / report/post_ent_max 51.03 / 
report/post_ent_mean 36.72 / report/post_ent_min 27.83 / report/post_ent_std 3.8 / report/prior_ent_mag 63.99 / report/prior_ent_max 63.99 / report/prior_ent_mean 37.83 / report/prior_ent_min 32.32 / report/prior_ent_std 4.99 / report/rep_loss_mean 1.42 / 
report/rep_loss_std 2.09 / report/reward_avg 1.72 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.07 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-5 / report/reward_pos_acc 1 / report/reward_pos_loss
0.12 / report/reward_pred 1.72 / report/reward_rate 0.86 / eval/cont_avg 1 / eval/cont_loss_mean 6e-11 / eval/cont_loss_std 2.6e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.47 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.2 / eval/model_loss_mean 1.24 / eval/model_loss_std 2.2 / eval/post_ent_mag 51.46 / eval/post_ent_max 51.46 / eval/post_ent_mean 38.12 / eval/post_ent_min 27.72 / 
eval/post_ent_std 4.11 / eval/prior_ent_mag 63.99 / eval/prior_ent_max 63.99 / eval/prior_ent_mean 39.39 / eval/prior_ent_min 32.3 / eval/prior_ent_std 5.19 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.47 / eval/reward_avg 1.38 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.08 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.5e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.38 / eval/reward_rate 0.69 / replay/size 5.1e5 / replay/inserts 3832 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3832 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 6.8e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.9 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.41 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.12 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.3e-4 / 
timer/agent.train_count 1916 / timer/agent.train_total 243.07 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.7e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.7e-5 / timer/dataset_eval_min 3.7e-5 / 
timer/dataset_eval_max 3.7e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T084035F377034-5N3bSAw01POhNFdIj9rcBZ-3eMv5uSTmdLFzpsrNsjKGf-1024.npz
Starting evaluation at step 511000 Counter(511000) 510937
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 511500 Counter(511500) 511437
Saved chunk: 20230922T084120F405396-5SYROGzcTcnMYhxAxNxGdC-1LtD5lO1rFAo1oORWVfle2-1024.npz
eval_Episode has 500 steps and return 836.0.
train_Episode has 500 steps and return 847.0.
Starting evaluation at step 512000 Counter(512000) 511937
Saved chunk: 20230922T084156F108826-3eMv5uSTmdLFzpsrNsjKGf-5MWGmFxWn4JqSj5OTDdJ2x-1024.npz
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 512500 Counter(512500) 512437
Saved chunk: 20230922T084239F442117-1LtD5lO1rFAo1oORWVfle2-6k5cazCkYYU13gQ226a8d6-1024.npz
eval_Episode has 500 steps and return 828.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 513000 Counter(513000) 512937
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T084315F551719-5MWGmFxWn4JqSj5OTDdJ2x-2efdn1Uqmf1HcM69xXwmJh-1024.npz
Starting evaluation at step 513500 Counter(513500) 513437
Saved chunk: 20230922T084357F202557-6k5cazCkYYU13gQ226a8d6-3PoY4iCwPFikBBMvR0DgEH-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 797.0.
Starting evaluation at step 514000 Counter(514000) 513937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T084438F250691-2efdn1Uqmf1HcM69xXwmJh-1P0FK7m4isO71iEqAguWhU-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1028978 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 841 / episode/reward_rate 0.84 / train/action_mag 4.32 / train/action_max 4.21 / train/action_mean -0.01 / train/action_min -4.08 / train/action_std 1.02 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -2.5 / train/adv_mag 0.51 / train/adv_max 0.39 / train/adv_mean 1.1e-4 / train/adv_min -0.45 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 / 
train/dyn_loss_std 2.99 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 671.03 / train/extr_critic_max 671.03 / train/extr_critic_mean 640.67 / train/extr_critic_min 478.58 / train/extr_critic_std 46.39 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.85 / train/extr_return_raw_max 668.85 / train/extr_return_raw_mean 640.69 / train/extr_return_raw_min 477.71 / train/extr_return_raw_std 46.47
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.44 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.16 / train/image_loss_std 0.26 / train/model_loss_mean 1.19 / train/model_loss_std 1.99 / 
train/model_opt_grad_norm 5.41 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.48 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.48 / train/policy_logprob_min -8.69 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.54 / train/post_ent_max 52.54 / train/post_ent_mean 37.82 / train/post_ent_min
27.78 / train/post_ent_std 4.17 / train/prior_ent_mag 64.14 / train/prior_ent_max 64.14 / train/prior_ent_mean 38.98 / train/prior_ent_min 31.41 / train/prior_ent_std 5.31 / train/rep_loss_mean 1.57 / train/rep_loss_std 2.99 / train/reward_avg 1.41 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 4.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.41 / train/reward_rate 0.71 /
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.49 / report/cont_avg 1 / report/cont_loss_mean 2.5e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.03 / report/image_loss_mean 0.15 / report/image_loss_std 0.2 / report/model_loss_mean 1.19 / report/model_loss_std 1.96 / report/post_ent_mag 53.16 / report/post_ent_max 53.16 / 
report/post_ent_mean 38.01 / report/post_ent_min 28.35 / report/post_ent_std 4.3 / report/prior_ent_mag 64.01 / report/prior_ent_max 64.01 / report/prior_ent_mean 39.25 / report/prior_ent_min 29.9 / report/prior_ent_std 5.4 / report/rep_loss_mean 1.61 / 
report/rep_loss_std 3.03 / report/reward_avg 1.33 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.6e-5 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.33 / report/reward_rate 0.67 / eval/cont_avg 1 / eval/cont_loss_mean 6.9e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.9e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.44 / eval/dyn_loss_std 2.39 / eval/image_loss_mean 0.13 / eval/image_loss_std 0.12 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.53 / eval/post_ent_mag 53.04 / eval/post_ent_max 53.04 / eval/post_ent_mean 
37.61 / eval/post_ent_min 30.35 / eval/post_ent_std 3.57 / eval/prior_ent_mag 64.01 / eval/prior_ent_max 64.01 / eval/prior_ent_mean 38.57 / eval/prior_ent_min 32.47 / eval/prior_ent_std 4.78 / eval/rep_loss_mean 1.44 / eval/rep_loss_std 2.39 / eval/reward_avg 1.63 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.11 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.63 / eval/reward_rate 0.82 / 
replay/size 5.1e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3886 / timer/env.step_total 19.44 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.64 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 4.1e-3 / timer/replay._sample_max 0.19 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.32 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.4e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.11 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.2e-5 / timer/dataset_eval_frac 1.1e-7 / timer/dataset_eval_avg 3.2e-5 / timer/dataset_eval_min 3.2e-5 / timer/dataset_eval_max 3.2e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 514500 Counter(514500) 514437
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T084514F886226-3PoY4iCwPFikBBMvR0DgEH-4wjzZMqNzzP0FI3F2jZHi1-1024.npz
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 515000 Counter(515000) 514937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T084557F425730-1P0FK7m4isO71iEqAguWhU-3K8KBWNaRT2tZrLqORDBH7-1024.npz
Starting evaluation at step 515500 Counter(515500) 515437
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T084633F740359-4wjzZMqNzzP0FI3F2jZHi1-4IUxE16vKW7gf44la2MXn0-1024.npz
train_Episode has 500 steps and return 798.0.
Starting evaluation at step 516000 Counter(516000) 515937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 797.0.
Saved chunk: 20230922T084718F193349-3K8KBWNaRT2tZrLqORDBH7-2kVScYRt6GOfMQ0nBttWwx-1024.npz
Starting evaluation at step 516500 Counter(516500) 516437
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 517000 Counter(517000) 516937
Saved chunk: 20230922T084751F836981-4IUxE16vKW7gf44la2MXn0-2MWQyqLVPw4eqLkwQZOYwH-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T084837F565721-2kVScYRt6GOfMQ0nBttWwx-2wmoVK2oOGRYWRQSnH3ZUt-1024.npz
Starting evaluation at step 517500 Counter(517500) 517437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 518000 Counter(518000) 517937
Saved chunk: 20230922T084945F085519-2MWQyqLVPw4eqLkwQZOYwH-7tMnwU8CHUBNLVCJak1ayK-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 697.0.
Saved chunk: 20230922T084956F886903-2wmoVK2oOGRYWRQSnH3ZUt-0s4PCl3vOgDFYLOCmW173c-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1036650 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 697 / episode/reward_rate 0.7 / train/action_mag 4.29 / train/action_max 4.14 / train/action_mean -0.01 / train/action_min -4.01 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -1.79 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 5.5e-5 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 / 
train/dyn_loss_std 3.04 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.85 / train/extr_critic_max 670.85 / train/extr_critic_mean 638.83 / train/extr_critic_min 477.28 / train/extr_critic_std 48.4 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.4 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.64 / train/extr_return_raw_max 668.64 / train/extr_return_raw_mean 638.84 / train/extr_return_raw_min 475.01 / train/extr_return_raw_std 48.49 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.42 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.28 / train/model_loss_mean 1.2 / train/model_loss_std 2.03 / 
train/model_opt_grad_norm 5.25 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.43 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.94 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.43 / train/policy_logprob_min -8.94 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.57 / train/policy_randomness_min 1.6e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.44 / train/post_ent_max 52.44 / train/post_ent_mean 37.86 / train/post_ent_min
27.14 / train/post_ent_std 4.28 / train/prior_ent_mag 64.06 / train/prior_ent_max 64.06 / train/prior_ent_mean 39.03 / train/prior_ent_min 31.25 / train/prior_ent_std 5.39 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.04 / train/reward_avg 1.39 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.39 / train/reward_rate 0.7 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.31 / report/cont_avg 1 / report/cont_loss_mean 2.8e-11 / report/cont_loss_std 1.5e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 2.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.55 / report/dyn_loss_std 2.97 / report/image_loss_mean 0.15 / report/image_loss_std 0.18 / report/model_loss_mean 1.16 / report/model_loss_std 1.92 / report/post_ent_mag 49.98 / report/post_ent_max 49.98 / 
report/post_ent_mean 37.99 / report/post_ent_min 29.13 / report/post_ent_std 4.44 / report/prior_ent_mag 64.13 / report/prior_ent_max 64.13 / report/prior_ent_mean 39.15 / report/prior_ent_min 32.42 / report/prior_ent_std 5.56 / report/rep_loss_mean 1.55 / 
report/rep_loss_std 2.97 / report/reward_avg 1.41 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.11 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 7.4e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.41 / report/reward_rate 0.7 / eval/cont_avg 1 / eval/cont_loss_mean 4.4e-11 / eval/cont_loss_std 1.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.4e-11 / eval/cont_pred
1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / eval/dyn_loss_std 3.19 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.34 / eval/model_loss_mean 1.27 / eval/model_loss_std 2.16 / eval/post_ent_mag 49.76 / eval/post_ent_max 49.76 / eval/post_ent_mean 37.76 / 
eval/post_ent_min 27.17 / eval/post_ent_std 3.74 / eval/prior_ent_mag 64.13 / eval/prior_ent_max 64.13 / eval/prior_ent_mean 39.05 / eval/prior_ent_min 32.54 / eval/prior_ent_std 5.14 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 3.19 / eval/reward_avg 1.55 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.6e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.55 / eval/reward_rate 0.78 / replay/size 
5.2e5 / replay/inserts 3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.8e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.07 / timer/env.step_count 3836 / timer/env.step_total 19.03 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4.2e-3 / timer/env.step_max 6.9e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.03 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.03 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.69 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.3e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.18 / 
timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1918 / timer/agent.train_total 242.6 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.3 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 518500 Counter(518500) 518437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 519000 Counter(519000) 518937
Saved chunk: 20230922T085102F645784-7tMnwU8CHUBNLVCJak1ayK-2vghpMFGdbRjDyIHtDFJpC-1024.npz
eval_Episode has 500 steps and return 830.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T085115F961984-0s4PCl3vOgDFYLOCmW173c-00MxfzI1oijMYgyxsAeRPD-1024.npz
Starting evaluation at step 519500 Counter(519500) 519437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 520000 Counter(520000) 519937
Saved chunk: 20230922T085221F585207-2vghpMFGdbRjDyIHtDFJpC-5mb5X5zbpuYRFrGRCiLNPV-1024.npz
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T085236F459463-00MxfzI1oijMYgyxsAeRPD-4w2lat03zAylXviS4gl5dz-1024.npz
Starting evaluation at step 520500 Counter(520500) 520437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 521000 Counter(521000) 520937
Saved chunk: 20230922T085339F319354-5mb5X5zbpuYRFrGRCiLNPV-3em1t1ZAFXCoLsjIrEpiBC-1024.npz
eval_Episode has 500 steps and return 840.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T085355F726993-4w2lat03zAylXviS4gl5dz-0UaNY9eJfmcvz6ZDy1754n-1024.npz
Starting evaluation at step 521500 Counter(521500) 521437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 522000 Counter(522000) 521937
Saved chunk: 20230922T085456F997719-3em1t1ZAFXCoLsjIrEpiBC-0TeTX9lScUT6lnY6qWKtrA-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 846.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T085514F978815-0UaNY9eJfmcvz6ZDy1754n-0000000000000000000000-884.npz
Saved chunk: 20230922T085614F523886-0TeTX9lScUT6lnY6qWKtrA-0000000000000000000000-379.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1044324 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 848 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 846 / episode/reward_rate 0.84 / train/action_mag 4.29 / train/action_max 4.11 / train/action_mean -0.01 / train/action_min -4.1 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -3.06 / train/adv_mag 0.46 / train/adv_max 0.36 / train/adv_mean 1.8e-4 / train/adv_min -0.42 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.1e-11 / train/cont_loss_std 1.3e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.1e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 / 
train/dyn_loss_std 3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 1.1e4 
/ train/extr_critic_mag 670.64 / train/extr_critic_max 670.64 / train/extr_critic_mean 638.73 / train/extr_critic_min 473.02 / train/extr_critic_std 48.63 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.43 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.52 / train/extr_return_raw_max 668.52 / train/extr_return_raw_mean 638.75 / train/extr_return_raw_min 471.58 / train/extr_return_raw_std 48.67
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.42 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.17 / train/image_loss_std 0.27 / train/model_loss_mean 1.19 / train/model_loss_std 1.99 / 
train/model_opt_grad_norm 5.62 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.81 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.81 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.9 / train/post_ent_max 52.9 / train/post_ent_mean 37.78 / train/post_ent_min 
27.39 / train/post_ent_std 4.27 / train/prior_ent_mag 63.94 / train/prior_ent_max 63.94 / train/prior_ent_mean 38.96 / train/prior_ent_min 31.22 / train/prior_ent_std 5.38 / train/rep_loss_mean 1.57 / train/rep_loss_std 3 / train/reward_avg 1.4 / train/reward_loss_mean 
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.4 / train/reward_rate 0.7 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.35 / report/cont_avg 1 / report/cont_loss_mean 4.1e-11 / report/cont_loss_std 1.7e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.83 / report/image_loss_mean 0.15 / report/image_loss_std 0.16 / report/model_loss_mean 1.14 / report/model_loss_std 1.78 / report/post_ent_mag 51.73 / report/post_ent_max 51.73 / 
report/post_ent_mean 37.71 / report/post_ent_min 25.66 / report/post_ent_std 4.43 / report/prior_ent_mag 63.82 / report/prior_ent_max 63.82 / report/prior_ent_mean 38.91 / report/prior_ent_min 26.21 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 2.83 / report/reward_avg 1.3 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.8e-4 / report/reward_pos_acc 1 / report/reward_pos_loss
0.11 / report/reward_pred 1.3 / report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 5.2e-11 / eval/cont_loss_std 1.9e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.2e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.62 / eval/dyn_loss_std 3.37 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.3 / eval/model_loss_mean 1.25 / eval/model_loss_std 2.25 / eval/post_ent_mag 49.33 / eval/post_ent_max 49.33 / eval/post_ent_mean 38.36 / eval/post_ent_min 31.01 / 
eval/post_ent_std 3.64 / eval/prior_ent_mag 63.82 / eval/prior_ent_max 63.82 / eval/prior_ent_mean 39.55 / eval/prior_ent_min 33.63 / eval/prior_ent_std 4.88 / eval/rep_loss_mean 1.62 / eval/rep_loss_std 3.37 / eval/reward_avg 1.38 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.16 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 6.1e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.37 / eval/reward_rate 0.69 / replay/size 5.2e5 / replay/inserts 
3837 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3837 / timer/env.step_total 19.19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 0.15 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.38 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.5e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 1 / 
timer/agent.save_total 0.1 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.1 / timer/agent.save_min 0.1 / timer/agent.save_max 0.1 / timer/agent.policy_count 7845 / timer/agent.policy_total 17.27 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / 
timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.6e-4 / 
timer/agent.train_count 1918 / timer/agent.train_total 243.07 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / 
timer/dataset_eval_max 3.5e-5 / fps 25.58

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T085514F978815-0UaNY9eJfmcvz6ZDy1754n-7dxvF4lbpwnBjfRsmg8O4r-1024.npz
Starting evaluation at step 522500 Counter(522500) 522437
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 700.0.
Starting evaluation at step 523000 Counter(523000) 522937
Saved chunk: 20230922T085614F523886-0TeTX9lScUT6lnY6qWKtrA-2ZKWPhYrJNdUML9VrVkEy7-1024.npz
eval_Episode has 500 steps and return 837.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T085635F387804-7dxvF4lbpwnBjfRsmg8O4r-2iQ4zpWWGER6EBdBnwmjs0-1024.npz
Starting evaluation at step 523500 Counter(523500) 523437
eval_Episode has 500 steps and return 801.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 524000 Counter(524000) 523937
Saved chunk: 20230922T085733F813187-2ZKWPhYrJNdUML9VrVkEy7-2hvYB2RlA9FeMOq9eUfSgS-1024.npz
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T085754F954422-2iQ4zpWWGER6EBdBnwmjs0-00z443IrsEHP1GSNVXTRtb-1024.npz
Starting evaluation at step 524500 Counter(524500) 524437
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 525000 Counter(525000) 524937
Saved chunk: 20230922T085851F591116-2hvYB2RlA9FeMOq9eUfSgS-0vJLOPUOEEkdwgw3mi9KnY-1024.npz
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 794.0.
Saved chunk: 20230922T085914F233949-00z443IrsEHP1GSNVXTRtb-5oqI7F6wtAPa1iDEPk7RBY-1024.npz
Starting evaluation at step 525500 Counter(525500) 525437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 526000 Counter(526000) 525937
Saved chunk: 20230922T090009F271631-0vJLOPUOEEkdwgw3mi9KnY-3ShMYIwQerY9dcrKDjP6gA-1024.npz
eval_Episode has 500 steps and return 850.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1052002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 850 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / train/action_mag 4.22 / train/action_max 4.1 / train/action_mean -0.01 / train/action_min -3.99 / train/action_std 0.99 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -0.41 / train/adv_mag 0.48 / train/adv_max 0.36 / train/adv_mean -9.6e-5 / train/adv_min -0.44 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.7e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.7e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 / 
train/dyn_loss_std 2.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.78 / train/extr_critic_max 670.78 / train/extr_critic_mean 640.43 / train/extr_critic_min 475.39 / train/extr_critic_std 47.66 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.38 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.63 / train/extr_return_raw_max 668.63 / train/extr_return_raw_mean 640.42 / train/extr_return_raw_min 474.07 / train/extr_return_raw_std 47.78
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.45 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.16 / train/image_loss_std 0.27 / train/model_loss_mean 1.19 / train/model_loss_std 1.99 / 
train/model_opt_grad_norm 5.26 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.46 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.89 / train/policy_logprob_mag 8.83 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.46 / train/policy_logprob_min -8.83 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.3e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.36 / train/post_ent_max 52.36 / train/post_ent_mean 37.57 / train/post_ent_min
27.46 / train/post_ent_std 4.27 / train/prior_ent_mag 64.1 / train/prior_ent_max 64.1 / train/prior_ent_mean 38.74 / train/prior_ent_min 31.39 / train/prior_ent_std 5.41 / train/rep_loss_mean 1.57 / train/rep_loss_std 2.98 / train/reward_avg 1.43 / train/reward_loss_mean 
0.09 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.43 / train/reward_rate 0.72 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.25 / report/cont_avg 1 / report/cont_loss_mean 1.8e-11 / report/cont_loss_std 5.6e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 1.8e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.8 / report/dyn_loss_std 4.17 / report/image_loss_mean 0.21 / report/image_loss_std 0.37 / report/model_loss_mean 1.36 / report/model_loss_std 2.76 / report/post_ent_mag 50.43 / report/post_ent_max 50.43 / 
report/post_ent_mean 38.81 / report/post_ent_min 28.05 / report/post_ent_std 4.97 / report/prior_ent_mag 64.14 / report/prior_ent_max 64.14 / report/prior_ent_mean 40.16 / report/prior_ent_min 32.43 / report/prior_ent_std 6.05 / report/rep_loss_mean 1.8 / 
report/rep_loss_std 4.17 / report/reward_avg 1.03 / report/reward_loss_mean 0.07 / report/reward_loss_std 0.09 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 2.9e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.03 / report/reward_rate 0.52 / eval/cont_avg 1 / eval/cont_loss_mean 7.3e-11 / eval/cont_loss_std 1.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.3e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.63 / eval/dyn_loss_std 3.15 / eval/image_loss_mean 0.17 / eval/image_loss_std 0.36 / eval/model_loss_mean 1.25 / eval/model_loss_std 2.2 / eval/post_ent_mag 50.41 / eval/post_ent_max 50.41 / eval/post_ent_mean 
36.82 / eval/post_ent_min 29.76 / eval/post_ent_std 3.2 / eval/prior_ent_mag 64.14 / eval/prior_ent_max 64.14 / eval/prior_ent_mean 38.08 / eval/prior_ent_min 32.38 / eval/prior_ent_std 4.76 / eval/rep_loss_mean 1.63 / eval/rep_loss_std 3.15 / eval/reward_avg 1.78 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.77 / eval/reward_rate 0.89 / 
replay/size 5.3e5 / replay/inserts 3839 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.23 / timer/env.step_count 3839 / timer/env.step_total 19.21 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 
/ timer/env.step_min 4e-3 / timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.31 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.7e-3 / timer/replay._sample_max 0.2 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7847 / timer/agent.policy_total 17.19 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.02 / 
timer/dataset_train_count 1920 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1920 / timer/agent.train_total 243.35 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T090033F450897-5oqI7F6wtAPa1iDEPk7RBY-4wyGz74MYoQNCGmzkgtIPo-1024.npz
Starting evaluation at step 526500 Counter(526500) 526437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 527000 Counter(527000) 526937
Saved chunk: 20230922T090126F952244-3ShMYIwQerY9dcrKDjP6gA-7KJ8WIvosKDckhGYtcSpdn-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T090153F819422-4wyGz74MYoQNCGmzkgtIPo-00tuZQxZo6UtOuGDOzvBLQ-1024.npz
Starting evaluation at step 527500 Counter(527500) 527437
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 528000 Counter(528000) 527937
Saved chunk: 20230922T090245F898172-7KJ8WIvosKDckhGYtcSpdn-5kL2vULDpujS2Yz8mdHHaH-1024.npz
eval_Episode has 500 steps and return 794.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T090313F268023-00tuZQxZo6UtOuGDOzvBLQ-0PVN7IbDcoVuNKMAepMjDj-1024.npz
Starting evaluation at step 528500 Counter(528500) 528437
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 529000 Counter(529000) 528937
Saved chunk: 20230922T090403F709871-5kL2vULDpujS2Yz8mdHHaH-7JObPXfkTRvmIw0wHqVjar-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 824.0.
Saved chunk: 20230922T090432F570241-0PVN7IbDcoVuNKMAepMjDj-3bvXWbz3kZ1uUDNc6xc8xc-1024.npz
Starting evaluation at step 529500 Counter(529500) 529437
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 811.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1059774 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 811 / episode/reward_rate 0.81 / eval_episode/length 500 / eval_episode/score 847 / eval_episode/reward_rate 0.85 / train/action_mag 4.29 / train/action_max 4.17 / train/action_mean -0.02 / train/action_min -4.01 / train/action_std 1 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.6e5 / train/actor_opt_loss -1.92 / train/adv_mag 0.48 / train/adv_max 0.38 / train/adv_mean 4.3e-5 / train/adv_min -0.43 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.56 / 
train/dyn_loss_std 2.94 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.6e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.91 / train/extr_critic_max 670.91 / train/extr_critic_mean 641.46 / train/extr_critic_min 473.89 / train/extr_critic_std 46.28 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.81 / 
train/extr_return_normed_min -0.37 / train/extr_return_normed_std 0.33 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.67 / train/extr_return_raw_max 668.67 / train/extr_return_raw_mean 641.46 / train/extr_return_raw_min 474.74 / train/extr_return_raw_std 46.36
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.46 / train/extr_reward_min 0 / train/extr_reward_std 0.85 / train/image_loss_mean 0.16 / train/image_loss_std 0.25 / train/model_loss_mean 1.18 / train/model_loss_std 1.95 / 
train/model_opt_grad_norm 5.56 / train/model_opt_grad_steps 2.6e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.51 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.88 / train/policy_logprob_mag 8.69 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.51 / train/policy_logprob_min -8.69 / train/policy_logprob_std 1.13 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 2.6e-5 / train/policy_randomness_std 0.38 / train/post_ent_mag 52.44 / train/post_ent_max 52.44 / train/post_ent_mean 37.52 / train/post_ent_min
27.82 / train/post_ent_std 4.27 / train/prior_ent_mag 64.08 / train/prior_ent_max 64.08 / train/prior_ent_mean 38.67 / train/prior_ent_min 31.54 / train/prior_ent_std 5.4 / train/rep_loss_mean 1.56 / train/rep_loss_std 2.94 / train/reward_avg 1.43 / train/reward_loss_mean
0.09 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.9e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.43 / train/reward_rate 0.72 / 
train_stats/mean_log_entropy 0.39 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 4.4e-11 / report/cont_loss_std 1.4e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 4.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.43 / report/dyn_loss_std 2.34 / report/image_loss_mean 0.14 / report/image_loss_std 0.13 / report/model_loss_mean 1.08 / report/model_loss_std 1.48 / report/post_ent_mag 52.1 / report/post_ent_max 52.1 / 
report/post_ent_mean 37.56 / report/post_ent_min 29.87 / report/post_ent_std 4.84 / report/prior_ent_mag 64.04 / report/prior_ent_max 64.04 / report/prior_ent_mean 38.63 / report/prior_ent_min 30.55 / report/prior_ent_std 5.9 / report/rep_loss_mean 1.43 / 
report/rep_loss_std 2.34 / report/reward_avg 1.29 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.16 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.12 / report/reward_pred 1.29 / report/reward_rate 0.65 / eval/cont_avg 1 / eval/cont_loss_mean 9e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 9e-11 / eval/cont_pred 1 
/ eval/cont_rate 1 / eval/dyn_loss_mean 1.41 / eval/dyn_loss_std 2.32 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.07 / eval/model_loss_std 1.5 / eval/post_ent_mag 52.07 / eval/post_ent_max 52.07 / eval/post_ent_mean 37.02 / 
eval/post_ent_min 30.17 / eval/post_ent_std 3.34 / eval/prior_ent_mag 64.04 / eval/prior_ent_max 64.04 / eval/prior_ent_mean 37.93 / eval/prior_ent_min 32.35 / eval/prior_ent_std 4.7 / eval/rep_loss_mean 1.41 / eval/rep_loss_std 2.32 / eval/reward_avg 1.82 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.03 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 1.8e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.82 / eval/reward_rate 0.91 / 
replay/size 5.3e5 / replay/inserts 3886 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3886 / timer/env.step_total 19.3 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 396.85 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7393 / timer/agent.policy_total 16.34 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.4e-3 / 
timer/dataset_train_count 1943 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.1e-4 / timer/agent.train_count 1943 / timer/agent.train_total 246.27 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.9

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 530000 Counter(530000) 529937
Saved chunk: 20230922T090521F409460-7JObPXfkTRvmIw0wHqVjar-2i4XMC5VreHTPqplfdqW14-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T090551F827786-3bvXWbz3kZ1uUDNc6xc8xc-4VqTkFcv2d1tY67hEGEk1P-1024.npz
Starting evaluation at step 530500 Counter(530500) 530437
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 839.0.
Starting evaluation at step 531000 Counter(531000) 530937
Saved chunk: 20230922T090640F154191-2i4XMC5VreHTPqplfdqW14-4ydcRwz0FRCN2FHfhQwnNd-1024.npz
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T090712F300804-4VqTkFcv2d1tY67hEGEk1P-31pq13V4v7qjz189ban78Y-1024.npz
Starting evaluation at step 531500 Counter(531500) 531437
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 532000 Counter(532000) 531937
Saved chunk: 20230922T090758F169471-4ydcRwz0FRCN2FHfhQwnNd-65zwooi2c4z17tEvJdpS5M-1024.npz
eval_Episode has 500 steps and return 844.0.
train_Episode has 500 steps and return 842.0.
Saved chunk: 20230922T090831F730692-31pq13V4v7qjz189ban78Y-5nTJ2TjLY6pgLuFuiKG0q4-1024.npz
Starting evaluation at step 532500 Counter(532500) 532437
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 533000 Counter(533000) 532937
Saved chunk: 20230922T090915F887956-65zwooi2c4z17tEvJdpS5M-0aMBUnfr5MtqT1BIEznJMA-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 840.0.
Starting evaluation at step 533500 Counter(533500) 533437
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T090950F949777-5nTJ2TjLY6pgLuFuiKG0q4-5CRAjWDHlsNBYIfvovdL8P-1024.npz
train_Episode has 500 steps and return 842.0.
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T091113F549796-5CRAjWDHlsNBYIfvovdL8P-0000000000000000000000-196.npz
Saved chunk: 20230922T091033F539303-0aMBUnfr5MtqT1BIEznJMA-0000000000000000000000-638.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1067446 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 848 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 842 / episode/reward_rate 0.84 / train/action_mag 4.32 / train/action_max 4.14 / train/action_mean -0.02 / train/action_min -4.15 / train/action_std 1.03 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -4.01 / train/adv_mag 0.47 / train/adv_max 0.36 / train/adv_mean 2.5e-4 / train/adv_min -0.43 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.6e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 
/ train/dyn_loss_std 3.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.07 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.59 / train/extr_critic_max 670.59 / train/extr_critic_mean 638.14 / train/extr_critic_min 460.82 / train/extr_critic_std 50.29 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.53 / train/extr_return_raw_max 668.53 / train/extr_return_raw_mean 638.18 / train/extr_return_raw_min 461.03 / train/extr_return_raw_std 50.32
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.43 / train/extr_reward_min 0 / train/extr_reward_std 0.88 / train/image_loss_mean 0.16 / train/image_loss_std 0.27 / train/model_loss_mean 1.19 / train/model_loss_std 2 / 
train/model_opt_grad_norm 5.24 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.53 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.82 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.53 / train/policy_logprob_min -8.82 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 8.3e-6 / train/policy_randomness_std 0.4 / train/post_ent_mag 53.41 / train/post_ent_max 53.41 / train/post_ent_mean 37.58 / train/post_ent_min 
27.36 / train/post_ent_std 4.37 / train/prior_ent_mag 64.01 / train/prior_ent_max 64.01 / train/prior_ent_mean 38.76 / train/prior_ent_min 30.97 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.57 / train/rep_loss_std 3.01 / train/reward_avg 1.4 / train/reward_loss_mean
0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.4 / train/reward_rate 0.7 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.52 / report/cont_avg 1 / report/cont_loss_mean 3.4e-11 / report/cont_loss_std 9.8e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.4e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.5 / report/dyn_loss_std 2.94 / report/image_loss_mean 0.16 / report/image_loss_std 0.3 / report/model_loss_mean 1.15 / report/model_loss_std 1.98 / report/post_ent_mag 49.66 / report/post_ent_max 49.66 / 
report/post_ent_mean 36.16 / report/post_ent_min 18.79 / report/post_ent_std 3.55 / report/prior_ent_mag 64 / report/prior_ent_max 64 / report/prior_ent_mean 37.2 / report/prior_ent_min 25.41 / report/prior_ent_std 4.72 / report/rep_loss_mean 1.5 / report/rep_loss_std 
2.94 / report/reward_avg 1.6 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.7e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.11 / 
report/reward_pred 1.6 / report/reward_rate 0.8 / eval/cont_avg 1 / eval/cont_loss_mean 5.4e-11 / eval/cont_loss_std 3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.4e-11 / eval/cont_pred 1 / eval/cont_rate 1 / 
eval/dyn_loss_mean 1.7 / eval/dyn_loss_std 3.23 / eval/image_loss_mean 0.2 / eval/image_loss_std 0.28 / eval/model_loss_mean 1.29 / eval/model_loss_std 2.15 / eval/post_ent_mag 51.95 / eval/post_ent_max 51.95 / eval/post_ent_mean 38.89 / eval/post_ent_min 28.07 / 
eval/post_ent_std 4.24 / eval/prior_ent_mag 64 / eval/prior_ent_max 64 / eval/prior_ent_mean 40.2 / eval/prior_ent_min 32.84 / eval/prior_ent_std 5.36 / eval/rep_loss_mean 1.7 / eval/rep_loss_std 3.23 / eval/reward_avg 1.25 / eval/reward_loss_mean 0.07 / 
eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.99 / eval/reward_neg_loss 3.9e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.25 / eval/reward_rate 0.63 / replay/size 5.3e5 / replay/inserts 
3836 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.08 / timer/env.step_count 3836 / timer/env.step_total 19.2 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 0.17 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 390.69 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 2.2e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 1 / 
timer/agent.save_total 0.11 / timer/agent.save_frac 3.5e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7844 / timer/agent.policy_total 17.23 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 /
timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.1 / timer/dataset_train_count 1918 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.4e-4 / 
timer/agent.train_count 1918 / timer/agent.train_total 243.16 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4
/ timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 4.1e-5 / timer/dataset_eval_frac 1.4e-7 / timer/dataset_eval_avg 4.1e-5 / timer/dataset_eval_min 4.1e-5 / 
timer/dataset_eval_max 4.1e-5 / fps 25.57

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 534000 Counter(534000) 533937
Saved chunk: 20230922T091033F539303-0aMBUnfr5MtqT1BIEznJMA-1QDST9RB1BpRwLGIhhsMvL-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 838.0.
Starting evaluation at step 534500 Counter(534500) 534437
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T091113F549796-5CRAjWDHlsNBYIfvovdL8P-7vDoKqE1XgkMZAES8dbUX6-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 535000 Counter(535000) 534937
Saved chunk: 20230922T091152F616199-1QDST9RB1BpRwLGIhhsMvL-48djkxwDppFukVx6DUQt3M-1024.npz
eval_Episode has 500 steps and return 846.0.
train_Episode has 500 steps and return 846.0.
Starting evaluation at step 535500 Counter(535500) 535437
eval_Episode has 500 steps and return 790.0.
Saved chunk: 20230922T091234F351652-7vDoKqE1XgkMZAES8dbUX6-6KFwpy3tTs6Xvly77JfsIb-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 536000 Counter(536000) 535937
eval_Episode has 500 steps and return 848.0.
Saved chunk: 20230922T091310F560512-48djkxwDppFukVx6DUQt3M-6I8mXPg3G76IR2SjkvK2Fr-1024.npz
train_Episode has 500 steps and return 832.0.
Starting evaluation at step 536500 Counter(536500) 536437
eval_Episode has 500 steps and return 839.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T091353F802754-6KFwpy3tTs6Xvly77JfsIb-2vnh5YiYCZtDO8EMxhkeIS-1024.npz
Starting evaluation at step 537000 Counter(537000) 536937
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T091428F404478-6I8mXPg3G76IR2SjkvK2Fr-2MFjPKSejHzSH1dAKSxyTc-1024.npz
train_Episode has 500 steps and return 841.0.
Starting evaluation at step 537500 Counter(537500) 537437
eval_Episode has 500 steps and return 850.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1075110 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 850 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 841 / episode/reward_rate 0.84 / train/action_mag 4.28 / train/action_max 4.12 / train/action_mean -0.02 / train/action_min -4.1 / train/action_std 1.02 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.34 / train/adv_mag 0.48 / train/adv_max 0.36 / train/adv_mean 8.4e-5 / train/adv_min -0.44 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 2e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.55 / 
train/dyn_loss_std 2.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.62 / train/extr_critic_max 670.62 / train/extr_critic_mean 639.93 / train/extr_critic_min 467.23 / train/extr_critic_std 47.87 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.48 / train/extr_return_raw_max 668.48 / train/extr_return_raw_mean 639.94 / train/extr_return_raw_min 467.11 / train/extr_return_raw_std 47.93
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.45 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.16 / train/image_loss_std 0.26 / train/model_loss_mean 1.18 / train/model_loss_std 1.93 / 
train/model_opt_grad_norm 5.39 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 8684.18 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 7382.2 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.52 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.88 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.52 / train/policy_logprob_min -8.88 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 9.3e-6 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.31 / train/post_ent_max 52.31 / train/post_ent_mean 37.4 / train/post_ent_min 
27.49 / train/post_ent_std 4.37 / train/prior_ent_mag 63.9 / train/prior_ent_max 63.9 / train/prior_ent_mean 38.56 / train/prior_ent_min 30.98 / train/prior_ent_std 5.47 / train/rep_loss_mean 1.55 / train/rep_loss_std 2.91 / train/reward_avg 1.43 / train/reward_loss_mean 
0.09 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.43 / train/reward_rate 0.71 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.39 / report/cont_avg 1 / report/cont_loss_mean 5.3e-11 / report/cont_loss_std 2.8e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.3e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.58 / report/dyn_loss_std 3.32 / report/image_loss_mean 0.16 / report/image_loss_std 0.39 / report/model_loss_mean 1.2 / report/model_loss_std 2.29 / report/post_ent_mag 52.44 / report/post_ent_max 52.44 / 
report/post_ent_mean 36.84 / report/post_ent_min 14.03 / report/post_ent_std 4.93 / report/prior_ent_mag 63.95 / report/prior_ent_max 63.95 / report/prior_ent_mean 38.01 / report/prior_ent_min 26.21 / report/prior_ent_std 5.87 / report/rep_loss_mean 1.58 / 
report/rep_loss_std 3.32 / report/reward_avg 1.42 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 9.6e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.42 / report/reward_rate 0.71 / eval/cont_avg 1 / eval/cont_loss_mean 8.7e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.45 / eval/dyn_loss_std 2.39 / eval/image_loss_mean 0.12 / eval/image_loss_std 0.16 / eval/model_loss_mean 1.09 / eval/model_loss_std 1.56 / eval/post_ent_mag 52.13 / eval/post_ent_max 52.13 / eval/post_ent_mean 
37.36 / eval/post_ent_min 26.24 / eval/post_ent_std 3.65 / eval/prior_ent_mag 63.95 / eval/prior_ent_max 63.95 / eval/prior_ent_mean 38.39 / eval/prior_ent_min 31.68 / eval/prior_ent_std 4.86 / eval/rep_loss_mean 1.45 / eval/rep_loss_std 2.39 / eval/reward_avg 1.78 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1e-7 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.78 / eval/reward_rate 0.89 / replay/size 
5.4e5 / replay/inserts 3832 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3832 / timer/env.step_total 19 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / 
timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 393.95 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.6e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.06 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 7.3e-3 / 
timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7e-5 / timer/dataset_train_max 5.9e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.43 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.12 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3e-5 / timer/dataset_eval_frac 1e-7 / timer/dataset_eval_avg 3e-5 / timer/dataset_eval_min 3e-5 / timer/dataset_eval_max 3e-5 / fps 25.55

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 844.0.
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Saved chunk: 20230922T091513F079363-2vnh5YiYCZtDO8EMxhkeIS-56sy3SndHnjBFLWagjdMWC-1024.npz
Starting evaluation at step 538000 Counter(538000) 537937
eval_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T091546F140692-2MFjPKSejHzSH1dAKSxyTc-6p3Cmfrh18BSE7HNjtDoM4-1024.npz
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 538500 Counter(538500) 538437
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
Saved chunk: 20230922T091633F383703-56sy3SndHnjBFLWagjdMWC-3WfbRQnWMYlb6KHwu1lhGz-1024.npz
Starting evaluation at step 539000 Counter(539000) 538937
eval_Episode has 500 steps and return 849.0.
Saved chunk: 20230922T091705F133516-6p3Cmfrh18BSE7HNjtDoM4-2CEdSwXWsRwZQawRh8TI95-1024.npz
train_Episode has 500 steps and return 843.0.
Starting evaluation at step 539500 Counter(539500) 539437
eval_Episode has 500 steps and return 805.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T091753F023756-3WfbRQnWMYlb6KHwu1lhGz-2W1bde0caXEgMgI7coIDmZ-1024.npz
Starting evaluation at step 540000 Counter(540000) 539937
eval_Episode has 500 steps and return 845.0.
train_Episode has 500 steps and return 829.0.
Starting evaluation at step 540500 Counter(540500) 540437
Saved chunk: 20230922T091822F998744-2CEdSwXWsRwZQawRh8TI95-7l3g9915i7zujnqvmzBatj-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T091912F362325-2W1bde0caXEgMgI7coIDmZ-08G87feQ8lMfyw5g5raVn7-1024.npz
Starting evaluation at step 541000 Counter(541000) 540937
eval_Episode has 500 steps and return 842.0.
train_Episode has 500 steps and return 845.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1082876 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 845 / episode/reward_rate 0.84 / eval_episode/length 500 / eval_episode/score 842 / eval_episode/reward_rate 0.84 / train/action_mag 4.28 / train/action_max 4.12 / train/action_mean -1.5e-3 / train/action_min -4.08 / train/action_std 
1.02 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.07 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.73 / train/adv_mag 0.49 / train/adv_max 0.38 / train/adv_mean 1.2e-4 / train/adv_min 
-0.43 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.9e-11 / train/cont_loss_std 1.9e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.9e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
1.58 / train/dyn_loss_std 3.02 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 670.46 / train/extr_critic_max 670.46 / train/extr_critic_mean 639.28 / train/extr_critic_min 469.5 / train/extr_critic_std 48.42 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / 
train/extr_return_normed_mean 0.8 / train/extr_return_normed_min -0.42 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.32 / train/extr_return_raw_max 668.32 / train/extr_return_raw_mean 639.3 / train/extr_return_raw_min 
469.78 / train/extr_return_raw_std 48.47 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.43 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.16 / train/image_loss_std 0.27 / train/model_loss_mean 1.2 / 
train/model_loss_std 2.01 / train/model_opt_grad_norm 5.27 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 
1.42 / train/policy_entropy_mean 0.52 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.83 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.52 / train/policy_logprob_min -8.83 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 1.1e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.16 / train/post_ent_max 52.16 / train/post_ent_mean 37.38 / train/post_ent_min
27.07 / train/post_ent_std 4.48 / train/prior_ent_mag 63.96 / train/prior_ent_max 63.96 / train/prior_ent_mean 38.57 / train/prior_ent_min 30.85 / train/prior_ent_std 5.58 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.02 / train/reward_avg 1.41 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 2.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.41 / train/reward_rate 0.7 / 
train_stats/mean_log_entropy 0.55 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 7.1e-11 / report/cont_loss_std 2.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 7.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.44 / report/dyn_loss_std 2.88 / report/image_loss_mean 0.13 / report/image_loss_std 0.2 / report/model_loss_mean 1.1 / report/model_loss_std 1.86 / report/post_ent_mag 49.02 / report/post_ent_max 49.02 / 
report/post_ent_mean 35.75 / report/post_ent_min 29.73 / report/post_ent_std 3.09 / report/prior_ent_mag 63.94 / report/prior_ent_max 63.94 / report/prior_ent_mean 36.68 / report/prior_ent_min 31.73 / report/prior_ent_std 4.53 / report/rep_loss_mean 1.44 / 
report/rep_loss_std 2.88 / report/reward_avg 1.79 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.04 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 6e-5 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.11 / report/reward_pred 1.79 / report/reward_rate 0.9 / eval/cont_avg 1 / eval/cont_loss_mean 8.7e-11 / eval/cont_loss_std 2.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.7e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.54 / eval/dyn_loss_std 2.33 / eval/image_loss_mean 0.18 / eval/image_loss_std 0.25 / eval/model_loss_mean 1.19 / eval/model_loss_std 1.55 / eval/post_ent_mag 60.77 / eval/post_ent_max 60.77 / eval/post_ent_mean 37.48 / eval/post_ent_min 26.65 / 
eval/post_ent_std 4.16 / eval/prior_ent_mag 63.94 / eval/prior_ent_max 63.94 / eval/prior_ent_mean 38.69 / eval/prior_ent_min 31.71 / eval/prior_ent_std 5.41 / eval/rep_loss_mean 1.54 / eval/rep_loss_std 2.33 / eval/reward_avg 1.51 / eval/reward_loss_mean 0.09 / 
eval/reward_loss_std 0.05 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 9.3e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.51 / eval/reward_rate 0.76 / replay/size 5.4e5 / replay/inserts 3883 
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.99 / timer/env.step_count 3883 / timer/env.step_total 19.25 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.1e-3 / 
timer/env.step_max 6.3e-3 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 395.6 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 5.1e-3 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7390 / timer/agent.policy_total 16.2 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 6.5e-3 / timer/dataset_train_count 
1941 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.4e-4 / timer/agent.train_count 1941 / timer/agent.train_total 246.41 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 541500 Counter(541500) 541437
Saved chunk: 20230922T092016F093557-7l3g9915i7zujnqvmzBatj-0je3B5d8s8l03F2prDEcf7-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 846.0.
Saved chunk: 20230922T092031F540160-08G87feQ8lMfyw5g5raVn7-20wur3Jqns6NPZpH4amTD6-1024.npz
Starting evaluation at step 542000 Counter(542000) 541937
eval_Episode has 500 steps and return 847.0.
train_Episode has 500 steps and return 837.0.
Starting evaluation at step 542500 Counter(542500) 542437
Saved chunk: 20230922T092134F978862-0je3B5d8s8l03F2prDEcf7-0q3zOTToUJnoja2Xk1rd2J-1024.npz
eval_Episode has 500 steps and return 843.0.
train_Episode has 500 steps and return 841.0.
Saved chunk: 20230922T092152F119445-20wur3Jqns6NPZpH4amTD6-6Sv4uy9I5hymbMmfTrGTbk-1024.npz
Starting evaluation at step 543000 Counter(543000) 542937
eval_Episode has 500 steps and return 804.0.
train_Episode has 500 steps and return 808.0.
Starting evaluation at step 543500 Counter(543500) 543437
Saved chunk: 20230922T092253F129872-0q3zOTToUJnoja2Xk1rd2J-5FKy8it6itkM0xlRjgyWwC-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T092311F760799-6Sv4uy9I5hymbMmfTrGTbk-06TExe1eQaiGT6wCxcrJgk-1024.npz
Starting evaluation at step 544000 Counter(544000) 543937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 842.0.
Starting evaluation at step 544500 Counter(544500) 544437
Saved chunk: 20230922T092411F034117-5FKy8it6itkM0xlRjgyWwC-01rgMYQo2upY3jlpoj6rfQ-1024.npz
eval_Episode has 500 steps and return 792.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T092431F177379-06TExe1eQaiGT6wCxcrJgk-3LveizjKMKgu4DoLbUT3op-1024.npz
Starting evaluation at step 545000 Counter(545000) 544937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 843.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1090538 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 843 / episode/reward_rate 0.84 / train/action_mag 4.3 / train/action_max 4.11 / train/action_mean 3.9e-3 / train/action_min -4.12 / train/action_std 1.01 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.09 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.75 / train/adv_mag 0.5 / train/adv_max 0.38 / train/adv_mean 1.3e-4 / train/adv_min -0.46 /
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.6e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.6e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 / 
train/dyn_loss_std 3.01 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.48 / train/extr_critic_max 670.48 / train/extr_critic_mean 639.75 / train/extr_critic_min 475.51 / train/extr_critic_std 47.31 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.36 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.17 / train/extr_return_raw_max 668.17 / train/extr_return_raw_mean 639.77 / train/extr_return_raw_min 474.94 / train/extr_return_raw_std 47.36
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.44 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.16 / train/image_loss_std 0.26 / train/model_loss_mean 1.19 / train/model_loss_std 2 / 
train/model_opt_grad_norm 5.21 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.49 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.94 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.49 / train/policy_logprob_min -8.94 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.6 / train/policy_randomness_min 2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.27 / train/post_ent_max 52.27 / train/post_ent_mean 37.37 / train/post_ent_min 
27.33 / train/post_ent_std 4.42 / train/prior_ent_mag 63.92 / train/prior_ent_max 63.92 / train/prior_ent_mean 38.53 / train/prior_ent_min 30.72 / train/prior_ent_std 5.52 / train/rep_loss_mean 1.57 / train/rep_loss_std 3.01 / train/reward_avg 1.41 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.5e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.41 / train/reward_rate 0.71 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.38 / report/cont_avg 1 / report/cont_loss_mean 5.1e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 5.1e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.44 / report/dyn_loss_std 2.49 / report/image_loss_mean 0.13 / report/image_loss_std 0.25 / report/model_loss_mean 1.09 / report/model_loss_std 1.73 / report/post_ent_mag 51.84 / report/post_ent_max 51.84 / 
report/post_ent_mean 36.69 / report/post_ent_min 28.3 / report/post_ent_std 4.18 / report/prior_ent_mag 63.98 / report/prior_ent_max 63.98 / report/prior_ent_mean 37.67 / report/prior_ent_min 31.39 / report/prior_ent_std 5.35 / report/rep_loss_mean 1.44 / 
report/rep_loss_std 2.49 / report/reward_avg 1.75 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.13 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 0.03 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.75 / report/reward_rate 0.88 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 2.2e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.84 / eval/dyn_loss_std 3.66 / eval/image_loss_mean 0.21 / eval/image_loss_std 0.42 / eval/model_loss_mean 1.4 / eval/model_loss_std 2.46 / eval/post_ent_mag 53.12 / eval/post_ent_max 53.12 / eval/post_ent_mean 
37.63 / eval/post_ent_min 23.8 / eval/post_ent_std 4.43 / eval/prior_ent_mag 63.98 / eval/prior_ent_max 63.98 / eval/prior_ent_mean 39.1 / eval/prior_ent_min 31.81 / eval/prior_ent_std 5.64 / eval/rep_loss_mean 1.84 / eval/rep_loss_std 3.66 / eval/reward_avg 1.43 / 
eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.06 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 6.5e-6 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.43 / eval/reward_rate 0.72 / replay/size
5.5e5 / replay/inserts 3831 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 299.98 / timer/env.step_count 3831 / timer/env.step_total 19.37 / timer/env.step_frac 0.06 / timer/env.step_avg 
5.1e-3 / timer/env.step_min 4.2e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 389.62 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 3.4e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7839 / timer/agent.policy_total 17.17 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.01 / 
timer/dataset_train_count 1916 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1916 / timer/agent.train_total 242.93 / 
timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.33 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / 
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T092528F735985-01rgMYQo2upY3jlpoj6rfQ-0000000000000000000000-897.npz
Saved chunk: 20230922T092550F376437-3LveizjKMKgu4DoLbUT3op-0000000000000000000000-532.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 545500 Counter(545500) 545437
Saved chunk: 20230922T092528F735985-01rgMYQo2upY3jlpoj6rfQ-4MIjLyJCTEHouxyEn069Wh-1024.npz
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 834.0.
Saved chunk: 20230922T092550F376437-3LveizjKMKgu4DoLbUT3op-13HJE8BvIGRzDWjW0oF07f-1024.npz
Starting evaluation at step 546000 Counter(546000) 545937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 844.0.
Starting evaluation at step 546500 Counter(546500) 546437
Saved chunk: 20230922T092647F786702-4MIjLyJCTEHouxyEn069Wh-3Jh6pk95f9j7YT8XcL8e6O-1024.npz
eval_Episode has 500 steps and return 848.0.
train_Episode has 500 steps and return 847.0.
Saved chunk: 20230922T092711F159947-13HJE8BvIGRzDWjW0oF07f-7MkyFEFp5yDgIGq8yGr2Bx-1024.npz
Starting evaluation at step 547000 Counter(547000) 546937
eval_Episode has 500 steps and return 796.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 547500 Counter(547500) 547437
Saved chunk: 20230922T092805F964929-3Jh6pk95f9j7YT8XcL8e6O-50ZUq1g2PP0IcIjm1umBOl-1024.npz
eval_Episode has 500 steps and return 851.0.
train_Episode has 500 steps and return 845.0.
Saved chunk: 20230922T092830F797398-7MkyFEFp5yDgIGq8yGr2Bx-4pOJT3i8Uqowkh6R9HbZqr-1024.npz
Starting evaluation at step 548000 Counter(548000) 547937
eval_Episode has 500 steps and return 807.0.
train_Episode has 500 steps and return 845.0.
Starting evaluation at step 548500 Counter(548500) 548437
Saved chunk: 20230922T092923F755799-50ZUq1g2PP0IcIjm1umBOl-5EtqgX0CBzh7tnp8wwH60X-1024.npz
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T092950F080776-4pOJT3i8Uqowkh6R9HbZqr-7LFOAxwnh2RJhfaHFbfds9-1024.npz
Starting evaluation at step 549000 Counter(549000) 548937
eval_Episode has 500 steps and return 849.0.
train_Episode has 500 steps and return 847.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1098198 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 849 / eval_episode/reward_rate 0.85 / episode/length 500 / episode/score 847 / episode/reward_rate 0.85 / train/action_mag 4.37 / train/action_max 4.17 / train/action_mean 0.01 / train/action_min -4.2 / train/action_std 1.03 / 
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -2.37 / train/adv_mag 0.51 / train/adv_max 0.39 / train/adv_mean 8.2e-5 / train/adv_min -0.46 / 
train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.4e-11 / train/cont_loss_std 1.7e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.4e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.56 / 
train/dyn_loss_std 2.94 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 670.49 / train/extr_critic_max 670.49 / train/extr_critic_mean 639.74 / train/extr_critic_min 476.55 / train/extr_critic_std 46.86 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.79 / 
train/extr_return_normed_min -0.45 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 668.16 / train/extr_return_raw_max 668.16 / train/extr_return_raw_mean 639.75 / train/extr_return_raw_min 475.38 / train/extr_return_raw_std 46.9 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.44 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.16 / train/image_loss_std 0.26 / train/model_loss_mean 1.18 / train/model_loss_std 1.96 / 
train/model_opt_grad_norm 5.09 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.53 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 9.1 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.53 / train/policy_logprob_min -9.1 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.61 / train/policy_randomness_min 2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.38 / train/post_ent_max 52.38 / train/post_ent_mean 37.22 / train/post_ent_min 
27.17 / train/post_ent_std 4.49 / train/prior_ent_mag 63.85 / train/prior_ent_max 63.85 / train/prior_ent_mean 38.38 / train/prior_ent_min 30.67 / train/prior_ent_std 5.57 / train/rep_loss_mean 1.56 / train/rep_loss_std 2.94 / train/reward_avg 1.42 / 
train/reward_loss_mean 0.08 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.42 / train/reward_rate 0.71 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.59 / report/cont_avg 1 / report/cont_loss_mean 8e-11 / report/cont_loss_std 4.6e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 8e-11 / report/cont_pred 
1 / report/cont_rate 1 / report/dyn_loss_mean 1.61 / report/dyn_loss_std 3.21 / report/image_loss_mean 0.19 / report/image_loss_std 0.38 / report/model_loss_mean 1.24 / report/model_loss_std 2.19 / report/post_ent_mag 49.77 / report/post_ent_max 49.77 / 
report/post_ent_mean 37.09 / report/post_ent_min 26.65 / report/post_ent_std 3.77 / report/prior_ent_mag 64.07 / report/prior_ent_max 64.07 / report/prior_ent_mean 38.2 / report/prior_ent_min 31.76 / report/prior_ent_std 5.01 / report/rep_loss_mean 1.61 / 
report/rep_loss_std 3.21 / report/reward_avg 1.47 / report/reward_loss_mean 0.08 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.5e-3 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.47 / report/reward_rate 0.74 / eval/cont_avg 1 / eval/cont_loss_mean 8.4e-11 / eval/cont_loss_std 2.3e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 8.4e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.46 / eval/dyn_loss_std 2.47 / eval/image_loss_mean 0.15 / eval/image_loss_std 0.24 / eval/model_loss_mean 1.13 / eval/model_loss_std 1.69 / eval/post_ent_mag 49.9 / eval/post_ent_max 49.9 / eval/post_ent_mean 
36.93 / eval/post_ent_min 29.38 / eval/post_ent_std 3.26 / eval/prior_ent_mag 64.07 / eval/prior_ent_max 64.07 / eval/prior_ent_mean 38.03 / eval/prior_ent_min 31.69 / eval/prior_ent_std 4.57 / eval/rep_loss_mean 1.46 / eval/rep_loss_std 2.47 / eval/reward_avg 1.74 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.18 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.97 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.74 / eval/reward_rate 0.87 / replay/size
5.5e5 / replay/inserts 3830 / replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.1 / timer/env.step_count 3830 / timer/env.step_total 19.31 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 /
timer/env.step_min 4.2e-3 / timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.99 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 1 / timer/agent.save_total 0.11 / timer/agent.save_frac 3.7e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7838 / timer/agent.policy_total 17.26 / timer/agent.policy_frac 0.06 / 
timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.11 / timer/dataset_train_count 1915 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.2e-5 / 
timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1915 / timer/agent.train_total 243.03 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11
/ timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.9e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.9e-5 / 
timer/dataset_eval_min 3.9e-5 / timer/dataset_eval_max 3.9e-5 / fps 25.52

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 549500 Counter(549500) 549437
Saved chunk: 20230922T093041F439624-5EtqgX0CBzh7tnp8wwH60X-4YcCj2ozVsVfVvYXOT7fUx-1024.npz
eval_Episode has 500 steps and return 850.0.
train_Episode has 500 steps and return 844.0.
Saved chunk: 20230922T093109F251499-7LFOAxwnh2RJhfaHFbfds9-2z13nJ1rSihKDDLKarB65Q-1024.npz
Starting evaluation at step 550000 Counter(550000) 549937
eval_Episode has 500 steps and return 801.0.
train_Episode has 500 steps and return 830.0.
Starting evaluation at step 550500 Counter(550500) 550437
Saved chunk: 20230922T093200F353848-4YcCj2ozVsVfVvYXOT7fUx-1GEKT1bjPV2Oj6OV5oteKM-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 610.0.
Saved chunk: 20230922T093229F886392-2z13nJ1rSihKDDLKarB65Q-7MmkPesSCke4egtLdP7BEP-1024.npz
Starting evaluation at step 551000 Counter(551000) 550937
eval_Episode has 500 steps and return 764.0.
train_Episode has 500 steps and return 749.0.
Starting evaluation at step 551500 Counter(551500) 551437
Saved chunk: 20230922T093318F313881-1GEKT1bjPV2Oj6OV5oteKM-6D7cPCa59k8h27RmebCkp9-1024.npz
eval_Episode has 500 steps and return 680.0.
train_Episode has 500 steps and return 756.0.
Saved chunk: 20230922T093349F346555-7MmkPesSCke4egtLdP7BEP-1iaSZHOmiTX84ZoC4Vf1Pm-1024.npz
Starting evaluation at step 552000 Counter(552000) 551937
eval_Episode has 500 steps and return 768.0.
train_Episode has 500 steps and return 768.0.
Starting evaluation at step 552500 Counter(552500) 552437
Saved chunk: 20230922T093436F059091-6D7cPCa59k8h27RmebCkp9-2mcHkMho6KeFqHy6MUZu47-1024.npz
eval_Episode has 500 steps and return 749.0.
train_Episode has 500 steps and return 766.0.
Saved chunk: 20230922T093508F563171-1iaSZHOmiTX84ZoC4Vf1Pm-4nrWM7q401OiWQ5WQa3X5K-1024.npz
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1105966 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 749 / eval_episode/reward_rate 0.75 / episode/length 500 / episode/score 766 / episode/reward_rate 0.76 / train/action_mag 4.31 / train/action_max 4.16 / train/action_mean -7.1e-3 / train/action_min -4.13 / train/action_std 
1.03 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.7e5 / train/actor_opt_loss -1.41 / train/adv_mag 0.51 / train/adv_max 0.37 / train/adv_mean -1.7e-5 / train/adv_min 
-0.46 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
1.56 / train/dyn_loss_std 2.91 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.7e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 670.09 / train/extr_critic_max 670.09 / train/extr_critic_mean 641.03 / train/extr_critic_min 466.8 / train/extr_critic_std 46.54 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.48 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.85 / train/extr_return_raw_max 667.85 / train/extr_return_raw_mean 641.03 / train/extr_return_raw_min 
466.52 / train/extr_return_raw_std 46.61 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.46 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.16 / train/image_loss_std 0.27 / train/model_loss_mean 1.18 / 
train/model_loss_std 1.94 / train/model_opt_grad_norm 5.34 / train/model_opt_grad_steps 2.7e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 
1.42 / train/policy_entropy_mean 0.54 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.9 / train/policy_logprob_mag 8.78 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.54 / train/policy_logprob_min -8.78 / train/policy_logprob_std 1.14 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.62 / train/policy_randomness_min 2.2e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.59 / train/post_ent_max 52.59 / train/post_ent_mean 37.24 / train/post_ent_min
27.31 / train/post_ent_std 4.38 / train/prior_ent_mag 63.88 / train/prior_ent_max 63.88 / train/prior_ent_mean 38.4 / train/prior_ent_min 30.68 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.56 / train/rep_loss_std 2.91 / train/reward_avg 1.43 / train/reward_loss_mean
0.09 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 4.6e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.43 / train/reward_rate 0.72 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.54 / report/cont_avg 1 / report/cont_loss_mean 3.5e-11 / report/cont_loss_std 2.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.5e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.52 / report/dyn_loss_std 2.6 / report/image_loss_mean 0.13 / report/image_loss_std 0.14 / report/model_loss_mean 1.14 / report/model_loss_std 1.64 / report/post_ent_mag 51.83 / report/post_ent_max 51.83 / 
report/post_ent_mean 35.96 / report/post_ent_min 13.2 / report/post_ent_std 3.35 / report/prior_ent_mag 64.03 / report/prior_ent_max 64.03 / report/prior_ent_mean 37.09 / report/prior_ent_min 26.58 / report/prior_ent_std 4.64 / report/rep_loss_mean 1.52 / 
report/rep_loss_std 2.6 / report/reward_avg 1.7 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.97 / report/reward_neg_loss 0.01 / report/reward_pos_acc 1 / report/reward_pos_loss 
0.11 / report/reward_pred 1.7 / report/reward_rate 0.85 / eval/cont_avg 1 / eval/cont_loss_mean 6.8e-11 / eval/cont_loss_std 2.8e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 6.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 /
eval/dyn_loss_mean 1.56 / eval/dyn_loss_std 3.12 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.21 / eval/model_loss_mean 1.16 / eval/model_loss_std 2.03 / eval/post_ent_mag 51.33 / eval/post_ent_max 51.33 / eval/post_ent_mean 36.98 / eval/post_ent_min 24.8 / 
eval/post_ent_std 3.99 / eval/prior_ent_mag 64.03 / eval/prior_ent_max 64.03 / eval/prior_ent_mean 38.06 / eval/prior_ent_min 31.49 / eval/prior_ent_std 5.07 / eval/rep_loss_mean 1.56 / eval/rep_loss_std 3.12 / eval/reward_avg 1.45 / eval/reward_loss_mean 0.08 / 
eval/reward_loss_std 0.07 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 2e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.45 / eval/reward_rate 0.73 / replay/size 5.5e5 / replay/inserts 3884 / 
replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.4e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3884 / timer/env.step_total 19.45 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.18 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 394.32 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7e-4 / timer/replay._sample_max 0.04 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.01 / timer/dataset_train_count 
1942 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.2 / timer/agent.train_frac 0.82 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.5e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.5e-5 / timer/dataset_eval_min 3.5e-5 / timer/dataset_eval_max 3.5e-5 / fps 25.89

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 553000 Counter(553000) 552937
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 726.0.
Starting evaluation at step 553500 Counter(553500) 553437
Saved chunk: 20230922T093553F648636-2mcHkMho6KeFqHy6MUZu47-2v7ZRfHTNCb6Ye7klmHSdm-1024.npz
eval_Episode has 500 steps and return 726.0.
train_Episode has 500 steps and return 770.0.
Saved chunk: 20230922T093627F694174-4nrWM7q401OiWQ5WQa3X5K-3LB7Eyeu13Zu2hTf9lviEm-1024.npz
Starting evaluation at step 554000 Counter(554000) 553937
eval_Episode has 500 steps and return 771.0.
train_Episode has 500 steps and return 774.0.
Starting evaluation at step 554500 Counter(554500) 554437
Saved chunk: 20230922T093712F720145-2v7ZRfHTNCb6Ye7klmHSdm-5AWvzEJaidF1kCKH0tcZWB-1024.npz
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 555000 Counter(555000) 554937
eval_Episode has 500 steps and return 768.0.
Saved chunk: 20230922T093748F448742-3LB7Eyeu13Zu2hTf9lviEm-0wYjqskrHtI65Dhru9D68s-1024.npz
train_Episode has 500 steps and return 759.0.
Starting evaluation at step 555500 Counter(555500) 555437
Saved chunk: 20230922T093830F625730-5AWvzEJaidF1kCKH0tcZWB-3jLm8KVCJ9CSbExetFz3Uw-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 772.0.
Starting evaluation at step 556000 Counter(556000) 555937
eval_Episode has 500 steps and return 755.0.
Saved chunk: 20230922T093911F212350-0wYjqskrHtI65Dhru9D68s-0XHxVouRaZCL9svE3A8CCc-1024.npz
train_Episode has 500 steps and return 764.0.
Starting evaluation at step 556500 Counter(556500) 556437
Saved chunk: 20230922T093948F402207-3jLm8KVCJ9CSbExetFz3Uw-5DMTRXk618IVmGj8yBRv54-1024.npz
eval_Episode has 500 steps and return 742.0.
train_Episode has 500 steps and return 771.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1113630 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 742 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 771 / episode/reward_rate 0.77 / train/action_mag 4.39 / train/action_max 4.27 / train/action_mean -6.1e-3 / train/action_min -4.11 / train/action_std 
1.05 / train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -2.98 / train/adv_mag 0.5 / train/adv_max 0.39 / train/adv_mean 1.4e-4 / train/adv_min 
-0.44 / train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean
1.57 / train/dyn_loss_std 3 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.05 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss
1.1e4 / train/extr_critic_mag 669.55 / train/extr_critic_max 669.55 / train/extr_critic_mean 639.68 / train/extr_critic_min 464.64 / train/extr_critic_std 47.41 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.49 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.58 / train/extr_return_raw_max 667.58 / train/extr_return_raw_mean 639.7 / train/extr_return_raw_min 463.13 / train/extr_return_raw_std 47.43 
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.45 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.16 / train/image_loss_std 0.28 / train/model_loss_mean 1.19 / train/model_loss_std 2.01 / 
train/model_opt_grad_norm 5.01 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.55 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.96 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.55 / train/policy_logprob_min -8.96 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.62 / train/policy_randomness_min 1.7e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.14 / train/post_ent_max 52.14 / train/post_ent_mean 37.39 / train/post_ent_min 
27.48 / train/post_ent_std 4.37 / train/prior_ent_mag 63.96 / train/prior_ent_max 63.96 / train/prior_ent_mean 38.56 / train/prior_ent_min 31 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.57 / train/rep_loss_std 3 / train/reward_avg 1.42 / train/reward_loss_mean 0.09
/ train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.1e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.42 / train/reward_rate 0.71 / eval_stats/mean_log_entropy 0 
/ train_stats/mean_log_entropy 0.64 / report/cont_avg 1 / report/cont_loss_mean 3.6e-11 / report/cont_loss_std 1.3e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.6e-11 / report/cont_pred 1 / report/cont_rate 1 / 
report/dyn_loss_mean 1.46 / report/dyn_loss_std 2.32 / report/image_loss_mean 0.14 / report/image_loss_std 0.13 / report/model_loss_mean 1.1 / report/model_loss_std 1.46 / report/post_ent_mag 52.17 / report/post_ent_max 52.17 / report/post_ent_mean 36.96 / 
report/post_ent_min 29.82 / report/post_ent_std 4.39 / report/prior_ent_mag 64.06 / report/prior_ent_max 64.06 / report/prior_ent_mean 38.03 / report/prior_ent_min 31.57 / report/prior_ent_std 5.5 / report/rep_loss_mean 1.46 / report/rep_loss_std 2.32 / report/reward_avg 
1.55 / report/reward_loss_mean 0.09 / report/reward_loss_std 0.05 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2e-4 / report/reward_pos_acc 1 / report/reward_pos_loss 0.11 / report/reward_pred 1.55 / 
report/reward_rate 0.77 / eval/cont_avg 1 / eval/cont_loss_mean 5.5e-11 / eval/cont_loss_std 1.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 5.5e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.77 / 
eval/dyn_loss_std 3.87 / eval/image_loss_mean 0.22 / eval/image_loss_std 0.87 / eval/model_loss_mean 1.37 / eval/model_loss_std 2.81 / eval/post_ent_mag 51.96 / eval/post_ent_max 51.96 / eval/post_ent_mean 37.43 / eval/post_ent_min 24.67 / eval/post_ent_std 4.41 / 
eval/prior_ent_mag 64.06 / eval/prior_ent_max 64.06 / eval/prior_ent_mean 38.74 / eval/prior_ent_min 31.81 / eval/prior_ent_std 5.59 / eval/rep_loss_mean 1.77 / eval/rep_loss_std 3.87 / eval/reward_avg 1.46 / eval/reward_loss_mean 0.09 / eval/reward_loss_std 0.12 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-5 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.12 / eval/reward_pred 1.46 / eval/reward_rate 0.73 / replay/size 5.6e5 / replay/inserts 3832 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.03 / timer/env.step_count 3832 / timer/env.step_total 19.01 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 6.3e-3 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.78 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 7.1e-4 / timer/replay._sample_max 0.2 / timer/agent.save_count 0 / timer/agent.save_total 0 / 
timer/agent.save_frac 0 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.37 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 1916 / 
timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4.2e-4 / timer/agent.train_count 1916 / timer/agent.train_total 243.03 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 4e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 4e-5 / timer/dataset_eval_min 4e-5 / timer/dataset_eval_max 4e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Writing checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Saved chunk: 20230922T094030F559683-0XHxVouRaZCL9svE3A8CCc-0000000000000000000000-868.npz
Saved chunk: 20230922T094106F129153-5DMTRXk618IVmGj8yBRv54-0000000000000000000000-132.npz
Wrote checkpoint: /fs/cml-projects/Pretrain_MBRL/dreamerv3_exp/dmc_cartpole_swingup_sparse/6/checkpoint.ckpt
Starting evaluation at step 557000 Counter(557000) 556937
eval_Episode has 500 steps and return 699.0.
Saved chunk: 20230922T094030F559683-0XHxVouRaZCL9svE3A8CCc-3IRqMwCGNObH7XYMjTIZ45-1024.npz
train_Episode has 500 steps and return 706.0.
Starting evaluation at step 557500 Counter(557500) 557437
Saved chunk: 20230922T094106F129153-5DMTRXk618IVmGj8yBRv54-27kESfNbP3nTrpWKDNtTC9-1024.npz
eval_Episode has 500 steps and return 704.0.
train_Episode has 500 steps and return 533.0.
Starting evaluation at step 558000 Counter(558000) 557937
eval_Episode has 500 steps and return 716.0.
Saved chunk: 20230922T094151F194210-3IRqMwCGNObH7XYMjTIZ45-7DRmdGanHi0rXcfGrmmqF7-1024.npz
train_Episode has 500 steps and return 581.0.
Starting evaluation at step 558500 Counter(558500) 558437
Saved chunk: 20230922T094225F448223-27kESfNbP3nTrpWKDNtTC9-40KB7yXkRRdHc68uuOgLRR-1024.npz
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 766.0.
Starting evaluation at step 559000 Counter(559000) 558937
eval_Episode has 500 steps and return 774.0.
Saved chunk: 20230922T094310F825879-7DRmdGanHi0rXcfGrmmqF7-5eBI3GiwZt7Xkh7T9WMhqi-1024.npz
train_Episode has 500 steps and return 760.0.
Starting evaluation at step 559500 Counter(559500) 559437
Saved chunk: 20230922T094343F373492-40KB7yXkRRdHc68uuOgLRR-3lmaAcXRB7GuivcYYjjvwY-1024.npz
eval_Episode has 500 steps and return 773.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 560000 Counter(560000) 559937
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T094430F172801-5eBI3GiwZt7Xkh7T9WMhqi-25SRMssihw1AEVjlwQweSw-1024.npz
Starting evaluation at step 560500 Counter(560500) 560437
Saved chunk: 20230922T094501F147075-3lmaAcXRB7GuivcYYjjvwY-3nqsSkje5w6Vd6WnTNGyf4-1024.npz
eval_Episode has 500 steps and return 741.0.
train_Episode has 500 steps and return 743.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1121294 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 741 / eval_episode/reward_rate 0.74 / episode/length 500 / episode/score 743 / episode/reward_rate 0.74 / train/action_mag 4.34 / train/action_max 4.21 / train/action_mean -6e-3 / train/action_min -4.15 / train/action_std 1.06 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.06 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -2.46 / train/adv_mag 0.49 / train/adv_max 0.39 / train/adv_mean 7.9e-5 / train/adv_min -0.41 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.5e-11 / train/cont_loss_std 2.1e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.5e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.58 
/ train/dyn_loss_std 3.05 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.42 / train/extr_critic_max 669.42 / train/extr_critic_mean 639.42 / train/extr_critic_min 462.76 / train/extr_critic_std 47.71 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.5 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.46 / train/extr_return_raw_max 667.46 / train/extr_return_raw_mean 639.43 / train/extr_return_raw_min 461.1 / train/extr_return_raw_std 47.76 /
train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.44 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.16 / train/image_loss_std 0.27 / train/model_loss_mean 1.19 / train/model_loss_std 2.03 / 
train/model_opt_grad_norm 5.6 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / train/policy_entropy_mean
0.57 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.96 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.57 / train/policy_logprob_min -8.96 / train/policy_logprob_std 1.16 / train/policy_randomness_mag 1 / 
train/policy_randomness_max 1 / train/policy_randomness_mean 0.63 / train/policy_randomness_min 1.7e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.11 / train/post_ent_max 52.11 / train/post_ent_mean 37.33 / train/post_ent_min 27.1 / train/post_ent_std 4.38 /
train/prior_ent_mag 64.01 / train/prior_ent_max 64.01 / train/prior_ent_mean 38.5 / train/prior_ent_min 31 / train/prior_ent_std 5.51 / train/rep_loss_mean 1.58 / train/rep_loss_std 3.05 / train/reward_avg 1.42 / train/reward_loss_mean 0.08 / train/reward_loss_std 0.09 / 
train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 3.7e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.42 / train/reward_rate 0.71 / eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy
0.51 / report/cont_avg 1 / report/cont_loss_mean 3.8e-11 / report/cont_loss_std 1.2e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.8e-11 / report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.57 / 
report/dyn_loss_std 3.45 / report/image_loss_mean 0.16 / report/image_loss_std 0.19 / report/model_loss_mean 1.18 / report/model_loss_std 2.2 / report/post_ent_mag 51.02 / report/post_ent_max 51.02 / report/post_ent_mean 37.84 / report/post_ent_min 27.48 / 
report/post_ent_std 4.46 / report/prior_ent_mag 63.97 / report/prior_ent_max 63.97 / report/prior_ent_mean 38.94 / report/prior_ent_min 30.59 / report/prior_ent_std 5.47 / report/rep_loss_mean 1.57 / report/rep_loss_std 3.45 / report/reward_avg 1.32 / 
report/reward_loss_mean 0.08 / report/reward_loss_std 0.1 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 0.99 / report/reward_neg_loss 3.1e-3 / report/reward_pos_acc 1 / report/reward_pos_loss 0.12 / report/reward_pred 1.32 / 
report/reward_rate 0.66 / eval/cont_avg 1 / eval/cont_loss_mean 7.1e-11 / eval/cont_loss_std 2.5e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 7.1e-11 / eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.64 / 
eval/dyn_loss_std 3.78 / eval/image_loss_mean 0.19 / eval/image_loss_std 0.27 / eval/model_loss_mean 1.26 / eval/model_loss_std 2.46 / eval/post_ent_mag 50.61 / eval/post_ent_max 50.61 / eval/post_ent_mean 38.02 / eval/post_ent_min 29.48 / eval/post_ent_std 3.73 / 
eval/prior_ent_mag 63.97 / eval/prior_ent_max 63.97 / eval/prior_ent_mean 39.14 / eval/prior_ent_min 32.01 / eval/prior_ent_std 5.02 / eval/rep_loss_mean 1.64 / eval/rep_loss_std 3.78 / eval/reward_avg 1.46 / eval/reward_loss_mean 0.08 / eval/reward_loss_std 0.06 / 
eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 1.3e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.11 / eval/reward_pred 1.46 / eval/reward_rate 0.73 / replay/size 5.6e5 / replay/inserts 3832 / replay/samples 3.1e4 / 
replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / 
eval_replay/sample_wait_avg 1.2e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.06 / timer/env.step_count 3832 / timer/env.step_total 19.04 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.03 / 
timer/replay._sample_count 3.1e4 / timer/replay._sample_total 392.48 / timer/replay._sample_frac 1.31 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 6.2e-3 / timer/replay._sample_max 0.21 / timer/agent.save_count 1 / timer/agent.save_total 0.11 / 
timer/agent.save_frac 3.6e-4 / timer/agent.save_avg 0.11 / timer/agent.save_min 0.11 / timer/agent.save_max 0.11 / timer/agent.policy_count 7840 / timer/agent.policy_total 17.3 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 
/ timer/agent.policy_max 0.11 / timer/dataset_train_count 1916 / timer/dataset_train_total 0.16 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8.1e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 4e-4 / timer/agent.train_count 1916 / 
timer/agent.train_total 243.18 / timer/agent.train_frac 0.81 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.32 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 
/ timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 2.8e-5 / timer/dataset_eval_frac 9.4e-8 / timer/dataset_eval_avg 2.8e-5 / timer/dataset_eval_min 2.8e-5 / timer/dataset_eval_max 2.8e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
Starting evaluation at step 561000 Counter(561000) 560937
eval_Episode has 500 steps and return 775.0.
train_Episode has 500 steps and return 767.0.
Saved chunk: 20230922T094549F396481-25SRMssihw1AEVjlwQweSw-6q5OdYib3GibUeTYZ3LYSo-1024.npz
Starting evaluation at step 561500 Counter(561500) 561437
eval_Episode has 500 steps and return 773.0.
Saved chunk: 20230922T094618F728493-3nqsSkje5w6Vd6WnTNGyf4-3phMgWHpJ2WPbd8zoTxd86-1024.npz
train_Episode has 500 steps and return 769.0.
Starting evaluation at step 562000 Counter(562000) 561937
eval_Episode has 500 steps and return 769.0.
train_Episode has 500 steps and return 758.0.
Saved chunk: 20230922T094709F898786-6q5OdYib3GibUeTYZ3LYSo-33a2JoucgsGBN7XVR7XK3o-1024.npz
Starting evaluation at step 562500 Counter(562500) 562437
eval_Episode has 500 steps and return 757.0.
Saved chunk: 20230922T094737F856229-3phMgWHpJ2WPbd8zoTxd86-6j3fpBfmPjSAmdYbpRmO0F-1024.npz
train_Episode has 500 steps and return 734.0.
Starting evaluation at step 563000 Counter(563000) 562937
eval_Episode has 500 steps and return 770.0.
train_Episode has 500 steps and return 598.0.
Saved chunk: 20230922T094829F334937-33a2JoucgsGBN7XVR7XK3o-4WYf4HGvOihwA46G5LRtq3-1024.npz
Starting evaluation at step 563500 Counter(563500) 563437
eval_Episode has 500 steps and return 779.0.
train_Episode has 500 steps and return 772.0.
Starting evaluation at step 564000 Counter(564000) 563937
Saved chunk: 20230922T094855F659714-6j3fpBfmPjSAmdYbpRmO0F-7dP5BSjhJi4QCsnmHPpdAV-1024.npz
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 772.0.
Saved chunk: 20230922T094948F667459-4WYf4HGvOihwA46G5LRtq3-7n8owih5qDRgGJ5yeX1hGC-1024.npz
Starting evaluation at step 564500 Counter(564500) 564437
eval_Episode has 500 steps and return 776.0.
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1129002 ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
eval_episode/length 500 / eval_episode/score 776 / eval_episode/reward_rate 0.77 / episode/length 500 / episode/score 772 / episode/reward_rate 0.77 / train/action_mag 4.28 / train/action_max 4.02 / train/action_mean -0.02 / train/action_min -4.14 / train/action_std 0.99 
/ train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -2.52 / train/adv_mag 0.47 / train/adv_max 0.37 / train/adv_mean 1.2e-4 / train/adv_min -0.41 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.2e-11 / train/cont_loss_std 1.4e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.2e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 1.57 
/ train/dyn_loss_std 2.98 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.8e5 / train/extr_critic_critic_opt_loss 
1.1e4 / train/extr_critic_mag 669.48 / train/extr_critic_max 669.48 / train/extr_critic_mean 638.59 / train/extr_critic_min 459.63 / train/extr_critic_std 49.74 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / train/extr_return_normed_mean 0.8 / 
train/extr_return_normed_min -0.47 / train/extr_return_normed_std 0.35 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.43 / train/extr_return_raw_max 667.43 / train/extr_return_raw_mean 638.61 / train/extr_return_raw_min 458.95 / train/extr_return_raw_std 49.79
/ train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.45 / train/extr_reward_min 0 / train/extr_reward_std 0.87 / train/image_loss_mean 0.16 / train/image_loss_std 0.27 / train/model_loss_mean 1.19 / train/model_loss_std 1.99 / 
train/model_opt_grad_norm 5.67 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 1.42 / 
train/policy_entropy_mean 0.45 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.91 / train/policy_logprob_mag 8.93 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.45 / train/policy_logprob_min -8.93 / train/policy_logprob_std 1.15 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.58 / train/policy_randomness_min 2.6e-5 / train/policy_randomness_std 0.39 / train/post_ent_mag 52.33 / train/post_ent_max 52.33 / train/post_ent_mean 37.33 / train/post_ent_min
27.49 / train/post_ent_std 4.4 / train/prior_ent_mag 63.83 / train/prior_ent_max 63.83 / train/prior_ent_mean 38.5 / train/prior_ent_min 30.93 / train/prior_ent_std 5.51 / train/rep_loss_mean 1.57 / train/rep_loss_std 2.98 / train/reward_avg 1.42 / train/reward_loss_mean 
0.09 / train/reward_loss_std 0.09 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 0.99 / train/reward_neg_loss 5.4e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.42 / train/reward_rate 0.71 / 
eval_stats/mean_log_entropy 0 / train_stats/mean_log_entropy 0.31 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 1e-10 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.34 / report/dyn_loss_std 1.69 / report/image_loss_mean 0.11 / report/image_loss_std 0.12 / report/model_loss_mean 1.02 / report/model_loss_std 1.09 / report/post_ent_mag 50.74 / report/post_ent_max 50.74 / 
report/post_ent_mean 36.9 / report/post_ent_min 29.77 / report/post_ent_std 3.79 / report/prior_ent_mag 64.05 / report/prior_ent_max 64.05 / report/prior_ent_mean 37.88 / report/prior_ent_min 31.9 / report/prior_ent_std 5.01 / report/rep_loss_mean 1.34 / 
report/rep_loss_std 1.69 / report/reward_avg 1.72 / report/reward_loss_mean 0.1 / report/reward_loss_std 0.04 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 2.2e-7 / report/reward_pos_acc 1 / report/reward_pos_loss
0.11 / report/reward_pred 1.72 / report/reward_rate 0.86 / eval/cont_avg 1 / eval/cont_loss_mean 4.8e-11 / eval/cont_loss_std 1.7e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.8e-11 / eval/cont_pred 1 / eval/cont_rate 1 
/ eval/dyn_loss_mean 1.53 / eval/dyn_loss_std 2.54 / eval/image_loss_mean 0.14 / eval/image_loss_std 0.17 / eval/model_loss_mean 1.18 / eval/model_loss_std 1.65 / eval/post_ent_mag 51.97 / eval/post_ent_max 51.97 / eval/post_ent_mean 37.2 / eval/post_ent_min 27.69 / 
eval/post_ent_std 3.99 / eval/prior_ent_mag 64.05 / eval/prior_ent_max 64.05 / eval/prior_ent_mean 38.36 / eval/prior_ent_min 31.85 / eval/prior_ent_std 5.24 / eval/rep_loss_mean 1.53 / eval/rep_loss_std 2.54 / eval/reward_avg 1.57 / eval/reward_loss_mean 0.12 / 
eval/reward_loss_std 0.21 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 0.93 / eval/reward_neg_loss 0.05 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.14 / eval/reward_pred 1.57 / eval/reward_rate 0.79 / replay/size 5.6e5 / replay/inserts 3854
/ replay/samples 3.1e4 / replay/insert_wait_avg 3.7e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 4008 / eval_replay/samples 16 / eval_replay/insert_wait_avg 2.7e-6 / 
eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.1e-6 / eval_replay/sample_wait_frac 1 / timer/duration 301.75 / timer/env.step_count 3854 / timer/env.step_total 19.14 / timer/env.step_frac 0.06 / timer/env.step_avg 5e-3 / timer/env.step_min 4.3e-3 / 
timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 391.54 / timer/replay._sample_frac 1.3 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.1e-3 / timer/replay._sample_max 0.03 / timer/agent.save_count 0 / 
timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7862 / timer/agent.policy_total 17.32 / timer/agent.policy_frac 0.06 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.8e-3 / timer/agent.policy_max 0.19 / timer/dataset_train_count 
1927 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.1e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 7.1e-5 / timer/dataset_train_max 5.6e-4 / timer/agent.train_count 1927 / timer/agent.train_total 244.81 / timer/agent.train_frac 0.81 / 
timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.57 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.8e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 / timer/agent.report_max 0.06 / 
timer/dataset_eval_count 1 / timer/dataset_eval_total 3.8e-5 / timer/dataset_eval_frac 1.3e-7 / timer/dataset_eval_avg 3.8e-5 / timer/dataset_eval_min 3.8e-5 / timer/dataset_eval_max 3.8e-5 / fps 25.54

GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
GIF summaries require ffmpeg in $PATH. [Errno 2] No such file or directory: 'ffmpeg'
train_Episode has 500 steps and return 774.0.
Starting evaluation at step 565000 Counter(565000) 564937
Saved chunk: 20230922T095048F818274-7dP5BSjhJi4QCsnmHPpdAV-11aHeEmkF4Ah5bhBFTkc4g-1024.npz
eval_Episode has 500 steps and return 775.0.
train_Episode has 500 steps and return 769.0.
Saved chunk: 20230922T095108F309822-7n8owih5qDRgGJ5yeX1hGC-1xN6VLft5PUZoTh1RsJFya-1024.npz
Starting evaluation at step 565500 Counter(565500) 565437
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 762.0.
Starting evaluation at step 566000 Counter(566000) 565937
Saved chunk: 20230922T095208F078246-11aHeEmkF4Ah5bhBFTkc4g-4oWqa7GYgjdaeR6UorDHRI-1024.npz
eval_Episode has 500 steps and return 774.0.
train_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T095228F797462-1xN6VLft5PUZoTh1RsJFya-6CLfU1uRCcnWzARNXnU7eZ-1024.npz
Starting evaluation at step 566500 Counter(566500) 566437
eval_Episode has 500 steps and return 765.0.
train_Episode has 500 steps and return 763.0.
Starting evaluation at step 567000 Counter(567000) 566937
Saved chunk: 20230922T095325F936930-4oWqa7GYgjdaeR6UorDHRI-6epTIHgqzDlsxF8ZRxeSe7-1024.npz
eval_Episode has 500 steps and return 772.0.
train_Episode has 500 steps and return 763.0.
Saved chunk: 20230922T095348F160825-6CLfU1uRCcnWzARNXnU7eZ-1Z2UB37bgRop2C1WBhGlxi-1024.npz
Starting evaluation at step 567500 Counter(567500) 567437
eval_Episode has 500 steps and return 760.0.
train_Episode has 500 steps and return 755.0.
Starting evaluation at step 568000 Counter(568000) 567937
Saved chunk: 20230922T095443F748145-6epTIHgqzDlsxF8ZRxeSe7-042HfyDqs17xhWuocpteJq-1024.npz
eval_Episode has 500 steps and return 763.0.
train_Episode has 500 steps and return 762.0.
Saved chunk: 20230922T095507F429925-1Z2UB37bgRop2C1WBhGlxi-4Qq8Rn7zVdYO8vfrP8ldbY-1024.npz
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── Step 1136770 ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
episode/length 500 / episode/score 762 / episode/reward_rate 0.76 / eval_episode/length 500 / eval_episode/score 763 / eval_episode/reward_rate 0.76 / train/action_mag 4.22 / train/action_max 3.97 / train/action_mean -0.02 / train/action_min -4.11 / train/action_std 1 /
train/actor_opt_actor_opt_grad_overflow 0 / train/actor_opt_actor_opt_grad_scale 1e4 / train/actor_opt_grad_norm 0.08 / train/actor_opt_grad_steps 2.8e5 / train/actor_opt_loss -4.13 / train/adv_mag 0.47 / train/adv_max 0.35 / train/adv_mean 2.8e-4 / train/adv_min -0.41 
/ train/adv_std 0.02 / train/cont_avg 1 / train/cont_loss_mean 3.3e-11 / train/cont_loss_std 1.5e-10 / train/cont_neg_acc nan / train/cont_neg_loss nan / train/cont_pos_acc 1 / train/cont_pos_loss 3.3e-11 / train/cont_pred 1 / train/cont_rate 1 / train/dyn_loss_mean 
1.55 / train/dyn_loss_std 2.93 / train/extr_critic_critic_opt_critic_opt_grad_overflow 0 / train/extr_critic_critic_opt_critic_opt_grad_scale 1e4 / train/extr_critic_critic_opt_grad_norm 0.06 / train/extr_critic_critic_opt_grad_steps 2.8e5 / 
train/extr_critic_critic_opt_loss 1.1e4 / train/extr_critic_mag 669.63 / train/extr_critic_max 669.63 / train/extr_critic_mean 639.97 / train/extr_critic_min 459.25 / train/extr_critic_std 48.46 / train/extr_return_normed_mag 1.01 / train/extr_return_normed_max 1.01 / 
train/extr_return_normed_mean 0.81 / train/extr_return_normed_min -0.48 / train/extr_return_normed_std 0.34 / train/extr_return_rate 1 / train/extr_return_raw_mag 667.7 / train/extr_return_raw_max 667.7 / train/extr_return_raw_mean 640.01 / train/extr_return_raw_min 
457.74 / train/extr_return_raw_std 48.48 / train/extr_reward_mag 2 / train/extr_reward_max 2 / train/extr_reward_mean 1.46 / train/extr_reward_min 0 / train/extr_reward_std 0.86 / train/image_loss_mean 0.16 / train/image_loss_std 0.25 / train/model_loss_mean 1.18 / 
train/model_loss_std 1.94 / train/model_opt_grad_norm 5.15 / train/model_opt_grad_steps 2.8e5 / train/model_opt_loss 1.2e4 / train/model_opt_model_opt_grad_overflow 0 / train/model_opt_model_opt_grad_scale 1e4 / train/policy_entropy_mag 1.42 / train/policy_entropy_max 
1.42 / train/policy_entropy_mean 0.47 / train/policy_entropy_min -0.88 / train/policy_entropy_std 0.92 / train/policy_logprob_mag 8.88 / train/policy_logprob_max 1.38 / train/policy_logprob_mean -0.47 / train/policy_logprob_min -8.88 / train/policy_logprob_std 1.16 / 
train/policy_randomness_mag 1 / train/policy_randomness_max 1 / train/policy_randomness_mean 0.59 / train/policy_randomness_min 2e-5 / train/policy_randomness_std 0.4 / train/post_ent_mag 52.35 / train/post_ent_max 52.35 / train/post_ent_mean 37.29 / train/post_ent_min 
27.48 / train/post_ent_std 4.37 / train/prior_ent_mag 63.96 / train/prior_ent_max 63.96 / train/prior_ent_mean 38.44 / train/prior_ent_min 31.03 / train/prior_ent_std 5.49 / train/rep_loss_mean 1.55 / train/rep_loss_std 2.93 / train/reward_avg 1.43 / 
train/reward_loss_mean 0.09 / train/reward_loss_std 0.1 / train/reward_max_data 2 / train/reward_max_pred 2 / train/reward_neg_acc 1 / train/reward_neg_loss 5.2e-3 / train/reward_pos_acc 1 / train/reward_pos_loss 0.12 / train/reward_pred 1.43 / train/reward_rate 0.72 / 
train_stats/mean_log_entropy 0.39 / eval_stats/mean_log_entropy 0 / report/cont_avg 1 / report/cont_loss_mean 3.2e-11 / report/cont_loss_std 9.4e-11 / report/cont_neg_acc nan / report/cont_neg_loss nan / report/cont_pos_acc 1 / report/cont_pos_loss 3.2e-11 / 
report/cont_pred 1 / report/cont_rate 1 / report/dyn_loss_mean 1.54 / report/dyn_loss_std 3.03 / report/image_loss_mean 0.16 / report/image_loss_std 0.25 / report/model_loss_mean 1.15 / report/model_loss_std 2 / report/post_ent_mag 52.27 / report/post_ent_max 52.27 / 
report/post_ent_mean 37.73 / report/post_ent_min 25.11 / report/post_ent_std 4.68 / report/prior_ent_mag 64.31 / report/prior_ent_max 64.31 / report/prior_ent_mean 38.9 / report/prior_ent_min 29.8 / report/prior_ent_std 5.7 / report/rep_loss_mean 1.54 / 
report/rep_loss_std 3.03 / report/reward_avg 1.12 / report/reward_loss_mean 0.06 / report/reward_loss_std 0.06 / report/reward_max_data 2 / report/reward_max_pred 2 / report/reward_neg_acc 1 / report/reward_neg_loss 1.3e-6 / report/reward_pos_acc 1 / 
report/reward_pos_loss 0.11 / report/reward_pred 1.12 / report/reward_rate 0.56 / eval/cont_avg 1 / eval/cont_loss_mean 4.2e-11 / eval/cont_loss_std 1.4e-10 / eval/cont_neg_acc nan / eval/cont_neg_loss nan / eval/cont_pos_acc 1 / eval/cont_pos_loss 4.2e-11 / 
eval/cont_pred 1 / eval/cont_rate 1 / eval/dyn_loss_mean 1.57 / eval/dyn_loss_std 3.03 / eval/image_loss_mean 0.16 / eval/image_loss_std 0.28 / eval/model_loss_mean 1.21 / eval/model_loss_std 2.01 / eval/post_ent_mag 48.47 / eval/post_ent_max 48.47 / eval/post_ent_mean 
37.74 / eval/post_ent_min 29.01 / eval/post_ent_std 4.29 / eval/prior_ent_mag 64.31 / eval/prior_ent_max 64.31 / eval/prior_ent_mean 38.94 / eval/prior_ent_min 31.87 / eval/prior_ent_std 5.37 / eval/rep_loss_mean 1.57 / eval/rep_loss_std 3.03 / eval/reward_avg 1.5 / 
eval/reward_loss_mean 0.1 / eval/reward_loss_std 0.21 / eval/reward_max_data 2 / eval/reward_max_pred 2 / eval/reward_neg_acc 1 / eval/reward_neg_loss 5.7e-3 / eval/reward_pos_acc 1 / eval/reward_pos_loss 0.13 / eval/reward_pred 1.49 / eval/reward_rate 0.75 / 
replay/size 5.7e5 / replay/inserts 3884 / replay/samples 3.1e4 / replay/insert_wait_avg 3.8e-6 / replay/insert_wait_frac 1 / replay/sample_wait_avg 1.1e-6 / replay/sample_wait_frac 1 / eval_replay/size 1e5 / eval_replay/inserts 3507 / eval_replay/samples 16 / 
eval_replay/insert_wait_avg 2.7e-6 / eval_replay/insert_wait_frac 1 / eval_replay/sample_wait_avg 1.3e-6 / eval_replay/sample_wait_frac 1 / timer/duration 300.02 / timer/env.step_count 3884 / timer/env.step_total 19.34 / timer/env.step_frac 0.06 / timer/env.step_avg 
5e-3 / timer/env.step_min 4.3e-3 / timer/env.step_max 0.02 / timer/replay._sample_count 3.1e4 / timer/replay._sample_total 397.14 / timer/replay._sample_frac 1.32 / timer/replay._sample_avg 0.01 / timer/replay._sample_min 1.4e-3 / timer/replay._sample_max 0.21 / 
timer/agent.save_count 0 / timer/agent.save_total 0 / timer/agent.save_frac 0 / timer/agent.policy_count 7391 / timer/agent.policy_total 16.24 / timer/agent.policy_frac 0.05 / timer/agent.policy_avg 2.2e-3 / timer/agent.policy_min 1.7e-3 / timer/agent.policy_max 9.1e-3 
/ timer/dataset_train_count 1942 / timer/dataset_train_total 0.15 / timer/dataset_train_frac 5.2e-4 / timer/dataset_train_avg 8e-5 / timer/dataset_train_min 6.9e-5 / timer/dataset_train_max 5.2e-4 / timer/agent.train_count 1942 / timer/agent.train_total 246.14 / 
timer/agent.train_frac 0.82 / timer/agent.train_avg 0.13 / timer/agent.train_min 0.12 / timer/agent.train_max 0.31 / timer/agent.report_count 2 / timer/agent.report_total 0.11 / timer/agent.report_frac 3.7e-4 / timer/agent.report_avg 0.06 / timer/agent.report_min 0.06 /
timer/agent.report_max 0.06 / timer/dataset_eval_count 1 / timer/dataset_eval_total 3.6e-5 / timer/dataset_eval_frac 1.2e-7 / timer/dataset_eval_avg 3.6e-5 / timer/dataset_eval_min 3.6e-5 / timer/dataset_eval_max 3.6e-5 / fps 25.89
